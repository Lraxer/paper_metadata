@inproceedings{DBLP:conf/nsdi/WangLNZLWXFCGWL23,
	author = {Zilong Wang and
                  Layong Luo and
                  Qingsong Ning and
                  Chaoliang Zeng and
                  Wenxue Li and
                  Xinchen Wan and
                  Peng Xie and
                  Tao Feng and
                  Ke Cheng and
                  Xiongfei Geng and
                  Tianhao Wang and
                  Weicheng Ling and
                  Kejia Huo and
                  Pingbo An and
                  Kui Ji and
                  Shideng Zhang and
                  Bin Xu and
                  Ruiqing Feng and
                  Tao Ding and
                  Kai Chen and
                  Chuanxiong Guo},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {{SRNIC:} {A} Scalable Architecture for {RDMA} NICs},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {1--14},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/wang-zilong},
	timestamp = {Tue, 09 Apr 2024 09:15:19 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/WangLNZLWXFCGWL23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {RDMA is expected to be highly scalable: to perform well in large-scale data center networks where packet losses are inevitable (i.e., high network scalability), and to support a large number of performant connections per server (i.e., high connection scalability). Commercial RoCEv2 NICs (RNICs) fall short on scalability as they rely on a lossless, limited-scale network fabric and support only a small number of performant connections. Recent work IRN improves the network scalability by relaxing the lossless network requirement, but the connection scalability issue remains unaddressed. In this paper, we aim to address the connection scalability challenge, while maintaining high performance and low CPU overhead as commercial RNICs, and high network scalability as IRN, by designing SRNIC, a Scalable RDMA NIC architecture. Our key insight in SRNIC is that, on-chip data structures and their memory requirements in RNICs can be minimized with careful protocol and architecture co-designs to improve connection scalability. Guided by this insight, we analyze all data structures involved in an RDMA conceptual model, and remove them as many as possible with RDMA protocol header modifications and architectural innovations, including cache-free QP scheduler and memory-free selective repeat. We implement a fully functional SRNIC prototype using FPGA. Experiments show that, SRNIC achieves 10K performant connections on chip and outperforms commercial RNICs by 18x in terms of normalized connection scalability (i.e., the number of performant connections per 1MB memory), while achieving 97 Gbps throughput and 3.3 Î¼s latency with less than 5% CPU overhead, and maintaining high network scalability.}
}


@inproceedings{DBLP:conf/nsdi/0004J0WZT0023,
	author = {Kefei Liu and
                  Zhuo Jiang and
                  Jiao Zhang and
                  Haoran Wei and
                  Xiaolong Zhong and
                  Lizhuang Tan and
                  Tian Pan and
                  Tao Huang},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {Hostping: Diagnosing Intra-host Network Bottlenecks in {RDMA} Servers},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {15--29},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/liu-kefei},
	timestamp = {Thu, 11 May 2023 17:08:22 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/0004J0WZT0023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Intra-host networking was considered robust in the RDMA (Remote Direct Memory Access) network and received little attention. However, as the RNIC (RDMA NIC) line rate increases rapidly to multi-hundred gigabits, the intra-host network becomes a potential performance bottleneck for network applications. Intra-host network bottlenecks may result in degraded intra-host bandwidth and increased intra-host latency, which can severely impact network performance. However, when intra-host bottlenecks occur, they can hardly be noticed due to the lack of a monitoring system. Furthermore, existing bottleneck diagnosis mechanisms fail to diagnose intra-host bottlenecks efficiently. In this paper, we analyze the symptom of intra-host bottlenecks based on our longterm troubleshooting experience and propose Hostping, the first bottleneck monitoring and diagnosis system dedicated to intra-host networks. The core idea of Hostping is conducting loopback tests between RNICs and endpoints within the host to measure intra-host latency and bandwidth. Hostping not only discovers intra-host bottlenecks we already knew but also reveals six bottlenecks we did not notice before.}
}


@inproceedings{DBLP:conf/nsdi/Kong0BXERPLZ23,
	author = {Xinhao Kong and
                  Jingrong Chen and
                  Wei Bai and
                  Yechen Xu and
                  Mahmoud Elhaddad and
                  Shachar Raindel and
                  Jitendra Padhye and
                  Alvin R. Lebeck and
                  Danyang Zhuo},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {Understanding {RDMA} Microarchitecture Resources for Performance Isolation},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {31--48},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/kong},
	timestamp = {Wed, 12 Jul 2023 08:21:23 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/Kong0BXERPLZ23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recent years have witnessed the wide adoption of RDMA in the cloud to accelerate first-party workloads and achieve cost savings by freeing up CPU cycles. Now cloud providers are working towards supporting RDMA in general-purpose guest VMs to benefit third-party workloads. To this end, cloud providers must provide strong performance isolation so that the RDMA workloads of one tenant do not adversely impact the RDMA performance of another tenant. Despite many efforts on network performance isolation in the public cloud, we find that RDMA brings unique challenges due to its complex NIC microarchitecture resources (e.g., the NIC cache). In this paper, we aim to systematically understand the impact of RNIC microarchitecture resources on performance isolation. We present a model that represents how RDMA operations use RNIC resources. Using this model, we develop a test suite to evaluate RDMA performance isolation solutions. Our test suite can break all existing solutions in various scenarios. Our results are acknowledged and reproduced by one of the largest RDMA NIC vendors. Finally, based on the test results, we summarize new insights on designing future RDMA performance isolation solutions.}
}


@inproceedings{DBLP:conf/nsdi/BaiAAABBBBCCCCE23,
	author = {Wei Bai and
                  Shanim Sainul Abdeen and
                  Ankit Agrawal and
                  Krishan Kumar Attre and
                  Paramvir Bahl and
                  Ameya Bhagat and
                  Gowri Bhaskara and
                  Tanya Brokhman and
                  Lei Cao and
                  Ahmad Cheema and
                  Rebecca Chow and
                  Jeff Cohen and
                  Mahmoud Elhaddad and
                  Vivek Ette and
                  Igal Figlin and
                  Daniel Firestone and
                  Mathew George and
                  Ilya German and
                  Lakhmeet Ghai and
                  Eric Green and
                  Albert G. Greenberg and
                  Manish Gupta and
                  Randy Haagens and
                  Matthew Hendel and
                  Ridwan Howlader and
                  Neetha John and
                  Julia Johnstone and
                  Tom Jolly and
                  Greg Kramer and
                  David Kruse and
                  Ankit Kumar and
                  Erica Lan and
                  Ivan Lee and
                  Avi Levy and
                  Marina Lipshteyn and
                  Xin Liu and
                  Chen Liu and
                  Guohan Lu and
                  Yuemin Lu and
                  Xiakun Lu and
                  Vadim Makhervaks and
                  Ulad Malashanka and
                  David A. Maltz and
                  Ilias Marinos and
                  Rohan Mehta and
                  Sharda Murthi and
                  Anup Namdhari and
                  Aaron Ogus and
                  Jitendra Padhye and
                  Madhav Pandya and
                  Douglas Phillips and
                  Adrian Power and
                  Suraj Puri and
                  Shachar Raindel and
                  Jordan Rhee and
                  Anthony Russo and
                  Maneesh Sah and
                  Ali Sheriff and
                  Chris Sparacino and
                  Ashutosh Srivastava and
                  Weixiang Sun and
                  Nick Swanson and
                  Fuhou Tian and
                  Lukasz Tomczyk and
                  Vamsi Vadlamuri and
                  Alec Wolman and
                  Ying Xie and
                  Joyce Yom and
                  Lihua Yuan and
                  Yanzhao Zhang and
                  Brian Zill},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {Empowering Azure Storage with {RDMA}},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {49--67},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/bai},
	timestamp = {Mon, 18 Sep 2023 15:26:48 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/BaiAAABBBBCCCCE23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Given the wide adoption of disaggregated storage in public clouds, networking is the key to enabling high performance and high reliability in a cloud storage service. In Azure, we choose Remote Direct Memory Access (RDMA) as our transport and aim to enable it for both storage frontend traffic (between compute virtual machines and storage clusters) and backend traffic (within a storage cluster) to fully realize its benefits. As compute and storage clusters may be located in different datacenters within an Azure region, we need to support RDMA at regional scale. This work presents our experience in deploying intra-region RDMA to support storage workloads in Azure. The high complexity and heterogeneity of our infrastructure bring a series of new challenges, such as the problem of interoperability between different types of RDMA network interface cards. We have made several changes to our network infrastructure to address these challenges. Today, around 70% of traffic in Azure is RDMA and intra-region RDMA is supported in all Azure public regions. RDMA helps us achieve significant disk I/O performance improvements and CPU core savings.}
}


@inproceedings{DBLP:conf/nsdi/WuZBL023,
	author = {Bingyang Wu and
                  Zili Zhang and
                  Zhihao Bai and
                  Xuanzhe Liu and
                  Xin Jin},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {Transparent {GPU} Sharing in Container Clouds for Deep Learning Workloads},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {69--85},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/wu},
	timestamp = {Thu, 11 May 2023 17:08:22 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/WuZBL023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Containers are widely used for resource management in datacenters. A common practice to support deep learning (DL) training in container clouds is to statically bind GPUs to containers in entirety. Due to the diverse resource demands of DL jobs in production, a significant number of GPUs are underutilized. As a result, GPU clusters have low GPU utilization, which leads to a long job completion time because of queueing. We present TGS (Transparent GPU Sharing), a system that provides transparent GPU sharing to DL training in container clouds. In stark contrast to recent application-layer solutions for GPU sharing, TGS operates at the OS layer beneath containers. Transparency allows users to use any software to develop models and run jobs in their containers. TGS leverages adaptive rate control and transparent unified memory to simultaneously achieve high GPU utilization and performance isolation. It ensures that production jobs are not greatly affected by opportunistic jobs on shared GPUs. We have built TGS and integrated it with Docker and Kubernetes. Experiments show that (i) TGS has little impact on the throughput of production jobs; (ii) TGS provides similar throughput for opportunistic jobs as the state-of-the-art application-layer solution AntMan, and improves their throughput by up to 15Ã compared to the existing OS-layer solution MPS.}
}


@inproceedings{DBLP:conf/nsdi/HwangP0Q0X23,
	author = {Changho Hwang and
                  KyoungSoo Park and
                  Ran Shu and
                  Xinyuan Qu and
                  Peng Cheng and
                  Yongqiang Xiong},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {{ARK:} GPU-driven Code Execution for Distributed Deep Learning},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {87--101},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/hwang},
	timestamp = {Thu, 11 May 2023 17:08:22 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/HwangP0Q0X23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Modern state-of-the-art deep learning (DL) applications tend to scale out to a large number of parallel GPUs. Unfortunately, we observe that the collective communication overhead across GPUs is often the key limiting factor of performance for distributed DL. It under-utilizes the networking bandwidth by frequent transfers of small data chunks, which also incurs a substantial I/O overhead on GPU that interferes with computation on GPU. The root cause lies in the inefficiency of CPU-based communication event handling as well as the inability to control the GPU's internal DMA engine with GPU threads. To address the problem, we propose a GPU-driven code execution system that leverages a GPU-controlled hardware DMA engine for I/O offloading. Our custom DMA engine pipelines multiple DMA requests to support efficient small data transfer while it eliminates the I/O overhead on GPU cores. Unlike existing GPU DMA engines initiated only by CPU, we let GPU threads to directly control DMA operations, which leads to a highly efficient system where GPUs drive their own execution flow and handle communication events autonomously without CPU intervention. Our prototype DMA engine achieves a line-rate from a message size as small as 8KB (3.9x better throughput) with only 4.3us of communication latency (9.1x faster) while it incurs little interference with computation on GPU, achieving 1.8x higher all-reduce throughput in a real training workload.}
}


@inproceedings{DBLP:conf/nsdi/LiuC00ZHPCCG23,
	author = {Tianfeng Liu and
                  Yangrui Chen and
                  Dan Li and
                  Chuan Wu and
                  Yibo Zhu and
                  Jun He and
                  Yanghua Peng and
                  Hongzheng Chen and
                  Hongzhi Chen and
                  Chuanxiong Guo},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {{BGL:} GPU-Efficient {GNN} Training by Optimizing Graph Data {I/O}
                  and Preprocessing},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {103--118},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/liu-tianfeng},
	timestamp = {Thu, 11 May 2023 17:08:22 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/LiuC00ZHPCCG23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graph neural networks (GNNs) have extended the success of deep neural networks (DNNs) to non-Euclidean graph data, achieving ground-breaking performance on various tasks such as node classification and graph property prediction. Nonetheless, existing systems are inefficient to train large graphs with billions of nodes and edges with GPUs. The main bottlenecks are the process of preparing data for GPUs â subgraph sampling and feature retrieving. This paper proposes BGL, a distributed GNN training system designed to address the bottlenecks with a few key ideas. First, we propose a dynamic cache engine to minimize feature retrieving traffic. By co-designing caching policy and the order of sampling, we find a sweet spot of low overhead and a high cache hit ratio. Second, we improve the graph partition algorithm to reduce cross-partition communication during subgraph sampling. Finally, careful resource isolation reduces contention between different data preprocessing stages. Extensive experiments on various GNN models and large graph datasets show that BGL significantly outperforms existing GNN training systems by 1.9x on average.}
}


@inproceedings{DBLP:conf/nsdi/YouCC23,
	author = {Jie You and
                  Jae{-}Won Chung and
                  Mosharaf Chowdhury},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {Zeus: Understanding and Optimizing {GPU} Energy Consumption of {DNN}
                  Training},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {119--139},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/you},
	timestamp = {Thu, 11 May 2023 17:08:22 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/YouCC23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Training deep neural networks (DNNs) is becoming increasingly more resource- and energy-intensive every year. Unfortunately, existing works primarily focus on optimizing DNN training for faster completion, often without considering the impact on energy efficiency. In this paper, we observe that common practices to improve training performance can often lead to inefficient energy usage. More importantly, we demonstrate that there is a tradeoff between energy consumption and performance optimization. To this end, we propose Zeus, an optimization framework to navigate this tradeoff by automatically finding optimal job- and GPU-level configurations for recurring DNN training jobs. Zeus uses an online exploration-exploitation approach in conjunction with just-in-time energy profiling, averting the need for expensive offline measurements, while adapting to data drifts over time. Our evaluation shows that Zeus can improve the energy efficiency of DNN training by 15.3%â75.8% for diverse workloads.}
}


@inproceedings{DBLP:conf/nsdi/0002WLXKALYZ23,
	author = {Jingrong Chen and
                  Yongji Wu and
                  Shihan Lin and
                  Yechen Xu and
                  Xinhao Kong and
                  Thomas Anderson and
                  Matthew Lentz and
                  Xiaowei Yang and
                  Danyang Zhuo},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {Remote Procedure Call as a Managed System Service},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {141--159},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/chen-jingrong},
	timestamp = {Tue, 22 Aug 2023 20:43:01 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/0002WLXKALYZ23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Remote Procedure Call (RPC) is a widely used abstraction for cloud computing. The programmer specifies type information for each remote procedure, and a compiler generates stub code linked into each application to marshal and unmarshal arguments into message buffers. Increasingly, however, application and service operations teams need a high degree of visibility and control over the flow of RPCs between services, leading many installations to use sidecars or service mesh proxies for manageability and policy flexibility. These sidecars typically involve inspection and modification of RPC data that the stub compiler had just carefully assembled, adding needless overhead. Further, upgrading diverse application RPC stubs to use advanced hardware capabilities such as RDMA or DPDK is a long and involved process, and often incompatible with sidecar policy control. In this paper, we propose, implement, and evaluate a novel approach, where RPC marshalling and policy enforcement are done as a system service rather than as a library linked into each application. Applications specify type information to the RPC system as before, while the RPC service executes policy engines and arbitrates resource use, and then marshals data customized to the underlying network hardware capabilities. Our system, mRPC, also supports live upgrades so that both policy and marshalling code can be updated transparently to application code. Compared with using a sidecar, mRPC speeds up a standard microservice benchmark, DeathStarBench, by up to 2.5Ã while having a higher level of policy flexibility and availability.}
}


@inproceedings{DBLP:conf/nsdi/WangQMLCNKX23,
	author = {Chenxi Wang and
                  Yifan Qiao and
                  Haoran Ma and
                  Shi Liu and
                  Wenguang Chen and
                  Ravi Netravali and
                  Miryung Kim and
                  Guoqing Harry Xu},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {Canvas: Isolated and Adaptive Swapping for Multi-Applications on Remote
                  Memory},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {161--179},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/wang-chenxi},
	timestamp = {Thu, 11 May 2023 17:08:22 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/WangQMLCNKX23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Remote memory techniques for datacenter applications have recently gained a great deal of popularity. Existing remote memory techniques focus on the efficiency of a single application setting only. However, when multiple applications co-run on a remote-memory system, significant interference could occur, resulting in unexpected slowdowns even if the same amounts of physical resources are granted to each application. This slowdown stems from massive sharing in applications' swap data paths. Canvas is a redesigned swap system that fully isolates swap paths for remote-memory applications. Canvas allows each application to possess its dedicated swap partition, swap cache, prefetcher, and RDMA bandwidth. Swap isolation lays a foundation for adaptive optimization techniques based on each application's own access patterns and needs. We develop three such techniques: (1) adaptive swap entry allocation, (2) semantics-aware prefetching, and (3) two-dimensional RDMA scheduling. A thorough evaluation with a set of widely-deployed applications demonstrates that Canvas minimizes performance variation and dramatically reduces performance degradation.}
}


@inproceedings{DBLP:conf/nsdi/QiaoWRBL0KX23,
	author = {Yifan Qiao and
                  Chenxi Wang and
                  Zhenyuan Ruan and
                  Adam Belay and
                  Qingda Lu and
                  Yiying Zhang and
                  Miryung Kim and
                  Guoqing Harry Xu},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {Hermit: Low-Latency, High-Throughput, and Transparent Remote Memory
                  via Feedback-Directed Asynchrony},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {181--198},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/qiao},
	timestamp = {Thu, 11 May 2023 17:08:22 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/QiaoWRBL0KX23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Remote memory techniques are gaining traction in datacenters because they can significantly improve memory utilization. A popular approach is to use kernel-level, page-based memory swapping to deliver remote memory as it is transparent, enabling existing applications to benefit without modifications. Unfortunately, current implementations suffer from high software overheads, resulting in significantly worse tail latency and throughput relative to local memory. Hermit is a redesigned swap system that overcomes this limitation through a novel technique called adaptive, feedback-directed asynchrony. It takes non-urgent but time-consuming operations (e.g., swap-out, cgroup charge, I/O deduplication, etc.) off the fault-handling path and executes them asynchronously. Different from prior work such as Fastswap, Hermit collects runtime feedback and uses it to direct how asynchrony should be performedâi.e., whether asynchronous operations should be enabled, the level of asynchrony, and how asynchronous operations should be scheduled. We implemented Hermit in Linux 5.14. An evaluation with a set of latency-critical applications shows that Hermit delivers low-latency remote memory. For example, it reduces the 99th percentile latency of Memcached by 99.7% from 36 ms to 91 Âµs. Running Hermit over batch applications improves their overall throughput by 1.24Ã on average. These results are achieved without changing a single line of user code.}
}


@inproceedings{DBLP:conf/nsdi/ZhaoWX23,
	author = {Bohan Zhao and
                  Wenfei Wu and
                  Wei Xu},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {NetRPC: Enabling In-Network Computation in Remote Procedure Calls},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {199--217},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/zhao-bohan},
	timestamp = {Thu, 11 May 2023 17:08:22 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/ZhaoWX23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {People have shown that in-network computation (INC) significantly boosts performance in many application scenarios include distributed training, MapReduce, agreement, and network monitoring. However, existing INC programming is unfriendly to the normal application developers, demanding tedious network engineering details like flow control, packet organization, chip-specific programming language, and ASIC architecture with many limitations. We propose a general INC-enabled RPC system, NetRPC. NetRPC provides a set of familiar and lightweight interfaces for software developers to describe an INC application using a traditional RPC programming model. NetRPC also proposes a general-purpose INC implementation together with a set of optimization techniques to guarantee the efficiency of various types of INC applications running on a shared INC data plane. We conduct extensive experiments on different types of applications on the real testbed. Results show that using only about 5% or even fewer human-written lines of code, NetRPC can achieve performance similar to the state-of-the-art INC solutions.}
}


@inproceedings{DBLP:conf/nsdi/ArslanL0D23,
	author = {Serhat Arslan and
                  Yuliang Li and
                  Gautam Kumar and
                  Nandita Dukkipati},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {Bolt: Sub-RTT Congestion Control for Ultra-Low Latency},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {219--236},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/arslan},
	timestamp = {Thu, 11 May 2023 17:08:22 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/ArslanL0D23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Data center networks are inclined towards increasing line rates to 200Gbps and beyond to satisfy the performance requirements of applications such as NVMe and distributed ML. With larger Bandwidth Delay Products (BDPs), an increasing number of transfers fit within a few BDPs. These transfers are not only more performance-sensitive to congestion, but also bring more challenges to congestion control (CC) as they leave little time for CC to make the right decisions. Therefore, CC is under more pressure than ever before to achieve minimal queuing and high link utilization, leaving no room for imperfect control decisions. We identify that for CC to make quick and accurate decisions, the use of precise congestion signals and minimization of the control loop delay are vital. We address these issues by designing Bolt, an attempt to push congestion control to its theoretical limits by harnessing the power of programmable data planes. Bolt is founded on three core ideas, (i) Sub-RTT Control (SRC) reacts to congestion faster than RTT control loop delay, (ii) Proactive Ramp-Up (PRU) foresees flow completions in the future to promptly occupy released bandwidth, and (iii) Supply matching (SM) explicitly matches bandwidth demand with supply to maximize utilization. Our experiments in testbed and simulations demonstrate that Bolt reduces 99th-p latency by 80% and improves 99th-p flow completion time by up to 3Ã compared to Swift and HPCC while maintaining near line-rate utilization even at 400Gbps.}
}


@inproceedings{DBLP:conf/nsdi/SharafzadehAG23,
	author = {Erfan Sharafzadeh and
                  Sepehr Abdous and
                  Soudeh Ghorbani},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {Understanding the impact of host networking elements on traffic bursts},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {237--254},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/sharafzadeh},
	timestamp = {Thu, 11 May 2023 17:08:22 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/SharafzadehAG23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Conventional host networking features various traffic shaping layers (e.g., buffers, schedulers, and pacers) with complex interactions and wide implications for performance metrics. These interactions can lead to large bursts at various time scales. Understanding the nature of traffic bursts is important for optimal resource provisioning, congestion control, buffer sizing, and traffic prediction but is challenging due to the complexity and feature velocity in host networking. We develop Valinor, a traffic measurement framework that consists of eBPF hooks and measurement modules in a programmable network. Valinor offers visibility into traffic burstiness over a wide span of timescales (nanosecond- to secondscale) at multiple vantage points. We deploy Valinor to analyze the burstiness of various classes of congestion control algorithms, qdiscs, Linux process scheduling, NIC packet scheduling, and hardware offloading. Our analysis counters the assumption that burstiness is primarily a function of the application layer and preserved by protocol stacks, and highlights the pronounced role of lower layers in the formation and suppression of bursts. We also show the limitations of canonical burst countermeasures (e.g., TCP pacing and qdisc scheduling) due to the intervening nature of segmentation offloading and fixed-function NIC scheduling. Finally, we demonstrate that, far from a universal invariant, burstiness varies significantly across host stacks. Our findings underscore the need for a measurement framework such as Valinor for regular burst analysis.}
}


@inproceedings{DBLP:conf/nsdi/WangML0NCD23,
	author = {Weitao Wang and
                  Masoud Moshref and
                  Yuliang Li and
                  Gautam Kumar and
                  T. S. Eugene Ng and
                  Neal Cardwell and
                  Nandita Dukkipati},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {Poseidon: Efficient, Robust, and Practical Datacenter {CC} via Deployable
                  {INT}},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {255--274},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/wang-weitao},
	timestamp = {Sat, 30 Sep 2023 09:54:14 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/WangML0NCD23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The difficulty in gaining visibility into the fine-timescale hop-level congestion state of networks has been a key challenge faced by congestion control (CC) protocols for decades. However, the emergence of commodity switches supporting in-network telemetry (INT) enables more advanced CC. In this paper, we present Poseidon, a novel CC protocol that exploits INT to address blind spots of CC algorithms and realize several fundamentally advantageous properties. First, Poseidon is efficient: it achieves low queuing delay, high throughput, and fast convergence. Furthermore, Poseidon decouples bandwidth fairness from the traditional AIMD control law, using a novel adaptive update scheme that converges quickly and smooths out oscillations. Second, Poseidon is robust: it realizes CC for the actual bottleneck hop, and achieves maxmin fairness across traffic patterns, including multi-hop and reverse-path congestion. Third, Poseidon is practical: it is amenable to incremental brownfield deployment in networks that mix INT and non-INT switches. We show, via testbed and simulation experiments, that Poseidon provides significant improvements over the state-of-the-art Swift CC algorithm across key metrics â RTT, throughput, fairness, and convergence â resulting in end-to-end application performance gains. Evaluated across several scenarios, Poseidon lowers fabric RTT by up to 50%, reduces time to converge up to 12Ã, and decreases throughput variation across flows by up to 70%. Collectively, these improvements reduce message transfer time by more than 61% on average and 14.5Ã at 99.9p.}
}


@inproceedings{DBLP:conf/nsdi/KimNGKYP23,
	author = {Taehyun Kim and
                  Deondre Martin Ng and
                  Junzhi Gong and
                  Youngjin Kwon and
                  Minlan Yu and
                  KyoungSoo Park},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {Rearchitecting the {TCP} Stack for I/O-Offloaded Content Delivery},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {275--292},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/kim-taehyun},
	timestamp = {Thu, 11 May 2023 17:08:22 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/KimNGKYP23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The recent advancement of high-bandwidth I/O devices enables scalable delivery of online content. Unfortunately, the traditional programming model for content servers has a tight dependency on the CPU, which severely limits the overall performance. Our experiments reveal that over 70% of CPU cycles are spent on simple tasks such as disk and network I/O operations in online content delivery. In this work, we present IO-TCP, a split TCP stack design that drastically reduces the burden on CPU for online content delivery. IO-TCP offloads disk I/O and TCP packet transfer to SmartNIC while the rest of the operations are executed on the CPU side. This division of labor realizes the separation of control and data planes of a TCP stack where the CPU side assumes the full control of the stack operation while only the data plane operations are offloaded to SmartNIC for high performance. Our evaluation shows that IO-TCP-ported lighttpd with a single CPU core outperforms the Atlas server and lighttpd on Linux TCP for TLS file transfer by 1.8x and 2.1x, respectively, even if they use all 10 CPU cores.}
}


@inproceedings{DBLP:conf/nsdi/ChoiMLP023,
	author = {Inho Choi and
                  Ellis Michael and
                  Yunfan Li and
                  Dan R. K. Ports and
                  Jialin Li},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {Hydra: Serialization-Free Network Ordering for Strongly Consistent
                  Distributed Applications},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {293--320},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/choi},
	timestamp = {Thu, 11 May 2023 17:08:22 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/ChoiMLP023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Many distributed systems, e.g., state machine replication and distributed databases, rely on establishing a consistent order of operations on groups of nodes in the system. Traditionally, this ordering has been established by application-level protocols like Paxos or two-phase locking. Recent work has shown significant performance improvements are attainable by making ordering a network service, but current network sequencing implementations require routing all requests through a single sequencer â leading to scalability, fault tolerance, and load balancing limitations. Our work, Hydra, overcomes these limitations by using a distributed set of network sequencers to provide network ordering. Hydra leverages loosely synchronized clocks on network sequencers to establish message ordering across them, per-sequencer sequence numbers to detect message drops, and periodic timestamp messages to enforce progress when some sequencers are idle. To demonstrate the benefit of Hydra, we co-designed a state machine replication protocol and a distributed transactional system using the Hydra network primitive. Compared to serialization-based network ordering systems, Hydra shows equivalent performance improvement over traditional approaches in both applications, but with significantly higher scalability, shorter sequencer failover time, and better network-level load balancing.}
}


@inproceedings{DBLP:conf/nsdi/ZhangXAVM23,
	author = {Lei Zhang and
                  Zhiqiang Xie and
                  Vaastav Anand and
                  Ymir Vigfusson and
                  Jonathan Mace},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {The Benefit of Hindsight: Tracing Edge-Cases in Distributed Systems},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {321--339},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/zhang-lei},
	timestamp = {Thu, 11 May 2023 17:08:22 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/ZhangXAVM23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Today's distributed tracing frameworks are ill-equipped to troubleshoot rare edge-case requests. The crux of the problem is a trade-off between specificity and overhead. On the one hand, frameworks can indiscriminately select requests to trace when they enter the system (head sampling), but this is unlikely to capture a relevant edge-case trace because the framework cannot know which requests will be problematic until after-the-fact. On the other hand, frameworks can trace everything and later keep only the interesting edge-case traces (tail sampling), but this has high overheads on the traced application and enormous data ingestion costs. In this paper we circumvent this trade-off for any edge-case with symptoms that can be programmatically detected, such as high tail latency, errors, and bottlenecked queues. We propose a lightweight and always-on distributed tracing system, Hindsight, which implements a retroactive sampling abstraction: instead of eagerly ingesting and processing traces, Hindsight lazily retrieves trace data only after symptoms of a problem are detected. Hindsight is analogous to a car dash-cam that, upon detecting a sudden jolt in momentum, persists the last hour of footage. Developers using Hindsight receive the exact edge-case traces they desire without undue overhead or dependence on luck. Our evaluation shows that Hindsight scales to millions of requests per second, adds nanosecondlevel overhead to generate trace data, handles GB/s of data per node, transparently integrates with existing distributed tracing systems, and successfully persists full, detailed traces in real-world use cases when edge-case problems are detected.}
}


@inproceedings{DBLP:conf/nsdi/MustafaKDV23,
	author = {Tammam Mustafa and
                  Konstantinos Kallas and
                  Pratyush Das and
                  Nikos Vasilakis},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {DiSh: Dynamic Shell-Script Distribution},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {341--356},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/mustafa},
	timestamp = {Thu, 11 May 2023 17:08:22 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/MustafaKDV23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Shell scripting remains prevalent for automation and data-processing tasks, partly due to its dynamic featuresâe.g., expansion, substitutionâand language agnosticismâi.e., the ability to combine third-party commands implemented in any programming language. Unfortunately, these characteristics hinder automated shell-script distribution, often necessary for dealing with large datasets that do not fit on a single computer. This paper introduces DiSh, a system that distributes the execution of dynamic shell scripts operating on distributed filesystems. DiSh is designed as a shim that applies program analyses and transformations to leverage distributed computing, while delegating all execution to the underlying shell available on each computing node. As a result, DiSh does not require modifications to shell scripts and maintains compatibility with existing shells and legacy functionality. We evaluate DiSh against several options available to users today: (i) Bash, a single-node shell-interpreter baseline, (ii) PaSh, a state-of-the-art automated-parallelization system, and (iii) Hadoop Streaming, a MapReduce system that supports language-agnostic third-party components. Combined, our results demonstrate that DiSh offers significant performance gains, requires no developer effort, and handles arbitrary dynamic behaviors pervasive in real-world shell scripts.}
}


@inproceedings{DBLP:conf/nsdi/AlimadadiMCFM023,
	author = {Mohammadreza Alimadadi and
                  Hieu Mai and
                  Shenghsun Cho and
                  Michael Ferdman and
                  Peter A. Milder and
                  Shuai Mu},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {Waverunner: An Elegant Approach to Hardware Acceleration of State
                  Machine Replication},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {357--374},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/alimadadi},
	timestamp = {Thu, 11 May 2023 17:08:22 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/AlimadadiMCFM023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {State machine replication (SMR) is a core mechanism for building highly available and consistent systems. In this paper, we propose Waverunner, a new approach to accelerate SMR using FPGA-based SmartNICs. Our approach does not implement the entire SMR system in hardware; instead, it is a hybrid software/hardware system. We make the observation that, despite the complexity of SMR, the most common routineâthe data replicationâis actually simple. The complex parts (leader election, failure recovery, etc.) are rarely used in modern datacenters where failures are only occasional. These complex routines are not performance critical; their software implementations are fast enough and do not need acceleration. Therefore, our system uses FPGA assistance to accelerate data replication, and leaves the rest to the traditional software implementation of SMR. Our Waverunner approach is beneficial in both the common and the rare case situations. In the common case, the system runs at the speed of the network, with a 99th percentile latency of 1.8 Î¼s achieved without batching on minimum-size packets at network line rate (85.5 Gbps in our evaluation). In rare cases, to handle uncommon situations such as leader failure and failure recovery, the system uses traditional software to guarantee correctness, which is much easier to develop and maintain than hardware-based implementations. Overall, our experience confirms Waverunner as an effective and practical solution for hardware accelerated SMRâachieving most of the benefits of hardware acceleration with minimum added complexity and implementation effort.}
}


@inproceedings{DBLP:conf/nsdi/KludzeG23,
	author = {Atsutse Kludze and
                  Yasaman Ghasempour},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {LeakyScatter: {A} Frequency-Agile Directional Backscatter Network
                  Above 100 GHz},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {375--388},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/kludze},
	timestamp = {Thu, 11 May 2023 17:08:22 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/KludzeG23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Wireless backscattering has been deemed suitable for various emerging energy-constrained applications given its low-power architectures. Although existing backscatter nodes often operate at sub-6 GHz frequency bands, moving to the sub-THz bands offers significant advantages in scaling low-power connectivity to dense user populations; as concurrent transmissions can be separated in both spectral and spatial domains given the large swath of available bandwidth and laser-shaped beam directionality in this frequency regime. However, the power consumption and complexity of wireless devices increase significantly with frequency. In this paper, we present LeakyScatter, the first backscatter system that enables directional, low-power, and frequency-agile wireless links above 100 GHz. LeakyScatter departs from conventional backscatter designs and introduces a novel architecture that relies on aperture reciprocity in leaky-wave devices. We have fabricated LeakyScatter and evaluated its performance through extensive simulations and over-the-air experiments. Our results demonstrate a scalable wireless link above 100 GHz that is retrodirective and operates at a large bandwidth (tens of GHz) and ultra-low-power (zero power consumed for directional steering and â¤1 mW for data modulation).}
}


@inproceedings{DBLP:conf/nsdi/LiFWZXC23,
	author = {Xinyi Li and
                  Chao Feng and
                  Xiaojing Wang and
                  Yangfan Zhang and
                  Yaxiong Xie and
                  Xiaojiang Chen},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {RF-Bouncer: {A} Programmable Dual-band Metasurface for Sub-6 Wireless
                  Networks},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {389--404},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/li-xinyi},
	timestamp = {Thu, 11 May 2023 17:08:22 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/LiFWZXC23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Offloading the beamforming task from the endpoints to the metasurface installed in the propagation environment has attracted significant attention. Currently, most of the metasurface-based beamforming solutions are designed and optimized for operation on a single ISM band (either 2.4 GHz or 5 GHz). In this paper, we propose RF-Bouncer, a compact, low-cost, simple-structure programmable dual-band metasurface that supports concurrent beamforming on two Sub-6 ISM bands. By configuring the states of the meta-atoms, the metasurface is able to simultaneously steer the incident signals from two bands towards their desired departure angles. We fabricate the metasurface and validate its performance via extensive experiments. Experimental results demonstrate that RF-Bouncer achieves 15.4 dB average signal strength improvement and a 2.49Ã throughput improvement even with a relatively small 16 Ã 16 array of meta-atoms.}
}


@inproceedings{DBLP:conf/nsdi/GongKY23,
	author = {Junzhi Gong and
                  Anuj Kalia and
                  Minlan Yu},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {Scalable Distributed Massive {MIMO} Baseband Processing},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {405--417},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/gong},
	timestamp = {Thu, 11 May 2023 17:08:22 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/GongKY23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Massive MIMO (multiple-in multiple-out) is a key wireless technique to get higher bandwidth in modern mobile networks such as 5G. The large amount of computation required for massive MIMO baseband processing poses a challenge to the ongoing softwarization of radio access networks (RAN), in which mobile network operators are replacing specialized baseband processing chips with commodity servers. Existing software-based systems for massive MIMO fail to scale to increasingly larger MIMO dimensions with an ever-increasing number of antennas and users. This paper presents a new scalable distributed system called Hydra, designed to parallelize massive MIMO baseband processing while minimizing the overhead of distributing computation over multiple machines. Hydra's high scalability comes from reducing inter-server and inter-core communication at different stages of baseband processing. To do so, among other techniques, we take advantage of hardware features in modern commodity radios in novel ways. Our evaluation shows that Hydra can support over four times larger MIMO configurations than prior state-of-the-art systems, handling for the first time, 150*32 massive MIMO with three servers.}
}


@inproceedings{DBLP:conf/nsdi/Sentosa0GHM23,
	author = {William Sentosa and
                  Balakrishnan Chandrasekaran and
                  Philip Brighten Godfrey and
                  Haitham Hassanieh and
                  Bruce M. Maggs},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {DChannel: Accelerating Mobile Applications With Parallel High-bandwidth
                  and Low-latency Channels},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {419--436},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/sentosa},
	timestamp = {Thu, 11 May 2023 17:08:22 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/Sentosa0GHM23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Interactive mobile applications like web browsing and gaming are known to benefit significantly from low latency networking, as applications communicate with cloud servers and other users' devices. Emerging mobile channel standards have not met these needs: 5G's general-purpose eMBB channel has much higher bandwidth than 4G but empirically offers little improvement for common latency-sensitive applications, while its ultra-low-latency URLLC channel is targeted at only specific applications with very low bandwidth requirements. We explore a different direction for wireless channel design to address the fundamental bandwidth-latency tradeoff: utilizing two channelsâone high bandwidth, one low latencyâsimultaneously to improve performance of common Internet applications.  We design DChannel, a fine-grained packet-steering scheme that takes advantage of these parallel channels to transparently improve application performance.  With 5G channels, our trace-driven and live network experiments show that even though URLLC offers just 1% of the bandwidth of eMBB, using both channels can improve web page load time and responsiveness of common mobile apps by 16-40% compared to using exclusively eMBB. This approach may provide service providers important incentives to make low latency channels available for widespread use.}
}


@inproceedings{DBLP:conf/nsdi/YangWLCBKZLMSS23,
	author = {Zongheng Yang and
                  Zhanghao Wu and
                  Michael Luo and
                  Wei{-}Lin Chiang and
                  Romil Bhardwaj and
                  Woosuk Kwon and
                  Siyuan Zhuang and
                  Frank Sifei Luan and
                  Gautam Mittal and
                  Scott Shenker and
                  Ion Stoica},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {SkyPilot: An Intercloud Broker for Sky Computing},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {437--455},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/yang-zongheng},
	timestamp = {Thu, 11 May 2023 17:08:22 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/YangWLCBKZLMSS23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {To comply with the increasing number of government regulations about data placement and processing, and to protect themselves against major cloud outages, many users want the ability to easily migrate their workloads between clouds. In this paper we propose doing so not by imposing uniform and comprehensive standards, but by creating a fine-grained two-sided market via an intercloud broker. These brokers will allow users to view the cloud ecosystem not just as a collection of individual and largely incompatible clouds but as a more integrated Sky of Computing. We describe the design and implementation of an intercloud broker, named SkyPilot, evaluate its benefits, and report on its real-world usage.}
}


@inproceedings{DBLP:conf/nsdi/AgarwalNGSB23,
	author = {Anup Agarwal and
                  Shadi A. Noghabi and
                  {\'{I}}{\~{n}}igo Goiri and
                  Srinivasan Seshan and
                  Anirudh Badam},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {Unlocking unallocated cloud capacity for long, uninterruptible workloads},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {457--478},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/agarwal-anup},
	timestamp = {Thu, 11 May 2023 17:08:22 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/AgarwalNGSB23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cloud providers auction off unallocated resources at a low cost to avoid keeping hardware idle. One such mechanism is Harvest VMs (HVMs). These VMs grow and shrink as the unallocated resources in a server change. While HVMs are larger in size and less prone to eviction compared to other low-cost VMs, their resource variations severely slow down long-running, uninterruptible (hard to checkpoint/migrate) workloads. We characterize HVMs from a major cloud provider and discover large spatial variations in their stability and resources. We leverage this diversity by predicting which HVMs will be stable enough to run tasks without preemptions. We use the predictions to inform scheduling and resource acquisition decisions. Our evaluation with real workloads shows that we can reduce mean and tail (90th percentile) job completion times by 27% and 44% respectively, at 75% lower cost than regular VMs.}
}


@inproceedings{DBLP:conf/nsdi/McClureMBJNPRST23,
	author = {Sarah McClure and
                  Zeke Medley and
                  Deepak Bansal and
                  Karthick Jayaraman and
                  Ashok Narayanan and
                  Jitendra Padhye and
                  Sylvia Ratnasamy and
                  Anees Shaikh and
                  Rishabh Tewari},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {Invisinets: Removing Networking from Cloud Networks},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {479--496},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/mcclure},
	timestamp = {Thu, 11 May 2023 17:08:22 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/McClureMBJNPRST23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cloud tenant networks are complex to provision, configure, and manage. Tenants must figure out how to assemble, configure, test, etc. a large set of low-level building blocks in order to achieve their high-level goals. As these networks are increasingly spanning multiple clouds and on-premises infrastructure, the complexity scales poorly. We argue that the current cloud abstractions place an unnecessary burden on the tenant to become a seasoned network operator. We thus propose an alternative interface to the cloud provider's network resources in which a tenant's connectivity needs are reduced to a set of parameters associated with compute endpoints. Our API removes the tenant networking layer of cloud deployments altogether, placing its former duties primarily upon the cloud provider. We demonstrate that this API reduces the complexity experienced by tenants by 80-90% while maintaining a scalable and secure architecture. We provide a prototype of the underlying infrastructure changes necessary to support new functionality introduced by our interface and implement our API on top of current cloud APIs.}
}


@inproceedings{DBLP:conf/nsdi/ThorpeZEQJZNX23,
	author = {John Thorpe and
                  Pengzhan Zhao and
                  Jonathan Eyolfson and
                  Yifan Qiao and
                  Zhihao Jia and
                  Minjia Zhang and
                  Ravi Netravali and
                  Guoqing Harry Xu},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {Bamboo: Making Preemptible Instances Resilient for Affordable Training
                  of Large DNNs},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {497--513},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/thorpe},
	timestamp = {Thu, 11 May 2023 17:08:22 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/ThorpeZEQJZNX23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {DNN models across many domains continue to grow in size, resulting in high resource requirements for effective training, and unpalatable (and often unaffordable) costs for organizations and research labs across scales. This paper aims to significantly reduce training costs with effective use of preemptible instances, i.e., those that can be obtained at a much cheaper price while idle, but may be preempted whenever requested by priority users. Doing so, however, requires new forms of resiliency and efficiency to cope with the possibility of frequent preemptions â a failure model that is drastically different from the occasional failures in normal cluster settings that existing checkpointing techniques target. We present Bamboo, a distributed system that tackles these challenges by introducing redundant computations into the training pipeline, i.e., whereby one node performs computations over not only its own layers but also over some layers in its neighbor. Our key insight is that training large models often requires pipeline parallelism where "pipeline bubbles" naturally exist. Bamboo carefully fills redundant computations into these bubbles, providing resilience at a low cost. Across a variety of widely used DNN models, Bamboo outperforms traditional checkpointing by 3.7Ã in training throughput, and reduces costs by 2.4Ã compared to a setting where on-demand instances are used.}
}


@inproceedings{DBLP:conf/nsdi/KrishnaswamySMB23,
	author = {Umesh Krishnaswamy and
                  Rachee Singh and
                  Paul Mattes and
                  Paul{-}Andre C. Bissonnette and
                  Nikolaj S. Bj{\o}rner and
                  Zahira Nasrin and
                  Sonal Kothari and
                  Prabhakar Reddy and
                  John Abeln and
                  Srikanth Kandula and
                  Himanshu Raj and
                  Luis Ir{\'{u}}n{-}Briz and
                  Jamie Gaudette and
                  Erica Lan},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {OneWAN is better than two: Unifying a split {WAN} architecture},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {515--529},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/krishnaswamy},
	timestamp = {Thu, 11 May 2023 17:08:22 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/KrishnaswamySMB23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Many large cloud providers operate two wide-area networks (WANs) â a software-defined WAN to carry inter-datacenter traffic and a standards-based WAN for Internet traffic. Our experience with operating two heterogeneous planet-scale WANs has revealed the operational complexity and cost inefficiency of the split-WAN architecture. In this work, we present the unification of Microsoft's split-WAN architecture consisting of SWAN and CORE networks into ONEWAN. ONEWAN serves both Internet and inter-datacenter traffic using software-defined control. ONEWAN grappled with the order of magnitude increase in network and routing table sizes. We developed a new routing and forwarding paradigm called traffic steering to manage the increased network scale using existing network equipment. Increased network and traffic matrix size posed scaling challenges to SDN traffic engineering in ONEWAN. We developed techniques to find paths in the network and chain multiple TE optimization solvers to compute traffic allocations within a few seconds. ONEWAN is the first to apply software-defined techniques in an Internet backbone and scales to a network that is 10Ã larger than SWAN.}
}


@inproceedings{DBLP:conf/nsdi/DuanFL0BP23,
	author = {Huayi Duan and
                  Rub{\'{e}}n Fischer and
                  Jie Lou and
                  Si Liu and
                  David A. Basin and
                  Adrian Perrig},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {{RHINE:} Robust and High-performance Internet Naming with {E2E} Authenticity},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {531--553},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/duan},
	timestamp = {Thu, 11 May 2023 17:08:22 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/DuanFL0BP23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The variety and severity of recent DNS-based attacks under- score the importance of a secure naming system. Although DNSSEC provides data authenticity in theory, practical deployments unfortunately are fragile, costly, and typically lacks end-to-end (E2E) guarantees. This motivates us to rethink authentication in DNS fundamentally and introduce RHINE, a secure-by-design Internet naming system. RHINE offloads the authentication of zone delegation to an end-entity PKI and tames the operational complexity in an offline manner, allowing the efficient E2E authentication of zone data during online name resolution. With a novel logging mechanism, Delegation Transparency, RHINE achieves a highly robust trust model that can tolerate the compromise of all but one trusted entities and, for the first time, counters threats from superordinate zones. We formally verify RHINE's security properties using the Tamarin prover. We also demonstrate its practicality and performance advantages with a prototype implementation.}
}


@inproceedings{DBLP:conf/nsdi/TahirM23,
	author = {Ammar Tahir and
                  Radhika Mittal},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {Enabling Users to Control their Internet},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {555--573},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/tahir},
	timestamp = {Thu, 11 May 2023 17:08:22 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/TahirM23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Access link from the ISP tends to be the bottleneck for many users. However, users today have no control over how the access bandwidth (which is under the ISP's control) is divided across their incoming flows. In this paper, we present a system, CRAB, that runs at the receiver's devices â home routers and endpoints â and enforces user-specified weights across the incoming flows, without any explicit support from the ISP or the senders. It involves a novel control loop that continuously estimates available downlink capacity and flow demands by observing the incoming traffic, computes the max-min weighted fair share rates for the flows using these estimates, and throttles the flows to the computed rates. The key challenge that CRAB must tackle is that the demand and capacity estimated by observing the incoming traffic at the receiver (after the bottleneck) is inherently ambiguous â CRAB's control loop is designed to effectively avoid and correct these ambiguities. We implement CRAB on a Linux machine and Linksys WRT3200ACM home router. Our evaluation, involving real-world flows, shows how CRAB can enforce user preferences to achieve 2Ã lower web page load times and 3Ã higher video quality than the status quo.}
}


@inproceedings{DBLP:conf/nsdi/WirtgenRCRBVLB23,
	author = {Thomas Wirtgen and
                  Tom Rousseaux and
                  Quentin De Coninck and
                  Nicolas Rybowski and
                  Randy Bush and
                  Laurent Vanbever and
                  Axel Legay and
                  Olivier Bonaventure},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {xBGP: Faster Innovation in Routing Protocols},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {575--592},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/wirtgen},
	timestamp = {Thu, 11 May 2023 17:08:22 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/WirtgenRCRBVLB23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Internet Service Providers use routers from multiple vendors that support standardized routing protocols. Network operators deploy new services by tuning these protocols. Unfortunately, while standardization is necessary for interoperability, this is a slow process. As a consequence, new features appear very slowly in routing protocols. We propose a new implementation model for BGP, called xBGP, that enables ISPs to innovate by easily deploying BGP extensions in their multivendor network. We define a vendor-neutral xBGP API which can be supported by any BGP implementation and an eBPF Virtual Machine that allows executing extension code within these BGP implementations. We demonstrate the feasibility of our approach by extending both FRRouting and BIRD. We demonstrate seven different use cases showing the benefits that network operators can obtain using xBGP programs. We propose a verification toolchain that enables operators to compile and verify the safety properties of xBGP programs before deploying them. Our testbed measurements show that the performance impact of xBGP is reasonable compared to native code.}
}


@inproceedings{DBLP:conf/nsdi/ShahCCMMMNS23,
	author = {Aashaka Shah and
                  Vijay Chidambaram and
                  Meghan Cowan and
                  Saeed Maleki and
                  Madan Musuvathi and
                  Todd Mytkowicz and
                  Jacob Nelson and
                  Olli Saarikivi},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {{TACCL:} Guiding Collective Algorithm Synthesis using Communication
                  Sketches},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {593--612},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/shah},
	timestamp = {Fri, 11 Aug 2023 15:15:41 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/ShahCCMMMNS23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Machine learning models are increasingly being trained across multiple GPUs and servers. In this setting, data is transferred between GPUs using communication collectives such as ALLTOALL and ALLREDUCE, which can become a significant bottleneck in training large models. Thus, it is important to use efficient algorithms for collective communication. We develop TACCL, a tool that enables algorithm designers to guide a synthesizer into automatically generating algorithms for a given hardware configuration and communication collective. TACCL uses a novel communication sketch abstraction to get crucial information from the designer to significantly reduce the search space and guide the synthesizer towards better algorithms. TACCL also uses a novel encoding of the problem that allows it to scale beyond single-node topologies. We use TACCL to synthesize algorithms for three collectives and two hardware topologies: DGX-2 and NDv2. We demonstrate that the algorithms synthesized by TACCL outperform the Nvidia Collective Communication Library (NCCL) by up to 6.7x. We also show that TACCL can speed up end-to-end training of Transformer-XL and BERT models by 11%â2.3x for different batch sizes.}
}


@inproceedings{DBLP:conf/nsdi/QiuB023,
	author = {Yiming Qiu and
                  Ryan Beckett and
                  Ang Chen},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {Synthesizing Runtime Programmable Switch Updates},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {613--628},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/qiu},
	timestamp = {Thu, 11 May 2023 17:08:22 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/QiuB023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We have witnessed a rapid growth of programmable switch applications, ranging from monitoring to security and offloading. Meanwhile, to safeguard the diverse network behaviors, researchers have developed formal verification techniques for high assurance. As a recent advance, network devices have become runtime programmable, supporting live program changes via partial reconfiguration. However, computing a runtime update plan that provides safety guarantees is a challenging task. FlexPlan is a tool that identifies step-by-step runtime update plans using program synthesis, guaranteeing that each transition state is correct with regard to a user specification and feasible within switch memory constraints. It develops novel, domain-specific techniques for this task, which scale to large, real-world programs with sizable changes.}
}


@inproceedings{DBLP:conf/nsdi/Ramanathan0GMWY23,
	author = {Sivaramakrishnan Ramanathan and
                  Ying Zhang and
                  Mohab Gawish and
                  Yogesh Mundada and
                  Zhaodong Wang and
                  Sangki Yun and
                  Eric Lippert and
                  Walid Taha and
                  Minlan Yu and
                  Jelena Mirkovic},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {Practical Intent-driven Routing Configuration Synthesis},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {629--644},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/ramanathan},
	timestamp = {Thu, 11 May 2023 17:08:22 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/Ramanathan0GMWY23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Configuration of production datacenters is challenging due to their scale (many switches), complexity (specific policy requirements), and dynamism (need for many configuration changes). This paper introduces Aura, a production-level synthesis system for datacenter routing policies. It consists of a high-level language, called RPL, that expresses the desired behavior and a compiler that automatically generates switch configurations. Unlike existing approaches, which generate full network configuration for a static policy, Aura is built to support frequent policy and network changes. It generates and deploys multiple parallel policy collections, in a way that supports smooth transitions between them without disrupting live production traffic. Aura has been deployed for over two years in Meta datacenters and has greatly improved our management efficiency. We also share our operational requirements and experiences, which can potentially inspire future research.}
}


@inproceedings{DBLP:conf/nsdi/ArashlooB023,
	author = {Mina Tahmasbi Arashloo and
                  Ryan Beckett and
                  Rachit Agarwal},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {Formal Methods for Network Performance Analysis},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {645--661},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/tahmasbi},
	timestamp = {Thu, 11 May 2023 17:08:22 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/ArashlooB023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Accurate and thorough analysis of network performance is challenging. Network simulations and emulations can only cover a subset of the continuously evolving set of workloads networks can experience, leaving room for unexplored corner cases and bugs that can cause sub-optimal performance on live traffic. Techniques from queuing theory and network calculus can provide rigorous bounds on performance metrics, but typically require the behavior of network components and the arrival pattern of traffic to be approximated with concise and well-behaved mathematical functions. As such, they are not immediately applicable to emerging workloads and the new algorithms and protocols developed for handling them. We explore a different approach: using formal methods to analyze network performance. We show that it is possible to accurately model network components and their queues in logic, and use techniques from program synthesis to automatically generate concise interpretable workloads as answers to queries about performance metrics. Our approach offers a new point in the space of existing tools for analyzing network performance: it is more exhaustive than simulation and emulation, and can be readily applied to algorithms and protocols that are expressible in first-order logic. We demonstrate the effectiveness of our approach by analyzing packet scheduling algorithms and a small leaf-spine network and generating concise workloads that can cause throughput, fairness, starvation, and latency problems.}
}


@inproceedings{DBLP:conf/nsdi/ZhaoZCZWZ23,
	author = {Shizhen Zhao and
                  Qizhou Zhang and
                  Peirui Cao and
                  Xiao Zhang and
                  Xinbing Wang and
                  Chenghu Zhou},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {Flattened Clos: Designing High-performance Deadlock-free Expander
                  Data Center Networks Using Graph Contraction},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {663--683},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/zhao-shizhen},
	timestamp = {Thu, 11 May 2023 17:08:22 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/ZhaoZCZWZ23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Clos networks have witnessed the successful deployment of RoCE in production data centers. However, as DCN bandwidth keeps increasing, building Clos networks is becoming cost-prohibitive and thus the more cost-efficient expander graph has received much attention in recent literature. Unfortunately, the existing expander graphs' topology and routing designs may contain Cyclic Buffer Dependency (CBD) and incur deadlocks in PFC-enabled RoCE networks. We propose Flattened Clos (FC), a topology/routing codesigned approach, to eliminate the PFC-induced deadlocks in expander networks. FC's topology and routing are designed in three steps: 1) logically divide each ToR switch into k virtual layers and establish connections only between adjacent virtual layers; 2) generate virtual up-down paths for routing; 3) flatten the virtual multi-layered network and the virtual up-down paths using graph contraction. We rigorously prove that FC's design is deadlock-free and validate this property using a real testbed and packet-level simulation. Compared to expander graphs with the edge-disjoint-spanning-tree (EDST) based routing (a state-of-art CBD-free routing algorithm for expander graphs), FC reduces the average hop count by at least 50% and improves network throughput by 2â10Ã or more. Compared to Clos networks with up-down routing, FC increases network throughput by 1.1â2Ã under all-to-all and uniform random traffic patterns.}
}


@inproceedings{DBLP:conf/nsdi/ZhaoGAA23,
	author = {Kevin Zhao and
                  Prateesh Goyal and
                  Mohammad Alizadeh and
                  Thomas E. Anderson},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {Scalable Tail Latency Estimation for Data Center Networks},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {685--702},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/zhao-kevin},
	timestamp = {Thu, 11 May 2023 17:08:22 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/ZhaoGAA23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we consider how to provide fast estimates of flow-level tail latency performance for very large scale data center networks. Network tail latency is often a crucial metric for cloud application performance that can be affected by a wide variety of factors, including network load, inter-rack traffic skew, traffic burstiness, flow size distributions, oversubscription, and topology asymmetry. Network simulators such as ns-3 and OMNeT++ can provide accurate answers, but are very hard to parallelize, taking hours or days to answer what if questions for a single configuration at even moderate scale. Recent work with MimicNet has shown how to use machine learning to improve simulation performance, but at a cost of including a long training step per configuration, and with assumptions about workload and topology uniformity that typically do not hold in practice. We address this gap by developing a set of techniques to provide fast performance estimates for large scale networks with general traffic matrices and topologies. A key step is to decompose the problem into a large number of parallel independent single-link simulations; we carefully combine these link-level simulations to produce accurate estimates of end-to-end flow level performance distributions for the entire network. LikeMimicNet, we exploit symmetry where possible to gain additional speedups, but without relying on machine learning, so there is no training delay. On a large-scale network where ns-3 takes 11 to 27 hours to simulate five seconds of network behavior, our techniques runin one to two minutes with accuracy within 9% for tail flow completion times.}
}


@inproceedings{DBLP:conf/nsdi/ZhengPKVA23,
	author = {Pengfei Zheng and
                  Rui Pan and
                  Tarannum Khan and
                  Shivaram Venkataraman and
                  Aditya Akella},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {Shockwave: Fair and Efficient Cluster Scheduling for Dynamic Adaptation
                  in Machine Learning},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {703--723},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/zheng},
	timestamp = {Thu, 11 May 2023 17:08:22 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/ZhengPKVA23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Dynamic adaptation has become an essential technique in accelerating distributed machine learning (ML) training. Recent studies have shown that dynamically adjusting model structure (e.g., lottery ticket hypothesis) or hyperparameters (e.g., batch size) can significantly accelerate training without sacrificing accuracy. However, existing ML cluster schedulers are not designed to handle dynamic adaptation. We show that existing schemes fail to provide fairness and degrade system efficiency when the training throughput changes over time under dynamic adaptation. We design Shockwave, a scheduler with future planning that builds on two key ideas. First, Shockwave extends classic market theory from static settings to dynamic settings to co-optimize efficiency and fairness. Second, Shockwave utilizes stochastic dynamic programming to handle dynamic changes. We build a system for Shockwave and validate its performance with both trace-driven simulation and cluster experiments. Results show that for traces of ML jobs with dynamic adaptation, Shockwave improves makespan by 1.3Ã and fairness by 2Ã when compared with existing fair scheduling schemes.}
}


@inproceedings{DBLP:conf/nsdi/Cho0PAB23,
	author = {Inho Cho and
                  Ahmed Saeed and
                  Seo Jin Park and
                  Mohammad Alizadeh and
                  Adam Belay},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {Protego: Overload Control for Applications with Unpredictable Lock
                  Contention},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {725--738},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/cho-inho},
	timestamp = {Thu, 11 May 2023 17:08:22 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/Cho0PAB23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Modern datacenter applications are concurrent, so they require synchronization to control access to shared data. Requests can contend for different combinations of locks, depending on application and request state. In this paper, we show that locks, especially blocking synchronization, can squander throughput and harm tail latency, even when the CPU is underutilized. Moreover, the presence of a large number of contention points, and the unpredictability in knowing which locks a request will require, make it difficult to prevent contention through overload control using traditional signals such as queueing delay and CPU utilization. We present Protego, a system that resolves these problems with two key ideas. First, it contributes a new admission control strategy that prevents compute congestion in the presence of lock contention. The key idea is to use marginal improvements in observed throughput, rather than CPU load or latency measurements, within a credit-based admission control algorithm that regulates the rate of incoming requests to a server. Second, it introduces a new latency-aware synchronization abstraction called Active Synchronization Queue Management (ASQM) that allows applications to abort requests if delays exceed latency objectives. We apply Protego to two real-world applications, Lucene and Memcached, and show that it achieves up to 3.3x more goodput and 12.2x lower 99th percentile latency than the state-of-the-art overload control systems while avoiding congestion collapse.}
}


@inproceedings{DBLP:conf/nsdi/WangKZGJM0K23,
	author = {Weiyang Wang and
                  Moein Khazraee and
                  Zhizhen Zhong and
                  Manya Ghobadi and
                  Zhihao Jia and
                  Dheevatsa Mudigere and
                  Ying Zhang and
                  Anthony Kewitsch},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {TopoOpt: Co-optimizing Network Topology and Parallelization Strategy
                  for Distributed Training Jobs},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {739--767},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/wang-weiyang},
	timestamp = {Thu, 11 May 2023 17:08:22 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/WangKZGJM0K23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We propose TopoOpt, a novel direct-connect fabric for deep neural network (DNN) training workloads. TopoOpt co-optimizes the distributed training process across three dimensions: computation, communication, and network topology. We demonstrate the mutability of AllReduce traffic, and leverage this property to construct efficient network topologies for DNN training jobs. TopoOpt then uses an alternating optimization technique and a group theory-inspired algorithm called TotientPerms to find the best network topology and routing plan, together with a parallelization strategy. We build a fully functional 12-node direct-connect prototype with remote direct memory access (RDMA) forwarding at 100 Gbps. Large-scale simulations on real distributed training models show that, compared to similar-cost Fat-Tree interconnects, TopoOpt reduces DNN training time by up to 3.4x.}
}


@inproceedings{DBLP:conf/nsdi/LaiDMC23,
	author = {Fan Lai and
                  Yinwei Dai and
                  Harsha V. Madhyastha and
                  Mosharaf Chowdhury},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {ModelKeeper: Accelerating {DNN} Training via Automated Training Warmup},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {769--785},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/lai-fan},
	timestamp = {Thu, 11 May 2023 17:08:22 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/LaiDMC23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With growing deployment of machine learning (ML) models, ML developers are training or re-training increasingly more deep neural networks (DNNs). They do so to find the most suitable model that meets their accuracy requirement while satisfying the resource and timeliness constraints of the target environment. In large shared clusters, the growing number of neural architecture search (NAS) and training jobs often result in models sharing architectural similarities with others from the same or a different ML developer. However, existing solutions do not provide a systematic mechanism to identify and leverage such similarities. We present ModelKeeper, the first automated training warmup system that accelerates DNN training by repurposing previously-trained models in a shared cluster. Our key insight is that initializing a training job's model by transforming an already-trained model's weights can jump-start it and reduce the total amount of training needed. However, models submitted over time can differ in their architectures and accuracy. Given a new model to train, ModelKeeper scalably identifies its architectural similarity with previously trained models, selects a parent model with high similarity and good model accuracy, and performs structure-aware transformation of weights to preserve maximal information from the parent model during the warmup of new model weights. Our evaluations across thousands of CV and NLP models show that ModelKeeper achieves 1.3Ãâ4.3Ã faster training completion with little overhead and no reduction in model accuracy.}
}


@inproceedings{DBLP:conf/nsdi/0025TKS23,
	author = {Hong Zhang and
                  Yupeng Tang and
                  Anurag Khandelwal and
                  Ion Stoica},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {{SHEPHERD:} Serving DNNs in the Wild},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {787--808},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/zhang-hong},
	timestamp = {Thu, 11 May 2023 17:08:22 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/0025TKS23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Model serving systems observe massive volumes of inference requests for many emerging interactive web services. These systems need to be scalable, guarantee high system goodput and maximize resource utilization across compute units. However, achieving all three goals simultaneously is challenging since inference requests have very tight latency constraints (10 â 500 ms), and production workloads can be extremely unpredictable at such small time granularities. We present SHEPHERD, a model serving system that achieves all three goals in the face of workload unpredictability. SHEPHERD uses a two-level design that decouples model serving into planning and serving modules. For planning, SHEPHERD exploits the insight that while individual request streams can be highly unpredictable, aggregating request streams into moderately-sized groups greatly improves predictability, permitting high resource utilization as well as scalability. For serving, SHEPHERD employs a novel online algorithm that provides guaranteed goodput under workload unpredictability by carefully leveraging preemptions and model-specific batching properties. Evaluation results over production workloads show that SHEPHERD achieves up to 18.1X higher goodput and 1.8X better utilization compared to prior state-of-the-art, while scaling to hundreds of workers.}
}


@inproceedings{DBLP:conf/nsdi/MahajanC0A23,
	author = {Kshiteej Mahajan and
                  Ching{-}Hsiang Chu and
                  Srinivas Sridharan and
                  Aditya Akella},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {Better Together: Jointly Optimizing {ML} Collective Scheduling and
                  Execution Planning using {SYNDICATE}},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {809--824},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/mahajan},
	timestamp = {Thu, 11 May 2023 17:08:22 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/MahajanC0A23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Emerging ML training deployments are trending towards larger models, and hybrid-parallel training that is not just dominated by compute-intensive all-reduce for gradient aggregation but also bandwidth-intensive collectives (e.g., all-to-all). These emerging collectives exacerbate the communication bottlenecks despite heterogeneous network interconnects with ample multipath opportunities. In this work, we propose SYNDICATE, a systematic, general framework to minimize communication bottlenecks and speed up training for both state-of-the-art and future large-scale models and interconnects. SYNDICATE proposes a novel abstraction, the motif, to break large communication work as smaller pieces as part of execution planning. SYNDICATE also does joint optimization of scheduling and execution planning by rethinking the interfaces in the networking systems stacks used for ML training. Motifs afford greater flexibility during scheduling and the joint optimizer exploits this flexibility by packing and ordering communication work so as to maximize both network utilization and overlap with compute. This improves the speed of training state-of-the-art large models by 21-74%.}
}


@inproceedings{DBLP:conf/nsdi/Zhong0MA23,
	author = {Ke Zhong and
                  Yiping Ma and
                  Yifeng Mao and
                  Sebastian Angel},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {Addax: {A} fast, private, and accountable ad exchange infrastructure},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {825--848},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/zhong},
	timestamp = {Thu, 11 May 2023 17:08:22 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/Zhong0MA23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper proposes Addax, a fast, verifiable, and private online ad exchange. When a user visits an ad-supported site, Addax runs an auction similar to those of leading exchanges; Addax requests bids, selects the winner, collects payment, and displays the ad to the user. A key distinction is that bids in Addax's auctions are kept private and the outcome of the auction is publicly verifiable. Addax achieves these properties by adding public verifiability to the affine aggregatable encodings in Prio (NSDI'17) and by building an auction protocol out of them. Our implementation of Addax over WAN with hundreds of bidders can run roughly half the auctions per second as a non-private and non-verifiable exchange, while delivering ads to users in under 600 ms with little additional bandwidth requirements. This efficiency makes Addax the first architecture capable of bringing transparency to this otherwise opaque ecosystem.}
}


@inproceedings{DBLP:conf/nsdi/RamseyerGM23,
	author = {Geoffrey Ramseyer and
                  Ashish Goel and
                  David Mazi{\`{e}}res},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {{SPEEDEX:} {A} Scalable, Parallelizable, and Economically Efficient
                  Decentralized EXchange},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {849--875},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/ramseyer},
	timestamp = {Thu, 11 May 2023 17:08:22 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/RamseyerGM23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {SPEEDEX is a decentralized exchange (DEX) that lets participants securely trade assets without giving any single party undue control over the market. SPEEDEX offers several advantages over prior DEXes. It achieves high throughputâover 200,000 transactions per second on 48-core servers, even with tens of millions of open offers. SPEEDEX runs entirely within a Layer-1 blockchain, and thus achieves its scalability without fragmenting market liquidity between multiple blockchains or rollups. It eliminates internal arbitrage opportunities, so that a direct trade from asset A to asset B always receives as good a price as trading through some third asset such as USD. Finally, it prevents certain front-running attacks that would otherwise increase the effective bid-ask spread for small traders. SPEEDEX's key design insight is its use of an Arrow-Debreu exchange market structure that fixes the valuation of assets for all trades in a given block of transactions. We construct an algorithm, which is both asymptotically efficient and empirically practical, that computes these valuations while exactly preserving a DEX's financial correctness constraints. Not only does this market structure provide fairness across trades, but it also makes trade operations commutative and hence efficiently parallelizable. SPEEDEX is prototyped but not yet merged within the Stellar blockchain, one of the largest Layer-1 blockchains.}
}


@inproceedings{DBLP:conf/nsdi/00020C0XWWL023,
	author = {Peipei Jiang and
                  Qian Wang and
                  Jianhao Cheng and
                  Cong Wang and
                  Lei Xu and
                  Xinyu Wang and
                  Yihao Wu and
                  Xiaoyuan Li and
                  Kui Ren},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {Boomerang: Metadata-Private Messaging under Hardware Trust},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {877--899},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/jiang},
	timestamp = {Mon, 25 Sep 2023 08:07:45 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/00020C0XWWL023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In end-to-end encrypted (E2EE) messaging systems, protecting communication metadata, such as who is communicating with whom, at what time, etc., remains a challenging problem. Existing designs mostly fall into the balancing act among security, performance, and trust assumptions: 1) designs with cryptographic security often use hefty operations, incurring performance roadblocks and expensive operational costs for large-scale deployment; 2) more performant systems often follow a weaker security guarantee, like differential privacy, and generally demand more trust from the involved servers. So far, there has been no dominant solution. In this paper, we take a different technical route from prior art, and propose Boomerang, an alternative metadata-private messaging system leveraging the readily available trust assumption on secure enclaves (as those emerging in the cloud). Through a number of carefully tailored oblivious techniques on message shuffling, workload distribution, and proactive patching of the communication pattern, Boomerang brings together low latency, horizontal scalability, and cryptographic security, without prohibitive extra cost. With 32 machines, Boomerang achieves 99th percentile latency of 7.76 seconds for 220 clients. We hope Boomerang offers attractive alternative options to the current landscape of metadata-private messaging designs.}
}


@inproceedings{DBLP:conf/nsdi/LovejoyVFKBN23,
	author = {James Lovejoy and
                  Madars Virza and
                  Cory Fields and
                  Kevin Karwaski and
                  Anders Brownworth and
                  Neha Narula},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {Hamilton: {A} High-Performance Transaction Processor for Central Bank
                  Digital Currencies},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {901--915},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/lovejoy},
	timestamp = {Thu, 11 May 2023 17:08:22 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/LovejoyVFKBN23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Over 80% of central banks around the world are investigating central bank digital currency (CBDC), a digital form of central bank money that would be made available to the public for payments. We present Hamilton, a transaction processor for CBDC that provides high throughput, low latency, and fault tolerance, and that minimizes data stored in the transaction processor and provides flexibility for multiple types of programmability and a variety of roles for financial intermediaries. Hamilton does so by decoupling the steps of transaction validation so only the validating layer needs to see the details of a transaction, and by co-designing the transaction format with a simple version of a two-phase-commit protocol, which efficiently applies state updates in parallel. An evaluation shows Hamilton achieves 1.7M transactions per second in a geo-distributed setting.}
}


@inproceedings{DBLP:conf/nsdi/KhaniAHJNSAB23,
	author = {Mehrdad Khani Shirkoohi and
                  Ganesh Ananthanarayanan and
                  Kevin Hsieh and
                  Junchen Jiang and
                  Ravi Netravali and
                  Yuanchao Shu and
                  Mohammad Alizadeh and
                  Victor Bahl},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {{RECL:} Responsive Resource-Efficient Continuous Learning for Video
                  Analytics},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {917--932},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/khani},
	timestamp = {Fri, 19 Apr 2024 11:28:32 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/KhaniAHJNSAB23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Continuous learning has recently shown promising results for video analytics by adapting a lightweight "expert" DNN model for each specific video scene to cope with the data drift in real time. However, current adaptation approaches either rely on periodic retraining and suffer its delay and significant compute costs or rely on selecting historical models and incur accuracy loss by not fully leveraging the potential of persistent retraining. Without dynamically optimizing the resource sharing among model selection and retraining, both approaches have a diminishing return at scale. RECL is a new video-analytics framework that carefully integrates model reusing and online model retraining, allowing it to quickly adapt the expert model given any video frame samples. To do this, RECL (i) shares across edge devices a (potentially growing) "model zoo" that comprises expert models previously trained for all edge devices, enabling history model reuse across video sessions, (ii) uses a fast procedure to online select a highly accurate expert model from this shared model zoo, and (iii) dynamically optimizes GPU allocation among model retraining, model selection, and timely updates of the model zoo. Our evaluation of RECL over 70 hours of real-world videos across two vision tasks (object detection and classification) shows substantial performance gains compared to prior work, further amplifying over the system lifetime.}
}


@inproceedings{DBLP:conf/nsdi/AgarwalN23,
	author = {Neil Agarwal and
                  Ravi Netravali},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {Boggart: Towards General-Purpose Acceleration of Retrospective Video
                  Analytics},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {933--951},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/agarwal-neil},
	timestamp = {Thu, 11 May 2023 17:08:22 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/AgarwalN23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Commercial retrospective video analytics platforms have increasingly adopted general interfaces to support the custom queries and convolutional neural networks (CNNs) that different applications require. However, existing optimizations were designed for settings where CNNs were platform- (not user-) determined, and fail to meet at least one of the following key platform goals when that condition is violated: reliable accuracy, low latency, and minimal wasted work. We present Boggart, a system that simultaneously meets all three goals while supporting the generality that today's platforms seek. Prior to queries being issued, Boggart carefully employs traditional computer vision algorithms to generate indices that are imprecise, but are fundamentally comprehensive across different CNNs/queries. For each issued query, Boggart employs new techniques to quickly characterize the imprecision of its index, and sparingly run CNNs (and propagate results to other frames) in a way that bounds accuracy drops. Our results highlight that Boggart's improved generality comes at low cost, with speedups that match (and most often, exceed) prior, model-specific approaches.}
}


@inproceedings{DBLP:conf/nsdi/RudowYKAER23,
	author = {Michael Rudow and
                  Francis Y. Yan and
                  Abhishek Kumar and
                  Ganesh Ananthanarayanan and
                  Martin Ellis and
                  K. V. Rashmi},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {Tambur: Efficient loss recovery for videoconferencing via streaming
                  codes},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {953--971},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/rudow},
	timestamp = {Thu, 11 May 2023 17:08:22 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/RudowYKAER23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Packet loss degrades the quality of experience (QoE) of videoconferencing. The standard approach to recovering lost packets for long-distance communication where retransmission takes too long is forward error correction (FEC). Conventional approaches for FEC for real-time applications are inefficient at protecting against bursts of losses. Yet such bursts frequently arise in practice and can be better tamed with a new class of theoretical FEC schemes, called "streaming codes," that require significantly less redundancy to recover bursts. However, existing streaming codes do not address the needs of videoconferencing, and their potential to improve the QoE for videoconferencing is largely untested. \\emph{Tambur} is a new streaming-codes-based approach to videoconferencing that overcomes the aforementioned limitations. We first evaluate Tambur in simulation over a large corpus of traces from Microsoft Teams. Tambur reduces the frequency of decoding failures for video frames by 26% and the bandwidth used for redundancy by 35% compared to the baseline. We implement Tambur in C++, integrate it with a videoconferencing application, and evaluate end-to-end QoE metrics over an emulated network showcasing substantial benefits for several key metrics. For example, Tambur reduces the frequency and cumulative duration of freezes by 26% and 29%, respectively.}
}


@inproceedings{DBLP:conf/nsdi/PadmanabhanAIAS23,
	author = {Arthi Padmanabhan and
                  Neil Agarwal and
                  Anand P. Iyer and
                  Ganesh Ananthanarayanan and
                  Yuanchao Shu and
                  Nikolaos Karianakis and
                  Guoqing Harry Xu and
                  Ravi Netravali},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {Gemel: Model Merging for Memory-Efficient, Real-Time Video Analytics
                  at the Edge},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {973--994},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/padmanabhan},
	timestamp = {Thu, 11 May 2023 17:08:22 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/PadmanabhanAIAS23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Video analytics pipelines have steadily shifted to edge deployments to reduce bandwidth overheads and privacy violations, but in doing so, face an ever-growing resource tension. Most notably, edge-box GPUs lack the memory needed to concurrently house the growing number of (increasingly complex) models for real-time inference. Unfortunately, existing solutions that rely on time/space sharing of GPU resources are insufficient as the required swapping delays result in unacceptable frame drops and accuracy loss. We present model merging, a new memory management technique that exploits architectural similarities between edge vision models by judiciously sharing their layers (including weights) to reduce workload memory costs and swapping delays. Our system, Gemel, efficiently integrates merging into existing pipelines by (1) leveraging several guiding observations about per-model memory usage and inter-layer dependencies to quickly identify fruitful and accuracy-preserving merging configurations, and (2) altering edge inference schedules to maximize merging benefits. Experiments across diverse workloads reveal that Gemel reduces memory usage by up to 60.7%, and improves overall accuracy by 8-39% relative to time or space sharing alone.}
}


@inproceedings{DBLP:conf/nsdi/ZhangJTL023,
	author = {Zili Zhang and
                  Chao Jin and
                  Linpeng Tang and
                  Xuanzhe Liu and
                  Xin Jin},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {Fast, Approximate Vector Queries on Very Large Unstructured Datasets},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {995--1011},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/zhang-zili},
	timestamp = {Thu, 11 May 2023 17:08:22 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/ZhangJTL023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The breakthroughs in deep learning enable unstructured data to be represented as high-dimensional feature vectors for serving a wide range of applications. Processing vector queries (i.e., finding the nearest neighbor vectors for an input vector) for large unstructured datasets (with billions of items) is challenging, especially for applications with strict service level objectives (SLOs). Existing solutions trade query accuracy for latency, but without any guarantees, causing SLO violations. This paper presents Auncel, a vector query engine for large unstructured datasets that provides bounded query errors and bounded query latencies. The core idea of Auncel is to exploit local geometric properties of individual query vectors to build a precise error-latency profile (ELP) for each query. This profile enables Auncel to sample the right amount of data to process a given query while satisfying its error or latency requirements. Auncel is a distributed solution that can scale out with multiple workers. We evaluate Auncel with a variety of benchmarking datasets. The experimental results show that Auncel outperforms state-of-the-art approximate solutions by up to 10Ã on query latency with the same error bound (â¤ 10%). In particular, Auncel only takes 25 ms to process a vector query on the DEEP1B dataset that contains one billion items with four c5.metal EC2 instances.}
}


@inproceedings{DBLP:conf/nsdi/ZhuWL23,
	author = {Zeying Zhu and
                  Kan Wu and
                  Zaoxing Liu},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {Arya: Arbitrary Graph Pattern Mining with Decomposition-based Sampling},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {1013--1030},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/zhu},
	timestamp = {Thu, 11 May 2023 17:08:22 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/ZhuWL23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graph pattern mining is compute-intensive in processing massive amounts of graph-structured data. This paper presents Arya, an ultra-fast approximate graph pattern miner that can detect and count arbitrary patterns of a graph. Unlike all prior approximation systems, Arya combines novel graph decomposition theory with edge sampling-based approximation to reduce the complexity of mining complex patterns on graphs with up to tens of billions of edges, a scale that was only possible on supercomputers. Arya can run on a single machine or distributed machines with an Error-Latency Profile (ELP) for users to configure the running time of pattern mining tasks based on different error targets. Our evaluation demonstrates that Arya outperforms existing exact and approximate pattern mining solutions by up to five orders of magnitude. Arya supports graphs with 5 billion edges on a single machine and scales to 10-billion-edge graphs on a 32-server testbed.}
}


@inproceedings{DBLP:conf/nsdi/LiagourisKFV23,
	author = {John Liagouris and
                  Vasiliki Kalavri and
                  Muhammad Faisal and
                  Mayank Varia},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {{SECRECY:} Secure collaborative analytics in untrusted clouds},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {1031--1056},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/liagouris},
	timestamp = {Tue, 07 May 2024 20:13:40 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/LiagourisKFV23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We present SECRECY, a system for privacy-preserving collaborative analytics as a service. SECRECY allows multiple data holders to contribute their data towards a joint analysis in the cloud, while keeping the data siloed even from the cloud providers. At the same time, it enables cloud providers to offer their services to clients who would have otherwise refused to perform a computation altogether or insisted that it be done on private infrastructure. SECRECY ensures no information leakage and provides provable security guarantees by employing cryptographically secure Multi-Party Computation (MPC). In SECRECY we take a novel approach to optimizing MPC execution by co-designing multiple layers of the system stack and exposing the MPC costs to the query engine. To achieve practical performance, SECRECY applies physical optimizations that amortize the inherent MPC overheads along with logical optimizations that dramatically reduce the computation, communication, and space requirements during query execution. Our multi-cloud experiments demonstrate that SECRECY improves query performance by over 1000x compared to existing approaches and computes complex analytics on millions of data records with modest use of resources.}
}


@inproceedings{DBLP:conf/nsdi/0001CWYH023,
	author = {Junxue Zhang and
                  Xiaodian Cheng and
                  Wei Wang and
                  Liu Yang and
                  Jinbin Hu and
                  Kai Chen},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {{FLASH:} Towards a High-performance Hardware Acceleration Architecture
                  for Cross-silo Federated Learning},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {1057--1079},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/zhang-junxue},
	timestamp = {Tue, 29 Aug 2023 08:51:09 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/0001CWYH023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cross-silo federated learning (FL) adopts various cryptographic operations to preserve data privacy, which introduces significant performance overhead. In this paper, we identify nine widely-used cryptographic operations and design an efficient hardware architecture to accelerate them. However, directly offloading them on hardware statically leads to (1) inadequate hardware acceleration due to the limited resources allocated to each operation; (2) insufficient resource utilization, since different operations are used at different times. To address these challenges, we propose FLASH, a high-performance hardware acceleration architecture for cross-silo FL systems. At its heart, FLASH extracts two basic operatorsâmodular exponentiation and multiplicationâ behind the nine cryptographic operations and implements them as highly-performant engines to achieve adequate acceleration. Furthermore, it leverages a dataflow scheduling scheme to dynamically compose different cryptographic operations based on these basic engines to obtain sufficient resource utilization. We have implemented a fully-functional FLASH prototype with Xilinx VU13P FPGA and integrated it with FATE, the most widely-adopted cross-silo FL framework. Experimental results show that, for the nine cryptographic operations, FLASH achieves up to 14.0Ã and 3.4Ã acceleration over CPU and GPU, translating to up to 6.8Ã and 2.0Ã speedup for realistic FL applications, respectively. We finally evaluate the FLASH design as an ASIC, and it achieves 23.6Ã performance improvement upon the FPGA prototype.}
}


@inproceedings{DBLP:conf/nsdi/LiangFXYLZYZ23,
	author = {Chieh{-}Jan Mike Liang and
                  Zilin Fang and
                  Yuqing Xie and
                  Fan Yang and
                  Zhao Lucis Li and
                  Li Lyna Zhang and
                  Mao Yang and
                  Lidong Zhou},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {On Modular Learning of Distributed Systems for Predicting End-to-End
                  Latency},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {1081--1095},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/liang-chieh-jan},
	timestamp = {Mon, 17 Jul 2023 12:54:26 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/LiangFXYLZYZ23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {An emerging trend in cloud deployments is to adopt machine learning (ML) models to characterize end-to-end system performance. Despite early success, such methods can incur significant costs when adapting to the deployment dynamics of distributed systems like service scaling-out and replacement. They require hours or even days for data collection and model training, otherwise models may drift to result in unacceptable inaccuracy. This problem arises from the practice of modeling the entire system with monolithic models. We propose Fluxion, a framework to model end-to-end system latency with modularized learning. Fluxion introduces learning assignment, a new abstraction that allows modeling individual sub-components. With a consistent interface, multiple learning assignments can then be dynamically composed into an inference graph, to model a complex distributed system on the fly. Changes in a system sub-component only involve updating the corresponding learning assignment, thus significantly reducing costs. Using three systems with up to 142 microservices on a 100-VM cluster, Fluxion shows a performance modeling MAE (mean absolute error) up to 68.41% lower than monolithic models. In turn, this lower MAE allows better system performance tuning, e.g., a speed up for 90-percentile end-to-end latency by up to 1.57Ã. All these are achieved under various system deployment dynamics.}
}


@inproceedings{DBLP:conf/nsdi/KarthikeyanNSZB23,
	author = {Ajaykrishna Karthikeyan and
                  Nagarajan Natarajan and
                  Gagan Somashekar and
                  Lei Zhao and
                  Ranjita Bhagwan and
                  Rodrigo Fonseca and
                  Tatiana Racheva and
                  Yogesh Bansal},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {SelfTune: Tuning Cluster Managers},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {1097--1114},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/karthikeyan},
	timestamp = {Thu, 11 May 2023 17:08:22 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/KarthikeyanNSZB23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Large-scale cloud providers rely on cluster managers for container allocation and load balancing (e.g., Kubernetes), VM provisioning (e.g., Protean), and other management tasks. These cluster managers use algorithms or heuristics whose behavior depends upon multiple configuration parameters. Currently, operators manually set these parameters using a combination of domain knowledge and limited testing. In very large-scale and dynamic environments, these manually-set parameters may lead to sub-optimal cluster states, adversely affecting important metrics such as latency and throughput. In this paper we describe SelfTune, a framework that automatically tunes such parameters in deployment. SelfTune piggybacks on the iterative nature of cluster managers which, through multiple iterations, drives a cluster to a desired state. Using a simple interface, developers integrate SelfTune into the cluster manager code, which then uses a principled reinforcement learning algorithm to tune important parameters over time. We have deployed SelfTune on tens of thousands of machines that run a large-scale background task scheduler at Microsoft. SelfTune has improved throughput by as much as 20% in this deployment by continuously tuning a key configuration parameter that determines the number of jobs concurrently accessing CPU and disk on every machine. We also evaluate SelfTune with two Azure FaaS workloads, the Kubernetes Vertical Pod Autoscaler, and the DeathStar microservice benchmark. In all cases, SelfTune significantly improves cluster performance.}
}


@inproceedings{DBLP:conf/nsdi/AlomarHNAAS23,
	author = {Abdullah Alomar and
                  Pouya Hamadanian and
                  Arash Nasr{-}Esfahany and
                  Anish Agarwal and
                  Mohammad Alizadeh and
                  Devavrat Shah},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {CausalSim: {A} Causal Framework for Unbiased Trace-Driven Simulation},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {1115--1147},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/alomar},
	timestamp = {Thu, 11 May 2023 17:08:22 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/AlomarHNAAS23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We present CausalSim, a causal framework for unbiased trace-driven simulation. Current trace-driven simulators assume that the interventions being simulated (e.g., a new algorithm) would not affect the validity of the traces. However, real-world traces are often biased by the choices algorithms make during trace collection, and hence replaying traces under an intervention may lead to incorrect results. CausalSim addresses this challenge by learning a causal model of the system dynamics and latent factors capturing the underlying system conditions during trace collection. It learns these models using an initial randomized control trial (RCT) under a fixed set of algorithms, and then applies them to remove biases from trace data when simulating new algorithms. Key to CausalSim is mapping unbiased trace-driven simulation to a tensor completion problem with extremely sparse observations. By exploiting a basic distributional invariance property present in RCT data, CausalSim enables a novel tensor completion method despite the sparsity of observations. Our extensive evaluation of CausalSim on both real and synthetic datasets, including more than ten months of real data from the Puffer video streaming system shows it improves simulation accuracy, reducing errors by 53% and 61% on average compared to expert-designed and supervised learning baselines. Moreover, CausalSim provides markedly different insights about ABR algorithms compared to the biased baseline simulator, which we validate with a real deployment.}
}


@inproceedings{DBLP:conf/nsdi/SongCSABCJJSG23,
	author = {Zhenyu Song and
                  Kevin Chen and
                  Nuikhil Sarda and
                  Deniz Altinb{\"{u}}ken and
                  Eugene Brevdo and
                  Jimmy Coleman and
                  Xiao Ju and
                  Pawel Jurczyk and
                  Richard Schooler and
                  Ramki Gummadi},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {{HALP:} Heuristic Aided Learned Preference Eviction Policy for YouTube
                  Content Delivery Network},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {1149--1163},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/song-zhenyu},
	timestamp = {Thu, 11 May 2023 17:08:22 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/SongCSABCJJSG23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Video streaming services are among the largest web applications in production, and a large source of downstream internet traffic. A large-scale video streaming service at Google, YouTube, leverages a Content Delivery Network (CDN) to serve its users. A key consideration in providing a seamless service is cache efficiency. In this work, we demonstrate machine learning techniques to improve the efficiency of YouTube's CDN DRAM cache. While many recently proposed learning-based caching algorithms show promising results, we identify and address three challenges blocking deployment of such techniques in a large-scale production environment: computation overhead for learning, robust byte miss ratio improvement, and measuring impact under production noise. We propose a novel caching algorithm, HALP, which achieves low CPU overhead and robust byte miss ratio improvement by augmenting a heuristic policy with machine learning. We also propose a production measurement method, impact distribution analysis, that can accurately measure the impact distribution of a new caching algorithm deployment in a noisy production environment. HALP has been running in YouTube CDN production as a DRAM level eviction algorithm since early 2022 and has reliably reduced the byte miss during peak by an average of 9.1% while expending a modest CPU overhead of 1.8%.}
}


@inproceedings{DBLP:conf/nsdi/MishraKSKC023,
	author = {Manan Mishra and
                  Daniel Jay Koch and
                  Muhammad Osama Shahid and
                  Bhuvana Krishnaswamy and
                  Krishna Chintalapudi and
                  Suman Banerjee},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {OpenLoRa: Validating LoRa Implementations through an Extensible and
                  Open-sourced Framework},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {1165--1183},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/mishra},
	timestamp = {Thu, 11 May 2023 17:08:22 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/MishraKSKC023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {LoRa is one of the most widely used LPWAN communication techniques operating in the unlicensed sub-GHz ISM bands. Its long range however also results in increased interference from other LoRa and non-LoRa networks, undermining network throughput due to packet collisions. This has motivated extensive research in the area of collision resolution techniques for concurrent LoRa transmissions and continues to be a topic of interest. In this paper, we verify the implementation and efficacy of four of the most recent works on LoRa packet collisions, in addition to standard LoRa. We implement OpenLoRa, an open-source, unified platform to evaluate these works and is extensible for future researchers to compare against existing works. We implement each of the four techniques in Python as well as separate the demodulator and decoder to provide benchmarks for future demodulators that can be plugged into the framework for fair and easy comparison against existing works. Our evaluation indicates that existing contention resolution techniques fall short in their throughput performance,  especially due to poor packet detection in low and ultra-low SNR regimes.}
}


@inproceedings{DBLP:conf/nsdi/ZhangH0W23,
	author = {Yi Zhang and
                  Weiying Hou and
                  Zheng Yang and
                  Chenshu Wu},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {VeCare: Statistical Acoustic Sensing for Automotive In-Cabin Monitoring},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {1185--1200},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/zhang-yi},
	timestamp = {Thu, 18 Jul 2024 08:52:00 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/ZhangH0W23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {On average, every 10 days a child dies from in-vehicle heatstroke. The life-threatening situation calls for an automatic Child Presence Detection (CPD) solution to prevent these tragedies. In this paper, we present VECARE, the first CPD system that leverages existing in-car audio without any hardware changes. To achieve so, we explore the fundamental properties of acoustic reflection signals and develop a novel paradigm of statistical acoustic sensing, which allows to detect motion, track breathing, and estimate speed in a unified model. Based on this, we build an accurate and robust CPD system by introducing a set of techniques that overcome multiple challenges concerning sound interference and sensing coverage. We implement VECARE using commodity speakers and a single microphone and conduct experiments with infant simulators and adults, as well as 15 young children for the real-world in-car study. The results demonstrate that VECARE achieves an average detection rate of 98.8% with a false alarm rate of 2.1% for 15 children in various cars, boosting the coverage by over 2.3Ã compared to state-of-the-art and achieving whole-car detection with no blind spot.}
}


@inproceedings{DBLP:conf/nsdi/ZhaoW0ZL23,
	author = {Renjie Zhao and
                  Kejia Wang and
                  Kai Zheng and
                  Xinyu Zhang and
                  Vincent Leung},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {SlimWiFi: Ultra-Low-Power IoT Radio Architecture Enabled by Asymmetric
                  Communication},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {1201--1219},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/zhao-renjie},
	timestamp = {Tue, 26 Sep 2023 07:34:23 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/ZhaoW0ZL23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {To communicate with existing wireless infrastructures such as Wi-Fi, an Internet of Things (IoT) radio device needs to adopt a compatible PHY layer which entails sophisticated hardware and high power consumption. This paper breaks the tension for the first time through a system called SlimWiFi. A SlimWiFi radio transmits on-off keying (OOK) modulated signals. But through a novel asymmetric communication scheme, it can be directly decoded by off-the-shelf Wi-Fi devices. With this measure, SlimWiFi radically simplifies the radio architecture, evading power hungry components such as data converters and high-stability carrier generators. In addition, it can cut the transmit power requirement by around 18 dB, while keeping a similar link budget as standard Wi-Fi. We have implemented SlimWiFi through PCB prototype and IC tape-out. Our experiments demonstrate that SlimWiFi can reach around 100 kbps goodput at up to 60 m, while reducing power consumption by around 3 orders of magnitude compared to a standard Wi-Fi transmitter.}
}


@inproceedings{DBLP:conf/nsdi/0002Z0W23,
	author = {Zheng Yang and
                  Yi Zhang and
                  Kun Qian and
                  Chenshu Wu},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {SLNet: {A} Spectrogram Learning Neural Network for Deep Wireless Sensing},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {1221--1236},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/yang-zheng},
	timestamp = {Thu, 11 May 2023 17:08:22 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/0002Z0W23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Advances in wireless technologies have transformed wireless networks from a pure communication medium to a pervasive sensing platform, enabling many sensorless and contactless applications. After years of effort, wireless sensing approaches centering around conventional signal processing are approaching their limits, and meanwhile, deep learning-based methods become increasingly popular and have seen remarkable progress. In this paper, we explore an unseen opportunity to push the limit of wireless sensing by jointly employing learning-based spectrogram generation and spectrogram learning. To this end, we present SLNet, a new deep wireless sensing architecture with spectrogram analysis and deep learning co-design. SLNet employs neural networks to generate super-resolution spectrogram, which overcomes the limitation of the time-frequency uncertainty. It then utilizes a novel polarized convolutional network that modulates the phase of the spectrograms for learning both local and global features. Experiments with four applications, i.e., gesture recognition, human identification, fall detection, and breathing estimation, show that SLNet achieves the highest accuracy with the smallest model and lowest computation among the state-of-the-art models. We believe the techniques in SLNet can be widely applied to fields beyond WiFi sensing.}
}


@inproceedings{DBLP:conf/nsdi/ScazzarielloCGB23,
	author = {Mariano Scazzariello and
                  Tommaso Caiazzi and
                  Hamid Ghasemirahni and
                  Tom Barbette and
                  Dejan Kostic and
                  Marco Chiesa},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {A High-Speed Stateful Packet Processing Approach for Tbps Programmable
                  Switches},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {1237--1255},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/scazzariello},
	timestamp = {Thu, 11 May 2023 17:08:22 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/ScazzarielloCGB23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {High-speed ASIC switches hold great promise for offloading complex packet processing pipelines directly in the highspeed data-plane. Yet, a large variety of today's packet processing pipelines, including stateful network functions and packet schedulers, require storing some (or all the) packets for short amount of times in a programmatic manner. Such a programmable buffer feature is missing on today's high-speed ASIC switches. In this work, we present RIBOSOME, a system that extends programmable switches with external memory (to store packets) and external general-purpose packet processing devices such as CPUs or FPGAs (to perform stateful operations). As today's packet processing devices are bottlenecked by their network interface speeds, RIBOSOME carefully transmits only the relevant bits to these devices. RIBOSOME leverages spare bandwidth from any directly connected servers to store the incoming payloads through RDMA. Our evaluation shows that RIBOSOME can process 300G of traffic through a stateful packet processing pipeline (e.g., firewall, load balancer, packet scheduler) by running the pipeline logic on a single server equipped with one 100G interface.}
}


@inproceedings{DBLP:conf/nsdi/KimSS23,
	author = {Daehyeok Kim and
                  Vyas Sekar and
                  Srinivasan Seshan},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {ExoPlane: An Operating System for On-Rack Switch Resource Augmentation},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {1257--1272},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/kim-daehyeok},
	timestamp = {Thu, 11 May 2023 17:08:22 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/KimSS23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The promise of in-network computing continues to be unrealized in realistic deployments (e.g., clouds and ISPs) as serving concurrent stateful applications on a programmable switch is challenging today due to limited switch's on-chip resources. In this paper, we argue that an on-rack switch resource augmentation architecture that augments a programmable switch with other programmable network hardware, such as smart NICs, on the same rack can be a pragmatic and incrementally scalable solution. To realize this vision, we design and implement ExoPlane, an operating system for on-rack switch resource augmentation to support multiple concurrent applications. In designing ExoPlane, we propose a practical runtime operating model and state abstraction to address challenges in managing application states correctly across multiple devices with minimal performance and resource overheads. Our evaluation with various P4 applications shows that ExoPlane can provide applications with low latency, scalable throughput, and fast failover while achieving these with small resource overheads and no or little modifications on applications.}
}


@inproceedings{DBLP:conf/nsdi/NamkungLKSS23,
	author = {Hun Namkung and
                  Zaoxing Liu and
                  Daehyeok Kim and
                  Vyas Sekar and
                  Peter Steenkiste},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {Sketchovsky: Enabling Ensembles of Sketches on Programmable Switches},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {1273--1292},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/namkung},
	timestamp = {Thu, 11 May 2023 17:08:22 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/NamkungLKSS23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Network operators need to run diverse measurement tasks on programmable switches to support management decisions (e.g., traffic engineering or anomaly detection). While prior work has shown the viability of running a single sketch instance, they largely ignore the problem of running an ensemble of sketch instances for a collection of measurement tasks. As such, existing efforts fall short of efficiently supporting a general ensemble of sketch instances. In this work, we present the design and implementation of Sketchovsky, a novel cross-sketch optimization and composition framework. We identify five new cross-sketch optimization building blocks to reduce critical switch hardware resources. We design efficient heuristics to select and apply these building blocks for arbitrary ensembles. To simplify developer effort, Sketchovsky automatically generates the composed code to be input to the hardware compiler. Our evaluation shows that Sketchovsky makes ensembles with up to 18 sketch instances become feasible and can reduce up to 45% of the critical hardware resources.}
}


@inproceedings{DBLP:conf/nsdi/LinCKRSWA23,
	author = {Jiaxin Lin and
                  Adney Cardoza and
                  Tarannum Khan and
                  Yeonju Ro and
                  Brent E. Stephens and
                  Hassan M. G. Wassel and
                  Aditya Akella},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {RingLeader: Efficiently Offloading Intra-Server Orchestration to NICs},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {1293--1308},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/lin},
	timestamp = {Thu, 11 May 2023 17:08:22 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/LinCKRSWA23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Careful orchestration of requests at a datacenter server is crucial to meet tight tail latency requirements and ensure high throughput and optimal CPU utilization. Orchestration is multi-pronged and involves load balancing and scheduling requests belonging to different services across CPU resources, and adapting CPU allocation to request bursts. Centralized intra-server orchestration offers ideal load balancing performance, scheduling precision, and burst-tolerant CPU re-allocation. However, existing software-only approaches fail to achieve ideal orchestration because they have limited scalability and waste CPU resources. We argue for a new approach that offloads intra-server orchestration entirely to the NIC. We present RingLeader, a new programmable NIC with novel hardware units for software-informed request load balancing and programmable scheduling and a new light-weight OS-NIC interface that enables close NIC-CPU coordination and supports NIC-assisted CPU scheduling. Detailed experiments with a 100 Gbps FPGA-based prototype show that we obtain better scalability, efficiency, latency, and throughput than state-of-the-art software-only orchestrators including Shinjuku and Caladan.}
}


@inproceedings{DBLP:conf/nsdi/LaiLDW0LLLLW23,
	author = {Zeqi Lai and
                  Hewu Li and
                  Yangtao Deng and
                  Qian Wu and
                  Jun Liu and
                  Yuanjie Li and
                  Jihao Li and
                  Lixin Liu and
                  Weisen Liu and
                  Jianping Wu},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {StarryNet: Empowering Researchers to Evaluate Futuristic Integrated
                  Space and Terrestrial Networks},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {1309--1324},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/lai-zeqi},
	timestamp = {Thu, 11 May 2023 17:08:22 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/LaiLDW0LLLLW23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Futuristic integrated space and terrestrial networks (ISTN) not only hold new opportunities for pervasive, low-latency Internet services, but also face new challenges caused by satellite dynamics on a global scale. It should be useful for researchers to run various experiments to systematically explore new problems in ISTNs. However, existing experimentation methods either attain realism but lack flexibility (e.g. live satellites), or achieve flexibility but lack realism (e.g. ISTN simulators). This paper presents StarryNet, a novel experimentation framework that enables researchers to conveniently build credible and flexible experimental network environments (ENE) mimicking satellite dynamics and network behaviors of large-scale ISTNs. StarryNet simultaneously achieves constellation-consistency, networked system realism and flexibility, by adopting a real-data-driven, lightweight-emulation-aided approach to build a digital twin of physical ISTNs in the terrestrial virtual environment. Driven by public and real constellation-relevant information, we show StarryNet's acceptable fidelity and demonstrate its flexibility to support various ISTN experiments, such as evaluating different inter-networking mechanisms for space-ground integration, and assessing the network resilience of futuristic ISTNs.}
}


@inproceedings{DBLP:conf/nsdi/Ni0LCM0W0LX23,
	author = {Yunzhe Ni and
                  Feng Qian and
                  Taide Liu and
                  Yihua Cheng and
                  Zhiyao Ma and
                  Jing Wang and
                  Zhongfeng Wang and
                  Gang Huang and
                  Xuanzhe Liu and
                  Chenren Xu},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {{POLYCORN:} Data-driven Cross-layer Multipath Networking for High-speed
                  Railway through Composable Schedulerlets},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {1325--1340},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/ni},
	timestamp = {Thu, 11 May 2023 17:08:22 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/Ni0LCM0W0LX23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Modern high-speed railway (HSR) systems offer a speed of more than 250 km/h, making on-board Internet access through track-side cellular base stations extremely challenging. We conduct extensive measurements on commercial HSR trains, and collect a massive 1.79 TB GPS-labeled TCP-LTE dataset covering a total travel distance of 28,800 km. Leveraging the new insights from the measurement, we de-sign, implement, and evaluate POLYCORN, a first-of-its-kind networking system that can significantly boost Internet performance for HSR passengers. The core design of POLYCORN consists of a suite of composable multipath schedulerlets that intelligently determine what, when, and how to schedule user traffic over multiple highly fluctuating cellular links between HSR and track-side base stations. POLYCORN is specially designed for HSR environments through a cross-layer and data-driven proactive approach. We deploy POLYCORN on the operational LTE gateway of the popular Beijing-Shanghai HSR route at 300 km/h. Real-world experiments demonstrate that POLYCORN outperforms the state-of-the-art multipath schedulers by up to 242% in goodput, and reduces the delivery time by 45% for instant messaging applications.}
}


@inproceedings{DBLP:conf/nsdi/BoroushakiLDEA23,
	author = {Tara Boroushaki and
                  Maisy Lam and
                  Laura Dodds and
                  Aline Eid and
                  Fadel Adib},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {Augmenting Augmented Reality with Non-Line-of-Sight Perception},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {1341--1358},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/boroushaki},
	timestamp = {Thu, 11 May 2023 17:08:22 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/BoroushakiLDEA23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We present the design, implementation, and evaluation of X-AR, an augmented reality (AR) system with non-line-of-sight perception. X-AR augments AR headsets with RF sensing to enable users to see things that are otherwise invisible to the human eye or to state-of-the-art AR systems. Our design introduces three main innovations: the first is an AR-conformal antenna that tightly matches the shape of the AR headset visor while providing excellent radiation and bandwidth capabilities for RF sensing. The second is an RF-visual synthetic aperture localization algorithm that leverages natural human mobility to localize RF-tagged objects in line-of-sight and non-line-of-sight settings. Finally, the third is an RF-visual verification primitive that fuses RF and vision to deliver actionable tasks to end users such as picking verification. We built an end-to-end prototype of our design by integrating it into a Microsoft Hololens 2 AR headset and evaluated it in line-of-sight and non-line-of-sight environments. Our results demonstrate that X-AR achieves decimeter-level RF localization (median of 9.8 cm) of fully-occluded items and can perform RFvisual picking verification with over 95% accuracy (FScore) when extracting RFID-tagged items. These results show that X-AR is successful in extending AR systems to non-line-of-sight perception, with important implications to manufacturing, warehousing, and smart home applications. Demo video: y2u.be/bdUN21ft7G0}
}


@inproceedings{DBLP:conf/nsdi/ZhangWYW0QLXY23,
	author = {Yongzhao Zhang and
                  Yezhou Wang and
                  Lanqing Yang and
                  Mei Wang and
                  Yi{-}Chao Chen and
                  Lili Qiu and
                  Yihong Liu and
                  Guangtao Xue and
                  Jiadi Yu},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {Acoustic Sensing and Communication Using Metasurface},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {1359--1374},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/zhang-yongzhao},
	timestamp = {Thu, 11 May 2023 17:08:22 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/ZhangWYW0QLXY23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Acoustic sensing is increasingly popular owing to widely available devices that support them. Yet the sensing resolution and range are still limited due to limited bandwidth and sharp decay in the signal at inaudible frequencies. Inspired by recent development in acoustic metasurfaces, in this paper, we first perform an in-depth study of acoustic metasurface (AMS) and compare it with the phased array speaker. Our results show that AMS is attractive as it achieves a significant SNR increase while maintaining a compact size. A major limitation of existing AMS is its static configuration. Since our target may be at any possible location, it is important to support scanning in different directions. We develop a novel acoustic system that leverages a metasurface and a small number of speakers. We jointly optimize the configuration of metasurface and transmission signals from the speakers to achieve low-cost dynamic steering. Using a prototype implementation and extensive evaluation, we demonstrate its effectiveness in improving SNR, acoustic sensing accuracy, and acoustic communication reliability over a wide range of scenarios.}
}


@inproceedings{DBLP:conf/nsdi/0001KWPGS23,
	author = {Paras Jain and
                  Sam Kumar and
                  Sarah Wooders and
                  Shishir G. Patil and
                  Joseph E. Gonzalez and
                  Ion Stoica},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {Skyplane: Optimizing Transfer Cost and Throughput Using Cloud-Aware
                  Overlays},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {1375--1389},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/jain},
	timestamp = {Thu, 11 May 2023 17:08:22 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/0001KWPGS23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cloud applications are increasingly distributing data across multiple regions and cloud providers. Unfortunately, widearea bulk data transfers are often slow, bottlenecking applications. We demonstrate that it is possible to significantly improve inter-region cloud bulk transfer throughput by adapting network overlays to the cloud settingâthat is, by routing data through indirect paths at the application layer. However, directly applying network overlays in this setting can result in unacceptable increases in cloud egress prices. We present Skyplane, a system for bulk data transfer between cloud object stores that uses cloud-aware network overlays to optimally navigate the trade-off between price and performance. Skyplane's planner uses mixed-integer linear programming to determine the optimal overlay path and resource allocation for data transfer, subject to user-provided constraints on price or performance. Skyplane outperforms public cloud transfer services by up to 4.6Ã for transfers within one cloud and by up to 5.0Ã across clouds.}
}


@inproceedings{DBLP:conf/nsdi/0008WDY23,
	author = {Yang Zhou and
                  Zezhou Wang and
                  Sowmya Dharanipragada and
                  Minlan Yu},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {Electrode: Accelerating Distributed Protocols with eBPF},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {1391--1407},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/zhou},
	timestamp = {Thu, 11 May 2023 17:08:22 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/0008WDY23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Implementing distributed protocols under a standard Linux kernel networking stack enjoys the benefits of load-aware CPU scaling, high compatibility, and robust security and isolation. However, it suffers from low performance because of excessive user-kernel crossings and kernel networking stack traversing. We present Electrode with a set of eBPF-based performance optimizations designed for distributed protocols. These optimizations get executed in the kernel before the networking stack but achieve similar functionalities as were implemented in user space (e.g., message broadcasting, collecting quorum of acknowledgments), thus avoiding the overheads incurred by user-kernel crossings and kernel networking stack traversing. We show that when applied to a classic Multi-Paxos state machine replication protocol, Electrode improves its throughput by up to 128.4% and latency by up to 41.7%.}
}


@inproceedings{DBLP:conf/nsdi/RuanPABS23,
	author = {Zhenyuan Ruan and
                  Seo Jin Park and
                  Marcos K. Aguilera and
                  Adam Belay and
                  Malte Schwarzkopf},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {Nu: Achieving Microsecond-Scale Resource Fungibility with Logical
                  Processes},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {1409--1427},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/ruan},
	timestamp = {Thu, 11 May 2023 17:08:22 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/RuanPABS23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Datacenters waste significant compute and memory resources today because they lack resource fungibility: the ability to reassign resources quickly and without disruption. We propose logical processes, a new abstraction that splits the classic UNIX process into units of state called proclets. Proclets can be migrated quickly within datacenter racks, to provide fungibility and adapt to the memory and compute resource needs of the moment. We prototype logical processes in Nu, and use it to build three different applications: a social network application, a MapReduce system, and a scalable key-value store. We evaluate Nu with 32 servers. Our evaluation shows that Nu achieves high efficiency and fungibility: it migrates proclets in â100Î¼s; under intense resource pressure, migration causes small disruptions to tail latencyâthe 99.9th percentile remains below or around 1msâfor a duration of 0.54â2.1s, or a modest disruption to throughput (<6%) for a duration of 24â37ms, depending on the application.}
}


@inproceedings{DBLP:conf/nsdi/MengW00XHLAHW23,
	author = {Zili Meng and
                  Tingfeng Wang and
                  Yixin Shen and
                  Bo Wang and
                  Mingwei Xu and
                  Rui Han and
                  Honghao Liu and
                  Venkat Arun and
                  Hongxin Hu and
                  Xue Wei},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {Enabling High Quality Real-Time Communications with Adaptive Frame-Rate},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {1429--1450},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/meng},
	timestamp = {Thu, 11 May 2023 17:08:22 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/MengW00XHLAHW23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Emerging high quality real-time communication (RTC) applications stream ultra-high-definition (UHD) videos with high frame rate (HFR). They use edge computing, which enables high bandwidth and low latency streaming. Our measurements, from the cloud gaming platform of one of the largest gaming companies, show that, in this setting, the client-side decoder is often the cause for high latency that hurts user's experience. We therefore propose an Adaptive Frame Rate (AFR) controller that helps achieve ultra-low latency by coordinating the frame rate with network fluctuation and decoder capacity. AFR's design addresses two key challenges: (1) queue measurements do not provide timely feedback for the control loop and (2) multiple factors control the decoder queue, and different actions must be taken depending on why the queue accumulates. Trace-driven simulations and large-scale deployments in the wild demonstrate that AFR can reduce the tail queuing delay by up to 7.4Ã and the stuttering events measured by end-to-end delay by 34% on average. AFR has been deployed in production in our cloud gaming service for over one year.}
}


@inproceedings{DBLP:conf/nsdi/0011DSLS023,
	author = {Hao Li and
                  Yihan Dang and
                  Guangda Sun and
                  Guyue Liu and
                  Danfeng Shan and
                  Peng Zhang},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {LemonNFV: Consolidating Heterogeneous Network Functions at Line Speed},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {1451--1468},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/li-hao},
	timestamp = {Thu, 11 May 2023 17:08:22 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/0011DSLS023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {NFV has entered into a new era that heterogeneous frameworks coexist. NFs built upon those frameworks are thus not interoperable, obstructing operators from getting the best of the breed. Traditional interoperation solutions either incur large overhead, e.g., virtualizing NFs into containers, or require huge code modification, e.g., rewriting NFs with specific abstractions. We present LemonNFV, a novel NFV framework that can consolidate heterogeneous NFs without code modification. LemonNFV loads NFs into a single process down to the binary level, schedules them using an intercepted I/O, and isolates them with the help of a restricted memory allocator. Experiments show that LemonNFV can consolidate 5 complex NFs without modifying the native code while achieving comparable performance to the ideal and state-of-the-art pure consolidation approaches with only 0.7â4.3% overhead.}
}


@inproceedings{DBLP:conf/nsdi/BansalDTZGGBDSA23,
	author = {Deepak Bansal and
                  Gerald DeGrace and
                  Rishabh Tewari and
                  Michal Zygmunt and
                  James Grantham and
                  Silvano Gai and
                  Mario Baldi and
                  Krishna Doddapaneni and
                  Arun Selvarajan and
                  Arunkumar Arumugam and
                  Balakrishnan Raman and
                  Avijit Gupta and
                  Sachin Jain and
                  Deven Jagasia and
                  Evan Langlais and
                  Pranjal Srivastava and
                  Rishiraj Hazarika and
                  Neeraj Motwani and
                  Soumya Tiwari and
                  Stewart Grant and
                  Ranveer Chandra and
                  Srikanth Kandula},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {Disaggregating Stateful Network Functions},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {1469--1487},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/bansal},
	timestamp = {Thu, 11 May 2023 17:08:22 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/BansalDTZGGBDSA23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {For security, isolation, metering and other purposes, public clouds today implement complex network functions at every server. Today's implementations, in software or on FPGAs and ASICs that are attached to each host, are becoming increasingly complex, costly and bottlenecks to scalability. We present a different design that disaggregates network function processing off the host and into shared resource pools by making novel use of appliances which tightly integrate general-purpose ARM cores with high-speed stateful match processing ASICs. When work is skewed across VMs, such disaggregation can offer better reliability and performance over the state-of-art at a lower per-server cost. We describe our solutions to the consequent challenges and present results from a production deployment at a large public cloud.}
}


@inproceedings{DBLP:conf/nsdi/YuC0C23,
	author = {Minchen Yu and
                  Tingjia Cao and
                  Wei Wang and
                  Ruichuan Chen},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {Following the Data, Not the Function: Rethinking Function Orchestration
                  in Serverless Computing},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {1489--1504},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/yu},
	timestamp = {Thu, 11 May 2023 17:08:22 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/YuC0C23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Serverless applications are typically composed of function workflows in which multiple short-lived functions are triggered to exchange data in response to events or state changes. Current serverless platforms coordinate and trigger functions by following high-level invocation dependencies but are oblivious to the underlying data exchanges between functions. This design is neither efficient nor easy to use in orchestrating complex workflows â developers often have to manage complex function interactions by themselves, with customized implementation and unsatisfactory performance. In this paper, we argue that function orchestration should follow a data-centric approach. In our design, the platform provides a data bucket abstraction to hold the intermediate data generated by functions. Developers can use a rich set of data trigger primitives to control when and how the output of each function should be passed to the next functions in a workflow. By making data consumption explicit and allowing it to trigger functions and drive the workflow, complex function interactions can be easily and efï¬ciently supported. We present Pheromone â a scalable, low-latency serverless platform following this data-centric design. Compared to well-established commercial and open-source platforms, Pheromone cuts the latencies of function interactions and data exchanges by orders of magnitude, scales to large workflows, and enables easy implementation of complex applications.}
}


@inproceedings{DBLP:conf/nsdi/LiuLNB23,
	author = {David H. Liu and
                  Amit Levy and
                  Shadi A. Noghabi and
                  Sebastian Burckhardt},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {Doing More with Less: Orchestrating Serverless Applications without
                  an Orchestrator},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {1505--1519},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/liu-david},
	timestamp = {Thu, 11 May 2023 17:08:22 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/LiuLNB23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Standalone orchestrators simplify the development of serverless applications by providing higher-level programming interfaces, coordinating function interactions and ensuring exactly-once execution. However, they limit application flexibility and are expensive to use. We show that these specialized orchestration services are unnecessary. Instead, application-level orchestration, deployed as a library, can support the same programming interfaces, complex interactions and execution guarantees, utilizing only basic serverless components that are already universally supported and billed at a fine-grained per-use basis. Furthermore, application-level orchestration affords applications more flexibility and reduces costs for both providers and users. To demonstrate this, we present Unum, an application-level serverless orchestration system. Unum introduces an intermediate representation that partitions higher-level application definitions at compile-time and provides orchestration as a runtime library that executes in-situ with user-defined FaaS functions. On unmodified serverless infrastructures, Unum functions coordinate and ensure correctness in a decentralized manner by leveraging strongly consistent data stores. Compared with AWS Step Functions, a state-of-the-art standalone orchestrator, our evaluation shows that Unum performs well, costs significantly less and grants applications greater flexibility to employ application-specific patterns and optimizations. For a representative set of applications, Unum runs as much as 2x faster and costs 9x cheaper.}
}


@inproceedings{DBLP:conf/nsdi/BuhlerJPV23,
	author = {Tobias B{\"{u}}hler and
                  Romain Jacob and
                  Ingmar Poese and
                  Laurent Vanbever},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {Enhancing Global Network Monitoring with Magnifier},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {1521--1539},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/buhler},
	timestamp = {Thu, 11 May 2023 17:08:22 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/BuhlerJPV23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Monitoring where traffic enters and leaves a network is a routine task for network operators. In order to scale with Tbps of traffic, large Internet Service Providers (ISPs) mainly use traffic sampling for such global monitoring. Sampling either provides a sparse view or generates unreasonable overhead. While sampling can be tailored and optimized to specific contexts, this coverageâoverhead trade-off is unavoidable. Rather than optimizing sampling, we propose to "magnify" the sampling coverage by complementing it with mirroring. Magnifier enhances the global network view using a two-step approach: based on sampling data, it first infers traffic ingress and egress points using a heuristic, then it uses mirroring to validate these inferences efficiently. The key idea behind Magnifier is to use negativemirroring rules; i.e., monitor where traffic should not go. We implement Magnifier on commercial routers and demonstrate that it indeed enhances the global network view with negligible traffic overhead. Finally, we observe that monitoring based on our heuristics also allows to detect other events, such as certain failures and DDoS attacks.}
}


@inproceedings{DBLP:conf/nsdi/ChenLKZWZDYRML23,
	author = {Yu Chen and
                  Liqun Li and
                  Yu Kang and
                  Boyang Zheng and
                  Yehan Wang and
                  More Zhou and
                  Yuchao Dai and
                  Zhenguo Yang and
                  Brad Rutkowski and
                  Jeff Mealiffe and
                  Qingwei Lin},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {NetPanel: Traffic Measurement of Exchange Online Service},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {1541--1555},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/chen-yu},
	timestamp = {Sat, 26 Aug 2023 22:01:10 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/ChenLKZWZDYRML23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Global cloud applications are composed of thousands of components. These components are constantly generating large volumes of network traffic, which is a major cost of cloud applications. Identifying the traffic contributors is a critical step before reducing the traffic cost. However, this is challenging because the measurement has to be component-level, cost-effective, and under strict resource restrictions. In this paper, we introduce NetPanel, which is a traffic measurement platform for the Exchange Online (EXO) service of Microsoft. NetPanel fuses three data sources, namely IPFIX, Event Tracing for Windows (ETW), and application logs, to jointly measure the service traffic at the component level, where each component is owned by a service team. NetPanel uses several schemes to reduce the measurement overhead. NetPanel has been in operation for more than one year. It has been used to profile network traffic characteristics and traffic cost composition of EXO. With the insights obtained through NetPanel, we have saved millions of dollars in network resources. The overhead of running NetPanel is relatively small, which requires less than 1% CPU and disk I/O on production servers and less than 0.01% of EXO computation cores to process the data in our big-data platform.}
}


@inproceedings{DBLP:conf/nsdi/PerryFHKMST23,
	author = {Yarin Perry and
                  Felipe Vieira Frujeri and
                  Chaim Hoch and
                  Srikanth Kandula and
                  Ishai Menache and
                  Michael Schapira and
                  Aviv Tamar},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {{DOTE:} Rethinking (Predictive) {WAN} Traffic Engineering},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {1557--1581},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/perry},
	timestamp = {Thu, 11 May 2023 17:08:22 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/PerryFHKMST23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We explore a new design point for traffic engineering on wide-area networks (WANs): directly optimizing traffic flow on the WAN using only historical data about traffic demands. Doing so obviates the need to explicitly estimate, or predict, future demands. Our method, which utilizes stochastic optimization, provably converges to the global optimum in well-studied theoretical models. We employ deep learning to scale to large WANs and real-world traffic. Our extensive empirical evaluation on real-world traffic and network topologies establishes that our approach's TE quality almost matches that of an (infeasible) omniscient oracle, outperforming previously proposed approaches, and also substantially lowers runtimes.}
}


@inproceedings{DBLP:conf/nsdi/LiXNJ23,
	author = {Zhuqi Li and
                  Yaxiong Xie and
                  Ravi Netravali and
                  Kyle Jamieson},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {Dashlet: Taming Swipe Uncertainty for Robust Short Video Streaming},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {1583--1599},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/li-zhuqi},
	timestamp = {Thu, 11 May 2023 17:08:22 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/LiXNJ23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Short video streaming applications have recently gained substantial traction, but the non-linear video presentation they afford swiping users fundamentally changes the problem of maximizing user quality of experience in the face of the vagaries of network throughput and user swipe timing. This paper describes the design and implementation of Dashlet, a system tailored for high quality of experience in short video streaming applications. With the insights we glean from an in-the-wild TikTok performance study and a user study focused on swipe patterns, Dashlet proposes a novel out-of-order video chunk pre-buffering mechanism that leverages a simple, non machine learning-based model of users' swipe statistics to determine the pre-buffering order and bitrate. The net result is a system that outperforms TikTok by 28-101%, while also reducing by 30% the number of bytes wasted on downloaded video that is never watched.}
}


@inproceedings{DBLP:conf/nsdi/TanZDL23,
	author = {Zhaowei Tan and
                  Jinghao Zhao and
                  Boyan Ding and
                  Songwu Lu},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {CellDAM: User-Space, Rootless Detection and Mitigation for 5G Data
                  Plane},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {1601--1619},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/tan},
	timestamp = {Thu, 11 May 2023 17:08:22 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/TanZDL23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Despite all deployed security fences in 5G, attacks against its data plane are still feasible. A smart attacker can fabricate data packets or intelligently forge/drop/modify data-plane signaling messages between the 5G infrastructure and the device to inflict damage. In this work, we propose CellDAM, a new solution that is used at the device without any infrastructure upgrades or standard changes. CellDAM exploits the key finding that such data-plane attacks by the adversary would trigger unexpected data signaling operations. It thus detects all known and even currently unreported attacks via verifying data signaling correctness with novel state-dependent model checking. CellDAM could work with or without firmware access at the device using inference on low-level 5G signaling and configurations. It mitigates the damage upon detection by inducing frequency band switches at the device via the existing handover procedure. The prototype and empirical evaluation in our testbed confirm the viability of CellDAM.}
}


@inproceedings{DBLP:conf/nsdi/LuoFCHMRS23,
	author = {Zhihong Luo and
                  Silvery Fu and
                  Natacha Crooks and
                  Shaddi Hasan and
                  Christian Maciocco and
                  Sylvia Ratnasamy and
                  Scott Shenker},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {{LOCA:} {A} Location-Oblivious Cellular Architecture},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {1621--1646},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/luo},
	timestamp = {Thu, 11 May 2023 17:08:22 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/LuoFCHMRS23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cellular operators today know both the identity and location of their mobile subscribers and hence can easily profile users based on this information. Given this status quo, we aim to design a cellular architecture that protects the location privacy of users from their cellular providers. The fundamental challenge in this is reconciling privacy with an operator's need to provide services based on a user's identity (e.g., post-pay, QoS and service classes, lawful intercept, emergency services, forensics). We present LOCA, a novel cellular design that, for the first time, provides location privacy to users without compromising on identity-based services. LOCA is applicable to emerging MVNO-based cellular architectures in which a virtual operator acts as a broker between users and infrastructure operators. Using a combination of formal analysis, simulation, prototype implementation, and wide-area experiments, we show that LOCA provides provable privacy guarantees and scales to realistic deployment figures.}
}


@inproceedings{DBLP:conf/nsdi/Cho0GAJ23,
	author = {Kun Woo Cho and
                  Mohammad Hossein Mazaheri and
                  Jeremy Gummeson and
                  Omid Abari and
                  Kyle Jamieson},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {mmWall: {A} Steerable, Transflective Metamaterial Surface for NextG
                  mmWave Networks},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {1647--1665},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/cho-kun-woo},
	timestamp = {Thu, 11 May 2023 17:08:22 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/Cho0GAJ23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Mobile operators are poised to leverage millimeter wave technology as 5G evolves, but despite efforts to bolster their reliability indoors and outdoors, mmWave links remain vulnerable to blockage by walls, people, and obstacles. Further, there is significant interest in bringing outdoor mmWave coverage indoors, which for similar reasons remains challenging today. This paper presents the design, hardware implementation, and experimental evaluation of mmWall, the first electronically almost-360-degree steerable metamaterial surface that operates above 24 GHz and both refracts or reflects incoming mmWave transmissions. Our metamaterial design consists of arrays of varactor-split ring resonator unit cells, miniaturized for mmWave. Custom control circuitry drives each resonator, overcoming coupling challenges that arise at scale. Leveraging beam steering algorithms, we integrate mmWall into the link layer discovery protocols of common mmWave networks. We have fabricated a 10 cm by 20 cm mmWall prototype consisting of a 28 by 76 unit cell array and evaluated it in indoor, outdoor-to-indoor, and multi-beam scenarios. Indoors, mmWall guarantees 91% of locations outage-free under 128-QAM mmWave data rates and boosts SNR by up to 15 dB. Outdoors, mmWall reduces the probability of complete link failure by a ratio of up to 40% under 0â80% path blockage and boosts SNR by up to 30 dB.}
}


@inproceedings{DBLP:conf/nsdi/HasanPDRKGSYABB23,
	author = {Shaddi Hasan and
                  Amar Padmanabhan and
                  Bruce Davie and
                  Jennifer Rexford and
                  Ulas Kozat and
                  Hunter Gatewood and
                  Shruti Sanadhya and
                  Nick Yurchenko and
                  Tariq Al{-}Khasib and
                  Oriol Batalla and
                  Marie Bremner and
                  Andrei Lee and
                  Evgeniy Makeev and
                  Scott Moeller and
                  Alex Rodriguez and
                  Pravin Shelar and
                  Karthik Subraveti and
                  Sudarshan Kandi and
                  Alejandro Xoconostle and
                  Praveen Kumar Ramakrishnan and
                  Xiaochen Tian and
                  Anoop Tomar},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {Building Flexible, Low-Cost Wireless Access Networks With Magma},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {1667--1681},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/hasan},
	timestamp = {Thu, 11 May 2023 17:08:22 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/HasanPDRKGSYABB23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Billions of people remain without Internet access due to availability or affordability of service. In this paper, we present Magma, an open and flexible system for building low-cost wireless access networks. Magma aims to connect users where operator economics are difficult due to issues such as low population density or income levels while preserving features expected in cellular networks such as authentication and billing policies. To achieve this, and in contrast to traditional cellular networks, Magma adopts an approach that extensively leverages Internet design patterns, terminating access network-specific protocols at the edge and abstracting the access network from the core architecture. This decision allows Magma to refactor the wireless core using SDN (software-defined networking) principles and leverage other techniques from modern distributed systems. In doing so, Magma lowers cost and operational complexity for network operators while achieving resilience, scalability, and rich policy support.}
}


@inproceedings{DBLP:conf/nsdi/DongLLWGZ023,
	author = {Wei Dong and
                  Borui Li and
                  Haoyu Li and
                  Hao Wu and
                  Kaijie Gong and
                  Wenzhao Zhang and
                  Yi Gao},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {LinkLab 2.0: {A} Multi-tenant Programmable IoT Testbed for Experimentation
                  with Edge-Cloud Integration},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {1683--1699},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/dong},
	timestamp = {Mon, 30 Oct 2023 08:25:25 +0100},
	biburl = {https://dblp.org/rec/conf/nsdi/DongLLWGZ023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we present LinkLab 2.0, a completely programmable and controllable IoT testbed with the support of edge devices and cloud infrastructures. To be more specific, LinkLab 2.0 leverages a tiered architecture for the programmable devices and the management system to achieve scalability. To better support the integrated experiment among IoT, edge and cloud, LinkLab 2.0 provides one-site programming support and leverages the customizable offloading with serverless functions. Moreover, LinkLab 2.0 proposes a device-involved multi-tenancy approach to ensure responsiveness for concurrent requests. Furthermore, targeting 24/7 availability for experimenters, LinkLab 2.0 leverages proactive and reactive anomaly detection to improve the reliability of the testbed. Finally, we describe the supported research experiments and the outreach usage by external users. We also report lessons learned from the four-year operation. LinkLab 2.0 has supported experiments for 2,100+ users. The accumulated usage time across all the devices exceeds 17,300 hours.}
}


@inproceedings{DBLP:conf/nsdi/Chen0NYX23,
	author = {Yinfang Chen and
                  Xudong Sun and
                  Suman Nath and
                  Ze Yang and
                  Tianyin Xu},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {Push-Button Reliability Testing for Cloud-Backed Applications with
                  Rainmaker},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {1701--1716},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/chen-yinfang},
	timestamp = {Thu, 11 May 2023 17:08:22 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/Chen0NYX23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Modern applications have been emerging towards a cloud-based programming model where applications depend on cloud services for various functionalities. Such âcloud nativeâ practice greatly simplifies application deployment and realizes cloud benefits (e.g., availability). Meanwhile, it imposes emerging reliability challenges for addressing fault models of the opaque cloud and less predictable Internet connections. In this paper, we discuss these reliability challenges. We develop a taxonomy of bugs that render cloud-backed applications vulnerable to common transient faults. We show that (mis)handling transient error(s) of even one REST call interaction can adversely affect application correctness. We take a first step to address the challenges by building a âpush-buttonâ reliability testing tool named Rainmaker, as a basic SDK utility for any cloud-backed application. Rainmaker helps developers anticipate the myriad of errors under the cloud-based fault model, without a need to write new policies, oracles, or test cases. Rainmaker directly works with existing test suites and is a plug-and-play tool for existing test environments. Rainmaker injects faults in the interactions between the application and cloud services. It does so at the REST layer, and thus is transparent to applications under test. More importantly, it encodes automatic fault injection policies to cover the various taxonomized bug patterns, and automatic oracles that embrace existing in-house software tests. To date, Rainmaker has detected 73 bugs (55 confirmed and 51 fixed) in 11 popular cloud-backed applications.}
}


@inproceedings{DBLP:conf/nsdi/XuDBMW23,
	author = {Xieyang Xu and
                  Weixin Deng and
                  Ryan Beckett and
                  Ratul Mahajan and
                  David Walker},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {Test Coverage for Network Configurations},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {1717--1732},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/xu},
	timestamp = {Mon, 08 Apr 2024 07:49:52 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/XuDBMW23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We develop NetCov, the first tool to reveal which network configuration lines are tested by a suite of network tests. It helps network engineers improve test suites and thus increase network reliability. A key challenge in developing a tool like NetCov is that many network tests test the data plane instead of testing the configurations (control plane) directly. We must be able to efficiently infer which configuration elements contribute to tested data plane elements, even when such contributions are non-local (on remote devices) or non-deterministic. NetCov uses an information flow graph based model that precisely captures various forms of contributions and a scalable method to infer contributions. Using NetCov, we show that an existing test suite for Internet2, a nation-wide backbone network in the USA, covers only 26% of the configuration lines. The feedback from NetCov makes it easy to define new tests that improve coverage. For Internet2, adding just three such tests covers an additional 17% of the lines.}
}


@inproceedings{DBLP:conf/nsdi/ChenT0D0MTZYCCZ23,
	author = {Yanqing Chen and
                  Bingchuan Tian and
                  Chen Tian and
                  Li Dai and
                  Yu Zhou and
                  Mengjing Ma and
                  Ming Tang and
                  Hao Zheng and
                  Zhewen Yang and
                  Guihai Chen and
                  Dennis Cai and
                  Ennan Zhai},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {Norma: Towards Practical Network Load Testing},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {1733--1749},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/chen-yanqing},
	timestamp = {Thu, 11 May 2023 17:08:22 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/ChenT0D0MTZYCCZ23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Network load tester is important to daily network operation. Motivated by our experience with a major cloud provider, a practical load tester should satisfy two important requirements: (R1) stateful protocol customization, and (R2) real network traffic emulation (including high-throughput traffic generation and precise rate control). Despite the success of recent load testers, we found they fail to meet both above requirements. This paper presents Norma, a practical network load tester built upon programmable switch ASICs. To achieve the above requirements, Norma addresses three challenges: (1) modeling stateful protocols on the pipelined architecture of the ASIC, (2) generating replying packets with customized payload for stateful protocols, and (3) controlling mimicked traffic in a precise way. Specifically, first, Norma introduces a stateful protocol abstraction that allows us to program the logic of the state machine (e.g., control flow and memory access) on the programmable switch ASIC. Second, Norma proposes a novel multi-queue structure to generate replying packets and customize the payload of packets. Third and finally, Norma coordinates meters and registers to construct a multi-stage rate control mechanism capable of offering precise rate and burst control. Norma has been used to test the performance of our production network devices for over two years and detected tens of performance issues. Norma can generate up to 3 Tbps TCP traffic and 1 Tbps HTTP traffic.}
}


@inproceedings{DBLP:conf/nsdi/Song0WZZYHL23,
	author = {Yihang Song and
                  Li Lu and
                  Jiliang Wang and
                  Chong Zhang and
                  Hui Zheng and
                  Shen Yang and
                  Jinsong Han and
                  Jian Li},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {{\(\mu\)}Mote: Enabling Passive Chirp De-spreading and {\(\mu\)}W-level
                  Long-Range Downlink for Backscatter Devices},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {1751--1766},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/song-yihang},
	timestamp = {Thu, 11 May 2023 17:08:22 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/Song0WZZYHL23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The downlink range of backscatter devices is commonly considered to be very limited, compared to tremendous long-range and low-power backscatter uplink designs that leverage the chirp spread spectrum (CSS) principle. Recently, some efforts are devoted to enhancing the downlink, but they are unable to achieve long-range receiving and low power consumption simultaneously. In this paper, we propose ÂµMote, a ÂµW-level long-range receiver for backscatter devices. ÂµMote achieves the first passive chirp de-spreading scheme for negative SINR in long-range receiving scenarios. Further, without consuming external energy, ÂµMote magnifies the demodulated signal by accumulating temporal energy of the signal itself in a resonator container, and meanwhile it preserves signal information during this signal accumulation. ÂµMote then leverages a ÂµW-level sampling-less decoding scheme to discriminate symbols, avoiding the high-power ADC-sampling. We prototype ÂµMote with COTS components, and conduct extensive experiments. The result shows that ÂµMote spends an overall power consumption of 62.07ÂµW to achieve a 400m receiving range at a 2kbps data rate with 1% BER, under â2dB SINR}
}


@inproceedings{DBLP:conf/nsdi/ChenYHM23,
	author = {Yongzhou Chen and
                  Ruihao Yao and
                  Haitham Hassanieh and
                  Radhika Mittal},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {Channel-Aware 5G {RAN} Slicing with Customizable Schedulers},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {1767--1782},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/chen-yongzhou},
	timestamp = {Thu, 11 May 2023 17:08:22 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/ChenYHM23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper focuses on 5G RAN slicing, where the 5G radio resources must be divided across slices (or enterprises) so as to achieve high spectrum efficiency, fairness and isolation across slices, and the ability for each slice to customize how the radio resources are divided across its own users. Realizing these goals requires accounting for the channel quality for each user (that varies over time and frequency domain) at both levels â inter-slice scheduling (i.e. dividing resources across slices) and enterprise scheduling (i.e. dividing resources within a slice). However, a cyclic dependency between the inter-slice and enterprise schedulers makes it difficult to incorporate channel awareness at both levels. We observe that the cyclic dependency can be broken if both the inter-slice and enterprise schedulers are greedy. Armed with this insight, we design RadioSaber, the first RAN slicing mechanism to do channel-aware inter-slice and enterprise scheduling. We implement RadioSaber on an open-source RAN simulator, and our evaluation shows how RadioSaber can achieve 17%-72% better throughput than the state-of-theart RAN slicing technique (that performs channel-agnostic inter-slice scheduling), while meeting the primary goals of fairness across slices and the ability to support a wide variety of customizable enterprise scheduling policies.}
}


@inproceedings{DBLP:conf/nsdi/LiangWZGZGZL0X23,
	author = {Bo Liang and
                  Purui Wang and
                  Renjie Zhao and
                  Heyu Guo and
                  Pengyu Zhang and
                  Junchen Guo and
                  Shunmin Zhu and
                  Hongqiang Harry Liu and
                  Xinyu Zhang and
                  Chenren Xu},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {RF-Chord: Towards Deployable {RFID} Localization System for Logistic
                  Networks},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {1783--1799},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/liang-bo},
	timestamp = {Mon, 25 Sep 2023 12:16:55 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/LiangWZGZGZL0X23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {RFID localization is considered the key enabler of automating the process of inventory tracking and management for the high-performance logistic network. A practical and deployable RFID localization system needs to meet reliability, throughput, and range requirements. This paper presents RF-CHORD, the first RFID localization system that simultaneously meets all three requirements. RF-CHORD features a multisine-constructed wideband design that can process RF signals with a 200 MHz bandwidth in real-time to facilitate one-shot localization at scale. In addition, multiple SINR enhancement techniques are designed for range extension. On top of that, a kernel-layer near-field localization framework and a multipath-suppression algorithm are proposed to reduce the 99th long-tail errors. Our empirical results show that RF-CHORD can localize up to 180 tags 6 m away from a reader within 1 second and with 99th longtail error of 0.786 m, achieving a 0% miss reading rate and ~0.01% cross-reading rate in the warehouse and fresh food delivery store deployment.}
}


@inproceedings{DBLP:conf/nsdi/LiuXS0V23,
	author = {Zikun Liu and
                  Changming Xu and
                  Emerson Sie and
                  Gagandeep Singh and
                  Deepak Vasisht},
	editor = {Mahesh Balakrishnan and
                  Manya Ghobadi},
	title = {Exploring Practical Vulnerabilities of Machine Learning-based Wireless
                  Systems},
	booktitle = {20th {USENIX} Symposium on Networked Systems Design and Implementation,
                  {NSDI} 2023, Boston, MA, April 17-19, 2023},
	pages = {1801--1817},
	publisher = {{USENIX} Association},
	year = {2023},
	url = {https://www.usenix.org/conference/nsdi23/presentation/liu-zikun},
	timestamp = {Thu, 11 May 2023 17:08:22 +0200},
	biburl = {https://dblp.org/rec/conf/nsdi/LiuXS0V23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Machine Learning (ML) is an increasingly popular tool for designing wireless systems, both for communication and sensing applications. We design and evaluate the impact of practically feasible adversarial attacks against such ML-based wireless systems. In doing so, we solve challenges that are unique to the wireless domain: lack of synchronization between a benign device and the adversarial device, and the effects of the wireless channel on adversarial noise. We build, RAFA (RAdio Frequency Attack), the first hardware-implemented adversarial attack platform against ML-based wireless systems, and evaluate it against two state-of-the-art communication and sensing approaches at the physical layer. Our results show that both these systems experience a significant performance drop in response to the adversarial attack}
}
