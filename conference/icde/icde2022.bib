@inproceedings{DBLP:conf/icde/NakajimaS22,
	author = {Kazuki Nakajima and
                  Kazuyuki Shudo},
	title = {Social Graph Restoration via Random Walk Sampling},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1--14},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00065},
	doi = {10.1109/ICDE53745.2022.00065},
	timestamp = {Fri, 05 Aug 2022 16:24:00 +0200},
	biburl = {https://dblp.org/rec/conf/icde/NakajimaS22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Analyzing social graphs with limited data access is challenging for third-party researchers. To address this challenge, a number of algorithms that estimate structural properties via a random walk have been developed. However, most existing algorithms are limited to the estimation of local structural properties. Here we propose a method for restoring the original social graph from the small sample obtained by a random walk. The proposed method generates a graph that preserves the estimates of local structural properties and the structure of the subgraph sampled by a random walk. We compare the proposed method with subgraph sampling using a crawling method and the existing method for generating a graph that structurally resembles the original graph via a random walk. Our experimental results show that the proposed method more accurately reproduces the local and global structural properties on average and the visual representation of the original graph than the compared methods. We expect that our method will lead to exhaustive analyses of social graphs with limited data access.}
}


@inproceedings{DBLP:conf/icde/WangMCW22,
	author = {Haibo Wang and
                  Chaoyi Ma and
                  Shigang Chen and
                  Yuanda Wang},
	title = {Online Cardinality Estimation by Self-morphing Bitmaps},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1--13},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00005},
	doi = {10.1109/ICDE53745.2022.00005},
	timestamp = {Sun, 12 Nov 2023 02:08:08 +0100},
	biburl = {https://dblp.org/rec/conf/icde/WangMCW22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Estimating the cardinality of a data stream is a fundamental problem underlying numerous applications such as traffic monitoring in a network or a datacenter, popularity tracking on social media, and cache optimization in proxy servers. Existing solutions suffer from high processing/query overhead or memory in-efficiency, which prevents them from operating online for data streams with very high arrival rates. This paper takes a new solution path different from the prior art and proposes a self-morphing bitmap, which combines operational simplicity with structural dynamics, allowing the bitmap to be morphed in a series of steps with an evolving sampling probability that automatically adapts to different stream sizes. We evaluate the self-morphing bitmap theoretically and experimentally. The results demonstrate that it significantly outperforms the prior art.}
}


@inproceedings{DBLP:conf/icde/ZhuLZLYRZ22,
	author = {Yulin Zhu and
                  Yuni Lai and
                  Kaifa Zhao and
                  Xiapu Luo and
                  Mingquan Yuan and
                  Jian Ren and
                  Kai Zhou},
	title = {BinarizedAttack: Structural Poisoning Attacks to Graph-based Anomaly
                  Detection},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {14--26},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00006},
	doi = {10.1109/ICDE53745.2022.00006},
	timestamp = {Mon, 22 Jan 2024 12:10:32 +0100},
	biburl = {https://dblp.org/rec/conf/icde/ZhuLZLYRZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graph-based Anomaly Detection (GAD) is becoming prevalent due to the powerful representation abilities of graphs as well as recent advances in graph mining techniques. These GAD tools, however, expose a new attacking surface, ironically due to their unique advantage of being able to exploit the relations among data. That is, attackers now can manipulate those relations (i.e., the structure of the graph) to allow some target nodes to evade detection. In this paper, we exploit this vulnerability by designing a new type of targeted structural poisoning attacks to a representative regression-based GAD system termed OddBall. Specifically, we formulate the attack against OddBall as a bi-level optimization problem, where the key technical challenge is to efficiently solve the problem in a discrete domain. We propose a novel attack method termed BinarizedAttack based on gradient descent. Comparing to prior arts, BinarizedAttack can better use the gradient information, making it particularly suitable for solving combinatorial optimization problems. Furthermore, we investigate the attack transferability of BinarizedAttack by employing it to attack other representation-learning-based GAD systems. Our comprehensive experiments demonstrate that BinarizedAttack is very effective in enabling target nodes to evade graph-based anomaly detection tools with limited attacker's budget, and in the black-box transfer attack setting, BinarizedAttack is also tested effective and in particular, can significantly change the node embeddings learned by the GAD systems. Our research thus opens the door to studying a new type of attack against security analytic tools that rely on graph data.}
}


@inproceedings{DBLP:conf/icde/ZhaoDPLCC22,
	author = {Kai Zhao and
                  Sheng Di and
                  Danny Perez and
                  Xin Liang and
                  Zizhong Chen and
                  Franck Cappello},
	title = {{MDZ:} An Efficient Error-bounded Lossy Compressor for Molecular Dynamics},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {27--40},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00007},
	doi = {10.1109/ICDE53745.2022.00007},
	timestamp = {Wed, 07 Dec 2022 23:09:58 +0100},
	biburl = {https://dblp.org/rec/conf/icde/ZhaoDPLCC22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Molecular dynamics (MD) has been widely used in today's scientific research across multiple domains including materials science, biochemistry, biophysics, and structural biology. MD simulations can produce extremely large amounts of data in that each simulation could involve a large number of atoms (up to trillions) for a large number of timesteps (up to hundreds of millions). In this paper, we perform an in-depth analysis of a number of MD simulation datasets and then develop an efficient error-bounded lossy compressor that can significantly improve the compression ratios. The contributions are fourfold. (1) We characterize a number of MD datasets and summarize two commonly-used execution models. (2) We develop an adaptive error-bounded lossy compression framework (called MDZ), which can optimize the compression for both execution models adaptively by taking advantage of their specific characteristics. (3) We compare our solution with six other state-of-the-art related works by using three MD simulation packages each with multiple configurations. Experiments show that our solution has up to 233 % higher compression ratios than the second-best lossy compressor in most cases. (4) We demonstrate that MDZ is fully capable of handing particle data beyond MD simulations.}
}


@inproceedings{DBLP:conf/icde/WangFM22,
	author = {Yanhao Wang and
                  Francesco Fabbri and
                  Michael Mathioudakis},
	title = {Streaming Algorithms for Diversity Maximization with Fairness Constraints},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {41--53},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00008},
	doi = {10.1109/ICDE53745.2022.00008},
	timestamp = {Sun, 02 Oct 2022 16:04:37 +0200},
	biburl = {https://dblp.org/rec/conf/icde/WangFM22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Diversity maximization is a fundamental problem with wide applications in data summarization, web search, and recommender systems. Given a set X of n elements, it asks to select a subset S of k\\ll n elements with maximum diversity, as quantified by the dissimilarities among the elements in S. In this paper, we focus on the diversity maximization problem with fairness constraints in the streaming setting. Specifically, we consider the max-min diversity objective, which selects a subset S that maximizes the minimum distance (dissimilarity) between any pair of distinct elements within it. Assuming that the set X is partitioned into m disjoint groups by some sensitive attribute, e.g., sex or race, ensuring fairness requires that the selected subset S contains k i elements from each group i є [1, m]. A streaming algorithm should process X sequentially in one pass and return a subset with maximum diversity while guaranteeing the fairness constraint. Although diversity maximization has been extensively studied, the only known algorithms that can work with the max-min diversity objective and fairness constraints are very inefficient for data streams. Since diversity maximization is NP-hard in general, we propose two approximation algorithms for fair diversity maximization in data streams, the first of which is \\frac{1-\\varepsilon}{4} -approximate and specific for m = 2, where є E (0,1), and the second of which achieves a \\frac{1-\\varepsilon}{3m+2} -approximation for an arbitrary m . Experimental results on real-world and synthetic datasets show that both algorithms provide solutions of comparable quality to the state-of-the-art algorithms while running several orders of magnitude faster in the streaming setting.}
}


@inproceedings{DBLP:conf/icde/ThaiTVD22,
	author = {Phuc Thai and
                  My T. Thai and
                  Tam Vu and
                  Thang N. Dinh},
	title = {SaPHyRa: {A} Learning Theory Approach to Ranking Nodes in Large Networks},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {54--67},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00009},
	doi = {10.1109/ICDE53745.2022.00009},
	timestamp = {Sun, 02 Oct 2022 16:04:37 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ThaiTVD22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Ranking nodes based on their centrality stands a fundamental, yet, challenging problem in large-scale networks. Approximate methods can quickly estimate nodes' centrality and identify the most central nodes, but the ranking for the majority of remaining nodes may be meaningless. For example, ranking for less-known websites in search queries is known to be noisy and unstable. To this end, we investigate a new node ranking problem with two important distinctions: a) ranking quality, rather than the centrality estimation quality, as the primary objective; and b) ranking only nodes of interest, e.g., websites that matched search criteria. We propose Sample space Partitloning Hypothesis Ranking, or SaPHyRa, that transforms node rankinginto a hy-pothesis ranking in machine learning. This transformation maps nodes' centrality to the expected risks of hypotheses, opening doors for theoretical machine learning (ML) tools. The key of SaPHyRa is to partition the sample space into exact and approx-imate subspaces. The exact subspace contains samples related to the nodes of interest, increasing both estimation and ranking qualities. The approximate space can be efficiently sampled with ML-based techniques to provide theoretical guarantees on the estimation error. Lastly, we present SaPHyRabo an illustration of SaPHyRa on ranking nodes' betweenness centrality (BC). By combining a novel bi-component sampling, a 2-hop sample partitioning, and improved bounds on the Vapnik-Chervonenkis dimension, SaPHyRas., can effectively rank any node subset in BC. Its performance is up to 200x faster than state-of-the-art methods in approximating BC, while its rank correlation to the ground truth is improved by multifold.}
}


@inproceedings{DBLP:conf/icde/LiuZFYPN22,
	author = {Jiahong Liu and
                  Min Zhou and
                  Philippe Fournier{-}Viger and
                  Menglin Yang and
                  Lujia Pan and
                  Mourad Nouioua},
	title = {Discovering Representative Attribute-stars via Minimum Description
                  Length},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {68--80},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00010},
	doi = {10.1109/ICDE53745.2022.00010},
	timestamp = {Fri, 05 Aug 2022 16:24:00 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LiuZFYPN22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graphs are a popular data type found in many domains. Numerous techniques have been proposed to find interesting patterns in graphs to help understand the data and support decision-making. However, there are generally two limitations that hinder their practical use: (1) they have multiple parameters that are hard to set but greatly influence results, (2) and they generally focus on identifying complex subgraphs while ignoring relationships between attributes of nodes. Graphs are a popular data type found in many domains. Numerous techniques have been proposed to find interesting patterns in graphs to help understand the data and support decision-making. However, there are generally two limitations that hinder their practical use: (1) they have multiple parameters that are hard to set but greatly influence results, (2) and they generally focus on identifying complex subgraphs while ignoring relationships between attributes of nodes. To address these problems, we propose a parameter-free algorithm named CSPM (Compressing Star Pattern Miner) which identifies star-shaped patterns that indicate strong correlations among attributes via the concept of conditional entropy and the minimum description length principle. Experiments performed on several benchmark datasets show that CSPM reveals insightful and interpretable patterns and is efficient in runtime. Moreover, quantitative evaluations on two real-world applications show that CSPM has broad applications as it successfully boosts the accuracy of graph attribute completion models by up to 30.68% and uncovers important patterns in telecommunication alarm data.}
}


@inproceedings{DBLP:conf/icde/TangZTH22,
	author = {Jing Tang and
                  Yuqing Zhu and
                  Xueyan Tang and
                  Kai Han},
	title = {Distributed Influence Maximization for Large-Scale Online Social Networks},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {81--95},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00011},
	doi = {10.1109/ICDE53745.2022.00011},
	timestamp = {Fri, 05 Aug 2022 16:24:00 +0200},
	biburl = {https://dblp.org/rec/conf/icde/TangZTH22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Thanks to billions of users in online social networks (OSNs), viral marketing becomes one of the most effective promotion channels for various new products or campaigns. Influence maximization is a classic problem in viral marketing, which has been extensively studied in the past two decades. Existing algorithms for influence maximization, however, mostly focus on single machine processing. To address the influence maximization problem on a massive scale, we design distributed algorithms via a cluster of machines, which can effectively speed up the computation while maintaining the state-of-the-art (1 -1/e-c)-approximation guarantee. Our distributed algorithms consist of two building blocks: (i) distributed reverse influence sampling, and (ii) element-distributed maximum coverage. We carry out extensive experiments on real datasets with millions of nodes and billions of edges to demonstrate the scalability of our distributed algorithms for both influence maximization and maximum coverage. In particular, our distributed algorithms accelerate the state-of-the-art IMM algorithm by 31x-56x times using a machine with 64 cores.}
}


@inproceedings{DBLP:conf/icde/FanZYYWWLC22,
	author = {Zhuochen Fan and
                  Yinda Zhang and
                  Tong Yang and
                  Mingyi Yan and
                  Gang Wen and
                  Yuhan Wu and
                  Hongze Li and
                  Bin Cui},
	title = {PeriodicSketch: Finding Periodic Items in Data Streams},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {96--109},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00012},
	doi = {10.1109/ICDE53745.2022.00012},
	timestamp = {Mon, 06 Feb 2023 17:38:48 +0100},
	biburl = {https://dblp.org/rec/conf/icde/FanZYYWWLC22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we study periodic items in data streams, which refer to those items arriving with a fixed interval. All existing works involving mining periodic patterns does not fit for data stream scenarios. To find periodic items in real time, we propose a novel sketch, PeriodicSketch, aiming to accurately record top-\nK\nperiodic items. To the best of our knowledge, this is the first work to find periodic items in data streams. Any interval may occur many times, and we use frequency to denote the number of an interval occurred. To pick out periodic items with high frequency, we propose a key technique called Guaranteed Soft Uniform (GSU) replacement strategy. Our theoretical proofs show that when replacement is successful, it is more likely that the new item has a higher frequency than the current smallest frequency; and GSU can ensure that our items in the sketch will approach the true periodic items closer and closer. And as soon as we get all the periodic items, the state would not change worse with high probability. We conduct extensive experiments, and the experimental results show that the Average Absolute Error (AAE) of our sketch using 1/10 memory is around 737 times (up to 2019 times) lower than the baseline solution. Finally, we provide a concrete case: Cache prefetch, which proves that PeriodicSketch can significantly improve the Cache hit ratio. All related codes of PeriodicSketch are open-sourced and available at GitHub [1].}
}


@inproceedings{DBLP:conf/icde/ZengWLZSTFHG22,
	author = {Juxiang Zeng and
                  Pinghui Wang and
                  Lin Lan and
                  Junzhou Zhao and
                  Feiyang Sun and
                  Jing Tao and
                  Junlan Feng and
                  Min Hu and
                  Xiaohong Guan},
	title = {Accurate and Scalable Graph Neural Networks for Billion-Scale Graphs},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {110--122},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00013},
	doi = {10.1109/ICDE53745.2022.00013},
	timestamp = {Mon, 11 Mar 2024 13:45:27 +0100},
	biburl = {https://dblp.org/rec/conf/icde/ZengWLZSTFHG22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graph Neural Networks (GNNs) have been success-fully applied to a variety of graph analysis tasks. Some recent studies have demonstrated that decoupling neighbor aggregation and feature transformation helps to scale GNNs to large graphs. However, very large graphs, with billions of nodes and millions of features, are still beyond the capacity of most existing GNNs. In addition, when we are only interested in a small number of nodes (called target nodes) in a large graph, it is inefficient to use the existing GNNs to infer the labels of these few target nodes. The reason is that they need to propagate and aggregate either node features or predicted labels over the whole graph, which incurs high additional costs relative to the few target nodes. To solve the above challenges, in this paper we propose a novel scalable and effective GNN framework COSAL. In COSAL, we substitute the expensive aggregation with an efficient proximate node selection mechanism, which picks out the most important\nK\nnodes for each target node according to the graph topology. We further propose a fine-grained neighbor importance quantification strategy to enhance the expressive power of COSAL. Empirical results demonstrate that our COSAL achieves superior performance in accuracy, training speed, and partial inference efficiency. Remarkably, in terms of node classification accuracy, our model COSAL outperforms baselines by significant margins of 2.22%, 2.23%, and 3.95% on large graph datasets Amazon2M, MAG-Scholar-C, and ogbn-papers100M, respectively. 1 1 Code available at https://github.com/joyce-x/COSAL.}
}


@inproceedings{DBLP:conf/icde/LiYC22,
	author = {Zhe Li and
                  Man Lung Yiu and
                  Tsz Nam Chan},
	title = {{PAW:} Data Partitioning Meets Workload Variance},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {123--135},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00014},
	doi = {10.1109/ICDE53745.2022.00014},
	timestamp = {Fri, 05 Aug 2022 16:24:03 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LiYC22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In distributed storage systems (e.g., HDFS, Amazon S3, Databricks), partitioning is applied on a dataset in order to enhance performance and availability. Recently, partitioning methods have been designed to optimize the query performance of partitions with respect to the historical query workload. Never-theless, in practice, future query workloads may deviate from the historical query workload, thus deteriorating the performance of existing partitioning methods. To fill this research gap, we model the variance of future query workloads from the historical query workload, then exploit this characteristic to produce partitions that perform well for future query workloads. In addition, we explore the space of irregular shaped partition regions to further optimize the query performance. Experimental results on TPC-H and real datasets show that our proposal is up to 70x more efficient than the state-of-the-art method.}
}


@inproceedings{DBLP:conf/icde/WangXXLWH22,
	author = {Lun Wang and
                  Yang Xu and
                  Hongli Xu and
                  Jianchun Liu and
                  Zhiyuan Wang and
                  Liusheng Huang},
	title = {Enhancing Federated Learning with In-Cloud Unlabeled Data},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {136--149},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00015},
	doi = {10.1109/ICDE53745.2022.00015},
	timestamp = {Wed, 07 Dec 2022 23:09:59 +0100},
	biburl = {https://dblp.org/rec/conf/icde/WangXXLWH22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated learning (FL) has been widely applied to collaboratively train deep learning (DL) models on massive end devices (i.e., clients). Due to the limited storage capacity and high labeling cost, there are always insufficient data stored and annotated on each client. Conversely, in cloud datacenters, there exist large-scale unlabeled data, which are easy to collect from public access (e.g., social media). Herein, upon the federated semi-supervised learning (FSSL) technology, we propose the Ada-FedSemi system, which leverages both on-device labeled data and in-cloud unlabeled data to boost the performance of DL models. Given the limited communication and massive quantity of the clients, in each training round, we decide to select partial clients to participate in FL, and their local models are aggregated by the parameter server (PS) to produce pseudo-labels for the unlabeled data, which are utilized to enhance the global model. Considering that the number of participating clients and the quality of pseudo-labels will have a significant impact on the training performance (e.g., efficiency and accuracy), we introduce a multi-armed bandit (MAB) based online algorithm to adaptively determine the participating fraction and confidence threshold during federated model training. Extensive experiments on benchmark models and datasets show that, given the same resource budget, the model trained by Ada-FedSemi achieves 3%-14.8 % higher test accuracy than that of the baseline methods. Besides, when achieving the same test accuracy, Ada-FedSemi saves up to 48% training cost, compared with the baselines.}
}


@inproceedings{DBLP:conf/icde/RebmannWA22,
	author = {Adrian Rebmann and
                  Matthias Weidlich and
                  Han van der Aa},
	title = {{GECCO:} Constraint-driven Abstraction of Low-level Event Logs},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {150--163},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00016},
	doi = {10.1109/ICDE53745.2022.00016},
	timestamp = {Sun, 06 Oct 2024 21:04:58 +0200},
	biburl = {https://dblp.org/rec/conf/icde/RebmannWA22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Process mining enables the analysis of complex systems using event data recorded during the execution of processes. Specifically, models of these processes can be discovered from event logs, i.e., sequences of events. However, the recorded events are often too fine-granular and result in unstructured models that are not meaningful for analysis. Log abstraction therefore aims to group together events to obtain a higher-level representation of the event sequences. While such a transformation shall be driven by the analysis goal, existing techniques force users to define how the abstraction is done, rather than what the result shall be. In this paper, we propose GECCO, an approach for log abstraction that enables users to impose requirements on the resulting log in terms of constraints. GECCO then groups events so that the constraints are satisfied and the distance to the original log is minimized. Since exhaustive log abstraction suffers from an exponential runtime complexity, GECCO also offers a heuristic approach guided by behavioral dependencies found in the log. We show that the abstraction quality of GECCO is superior to baseline solutions and demonstrate the relevance of considering constraints during log abstraction in real-life settings.}
}


@inproceedings{DBLP:conf/icde/ZhaoZYYCU22,
	author = {Yikai Zhao and
                  Yubo Zhang and
                  Pu Yi and
                  Tong Yang and
                  Bin Cui and
                  Steve Uhlig},
	title = {The Stair Sketch: Bringing more Clarity to Memorize Recent Events},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {164--177},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00017},
	doi = {10.1109/ICDE53745.2022.00017},
	timestamp = {Sat, 20 Apr 2024 10:27:52 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhaoZYYCU22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Data stream processing has become fundamental in computer science, with a wide range of applications, such as in databases, data mining, and security. Memorizing when an item appears in the data stream is one important task in stream processing. Because the older data is, the less value it has, memorizing recent events with higher accuracy is desirable. To achieve this, we propose a novel data stream processing structure named the Stair sketch. Our key idea is to organize the memory used by different time periods in the shape of stairs. We deploy the Stair sketch on Bloom filters, CM sketches, and CU sketches as case studies. Experiment results show that our approach outperforms state-of-the-art algorithms by more than 5× in accuracy while providing comparable efficiency. The source code of the Stair sketch is available at GitHub.}
}


@inproceedings{DBLP:conf/icde/LiLZLYZLW22,
	author = {Xiuxing Li and
                  Zhenyu Li and
                  Zhengyan Zhang and
                  Ning Liu and
                  Haitao Yuan and
                  Wei Zhang and
                  Zhiyuan Liu and
                  Jianyong Wang},
	title = {Effective Few-Shot Named Entity Linking by Meta-Learning},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {178--191},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00018},
	doi = {10.1109/ICDE53745.2022.00018},
	timestamp = {Sat, 20 Apr 2024 10:27:38 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LiLZLYZLW22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Entity linking aims to link ambiguous mentions to their corresponding entities in a knowledge base, which is significant and fundamental for various downstream applications, e.g., knowledge base completion, question answering, and information extraction. While great efforts have been devoted to this task, most of these studies follow the assumption that large-scale labeled data is available. However, when the labeled data is insufficient for specific domains due to labor-intensive annotation work, the performance of existing algorithms will suffer an intolerable decline. In this paper, we endeavor to solve the problem of few-shot entity linking, which only requires a minimal amount of in-domain labeled data and is more practical in real situations. Specifically, we firstly propose a novel weak supervision strategy to generate non-trivial synthetic entity-mention pairs based on mention rewriting. Since the quality of the synthetic data has a critical impact on effective model training, we further design a meta-learning mechanism to assign different weights to each synthetic entity-mention pair automatically. Through this way, we can profoundly exploit rich and precious semantic information to derive a well-trained entity linking model under the few-shot setting. The experiments on real-world datasets show that the proposed method can extensively improve the state-of-the-art few-shot entity linking model and achieve impressive performance when only a small amount of labeled data is available. Moreover, we also demonstrate the outstanding ability of the model's transferability. Our code and models will be open-sourced.}
}


@inproceedings{DBLP:conf/icde/PengOZYL22,
	author = {Peng Peng and
                  M. Tamer {\"{O}}zsu and
                  Lei Zou and
                  Cen Yan and
                  Chengjun Liu},
	title = {{MPC:} Minimum Property-Cut {RDF} Graph Partitioning},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {192--204},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00019},
	doi = {10.1109/ICDE53745.2022.00019},
	timestamp = {Tue, 21 Mar 2023 20:50:57 +0100},
	biburl = {https://dblp.org/rec/conf/icde/PengOZYL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Scaling-out RDF processing to deal with graph size usually requires partitioning the RDF graph. Typical partitioning approaches minimize edge-cuts or vertex-cuts. In this paper we argue that these approaches do not avoid or reduce joins between different partitions (i.e., inter-partition join), and propose an approach based on minimizing the number of distinct crossing properties, which we call Minimum Property-Cut (MPC). This approach enables more queries to be independently evaluated without inter-partition join. However, the minimum property-cut partitioning is a NP-hard problem and we propose a heuristic greedy algorithm to address that. Extensive experiments over a variety of synthetic and real RDF graphs show that the proposed technique can significantly avoid joins and results in good performance.}
}


@inproceedings{DBLP:conf/icde/HuiYCK22,
	author = {Bo Hui and
                  Da Yan and
                  Haiquan Chen and
                  Wei{-}Shinn Ku},
	title = {Time-sensitive {POI} Recommendation by Tensor Completion with Side
                  Information},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {205--217},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00020},
	doi = {10.1109/ICDE53745.2022.00020},
	timestamp = {Fri, 06 Oct 2023 08:56:41 +0200},
	biburl = {https://dblp.org/rec/conf/icde/HuiYCK22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Context has been recognized as an important factor to consider in personalized recommender systems. Particularly in location-based services (LBSs), a fundamental task is to recommend to a mobile user where he/she could be interested to visit next at the right time. Additionally, location-based social networks (LBSNs) allow users to share location-embedded information with friends who often co-occur in the same or nearby points-of-interest (POIs) or share similar POI visiting histories, due to the social homophily theory and Tobler's first law of geography. So, both the time information and LBSN friendship relations should be utilized for POI recommendation. Tensor completion has recently gained some attention in time-aware recommender systems. The problem decomposes a user-item-time tensor into low-rank embedding matrices of users, items and times using its observed entries, so that the underlying low-rank subspace structure can be tracked to fill the missing entries for time-aware recommendation. However, these tensor completion methods ignore the social-spatial context information available in LBSNs, which is important for POI recommendation since people tend to share their preferences with their friends, and near things are more related than distant things. In this paper, we utilize the side information of social networks and POI locations to enhance the tensor completion model paradigm for more effective time-aware POI recommendation. Specifically, we propose a regularization loss head based on a novel social Hausdorff distance function to optimize the reconstructed tensor. We also quantify the popularity of different POIs with location entropy to prevent very popular POIs from being over-represented hence suppressing the appearance of other more diverse POIs. To address the sensitivity of negative sampling, we train the model on the whole data by treating all unlabeled entries in the observed tensor as negative, and rewriting the loss function in a smart way to reduce the computational cost. Through extensive experiments on real datasets, we demonstrate the superiority of our model over state-of-the-art tensor completion methods.}
}


@inproceedings{DBLP:conf/icde/EsfahaniSTW22,
	author = {Fatemeh Esfahani and
                  Venkatesh Srinivasan and
                  Alex Thomo and
                  Kui Wu},
	title = {Nucleus Decomposition in Probabilistic Graphs: Hardness and Algorithms},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {218--231},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00021},
	doi = {10.1109/ICDE53745.2022.00021},
	timestamp = {Fri, 05 Aug 2022 16:24:01 +0200},
	biburl = {https://dblp.org/rec/conf/icde/EsfahaniSTW22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Finding dense components in graphs is of great importance in analysing the structure of networks. Popular frameworks for discovering dense subgraphs are core and truss decompositions. Recently, Sarıyüce et al. introduced nucleus decomposition, which uses\nr\n-cliques contained in\ns\n-eliques, where\ns>r\n, as the basis for defining dense subgraphs. Nucleus decomposition can reveal interesting subgraphs that can be missed by core and truss decompositions. In this paper, we present nucleus decomposition in probabilistic graphs. The major questions we address are: How to define meaningfully nucleus decomposition in probabilistic graphs? How hard is computing nucleus decomposition in probabilistic graphs? Can we devise efficient algorithms for exact or approximate nucleus decomposition in large graphs? We present three natural definitions of nucleus decomposition in probabilistic graphs: local, global, and weakly-global. We show that the local version is in PTIME, whereas global and weakly-global are #P-hard and NP-hard, respectively. We present an efficient and exact dynamic programming approach for the local case. Further, we present statistical approximations that can scale to bigger datasets without much loss of accuracy. For global and weakly-global decompositions we complement our intractability results by proposing efficient algorithms that give approximate solutions based on search space pruning and Monte-Carlo sampling. Extensive experiments show the scalability and efficiency of our algorithms. Compared to probabilistic core and truss decompositions, nucleus decomposition significantly outperforms in terms of density and clustering metrics.}
}


@inproceedings{DBLP:conf/icde/XiaoWLZ22,
	author = {Guorui Xiao and
                  Jin Wang and
                  Chunbin Lin and
                  Carlo Zaniolo},
	title = {Highly Efficient String Similarity Search and Join over Compressed
                  Indexes},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {232--244},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00022},
	doi = {10.1109/ICDE53745.2022.00022},
	timestamp = {Fri, 05 Aug 2022 16:24:02 +0200},
	biburl = {https://dblp.org/rec/conf/icde/XiaoWLZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {String similarity search and join are essential op-erations in many fields. Existing solutions adopt a filter-and-verification framework and build inverted indexes based on generated signatures to prune dissimilar candidates. While existing solutions mainly focus on improving the query processing performance, little attention is paid to reducing the inverted indexes' memory consumption. In cases where the index size is larger than the memory, users have to employ more expensive disk-based algorithms rather than in-memory ones. In this paper, we propose a flexible framework CSS to reduce the index size and keep high query performance for string search and join applications. It can be easily incorporated into a broad scope of existing frameworks. We first give improved solutions for offline inverted lists construction to better support string similarity search. Nevertheless, they cannot be applied in the problem of string similarity join where indexes are constructed online. To address this issue, we further propose the first approach for online construction of compressed inverted lists. We theoretically study a benefit model to help find the best trade-off between memory consumption and execution time, and then propose an adaptive compression approach based on it. Experimental results on large-scale datasets demonstrate that CSS can reduce the memory consumption by 3 to 5 times while having similar or even better query processing performance for a variety of string similarity search and join frameworks.}
}


@inproceedings{DBLP:conf/icde/WangZQWZL22,
	author = {Hanchen Wang and
                  Ying Zhang and
                  Lu Qin and
                  Wei Wang and
                  Wenjie Zhang and
                  Xuemin Lin},
	title = {Reinforcement Learning Based Query Vertex Ordering Model for Subgraph
                  Matching},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {245--258},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00023},
	doi = {10.1109/ICDE53745.2022.00023},
	timestamp = {Mon, 29 Jul 2024 16:18:15 +0200},
	biburl = {https://dblp.org/rec/conf/icde/WangZQWZL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Subgraph matching is a fundamental problem in various fields that use graph structured data. Subgraph matching algorithms enumerate all isomorphic embeddings of a query graph\nq\nin a data graph G. An important branch of matching algorithms exploit the backtracking search approach which recursively extends intermediate results following a matching order of query vertices. It has been shown that the matching order plays a critical role in time efficiency of these backtracking based subgraph matching algorithms. In recent years, many advanced techniques for query vertex ordering (i.e., matching order generation) have been proposed to reduce the unpromising intermediate results according to the preset heuristic rules. In this paper, for the first time we apply the Reinforcement Learning (RL) and Graph Neural Networks (GNNs) techniques to generate the high-quality matching order for subgraph matching algorithms. Instead of using the fixed heuristics to generate the matching order, our model could capture and make full use of the graph information, and thus determine the query vertex order with the adaptive learning-based rule that could significantly reduces the number of redundant enumerations. With the help of the reinforcement learning framework, our model is able to consider the long-term benefits rather than only consider the local information at current ordering step. Extensive experiments on six real-life data graphs demonstrate that our proposed matching order generation technique could reduce up to two orders of magnitude of query processing time compared to the state-of-the-art algorithms.}
}


@inproceedings{DBLP:conf/icde/PanLZDTW22,
	author = {Minjia Pan and
                  Rong{-}Hua Li and
                  Qi Zhang and
                  Yongheng Dai and
                  Qun Tian and
                  Guoren Wang},
	title = {Fairness-aware Maximal Clique Enumeration},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {259--271},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00024},
	doi = {10.1109/ICDE53745.2022.00024},
	timestamp = {Sat, 22 Apr 2023 19:56:09 +0200},
	biburl = {https://dblp.org/rec/conf/icde/PanLZDTW22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cohesive sub graph mining on attributed graphs is a fundamental problem in graph data analysis. Existing cohesive sub graph mining algorithms on attributed graphs do not consider the fairness of attributes in the subgraph. In this paper, we for the first time introduce fairness into the widely-used clique model to mine fairness-aware cohesive subgraphs. In particular, we propose two novel fairness-aware maximal clique models on attributed graphs, called weak fair clique and strong fair clique respectively. To enumerate all weak fair cliques, we develop an efficient backtracking algorithm called WFCEnum equipped with a novel colorful k-core based pruning technique. We also propose an efficient enumeration algorithm called SFCEnum to find all strong fair cliques based on a new attribute-alternatively-selection search technique. To further improve the efficiency, we also present several non-trivial ordering techniques for both weak and strong fair clique enumeration. The results of extensive experiments on four real-world graphs demonstrate the efficiency and effectiveness of the proposed algorithms.}
}


@inproceedings{DBLP:conf/icde/PacaciBO22,
	author = {Anil Pacaci and
                  Angela Bonifati and
                  M. Tamer {\"{O}}zsu},
	title = {Evaluating Complex Queries on Streaming Graphs},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {272--285},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00025},
	doi = {10.1109/ICDE53745.2022.00025},
	timestamp = {Tue, 21 Mar 2023 20:50:58 +0100},
	biburl = {https://dblp.org/rec/conf/icde/PacaciBO22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We study the problem of evaluating persistent queries over streaming graphs in a principled fashion. These queries need to be evaluated over unbounded and very high speed graph streams. We define a streaming graph data model and query model incorporating navigational queries, subgraph queries and paths as first-class citizens. To support this full-fledged query model we develop a streaming graph algebra that describes the precise semantics of persistent graph queries with their complex constructs. We present transformation rules and describe query formulation and plan generation for persistent graph queries over streaming graphs. Our implementation of a streaming graph query processor shows the feasibility of our approach and allows us to gauge the high performance gains obtained for query processing over streaming graphs.}
}


@inproceedings{DBLP:conf/icde/XiaoYTMW22,
	author = {Renjie Xiao and
                  Yong'an Yuan and
                  Zijing Tan and
                  Shuai Ma and
                  Wei Wang},
	title = {Dynamic Functional Dependency Discovery with Dynamic Hitting Set Enumeration},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {286--298},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00026},
	doi = {10.1109/ICDE53745.2022.00026},
	timestamp = {Tue, 21 Mar 2023 20:50:56 +0100},
	biburl = {https://dblp.org/rec/conf/icde/XiaoYTMW22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Functional dependencies (FDs) are widely applied in data management tasks. Since FDs on data are usually unknown, FD discovery techniques are studied for automatically finding hidden FDs from data. In this paper, we develop techniques to dynamically discover FDs in response to changes on data. Formally, given the complete set \\Sigma\nof minimal and valid FDs on a relational instance r\n, we aim to find the complete set \\Sigma^{\\prime}\nof minimal and valid FDs on r\\oplus\\Delta r\n, where \\Delta r\nis a set of tuple insertions and deletions. Different from the batch approaches that compute \\Sigma^{\\prime}\non r\\oplus\\Delta r\nfrom scratch, our dynamic method computes \\Sigma^{\\prime}\nin response to \\triangle\\uparrow\n. by leveraging the known \\Sigma\non r\n, and avoids processing the whole of r\nfor each update from \\Delta r\n. We tackle dynamic FD discovery on r\\oplus\\Delta r\nby dynamic hitting set enumeration on the difference-set of r\\oplus\\Delta r\n. Specifically, (1) leveraging auxiliary structures built on r\n, we first present an efficient algorithm to update the difference-set of r\nto that of r\\oplus\\Delta r\n. (2) We then compute \\Sigma^{\\prime}\n, by recasting dynamic FD discovery as dynamic hitting set enumeration on the difference-set of r\\oplus\\Delta r\nand developing novel techniques for dynamic hitting set enumeration. (3) We finally experimentally verify the effectiveness and efficiency of our approaches, using real-life and synthetic data. The results show that our dynamic FD discovery method outperforms the batch counterparts on most tested data, even when \\Delta r\nis up to 30 % of r\n.}
}


@inproceedings{DBLP:conf/icde/ChenYWBSK22,
	author = {Yankai Chen and
                  Yaming Yang and
                  Yujing Wang and
                  Jing Bai and
                  Xiangchen Song and
                  Irwin King},
	title = {Attentive Knowledge-aware Graph Convolutional Networks with Collaborative
                  Guidance for Personalized Recommendation},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {299--311},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00027},
	doi = {10.1109/ICDE53745.2022.00027},
	timestamp = {Mon, 26 Jun 2023 20:41:55 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ChenYWBSK22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {To alleviate data sparsity and cold-start problems of traditional recommender systems (RSs), incorporating knowledge graphs (KGs) to supplement auxiliary information has attracted considerable attention recently. However, simply integrating KGs in current KG-based RS models is not necessarily a guarantee to improve the recommendation performance, which may even weaken the holistic model capability. This is because the construction of these KGs is independent of the collection of historical user-item interactions; hence, information in these KGs may not always be helpful for recommendation to all users. In this paper, we propose attentive Knowledge-aware Graph convolutional networks with Collaborative Guidance for personalized Recommendation (CG-KGR). CG-KGR is a novel knowledge-aware recommendation model that enables ample and coherent learning of KGs and user-item interactions, via our proposed Collaborative Guidance Mechanism. Specifically, CG-KGR first encapsulates historical interactions to interactive information summarization. Then CG-KGR utilizes it as guidance to extract information out of KGs, which eventually provides more precise personalized recommendation. We conduct extensive experiments on four real-world datasets over two recommendation tasks, i.e., Top-K recommendation and Click-Through rate (CTR) prediction. The experimental results show that the CG-KGR model significantly outperforms recent state-of-the-art models by 1.4-27.0% in terms of Recall metric on Top-K recommendation.}
}


@inproceedings{DBLP:conf/icde/ZhuLYWXHL22,
	author = {Huaijie Zhu and
                  Wei Liu and
                  Jian Yin and
                  Mengxiang Wang and
                  Jianliang Xu and
                  Xin Huang and
                  Wang{-}Chien Lee},
	title = {Continuous Geo-Social Group Monitoring over Moving Users},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {312--324},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00028},
	doi = {10.1109/ICDE53745.2022.00028},
	timestamp = {Thu, 15 Dec 2022 10:00:37 +0100},
	biburl = {https://dblp.org/rec/conf/icde/ZhuLYWXHL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recently a lot of research works have focused on geo-social group queries for group-based activity planning and scheduling in location-based social networks (LBSNs), which return a social cohesive user group with a spatial constraint. However, existing studies on geo-social group queries assume the users are stationary whereas in real LBSN applications all users may continuously move over time. Thus, in this paper we in-vestigate the problem of continuous geo-social groups monitoring (CGSGM) over moving users. A challenge in answering CGSGM queries over moving users is how to efficiently update geo-social groups when users are continuously moving. To address the CGSGM problem, we first propose a baseline algorithm, namely Baseline-BB, which recomputes the new geo-social groups from scratch at each time instance by utilizing a branch and bound (BB) strategy. To improve the inefficiency of BB, we propose a new strategy, called common neighbor or neighbor expanding (CNNE), which expands the common neighbors of edges or the neighbors of users in intermediate groups to quickly produce the valid group combinations. Based on CNNE, we propose another baseline algorithm, namely Baseline-CNNE. As these baseline algorithms do not maintain any intermediate results to facilitate further query processing, we develop an incremental algorithm, called incremental monitoring algorithm (IMA), which maintains the support, common neighbors and the neighbors of current users when exploring possible user groups for further updates and query processing. Finally, we conduct extensive experiments using three real datasets to validate our ideas and evaluate the proposed algorithms,}
}


@inproceedings{DBLP:conf/icde/ChenCZFWLF22,
	author = {Xuefeng Chen and
                  Xin Cao and
                  Yifeng Zeng and
                  Yixiang Fang and
                  Sibo Wang and
                  Xuemin Lin and
                  Liang Feng},
	title = {Constrained Path Search with Submodular Function Maximization},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {325--337},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00029},
	doi = {10.1109/ICDE53745.2022.00029},
	timestamp = {Tue, 05 Mar 2024 16:17:01 +0100},
	biburl = {https://dblp.org/rec/conf/icde/ChenCZFWLF22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we study the problem of constrained path search with submodular function maximization (CPS-SM). We aim to find the path with the best submodular function score under a given constraint (e.g., a length limit), where the submodular function score is computed over the set of nodes in this path. This problem can be used in many applications. For example, tourists may want to search the most diversified path (e.g., a path passing by the most diverse facilities such as parks and museums) given that the traveling time is less than 6 hours. We show that the CPS-SM problem is NP-hard. We first propose a concept called “submodular\nα\n-dominance” by utilizing the submodular function properties, and we develop an algorithm with a guaranteed error bound based on this concept. By relaxing the submodular\nα\n-dominance conditions, we design another more efficient algorithm that has the same error bound. We also utilize the way of bi-directional path search to further improve the efficiency of the algorithms. We finally propose a heuristic algorithm that is efficient yet effective in practice. The experiments conducted on several real datasets show that our proposed algorithms can achieve high accuracy and are faster than one state-of-the-art method by orders of magnitude.}
}


@inproceedings{DBLP:conf/icde/XuLWK22,
	author = {Xiaoliang Xu and
                  Jun Liu and
                  Yuxiang Wang and
                  Xiangyu Ke},
	title = {Academic Expert Finding via {\textdollar}(k, {\textbackslash}mathcal\{P\}){\textdollar}-Core
                  based Embedding over Heterogeneous Graphs},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {338--351},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00030},
	doi = {10.1109/ICDE53745.2022.00030},
	timestamp = {Mon, 05 Feb 2024 20:31:12 +0100},
	biburl = {https://dblp.org/rec/conf/icde/XuLWK22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Finding relevant experts in specified areas is often crucial for a wide range of applications in both academia and industry. Given a user input query and a large amount of academic knowledge (e.g., academic papers), expert finding aims to find and rank the experts who are most relevant to the given query, from the academic knowledge. Existing studies mainly focus on the embedding-based solutions that (1) consider academic papers' textual semantic similarities to a given query through document representation models and (2) extract the \\mathbf{top-}n\nexperts with the greatest similarities. Beyond the implicit textual semantics of papers, however, the papers' explicit relationships (e.g., co-authorship, citation, and same-topic relationship) in a heterogeneous academic graph (e.g., DBLP) are critical for document representation, insofar as they help improve the expert finding quality. Despite their importance, the explicit relationships of papers generally have been ignored in the literature. In this paper, we study the academic expert finding on heterogeneous graphs by considering the explicit relationships besides the implicit textual semantics of papers in one representation model. Specifically, we first define the (k,\\mathcal{P})\n-core to denote a cohesive community of papers that are closely connected via a meta-path \\mathcal{P}(\\mathcal{P}\nindicates the different relationships of papers). We then propose an offline (k,\\mathcal{P})\n-core based document embedding model to capture papers' various explicit relationships for representation. Moreover, by using papers' embeddings, we present an online threshold algorithm (TA)-based method to efficiently return top-n experts via a carefully designed proximity graph-based index (PG-Index). We extend our approach to support multiple relationships simultaneously for representation. Extensive experiments over real-world datasets demonstrate the effectiveness and efficiency of our approach.}
}


@inproceedings{DBLP:conf/icde/XuCHTHLCL22,
	author = {Jin Xu and
                  Mingjian Chen and
                  Jianqiang Huang and
                  Xingyuan Tang and
                  Ke Hu and
                  Jian Li and
                  Jia Cheng and
                  Jun Lei},
	title = {AutoHEnsGNN: Winning Solution to AutoGraph Challenge for {KDD} Cup
                  2020},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {352--366},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00031},
	doi = {10.1109/ICDE53745.2022.00031},
	timestamp = {Sat, 20 May 2023 23:28:06 +0200},
	biburl = {https://dblp.org/rec/conf/icde/XuCHTHLCL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graph Neural Networks (GNNs) have become increasingly popular and achieved impressive results in many graph-based applications. However, extensive manual work and domain knowledge are required to design effective architectures, and the results of GNN models have high variance with different training setups, which limits the application of existing GNN models. In this paper, we present AutoHEnsGNN, a framework to build effective and robust models for graph tasks without any human intervention. AutoHEnsGNN won first place in the AutoGraph Challenge for KDD Cup 2020, and achieved the best rank score of five real-life datasets in the final phase. Given a task, AutoHEnsGNN first applies a fast proxy evaluation to automatically select a pool of promising GNN models. Then it builds a hierarchical ensemble framework: 1) We propose graph self-ensemble (GSE), which can reduce the variance of weight initialization and efficiently exploit the information of local and global neighborhoods; 2) Based on GSE, a weighted ensemble of different types of GNN models is used to effectively learn more discriminative node representations. To efficiently search the architectures and ensemble weights, we propose AutoHEnsGNN Gradient , which treats the architectures and ensemble weights as architecture parameters and uses gradient-based architecture search to obtain optimal configurations, and AutoHEnsGNN Adaptive , which can adaptively adjust the ensemble weight based on the model accuracy. Extensive experiments on node classification, graph classification, edge prediction and KDD Cup challenge demonstrate the effectiveness and generality of AutoHEnsGNN.}
}


@inproceedings{DBLP:conf/icde/WangYZZLW22,
	author = {Yishu Wang and
                  Ye Yuan and
                  Wenjie Zhang and
                  Yi Zhang and
                  Xuemin Lin and
                  Guoren Wang},
	title = {Reachability-Driven Influence Maximization in Time-dependent Road-social
                  Networks},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {367--379},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00032},
	doi = {10.1109/ICDE53745.2022.00032},
	timestamp = {Mon, 04 Dec 2023 13:56:31 +0100},
	biburl = {https://dblp.org/rec/conf/icde/WangYZZLW22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The influence maximization in a social network has been extensively studied, however, existing works have neglected the fact that time-dependent reachable information plays an important role in this query processing. Many real-world applications, such as location-based recommendations, location-based advertisements, and location-based emergency message distribution, require such a query. In this paper, we formally define reachability-driven influence maximization (RDIM) in time-dependent road-social networks, to find a seed set that maximizes the expected influence over potential users, i.e., target users, who are likely to reach a given location within a deadline. To efficiently compute the influence diffusion, we define a versatile influence (VI) diffusion model based on user relationships and time-dependent location information. The RDIM has two critical challenges: identifying the target users and finding the seed nodes. We propose a TS-index with temporal and regional dimensions for identifying the target users by employing a reachable region. To find seed nodes, we construct a CTS-index by extending a community dimension into the TS-index to enhance the calculation of social influence by using the relationship between communities and the reachable region. Finally, we use the real road and social network data to empirically verify the efficiency and effectiveness of our solutions.}
}


@inproceedings{DBLP:conf/icde/ZhangLPDWY22,
	author = {Qi Zhang and
                  Rong{-}Hua Li and
                  Minjia Pan and
                  Yongheng Dai and
                  Guoren Wang and
                  Ye Yuan},
	title = {Efficient Top-k Ego-Betweenness Search},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {380--392},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00033},
	doi = {10.1109/ICDE53745.2022.00033},
	timestamp = {Sat, 22 Apr 2023 19:56:09 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhangLPDWY22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Betweenness centrality, measured by the number of times a vertex occurs on all shortest paths of a graph, has been recognized as a key indicator for the importance of a vertex in the network. However, the betweenness of a vertex is often very hard to compute because it needs to explore all the shortest paths between the other vertices. Recently, a relaxed concept called ego-betweenness was introduced which focuses on computing the betweenness of a vertex in its ego network. In this work, we study a problem of finding the top-k vertices with the highest ego-betweennesses. We first develop two novel search algorithms equipped with a basic upper bound and a dynamic upper bound to efficiently solve this problem. Then, we propose local-update and lazy-update solutions to maintain the ego-betweennesses for all vertices and the top-k results when the graph is updated by an edge insertion and deletion, respectively. In addition, we also present two efficient parallel algorithms to further improve the efficiency. The results of extensive experiments on five large real-life datasets demonstrate the efficiency, scalability, and effectiveness of our algorithms.}
}


@inproceedings{DBLP:conf/icde/CaiZOWY22,
	author = {Qingpeng Cai and
                  Kaiping Zheng and
                  Beng Chin Ooi and
                  Wei Wang and
                  Chang Yao},
	title = {{ELDA:} Learning Explicit Dual-Interactions for Healthcare Analytics},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {393--406},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00034},
	doi = {10.1109/ICDE53745.2022.00034},
	timestamp = {Sat, 30 Sep 2023 09:44:49 +0200},
	biburl = {https://dblp.org/rec/conf/icde/CaiZOWY22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Interaction learning plays an essential role in learning patients' comprehensive representations that contribute to improved performance in many analytical tasks. In healthcare, interactions among medical features (i.e., feature-level interactions) can exhibit different abnormal patterns in detail, while interactions among time steps (i.e., time-level interactions) can indicate the dynamic changes in patients' health conditions. Therefore, it is necessary to capture and analyze both types of interactions when conducting healthcare analytics, In this paper, we propose a general framework ELDA that is supported by the novel model ELDA-Net to learn dual-interactions for healthcare analytics in an explicit manner. Specifically, we devise a Feature-level Interaction Learning Module that can enrich a separately processed medical feature by learned interactions among medical features, and a Time-level Interaction Learning Module that can enhance the representations of the patients' health conditions by learned interactions among time steps. In both levels, ELDA can provide explicit and intuitive interpretations via explaining through the designed attention mechanism. Further, to facilitate the feature-level interaction learning, we propose a novel Bi-directional Embedding Module in ELDA-Net which can efficiently embed the medical features recorded in numerical values. We evaluate the effectiveness and interpretability of ELDA over two public real-world clinical datasets. The experimental results confirm that ELDA consistently outperforms existing state-of-the-art methods with a significant margin, and supports fine-grained interpretability in both the feature level and the time level with medical insights.}
}


@inproceedings{DBLP:conf/icde/DuanYH22,
	author = {Jiawei Duan and
                  Qingqing Ye and
                  Haibo Hu},
	title = {Utility Analysis and Enhancement of {LDP} Mechanisms in High-Dimensional
                  Space},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {407--419},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00035},
	doi = {10.1109/ICDE53745.2022.00035},
	timestamp = {Sat, 30 Sep 2023 09:44:50 +0200},
	biburl = {https://dblp.org/rec/conf/icde/DuanYH22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Local differential privacy (LDP), which perturbs each user's data locally and only sends the noisy version of her information to the aggregator, is a popular privacy-preserving data collection mechanism. In LDP, the data collector could obtain accurate statistics without access to original data, thus guaranteeing users' privacy. However, a primary drawback of LDP is its disappointing utility in high-dimensional space. Although various LDP schemes have been proposed to reduce perturbation, they share the same and naive aggregation mechanism at the collector's side. In this paper, we first bring forward an analytical framework to generally measure the utilities of LDP mechanisms in high-dimensional space, which can benchmark existing and future LDP mechanisms without conducting any experiment. Based on this, the framework further reveals that the naive aggregation is sub-optimal in high-dimensional space, and there is much room for improvement. Motivated by this, we present a re-calibration protocol HDR4ME for high-dimensional mean estimation, which improves the utilities of existing LDP mechanisms without making any change to them. Both theoretical analysis and extensive experiments confirm the generality and effectiveness of our framework and protocol.}
}


@inproceedings{DBLP:conf/icde/QuLZCSQZ22,
	author = {Luyi Qu and
                  Yuming Li and
                  Rong Zhang and
                  Ting Chen and
                  Ke Shu and
                  Weining Qian and
                  Aoying Zhou},
	title = {Application-Oriented Workload Generation for Transactional Database
                  Performance Evaluation},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {420--432},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00036},
	doi = {10.1109/ICDE53745.2022.00036},
	timestamp = {Fri, 05 Aug 2022 16:24:03 +0200},
	biburl = {https://dblp.org/rec/conf/icde/QuLZCSQZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Generating synthetic workloads is essential and critical to performance evaluation of database systems. When evaluating database performance for a specific application, the similarity between synthetic workloads and real application workloads determines the credibility of the evaluation results. However, it meets a great challenge to catch workload characteristics with respect to a target application considering the complexity of transaction executions. To address this problem, we propose a workload duplicator (Lauca) that can generate synthetic workloads with highly similar performance metrics compared to the real workloads of a specific application. By carefully studying the application-oriented workload generation problem, we present Transaction Logic and Data Access Distribution to characterize workloads of online transaction processing (OLTP) applications, and propose novel generation algorithms to guarantee the high fidelity of synthetic workloads. To the best of our knowledge, Lauca is the first application-oriented transactional workload generator. We conduct extensive experiments based on TPCC, SmallBank and YCSB on both centralized and distributed databases. The experimental results show that Lauca consistently generates high quality synthetic workloads.}
}


@inproceedings{DBLP:conf/icde/WangC22,
	author = {Yufei Wang and
                  Xiang Cheng},
	title = {{PRISM:} Prefix-Sum based Range Queries Processing Method under Local
                  Differential Privacy},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {433--445},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00037},
	doi = {10.1109/ICDE53745.2022.00037},
	timestamp = {Sun, 19 Mar 2023 00:06:00 +0100},
	biburl = {https://dblp.org/rec/conf/icde/WangC22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Range query over data cubes is a powerful tool for online analytical processing (OLAP). In this paper, we focus on answering range queries while satisfying local differential privacy (LDP). The key technical challenges come from the problem of noise aggregation and the curse of high dimensionality: multiple LDP noise will be aggregated when answering range queries and collecting high-dimensional data under LDP will further degrade the utility of the results. To this end, we present a novel method called Prefix-Sum based Range QuerIes ProceSsing Method (PRISM). Its main idea is to selectively collect a few prefix-sums in a data-dependent way, and answer range queries over prefix-sum-based cubes based on which any range query can be processed by using constant pieces of prefix-sums. In PRISM, we first alleviate the problem of noise aggregation by proposing a LDP mechanism called Range based Randomized Response (RRR) and a new type of prefix-sums-based cube called Grained Prefix-Sum (GPS) cube. We then alleviate the curse of high dimensionality by proposing a Data-Dependent Selective Prefix-Sum Collection Strategy (DELFT). We conduct experiments on both real-world datasets and synthetic datasets. Experimental results confirm the effectiveness of PRISM over existing methods.}
}


@inproceedings{DBLP:conf/icde/HeWZLZ22,
	author = {Yizhang He and
                  Kai Wang and
                  Wenjie Zhang and
                  Xuemin Lin and
                  Ying Zhang},
	title = {Efficient Reinforcement of Bipartite Networks at Billion Scale},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {446--458},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00038},
	doi = {10.1109/ICDE53745.2022.00038},
	timestamp = {Mon, 05 Feb 2024 20:31:13 +0100},
	biburl = {https://dblp.org/rec/conf/icde/HeWZLZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Bipartite networks, which model relationships between two different types of entities, are prevalent in many real-world applications. On bipartite networks, the cascading node departure undermines the networks' ability to provide sustainable services, which makes reinforcing bipartite networks a vital problem. Although network reinforcement is extensively studied on unipartite networks, it remains largely unexplored on bipartite graphs. On bipartite networks, (\nα,β\n) -core is a stable structure that ensures different minimum engagement levels of the vertices from different layers, and we aim to reinforce bipartite networks by maximizing the (\nα,β\n) -core. Specifically, given a bipartite network\nG\n, degree constraints\nα\nand\nβ\n, budgets\nb\n1\nand\nb\n2\n, we aim to find\nb\n1\nupper layer vertices and\nb\n2\nlower layer vertices as anchors and bring them into the (\nα,β\n) -core s.t. the number of non-anchor vertices entering in the (\nα,β\n) -core is maximized. We prove the problem is NP-hard and propose a heuristic algorithm FILVER to solve the problem. FILVER runs\nb\n1\n+\nb\n2\niterations and choose the best anchor in each iteration. Under a filter-verification framework, it reduces the pool of candidate anchors (in the filter stage) and computes the resulting (\nα,β\n) - core for each anchor vertex more efficiently (in the verification stage). In addition, filter-stage optimizations are proposed to further reduce “dominated” anchors and allow computation-sharing across iterations. To optimize the verification stage, we explore the cumulative effect of placing multiple anchors, which effectively reduces the number of running iterations. Extensive experiments on 18 real-world datasets and a billion-scale synthetic dataset validate the effectiveness and efficiency of our proposed techniques.}
}


@inproceedings{DBLP:conf/icde/WangLPYHWT22,
	author = {Yu Wang and
                  Chi Harold Liu and
                  Chengzhe Piao and
                  Ye Yuan and
                  Rui Han and
                  Guoren Wang and
                  Jian Tang},
	title = {Human-Drone Collaborative Spatial Crowdsourcing by Memory-Augmented
                  and Distributed Multi-Agent Deep Reinforcement Learning},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {459--471},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00039},
	doi = {10.1109/ICDE53745.2022.00039},
	timestamp = {Mon, 06 Feb 2023 18:00:22 +0100},
	biburl = {https://dblp.org/rec/conf/icde/WangLPYHWT22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Spatial crowdsourcing (SC) has been proved quite successful by employing human participants to achieve certain tasks like Uber and Gigwalk. Meanwhile, with the fast devel-opment of unmanned aerial vehicles (e.g., drones), they have become a new source of data collectors equipped with a variety of different sensors. In this paper, we propose a novel SC scenario, enabling human participants to work collaboratively with drones in the presence of multiple charging stations to achieve certain data collection tasks, like videography and surveillance. We propose a novel deep reinforcement learning (D RL) framework called “FD- MAPPO (Cubic Map)”, which consists of a fully de-centralized multi-agent DRL (MADRL) algorithm called “Fully Decentralized Multi-Agent Proximal Policy Optimization (FD-MAPPO)”, and a spatiotemporal memory augmented neural network with novel cubic writing and spatially contextual reading mechanisms called “Cubic Map”. Cubic Map extracts long-term spatiotemporal features, navigates drones to accurately locate the position of the target, i.e., charging stations or sensors. Extensive results on two real datasets of KAIST and NCSU campuses show that FD- MAPPO (Cubic Map) consistently outperforms six other baselines in terms of efficiency.}
}


@inproceedings{DBLP:conf/icde/LeeKS22,
	author = {Kyuhan Lee and
                  Jihoon Ko and
                  Kijung Shin},
	title = {{SLUGGER:} Lossless Hierarchical Summarization of Massive Graphs},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {472--484},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00040},
	doi = {10.1109/ICDE53745.2022.00040},
	timestamp = {Fri, 05 Aug 2022 16:24:03 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LeeKS22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Given a massive graph, how can we exploit its hierarchical structure for concisely but exactly summarizing the graph? By exploiting the structure, can we achieve better compression rates than state-of-the-art graph summarization methods? The explosive proliferation of the Web has accelerated the emergence of large graphs, such as online social networks and hyperlink networks. Consequently, graph compression has become increasingly important to process such large graphs without expensive I/O over the network or to disk. Among a number of approaches, graph summarization, which in essence combines similar nodes into a supernode and describe their connectivity concisely, protrudes with several advantages. However, we note that it fails to exploit pervasive hierarchical structures of real-world graphs as its underlying representation model enforces supernodes to be disjoint. In this work, we propose the hierarchical graph summarization model, which is an expressive graph representation model that includes the previous one proposed by Navlakha et al. as a special case. The new model represents an unweighted graph using positive and negative edges between hierarchical supernodes, each of which can contain others. Then, we propose Slugger, a scalable heuristic for concisely and exactly representing a given graph under our new model. Slugger greedily merges nodes into supernodes while maintaining and exploiting their hierarchy, which is later pruned. Slugger significantly accelerates this process by sampling, approximation, and memoization. Our experiments on 16 real-world graphs show that Slugger is (a) Effective: yielding up to 29.6% more concise summary than state-of-the-art lossless summarization methods, (b) Fast: summarizing a graph with 0.8 billion edges in a few hours, and (c) Scalable: scaling linearly with the number of edges in the input graph.}
}


@inproceedings{DBLP:conf/icde/LuoC22,
	author = {Chen Luo and
                  Michael J. Carey},
	title = {DynaHash: Efficient Data Rebalancing in Apache AsterixDB},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {485--497},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00041},
	doi = {10.1109/ICDE53745.2022.00041},
	timestamp = {Mon, 19 Dec 2022 20:39:08 +0100},
	biburl = {https://dblp.org/rec/conf/icde/LuoC22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Parallel shared-nothing data management systems have been widely used to exploit a cluster of machines for efficient and scalable data processing. When a cluster needs to be dynamically scaled in or out, data must be efficiently rebalanced. Ideally, data rebalancing should have a low data movement cost, incur a small overhead on data ingestion and query processing, and be performed online without blocking reads or writes. However, existing parallel data management systems often exhibit certain limitations and drawbacks in terms of efficient data rebalancing. In this paper, we introduce DynaHash, an efficient data rebalancing approach that combines dynamic bucketing with extendible hashing for shared-nothing OLAP-style parallel data management systems. DynaHash dynamically partitions the records into a number of buckets using extendible hashing to achieve good a load balance with small rebalancing costs. We further describe an end-to-end implementation of the proposed approach inside an open-source Big Data Management System (BDMS), Apache AsterixDB. Our implementation exploits the out-of-place update design of LSM-trees to efficiently rebalance data without blocking concurrent reads and writes. Finally, we have conducted performance experiments using the TPC-H benchmark and we present the results here.}
}


@inproceedings{DBLP:conf/icde/WangZLQZ22,
	author = {Kai Wang and
                  Wenjie Zhang and
                  Xuemin Lin and
                  Lu Qin and
                  Alexander Zhou},
	title = {Efficient Personalized Maximum Biclique Search},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {498--511},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00042},
	doi = {10.1109/ICDE53745.2022.00042},
	timestamp = {Sun, 06 Oct 2024 21:04:59 +0200},
	biburl = {https://dblp.org/rec/conf/icde/WangZLQZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Bipartite graphs are naturally used to model relationships between two different types of entities. On bipartite graphs, maximum biclique search is a fundamental problem that aims to find the complete bipartite subgraph (biclique) with the maximum number of edges and is widely adopted for many applications such as anomaly detection in E-commerce and social network analysis. However, maximum biclique search only identifies the biclique whose size is globally maximum, whereas fast microscopic (personalized) analysis is needed in many real-world scenarios. For instance, when a suspected user is identified in an E-commerce network (e.g., a user-product network), it is important to quickly find the anomalous group containing the user and send the group of users for further human expert investigation. To fill this research gap, for the first time, we study the efficient personalized maximum biclique search problem, which aims to find the maximum biclique containing a specific query vertex in real-time. Apart from online computation algorithms, we explore index-based approaches and propose the PMBC-Index. With the PMBC-Index, the query algorithm is up to five orders of magnitude faster than the baseline algorithms. Furthermore, effective pruning strategies and parallelization techniques are devised to support efficient index construction. Extensive experiments on 10 real-world graphs validate both the effectiveness and the efficiency of our proposed techniques.}
}


@inproceedings{DBLP:conf/icde/FengPZZL22,
	author = {Qingshuai Feng and
                  You Peng and
                  Wenjie Zhang and
                  Ying Zhang and
                  Xuemin Lin},
	title = {Towards Real-Time Counting Shortest Cycles on Dynamic Graphs: {A}
                  Hub Labeling Approach},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {512--524},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00043},
	doi = {10.1109/ICDE53745.2022.00043},
	timestamp = {Tue, 21 Mar 2023 20:50:56 +0100},
	biburl = {https://dblp.org/rec/conf/icde/FengPZZL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the ever-increasing prevalence of graph data in a wide spectrum of applications, it becomes essential to analyze structural trends in dynamic graphs on a continual basis. The shortest cycle is a fundamental pattern in graph analytics. In this paper, we investigate the problem of shortest cycle counting for a given vertex in dynamic graphs in light of its applicability to problems such as fraud detection. To address such queries efficiently, we propose a 2-hop labeling based algorithm called Counting Shortest Cycle (CSC for short). Additionally, techniques for dynamically updating the CSC index are explored. Comprehensive experiments are conducted to demonstrate the efficiency and effectiveness of our method. In particular, CSC enables query evaluation in a few hundreds of microseconds for graphs with millions of edges, and improves query efficiency by two orders of magnitude when compared to the baseline solutions. Also, the update algorithm could efficiently cope with edge insertions (deletions).}
}


@inproceedings{DBLP:conf/icde/YanWYGHZ22,
	author = {Hua Yan and
                  Shuai Wang and
                  Yu Yang and
                  Baoshen Guo and
                  Tian He and
                  Desheng Zhang},
	title = {{\textdollar}O{\^{}}\{2\}{\textdollar}-SiteRec: Store Site Recommendation
                  under the {O2O} Model via Multi-graph Attention Networks},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {525--538},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00044},
	doi = {10.1109/ICDE53745.2022.00044},
	timestamp = {Sun, 02 Oct 2022 16:04:37 +0200},
	biburl = {https://dblp.org/rec/conf/icde/YanWYGHZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The emergence of Online-to-Offline (O2O) stores based on delivery platforms (e.g., Uber Eats, DoorDash, and Eleme) provides great convenience to people's lives. In the O2O model, one of the essential problems for merchants is to select a suitable store site, i.e., store site recommendation problem. We argue that the existing works for the traditional brick-and-mortar stores cannot address this problem due to two unique factors in the O2O model including (i) dynamic supply caused by courier capacity and dispatching strategies and (ii) various customer demands caused by delivery distance and customer preferences. To incorporate these new factors, we design\nO\n2\nSiteRec, a store site recommendation method under the O2O model via multi-graph attention networks, which consists of (i) a courier capacity model based on a multi-semantic relation graph attention network to capture courier capacity; (ii) a heterogeneous multi-graph based recommendation model, where the courier capacity, customer preferences, and context features are fused. We evaluate our method based on one-month real-world data consisting of 39,465 stores and 23.6 million orders from one of the largest O2O platforms in China. Experimental results demonstrate that our method outperforms state-of-the-art baselines in various metrics.}
}


@inproceedings{DBLP:conf/icde/ZhangLSYS22,
	author = {Hanyuan Zhang and
                  Siqiang Luo and
                  Jieming Shi and
                  Jing Nathan Yan and
                  Weiwei Sun},
	title = {Example-based Spatial Search at Scale},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {539--551},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00045},
	doi = {10.1109/ICDE53745.2022.00045},
	timestamp = {Sun, 04 Aug 2024 19:37:46 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhangLSYS22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Searching spatial objects is a fundamental task in spatial services such as online maps. Traditional search methods are based on filtering conditions, burdening users to specify their requirements. This paper focuses on spatial search via examples. Particularly, the user can specify an example, which is a set of objects of interest, and the purpose is to find a list of results, each containing a set of objects with similar properties to the given example. We conducted a user study, showing that a search interface based on examples can effectively complement existing approaches. However, the existing example-based search is not scalable, hindering its applications to larger datasets. To address this challenge, we propose two new algorithms, namely HSP and LORA, to efficiently answer example-based spatial queries. HSP is an algorithm based on a hierarchical partitioning of the search space, and it achieves up to 20 times faster than the state-of-the-art algorithm. LORA further improves the efficiency, running up to 5000 times faster than the state-of-the-art algorithm. We present a systematic evaluation to demonstrate the efficacy of our algorithms.}
}


@inproceedings{DBLP:conf/icde/YuWZQZL22,
	author = {Yuanhang Yu and
                  Dong Wen and
                  Ying Zhang and
                  Lu Qin and
                  Wenjie Zhang and
                  Xuemin Lin},
	title = {GPU-accelerated Proximity Graph Approximate Nearest Neighbor Search
                  and Construction},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {552--564},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00046},
	doi = {10.1109/ICDE53745.2022.00046},
	timestamp = {Sun, 06 Oct 2024 21:04:59 +0200},
	biburl = {https://dblp.org/rec/conf/icde/YuWZQZL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The approximate nearest neighbor (ANN) search in high-dimensional space offers a wide spectrum of applications across many domains such as database, machine learning, multimedia and computer vision. A variety of ANN search algorithms have been proposed in the literature. In recent years, proximity graph-based approaches have attracted considerable attention from both industry and academic settings due to the superior search performance in terms of speed and accuracy. A recent work utilizes a graphics processing unit (GPU) to accelerate the ANN search on proximity graphs. Though significantly reducing the distance computation time by taking advantage of the massive parallelism of GPUs, the algorithm suffers from the high expenses of data structure operations. In this paper, we propose a novel GPU -accelerated algorithm that designs a novel GPU-friendly search framework on proximity graphs to fully exploit the massively parallel processing power of GPUs at key steps of the search. Also, we propose GPU-accelerated proximity graph construction algorithms which can build high-quality representative proximity graphs with efficient parallel implementations. Extensive experiments on benchmark high-dimensional datasets demonstrate the outstanding performance of our proposed algorithms in both ANN search and proximity graph construction.}
}


@inproceedings{DBLP:conf/icde/YangZWLZ22,
	author = {Zhong Yang and
                  Bolong Zheng and
                  Xianzhi Wang and
                  Guohui Li and
                  Xiaofang Zhou},
	title = {minIL: {A} Simple and Small Index for String Similarity Search with
                  Edit Distance},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {565--577},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00047},
	doi = {10.1109/ICDE53745.2022.00047},
	timestamp = {Sun, 06 Oct 2024 21:04:59 +0200},
	biburl = {https://dblp.org/rec/conf/icde/YangZWLZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The string similarity search is core functionality in a range of applications, including data cleaning, near-duplicate object detection, and data integration. We study the problem of threshold similarity search with the edit distance, where given a set of strings, a threshold\nk\n, and a query string\nq\n, we aim to find all strings in the set whose edit distances to\nq\nare no larger than\nk\n. Extensive studies have been proposed for the threshold similarity search problem with the edit distance. However, they suffer from a huge space consumption issue when achieving only an acceptable efficiency, especially for long strings. In this paper, we propose a simple yet small index, called minIL, to eliminate this issue. First, we adopt a minhash family to capture pivot characters and to construct sketch representations for strings. Second, we develop a multi-level inverted index to search sketches with a low space consumption. Finally, we apply a novel learned index technique on top of the index that further improves the query efficiency. Extensive experiments on real-world datasets offer insight into the performance of our method and show that it substantially reduces the index size, and is capable of outperforming the baseline approaches.}
}


@inproceedings{DBLP:conf/icde/HuanLLLHCJWS22,
	author = {Chengying Huan and
                  Hang Liu and
                  Mengxing Liu and
                  Yongchao Liu and
                  Changhua He and
                  Kang Chen and
                  Jinlei Jiang and
                  Yongwei Wu and
                  Shuaiwen Leon Song},
	title = {TeGraph: {A} Novel General-Purpose Temporal Graph Computing Engine},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {578--592},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00048},
	doi = {10.1109/ICDE53745.2022.00048},
	timestamp = {Wed, 07 Dec 2022 23:09:58 +0100},
	biburl = {https://dblp.org/rec/conf/icde/HuanLLLHCJWS22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Temporal graphs attach time information to edges and are commonly used for implementing time-critical applications that can not be effectively processed by traditional static and dynamic graph processing engines. State-of-the-art solutions that target temporal path problems remain ad-hoc and often suboptimal. A unified and high-performance solution that could efficiently process general temporal path problems via a universal optimization strategy and relieve practitioners from heavy optimization efforts is in urgent demand. In this paper, we make two key observations: (1) temporal path problems can be described as topological-optimum problems and solved by a universal single scan execution model; and (2) data redundancy commonly occurs in the native format of the transformed temporal graphs, which is unnecessary for information propagation and can be eliminated for better memory utilization and execution efficiency. Based on these core insights, we propose TegRaph, the first general-purpose temporal graph computing engine to provide a unified optimization strategy and execution model for general temporal path problems and their applications. TegRaph not only presents temporal information-aware graph representation that naturally fits temporal graphs but also offers general system-level supports such as out-of-core execution. Extensive evaluation reveals that TegRaph can achieve significant speedups over the state-of-the-art designs with up to two orders of magnitude (241×) with the throughput of two hundred million edges per second.}
}


@inproceedings{DBLP:conf/icde/KongXZ22,
	author = {Deyu Kong and
                  Xike Xie and
                  Zhuoxu Zhang},
	title = {Clustering-based Partitioning for Large Web Graphs},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {593--606},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00049},
	doi = {10.1109/ICDE53745.2022.00049},
	timestamp = {Fri, 05 Aug 2022 16:24:00 +0200},
	biburl = {https://dblp.org/rec/conf/icde/KongXZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graph partitioning plays a vital role in distributed large-scale web graph analytics, such as pagerank and label propagation. The quality and scalability of partitioning strategy have a strong impact on such communication- and computation-intensive applications, since it drives the communication cost and the workload balance among distributed computing nodes. Recently, the streaming model shows promise in optimizing graph partitioning. However, existing streaming partitioning strategies either lack of adequate quality or fall short in scaling with a large number of partitions. In this work, we explore the property of web graph clustering and propose a novel restreaming algorithm for vertex-cut partitioning. We investigate a series of techniques, which are pipelined as three steps, streaming clustering, cluster partitioning, and partition transformation. More, these techniques can be adapted to a parallel mechanism for further acceleration of partitioning. Experiments on real datasets and real systems show that our algorithm outperforms state-of-the-art vertex-cut partitioning methods in large-scale web graph processing. Surprisingly, the runtime cost of our method can be an order of magnitude lower than that of one-pass streaming partitioning algorithms, when the number of partitions is large.}
}


@inproceedings{DBLP:conf/icde/Faure-Giovagnoli22,
	author = {Pierre Faure{-}Giovagnoli and
                  Jean{-}Marc Petit and
                  Vasile{-}Marian Scuturici},
	title = {Assessing the Existence of a Function in a Dataset with the g3 Indicator},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {607--620},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00050},
	doi = {10.1109/ICDE53745.2022.00050},
	timestamp = {Wed, 07 Dec 2022 23:09:58 +0100},
	biburl = {https://dblp.org/rec/conf/icde/Faure-Giovagnoli22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Taking domain knowledge into account is a long-standing issue in AI, especially nowadays where huge amounts of data are collected in the hope of delivering new in-sights and value. Let us consider the following scenario. Let D(y, x1, … ,x n ) be a dataset, Alice a data scientist, Bob a domain expert and\ny\n=\nf\n(x1, … , xn) a function known by Bob from his background knowledge. We are interested in the following simple yet crucial questions for Alice: how to define the satisfaction of f in D and how difficult is it to measure that satisfaction? It turns out that those problems are related to functional dependencies (FDs) and especially FD measurements used to quantify their satisfaction in a dataset such as the g3 indicator. In this paper, we examine the computation of g3 with crisp FDs (aka. exact FDs) and a large class of non-crisp FDs replacing strict equality by more flexible predicates. Interestingly, it is known that the computation of g3 with crisp FDs is polynomial but turns out to be NP-Hard for non-crisp FDs. In this paper, we propose different exact and approximate solutions for the computation of g3 for both types. First, for crisp FDs with very large datasets, we propose solutions based on uniform and stratified random sampling. Second, for non-crisp FDs we present a detailed computation pipeline with various computation optimizations, including approximation algorithms and adaptations of recent developments in sublinear algorithms for NP-Hard problems. We also propose an in-depth experimental study of the algorithms presented in terms of time performances and approximation accuracy. All the algorithms are also made available through FASTG3, an open-source Python library designed to be intuitive and efficient thanks to an underlying C++ implementation.}
}


@inproceedings{DBLP:conf/icde/ComignaniBNB22,
	author = {Ugo Comignani and
                  Laure Berti{-}{\'{E}}quille and
                  No{\"{e}}l Novelli and
                  Angela Bonifati},
	title = {Provenance-aware Discovery of Functional Dependencies on Integrated
                  Views},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {621--633},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00051},
	doi = {10.1109/ICDE53745.2022.00051},
	timestamp = {Wed, 07 Dec 2022 23:09:58 +0100},
	biburl = {https://dblp.org/rec/conf/icde/ComignaniBNB22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The automatic discovery of functional dependencies (FDs) has been widely studied as one of the hardest problems in data profiling. Existing approaches have focused on making the FD computation efficient while inspecting single relations at a time. In this paper, for the first time we address the problem of inferring FDs for multiple relations as they occur in integrated views by solely using the functional dependencies of the base relations of the view itself. To this purpose, we leverage logical inference and selective mining and show that we can discover most of the exact FDs from the base relations and avoid the full computation of the FDs for the integrated view itself, while at the same time preserving the lineage of FDs of base relations. We propose algorithms to speedup the inferred FD discovery process and mine FDs on-the-fly only from necessary data partitions. We present InFine (INferred FunctIoNal dEpendency), an end-to-end solution to discover inferred FDs on integrated views by leveraging provenance information of base relations. Our experiments on a range of real-world and synthetic datasets demonstrate the benefits of our method over existing FD discovery methods that need to rerun the discovery process on the view from scratch and cannot exploit lineage information on the FDs. We show that InFine outperforms traditional methods necessitating the full integrated view computation by one to two order of magnitude in terms of runtime. It is also the most memory efficient method while preserving FD provenance information using mainly inference from base table with negligible execution time.}
}


@inproceedings{DBLP:conf/icde/FanGJLTY22,
	author = {Wenfei Fan and
                  Liang Geng and
                  Ruochun Jin and
                  Ping Lu and
                  Resul Tugay and
                  Wenyuan Yu},
	title = {Linking Entities across Relations and Graphs},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {634--647},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00052},
	doi = {10.1109/ICDE53745.2022.00052},
	timestamp = {Mon, 30 Oct 2023 12:09:01 +0100},
	biburl = {https://dblp.org/rec/conf/icde/FanGJLTY22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper proposes a notion of parametric simulation to link entities across a relational database\nD\nand a graph\nG\n. Taking functions and thresholds for measuring vertex close-ness, path associations and important properties as parameters, parametric simulation identifies tuples\nt\nin\nD\nand vertices\nv\nin\nG\nthat refer to the same real-world entity, based on topological and semantic matching. We develop machine learning methods to learn the parameter functions and thresholds. We show that parametric simulation is in quadratic-time, by providing such an algorithm. Putting these together, we develop HER, a parallel system to check whether\n(t,v)\nmakes a match, find all vertex matches of\nt\nin\nG\n, and compute all matches across\nD\nand\nG\n, all in quadratic-time. Using real-life and synthetic data, we empirically verify that HER is accurate with\nF\n-measure of 0.94 on average, and is able to scale with database\nD\nand graph\nG\n.}
}


@inproceedings{DBLP:conf/icde/SongGQWY22,
	author = {Zhen Song and
                  Yu Gu and
                  Jianzhong Qi and
                  Zhigang Wang and
                  Ge Yu},
	title = {EC-Graph: {A} Distributed Graph Neural Network System with Error-Compensated
                  Compression},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {648--660},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00053},
	doi = {10.1109/ICDE53745.2022.00053},
	timestamp = {Mon, 05 Feb 2024 20:31:12 +0100},
	biburl = {https://dblp.org/rec/conf/icde/SongGQWY22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The high training costs of graph neural networks (GNNs) have limited their applicability on large graphs, e.g., graphs with hundreds of millions of vertices which have become common in the era of big data. A few recent studies propose distributed GNN systems. However, these systems may generate high communication costs due to the extensive message passing among graph vertices stored on different machines. To address such limitations, in the paper, 1) we propose a distributed GNN computation system named EC-Graph for CPU clusters, which drastically reduces the communication costs among the machines by message compression; 2) we design a requesting-end compensation method for the embeddings to mitigate the errors induced by compression in the forward propagation and a Bit-Tuner to adaptively balance the model accuracy and message size; and 3) we propose a responding-end compensation approach for the embedding gradients in the backward propagation. Extensive experiments over large real-world datasets show that EC-Graph outperforms state-of-the-art distributed GNN systems on two CPU clusters of different sizes.}
}


@inproceedings{DBLP:conf/icde/SasakiFO22,
	author = {Yuya Sasaki and
                  George Fletcher and
                  Makoto Onizuka},
	title = {Language-aware Indexing for Conjunctive Path Queries},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {661--673},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00054},
	doi = {10.1109/ICDE53745.2022.00054},
	timestamp = {Sat, 30 Sep 2023 09:44:51 +0200},
	biburl = {https://dblp.org/rec/conf/icde/SasakiFO22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Conjunctive path queries (CPQ) are one of the most frequently used queries for complex graph analysis. However, current graph indexes are not tailored to fully support the power of query languages to express CPQs. Consequently, current methods do not take advantage of significant pruning opportunities during\nCPQ\nevaluation, resulting in poor query processing performance. We propose the CPQ-aware path index CPQx, the first path index tailored to the expressivity of CPQ. CPQx is built on the partition of the set of source-target vertex pairs of paths in a graph based on the structural notion of path-bisimulation. Path-bisimulation is an equivalence relation on paths such that each partition block induced by the relation consists of paths in the graph indistinguishable with respect to CPQs. This language-aware partitioning of the graph can significantly reduce the cost of query evaluation. We present methods to support the full index life cycle: index construction, maintenance, and query processing with our index. We also develop interest-aware CPQx to reduce index size and index construction overhead while accelerating query evaluation for queries of interest. We demonstrate through extensive experiments on 14 real graphs that our methods accelerate query processing by up to multiple orders of magnitude over the state-of-the-art methods, with smaller index sizes. Our complete C++ codebase is available as open source for further research.}
}


@inproceedings{DBLP:conf/icde/LeiZZL22,
	author = {Jiayu Lei and
                  Zheng Zhang and
                  Lan Zhang and
                  Xiang{-}Yang Li},
	title = {{COCA:} Cost-Effective Collaborative Annotation System by Combining
                  Experts and Amateurs},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {674--685},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00055},
	doi = {10.1109/ICDE53745.2022.00055},
	timestamp = {Mon, 26 Aug 2024 17:50:31 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LeiZZL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Data annotation has been a key boost for the artificial intelligence. However, difficult tasks such as fine-grained classification need lots of labeled data to train a feasible model. On the one hand, using people who have expert knowledge on the datasets to annotate all data can be costly. On the other hand, amateurs are cheaper but not able to give precise labels. Related works like machine labeling need labeled data to start up. Crowd-Model labeling can hardly solve complex tasks like fine-grained classification. Lately, combining domain experts and cost-effective crowd to solve complex tasks has become an area of increasing interest in research and industry. However, most works rarely investigate the cost gap between experts and amateurs and see how it influences the final annotation cost. In this paper, we combine both experts and amateurs to build a cost-effective data annotation system called COCA. COCA annotates the target dataset from scratch and save costs by our annotation assignment strategy. Extensive evaluations show that when reaching the same precision, COCA can reach a lower cost than SOTA automatic labeling models when the ratio of expert price to amateur price is above a certain value.}
}


@inproceedings{DBLP:conf/icde/ZhangLQZWCL22,
	author = {Junhua Zhang and
                  Wentao Li and
                  Lu Qin and
                  Ying Zhang and
                  Dong Wen and
                  Lizhen Cui and
                  Xuemin Lin},
	title = {Reachability Labeling for Distributed Graphs},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {686--698},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00056},
	doi = {10.1109/ICDE53745.2022.00056},
	timestamp = {Mon, 20 Nov 2023 13:58:36 +0100},
	biburl = {https://dblp.org/rec/conf/icde/ZhangLQZWCL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Real-world graphs are typically distributed across multiple data centers. When performing reachability queries on these distributed graphs, reachability labeling methods ensure fast query processing by using lightweight indexes. One of the best-known labeling methods is TOL; however, TOL is a serial algorithm and cannot handle distributed graphs. The main goal of this paper is to design new labeling methods that can work in parallel while producing the same index as TOL. To this end, we investigate the limitation of TOL and thus propose a filtering-and-refinement framework for index creation. This framework first obtains a super-set of each vertex's label sets and then eliminates the invalid elements. Based on this framework, we design distributed labeling algorithms and then use batch processing to improve efficiency. Experimental results on real-world graphs show that the proposed algorithms can index distributed graphs efficiently.}
}


@inproceedings{DBLP:conf/icde/LuoJQCDHZ22,
	author = {Xiao Luo and
                  Wei Ju and
                  Meng Qu and
                  Chong Chen and
                  Minghua Deng and
                  Xian{-}Sheng Hua and
                  Ming Zhang},
	title = {DualGraph: Improving Semi-supervised Graph Classification via Dual
                  Contrastive Learning},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {699--712},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00057},
	doi = {10.1109/ICDE53745.2022.00057},
	timestamp = {Tue, 07 May 2024 20:05:35 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LuoJQCDHZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we study semi-supervised graph classification, a fundamental problem in data mining and machine learning. The problem is typically solved by learning graph neural networks with pseudo-labeling or knowledge distillation to incorporate both labeled and unlabeled graphs. However, these methods usually either suffer from overconfident and biased pseudo-labels or suboptimal distillation caused by the insufficient use of unlabeled data. Inspired by the recent progress of contrastive learning and dual learning, we propose DualGraph, a principled framework to leverage unlabeled graphs more effectively for semi-supervised graph classification. DualGraph consists of a prediction module and a retrieval module to model graphs\nG\nand their labels\ny\nfrom opposite while complementary views (i.e., p(y | G) and p(G | y) respectively). The two modules are jointly trained via posterior regularization, which encourages their inter-module consistency on unlabeled graphs. Moreover, we improve model training for each module with a contrastive learning framework to encourage the intra-module consistency on unlabeled data. Experimental results on a range of publicly accessible datasets reveal the effectiveness of our DualGraph.}
}


@inproceedings{DBLP:conf/icde/LiWNZCHP22,
	author = {Guanyao Li and
                  Xiaofeng Wang and
                  Gunarto Sindoro Njoo and
                  Shuhan Zhong and
                  S.{-}H. Gary Chan and
                  Chih{-}Chieh Hung and
                  Wen{-}Chih Peng},
	title = {A Data-Driven Spatial-Temporal Graph Neural Network for Docked Bike
                  Prediction},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {713--726},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00058},
	doi = {10.1109/ICDE53745.2022.00058},
	timestamp = {Mon, 05 Feb 2024 20:31:13 +0100},
	biburl = {https://dblp.org/rec/conf/icde/LiWNZCHP22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Docked bike systems have been widely deployed in many cities around the world. To the service provider, predicting the demand and supply of bikes at any station is crucial to offering the best service quality. The docked bike prediction problem is highly challenging because of the complicated joint spatial-temporal (ST) dependency as bikes are picked up and dropped off, the so-called “flows”, between stations. Prior works often considered the spatial and temporal dependencies separately using sequential network models, and based on locality assumptions. Without sufficiently capturing the joint spatial and temporal features, these approaches are not optimal for attaining the best prediction accuracy. We propose STGNN-DJD, a novel data-driven Spatial-Temporal Graph Neural Network to solve the bike demand and supply prediction problem by unifiedly embedding the Dynamic and Joint ST Dependency in two novel ST graphs. Given station locations and historical rental data on bike flow over the past time slots 0 to $t-1$ , we seek to predict online the bike demand and supply at any station at time $t$ . To extract joint spatial-temporal dependency, STGNN-DJD employs a graph generator to construct, at the beginning of time $t$ , two graphs that embed the flow relationships between stations at various time slots (flow-convoluted graph) and dynamic demand-supply pattern correlation between stations (pattern correlation graph), respectively. Given the two spatial-temporal graphs, STGNN-DJD subsequently employs a graph neural network with novel flow-based and attention-based aggregators to generate embedding of each station for docked bike prediction. We have conducted extensive experiments on two large bike-sharing datasets. Our re-sults confirm the effectiveness of STGNN-DJD as compared with other state-of-the-art approaches, with significant improvement on RMSE and MAE (by 20%-50%). We also provide a case study on dynamic dependencies between stations and demonstrate that the locality assumption does not always hold for a docked bike system.}
}


@inproceedings{DBLP:conf/icde/GuoZHQGCTHZ22,
	author = {Wei Guo and
                  Can Zhang and
                  Zhicheng He and
                  Jiarui Qin and
                  Huifeng Guo and
                  Bo Chen and
                  Ruiming Tang and
                  Xiuqiang He and
                  Rui Zhang},
	title = {{MISS:} Multi-Interest Self-Supervised Learning Framework for Click-Through
                  Rate Prediction},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {727--740},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00059},
	doi = {10.1109/ICDE53745.2022.00059},
	timestamp = {Sun, 06 Oct 2024 21:04:57 +0200},
	biburl = {https://dblp.org/rec/conf/icde/GuoZHQGCTHZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {CTR prediction is essential for modern recommender systems. Ranging from early factorization machines to deep learning based models in recent years, existing CTR methods focus on capturing useful feature interactions or mining important behavior patterns. Despite the effectiveness, we argue that these methods suffer from the risk of label sparsity (i.e., the user-item interactions are highly sparse with respect to the feature space), label noise (i.e., the collected user-item interactions are usually noisy), and the underuse of domain knowledge (i.e., the pairwise correlations between samples). To address these challenging problems, we propose a novel Multi-Interest Self-Supervised learning (MISS) framework which enhances the feature embeddings with interest-level self-supervision signals. With the help of two novel CNN-based multi-interest extractors, self-supervision signals are discovered with full considerations of different interest representations (point-wise and union-wise), interest dependencies (short-range and long-range), and interest correlations (inter-item and intra-item). Based on that, contrastive learning losses are further applied to the augmented views of interest representations, which effectively improves the feature representation learning. Furthermore, our proposed MISS frame-work can be used as an “plug-in” component with existing CTR prediction models and further boost their performances. Extensive experiments on three large-scale datasets show that MISS significantly outperforms the state-of-the-art models, by up to 13.55% in AUC, and also enjoys good compatibility with representative deep CTR models.}
}


@inproceedings{DBLP:conf/icde/ChenXL22,
	author = {Yuyan Chen and
                  Yanghua Xiao and
                  Bang Liu},
	title = {Grow-and-Clip: Informative-yet-Concise Evidence Distillation for Answer
                  Explanation},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {741--754},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00060},
	doi = {10.1109/ICDE53745.2022.00060},
	timestamp = {Fri, 05 Aug 2022 16:24:03 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ChenXL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Interpreting the predictions of existing Question Answering (QA) models is critical to many real-world intelligent applications, such as QA systems for healthcare, education, and finance. However, existing QA models lack interpretability and provide no feedback or explanation for end-users to help them understand why a specific prediction is the answer to a question. In this research, we argue that the evidences of an answer is critical to enhancing the interpretability of QA models. Unlike previous research that simply extracts several sentence(s) in the context as evidence, we are the first to explicitly define the concept of evidence as the supporting facts in a context which are informative, concise, and readable. Besides, we provide effective strategies to quantitatively measure the informativeness, conciseness and readability of evidence. Furthermore, we propose Grow-and-Clip Evidence Distillation (GCED) algorithm to extract evidences from the contexts by trade-off informativeness, conciseness, and readability. We conduct extensive experiments on the SQuAD and TriviaQA datasets with several baseline models to evaluate the effect of GCED on interpreting answers to questions. Human evaluation are also carried out to check the quality of distilled evidences. Experimental results show that automatic distilled evidences have human-like informativeness, conciseness and readability, which can enhance the interpretability of the answers to questions.}
}


@inproceedings{DBLP:conf/icde/ZhangGHCL22,
	author = {Kaiqi Zhang and
                  Hong Gao and
                  Xixian Han and
                  Jian Chen and
                  Jianzhong Li},
	title = {Maximizing Range Sum in Trajectory Data},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {755--766},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00061},
	doi = {10.1109/ICDE53745.2022.00061},
	timestamp = {Wed, 02 Aug 2023 15:25:32 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhangGHCL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Maximizing Range Sum (MaxRS) query is a basic operation in computational geometry and database communities. Given a set of weighted objects in 2-dimensional space and a rectangle, MaxRS query aims to find an optimal position of the rectangle to maximize the total weight of covered objects (i.e., Range Sum). All the existing literature for MaxRS query commonly assumes that every object is associated with a unique point. In real applications, however, every object (e.g., GPS-enabled moving vehicle) is related to a trajectory including a sequence of points, which goes beyond this restrictive assumption. How to tackle the problem of MaxRS query in trajectory data (MaxRST) is important and challenging. In this paper, we propose the definition of MaxRST query where a trajectory is covered by a rectangle if at least one of points in the trajectory is enclosed by the rectangle. We propose a novel method to solve MaxRST query by converting it to rectilinear polygon intersection problem. Then, an interval-tree-based partitioning technique is developed to efficiently settle rectilinear polygon intersection problem. To further shorten the response time, we present (\nϵ,δ\n) -approximate MaxRST query, which returns an approximate answer having the relative error\nϵ\nto the optimal covered weight with probability at least\nδ\n. Furthermore, two complementary sampling-based (\nϵ,δ\n) -approximate MaxRST algorithms are proposed. One performs random sampling with replacements on rectilinear polygons and the sample size is irrelevant to the number of trajectories. The other employs grid shifting technique to reduce sample size yet requires an extra cost for grid construction. The theoretical analysis and experimental results show that our proposed algorithms have high performance in terms of efficiency and accuracy.}
}


@inproceedings{DBLP:conf/icde/JiangXXWQZ22,
	author = {Zhida Jiang and
                  Yang Xu and
                  Hongli Xu and
                  Zhiyuan Wang and
                  Chunming Qiao and
                  Yangming Zhao},
	title = {FedMP: Federated Learning through Adaptive Model Pruning in Heterogeneous
                  Edge Computing},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {767--779},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00062},
	doi = {10.1109/ICDE53745.2022.00062},
	timestamp = {Fri, 05 Aug 2022 16:24:01 +0200},
	biburl = {https://dblp.org/rec/conf/icde/JiangXXWQZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated learning (FL) has been widely adopted to train machine learning models over massive distributed data sources in edge computing. However, the existing FL frameworks usually suffer from the difficulties of resource limitation and edge heterogeneity. Herein, we design and implement FedMP, an efficient FL framework through adaptive model pruning. We theoretically analyze the impact of pruning ratio on model training performance, and propose to employ a Multi-Armed Bandit based online learning algorithm to adaptively determine different pruning ratios for heterogeneous edge nodes, even without any prior knowledge of their computation and communication capabilities. With adaptive model pruning, FedMP can not only reduce resource consumption but also achieve promising accuracy. To prevent the diverse structures of pruned models from affecting the training convergence, we further present a new parameter synchronization scheme, called Residual Recovery Synchronous Parallel (R2SP), and provide a theoretical convergence guarantee. Extensive experiments on the classical models and datasets demonstrate that FedMP is effective for different heterogeneous scenarios and data distributions, and can provide up to 4.1× speedup compared to the existing FL methods.}
}


@inproceedings{DBLP:conf/icde/FengQC22,
	author = {Zijin Feng and
                  Miao Qiao and
                  Hong Cheng},
	title = {Clustering Activation Networks},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {780--792},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00063},
	doi = {10.1109/ICDE53745.2022.00063},
	timestamp = {Fri, 05 Aug 2022 16:24:01 +0200},
	biburl = {https://dblp.org/rec/conf/icde/FengQC22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A real-world graph often has frequently interacting nodes on less frequently updated edges. Each interaction activates an existing edge and changes the activeness of the edge. In such an activation network, nodes that are cohesively connected by active edges form a cluster in both structural and temporal senses. For activation networks, incrementally maintaining a structure for an efficient clustering query processing is thus important. This raises problems on maintaining the edge activeness, combining the structural cohesiveness and activeness for clustering, and designing indexes for online clustering queries. This paper considers the time-decay scheme in modelling the activeness and proposes a suite of techniques with great effort made on simplification and innovation for efficiency, effectiveness and scalability. The query time is only related to the query results as opposed to the graph. The index size is linear up to a logarithmic factor. Extensive experiments verify the quality of the clustering results and moreover, the update time is up to six orders of magnitude faster than the baseline.}
}


@inproceedings{DBLP:conf/icde/YamaguchiUK22,
	author = {Akihiro Yamaguchi and
                  Ken Ueno and
                  Hisashi Kashima},
	title = {Learning Evolvable Time-series Shapelets},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {793--805},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00064},
	doi = {10.1109/ICDE53745.2022.00064},
	timestamp = {Tue, 14 Feb 2023 17:14:16 +0100},
	biburl = {https://dblp.org/rec/conf/icde/YamaguchiUK22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Shapelets are subsequences that are effective for classifying time-series instances. In this study, we consider when each time-series instance is obtained as progress, and formulate the problem of learning shapelet evolution over progress. For example, shapelets can change their shapes according to progress with human habituation, seasonal effects, and system degradation. When given time-series instances, progress values, and binary class labels, the proposed optimization formulation can jointly learn not only the shapelets and a classifier but also regression models for predicting shapelet evolution. The derived optimization solution method allows regression models to be learned by using off-the-shelf regression solvers, and scales linearly with time-series length. We demonstrate its effectiveness in industrial case studies.}
}


@inproceedings{DBLP:conf/icde/DeshmukhSP22,
	author = {Harshad Deshmukh and
                  Bruhathi Sundarmurthy and
                  Jignesh M. Patel},
	title = {On inter-operator data transfers in query processing},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {820--832},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00066},
	doi = {10.1109/ICDE53745.2022.00066},
	timestamp = {Fri, 05 Aug 2022 16:24:02 +0200},
	biburl = {https://dblp.org/rec/conf/icde/DeshmukhSP22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In designing query processing primitives, a crucial design choice is the method for data transfer between two operators in a query plan. As we were considering this critical design mechanism for an in-memory database system that we are building, we quickly realized that (surprisingly) there isn't a clear definition of this concept. Papers are full of ad hoc use of terms like pipelining and blocking, but these terms are not crisply defined, making it hard to fully understand the results attributed to these concepts. To address this limitation, we introduce a clear terminology for how to think about data transfer between operators in a query pipeline. We argue that there isn't a clear definition of pipelining and blocking, and that there is a full spectrum of techniques based on a simple concept called unit-of-transfer. Next, we develop an analytical model for inter-operator communication, and highlight the key parameters that impact performance (for in-memory database settings). Armed with this model, we then apply it to the system we are designing and highlight the insights that we gathered from this exercise. We find that the gap between the traditional “pipelining” and “non-pipelining” methods of query processing, w.r.t. key factors such as performance and memory footprint is quite narrow, and thus system designers should likely rethink the notion of “pipelining” vs. “blocking” for in-memory database systems.}
}


@inproceedings{DBLP:conf/icde/NikookarSSAR22,
	author = {Sepideh Nikookar and
                  Paras Sakharkar and
                  Baljinder Smagh and
                  Sihem Amer{-}Yahia and
                  Senjuti Basu Roy},
	title = {Guided Task Planning Under Complex Constraints},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {833--845},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00067},
	doi = {10.1109/ICDE53745.2022.00067},
	timestamp = {Fri, 05 Aug 2022 16:24:01 +0200},
	biburl = {https://dblp.org/rec/conf/icde/NikookarSSAR22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Creating a plan, i.e., composing a sequence of items to achieve a task is inherently complex if done manually. This requires not only finding a sequence of relevant items but also understanding user requirements and incorporating them as constraints. For instance, in course planning, items are core and elective courses, and degree requirements capture their complex dependencies as constraints. In trip planning, items are points of interest (POIs) and constraints represent time and monetary budget, two user-specified requirements. Most importantly, a plan must comply with the ideal interleaving of items to achieve a goal such as enhancing students' skills towards the broader learning goal of an education program, or in the travel scenario, improving the overall user experience. We study the Task Planning Problem (TPP) with the goal of generating a sequence of items that optimizes multiple objectives while satisfying complex constraints. TPP is modeled as a Constrained Markov Decision Process, and we adapt weighted Reinforcement Learning to learn a policy that satisfies complex dependencies between items, user requirements, and satisfaction. We present a computational framework RL-Planner for TPP. RL-Planner requires minimal input from domain experts (academic advisors for courses, or travel agents for trips), yet produces personalized plans satisfying all constraints. We run extensive experiments on datasets from university programs and from travel agencies. We compare our solutions with plans drafted by human experts and with fully automated approaches. Our experiments corroborate that existing automated solutions are not suitable to solve TPP and that our plans are highly comparable to expensive handcrafted ones.}
}


@inproceedings{DBLP:conf/icde/HuangFLCZO22,
	author = {Chenji Huang and
                  Yixiang Fang and
                  Xuemin Lin and
                  Xin Cao and
                  Wenjie Zhang and
                  Maria E. Orlowska},
	title = {Estimating Node Importance Values in Heterogeneous Information Networks},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {846--858},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00068},
	doi = {10.1109/ICDE53745.2022.00068},
	timestamp = {Sun, 12 Nov 2023 02:08:09 +0100},
	biburl = {https://dblp.org/rec/conf/icde/HuangFLCZO22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Node importance estimation is a fundamental task in graph data analysis. Extensive studies have focused on this task, and various downstream applications have benefited from it, such as recommendation, resource allocation optimization, and missing value completion. However, existing works either focus on the homogeneous network or only study importance-based ranking. We are the first to consider the node importance values as heterogeneous values in heterogeneous information networks (HINs). A typical HIN is built of several distinguished node types where each type has its own measure of importance value (e.g., in the DBLP network, the importance values of authors and papers can be reflected by their h-index and citation numbers, respectively). This characteristic makes the above problem more challenging than computing the node importance in conventional homogeneous networks. In this paper, we formally introduce the problem of node importance value estimation in HINs; that is, given the importance values of a subset of nodes in an HIN, we aim to estimate the importance values of the remaining nodes. To solve this problem, we propose an effective graph neural network (GNN) model, called HIN Importance Value Estimation Network (HIVEN). HIVEN traces the local information of each node, specifically by utilizing the heterogeneity of the HIN. Furthermore, the meta schema is deployed to alleviate the node type domination issue. Additionally, HIVEN exploits the node similarity within each type to remedy the shortcoming of GNN models in capturing global information. Extensive experiments on real-world HIN datasets demonstrate that HIVEN superiorly outperforms the baseline methods.}
}


@inproceedings{DBLP:conf/icde/LiuZCHW22,
	author = {Xiaochen Liu and
                  Weiguo Zheng and
                  Zhenyi Chen and
                  Zhenying He and
                  X. Sean Wang},
	title = {Querying Maximum Quasi-independent Set by Pay-and-Recycle},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {859--871},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00069},
	doi = {10.1109/ICDE53745.2022.00069},
	timestamp = {Fri, 05 Aug 2022 16:24:01 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LiuZCHW22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the paper, we study the problem of computing a maximum quasi-independent set that admits\nk\nconflict edges at most but contains the set of query vertices\nS\n. It generalizes the task of finding a maximum independent set (shorted as MIS) for a given graph. Due to the intractable hardness of computing an exact solution, delivering a high-quality approximate solution within a time budget can be accepted. The existing algorithms for the maximum quasi-independent set are organized in two phases, namely near-MIS initialization and edge expansion (i.e., deleting edges). As both of the two phases adopt greedy strategies, error propagation degrades the quality of delivered answer sets. In contrast, we develop a novel pay-and-recycle approach interleaving the above two phases. Instead of making greedy peelings when no reduction rules can be applied, we delete an edge (i.e., edge expansion) to create opportunities for applying reduction rules. To enhance the performance, the wasted edges are detected and recycled for further expansion. Moreover, we propose an effective method to guide edge expansion based on offline samples. Extensive empirical studies show that our proposed method outperforms the state-of-the-art algorithm in finding larger quasi-independent sets.}
}


@inproceedings{DBLP:conf/icde/GuNPGIH22,
	author = {Geonmo Gu and
                  Yehyun Nam and
                  Kunsoo Park and
                  Zvi Galil and
                  Giuseppe F. Italiano and
                  Wook{-}Shin Han},
	title = {Efficient Graph Isomorphism Query Processing using Degree Sequences
                  and Color-Label Distributions},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {872--884},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00070},
	doi = {10.1109/ICDE53745.2022.00070},
	timestamp = {Sun, 06 Oct 2024 21:04:57 +0200},
	biburl = {https://dblp.org/rec/conf/icde/GuNPGIH22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Given a set of data graphs and a query graph, graph isomorphism query processing is the problem of finding all the data graphs that are isomorphic to the query graph. Graph isomorphism query processing is a core problem in graph analysis of various application domains. In existing approaches, index construction or query processing takes much time as the graph sizes increase. In this paper, we propose an efficient algorithm for graph isomorphism query processing. We introduce the color-label distribution which represents the canonical coloring of a vertex-labeled graph. Based on degree sequences and color-label distributions, we introduce a two-level index, which helps us efficiently solve graph isomorphism query processing. Experimental results on real datasets show that the proposed algorithm is orders of magnitude faster than the state-of-the-art algorithms in terms of index construction time, and it runs faster than existing algorithms in terms of query processing time as the graph sizes increase.}
}


@inproceedings{DBLP:conf/icde/LiWWSP22,
	author = {Yan Li and
                  Liwei Wang and
                  Sheng Wang and
                  Yuan Sun and
                  Zhiyong Peng},
	title = {A Resource-Aware Deep Cost Model for Big Data Query Processing},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {885--897},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00071},
	doi = {10.1109/ICDE53745.2022.00071},
	timestamp = {Thu, 20 Jul 2023 08:05:17 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LiWWSP22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The efficiency of query processing is highly affected by execution plans and allocated resources in the Spark SQL big data processing engine. However, the cost models for Spark SQL are still based on hand-crafted rules. The learning-based cost models have been proposed for relational databases, but it does not consider the effect of the available resources. To address this, we propose a resource-aware deep learning model that can automatically predict the execution time of query plans based on historical data. To train our model, we embed the query execution plans based on the query plan tree and extract features from the allocated resources. A deep learning model with adaptive attention mechanisms is then trained to predict the execution time of query plans. The experiments show that our deep cost model can achieve higher accuracy in predicting the execution time of query plans compared to traditional rule-based methods and relational database learning-based optimizers.}
}


@inproceedings{DBLP:conf/icde/LuoLZGL22,
	author = {Wensheng Luo and
                  Kenli Li and
                  Xu Zhou and
                  Yunjun Gao and
                  Keqin Li},
	title = {Maximum Biplex Search over Bipartite Graphs},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {898--910},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00072},
	doi = {10.1109/ICDE53745.2022.00072},
	timestamp = {Tue, 27 Jun 2023 11:27:57 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LuoLZGL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As a typical most-to-most connected quasi-biclique model, k-biplex is a superset of bicliques, which allows nodes on each side of a fully connected subgraph to lose at most\nk\nconnections. In this paper, we investigate the maximum biplex search problem for the first time. The goal here is to find a k-biplex with the maximum number of edges and we have proved that the problem is NP-hard. It is widely used in fraudulent reviewer group detection, gene expression analysis, social recommendation, and other real-life applications. To solve this problem, a maximum k-biplex search algorithm (MBS) is first presented by integrating two pruning strategies, including degree-based and 2-hop-based pruning. In addition, we define a new dense subgraph over bipartite graphs,\n⟨x,y⟩\n-core, and develop a core-based maximum k-biplex search algorithm (MBS-Core) which can significantly reduce the search space with the introduction of a core-based graph reduction technique. In particular, it only needs to search these cores instead of the entire graph to obtain the maximum k-biplex. Moreover, a parallel algorithm and a heuristic algorithm are developed to achieve better query performance on larger-scale bipartite graphs. Extensive experiments have been conducted on real-life and synthetic datasets to verify the efficiency and effectiveness of the proposed algorithms. Our results show that MBS-Core is up to 3 orders of magnitude faster than the existing approaches.}
}


@inproceedings{DBLP:conf/icde/WangZLYC22,
	author = {Junhao Wang and
                  Lan Zhang and
                  Anran Li and
                  Xuanke You and
                  Haoran Cheng},
	title = {Efficient Participant Contribution Evaluation for Horizontal and Vertical
                  Federated Learning},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {911--923},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00073},
	doi = {10.1109/ICDE53745.2022.00073},
	timestamp = {Fri, 05 Aug 2022 16:24:01 +0200},
	biburl = {https://dblp.org/rec/conf/icde/WangZLYC22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated Learning (FL) enables multiple partici-pants to collaboratively train a model in a privacy-preserving way. The performance of the FL model heavily depends on the quality of participants' local data, which makes measuring the contributions of participants an essential task for various purposes, e.g., participant selection and reward allocation. The Shapley value is widely adopted by previous work for contribution assessment, which, however, requires repeatedly leave-one-out retraining and thus incurs the prohibitive cost for FL. In this paper, we propose a highly efficient approach, named DIG-FL, to estimate the Shapley value of each participant without any model retraining. It's worth noting that our approach is applicable to both vertical federated learning (VFL) and horizontal federated learning (HFL), and we provide concrete design for VFL and HFL. In addition, we propose a DIG-FL based reweight mechanism to improve the model training in terms of accuracy and convergence speed by dynamically adjusting the weights of participants according to their per-epoch contributions, and theoretically analyze the convergence speed. Our extensive evaluations on 14 public datasets show that the estimated Shapley value is very close to the actual Shapley value with Pearson's correlation coefficient up to 0.987, while the cost is orders of magnitude smaller than state-of-the-art methods. When there are more than 80% participants holding low-quality data, by dynamically adjusting the weights, DIG-FL can effectively accelerate the convergence and improve the model accuracy.}
}


@inproceedings{DBLP:conf/icde/DixitK22,
	author = {Akhil A. Dixit and
                  Phokion G. Kolaitis},
	title = {Consistent Answers of Aggregation Queries via {SAT}},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {924--937},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00074},
	doi = {10.1109/ICDE53745.2022.00074},
	timestamp = {Fri, 05 Aug 2022 16:24:00 +0200},
	biburl = {https://dblp.org/rec/conf/icde/DixitK22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The framework of database repairs and consistent answers to queries is a principled approach to managing inconsistent databases. We describe the first system able to compute the consistent answers of general aggregation queries with the COUNT (\nA\n), COUNT (*), and SUM operators, and with or without grouping constructs. Our system uses reductions to optimization versions of Boolean satisfiability (SAT) and then leverages powerful SAT solvers. We carry out an extensive set of experiments on both synthetic and real-world data that demonstrate the usefulness and scalability of this approach.}
}


@inproceedings{DBLP:conf/icde/ZhengCCYLY22,
	author = {Libin Zheng and
                  Peng Cheng and
                  Lei Chen and
                  Jianxing Yu and
                  Xuemin Lin and
                  Jian Yin},
	title = {Crowdsourced Fact Validation for Knowledge Bases},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {938--950},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00075},
	doi = {10.1109/ICDE53745.2022.00075},
	timestamp = {Mon, 26 Jun 2023 20:41:55 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhengCCYLY22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In spite of its wide usage in various applications, existing construction methods for Knowledge Base (KB) are still on their way to obtaining 100% correct facts. Thus, employing crowd workers to validate a KB has been proposed to improve its reliability. Most of the existing works focus on devising games with proper incentives to engage workers in validating more facts, but rarely consider matching facts with proper workers. Facts have diverse domains (topics), which naturally require workers of different expertise. In addition, they also generally have different utilities, i.e., some are more heavily used than others. Thus, distinguishing the facts in terms of utility to give them different validation priorities is meaningful, especially when the budget is limited. To this end, we study the crowdsourced fact validation problem which considers worker domains and fact utilities, and find that with some reductions, it can be solved by the existing minimum cost network flow method. However, directly employing that method requires a huge time cost. We thereby propose an optimized network flow method which reduces the network complexity to save the time cost by properly grouping the facts. Furthermore, we propose an incremental validation method, which utilizes the previous results for validating an evolving KB. We finally conduct extensive experiments to demonstrate the effectiveness of the proposed methods.}
}


@inproceedings{DBLP:conf/icde/NetoNCS22,
	author = {Ant{\^{o}}nio Cavalcante Ara{\'{u}}jo Neto and
                  Murilo Coelho Naldi and
                  Ricardo J. G. B. Campello and
                  J{\"{o}}rg Sander},
	title = {{CORE-SG:} Efficient Computation of Multiple MSTs for Density-Based
                  Methods},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {951--964},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00076},
	doi = {10.1109/ICDE53745.2022.00076},
	timestamp = {Fri, 05 Aug 2022 16:24:01 +0200},
	biburl = {https://dblp.org/rec/conf/icde/NetoNCS22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Several popular density-based methods for unsuper-vised and semi-supervised learning tasks, including clustering and classification, can be formulated as instances of a framework that is based on the processing of a minimum spanning tree of the data, where the edge weights correspond to a form of (unnormalized) density estimate w.r.t. a smoothing parameter\nm\npts\n. While density-based methods are considered to be robust w.r.t.\nm\npts\nin the sense that small changes in its value usually lead to slight or no changes in the resulting structure, wider ranges of\nm\npts\nvalues may lead to different results that a user would like to analyze before choosing the most suitable value for a given data set or application. However, to explore multiple results for a range of\nm\npts\nvalues, until recently, one had to re-run the density-based method for each value in the range independently, which is computationally inefficient. This paper proposes a new computationally efficient approach to compute multiple density-based minimum spanning trees w.r.t. a set of\nm\npts\nvalues by leveraging a graph obtained from a single run of the density-based algorithm, without the need for re-runs of the original algorithm. We present theoretical and experimental results that show that our approach overcomes the drawbacks of the previous state-of-the-art, and it is considerably superior in runtime and graph size while being easier to implement. Our experimental evaluation using synthetic and real data shows that our strategy can lead to speed-up factors of hundreds to thousands of times on the computation of density-based minimum spanning trees.}
}


@inproceedings{DBLP:conf/icde/LiDCH22,
	author = {Qinbin Li and
                  Yiqun Diao and
                  Quan Chen and
                  Bingsheng He},
	title = {Federated Learning on Non-IID Data Silos: An Experimental Study},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {965--978},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00077},
	doi = {10.1109/ICDE53745.2022.00077},
	timestamp = {Sun, 19 Mar 2023 20:50:16 +0100},
	biburl = {https://dblp.org/rec/conf/icde/LiDCH22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Due to the increasing privacy concerns and data regulations, training data have been increasingly fragmented, forming distributed databases of multiple “data silos” (e.g., within different organizations and countries). To develop effective machine learning services, there is a must to exploit data from such distributed databases without exchanging the raw data. Recently, federated learning (FL) has been a solution with growing interests, which enables multiple parties to collaboratively train a machine learning model without exchanging their local data. A key and common challenge on distributed databases is the heterogeneity of the data distribution among the parties. The data of different parties are usually non-independently and identically distributed (i.e., non-IID). There have been many FL algorithms to address the learning effectiveness under non-IID data settings. However, there lacks an experimental study on systematically understanding their advantages and disadvantages, as previous studies have very rigid data partitioning strategies among parties, which are hardly representative and thorough. In this paper, to help researchers better understand and study the non-IID data setting in federated learning, we propose comprehensive data partitioning strategies to cover the typical non-IID data cases. Moreover, we conduct extensive experiments to evaluate state-of-the-art FL algorithms. We find that non-IID does bring significant challenges in learning accuracy of FL algorithms, and none of the existing state-of-the-art FL algorithms outperforms others in all cases. Our experiments provide insights for future studies of addressing the challenges in “data silos”.}
}


@inproceedings{DBLP:conf/icde/WangDLYGZC22,
	author = {Hancheng Wang and
                  Haipeng Dai and
                  Meng Li and
                  Jun Yu and
                  Rong Gu and
                  Jiaqi Zheng and
                  Guihai Chen},
	title = {Bamboo Filters: Make Resizing Smooth},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {979--991},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00078},
	doi = {10.1109/ICDE53745.2022.00078},
	timestamp = {Wed, 22 Nov 2023 12:10:46 +0100},
	biburl = {https://dblp.org/rec/conf/icde/WangDLYGZC22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The approximate membership query (AMQ) data structure is a kind of space-efficient probabilistic data structure. It can approximately indicate whether an element exists in a set. The AMQ data structure has been widely used in database indexing, network security, IoT applications, etc. Resizing is an extensively utilized operation of the AMQ data structure, but it can lead to system performance degradation. We summarize two main problems that lead to such degradation. Specifically, one of them is that the resizing operation can block other operations, while the other is that the performance of AMQ structures will deteriorate after multiple resizing operations. However, existing related work cannot alleviate both of them. Therefore, we propose a novel AMQ data structure called bamboo filter, which can alleviate the two problems simultaneously. Bamboo filters can insert, search and delete an element in constant time. Moreover, bamboo filters can dynamically resize in a fine-grained way according to the number of contained elements. Experimental results show that bamboo filters significantly outperform state-of-the-art resizable AMQ data structures in insertion, lookup, and deletion operations. For example, bamboo filters achieve\n2.46×\nlookup throughput of the dynamic cuckoo filter, on average.}
}


@inproceedings{DBLP:conf/icde/ZhaoFZWTLP22,
	author = {Sha Zhao and
                  Junwei Fang and
                  Shiwei Zhao and
                  Runze Wu and
                  Jianrong Tao and
                  Shijian Li and
                  Gang Pan},
	title = {T-Detector: {A} Trajectory based Pre-trained Model for Game Bot Detection
                  in MMORPGs},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {992--1003},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00079},
	doi = {10.1109/ICDE53745.2022.00079},
	timestamp = {Fri, 05 Aug 2022 16:24:02 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhaoFZWTLP22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Game bots are programmed to automatically play games and illegally obtain profit, seriously affecting game experience of honest players and breaking the balance of game ecosystem. Therefore, bot detection needs to be addressed urgently, especially for MMORPGs, one of the most rapidly expanding genres of games. There have been some studies for bot detection, but the features they used are dependent on specific games and the methods cannot be generalized to other games. In this paper, we propose a trajectory based pre-trained model for game bot detection from game character trajectories and mouse trajectories, named T-Detector, which is independent to specific games and can be generalized to others. More specifically, we propose a pretrain method of LocationTime2Vec to learn representations of trajectories from huge unlabeled samples, which deeply embed spatial and temporal information hidden in trajectories. Moreover, we extract universal features based on behavioral differences in movement trajectories between human players and bots. We design an Angle Pretrain to extract features of turning angle, and propose an attention pooling module to extract features of moving speed and distance. Such features are not dependent on any specific game, enabling T-Detector to be generalized to many MMORPGs. Evaluated by two large-scale real-world datasets of 143,938 samples from two MMORPGs, T-Detector achieves the state-of-the-art performance in bot detection, and demonstrates powerful generalization ability.}
}


@inproceedings{DBLP:conf/icde/YaoCQ22,
	author = {Kai Yao and
                  Lijun Chang and
                  Lu Qin},
	title = {Computing Maximum Structural Balanced Cliques in Signed Graphs},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1004--1016},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00080},
	doi = {10.1109/ICDE53745.2022.00080},
	timestamp = {Sat, 30 Sep 2023 09:44:52 +0200},
	biburl = {https://dblp.org/rec/conf/icde/YaoCQ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Signed graphs have been used to capture the polarity of relationships between entities through positive and negative edge signs, indicating friendly and antagonistic relationships, respectively. In this paper, we focus on (structural) balanced cliques in signed graphs, where a clique, denoted by its vertex set $C$ , is (structural) balanced if it can be uniquely partitioned into two sets $C_{L}$ and $C_{R}$ such that all negative edges in the clique are between $C_{L}$ and $C_{R}$ . We study the maximum balanced clique problem that aims to find the balanced clique $C^{\\ast}$ such that $\\min\\{\\vert C_{L}^{\\ast}\\vert, \\vert C_{R}^{\\ast}\\vert \\}\\geq\\tau$ for a user-given threshold $\\tau$ and $\\vert C^{\\ast}\\vert$ is the largest possible. We propose a novel graph reduction technique by transforming the maximum balanced clique problem over a signed graph $G$ to a series of maximum dichromatic clique problems over small subgraphs of $G$ . That is, for a vertex $u$ in $G$ , we first extract the subgraph $G_{u}$ of $G$ induced by vertex set $V_{L}\\cup V_{R}$ , where $V_{L}$ is the union of $u$ and its positive neighbors and $V_{R}$ is $u$ 's negative neighbors. Then, we remove from $G_{u}$ all negative edges between vertices of the same set (i.e., $V_{L}$ or $V_{R}$ ) as well as remove all positive edges between V L and $V_{R}$ ; denote the resulting graph of discarding edge signs as $g_{u}$ . We show that the maximum balanced clique containing $u$ in $G$ is the same as the maximum dichromatic clique (i.e., it has at least $\\tau$ vertices from each of $V_{L}$ and $V_{R}$ ) containing $u$ in $g_{u}$ . Due to the small size and no edge signs in $g_{u}$ , the maximum dichromatic clique containing $u$ in $g_{u}$ can be efficiently computed by exploiting the existing pruning and bounding techniques that are designed for the classic maximum clique problem on unsigned graphs. Furthermore, we extend our techniques to the polarization factor problem which aims to find the largest $\\tau$ such that there is a balanced clique $C$ with $\\min\\{\\vert C_{L}\\vert, \\vert C_{R}\\vert \\}\\geq\\tau$ , and to the generalized maximum balanced clique problem that reports a maximum balanced clique for each $\\tau\\geq 0$ . Experimental studies on large real signed graphs demonstrated the efficiency and effectiveness of our techniques.}
}


@inproceedings{DBLP:conf/icde/LiDLCC22,
	author = {Haoyang Li and
                  Shimin Di and
                  Zijian Li and
                  Lei Chen and
                  Jiannong Cao},
	title = {Black-box Adversarial Attack and Defense on Graph Neural Networks},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1017--1030},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00081},
	doi = {10.1109/ICDE53745.2022.00081},
	timestamp = {Mon, 05 Aug 2024 15:14:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LiDLCC22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graph neural networks (GNNs) have achieved great success on various graph tasks. However, recent studies have re-vealed that GNNs are vulnerable to adversarial attacks, including topology modifications and feature perturbations. Regardless of the fruitful progress, existing attackers require node labels and GNN parameters to optimize a bi-level problem, or cannot cover both topology modifications and feature perturbations, which are not practical, efficient, or effective. In this paper, we propose a black-box attacker PEEGA, which is restricted to access node features and graph topology for practicability. Specifically, we propose to measure the negative impact of various adversarial attacks from the perspective of node representations, thereby we formulate a single-level problem that can be efficiently solved. Furthermore, we observe that existing attackers tend to blur the context of nodes through adding edges between nodes with different labels. As a result, GNNs are unable to recognize nodes. Based on this observation, we propose a GNN defender GNAT, which incorporates three augmented graphs, i.e., a topology graph, a feature graph, and an ego graph, to make the context of nodes more distinguishable. Extensive experiments on three real-world datasets demonstrate the effectiveness and efficiency of our proposed attacker, despite the fact that we do not access node labels and GNN parameters. Moreover, the effectiveness and efficiency of our proposed defender are also validated by substantial experiments.}
}


@inproceedings{DBLP:conf/icde/ZhangZZPZ22,
	author = {Yuejia Zhang and
                  Weiguo Zheng and
                  Zhijie Zhang and
                  Peng Peng and
                  Xuecang Zhang},
	title = {Hybrid Subgraph Matching Framework Powered by Sketch Tree for Distributed
                  Systems},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1031--1043},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00082},
	doi = {10.1109/ICDE53745.2022.00082},
	timestamp = {Sat, 19 Aug 2023 18:10:20 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhangZZPZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the rapid growth of graph scale, challenges emerge for subgraph search when the data graph cannot reside in the memory of a single machine. It is important to develop practical algorithms to answer subgraph queries in distributed systems and has attracted extensive attention in recent years. The existing join-based algorithms are natively supported in many distributed engines, but they often suffer from a large number of invalid intermediate results and duplicate computation. The exploration-based algorithms minimize invalid intermediate results, while they are likely to produce results of exponential size. In this paper, we propose an efficient hybrid subgraph matching framework that integrates the advantages of both join-based and exploration-based paradigms. We formulate a novel decomposition for the query graph, namely sketch tree, which can reduce invalid intermediate results and avoid duplicate computation. We implement the proposed algorithm in the Pregel + system and optimize the communication cost powered by the sketch tree. Extensive experiments on real graphs demonstrate that our proposed algorithm significantly outperforms the state-of-the-art join-based and exploration-based methods.}
}


@inproceedings{DBLP:conf/icde/MiaoPCPGY22,
	author = {Xiaoye Miao and
                  Huanhuan Peng and
                  Kai Chen and
                  Yuchen Peng and
                  Yunjun Gao and
                  Jianwei Yin},
	title = {Maximizing Time-aware Welfare for Mixed Items},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1044--1057},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00083},
	doi = {10.1109/ICDE53745.2022.00083},
	timestamp = {Fri, 05 Aug 2022 16:24:01 +0200},
	biburl = {https://dblp.org/rec/conf/icde/MiaoPCPGY22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Welfare maximization (WM) aims to select a group of seed nodes to allocate different items for marketing, so that the whole welfare after diffusion over a social network is maximized. It has attracted much attention due to the practical applications such as viral marketing and online advertisements, where the economic incentives are incorporated into users' adoption behaviors. However, existing studies ignore the time impact on the diffusion and consider a single item type. In this paper, we propose an effective time-aware utility-driven independent cascade (TUIC) model, that incorporates the time-aware multi-item propagation, utility-driven item adoption, and mixed item relationships together. We identify and formulate the time-aware welfare maximization problem. We develop a general framework to address the problem for mixed competitive, complementary, and independent items. It derives item allocation with the\n(1−1/e−ϵ)\napproximate social welfare in special cases. Extensive experiments on several real-life social networks demonstrate the effectiveness of TUIC model and the efficiency of the proposed framework, compared to the state of the arts.}
}


@inproceedings{DBLP:conf/icde/AhmadiSP22,
	author = {Naser Ahmadi and
                  Hansjorg Sand and
                  Paolo Papotti},
	title = {Unsupervised Matching of Data and Text},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1058--1070},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00084},
	doi = {10.1109/ICDE53745.2022.00084},
	timestamp = {Fri, 05 Aug 2022 16:24:03 +0200},
	biburl = {https://dblp.org/rec/conf/icde/AhmadiSP22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Entity resolution is a widely studied problem with several proposals to match records across relations. Matching textual content is a widespread task in many applications, such as question answering and search. While recent methods achieve promising results for these two tasks, there is no clear solution for the more general problem of matching textual content and structured data. We introduce a framework that supports this new task in an unsupervised setting for any pair of corpora, being relational tables or text documents. Our method builds a fine-grained graph over the content of the corpora and derives word embeddings to represent the objects to match in a low dimensional space. The learned representation enables effective and efficient matching at different granularity, from relational tuples to text sentences and paragraphs. Our flexible framework can exploit pre-trained resources, but, differently from other solutions, it does not depends on their existence and achieves better quality performance in matching content when the vocab-ulary is domain specific. We also introduce optimizations in the graph creation process with an “expand and compress” approach that first identifies new valid relationships across elements, to improve matching, and then prunes nodes and edges, to reduce the graph size. Experiments on real use cases and public datasets show that our framework produces embeddings that outperform word embeddings and fine-tuned language models both in results' quality and in execution times.}
}


@inproceedings{DBLP:conf/icde/DengCZXTX22,
	author = {Cai Deng and
                  Qi Chen and
                  Xiangyu Zou and
                  Erci Xu and
                  Bo Tang and
                  Wen Xia},
	title = {imDedup: {A} Lossless Deduplication Scheme to Eliminate Fine-grained
                  Redundancy among Images},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1071--1084},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00085},
	doi = {10.1109/ICDE53745.2022.00085},
	timestamp = {Sat, 30 Sep 2023 09:44:50 +0200},
	biburl = {https://dblp.org/rec/conf/icde/DengCZXTX22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Images occupy a large amount of storage in data centers. To cope with the explosive growth of the image storage requirement, image compression techniques are devised to shrink the size of every single image at first. Furthermore, image deduplication methods are proposed to reduce the storage cost as they could be used to eliminate redundancy among images. However, state-of-the-art image deduplication methods either can only eliminate file-level coarse-grained redundancy or cannot guarantee lossless deduplication. In this work, we propose a new lossless image deduplication framework to eliminate fine-grained redundancy among images. It first decodes images to expose similarity, then eliminates fine-grained redundancy on the decoded data by delta compres-sion, and finally re-compresses the remaining data by image compression encoding. Based on this framework, we propose a novel lossless similarity-based deduplication (SBD) scheme for decoded image data (called imDedup). Specifically, imDedup uses a novel and fast sampling method (called Feature Map) to detect similar images in a two-dimensional way, which greatly reduces computation overhead. Meanwhile, it uses a novel delta encoder (called Idelta) which incorporates image compression encoding characteristics into deduplication to guarantee the remaining deduplicated image data to be friendly re-compressed via image encoding, which significantly improves the compression ratio. We implement a prototype of imDedup for JPEG images, and demonstrate its superiority on four datasets: Compared with exact image deduplication, imDedup achieves a 19%-38% higher compression ratio by efficiently eliminating fine-grained redundancy. Compared with the similarity detector and delta encoder of state-of-the-art SBD schemes running on the decoded image data, imDedup achieves a 1.8×-3.4× higher throughput and a 1.3 ×-1. 6 × higher compression ratio, respectively.}
}


@inproceedings{DBLP:conf/icde/BhowmickDM22,
	author = {Satadisha Saha Bhowmick and
                  Eduard C. Dragut and
                  Weiyi Meng},
	title = {Boosting Entity Mention Detection for Targetted Twitter Streams with
                  Global Contextual Embeddings},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1085--1097},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00086},
	doi = {10.1109/ICDE53745.2022.00086},
	timestamp = {Fri, 05 Aug 2022 16:24:02 +0200},
	biburl = {https://dblp.org/rec/conf/icde/BhowmickDM22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Microblogging sites, like Twitter, have emerged as ubiquitous sources of information. Two important tasks related to the automatic extraction and analysis of information in Microblogs are Entity Mention Detection (EMD) and Entity Detection (ED). The state-of-the-art EMD systems aim to model the non-literary nature of microblog text by training upon offline static datasets. They extract a combination of surface-level features - orthographic, lexical, and semantic - from individual messages for noisy text modeling and entity extraction. But given the constantly evolving nature of microblog streams, detecting all entity mentions from such varying yet limited context of short messages remains a difficult problem. To this end, we propose a framework named EMD Globalizer, better suited for the execution of EMD learners on microblog streams. It deviates from the processing of isolated microblog messages by existing EMD systems, where learned knowledge from the immediate context of a message is used to suggest entities. Instead, it recognizes that messages within a microblog stream are topically related and often repeat entity mentions, thereby leaving the scope for EMD systems to go beyond the localized processing of individual messages. After an initial extraction of entity candidates by an EMD system, the proposed framework leverages occurrence mining to find additional candidate mentions that are missed during this first detection. Aggregating the local contextual representations of these mentions, a global embedding is drawn from the collective context of an entity candidate within a stream. The global embeddings are then utilized to separate entities within the candidates from false positives. All mentions of said entities from the stream are produced in the framework's final outputs. Our experiments show that EMD Globalizer can enhance the effectiveness of all existing EMD systems that we tested (on average by 25.61 %) with a small additional computational overhead.}
}


@inproceedings{DBLP:conf/icde/KaregarMGGKSS22,
	author = {Reza Karegar and
                  Melicaalsadat Mirsafian and
                  Parke Godfrey and
                  Lukasz Golab and
                  Mehdi Kargar and
                  Divesh Srivastava and
                  Jaroslaw Szlichta},
	title = {Discovering Domain Orders via Order Dependencies},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1098--1110},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00087},
	doi = {10.1109/ICDE53745.2022.00087},
	timestamp = {Fri, 05 Aug 2022 16:24:01 +0200},
	biburl = {https://dblp.org/rec/conf/icde/KaregarMGGKSS22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Most real-world data come with explicitly defined domain orders; e.g., lexicographic for strings, numeric for integers, and chronological for time. Our goal is to discover implicit domain orders that we do not already know; for instance, that the order of months in the Chinese Lunar calendar is Corner\n<\nApricot\n<\nPeach. To do so, we enhance data profiling methods by discovering implicit domain orders in data through order dependencies. We enumerate tractable special cases and show that the general case is NP-complete but can be effectively handled by a SAT solver. We also devise an interestingness measure to rank the discovered implicit domain orders. Based on an extensive suite of experiments with real-world data, we establish the efficacy of our algorithms.}
}


@inproceedings{DBLP:conf/icde/AbuodaTA22,
	author = {Ghadeer Abuoda and
                  Saravanan Thirumuruganathan and
                  Ashraf Aboulnaga},
	title = {Accelerating Entity Lookups in Knowledge Graphs Through Embeddings},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1111--1123},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00088},
	doi = {10.1109/ICDE53745.2022.00088},
	timestamp = {Sat, 30 Sep 2023 09:44:49 +0200},
	biburl = {https://dblp.org/rec/conf/icde/AbuodaTA22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Tabular data is widespread on the web and in enterprise data lakes. Recently, there has been increasing interest in developing algorithms for matching tabular data with knowledge graphs. This involves learning correspondences between tabular entities such as cells, rows, and columns and entities in the knowledge graph. Such semantic annotation of tabular entities has numerous applications such as entity disambiguation, knowledge graph expansion, error detection and repair in tabular data, and more. A key first step for all these applications is the lookup function that matches a query string to a candidate set of knowledge graph entities. Despite the importance of entity lookup, current implementations are not optimized, not robust to misspellings, and ignore semantic relationships. To address these problems, we represent each entity as an embedding - a compact vector representation that is cognizant of syntactic and semantic similarities and supports fast lookup. We propose, EMBLOOKUP, a novel and efficient approach for learning such an embedding. EMBLOOKUP is based on deep metric learning with triplet loss and supports accurate and efficient lookup of knowledge graph entities. We conduct extensive experiments that demonstrate that EMBLOOKUP achieves 1–2 orders of magnitude speedup while being tolerant to many types of errors in the query and data. We demonstrate the generality of EMBLOOKUP over diverse application scenarios in semantic table annotation, entity disambiguation, and data repair.}
}


@inproceedings{DBLP:conf/icde/CachelRH22,
	author = {Kathleen Cachel and
                  Elke A. Rundensteiner and
                  Lane Harrison},
	title = {MANI-Rank: Multiple Attribute and Intersectional Group Fairness for
                  Consensus Ranking},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1124--1137},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00089},
	doi = {10.1109/ICDE53745.2022.00089},
	timestamp = {Fri, 05 Aug 2022 16:24:00 +0200},
	biburl = {https://dblp.org/rec/conf/icde/CachelRH22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Combining the preferences of many rankers into one single consensus ranking is critical for consequential applications from hiring and admissions to lending. While group fairness has been extensively studied for classification, group fairness in rankings and in particular rank aggregation remains in its infancy. Recent work introduced the concept of fair rank aggregation for combining rankings but restricted to the case when candidates have a single binary protected attribute, i.e., they fall into two groups only. Yet it remains an open problem how to create a consensus ranking that represents the preferences of all rankers while ensuring fair treatment for candidates with multiple protected attributes such as gender, race, and nationality. In this work, we are the first to define and solve this open Multi-attribute Fair Consensus Ranking (MFCR) problem. As a foundation, we design novel group fairness criteria for rankings, called MANI-Rank, ensuring fair treatment of groups defined by individual protected attributes and their intersection. Leveraging the MANI-Rank criteria, we develop a series of algorithms that for the first time tackle the MFCR problem. Our experimental study with a rich variety of consensus scenarios demonstrates our MFCR methodology is the only approach to achieve both intersectional and protected attribute fairness while also representing the preferences expressed through many base rankings. Our real world case study on merit scholarships illustrates the effectiveness of our MFCR methods to mitigate bias across multiple protected attributes and their intersections.}
}


@inproceedings{DBLP:conf/icde/ChuZZLZ22,
	author = {Deming Chu and
                  Fan Zhang and
                  Wenjie Zhang and
                  Xuemin Lin and
                  Ying Zhang},
	title = {Hierarchical Core Decomposition in Parallel: From Construction to
                  Subgraph Search},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1138--1151},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00090},
	doi = {10.1109/ICDE53745.2022.00090},
	timestamp = {Sat, 30 Sep 2023 09:44:50 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ChuZZLZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The model of k-core discovers a novel hierarchical structure of a network, which has been widely applied in various areas, e.g., sociology, biology, and brain science. Based on the containment relations of k-cores with different\nk\n, the hierarchical core decomposition (HCD) of a graph formalizes the hierarchy of all k-cores for each possible\nk\n• HCD is effective in locating high-quality subgraphs (e.g., densest subgraph search) and exploring particular network phenomena (e.g., user engagement study). However, existing solutions of HCD are still not efficient enough, for both the hierarchy construction and the subgraph search on the hierarchy. In this paper, we propose the first parallel construction algorithm PHCD for HCD, using a new union-find-based paradigm, and the first parallel algorithm PBKS to search high-quality subgraphs from the hierarchy with respect to various community scoring metrics. We prove the problem of hierarchy construction is\nP\n-complete (difficult to parallelize effectively). Despite the negative result, our PHCD has a near-linear time cost, and PBKS is time-optimal in score computation for most community metrics. Extensive experiments are conducted on 10 real-world networks, where our proposed parallel algorithms significantly outperform the existing solutions, for both the hierarchy construction and the subgraph search.}
}


@inproceedings{DBLP:conf/icde/CongTHCC22,
	author = {Qianhao Cong and
                  Jing Tang and
                  Yuming Huang and
                  Lei Chen and
                  Yeow Meng Chee},
	title = {Cost-Effective Algorithms for Average-Case Interactive Graph Search},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1152--1165},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00091},
	doi = {10.1109/ICDE53745.2022.00091},
	timestamp = {Tue, 07 May 2024 20:05:37 +0200},
	biburl = {https://dblp.org/rec/conf/icde/CongTHCC22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Interactive graph search (IGS) uses human intelligence to locate the target node in hierarchy, which can be applied for image classification, product categorization and searching a database. Specifically, IGS aims to categorize an object from a given category hierarchy via several rounds of interactive queries. In each round of query, the search algorithm picks a category and receives a boolean answer on whether the object is under the chosen category. The main efficiency goal asks for the minimum number of queries to identify the correct hierarchical category for the object. In this paper, we study the average-case interactive graph search (AIGS) problem that aims to minimize the expected number of queries when the objects follow a probability distribution. We propose a greedy search policy that splits the candidate categories as evenly as possible with respect to the probability weights, which offers an approximation guarantee of\nO(logn)\nfor AIGS given the category hierarchy is a directed acyclic graph (DAG), where\nn\nis the total number of categories. Meanwhile, if the input hierarchy is a tree, we show that a constant approximation factor of\n(1+\n5\n–\n√\n)/2\ncan be achieved. Furthermore, we present efficient implementations of the greedy policy, namely GreedyTree and GreedyDAG, that can quickly categorize the object in practice. Extensive experiments in real-world scenarios are carried out to demonstrate the superiority of our proposed methods.}
}


@inproceedings{DBLP:conf/icde/MiaoLCGY22,
	author = {Xiaoye Miao and
                  Yue Liu and
                  Lu Chen and
                  Yunjun Gao and
                  Jianwei Yin},
	title = {Reliable Community Search on Uncertain Graphs},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1166--1179},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00092},
	doi = {10.1109/ICDE53745.2022.00092},
	timestamp = {Sun, 06 Oct 2024 21:04:58 +0200},
	biburl = {https://dblp.org/rec/conf/icde/MiaoLCGY22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Community search (CS) on graphs returns the largest densely connected vertex subset containing a query vertex, namely k-community, where every vertex's degree in the induced subgraph is not less than\nk\n. It has significant influence in many real-life applications including event organization and friend recommendation. Many complex networks such as social networks and protein-protein interaction (PPI) networks are often modeled as uncertain graphs. In this paper, we identify and study the problem of reliable community search on uncertain graphs (UCS for short). Given an uncertain graph, a query vertex\nq\n, a positive integer\nk\nand a probability threshold θ, the reliable community, viz., (k, θ) -community, of\nq\nis the largest vertex subset, so that the probability of every vertex to be in\nq\n's k-community is not less than θ. We prove that it is a NP-hard problem. We propose two novel pruning strategies to reduce the candidate set to a much smaller size. We develop an efficient index, namely CD-index, with which the pruning process can be done in optimal time. We also present efficient sampling algorithms on top of stratified sampling and lazy sampling to accelerate the search under accuracy guarantees. Extensive experiments using four real-world datasets demonstrate the superior performance of proposed algorithms to the state-of-the-art approaches.}
}


@inproceedings{DBLP:conf/icde/TanYWCLZ22,
	author = {Yanchao Tan and
                  Carl Yang and
                  Xiangyu Wei and
                  Chaochao Chen and
                  Longfei Li and
                  Xiaolin Zheng},
	title = {Enhancing Recommendation with Automated Tag Taxonomy Construction
                  in Hyperbolic Space},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1180--1192},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00093},
	doi = {10.1109/ICDE53745.2022.00093},
	timestamp = {Thu, 15 Feb 2024 16:22:21 +0100},
	biburl = {https://dblp.org/rec/conf/icde/TanYWCLZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The sparse interactions between users and items on the web have aggravated the difficulty of their representations in recommender systems. Existing approaches leverage tags to alleviate the data sparsity problem, so as to enhance the performance and interpretability of recommendation. However, directly using flat item tags fails to fully exploit the hierarchical relations in data, but tag taxonomies are not always available. To this end, we propose TaxoRec to jointly construct a tag taxonomy automatically and perform recommendation accurately in hyperbolic space. Specifically, we first leverage hyperbolic space and enable the optimization of a discrete taxonomy structure via a representation-aware scoring function and an adaptive clustering algorithm, and preserve the hierarchical structure for interpretability. Then, we propose to capture the complex relations among users, items, and tags in a unified hyperbolic metric space, where a novel tag-enhanced aggregation mechanism and tag-enhanced metric learning algorithm for users and items are defined. Extensive experiments on four real-world benchmark datasets show drastic performance gains brought by our proposed TaxoRec framework 1 1 https://github.com/Melinda315/TaxoRec, which constantly achieves an average of 7.76% improvement over the state-of-the-art baselines regarding both Recall and NDCG metrics. Insightful case studies also show that our automatically constructed tag taxonomies are highly accurate and interpretable.}
}


@inproceedings{DBLP:conf/icde/JinCCLZ22,
	author = {Jiabao Jin and
                  Peng Cheng and
                  Lei Chen and
                  Xuemin Lin and
                  Wenjie Zhang},
	title = {GridTuner: Reinvestigate Grid Size Selection for Spatiotemporal Prediction
                  Models},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1193--1205},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00094},
	doi = {10.1109/ICDE53745.2022.00094},
	timestamp = {Mon, 26 Jun 2023 20:41:55 +0200},
	biburl = {https://dblp.org/rec/conf/icde/JinCCLZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the development of traffic prediction technology, spatiotemporal prediction models have attracted more and more attention from academia communities and industry. However, most existing researches focus on reducing model's prediction error but ignore the error caused by the uneven distribution of spatial events within a region. In this paper, we study a region partitioning problem, namely optimal grid size selection problem (OGSS), which aims to minimize the real error of spatiotemporal prediction models by selecting the optimal grid size. In order to solve OGSS, we analyze the upper bound of real error of spatiotemporal prediction models and minimize the real error by minimizing its upper bound. Through in-depth analysis, we find that the upper bound of real error will decrease then increase when the number of model grids increase from 1 to the maximum allowed value. Then, we propose two algorithms, namely Ternary Search and Iterative Method, to automatically find the optimal grid size. Finally, the experiments verify that the error of prediction has the same trend as its upper bound, and the change trend of the upper bound of real error with respect to the increase of the number of model grids will decrease then increase. Meanwhile, in a case study, by selecting the optimal grid size, the order dispatching results of a state-of-the-art prediction-based algorithm can be improved up to 13.6%, which shows the effectiveness of our methods on tuning the region partition for spatiotemporal prediction models.}
}


@inproceedings{DBLP:conf/icde/WuHZLZJWCYC22,
	author = {Chengmin Wu and
                  Enrui Hu and
                  Ke Zhan and
                  Lan Luo and
                  Xinyu Zhang and
                  Hao Jiang and
                  Qirui Wang and
                  Zhao Cao and
                  Fan Yu and
                  Lei Chen},
	title = {Triple-Fact Retriever: An explainable reasoning retrieval model for
                  multi-hop {QA} problem},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1206--1218},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00095},
	doi = {10.1109/ICDE53745.2022.00095},
	timestamp = {Thu, 08 Aug 2024 08:11:04 +0200},
	biburl = {https://dblp.org/rec/conf/icde/WuHZLZJWCYC22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Nowadays, multi-hop question answer (QA) problem is challenging and not well solved in the QA community. The dominant bottleneck of the multi-hop QA problem is the need for a reasoning retriever to fetch a document path from an open-domain corpus (e.g., Wikipedia). A reasoning retriever aims to collect an evidence document from large corpora at one hop retrieval and aggregate the evidence for subsequent hop retrieval, which yields a document path after multi-hop retrieval. There exist two challenges, (1) to fetch the evidence document in an efficient and explainable way at one hop retrieval and (2) to update the question information by aggregating the evidence from the retrieved document after each hop retrieval. To address these two challenges, we propose a triple-fact-based retrieval model to effectively retrieve a related document path in an explainable way for each question. We extract a structured representation from the unstructured document and utilize the knowledge of pre-trained language model (PLM) to do the semantic-level matching between the question and document. We evaluate the proposed Triple-fact Retriever model on the recently proposed open-domain multi-hop QA dataset, HotpotQA, and a cross-document multi-step Reading Comprehension dataset, Wikihop. The results 1 1 The source code is available on our website: https://github.com/Rebaccamin/triple_retriever. demonstrate that the Triple-fact retriever outperforms the existing baseline retrieval works.}
}


@inproceedings{DBLP:conf/icde/HaoLWC22,
	author = {Shuang Hao and
                  Peng Li and
                  Renzhi Wu and
                  Xu Chu},
	title = {A Model-Agnostic Approach for Learning with Noisy Labels of Arbitrary
                  Distributions},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1219--1231},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00096},
	doi = {10.1109/ICDE53745.2022.00096},
	timestamp = {Sun, 04 Aug 2024 19:37:45 +0200},
	biburl = {https://dblp.org/rec/conf/icde/HaoLWC22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Most real-world datasets contain label noise, which can negatively affect downstream ML models trained on them. To deal with this problem, one can clean the mislabeled data before training, which is not only time-consuming and expensive but also requires domain expertise. Another approach is to use a noise-robust ML training algorithm. However, existing methods have some prerequisites that may not be practical in many applications (e.g., they are tied to specific downstream model architecture or they are applicable to specific noise distributions). In this paper, we propose a model-agnostic approach for learning with noisy labels of arbitrary distributions. In particular, our approach can work with any gradient descent optimization based machine learning model and deal with any label noise distribution. We achieve them by proposing two theoretically grounded noise-robust loss functions (for different noise distributions), and we are able to automatically decide which loss function to use based on a novel noise setting detection module. We directly learn the required hyper-parameters in the loss functions via meta-learning technique to minimize the loss on a given small clean validation set, and propose several strategies to improve the efficiency of training. Experiments on multiple datasets with both real-world and injected label noise show that our method performs better than state-of-the-art approaches.}
}


@inproceedings{DBLP:conf/icde/QiLN22,
	author = {Panpan Qi and
                  Dan Li and
                  See{-}Kiong Ng},
	title = {{MAD-SGCN:} Multivariate Anomaly Detection with Self-learning Graph
                  Convolutional Networks},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1232--1244},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00097},
	doi = {10.1109/ICDE53745.2022.00097},
	timestamp = {Thu, 29 Dec 2022 16:09:44 +0100},
	biburl = {https://dblp.org/rec/conf/icde/QiLN22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Today's Cyber Physical Systems (CPSs) are large and complex data-intensive systems. Constant monitoring and analysis of the data generated by a multitude of interconnected sensors and actuators are required in order to detect anomalies due to possible intrusions or faults with high accuracy and timeliness. Recently, unsupervised anomaly detection techniques based on deep learning for multivariate time series have been proposed for detecting CPSs attacks with promising performance. However, the current methods are either limited by their representation learning methods in encoding the temporal and spatial information simultaneously and effectively, or cannot easily scale to other tasks without having explicit knowledge of the internal relationships between the different variables or sensors, which are both important for characterising CPSs data. In this paper, we propose a novel unsupervised anomaly detection method for multivariate time series MAD-SGCN which effectively captures the temporal and spatial correlations of the input sequences simultaneously using Long Short-Term Memory networks (LSTMs) and spectral-based Graph Convolutional Networks (GCNs). We design a self-supervised graph structure learning mechanism to minimize the usage of the prior knowledge about the network structures of the CPSs. Experiments on four CPS datasets demonstrate the superiority of the proposed method.}
}


@inproceedings{DBLP:conf/icde/ChenLQZJZ22,
	author = {Zhihao Chen and
                  Qingqing Li and
                  Xiaodong Qi and
                  Zhao Zhang and
                  Cheqing Jin and
                  Aoying Zhou},
	title = {BlockOPE: Efficient Order-Preserving Encryption for Permissioned Blockchain},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1245--1258},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00098},
	doi = {10.1109/ICDE53745.2022.00098},
	timestamp = {Tue, 11 Apr 2023 13:49:45 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ChenLQZJZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Permissioned blockchain is increasingly being used as a collaborative platform for sharing data. However, current blockchain-based data sharing is unable to balance privacy pro-tection and query functionality, limiting its application scenarios. Order-preserving encryption/encoding (OPE) allows encrypting data to prevent privacy leakage while still supporting efficient order-oriented queries on ciphertexts. But existing OPE schemes are constrained by limited use cases and inherent performance limitations that make them difficult to be adopted by permissioned blockchain where performance is a major concern. In this paper, we present BlockOPE, an efficient OPE scheme designed around the first study integrating OPE into blockchain systems. By supporting parallel processing with a conflict-reducing design, we argue that BlockOPE is feasible for permissioned blockchain, achieving orders-of-magnitude performance improvement while preserving the ideal OPE security. Additionally, we improve query processing by leveraging an adaptive lightweight client cache. Extensive experiment results and theoretical analysis illustrate the practicability of our approach.}
}


@inproceedings{DBLP:conf/icde/XieSLWGZDC22,
	author = {Xu Xie and
                  Fei Sun and
                  Zhaoyang Liu and
                  Shiwen Wu and
                  Jinyang Gao and
                  Jiandong Zhang and
                  Bolin Ding and
                  Bin Cui},
	title = {Contrastive Learning for Sequential Recommendation},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1259--1273},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00099},
	doi = {10.1109/ICDE53745.2022.00099},
	timestamp = {Wed, 13 Nov 2024 14:20:38 +0100},
	biburl = {https://dblp.org/rec/conf/icde/XieSLWGZDC22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Sequential recommendation methods play a crucial role in modern recommender systems because of their ability to capture a user's dynamic interest from her/his historical inter-actions. Despite their success, we argue that these approaches usually rely on the sequential prediction task to optimize the huge amounts of parameters. They usually suffer from the data sparsity problem, which makes it difficult for them to learn high-quality user representations. To tackle that, inspired by recent advances of contrastive learning techniques in the computer vision, we propose a novel multi-task framework called Contrastive Learning for Sequential Recommendation (CL4SRec). CL4SRec not only takes advantage of the traditional next item prediction task but also utilizes the contrastive learning framework to derive self-supervision signals from the original user behavior sequences. Therefore, it can extract more meaningful user patterns and further encode the user representations effectively. In addition, we propose three data augmentation approaches to construct self-supervision signals. Extensive experiments on four public datasets demonstrate that CL4SRec achieves state-of-the-art performance over existing baselines by inferring better user representations.}
}


@inproceedings{DBLP:conf/icde/DingZHPFJY22,
	author = {Daizong Ding and
                  Mi Zhang and
                  Yuanmin Huang and
                  Xudong Pan and
                  Fuli Feng and
                  Erling Jiang and
                  Min Yang},
	title = {Towards Backdoor Attack on Deep Learning based Time Series Classification},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1274--1287},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00100},
	doi = {10.1109/ICDE53745.2022.00100},
	timestamp = {Thu, 27 Apr 2023 08:37:39 +0200},
	biburl = {https://dblp.org/rec/conf/icde/DingZHPFJY22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As a fundamental task in modern data mining, time series classification is powering mission-critical tasks including stock price prediction and network traffic analysis. Due to the non-linear structure of deep neural networks (DNN), deep learning has established as a promising solution to time series classification. However, the excessive learning capacity of DNNs may make them prone to threats of backdoor attacks, where an attacker embeds hidden functionalities (i.e., backdoor) to DNNs and activates the backdoor by specially-designed inputs (i.e., triggers). Despite extensive studies concerning backdoor attacks on image and text domains, there is little known about the vulnerability of DNN based time series classifiers against backdoor attacks. Due to the unique characteristics of time series data, most existing backdoor attack techniques fail to threaten time series classifiers. In this paper, through analyzing the key factors which influence the effectiveness of a backdoor, we systematize a list of practical principles for designing triggers on time series data. In this light, we propose a novel framework called TimeTrojan, which aims to learn to form the trigger pattern through a constrained multi-objective optimization. To solve the hereafter challenging optimization issue, we further design an iterative learning algorithm. Remarkably, the proposed framework is agnostic to a wide range of DNN classifiers. Extensive empirical results on 6 representative DNN classifiers and 6 real-world datasets validate the effectiveness of the proposed attack framework. In most cases, TimeTrojan successfully injects backdoors with 100% attack success rate without affecting the model accuracy on clean samples, which implies the complete control of the behavior of the DNN classifiers by the adversary.}
}


@inproceedings{DBLP:conf/icde/LiakosPSD22,
	author = {Panagiotis Liakos and
                  Katia Papakonstantinopoulou and
                  Theodore Stefou and
                  Alex Delis},
	title = {On Compressing Temporal Graphs},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1301--1313},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00102},
	doi = {10.1109/ICDE53745.2022.00102},
	timestamp = {Fri, 05 Aug 2022 16:24:01 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LiakosPSD22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Contemporary data-systems empowering the daily human activity are routinely represented with graphs. During the last decade, the volume growth of such systems has been unprece-dented. This hinders the timely analysis of the formed networks due to existing physical memory limitations and significant I/O overheads. Graph compression techniques have managed to reduce memory requirements and allow for representing such networks using a few bits-per-edge. Respective approaches offer succinct mappings for social, biological, and information networks while allowing for the efficient access of sought graph elements. Despite their success, such methods mostly focus on static graphs, and predominantly offer access to either a snapshot or an aggregated view of a network. In reality however, networks change over time and, in many instances, we are interested in capturing and studying this evolution. In this paper we propose a framework for compressing emerging temporal graphs based on a dual-representation which articulates both network structure and corresponding temporal information. We empirically establish properties exhibited by community-networks regarding their time aspect(s) and harness these features in our proposed repre-sentation. Our experimental evaluation demonstrates that our approach for compressing temporal graphs readily outperforms competing techniques, attaining compression ratios that are on average around 60% of the space required by state-of-the-art techniques. Moreover, our memory-efficient representation yields more than 70 % faster graph compression and orders of magnitude quicker retrieval of graphs' elements, especially when it comes to large-scale networks. Finally, our framework is the first effort we are aware of, that considers actual time instead of time steps. This helps us attain better control for the size of our representation and reap further memory savings.}
}


@inproceedings{DBLP:conf/icde/VerheijdeKFK22,
	author = {Jim Verheijde and
                  Vassilios Karakoidas and
                  Marios Fragkoulis and
                  Asterios Katsifodimos},
	title = {{S-QUERY:} Opening the Black Box of Internal Stream Processor State},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1314--1327},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00103},
	doi = {10.1109/ICDE53745.2022.00103},
	timestamp = {Fri, 05 Aug 2022 16:24:01 +0200},
	biburl = {https://dblp.org/rec/conf/icde/VerheijdeKFK22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Distributed streaming dataflow systems have evolved into scalable and fault-tolerant production-grade systems. Their applicability has departed from the mere analysis of streaming windows and complex-event processing, and now includes cloud applications and machine learning inference. Although the advancements in the state management of streaming systems have contributed significantly to their maturity, the internal state of streaming operators has been so far hidden from external applications. However, that internal state can be seen as a materialized view that can be used for analytics, monitoring, and debugging. In this paper we argue that exposing the internal state of streaming systems to outside applications by making it queryable, opens the road for novel use cases. To this end, we introduce S-QUERY: an approach and reference architecture where the state of stream processors can be queried - either live or through snapshots, achieving different isolation levels. We show how this new capability can be implemented in an existing open-source stream processor, and how queryable state can affect the performance of such a system. Our experimental evaluation suggests that the snapshot configuration adds only up to 8ms latency in the 99.99 th percentile and negligible increase in 0-90 th percentiles.}
}


@inproceedings{DBLP:conf/icde/LaoYZL22,
	author = {Yingjie Lao and
                  Peng Yang and
                  Weijie Zhao and
                  Ping Li},
	title = {Identification for Deep Neural Network: Simply Adjusting Few Weights!},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1328--1341},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00104},
	doi = {10.1109/ICDE53745.2022.00104},
	timestamp = {Fri, 19 Jan 2024 08:33:25 +0100},
	biburl = {https://dblp.org/rec/conf/icde/LaoYZL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Through the development of powerful algorithms and design tools, deep neural networks (DNNs) have recently approached or even surpassed human-level performance in many real-world applications. Nowadays, since a product-level DNN modeling requires a large amount of training data and expensive computing resources and thus DNN models are considered as valuable data, protecting the intellectual property (IP) of DNN builders becomes an important problem in the security domain. In this paper, we propose a novel watermarking approach that only requires adjusting a few weights, as opposed to prior works that embed watermarks via end-to-end training. The protected model with tiny parameter modifications can output pre-specified labels with carefully selected key samples as inputs, which serves as a strong proof of ownership. Besides, our methodology can be naturally extended to identification, i.e., embedding unique watermarks to identify different users. Watermark embedding is achieved by modifying a very small subset of parameters, guaranteeing a high fidelity while dramatically reducing the computational overhead. The experimental results demonstrate that the proposed algorithm can embed key samples with a high success rate, while well preserving the original functionality of the target model. We show that the proposed method is robust against various transformation attacks.}
}


@inproceedings{DBLP:conf/icde/KieuYGCZSJ22,
	author = {Tung Kieu and
                  Bin Yang and
                  Chenjuan Guo and
                  Razvan{-}Gabriel Cirstea and
                  Yan Zhao and
                  Yale Song and
                  Christian S. Jensen},
	title = {Anomaly Detection in Time Series with Robust Variational Quasi-Recurrent
                  Autoencoders},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1342--1354},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00105},
	doi = {10.1109/ICDE53745.2022.00105},
	timestamp = {Wed, 07 Dec 2022 23:09:59 +0100},
	biburl = {https://dblp.org/rec/conf/icde/KieuYGCZSJ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We propose variational quasi-recurrent autoencoders (VQRAEs) to enable robust and efficient anomaly detection in time series in unsupervised settings. The proposed VQRAEs employs a judiciously designed objective function based on robust divergences, including a, ß, and, -divergence, making it possible to separate anomalies from normal data without the reliance on anomaly labels, thus achieving robustness and fully unsupervised training. To better capture temporal dependencies in time series data, VQRAEs are built upon quasi-recurrent neural networks, which employ convolution and gating mechanisms to avoid the inefficient recursive computations used by classic recurrent neural networks. Further, VQRAEs can be extended to bi-directional Bi VQRAEs that utilize bi-directional information to further improve the accuracy. The above design choices make VQRAEs not only robust and thus accurate, but also efficient at detecting anomalies in streaming settings. Experiments on five real-world time series offer insight into the design properties of VQRAEs and demonstrate that VQRAEs are capable of outperforming state-of-the-art methods.}
}


@inproceedings{DBLP:conf/icde/GuWWLXWXYS22,
	author = {Tiankai Gu and
                  Chaokun Wang and
                  Cheng Wu and
                  Yunkai Lou and
                  Jingcao Xu and
                  Changping Wang and
                  Kai Xu and
                  Can Ye and
                  Yang Song},
	title = {HybridGNN: Learning Hybrid Representation for Recommendation in Multiplex
                  Heterogeneous Networks},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1355--1367},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00106},
	doi = {10.1109/ICDE53745.2022.00106},
	timestamp = {Wed, 12 Jun 2024 21:04:47 +0200},
	biburl = {https://dblp.org/rec/conf/icde/GuWWLXWXYS22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recently, graph neural networks have shown the superiority of modeling the complex topological structures in heterogeneous network-based recommender systems. Due to the diverse interactions among nodes and abundant semantics emerging from diverse types of nodes and edges, there is a bursting research interest in learning expressive node repre-sentations in multiplex heterogeneous networks. One of the most important tasks in recommender systems is to predict the potential connection between two nodes under a specific edge type (i.e., relationship). Although existing studies utilize explicit metapaths to aggregate neighbors, practically they only consider intra-relationship metapaths and thus fail to leverage the potential uplift by inter-relationship information. Moreover, it is not always straightforward to exploit inter-relationship metapaths comprehensively under diverse relationships, espe-cially with the increasing number of node and edge types. In addition, contributions of different relationships between two nodes are difficult to measure. To address the challenges, we propose HybridGNN, an end-to-end GNN model with hybrid aggregation flows and hierarchical attentions to fully utilize the heterogeneity in the multiplex scenarios. Specifically, HybridGNN applies a randomized inter-relationship exploration module to exploit the multiplexity property among different relationships. Then, our model leverages hybrid aggregation flows under intra-relationship metapaths and randomized exploration to learn the rich semantics. To explore the importance of different aggregation flow and take advantage of the multiplexity property, we bring forward a novel hierarchical attention module which leverages both metapath-Ievel attention and relationship-level attention. Extensive experimental results on five real-world datasets suggest that HybridGNN achieves the best performance compared to several state-of-the-art baselines (p < 0.01, t-test) with statistical significance.}
}


@inproceedings{DBLP:conf/icde/ChockchowwatSP22,
	author = {Supawit Chockchowwat and
                  Chaitanya Sood and
                  Yongjoo Park},
	title = {Airphant: Cloud-oriented Document Indexing},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1368--1381},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00107},
	doi = {10.1109/ICDE53745.2022.00107},
	timestamp = {Sat, 30 Sep 2023 09:44:50 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ChockchowwatSP22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Modern data warehouses can scale compute nodes independently of storage. These systems persist their data on cloud storage, which is always available and cost-efficient. Ad-hoc compute nodes then fetch necessary data on-demand from cloud storage. This ability to quickly scale or shrink data systems is highly beneficial if query workloads may change over time. We apply this new architecture to search engines with a focus on optimizing their latencies in cloud environments. However, simply placing existing search engines (e.g., Apache Lucene) on top of cloud storage significantly increases their end-to-end query latencies (i.e., more than 6 seconds on average in one of our studies). This is because their indexes can incur multiple network round-trips due to their hierarchical structure (e.g., skip lists, B-trees, learned indexes). To address this issue, we develop a new statistical index, called IoU Sketch. For lookup, IoU Sketch makes multiple asynchronous network requests in parallel. While IoU Sketch may fetch more bytes than existing indexes, it significantly reduces the index lookup time because parallel requests do not block each other. Based on IoU Sketch, we built an end-to-end search engine called Airphant; we describe how Airphant builds, optimizes, and manages IoU Sketch, and ultimately supports keyword-based querying. In our experiments with four real datasets, Airphant's average end-to-end latencies are between 13 milliseconds and 300 milliseconds, up to 8.97× faster than Apache Lucence and 113.39× faster than Elasticsearch.}
}


@inproceedings{DBLP:conf/icde/SundarmurthyDKN22,
	author = {Bruhathi Sundarmurthy and
                  Harshad Deshmukh and
                  Paris Koutris and
                  Jeffrey F. Naughton},
	title = {Salvaging failing and straggling queries},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1382--1395},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00108},
	doi = {10.1109/ICDE53745.2022.00108},
	timestamp = {Fri, 05 Aug 2022 16:24:02 +0200},
	biburl = {https://dblp.org/rec/conf/icde/SundarmurthyDKN22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Interactive time responses are a crucial requirement for users analyzing large amounts of data, typically stored in a relational style data-warehouse where data is partitioned across thousands of nodes for high efficiency and throughput. However, consistently providing quick responses remains a big challenge for two reasons: (1) with data distributed across thousands of nodes, it is highly likely that some nodes are unavailable or are very slow during query execution and, (2) large number of users result in high resource contention which exacerbates the problem of slow and failing nodes. In such situations, systems typically straggle or fail the query resulting in higher latencies and wastage of resources. In this paper, we propose a novel solution to alleviate the failure/straggling problem: use the intermediate results from the partial query execution over available data, and exploit the statistical properties of efficiently partitioned data, particularly, co-hash partitioned data, to provide approximate answers along with confidence bounds. The proposed approach handles aggregate queries that involve joins, group bys, having clauses and a subclass of nested subqueries, covering a large portion of analytical queries. We validate our approach through extensive experiments on the TPC-H dataset and we observe that even with a low data availability of 1%, our proposed solution provides answers with less than 5% error.}
}


@inproceedings{DBLP:conf/icde/LuZZY22,
	author = {Zhao Lu and
                  Yuanyuan Zhu and
                  Ming Zhong and
                  Jeffrey Xu Yu},
	title = {On Time-optimal (k, p)-core Community Search in Dynamic Graphs},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1396--1407},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00109},
	doi = {10.1109/ICDE53745.2022.00109},
	timestamp = {Mon, 05 Feb 2024 20:31:12 +0100},
	biburl = {https://dblp.org/rec/conf/icde/LuZZY22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Community search aims to find cohesive subgraphs containing certain vertices, attracting increasing interest recently. However, existing cohesive models such as k-core mainly focus on the dense connections inside the community, and neglect the interactions with the vertices outside. In this paper, we study the (k,p) -core community search (KPCS) problem in dynamic graphs, i.e., find the maximal connected subgraph containing a query vertex where each vertex has at least k neighbors and at least p fraction of its neighbors in the subgraph. Such fraction and connectivity constraints bring non-trivial challenges to the online community search in dynamic graphs. Thus, we design a space-efficient\nO(m)\nwhere\nm\nis the edge number) index KPForest which can support time-optimal (k,p) -core community search. We also propose novel construction and maintenance algorithms to record and update the (k,p) value and the connectivity information for dynamic graphs correctly and efficiently. Extensive experimental studies on ten real-world datasets show that our index can support community search with two orders of magnitude speedup at a small cost of construction and maintenance compared with the baseline algorithms.}
}


@inproceedings{DBLP:conf/icde/SandurPVAJ22,
	author = {Atul Sandur and
                  Chanho Park and
                  Stavros Volos and
                  Gul Agha and
                  Myeongjae Jeon},
	title = {Jarvis: Large-scale Server Monitoring with Adaptive Near-data Processing},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1408--1422},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00110},
	doi = {10.1109/ICDE53745.2022.00110},
	timestamp = {Thu, 28 Mar 2024 08:26:14 +0100},
	biburl = {https://dblp.org/rec/conf/icde/SandurPVAJ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Rapid detection and mitigation of issues that impact performance and reliability are paramount for large-scale online services. For real-time detection of such issues, datacenter operators use a stream processor and analyze streams of monitoring data collected from servers (referred to as data source nodes) and their hosted services. The timely processing of incoming streams requires the network to transfer massive amounts of data, and significant compute resources to process it. These factors often create bottlenecks for stream analytics. To help overcome these bottlenecks, current monitoring systems employ near-data processing by either computing an optimal query partition based on a cost model or using model-agnostic heuristics. Optimal partitioning is computationally expensive, while model-agnostic heuristics are iterative and search over a large solution space. We combine these approaches by using model-agnostic heuristics to improve the partitioning solution from a model-based heuristic. Moreover, current systems use operator-level partitioning: if a data source does not have sufficient resources to execute an operator on all records, the operator is executed only on the stream processor. Instead, we perform data-level partitioning—i.e., we allow an operator to be executed both on a stream processor and data sources. We implement our algorithm in a system called Jarvis, which enables quick adaptation to dynamic resource conditions. Our evaluation on a diverse set of monitoring workloads suggests that Jarvis converges to a stable query partition within seconds of a change in node resource conditions. Compared to current partitioning strategies, Jarvis handles up to 75% more data sources while improving throughput in resource-constrained scenarios by 1.2-4.4×.}
}


@inproceedings{DBLP:conf/icde/ShetiyaSAD22,
	author = {Suraj Shetiya and
                  Ian P. Swift and
                  Abolfazl Asudeh and
                  Gautam Das},
	title = {Fairness-Aware Range Queries for Selecting Unbiased Data},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1423--1436},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00111},
	doi = {10.1109/ICDE53745.2022.00111},
	timestamp = {Tue, 07 May 2024 20:05:36 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ShetiyaSAD22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We are being constantly judged by automated decision systems that have been widely criticised for being discriminatory and unfair. Since an algorithm is only as good as the data it works with, biases in the data can significantly amplify unfairness issues. In this paper, we take initial steps towards integrating fairness conditions into database query processing and data management systems. Specifically, we focus on selection bias in range queries. We formally define the problem of fairness-aware range queries as obtaining a fair query which is most similar to the user's query. We propose a sub-linear time algorithm for single-predicate range queries and efficient algorithms for multi-predicate range queries. Our empirical evaluation on real and synthetic datasets confirms the effectiveness and efficiency of our proposal.}
}


@inproceedings{DBLP:conf/icde/LyuTGTHZL22,
	author = {Fuyuan Lyu and
                  Xing Tang and
                  Huifeng Guo and
                  Ruiming Tang and
                  Xiuqiang He and
                  Rui Zhang and
                  Xue Liu},
	title = {Memorize, Factorize, or be Naive: Learning Optimal Feature Interaction
                  Methods for {CTR} Prediction},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1450--1462},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00113},
	doi = {10.1109/ICDE53745.2022.00113},
	timestamp = {Sun, 06 Oct 2024 21:04:58 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LyuTGTHZL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Click-through rate prediction is one of the core tasks in commercial recommender systems. It aims to predict the prob-ability of a user clicking a particular item given user and item features. As feature interactions bring in non-linearity, they are widely adopted to improve the performance of CTR prediction models. Therefore, effectively modelling feature interactions has attracted much attention in both the research and industry field. The current approaches can generally be categorized into three classes: (i) naïve methods, which do not model feature interactions and only use original features; (ii) memorized methods, which memorize feature interactions by explicitly viewing them as new features and assigning trainable embeddings; (iii) factorized meth-ods, which learn latent vectors for original features and implicitly model feature interactions through factorization functions. Studies have shown that modelling feature interactions by one of these methods alone are suboptimal due to the unique characteristics of different feature interactions. To address this issue, we first propose a general framework called OptInter which finds the most suitable modelling method for each feature interaction. Different state-of-the-art deep CTR models can be viewed as instances of OptInter. To realize the functionality of OptInter, we also introduce a learning algorithm that automatically searches for the optimal modelling method. We conduct extensive experiments on four large datasets, including three public and one private. Experimental results demonstrate the effectiveness of OptInter. Because our OptInter finds the optimal modelling method for each feature interaction, our experiments show that OptInter improves the best performed state-of-the-art baseline deep CTR models by up to 2.21%. Compared to the memorized method, which also outperforms baselines, we reduce up to 91% parameters. In addition, we conduct several ablation studies to investigate the influence of different components of OptInter. Finally, we provide interpretable discussions on the results of OptInter.}
}


@inproceedings{DBLP:conf/icde/GazzazCN22,
	author = {Samaa Gazzaz and
                  Vishal Chakraborty and
                  Faisal Nawab},
	title = {Croesus: Multi-Stage Processing and Transactions for Video-Analytics
                  in Edge-Cloud Systems},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1463--1476},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00114},
	doi = {10.1109/ICDE53745.2022.00114},
	timestamp = {Fri, 05 Aug 2022 16:24:01 +0200},
	biburl = {https://dblp.org/rec/conf/icde/GazzazCN22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Emerging edge applications require both a fast response latency and complex processing. This is infeasible with-out expensive hardware that can process complex operations-such as object detection-within a short time. Many approach this problem by addressing the complexity of the models-via model compression, pruning and quantization-or compressing the input. In this paper, we propose a different perspective when addressing the performance challenges. Croesus is a multi-stage approach to edge-cloud systems that provides the ability to find the balance between accuracy and performance. Croesus consists of two stages (that can be generalized to multiple stages): an initial and a final stage. The initial stage performs the compu-tation in real-time using approximate/best-effort computation at the edge. The final stage performs the full computation at the cloud, and uses the results to correct any errors made at the initial stage. In this paper, we demonstrate the implications of such an approach on a video analytics use-case and show how multi-stage processing yields a better balance between accuracy and performance. Moreover, we study the safety of multi-stage transactions via two proposals: multi-stage serializability (MS-SR) and multi-stage invariant confluence with Apologies (MS-IA).}
}


@inproceedings{DBLP:conf/icde/WuDK22,
	author = {Renjie Wu and
                  Audrey Der and
                  Eamonn J. Keogh},
	title = {When is Early Classification of Time Series Meaningful? (Extended
                  Abstract)},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1477--1478},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00115},
	doi = {10.1109/ICDE53745.2022.00115},
	timestamp = {Sun, 02 Oct 2022 16:04:37 +0200},
	biburl = {https://dblp.org/rec/conf/icde/WuDK22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The problem of early classification of time series (ETSC) generalizes classic time series classification to ask if we can classify a time series subsequence with sufficient accuracy and confidence after seeing only some prefix of a target pattern. The idea is that the earlier classification would allow us to take immediate actions, such as sounding an alarm or applying the brakes in an automobile. In this work, we make a surprising claim. In spite of the fact that there are dozens of papers on ETSC, it is not clear that any of them could ever work in a real-world setting. The issue is not with the algorithms per se, but with the vague and underspecified problem definition.}
}


@inproceedings{DBLP:conf/icde/WuK22,
	author = {Renjie Wu and
                  Eamonn J. Keogh},
	title = {Current Time Series Anomaly Detection Benchmarks are Flawed and are
                  Creating the Illusion of Progress (Extended Abstract)},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1479--1480},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00116},
	doi = {10.1109/ICDE53745.2022.00116},
	timestamp = {Sun, 02 Oct 2022 16:04:37 +0200},
	biburl = {https://dblp.org/rec/conf/icde/WuK22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Most of the time series anomaly detection papers tested on a handful of popular benchmark datasets, created by Yahoo [1], Numenta [2], NASA [3] or Pei's Lab (OMNI) [4], etc. There is a strong implicit assumption that doing well on these public datasets is a sufficient condition to declare an anomaly detection algorithm is useful. In this work, we make a surprising claim. The majority of the individual exemplars in these dataset suffers from one or more of four flaws: triviality, unrealistic anomaly density, mislabeled ground truth and run-to-failure bias. Because of these four flaws, we believe that most published comparisons of anomaly detection algorithms may be unreliable, and more importantly, much of the apparent progress in recent years may be illusionary.}
}


@inproceedings{DBLP:conf/icde/WangGCL22,
	author = {Xinrui Wang and
                  Hong Gao and
                  Zhipeng Cai and
                  Jianzhong Li},
	title = {Who Should Deserve Investment? Attractive Individual and Group Search
                  in Dynamic Information Networks (Extended Abstract)},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1481--1482},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00117},
	doi = {10.1109/ICDE53745.2022.00117},
	timestamp = {Fri, 05 Aug 2022 16:24:01 +0200},
	biburl = {https://dblp.org/rec/conf/icde/WangGCL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Analyzing dynamic information networks, which contain evolving objects and links, has attracted much attention in recent years. For sales companies, recruiting staff who are socialites would help to increase sales volume since such staff often sell more. For universities, employing active collaborators who are productive and well connected to many different scholars over time could bring many benefits to their development. However, no previous work has focused on socialites and active collaborators who are worthy of investment in reality. In this paper, we advocate attractive individuals to model such special objects, and introduce attractive groups to represent groups of well-connected attractive individuals. Then we propose several algorithms to search attractive individuals and groups. Extensive experiments show high performance of our methods and the significance of attractive individuals and groups in reality.}
}


@inproceedings{DBLP:conf/icde/YuLPC22,
	author = {Kaiqiang Yu and
                  Cheng Long and
                  Deepak P and
                  Tanmoy Chakraborty},
	title = {On Efficient Large Maximal Biplex Discovery (Extended abstract)},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1483--1484},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00118},
	doi = {10.1109/ICDE53745.2022.00118},
	timestamp = {Tue, 22 Oct 2024 20:38:20 +0200},
	biburl = {https://dblp.org/rec/conf/icde/YuLPC22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cohesive subgraph discovery is an important problem in bipartite graph mining. In this paper, we focus on one kind of cohesive structure, called k\n-biplex, where each vertex of one side is disconnected from at most k\nvertices of the other side. We consider the large maximal k\n-biplex enumeration problem which is to list all those maximal k\n-biplexes with the number of vertices at each side at least a non-negative integer \\theta\n. This formulation aims to find non-redundant results by excluding non-maximal ones and has various applications. Existing approaches suffer from massive redundant computations and can only run on small and moderate datasets. Towards improving scalability, we propose an efficient tree-based algorithm with two advanced strategies and powerful pruning techniques. Experimental results show the superiority of our algorithm over existing approaches.}
}


@inproceedings{DBLP:conf/icde/WeiWC22,
	author = {Shiwei Wei and
                  Yuping Wang and
                  Yiu{-}ming Cheung},
	title = {A Branch Elimination-based Efficient Algorithm for Large-scale Multiple
                  Longest Common Subsequence Problem (Extended Abstract)},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1485--1486},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00119},
	doi = {10.1109/ICDE53745.2022.00119},
	timestamp = {Fri, 05 Aug 2022 16:24:02 +0200},
	biburl = {https://dblp.org/rec/conf/icde/WeiWC22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Searching Longest Common Subsequences (LCS) of Multi-ple (i.e., three or more) sequences, denoted as MLCS for short, is a fundamental problem in computational biology, pattern recognition, file comparison and information retrieval, to name a few. Basically, an MLCS problem is more challenging than the LCS of two sequences which can be solved by a dynamic programming (DP) method whose running time and memory space are both O(n^{2})\n, where n\nis the length of the sequences.}
}


@inproceedings{DBLP:conf/icde/ChangXLPB22,
	author = {Zhao Chang and
                  Dong Xie and
                  Feifei Li and
                  Jeff M. Phillips and
                  Rajeev Balasubramonian},
	title = {Efficient and Oblivious Query Processing for Range and kNN Queries
                  (Extended Abstract)},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1487--1488},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00120},
	doi = {10.1109/ICDE53745.2022.00120},
	timestamp = {Sat, 30 Sep 2023 09:44:49 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ChangXLPB22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Oblivious RAMs (ORAMs) are proposed to completely hide access patterns. However, most ORAM constructions are expensive and not suitable to deploy in a database for supporting query processing over large data. In this work, we design a practical oblivious query processing framework to enable efficient query processing over a cloud database. In particular, we focus on processing multiple range and kNN queries asynchronously and concurrently with high throughput. The key idea is to integrate indices into ORAM which leverages a suite of optimization techniques (e.g., oblivious batch processing and caching). Our construction shows an order of magnitude speedup in comparison with other baselines over large datasets.}
}


@inproceedings{DBLP:conf/icde/SunLJC22,
	author = {Luming Sun and
                  Cuiping Li and
                  Tao Ji and
                  Hong Chen},
	title = {{MOSE:} {A} Monotonic Selectivity Estimator Using Learned {CDF} (Extended
                  abstract)},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1489--1490},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00121},
	doi = {10.1109/ICDE53745.2022.00121},
	timestamp = {Fri, 03 Mar 2023 09:55:19 +0100},
	biburl = {https://dblp.org/rec/conf/icde/SunLJC22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The accuracy of selectivity estimation is of vital importance to create good query plans in database management systems. We propose MOSE, a learning-based MOnotonic Selectivity Estimator, to provide accurate, reliable, and efficient selectivity estimation for query optimization.}
}


@inproceedings{DBLP:conf/icde/ChenY22,
	author = {Lin Chen and
                  Jihong Yu},
	title = {Multiset Membership Lookup in Large Datasets (Extended abstract)},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1491--1492},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00122},
	doi = {10.1109/ICDE53745.2022.00122},
	timestamp = {Mon, 05 Feb 2024 20:31:12 +0100},
	biburl = {https://dblp.org/rec/conf/icde/ChenY22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We investigate multiset membership lookup prob-lem, a pivotal functionality in many computing and networking paradigms. We devise compact data structures and lookup algorithms that are amendable for hardware implementation, while guaranteeing high lookup accuracy and supporting interactive query processing. We first propose multi-hash color table, a variant of Bloom filter, to encode subset IDs compactly and map the ID of an item to its subset ID. We further construct a more balanced data structure called balanced multi-hash color table to improve the compactness by integrating load balancing.}
}


@inproceedings{DBLP:conf/icde/ChenWSW22,
	author = {Chen Chen and
                  Yanping Wu and
                  Renjie Sun and
                  Xiaoyang Wang},
	title = {Maximum Signed {\textdollar}{\textbackslash}theta{\textdollar}-Clique
                  Identification in Large Signed Graphs (Extended abstract)},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1493--1494},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00123},
	doi = {10.1109/ICDE53745.2022.00123},
	timestamp = {Sun, 02 Oct 2022 16:04:35 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ChenWSW22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Maximum clique identification is a fundamental problem for many domains. In real-world applications, signed information, e.g., friend and enemy, naturally exists in graphs. However, most existing research focuses on unsigned graph analysis. In this paper, we propose a new clique model for signed graphs, named signed\nθ\n-clique. We show that the problem of identifying the maximum signed\nθ\n-clique is NP-hard. To scale for large signed graphs, novel pruning rules and search strategies are developed. Extensive experiments are conducted on 8 real-world graphs to verify the advantages of proposed model and techniques.}
}


@inproceedings{DBLP:conf/icde/SunCWW22,
	author = {Renjie Sun and
                  Chen Chen and
                  Xiaoyang Wang and
                  Xun Wang},
	title = {Stable Community Detection in Signed Social Networks (Extended abstract)},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1495--1496},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00124},
	doi = {10.1109/ICDE53745.2022.00124},
	timestamp = {Sun, 02 Oct 2022 16:04:37 +0200},
	biburl = {https://dblp.org/rec/conf/icde/SunCWW22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Community detection is a fundamental problem in graph analysis, while most existing research focuses on unsigned graphs. In many applications, networks involve both positive and negative connections. It is important to exploit the signed information to identify more stable communities. In this paper, we propose a novel model, named stable k-core, to measure the stability of a community in signed graphs by leveraging the concept of balance theory. We show that the problem of finding the maximum stable k-core is NP-hard. Advanced approaches are proposed to accelerate the processing. Experiments on 6 signed networks are conducted to verify the efficiency and effectiveness of proposed model and techniques.}
}


@inproceedings{DBLP:conf/icde/ZhaoDCZTY22,
	author = {Shu Zhao and
                  Ziwei Du and
                  Jie Chen and
                  Yanping Zhang and
                  Jie Tang and
                  Philip S. Yu},
	title = {Hierarchical Representation Learning for Attributed Networks},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1497--1498},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00125},
	doi = {10.1109/ICDE53745.2022.00125},
	timestamp = {Fri, 05 Aug 2022 16:24:02 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhaoDCZTY22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Network representation learning, also called network embedding, aiming to learn low dimensional vectors for nodes while preserving essential properties of the network, such as structural similarity, attribute similarity, etc. The low-dimensional vector of the node can be used as the input of the machine learning algorithm and applied to a lot of downstream tasks, such as node classification and link prediction, benefits plenty of practical applications.}
}


@inproceedings{DBLP:conf/icde/LiangSZZC22,
	author = {Shuang Liang and
                  Jie Shao and
                  Dongyang Zhang and
                  Jiasheng Zhang and
                  Bin Cui},
	title = {{DRGI:} Deep Relational Graph Infomax for Knowledge Graph Completion:
                  (Extended Abstract)},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1499--1500},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00126},
	doi = {10.1109/ICDE53745.2022.00126},
	timestamp = {Fri, 15 Nov 2024 20:05:33 +0100},
	biburl = {https://dblp.org/rec/conf/icde/LiangSZZC22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recently, many knowledge graph embedding models for knowledge graph completion have been proposed, ranging from the initial translation-based models such as TransE to recent convolutional neural network (CNN) models such as ConvE. However, these models only focus on semantic information of knowledge graph and neglect the natural graph structure information. Although graph convolutional network (GCN)-based models for knowledge graph embedding have been introduced to address this issue, they still suffer from fact incompleteness, resulting in the unconnectedness of knowledge graph. To solve this problem, we propose a novel model called deep relational graph infomax (DRGI) with mutual information (MI) maximization which takes the benefit of complete structure information and semantic information together. Specifically, the proposed DRGI consists of two encoders which are two identical adaptive relational graph attention networks (ARGATs), corresponding to catching semantic information and complete structure information respectively. Our method establishes new state-of-the-art on the standard datasets for knowledge graph completion.}
}


@inproceedings{DBLP:conf/icde/ZhangCWYTC22,
	author = {Dongxiang Zhang and
                  Zhihao Chang and
                  Sai Wu and
                  Ye Yuan and
                  Kian{-}Lee Tan and
                  Gang Chen},
	title = {Continuous Trajectory Similarity Search for Online Outlier Detection
                  (Extended Abstract)},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1501--1502},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00127},
	doi = {10.1109/ICDE53745.2022.00127},
	timestamp = {Sun, 30 Apr 2023 12:18:05 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhangCWYTC22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we study a new variant of trajectory similarity search from the context of continuous query processing. Given a moving object from s\nto d\n, following a reference route T_{r}\n, we monitor the trajectory similarity between the reference route and the current partial route at each timestamp for online detour detection. We consider deviation calculation in both Euclidean space and road networks. Furthermore, we propose efficient incremental processing strategies to facilitate continuous query processing for moving objects. Our experiments are conducted on multiple real datasets and the experimental results verify the efficiency of our query processing algorithms.}
}


@inproceedings{DBLP:conf/icde/YangWWZ22,
	author = {Peizhong Yang and
                  Lizhen Wang and
                  Xiaoxuan Wang and
                  Lihua Zhou},
	title = {{SCPM-CR:} {A} Novel Method for Spatial Co-location Pattern Mining
                  with Coupling Relation Consideration},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1503--1504},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00128},
	doi = {10.1109/ICDE53745.2022.00128},
	timestamp = {Fri, 15 Mar 2024 17:11:59 +0100},
	biburl = {https://dblp.org/rec/conf/icde/YangWWZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Spatial co-location pattern mining (SCPM) aims to discover subsets of spatial features frequently located in nearby geographic space. Previous studies of SCPM only concern the inter-features association of a pattern, but neglect the interesting intra-feature behavior. In this paper, we propose spatial co-location pattern mining with coupling relation consideration (SCPM-CR) to capture complex relations in a co-location. Specifically, InterPCI is proposed to capture the inter-features coupling in a pattern, and IntraCAI is designed to capture the congregating behavior of intra-feature objects. Based on the anti-monotone property of InterPCI, a general framework which searches for patterns in a level-wise manner is suggested. To tackle the participating object search problem, a candidate-and-search algorithm with a heuristic backtracking search is proposed, namely CS-HBS. Extensive experiments are conducted to demonstrate the superiority of SCPM-CR, and also to validate the efficiency and scalability of CS-HBS.}
}


@inproceedings{DBLP:conf/icde/ChanLLW22,
	author = {Harry Kai{-}Ho Chan and
                  Shengxin Liu and
                  Cheng Long and
                  Raymond Chi{-}Wing Wong},
	title = {Cost-Aware and Distance-Constrained Collective Spatial Keyword Query
                  (Extended Abstract)},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1505--1506},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00129},
	doi = {10.1109/ICDE53745.2022.00129},
	timestamp = {Tue, 22 Oct 2024 20:38:20 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ChanLLW22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the proliferation of location-based services, geo-textual data is becoming ubiquitous. Objects involved in geo-textual data include geospatial locations, textual descriptions or keywords, and various attributes (e.g., a point-of-interest has its expenses and users' ratings). Many types of spatial keyword queries have been proposed on geo-textual data. Among them, one prominent type is to find, for a query consisting of a query location and some query keywords, a set of multiple objects such that the objects in the set collectively cover all the query keywords, and the object set is of good quality according to some criterion. Existing studies define the criterion either based on the geospatial information of the objects solely, or simply treat the geospatial information and the attribute information of the objects together without differentiation though they may have different semantics and scales. As a result, they cannot provide users flexibility to express finer grained preferences on the objects. In this paper, we propose a new criterion which is to find a set of objects where the distance (defined based on the geospatial information) is at most a threshold specified by users and the cost (defined based on the attribute information) is optimized. We develop a suite of two algorithms including an exact algorithm and an approximation algorithm with provable guarantees for the problem. We conducted extensive experiments on both real and synthetic datasets, which verified the efficiency and effectiveness of proposed algorithms.}
}


@inproceedings{DBLP:conf/icde/NadalARVV22,
	author = {Sergi Nadal and
                  Alberto Abell{\'{o}} and
                  Oscar Romero and
                  Stijn Vansummeren and
                  Panos Vassiliadis},
	title = {Graph-Driven Federated Data Management (Extended Abstract)},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1507--1508},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00130},
	doi = {10.1109/ICDE53745.2022.00130},
	timestamp = {Tue, 21 Mar 2023 20:50:55 +0100},
	biburl = {https://dblp.org/rec/conf/icde/NadalARVV22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Modern data analysis applications require the ability to provide on-demand integration of data sources while offering a user-friendly query interface. Traditional methods for answering queries using views, focused on a rather static setting, fail to address such requirements. To overcome these issues, we propose a full fledged, GLAV-based data integration approach based on graph-based constructs. The extensibility of graphs allows us to extend the traditional framework for data integration with view definitions. Furthermore, we also propose a query language based on subgraphs. We tackle query answering via a query rewriting algorithm based on well-known algorithms for answering queries using views. We experimentally show that our method yields good performance with no significant overhead.}
}


@inproceedings{DBLP:conf/icde/HuynhTNTSYN22,
	author = {Thanh Trung Huynh and
                  Duong Chi Thang and
                  Thanh Tam Nguyen and
                  Van Vinh Tong and
                  Abdul Sattar and
                  Hongzhi Yin and
                  Quoc Viet Hung Nguyen},
	title = {Network Alignment with Holistic Embeddings (Extended Abstract)},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1509--1510},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00131},
	doi = {10.1109/ICDE53745.2022.00131},
	timestamp = {Sun, 02 Oct 2022 16:04:35 +0200},
	biburl = {https://dblp.org/rec/conf/icde/HuynhTNTSYN22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Network alignment is the task of identifying topo-logically and semantically similar nodes across (two) different networks. However, existing alignment models either cannot handle large-scale graphs or fail to leverage different types of network information or modalities. In this paper, we pro-pose a novel end-to-end alignment framework that can lever-age different modalities to compare and align network nodes in an efficient way. A comprehensive evaluation on various datasets shows that our technique outperforms state-of-the-art approaches. Our source code is available at https://github.com/thanhtrunghuynh93/holisticEmbeddingsNA.}
}


@inproceedings{DBLP:conf/icde/WangWQCZ22,
	author = {Xubo Wang and
                  Dong Wen and
                  Lu Qin and
                  Lijun Chang and
                  Wenjie Zhang},
	title = {ScaleG: {A} Distributed Disk-based System for Vertex-centric Graph
                  Processing (Extended Abstract)},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1511--1512},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00132},
	doi = {10.1109/ICDE53745.2022.00132},
	timestamp = {Mon, 20 Nov 2023 13:58:36 +0100},
	biburl = {https://dblp.org/rec/conf/icde/WangWQCZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Designing disk-based distributed graph systems has drawn a lot of research due to the strong expressiveness of the graph model and rapidly increasing graph volume. However, several challenges still exist in achieving both high computational efficiency and low network communication under the limitation of memory. In this paper, we design a novel distributed disk-based graph processing system, ScaleG, with a series of user-friendly programming interfaces. We propose several techniques to reduce both disk I/Os in each machine and message I/Os via the network. We manage all messages in memory and bound the volume of all messages by the number of vertices. We also carefully design the data structure to support partial computation and automatic vertex activation. We conduct extensive experiments on real-world big graphs to show the high efficiency of our system.}
}


@inproceedings{DBLP:conf/icde/GuanHC22,
	author = {Jiewen Guan and
                  Xin Huang and
                  Bilian Chen},
	title = {Community-aware Social Recommendation: {A} Unified {SCSVD} Framework
                  (Extended Abstract)},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1513--1514},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00133},
	doi = {10.1109/ICDE53745.2022.00133},
	timestamp = {Thu, 15 Dec 2022 10:00:42 +0100},
	biburl = {https://dblp.org/rec/conf/icde/GuanHC22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Social recommendation aims at improving recommendation performance by incorporating social information. Most existing social recommender systems only utilize the one-hop interpersonal social information, neglecting the community structure emerged in social networks, which may contain additional conducive information. In this paper, we propose a unified Simultaneous Community detection and Singular Value Decomposition (SCSVD) framework for community-aware social recommendation. An efficient optimization algorithm is also derived to optimize SCSVD, with an analysis of convergence and computational complexity. Comprehensive experimental results on three real-world benchmark datasets demonstrate the effectiveness of SCSVD, over both traditional matrix factorization based recommendation models and advanced neural network based recommendation models.}
}


@inproceedings{DBLP:conf/icde/DaiLWMZY22,
	author = {Qiangqiang Dai and
                  Rong{-}Hua Li and
                  Guoren Wang and
                  Rui Mao and
                  Zhiwei Zhang and
                  Ye Yuan},
	title = {Core Decomposition on Uncertain Graphs Revisited (Extended Abstract)},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1515--1516},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00134},
	doi = {10.1109/ICDE53745.2022.00134},
	timestamp = {Mon, 05 Feb 2024 20:31:13 +0100},
	biburl = {https://dblp.org/rec/conf/icde/DaiLWMZY22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Core decomposition on uncertain graphs is shown to be a key problem in graph analysis. However, existing algorithms for solving this problem are based on a peeling algorithm with the dynamically updating technique, which can lead to relatively large errors due to the inaccuracy of the recursive floating-point number division operations. In this paper, we first develop two novel algorithms, a bottom-up approach and a top-down approach, which do not involve any floating-point number division operations to guarantee correctness. Then, we develop a parallel version for each approach to deal with large graphs. Extensive experimental results evidence the efficiency, effectiveness, and scalability of our proposed algorithms.}
}


@inproceedings{DBLP:conf/icde/Domingo-FerrerS22,
	author = {Josep Domingo{-}Ferrer and
                  Jordi Soria{-}Comas},
	title = {Multi-Dimensional Randomized Response},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1517--1518},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00135},
	doi = {10.1109/ICDE53745.2022.00135},
	timestamp = {Fri, 05 Aug 2022 16:24:01 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Domingo-FerrerS22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In our data world, a host of not necessarily trusted controllers gather data on individual subjects. To preserve her privacy and, more generally, her informational self-determination, the individual has to be empowered by giving her agency on her own data. Maximum agency is afforded by local anonymization, that allows each individual to anonymize her own data before handing them to the data controller. Randomized response (RR) is a local anonymization approach able to yield multi-dimensional full sets of anonymized microdata that are valid for exploratory analysis and machine learning. This is so because an unbiased estimate of the distribution of the true data of individuals can be obtained from their pooled randomized data. Furthermore, RR offers rigorous privacy guarantees. The main weakness of RR is the curse of dimensionality when applied to several attributes: as the number of attributes grows, the accuracy of the estimated true data distribution quickly degrades. We propose several complementary approaches to mitigate the dimensionality problem. First, we present two basic protocols, separate RR on each attribute and joint RR for all attributes, and discuss their limitations. Then we introduce an algorithm to form clusters of attributes so that attributes in different clusters can be viewed as independent and joint RR can be performed within each cluster. After that, we introduce an adjustment algorithm for the randomized data set that repairs some of the accuracy loss due to assuming independence between attributes when using RR separately on each attribute or due to assuming independence between clusters in cluster-wise RR. We also present empirical work to illustrate the proposed methods.}
}


@inproceedings{DBLP:conf/icde/JiangCWYFCTSS22,
	author = {Renhe Jiang and
                  Zekun Cai and
                  Zhaonan Wang and
                  Chuang Yang and
                  Zipei Fan and
                  Quanjun Chen and
                  Kota Tsubouchi and
                  Xuan Song and
                  Ryosuke Shibasaki},
	title = {DeepCrowd: {A} Deep Model for Large-Scale Citywide Crowd Density and
                  Flow Prediction (Extended abstract)},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1519--1520},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00136},
	doi = {10.1109/ICDE53745.2022.00136},
	timestamp = {Sat, 30 Sep 2023 09:44:50 +0200},
	biburl = {https://dblp.org/rec/conf/icde/JiangCWYFCTSS22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Predicting the density and flow of the crowd at a citywide level is significant for city management. By meshing a large urban area to a number of fine-grained mesh-grids, citywide crowd and traffic information in a continuous time period can be represented with 4D tensor (Timestep, Height, Width, Channel). Based on this, we revisit the density and in-out flow prediction problem and publish a new aggregated human mobility dataset generated from a real-world smartphone application. Compared with the existing ones, our dataset has larger mesh-grid number, finer-grained mesh size, and higher user sample. Towards such kind of large-scale crowd dataset, we propose a novel deep learning model called DeepCrowd by designing pyramid architectures and high-dimensional attention mechanism based on Convolutional LSTM. Both the datasets and codes are made available at https://github.com/deepkashiwa20/DeepCrowd.}
}


@inproceedings{DBLP:conf/icde/BhowmickDM22a,
	author = {Satadisha Saha Bhowmick and
                  Eduard C. Dragut and
                  Weiyi Meng},
	title = {TwiCS: Twitter Stream Entity Mention Detection (Extended Abstract)},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1521--1522},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00137},
	doi = {10.1109/ICDE53745.2022.00137},
	timestamp = {Fri, 05 Aug 2022 16:24:01 +0200},
	biburl = {https://dblp.org/rec/conf/icde/BhowmickDM22a.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we propose a system TwiCS for Entity Mention Detection (EMD) and Entity Detection (ED) in streaming environments. TwiCS employs a computationally light two-phase process: (1) exploit simple (low computation) syntactic cues to suggest Entity Mention (EM) candidates and (2) use occurrence mining to classify candidates according to their likelihood of being true EMs. Our experiments show that on average TwiCS improves effectiveness by 14.6%, while achieving at least 2.64 times higher throughput, when compared to several state-of-the-art systems.}
}


@inproceedings{DBLP:conf/icde/QiWZ22,
	author = {Zhixin Qi and
                  Hongzhi Wang and
                  Haoran Zhang},
	title = {A Dual-Store Structure for Knowledge Graphs (Extended Abstract)},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1523--1524},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00138},
	doi = {10.1109/ICDE53745.2022.00138},
	timestamp = {Tue, 30 Apr 2024 17:03:24 +0200},
	biburl = {https://dblp.org/rec/conf/icde/QiWZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Existing knowledge graph stores are classified to relational stores and native graph stores. Relational stores are able to store large-scale knowledge graphs and convenient in updating data, but the query performance weakens obviously when the selectivity of a knowledge graph query is large. Graph stores are efficient in processing complex knowledge graph queries, but they are inapplicable to manage a large-scale knowledge graph due to limited storage budgets or inflexible updating process. Motivated by this, we propose a dual-store structure which leverages a graph store to accelerate the complex query process in the relational store. However, it is challenging to determine that when we transfer which data partitions from relational store to graph store. To address this problem, we derive a physical design tuner DOTIL based on reinforcement learning. Experimental results demonstrate that the dual-store structure improves query performance up to average 50.11% compared with the most commonly used relational stores.}
}


@inproceedings{DBLP:conf/icde/SunWJHXHLZQZ22,
	author = {Heli Sun and
                  Ning Wang and
                  Jingyu Jia and
                  Jianbin Huang and
                  Hui Xiong and
                  Liang He and
                  Xinwang Liu and
                  Shan Zhang and
                  Shaojie Qiao and
                  Jizhong Zhao},
	title = {Platform-Oriented Event Time Allocation(Extended Abstract)},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1525--1536},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00139},
	doi = {10.1109/ICDE53745.2022.00139},
	timestamp = {Mon, 12 Feb 2024 10:23:33 +0100},
	biburl = {https://dblp.org/rec/conf/icde/SunWJHXHLZQZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Online Event-based social networks (EBSNs), such as Meetup and Whova, which provide platforms for users to publish, arrange and participate in events, have become increasingly popular. A major challenge for managing EBSNs is to generate the most satisfactory event arrangement. Existing approaches usually focus on assigning a set of events organized to time intervals, but ignore the competitive relationships among different event organizers, which will lead to event time allocations unacceptable to organizers. Thus, a more intelligent EBSNs platform that allocates social events properly in a global view (i.e. the perspective of platform) is desired. In this work, we first formally define the problem of Platform-oriented Event Time Allocation (PETA), which contains two parts: the prediction of event feasible time period and the event time allocation. We propose a method to calculate event feasible time period based on event time prediction, and design a greedy algorithm and two approximation algorithms to solve the PETA problem. Extensive experiments on both real and synthetic datasets demonstrate that the proposed algorithms have high effectiveness and efficiency.}
}


@inproceedings{DBLP:conf/icde/ZhangYTL22,
	author = {Jiahao Zhang and
                  Man Lung Yiu and
                  Bo Tang and
                  Qing Li},
	title = {Fast Error-Bounded Distance Distribution Computation (Extended Abstract)},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1527--1528},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00140},
	doi = {10.1109/ICDE53745.2022.00140},
	timestamp = {Mon, 05 Feb 2024 20:31:12 +0100},
	biburl = {https://dblp.org/rec/conf/icde/ZhangYTL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Distance distributions have been widely applied in many real-world applications, e.g., graph analysis. Unfortunately, due to the large data volume and expensive distance computation, the exact distance distribution computation is excessively slow. Motivated by this, we present a novel approximate solution in this paper that (i) achieves error-bound guarantees and (ii) is generic to various distance measures. Our proposed method outperforms the baseline in terms of accuracy and efficiency when evaluating on three widely used distance measures with real-world datasets.}
}


@inproceedings{DBLP:conf/icde/PeiYZ22,
	author = {Shichao Pei and
                  Lu Yu and
                  Xiangliang Zhang},
	title = {Set-aware Entity Synonym Discovery with Flexible Receptive Fields
                  (Extended Abstract)},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1529--1530},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00141},
	doi = {10.1109/ICDE53745.2022.00141},
	timestamp = {Sun, 02 Oct 2022 16:04:36 +0200},
	biburl = {https://dblp.org/rec/conf/icde/PeiYZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Entity synonym discovery (ESD) from text corpus is an essential problem in many entity-leveraging applications. This paper aims to address three limitations that widely exist in the current ESD solutions: 1) the lack of effective utilization for synonym set information; 2) the feature extraction of entities from restricted receptive fields; and 3) the incapacity to capture higher-order contextual information. We propose a novel set-aware ESD model that enables a flexible receptive field for ESD by using entity synonym set information and constructing a two-level network. Extensive experimental results on public datasets show that our model consistently outperforms the state-of-the-art with significant improvement.}
}


@inproceedings{DBLP:conf/icde/LiuGS22,
	author = {Penghang Liu and
                  Valerio Guarrasi and
                  Ahmet Erdem Sariy{\"{u}}ce},
	title = {Temporal Network Motifs: Models, Limitations, Evaluation (Extended
                  abstract)},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1531--1532},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00142},
	doi = {10.1109/ICDE53745.2022.00142},
	timestamp = {Fri, 05 Aug 2022 16:24:00 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LiuGS22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Investigating the frequency and distribution of small sub-graphs with a few nodes/edges, i.e., motifs, is an effective analysis method for static networks. Motif-driven analysis is also useful for temporal networks where the spectrum of motifs is significantly larger due to the additional temporal information on edges. This variety makes it challenging to design a temporal motif model that can consider all aspects of temporality. In the literature, previous works have introduced various models that handle different characteristics. In this work, we compare the existing temporal motif models and evaluate the facets of temporal networks that are overlooked in the literature. We first survey four temporal motif models and highlight their differences. Then, we evaluate the advantages and limitations of these models with respect to the temporal inducedness and timing constraints. In addition, we suggest a new lens, event pairs, to investigate temporal correlations. We believe that our comparative survey and extensive evaluation will catalyze the research on temporal network motif models. Our full paper is available at [1].}
}


@inproceedings{DBLP:conf/icde/ChenYRHZW22,
	author = {Tong Chen and
                  Hongzhi Yin and
                  Jie Ren and
                  Zi Huang and
                  Xiangliang Zhang and
                  Hao Wang},
	title = {Uniting Heterogeneity, Inductiveness, and Efficiency for Graph Representation
                  Learning (Extended Abstract)},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1533--1534},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00143},
	doi = {10.1109/ICDE53745.2022.00143},
	timestamp = {Sun, 02 Oct 2022 16:04:35 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ChenYRHZW22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recently, graph neural networks (GNNs) have greatly advanced the performance of node representation learning on graphs. However, the majority class of early GNNs are only designed for homogeneous graphs, leading to inferior adaptivity to the more complex nodes and edges in heterogeneous graphs. Also, few heterogeneous GNNs can bypass the transductive learning scheme where all nodes must be known during training, highlighting the need for inductiveness. Furthermore, the training efficiency of most heterogeneous GNNs has been hindered by their sophisticated designs for extracting the semantics associated with each meta path or relation type. In this paper, we propose wide and deep message passing network (WIDEN) to cope with the aforementioned problems about heterogeneity, inductiveness, and efficiency that are rarely investigated together in graph representation learning. We propose a novel inductive, meta path-free message passing scheme that packs up heterogeneous node features with their associated edges from both low- and high-order neighbor nodes. Meanwhile, we present an innovative downsampling strategy to facilitate faster information propagation. Experiments on real-world heterogeneous graphs have further validated the performance of WIDEN from both effectiveness and efficiency perspectives.}
}


@inproceedings{DBLP:conf/icde/ChenZWWX22,
	author = {Yu Chen and
                  Yong Zhang and
                  Jin Wang and
                  Jiacheng Wu and
                  Chunxiao Xing},
	title = {Efficient EMD-based Similarity Search via Batch Pruning and Incremental
                  Computation (Extended Abstract)},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1535--1536},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00144},
	doi = {10.1109/ICDE53745.2022.00144},
	timestamp = {Thu, 11 Aug 2022 16:27:58 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ChenZWWX22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As a robust similarity measurement, Earth Mover's Distance (EMD) has been widely adopted in many real-world applications, such as machine learning, computer vision and natural language processing. In this paper, we study the problem of EMD-based similarity search, which aims at finding all histogram objects from a dataset whose EMD is within a pre-defined threshold from the given query. Since the time complexity of computing EMD is rather high, it is essential to devise effective techniques to accelerate the query processing. To this end, we propose a filter-and-verification framework: In the filter step, we devise effective strategies to prune dissimilar objects in batch by sharing the computation between multiple objects. In the verification step, we develop novel flow adjustment techniques to incrementally calculate the EMD of candidates and enable early termination. We justify our proposed framework by conducting both theoretical analysis and extensive experiments. The results on four real world datasets show that our proposed techniques achieve up to an order of magnitude performance gain than state-of-the-art approaches.}
}


@inproceedings{DBLP:conf/icde/LiuZW22,
	author = {Yu Liu and
                  Lei Zou and
                  Zhewei Wei},
	title = {Building Graphs at Scale via Sequence of Edges: Model and Generation
                  Algorithms (Extended Abstract)},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1537--1538},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00145},
	doi = {10.1109/ICDE53745.2022.00145},
	timestamp = {Wed, 10 Jul 2024 07:43:38 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LiuZW22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Real-world graphs exhibit many interesting properties that differentiate them from random graphs, which have been extensively studied for the past decades. For various proposed generative models, a majority of them build the graph by sequentially adding each node and the attached edges. However, the growth of many real-world graphs, such as social networks, is naturally modeled by the sequential insertion of edges. Unfortunately, to the best of our knowledge, no generative model has been proposed to reveal this process. We propose the first sequence-of-edges model, denoted as temporal preferential attachment (TPA). It relies on preferential attachment (PA), one of the most influential mechanisms to generate scale-free graphs, and takes time-decay effect and node fitness into consideration. Empirical analysis demonstrates that our model preserves several key properties of the real-world graphs, including both the properties observed from the snapshot graphs (e.g., power-law distribution) and temporal properties observed from the graph generation process (e.g., shrinking diameter). Meanwhile, our model is sufficiently general to accommodate several forms of time decay and fitness distributions. Then, we design two efficient algorithms that generate TPA graphs with billions of edges in several minutes.}
}


@inproceedings{DBLP:conf/icde/ZhaoZRYH22,
	author = {Kangfei Zhao and
                  Zhiwei Zhang and
                  Yu Rong and
                  Jeffrey Xu Yu and
                  Junzhou Huang},
	title = {Finding Critical Users in Social Communities via Graph Convolutions
                  (Extended Abstract)},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1539--1540},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00146},
	doi = {10.1109/ICDE53745.2022.00146},
	timestamp = {Mon, 05 Feb 2024 20:31:13 +0100},
	biburl = {https://dblp.org/rec/conf/icde/ZhaoZRYH22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Finding critical users whose existence keeps a social community cohesive is an important problem in social networks. Considering a k-core community, finding critical users is to find a set of nodes U, with a given size b, in the community that maximizes the number of nodes to be deleted when nodes\nU\nare deleted. The problem is NP-complete. The state-of-the-art algorithm is a greedy algorithm without a performance guaran-tee. To improve the performance, we propose a novel learning-based heuristic. A neural network model, Self-attentive Core Graph Convolution Network, SCGCN is learned for inference the criticalness of unseen node combinations. Furthermore, to reduce the inference space, we propose a deterministic strategy to prune unpromising nodes. Our experiments show that SCGCN signifi-cantly improves the quality of the solutions compared with the state-of-the-art algorithms.}
}


@inproceedings{DBLP:conf/icde/AliBCMGS22,
	author = {Junaid Ali and
                  Mahmoudreza Babaei and
                  Abhijnan Chakraborty and
                  Baharan Mirzasoleiman and
                  Krishna P. Gummadi and
                  Adish Singla},
	title = {On the Fairness of Time-Critical Influence Maximization in Social
                  Networks (Extended Abstract)},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1541--1542},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00147},
	doi = {10.1109/ICDE53745.2022.00147},
	timestamp = {Sun, 04 Aug 2024 19:37:46 +0200},
	biburl = {https://dblp.org/rec/conf/icde/AliBCMGS22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Influence maximization has found applications in a wide range of real-world problems, for instance, viral marketing of products in an online social network, and propagation of valuable information such as job vacancy advertisements. While existing algorithmic techniques usually aim at maximizing the total number of people influenced, the population often comprises several socially salient groups, e.g., based on gender or race. As a result, these techniques could lead to disparity across different groups in receiving important information. Furthermore, in many applications, the spread of influence is time-critical, i.e., it is only beneficial to be influenced before a deadline. As we show in this paper, such time-criticality of information could further exacerbate the disparity of influence across groups. This dis-parity could have far-reaching consequences, impacting people's prosperity and putting minority groups at a big disadvantage. In this work, we propose a notion of group fairness in time-critical influence maximization. We introduce surrogate objective functions to solve the influence maximization problem under fair-ness considerations. By exploiting the submodularity structure of our objectives, we provide computationally efficient algorithms with guarantees that are effective in enforcing fairness during the propagation process. Extensive experiments on synthetic and real-world datasets demonstrate the efficacy of our proposal.}
}


@inproceedings{DBLP:conf/icde/ZhouYQTCD22,
	author = {Junfeng Zhou and
                  Jeffrey Xu Yu and
                  Yaxian Qiu and
                  Xian Tang and
                  Ziyang Chen and
                  Ming Du},
	title = {Fast Reachability Queries Answering based on {RCN} Reduction (Extended
                  abstract)},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1543--1544},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00148},
	doi = {10.1109/ICDE53745.2022.00148},
	timestamp = {Fri, 05 Aug 2022 16:24:02 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhouYQTCD22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We study graph reduction to accelerate reachability queries answering. We propose a novel graph reduction approach, namely RCN reduction, to reduce the input graph G\nof \\vert V\\vert\nnodes into a smaller one with \\vert V^{r}\\vert\nnodes. Assume that the probability of a node of G\nto be a query node is 1/\\vert V\\vert\n, we show that based on our approach, the lower bound probability that a query q\ncan be answered in constant time is 1-(\\frac{\\vert V^{r}\\vert}{\\vert V\\vert})^{2}\n, denoting that the smaller the reduced graph, the larger the probability that q\ncan be answered in constant time. We show the difficulties of RCN reduction and propose efficient algorithms to improve the reduction ratio. We confirm the benefits of our approach by rich experimental results using real datasets.}
}


@inproceedings{DBLP:conf/icde/HouZHT22,
	author = {Chengbin Hou and
                  Han Zhang and
                  Shan He and
                  Ke Tang},
	title = {GloDyNE: Global Topology Preserving Dynamic Network Embedding (Extended
                  Abstract)},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1545--1546},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00149},
	doi = {10.1109/ICDE53745.2022.00149},
	timestamp = {Fri, 30 Dec 2022 11:13:32 +0100},
	biburl = {https://dblp.org/rec/conf/icde/HouZHT22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Dynamic Network Embedding (DNE) is attracting much attention due to the time-evolving nature of many real-world networks. The main objective of DNE is to efficiently update node embeddings while preserving network topology at each timestep. The idea of most existing DNE methods is to capture the topological changes at or around the most affected nodes (instead of all nodes) and accordingly update node embeddings. Unfortunately, this kind of approximation, although can improve efficiency, cannot effectively preserve the global topology of a dynamic network at each timestep, due to not considering the inactive sub-networks that receive accumulated topological changes propagated via the high-order proximity. To address this issue, we propose a new DNE method for better global topology preservation. Extensive experiments demonstrate the effectiveness and efficiency of the proposed method.}
}


@inproceedings{DBLP:conf/icde/ChengCWX22,
	author = {Dawei Cheng and
                  Chen Chen and
                  Xiaoyang Wang and
                  Sheng Xiang},
	title = {Efficient Top-k Vulnerable Nodes Detection in Uncertain Graphs (Extended
                  abstract)},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1547--1548},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00150},
	doi = {10.1109/ICDE53745.2022.00150},
	timestamp = {Tue, 04 Oct 2022 16:42:32 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ChengCWX22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Uncertain graphs have been widely used to model complex linked data in many applications, such as guaranteed-loan networks and power grids. In these networks, a node usually has a certain chance of default due to self-factors or the influence from upstream nodes. For regulatory authorities, it is critical to efficiently and accurately identify the vulnerable nodes, i.e., nodes with high default risk, such that people could pay more attention to these nodes for the purpose of risk management. In this paper, we propose and investigate the top-k vulnerable nodes detection problem in uncertain graphs. Due to the hardness of the problem, sampling-based methods are proposed with tight theoretical guarantee. We demonstrate the performance of proposed techniques on 3 real financial networks and 5 benchmark networks.}
}


@inproceedings{DBLP:conf/icde/XieMWWVH22,
	author = {Shangyu Xie and
                  Meisam Mohammady and
                  Han Wang and
                  Lingyu Wang and
                  Jaideep Vaidya and
                  Yuan Hong},
	title = {A Generalized Framework for Preserving Both Privacy and Utility in
                  Data Outsourcing (Extended Abstract)},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1549--1550},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00151},
	doi = {10.1109/ICDE53745.2022.00151},
	timestamp = {Fri, 05 Aug 2022 16:24:01 +0200},
	biburl = {https://dblp.org/rec/conf/icde/XieMWWVH22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we propose a prefix-preserving encryption based data outsourcing framework which is applicable to multiple different types of data, such as geo-locations, market basket data, DNA sequences, numerical data and timestamps. It enables accurate data analyses on the encrypted data while ensuring strong privacy against inference attacks. The basic idea is to generates multiple indistinguishable data views in which one view fully preserves the utility for data analysis, and its accurate analysis result can be obliviously retrieved. We empirically evaluate the performance of our outsourcing framework against two common inference attacks on two different real datasets: the check-in location dataset and network traffic dataset, respectively. The experimental results demonstrate that our proposed framework preserves both privacy (with bounded leakage and indistinguishability of data views) and utility.}
}


@inproceedings{DBLP:conf/icde/JumonjiSSK22,
	author = {Seiya Jumonji and
                  Kazuya Sakai and
                  Min{-}Te Sun and
                  Wei{-}Shinn Ku},
	title = {Privacy-Preserving Collaborative Filtering Using Fully Homomorphic
                  Encryption},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1551--1552},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00152},
	doi = {10.1109/ICDE53745.2022.00152},
	timestamp = {Fri, 05 Aug 2022 16:24:03 +0200},
	biburl = {https://dblp.org/rec/conf/icde/JumonjiSSK22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we propose privacy-preserving user-based CF protocols using the BGV fully homomorphic encryption scheme, named BGV-CF and optimized BGV-CF (OBGV-CF), in order to protect privacy of users in recommender systems. The proposed schemes are implemented by C++, and testbeds using the MovieLens dataset demonstrate that the proposed protocols successfully achieve their design goals.}
}


@inproceedings{DBLP:conf/icde/ChenZCCSZ22,
	author = {Xi Chen and
                  Xiangmin Zhou and
                  Jeffrey Chan and
                  Lei Chen and
                  Timos Sellis and
                  Yanchun Zhang},
	title = {Event Popularity Prediction Using Influential Hashtags from Social
                  Media (Extended Abstract)},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1553--1554},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00153},
	doi = {10.1109/ICDE53745.2022.00153},
	timestamp = {Fri, 05 Aug 2022 16:24:03 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ChenZCCSZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Event popularity prediction over social media is crucial for estimating information propagation scope, decision making, and emergency prevention. It has been widely inves-tigated by existing approaches focusing on predicting single attribute occurrences which are not comprehensive enough for representing complex social event propagation. Motivated by this, we propose a novel hashtag-influence-based event popularity prediction by mining the impact of an influential hashtag set on the event propagation. We have conducted extensive experiments to prove the effectiveness and efficiency of the proposed approach.}
}


@inproceedings{DBLP:conf/icde/LiCLAT22,
	author = {Lingxiao Li and
                  Muhammad Aamir Cheema and
                  Hua Lu and
                  Mohammed Eunus Ali and
                  Adel Nadjaran Toosi},
	title = {Comparing Alternative Route Planning Techniques: {A} Comparative User
                  Study on Melbourne, Dhaka and Copenhagen Road Networks (Extended Abstract)},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1555--1556},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00154},
	doi = {10.1109/ICDE53745.2022.00154},
	timestamp = {Fri, 05 Aug 2022 16:24:02 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LiCLAT22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Computing multiple alternative routes from a source s\nto a target t\nhas received significant research attention. However, it is unclear which of the existing approaches generates alternative routes of better quality because the quality of these alternatives is mostly subjective. Motivated by this, in this paper, we present a user study conducted on the road networks of Melbourne, Dhaka and Copenhagen comparing four of the most popular existing approaches including Google Maps. We report the average ratings received by the four approaches, and our statistical analysis shows that there is no credible evidence that the four approaches receive different ratings on average. We also discuss the limitations of this user study and recommend the readers interpret these results with caution.}
}


@inproceedings{DBLP:conf/icde/ChenFLW22,
	author = {Zitong Chen and
                  Ada Wai{-}Chee Fu and
                  Cheng Long and
                  Yang Wu},
	title = {k-Pleased Querying (Extended Abstract)},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1557--1558},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00155},
	doi = {10.1109/ICDE53745.2022.00155},
	timestamp = {Tue, 22 Oct 2024 20:38:20 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ChenFLW22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {k\n-Regret Querying is a well studied problem to query a dataset D\nfor a small subset S\nof size k\nwith the minimal regret ratio for unknown utility functions. In this paper, we point out some issues in k\n- Regret Querying, including the assumption of non-negative dataset and the lack of shift invariance. Known algorithms for k\n- Regret Querying are limited in scope and result quality, and are based on the assumption of non-negative data. We introduce a new problem definition called k-pleased querying for dealing with the shift variance issue, and propose a strategy of random sampling of the utility functions. This strategy is based on a study of the theoretical guarantee of the sampling approach. We also introduce a dimensionality reduction strategy, an improved greedy algorithm, and a study of other utility function sampling methods. All of our solutions can handle negative data. Theoretically, we derive a guarantee on the approximation attained by our sampling algorithm. Experimental results on numerous real datasets show that our proposed method is effective even with a small number of samples and small values of k\n.}
}


@inproceedings{DBLP:conf/icde/ShiTZZDC22,
	author = {Yexuan Shi and
                  Yongxin Tong and
                  Yuxiang Zeng and
                  Zimu Zhou and
                  Bolin Ding and
                  Lei Chen},
	title = {Efficient Approximate Range Aggregation over Large-scale Spatial Data
                  Federation (Extended Abstract)},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1559--1560},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00156},
	doi = {10.1109/ICDE53745.2022.00156},
	timestamp = {Tue, 21 Mar 2023 20:50:57 +0100},
	biburl = {https://dblp.org/rec/conf/icde/ShiTZZDC22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Data federations notably increase the amount of data available for data-intensive applications such as smart mobility planning and public health emergency responses. Yet they also challenge the conventional implementation of range aggregation queries because the raw data cannot be shared within the federation and the data partition at each data silo is fixed during query processing. In this work, we propose the first-of-its-kind approximate algorithms for efficient range aggregation over spatial data federation. We devise novel single-silo sampling algorithms that process queries in parallel and design a level sampling based algorithm which reduces the time complexity of local queries at each data silo to\nO(log\n1\nϵ\n)\n, where ∊ is the approximation ratio of the accuracy guarantee. Extensive experiments on real-world dataset validate the efficiency and effectiveness of the solutions.}
}


@inproceedings{DBLP:conf/icde/MiaoZSCCZJ22,
	author = {Xupeng Miao and
                  Wentao Zhang and
                  Yingxia Shao and
                  Bin Cui and
                  Lei Chen and
                  Ce Zhang and
                  Jiawei Jiang},
	title = {Lasagne: {A} Multi-Layer Graph Convolutional Network Framework via
                  Node-aware Deep Architecture (Extended Abstract)},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1561--1562},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00157},
	doi = {10.1109/ICDE53745.2022.00157},
	timestamp = {Tue, 27 Aug 2024 17:30:57 +0200},
	biburl = {https://dblp.org/rec/conf/icde/MiaoZSCCZJ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we propose Lasagne, a novel multi-layer graph convolutional network (GCN) framework to over-come the over-smoothing problem and realize the full poten-tials of deep GCNs. We analyze how node localities affect the information propagation in GCN, propose an adaptive novel node aggregation mechanism and further demystify from a mutual information view. Evaluation results on both real-world benchmark data sets and large-scale industrial production data sets show Lasagne significantly outperforms the state-of- the-art methods without considering the node locality.}
}


@inproceedings{DBLP:conf/icde/LoHHSCSK22,
	author = {Chia{-}Yu Lo and
                  Wen{-}Hsing Huang and
                  Ming{-}Feng Ho and
                  Min{-}Te Sun and
                  Ling{-}Jyh Chen and
                  Kazuya Sakai and
                  Wei{-}Shinn Ku},
	title = {Recurrent Learning on {\textdollar}{\textbackslash}text\{PM\}{\_}\{2.5\}{\textdollar}
                  Prediction Based on Clustered Airbox Dataset: Extended Abstract},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1563--1564},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00158},
	doi = {10.1109/ICDE53745.2022.00158},
	timestamp = {Fri, 05 Aug 2022 16:24:03 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LoHHSCSK22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {By predicting the air pollutant concentration, people can take precautions to avoid overexposure to air pollutants. Consequently, accurate \\mathbf{PM}_{2.5}\nprediction becomes more important. In this paper, we propose a \\mathbf{PM}_{2.5}\nprediction system, which utilizes the dataset from EdiGreen Airbox and Taiwan EPA. Our \\mathbf{PM}_{2.5}\nprediction system is composed of four parts: data collection, data preprocessing, prediction model construction, and Line platform. To assess the performance of the model prediction, the daily average error and the hourly average accuracy for the duration of a week are calculated. The experimental results show that LSTM based on K- means has the best performance among all methods. Therefore, LSTM based on K-means is chosen to provide real-time \\mathbf{PM}_{2.5}\nprediction through the Linebot.}
}


@inproceedings{DBLP:conf/icde/BertsimasD22,
	author = {Dimitris Bertsimas and
                  Vassilis Digalakis},
	title = {Frequency Estimation in Data Streams: Learning the Optimal Hashing
                  Scheme (Extended Abstract)},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1565--1566},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00159},
	doi = {10.1109/ICDE53745.2022.00159},
	timestamp = {Fri, 05 Aug 2022 16:24:02 +0200},
	biburl = {https://dblp.org/rec/conf/icde/BertsimasD22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We present a novel approach for the problem of frequency estimation in data streams that is based on optimization and machine learning. Contrary to state-of-the-art streaming frequency estimation algorithms, which heavily rely on random hashing to maintain the frequency distribution of the data steam using limited storage, the proposed approach exploits an observed stream prefix to near-optimally hash elements and compress the target frequency distribution. We develop and solve (exactly and approximately) an optimization formulation, which enables us to compute optimal or near-optimal hashing schemes for elements seen in the observed stream prefix; then, we use machine learning to hash unseen elements. We empirically evaluate the proposed approach both on synthetic datasets and on real-world search query data. We show that the proposed approach outperforms existing approaches by one to two orders of magnitude in terms of its average (per element) estimation error and by 45-90% in terms of its expected magnitude of estimation error.}
}


@inproceedings{DBLP:conf/icde/HsiehL22,
	author = {I{-}Chung Hsieh and
                  Cheng{-}Te Li},
	title = {CoANE: Modeling Context Co-occurrence for Attributed Network Embedding},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1567--1568},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00160},
	doi = {10.1109/ICDE53745.2022.00160},
	timestamp = {Fri, 05 Aug 2022 16:24:01 +0200},
	biburl = {https://dblp.org/rec/conf/icde/HsiehL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Attributed network embedding (ANE) is to learn low-dimensional vectors so that not only the network structure but also node attributes can be preserved in embeddings. Existing ANE models do not consider the specific combination between graph structure and attributes. While each node has its structural characteristics, such as highly-interconnected neighbors along with their certain patterns of attribute distribution, each node's neighborhood should be not only depicted by multi-hop nodes, but consider certain social circles. To model such information, in this paper, we propose a novel ANE model, Context Co-occurrence-aware Attributed Network Embedding (CoANE). The basic idea of CoANE is to model the context attributes for each node, and apply the convolutional mechanism to encode latent social circles. To better preserve network knowledge, we devise objective functions including positive graph likelihood, contextual negative sampling, and attribute reconstruction. We conduct experiments on five real datasets for downstream tasks, including node classification, link prediction, and community detection. The results exhibit that CoANE can significantly outperform state-of-the-art ANE models. This work was accepted to IEEE TKDE 1 1 Full paper is available at https://ieeexplore.ieee.org/document/9431700.}
}


@inproceedings{DBLP:conf/icde/ZhuFZCCJW22,
	author = {Fanwei Zhu and
                  Yuan Fang and
                  Kai Zhang and
                  Kevin Chen{-}Chuan Chang and
                  Hongtai Cao and
                  Zhen Jiang and
                  Minghui Wu},
	title = {Unified and Incremental SimRank: Index-free Approximation with Scheduled
                  Principle (Extended Abstract)},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1569--1570},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00161},
	doi = {10.1109/ICDE53745.2022.00161},
	timestamp = {Sun, 04 Aug 2024 19:37:46 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhuFZCCJW22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {SimRank is a popular link-based similarity measure on graphs. It enables a variety of applications with different modes of querying. In this paper, we propose UISim, a unified and incremental framework for all SimRank modes based on a scheduled approximation principle. UISim processes queries with incremental and prioritized exploration of the entire computation space, and thus allows flexible tradeoff of time and accuracy. On the other hand, it creates and shares common “building blocks” for online computation without relying on indexes, and thus is efficient to handle both static and dynamic graphs. Our experiments on various real-world graphs show that to achieve the same accuracy, UISim runs faster than its respective state-of-the-art baselines, and scales well on larger graphs.}
}


@inproceedings{DBLP:conf/icde/LiuFLZ22,
	author = {Zemin Liu and
                  Yuan Fang and
                  Yong Liu and
                  Vincent W. Zheng},
	title = {Neighbor-Anchoring Adversarial Graph Neural Networks (Extended Abstract)},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1571--1572},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00162},
	doi = {10.1109/ICDE53745.2022.00162},
	timestamp = {Tue, 21 Feb 2023 21:52:53 +0100},
	biburl = {https://dblp.org/rec/conf/icde/LiuFLZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {While graph neural networks (GNNs) exhibit strong discriminative power, they often fall short of learning the underlying node distribution for increased robustness. To deal with this, inspired by generative adversarial networks (GANs), we investigate the problem of adversarial learning on graph neural networks, and propose a novel framework named NAGNN (i.e., Neighbor-anchoring Adversarial Graph Neural Networks) for graph representation learning, which trains not only a discriminator but also a generator that compete with each other. In particular, we propose a novel neighbor-anchoring strategy, where the generator produces samples with explicit features and neighborhood structures anchored on a reference real node, so that the discriminator can perform neighborhood aggregation on the fake samples to learn superior representations.}
}


@inproceedings{DBLP:conf/icde/ChenYWWL22,
	author = {Chen Chen and
                  Ye Yuan and
                  Zhenyu Wen and
                  Guoren Wang and
                  Anteng Li},
	title = {{GQP:} {A} Framework for Scalable and Effective Graph Query-based
                  Pricing},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1573--1585},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00163},
	doi = {10.1109/ICDE53745.2022.00163},
	timestamp = {Fri, 05 Aug 2022 16:24:02 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ChenYWWL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Data is increasingly being bought and sold online, and data market platforms have emerged to facilitate these activities. However, current mechanisms for pricing data mainly focus on traditional relational data. In this paper, we propose a framework GQP for pricing graph data on the data market platform. Specifically, given a set of graph price points and a graph query, we can efficiently compute the price of the query based on the graph price points. We first identify an important property (called arbitrage-free) GQP should satisfy with, such that GQP can effectively price the graph query. We then study the exact pricing problem (NP-completeness) and develop an efficient approximation algorithm to solve the problem. We also study the approximate pricing when the query cannot be answered by price points exactly. Furthermore, to avoid the expensive computing cost of updating graph price points, we study the dynamic query pricing and propose novel solutions to reuse the computed graph price points to reduce the computational complexity. Finally, we use real-life data and synthetic data to experimentally verify that the proposed algorithms are able to effectively and efficiently price large graph data based on the framework GQP.}
}


@inproceedings{DBLP:conf/icde/LiuXXLWH22,
	author = {Jianchun Liu and
                  Yang Xu and
                  Hongli Xu and
                  Yunming Liao and
                  Zhiyuan Wang and
                  He Huang},
	title = {Enhancing Federated Learning with Intelligent Model Migration in Heterogeneous
                  Edge Computing},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1586--1597},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00164},
	doi = {10.1109/ICDE53745.2022.00164},
	timestamp = {Fri, 05 Aug 2022 16:24:03 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LiuXXLWH22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {To approach the challenges of non-IID data and limited communication resource raised by the emerging federated learning (FL) in mobile edge computing (MEC), we propose an efficient framework, called FedMigr, which integrates a deep reinforcement learning (DRL) based model migration strategy into the pioneer FL algorithm FedAvg. According to the data distribution and resource constraints, our FedMigr will intelligently guide one client to forward its local model to another client after local updating, rather than directly sending the local models to the server for global aggregation as in FedAvg. Intuitively, migrating a local model from one client to another is equivalent to training it over more data from different clients, contributing to alleviating the influence of non-IID issue. We prove that FedMigr can help to reduce the parameter divergences between different local models and the global model from a theoretical perspective, even over local datasets with non-IID settings. Extensive experiments on three popular benchmark datasets demonstrate that FedMigr can achieve an average accuracy improvement of around 13%, and reduce bandwidth consumption for global communication by 42% on average, compared with the baselines.}
}


@inproceedings{DBLP:conf/icde/LuoNKSBHWALTSLD22,
	author = {Zhenxiao Luo and
                  Lu Niu and
                  Venki Korukanti and
                  Yutian Sun and
                  Masha Basmanova and
                  Yi He and
                  Beinan Wang and
                  Devesh Agrawal and
                  Hao Luo and
                  Chunxu Tang and
                  Ashish Singh and
                  Yao Li and
                  Peng Du and
                  Girish Baliga and
                  Maosong Fu},
	title = {From Batch Processing to Real Time Analytics: Running Presto{\textregistered}
                  at Scale},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1598--1609},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00165},
	doi = {10.1109/ICDE53745.2022.00165},
	timestamp = {Fri, 05 Aug 2022 16:24:01 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LuoNKSBHWALTSLD22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Presto is an open source distributed query engine used widely at Facebook, Uber, Twitter, Pinterest, and many other internet companies. Since open sourced in 2013, the Presto community has made several rounds of design and implementations, to support a variety of use cases, including interactive analytics, real time reporting and dashboard, ETL workloads, A/B testing, monitoring and alerts, etc. In this paper, we'd like to introduce some of the most important features and performance improvements the open source Presto community made in recent years, which enables companies running Presto at scale, supporting millions of queries per day, with hundreds of thousands of machines. Specifically, how Presto provides unified SQL on heterogeneous storage systems without data copy; how Presto deals with complex data, including nested columnar data and schema evolution; How Presto supports geospatial queries efficiently, and how file list cache works in Presto. We also talk about cluster federation, and Presto on cloud. Experimental results and our production experience could help others running interactive SQL systems at scale.}
}


@inproceedings{DBLP:conf/icde/BrunoDSZ22,
	author = {Nicolas Bruno and
                  Johnny Debrodt and
                  Chujun Song and
                  Wei Zheng},
	title = {Computation Reuse via Fusion in Amazon Athena},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1610--1620},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00166},
	doi = {10.1109/ICDE53745.2022.00166},
	timestamp = {Fri, 05 Aug 2022 16:24:02 +0200},
	biburl = {https://dblp.org/rec/conf/icde/BrunoDSZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Amazon Athena is a serverless, interactive query service that allows efficiently analyzing large volumes of data stored in Amazon S3 using ANSI SQL. Some design choices in the engine, especially those concerning streaming of intermediate results, can result in suboptimal executions for query patterns that have common expressions. In this paper we build upon recent work and introduce new optimizations in Athena that handle some common expression scenarios without materializing intermediate results or duplicating work. We describe commonalities and differences with previous work, and provide experimental results that validate our approach on TPC-DS data.}
}


@inproceedings{DBLP:conf/icde/YinFLZWLCH22,
	author = {Nan Yin and
                  Fuli Feng and
                  Zhigang Luo and
                  Xiang Zhang and
                  Wenjie Wang and
                  Xiao Luo and
                  Chong Chen and
                  Xian{-}Sheng Hua},
	title = {Dynamic Hypergraph Convolutional Network},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1621--1634},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00167},
	doi = {10.1109/ICDE53745.2022.00167},
	timestamp = {Tue, 07 May 2024 20:05:37 +0200},
	biburl = {https://dblp.org/rec/conf/icde/YinFLZWLCH22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Hypergraph Convolutional Network (HCN) has be-come a proper choice for capturing high-order relationships. Existing HCN methods are tailored for static hypergraphs, which are unsuitable for the dynamic evolution in real-world scenarios. In this paper, we explore a dynamic HCN based on the attention mechanism (DyHCN) for time series prediction. It not only effectively exploits the spatial and temporal relationships in the dynamic hypergraph, but also continuously aggregates the temporal evolution cues of time-varying hypergraphs with the global and local embeddings. Specifically, these merits can be attributed to 1) dynamic hypergraph construction (DHC), which captures the feature of historical context content and provides a guideline for dynamic hypergraph construction; 2) spatio-temporal hypergraph convolution module (STHC), responsible for extracting the spatial and temporal relationships among nodes and hyperedges, and 3) collaborative prediction module (CP), for the overall time-varying hypergraphs embedding aggregation. Such modules endeavor to well learn feature embedding from nodes, hyperedges, and hypergraphs, which produces informative representations for downstream tasks. Experiments on three datasets including Tiingo, Stocktwits, and NYC-Taxi demonstrate that the proposed DyHCN achieves sound performance over existing cousins, and both STHC and CP modules play a key role in modeling the dynamic evolution property of hypergraphs.}
}


@inproceedings{DBLP:conf/icde/ShafieinejadGLK22,
	author = {Masoumeh Shafieinejad and
                  Suraj Gupta and
                  Jin Yang Liu and
                  Koray Karabina and
                  Florian Kerschbaum},
	title = {Equi-Joins over Encrypted Data for Series of Queries},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1635--1648},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00168},
	doi = {10.1109/ICDE53745.2022.00168},
	timestamp = {Fri, 05 Aug 2022 16:24:03 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ShafieinejadGLK22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Encryption provides a method to protect data out-sourced to a DBMS provider, e.g., in the cloud. However, performing database operations over encrypted data requires specialized encryption schemes that carefully balance security and performance. In this paper, we present a new encryption scheme that can efficiently perform equi-joins over encrypted data using only software and a single server with better security than the state-of-the-art. In particular, our encryption scheme reduces the leakage to equality of rows that match a selection criterion and only reveals the transitive closure of the union of the leakages of each query in a series of queries. Our encryption scheme is provable secure. We implemented our encryption scheme and evaluated it over a dataset from the TPC- H benchmark.}
}


@inproceedings{DBLP:conf/icde/NobariR22,
	author = {Arash Dargahi Nobari and
                  Davood Rafiei},
	title = {Efficiently Transforming Tables for Joinability},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1649--1661},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00169},
	doi = {10.1109/ICDE53745.2022.00169},
	timestamp = {Fri, 05 Aug 2022 16:24:01 +0200},
	biburl = {https://dblp.org/rec/conf/icde/NobariR22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Data from different sources rarely conform to a single formatting even if they describe the same set of entities, and this raises concerns when data from multiple sources must be joined or cross-referenced. Such a formatting mismatch is unavoidable when data is gathered from various public and third-party sources. Commercial database systems are not able to perform the join when there exist differences in data representation or formatting, and manual reformatting is both time consuming and error-prone. We study the problem of efficiently joining textual data under the condition that the join columns are not formatted the same and cannot be equi-joined, but they become joinable under some transformations. The problem is challenging simply because the number of possible transformations explodes with both the length of the input and the number of rows, even if each transformation is formed using very few basic units. We show that an efficient algorithm can be developed based on the common characteristics of the joined columns and over a rich set of basic operations that can be composed to form transformations. Compared to a state-of-the-art approach, our algorithm covers every transformation that is covered in the state-of-the-art approach but is a few orders of magnitude faster, as evaluated on various real and synthetic data.}
}


@inproceedings{DBLP:conf/icde/LinMLCSLYLMLCZ22,
	author = {Shu Lin and
                  Arunprasad P. Marathe and
                  Per{-}{\AA}ke Larson and
                  Chong Chen and
                  Calvin Sun and
                  Paul Lee and
                  Weidong Yu and
                  Jianwei Li and
                  Juncai Meng and
                  Roulin Lin and
                  Xiaoyang Chen and
                  Qingping Zhu},
	title = {Near Data Processing in Taurus Database},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1662--1674},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00170},
	doi = {10.1109/ICDE53745.2022.00170},
	timestamp = {Thu, 11 Aug 2022 09:01:36 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LinMLCSLYLMLCZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Huawei's cloud-native database system GaussDB for MySQL (also known as Taurus) stores data in a separate storage layer consisting of a pool of storage servers. Each server has considerable compute power making it possible to push data reduction operations (selection, projection, and aggregation) close to storage. This paper describes the design and implementation of near data processing (NDP) in Taurus. NDP has several benefits: it reduces the amount of data shipped over the network; frees up CPU capacity in the compute layer; and reduces query run time, thereby enabling higher system throughput. Experiments with the TPC-H benchmark (100 GB) showed that 18 out of 22 queries benefited from NDP; data shipped was reduced by 63%; and CPU time by 50%. On Q15 the impact was even higher: data shipped was reduced by 98%; CPU time by 91%; and run time by 80%.}
}


@inproceedings{DBLP:conf/icde/NaMYWH22,
	author = {Inju Na and
                  Yang{-}Sae Moon and
                  Ilyeop Yi and
                  Kyu{-}Young Whang and
                  Soon J. Hyun},
	title = {Regular Path Query Evaluation Sharing a Reduced Transitive Closure
                  Based on Graph Reduction},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1675--1686},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00171},
	doi = {10.1109/ICDE53745.2022.00171},
	timestamp = {Fri, 05 Aug 2022 16:24:02 +0200},
	biburl = {https://dblp.org/rec/conf/icde/NaMYWH22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Regular path queries (RPQs) find pairs of vertices of paths satisfying given regular expressions on an edge-labeled, directed multigraph. When evaluating an RPQ, the evaluation of a Kleene closure is very expensive. Furthermore, when multiple RPQs include a Kleene closure as a common sub-query, repeated evaluations of the common sub-query cause serious performance degradation. In this paper, we present a novel concept of RPQ-based graph reduction, which significantly simplifies the original graph through edge-level and vertex-level reductions. Interestingly, RPQ-based graph reduction can replace the evaluation of the Kleene closure on the large original graph to that of the transitive closure to the small reduced graph. We then propose a reduced transitive closure (RTC) as a lightweight structure for efficiently sharing the result of a Kleene closure. We also present an RPQ evaluation algorithm, RTCSharing, which treats each clause in the disjunctive normal form of the given RPQ as a batch unit. If the batch units include a Kleene closure as a common sub-query, we share the lightweight RTC instead of the heavyweight result of the Kleene closure. RPQ-based graph reduction further enables us to formally represent the result of an RPQ including a Kleene closure as a relational algebra expression including the RTC. Through the formal expression, we optimize the evaluation of the batch unit by eliminating useless and redundant operations of the previous method. Experiments show that RTCSharing improves the performance significantly by up to 73.86 times compared with existing methods in terms of query response time.}
}


@inproceedings{DBLP:conf/icde/ZhouLLGL22,
	author = {Xu Zhou and
                  Shiting Liang and
                  Kenli Li and
                  Yunjun Gao and
                  Keqin Li},
	title = {Bilateral Preference-aware Task Assignment in Spatial Crowdsourcing},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1687--1699},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00172},
	doi = {10.1109/ICDE53745.2022.00172},
	timestamp = {Fri, 05 Aug 2022 16:24:02 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhouLLGL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Task assignment is a crucial issue in spatial crowd-sourcing. In most existing studies, the results of the task assignment cannot satisfy the workers and tasks at the same time. This is because only one-sided preferences are taken into account. Moreover, tasks are always assigned based on the locations of workers instead of the trajectories. Accordingly, they are not appropriate to the specific applications, such as carpool. Inspired by this, we investigate an interesting problem of task assignment, namely bilateral preference-aware task assignment (BPTA), with the goal of maximizing the overall satisfaction of workers and tasks by assigning tasks to suitable workers based on their routine trajectories. To tackle this problem effectively, we first propose greedy algorithms, namely task preference priority greedy and worker preference priority greedy algorithms, which are task-driven and worker-driven, respectively. Although these algorithms can solve the BPTA problem effectively, they cannot ensure the stability of the task assignment results. In other words, there can be better choices for some workers and tasks. Accordingly, we further explore deferred acceptance algorithms to find a stable matching for workers and tasks by simultaneously considering the preferences of workers and tasks. Moreover, two optimizing strategies, including a parallel strategy and a top-\nk\nstrategy, are introduced to boost the performance in handling the BPTA problem. Extensive experiments on both real and synthetic datasets have validated the efficiency and effectiveness of our proposed algorithms.}
}


@inproceedings{DBLP:conf/icde/YangWLZQZ22,
	author = {Peilun Yang and
                  Hanchen Wang and
                  Defu Lian and
                  Ying Zhang and
                  Lu Qin and
                  Wenjie Zhang},
	title = {{TMN:} Trajectory Matching Networks for Predicting Similarity},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1700--1713},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00173},
	doi = {10.1109/ICDE53745.2022.00173},
	timestamp = {Mon, 29 Jul 2024 16:18:15 +0200},
	biburl = {https://dblp.org/rec/conf/icde/YangWLZQZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Trajectory similarity computation is the cornerstone of many applications in the field of trajectory data analysis. To cope with the high time complexity of calculating exact similarity between trajectories, learning-based models have been developed for a good trade-off between the similarity computing time and the accuracy of the learned similarity. As each trajectory can be represented by a fixed-length vector regardless of the size of the trajectory, the similarity computation among the trajectories is highly time-efficient. Nevertheless, we observe that these learning-based models are designed based on recurrent neural networks (RNN), which cannot properly capture the correlations among the trajectories. Moreover, these learning-based models simply use the similarity scores of the pairs of trajectories in the training for a specific similarity metric, while a vital piece of information is neglected: the mappings of the points between two trajectories are readily available when the similarity score is calculated. These motivate us to design a new learning-based model, named TMN, based on attention networks, aiming to significantly improve the accuracy such that a better trade-off between the similarity computing time and the accuracy can be achieved. The proposed matching mechanism associates points across trajectories by computing attention weights of point pairs so that TMN learns to simulate similarity computation between the trajectory pair. Apart from taking interactions between trajectories into consideration, the sequential information of each individual trajectory is also considered, thereby making full use of spatial features of a pair of trajectories. We evaluate various approaches on real-life datasets under extensive trajectory distance metrics. Experimental results demonstrate that TMN outperforms state-of-the-art methods in terms of accuracy. Besides, ablation studies prove the effectiveness of our novel matching mechanism.}
}


@inproceedings{DBLP:conf/icde/WuZLLG22,
	author = {Zhen Wu and
                  Jingya Zhou and
                  Ling Liu and
                  Chaozhuo Li and
                  Fei Gu},
	title = {Deep Popularity Prediction in Multi-Source Cascade with {HERI-GCN}},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1714--1726},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00174},
	doi = {10.1109/ICDE53745.2022.00174},
	timestamp = {Mon, 13 May 2024 15:00:26 +0200},
	biburl = {https://dblp.org/rec/conf/icde/WuZLLG22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Popularity prediction is to predict the number of social network users involved in information diffusion. Recently, deep learning methods for popularity prediction advance traditional approaches that rely on hand-crafted features. However, existing approaches ignore the multi-source cascade that consists of multiple sub-cascades with different content but under the same topic. Different from single-source cascade, more cascading information can be observed from multi-source cascade and they are potentially correlated. How to correlate the diverse information and take advantage of them from both temporal and spatial aspects is critical for prediction. To this end, we propose a novel framework, called HEterogeneous Recurrent Integrated Graph Convolutional Neural Network (HERI-GCN). Specifically, we construct a heterogeneous cascade graph to model the multi-source cascade where time intervals are treated as heterogeneous time nodes. Besides, we propose a heterogeneous GCN to learn rich features from the multi-source cascade. RNN is organically integrated into the heterogeneous GCN to overcome the limited learning ability toward temporal and spatial data. We evaluate HERI-GCN through comparative experiments on three datasets. The experimental evaluation shows that HERI-GCN outperforms the state-of-the-art baseline methods.}
}


@inproceedings{DBLP:conf/icde/JinHRZ22,
	author = {Fengmei Jin and
                  Wen Hua and
                  Boyu Ruan and
                  Xiaofang Zhou},
	title = {Frequency-based Randomization for Guaranteeing Differential Privacy
                  in Spatial Trajectories},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1727--1739},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00175},
	doi = {10.1109/ICDE53745.2022.00175},
	timestamp = {Tue, 21 Mar 2023 20:50:56 +0100},
	biburl = {https://dblp.org/rec/conf/icde/JinHRZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the popularity of GPS-enabled devices, a huge amount of trajectory data has been continuously collected and a variety of location-based services have been developed that greatly benefit our daily life. However, the released trajectories also bring severe concern on personal privacy, and several recent studies have demonstrated the existence of personally-identifying information in spatial trajectories. Trajectory anonymization is nontrivial due to the trade-off between privacy protection and utility preservation. Furthermore, recovery attack has not been well studied in the current literature. To tackle these issues, we propose a frequency-based randomization model with a rigorous differential privacy guarantee for trajectory data publishing. In particular, we introduce two randomized mechanisms to perturb the local/global frequency distributions of significantly important locations in trajectories by injecting Laplace noise. We design a hierarchical indexing along with a novel search algorithm to support efficient trajectory modification, ensuring the modified trajectories satisfy the perturbed distributions without compromising privacy guarantee or data utility. Extensive experiments on a real-world trajectory dataset verify the effectiveness of our approaches in resisting individual re-identification and recovery attacks, and meanwhile preserving desirable data utility as well as the feasibility in practice.}
}


@inproceedings{DBLP:conf/icde/HanZFLL22,
	author = {Feng Han and
                  Lan Zhang and
                  Hanwen Feng and
                  Weiran Liu and
                  Xiang{-}Yang Li},
	title = {Scape: Scalable Collaborative Analytics System on Private Database
                  with Malicious Security},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1740--1753},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00176},
	doi = {10.1109/ICDE53745.2022.00176},
	timestamp = {Mon, 08 Aug 2022 11:28:42 +0200},
	biburl = {https://dblp.org/rec/conf/icde/HanZFLL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Many data applications can be facilitated or even spawned by joint analysis on databases held by different owners, but privacy concerns are currently the biggest hindrance. Though a practical privacy-preserving collaborative database analytics system is strongly desired, existing approaches do not support efficient queries for several essential SQL operators such as the general join, especially on large databases. In this paper, we propose, analyze, and implement Scape, a Scalable Collaborative Analytics system on Private databasE with malicious security. In Scape, databases from different parties are secretly shared to three non-colluding computing parties. Users can perform various SQL queries (including fully functional Join, Group by, Aggregation, etc.) on shared databases, and all entities learn nothing beyond their priori knowledge during the whole execution even when they deviate from protocols. At the heart of Scape lies several asymptotically efficient SQL protocols. Particularly, our general join protocol has O (n log 2 n + m) communication/computation cost when joining two tables with o (n) rows to a table with 0 (m) rows, significantly outperforming the state-of-the-art approach with O(n 2 ) cost. The benchmark results confirm the advantages of Scape, which is up to 25 x faster than the baseline.}
}


@inproceedings{DBLP:conf/icde/DongMLWCL22,
	author = {Sicong Dong and
                  Xupeng Miao and
                  Pengkai Liu and
                  Xin Wang and
                  Bin Cui and
                  Jianxin Li},
	title = {{HET-KG:} Communication-Efficient Knowledge Graph Embedding Training
                  via Hotness-Aware Cache},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1754--1766},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00177},
	doi = {10.1109/ICDE53745.2022.00177},
	timestamp = {Tue, 21 Mar 2023 20:50:57 +0100},
	biburl = {https://dblp.org/rec/conf/icde/DongMLWCL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the popularization and application of Artificial Intelligence technology, knowledge graph embedding methods are widely used for a variety of machine learning tasks. However, most of the current knowledge graph embedding models are trained with a large number of parameters and high computational time complexity. This becomes a main obstacle to apply these existing models to large-scale knowledge graphs. To address this challenge, we propose HET-KG, a distributed system for training knowledge graph embedding efficiently. HET-KG can reduce the communication overheads by introducing a cache embedding table structure to maintain hot-embeddings at each worker. To improve the effectiveness of the cache mechanism, we design a prefetching algorithm and a filtering algorithm for adaptively selecting hot-embeddings, and provide two kinds of hot-embedding table construction strategies. To address the issue of inconsistency between the local cached hot-embeddings and the global embeddings, we also develop a hot-embedding synchronization algorithm for dynamically updating the cache embedding table, which can guarantee the inconsistency bounded within a given threshold. Finally, extensive experiments are conducted on three knowledge graph datasets FB15k, WN18, and Freebase-86m. The experimental results show that HET-KG achieves 3.7x and 1.1x speedup over the state-of-the-art systems PyTorch-BigGraph and DGL-KE, respectively.}
}


@inproceedings{DBLP:conf/icde/XieLSBG22,
	author = {Yi Xie and
                  Wen Li and
                  Yuqing Sun and
                  Elisa Bertino and
                  Bin Gong},
	title = {Subspace Embedding Based New Paper Recommendation},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1767--1780},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00178},
	doi = {10.1109/ICDE53745.2022.00178},
	timestamp = {Tue, 05 Mar 2024 16:17:01 +0100},
	biburl = {https://dblp.org/rec/conf/icde/XieLSBG22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As huge numbers of academic papers are published every year, it is critical to be able to recommend high quality papers. The typical evaluation method for papers is to use citation information, which however is not applicable to new papers. To address such a shortcoming, in this paper, we consider a novel perspective on the association between the content difference of a paper, with respect to other papers, and its innovation. Since innovation has often domain-specific characteristics and forms, we introduce the concept of subspace to describe the commonly recognized aspects of paper contents, namely background, methods and results. A set of expert rules are formalized to annotate the differences between papers, based on which a twin-network is proposed for learning the embeddings of papers in different subspaces. A series of empirical studies show that there are clear correlations between a paper influence and its difference with others in those subspaces. The results also show the characteristics of innovation in different scientific disciplines. To take into account information about academic networks for paper recommendation, we propose a graph convolutional neural method to combine the paper content with other related elements, where user interests and academic influences are modeled asymmetric. Experimental results on real datasets show that our method is more effective than other baseline methods for new paper recommendation. We also discuss the characteristics of scientific disciplines and authors to show the effectiveness of modeling the asymmetric user interests and influences. Finally, we verify the reusability of our method on a patent dataset. The results show that it is also applicable to academic data with low-resource features.}
}


@inproceedings{DBLP:conf/icde/LiCXBMW22,
	author = {Guozhong Li and
                  Byron Choi and
                  Jianliang Xu and
                  Sourav S. Bhowmick and
                  Daphne Ngar{-}yin Mah and
                  Grace Lai{-}Hung Wong},
	title = {{IPS:} Instance Profile for Shapelet Discovery for Time Series Classification},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1781--1793},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00179},
	doi = {10.1109/ICDE53745.2022.00179},
	timestamp = {Fri, 05 Aug 2022 16:24:03 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LiCXBMW22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Time series classification (TSC) has been one of the most fundamental problems of time series data. Time series shapelets (or simply, shapelets) are discriminative subsequences that have been recently found both effective and interpretable for solving TSC. However, shapelet discovery is known to be computationally costly. Meanwhile, matrix profile has been recently proposed for efficient motif discovery and anomaly detection. Our preliminary experiment shows that a direct adoption of the matrix profile on TSC does not bring superior classification accuracy. We have identified two main issues of such an adoption: 1) discords as “shapelets”, and 2) lack of shapelet diversity. In response to these issues, we propose instance profile for shapelets, called IPS, for shapelet discovery for TSC. The main challenge is to utilize the instance profile (IP) to capture the characteristics of shapelets in a robust manner and then to discover high-quality shapelets efficiently. First, we use our IP to generate abundant shapelet candidates. We next efficiently prune candidates that do not align with the definition of shapelets using a novel distribution-aware bloom filter (DABF). Three utility functions are proposed to measure the shapelet candidates and DABF is used to efficiently compute the functions. We have conducted comprehensive experiments on IPS with 12 competitive state-of-the-art methods using UCR Archive datasets. The efficiency is on average 25 times faster than that of BSPCOVER (the current state-of-the-art method). The accuracy of IPS is comparable to or higher than that of existing work. Furthermore, we select one case study to illustrate the interpretability of the shapelets.}
}


@inproceedings{DBLP:conf/icde/LinWZDLC22,
	author = {Qiuru Lin and
                  Sai Wu and
                  Junbo Zhao and
                  Jian Dai and
                  Feifei Li and
                  Gang Chen},
	title = {A Comparative Study of in-Database Inference Approaches},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1794--1807},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00180},
	doi = {10.1109/ICDE53745.2022.00180},
	timestamp = {Fri, 21 Jun 2024 12:54:59 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LinWZDLC22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In Alibaba's IoT platform, we face the challenge of processing analytical queries involving both structured and unstructured data. Normally, collaborative queries need deep learning (DL) models and relational algebras to work intertwined to produce sophisticated analytical answers. To be able to support collaborative queries, a variety of approaches have been proposed. In this paper, we present the three most representative ones and study their advantages and limitations. The first one translates the collaborative query into a series of database and DL sub-queries and then maintains the dependence of the intermediate results of two sub-systems and computes the final results on the fly. The second one transforms a DL model to a database built-in User Defined Function(UDF) implemented in C++. The whole collaborative query is then processed by the database system independently. The third one is our novel solution proposed in the paper, DL2SQL, where neural operators underneath DL models are rewritten as SQL queries, and collaborative queries are processed using native SQL syntax. A cost model for our SQL-native neural operators is designed to leverage the database's optimizer to generate an efficient query plan. All three approaches are implemented on the ClickHouse. Finally, we use the real-world workloads on Alibaba's IoT platform as our benchmark and deploy various approaches on both an embedded device and a Cloud server to compare their performance. Results show that DL2SQL outperforms others in most scenarios and is more extensible.}
}


@inproceedings{DBLP:conf/icde/YangWLZYGYFGL22,
	author = {Xinying Yang and
                  Sheng Wang and
                  Feifei Li and
                  Yuan Zhang and
                  Wenyuan Yan and
                  Fangyu Gai and
                  Benquan Yu and
                  Likai Feng and
                  Qun Gao and
                  Yize Li},
	title = {Ubiquitous Verification in Centralized Ledger Database},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1808--1821},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00181},
	doi = {10.1109/ICDE53745.2022.00181},
	timestamp = {Sat, 06 Aug 2022 22:05:42 +0200},
	biburl = {https://dblp.org/rec/conf/icde/YangWLZYGYFGL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Verifiability is the backbone of most ledger systems to realize credible authentication. However, existing permissioned blockchains and centralized ledger databases lack rigorous verifiability to authenticate all facts (i.e., what-when-who validation). Besides, they suffer from high verification cost to a continually growing immutable storage. In this paper, we introduce verification principles behind LedgerDB, a centralized ledger database that achieves both strong external auditability and fast verification. We coin a novel concept called Dasein Verification that composes of three validation factors what-when-who to formalize ledger auditing. Regarding what, LedgerDB devises fam (fractal accumulating model) to accelerate existence verification, and CM-Tree for efficient lineage verification. Veri-fiable data mutations are also supported. For when, we discuss attacks on existing time pegging protocols that compromise the authenticity of timestamps, and propose a time notary protocol to resolve those threats. Evaluations show that fam and CM- Tree significantly outperform traditional approaches. Compared to Hyperledger Fabric, LedgerDB achieves 23x higher verification throughput with 500 x lower latency in notarization applications, and 3 x higher throughput with 300 x lower latency in lineage tracking applications. As a public-cloud ledger service, the end-to-end verification latencies of LedgerDB are on average 50 x and 1000x lower than that of QLDB in the above applications, respectively.}
}


@inproceedings{DBLP:conf/icde/KangWGTZ22,
	author = {Guoxin Kang and
                  Lei Wang and
                  Wanling Gao and
                  Fei Tang and
                  Jianfeng Zhan},
	title = {OLxPBench: Real-time, Semantically Consistent, and Domain-specific
                  are Essential in Benchmarking, Designing, and Implementing {HTAP}
                  Systems},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1822--1834},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00182},
	doi = {10.1109/ICDE53745.2022.00182},
	timestamp = {Fri, 05 Aug 2022 16:24:03 +0200},
	biburl = {https://dblp.org/rec/conf/icde/KangWGTZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As real-time analysis on the fresh data become in-creasingly compelling, more organizations deploy Hybrid Trans-actional/Analytical Processing (HTAP) systems to support real-time queries on data recently generated by online transaction processing. This paper argues that real-time queries, semantically consistent schema, and domain-specific workloads are essential in benchmarking, designing, and implementing HTAP systems. However, most state-of-the-art and state-of-the-practice bench-marks ignore those critical factors. Hence, at best, they are incommensurable and, at worst, misleading in benchmarking, designing, and implementing HTAP systems. This paper presents OLxPBench, a composite HTAP benchmark suite. OLxPBench proposes: (1) the abstraction of a hybrid transaction, performing a real-time query in-between an online transaction, to model widely-observed behavior pattern - making a quick decision while consulting real-time analysis; (2) a semantically consistent schema to express the relationships between OLTP and OLAP schema; (3) the combination of domain-specific and general benchmarks to characterize diverse application scenarios with varying resource demands. Our evaluations justify the three design decisions of OLxPBench and pinpoint the bottlenecks of two mainstream distributed HTAP DBMSs. International Open Benchmark Council (Bench Council) sets up the OLxP-Bench homepage at https://www.benchcouncil.org/olxpbench/. Its source code is available from https://github.com/BenchCouncil/olxpbench.git.}
}


@inproceedings{DBLP:conf/icde/GaoLM22,
	author = {Xiangyu Gao and
                  Jianzhong Li and
                  Dongjing Miao},
	title = {Dynamic Approximate Maximum Independent Set on Massive Graphs},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1835--1847},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00183},
	doi = {10.1109/ICDE53745.2022.00183},
	timestamp = {Sun, 06 Oct 2024 21:04:57 +0200},
	biburl = {https://dblp.org/rec/conf/icde/GaoLM22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Computing a maximum independent set (MaxIS) is a fundamental NP-hard problem in graph theory, which has important applications in a wide spectrum of fields. Since graphs in many applications are changing frequently over time, the problem of maintaining a MaxIS over dynamic graphs has attracted increasing attention over the past few years. Due to the intractability of maintaining an exact MaxIS, this paper aims to develop efficient algorithms that can maintain an approximate MaxIS with an accuracy guarantee theoretically. In particular, we propose a framework that maintains a\n(\n△\n2\n+1)\n-approximate MaxIS over dynamic graphs and prove that it achieves a constant approximation ratio in many real-world networks. To the best of our knowledge, this is the first non-trivial approximability result for the dynamic MaxIS problem. Following the framework, we implement an efficient linear-time dynamic algorithm and a more effective dynamic algorithm with near-linear expected time complexity. Our thorough experiments over real and synthetic graphs demonstrate the effectiveness and efficiency of the pro-posed algorithms, especially when the graph is highly dynamic.}
}


@inproceedings{DBLP:conf/icde/XiaoL22,
	author = {Xingxing Xiao and
                  Jianzhong Li},
	title = {Rank-Regret Minimization},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1848--1860},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00184},
	doi = {10.1109/ICDE53745.2022.00184},
	timestamp = {Sun, 03 Sep 2023 20:30:24 +0200},
	biburl = {https://dblp.org/rec/conf/icde/XiaoL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Multi-criteria decision-making often requires finding a small representative set from the database. A recently proposed method is the regret minimization set (RMS) query. RMS returns a size\nr\nsubset\nS\nof dataset\nD\nthat minimizes the regret- ratio (the difference between the score of top-1 in\nS\nand the score of top-l in\nD\n, for any possible utility function). RMS is not shift invariant, causing inconsistency in results. Further, existing work showed that the regret-ratio is often a “made up” number and users may mistake its absolute value. Instead, users do understand the notion of rank. Thus it considered the problem of finding the minimal set\nS\nwith a rank-regret (the rank of top-l tuple of\nS\nin the sorted list of\nD\n) at most\nk\n, called the rank-regret representative (RRR) problem. Corresponding to RMS, we focus on the min-error version of RRR, called the rank-regret minimization (RRM) problem, which finds a size\nr\nset to minimize the maximum rank-regret for all utility functions. Further, we generalize RRM and propose the restricted RRM (i.e., RRRM) problem to optimize the rank-regret for functions restricted in a given space. Previous studies on both RMS and RRR did not consider the restricted function space. The solution for RRRM usually has a lower regret level and can better serve the specific preferences of some users. Note that RRM and RRRM are shift invariant. In 2D space, we design a dynamic programming algorithm 2DRRM to return the optimal solution for RRM. In HD space, we propose an algorithm HDRRM that introduces a double approximation guarantee on rank-regret. Both 2DRRM and HDRRM are applicable for RRRM. Extensive experiments on the synthetic and real datasets verify the efficiency and effectiveness of our algorithms. In particular, HDRRM always has the best output uuality in experiments.}
}


@inproceedings{DBLP:conf/icde/ShedgeSAAA22,
	author = {Sagar Shedge and
                  Nishant Sharma and
                  Anant Agarwal and
                  Mohammed Abouzour and
                  G{\"{u}}nes Alu{\c{c}}},
	title = {An Extended SSD-Based Cache for Efficient Object Store Access in {SAP}
                  {IQ}},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1861--1873},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00185},
	doi = {10.1109/ICDE53745.2022.00185},
	timestamp = {Fri, 05 Aug 2022 16:24:00 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ShedgeSAAA22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The cloud-native version of SAP IQ aims to reduce the storage and compute costs by storing data directly on object stores while benefiting from the greater elasticity and scale-out properties that are offered. In the cloud-native version of SAP IQ, the buffer manager has gone through a significant re-design for two major reasons. First, RAM is more expensive on the cloud; therefore, a buffer manager that relies exclusively on RAM would not have been a viable solution. Second, on object stores, read and write operations are generally associated with higher latencies. To counteract the impact of higher latencies without utilizing more RAM, we have extended SAP IQ's buffer manager with a second layer of cache, namely, the Extended Cache Manager (ECM). The ECM relies on fast solid state drives (SSDs). In this paper, we describe our experience with the design and implementation of the ECM, in particular, the design choices we had to make to overcome the fact that, when compared to object stores, SSDs have a much more limited I/O bandwidth.}
}


@inproceedings{DBLP:conf/icde/LiuLFL22,
	author = {Yunfei Liu and
                  Zhen Liu and
                  Xiaodong Feng and
                  Zhongyi Li},
	title = {Robust Attributed Network Embedding Preserving Community Information},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1874--1886},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00186},
	doi = {10.1109/ICDE53745.2022.00186},
	timestamp = {Sun, 03 Sep 2023 20:30:24 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LiuLFL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Network embedding, also known as network repre-sentation, has attracted a surge of attention in data mining and machine learning community as a fundamental tool to treat net-work data. Most existing deep learning-based network embedding approaches focus on reconstructing the pairwise connections of micro-structure, which are easily disturbed by network anomaly or attack. Thus, to address the aforementioned challenge, we pro-pose a novel robust framework for attributed network embedding by preserving Community Information (AnECI). Rather than using pairwise connection-based micro-structure, we try to guide the node embedding by the underlying community structure learned from data itself as an unsupervised learning, as to own stronger anti-interference ability. Specially, we put forward a new modularity function for high-order proximity and overlapped community to guide the network embedding of an attributed graph encoder. We conducted extensive experiments on node classification, anomaly detection and community detection tasks on real benchmark data sets, and the results show that AnECI is superior to the state-of-art attributed network embedding methods.}
}


@inproceedings{DBLP:conf/icde/SunWCWZL22,
	author = {Renjie Sun and
                  Yanping Wu and
                  Chen Chen and
                  Xiaoyang Wang and
                  Wenjie Zhang and
                  Xuemin Lin},
	title = {Maximal Balanced Signed Biclique Enumeration in Signed Bipartite Graphs},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1887--1899},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00187},
	doi = {10.1109/ICDE53745.2022.00187},
	timestamp = {Tue, 21 Mar 2023 20:50:56 +0100},
	biburl = {https://dblp.org/rec/conf/icde/SunWCWZL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Maximal biclique enumeration is a fundamental problem in bipartite graph analysis, and can find numerous applications. However, previous studies only focus on unsigned bipartite graphs. Signed information, such as friend and enemy, naturally exists in real-world networks. It is critical to leverage signed information to better characterize biclique. To fill this gap, in this paper, we propose a novel biclique model, named balanced signed biclique, by leveraging the property of balance theory. Specifically, given a signed bipartite graph\nG\n, two positive integers\nτ\nU\n,\nτ\nV\n, a subgraph\nS=(\nU\nS\n, \nV\nS\n, \nE\nS\n)\nof\nG\nis a balanced signed biclique if\ni\n)\nS\nis a biclique without any unstable motif, i.e., unbalanced butterfly, and ii)\n|\nU\nS\n|≥\nτ\nU\nand\n|\nV\nS\n|≥\nτ\nV\n. In this paper, we aim to enumerate all the maximal balanced signed bicliques, which is proved to be NP-hard. Moreover, due to the unique features of signed bipartite graphs, the previous works cannot be applied to our problem directly. To construct a reasonable baseline, we extend the existing biclique enumeration framework for unsigned bipartite graphs and integrate the developed balanced bipartite graph property. To scale for larger networks, novel optimized strategies are proposed to overcome the three limitations in the baseline method. Extensive experi-ments are conducted on 8 real-world datasets to demonstrate the efficiency and effectiveness of proposed techniques and model. Compared with the baseline approach, the optimized algorithm can achieve up to 3 orders of magnitude speedup.}
}


@inproceedings{DBLP:conf/icde/GuoYYKLJZ22,
	author = {Guimu Guo and
                  Da Yan and
                  Lyuheng Yuan and
                  Jalal Khalil and
                  Cheng Long and
                  Zhe Jiang and
                  Yang Zhou},
	title = {Maximal Directed Quasi -Clique Mining},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1900--1913},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00188},
	doi = {10.1109/ICDE53745.2022.00188},
	timestamp = {Tue, 22 Oct 2024 20:38:20 +0200},
	biburl = {https://dblp.org/rec/conf/icde/GuoYYKLJZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Quasi-cliques are a type of dense subgraphs that generalize the notion of cliques, important for applications such as community/module detection in various social and biological networks. However, the existing quasi-clique definition and algorithms are only applicable to undirected graphs. In this paper, we generalize the concept of quasi-cliques to directed graphs by proposing (γ 1 , γ 2 ) -quasi-cliques which have density requirements in both inbound and outbound directions of each vertex in a quasi-clique subgraph. An efficient recursive algorithm is proposed to find maximal (γ 1 ,γ 2 )-quasi-cliques which integrates many effective pruning rules that are validated by ablation studies. We also study the finding of top-k large quasi-cliques directly by bootstrapping the search from more compact quasi-cliques, to scale the mining to larger networks. The algorithms are parallelized with effective load balancing, and we demonstrate that they can scale up effectively with the number of CPU cores.}
}


@inproceedings{DBLP:conf/icde/KangM22,
	author = {Yunfan Kang and
                  Amr Magdy},
	title = {{EMP:} Max-P Regionalization with Enriched Constraints},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1914--1926},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00189},
	doi = {10.1109/ICDE53745.2022.00189},
	timestamp = {Fri, 05 Aug 2022 16:24:01 +0200},
	biburl = {https://dblp.org/rec/conf/icde/KangM22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Spatial regionalization is the process of grouping a set of spatial areas into spatially contiguous and homogeneous regions. This paper introduces an enriched max-p-regions (EMP) problem; a regionalization process that allows enriched user-defined constraints based on SQL aggregate functions. In addition to enabling richer constraints, it enables users to employ multiple constraints simultaneously to significantly push the expressiveness and effectiveness of the existing regionalization literature. The EMP problem is NP-hard and significantly enriches the existing regionalization problems. Such a major enrichment introduces several challenges in both feasibility and scalability. To address these challenges, we propose the FaCT algorithm, a three-phase greedy approach that finds a feasible set of spatial regions that satisfy EMP constraints while supporting large datasets compared to the existing literature. Our extensive experimental evaluation has demonstrated the effectiveness and scalability of our techniques on several real datasets.}
}


@inproceedings{DBLP:conf/icde/WangXZXPP22,
	author = {Haixin Wang and
                  Cheng Xu and
                  Ce Zhang and
                  Jianliang Xu and
                  Zhe Peng and
                  Jian Pei},
	title = {vChain+: Optimizing Verifiable Blockchain Boolean Range Queries},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1927--1940},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00190},
	doi = {10.1109/ICDE53745.2022.00190},
	timestamp = {Sat, 30 Sep 2023 09:44:51 +0200},
	biburl = {https://dblp.org/rec/conf/icde/WangXZXPP22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Blockchain has recently gained massive attention thanks to the success of cryptocurrencies and decentralized applications. With immutability and tamper-resistance features, it can be seen as a promising secure database solution. To address the need of searches over blockchain databases, prior work vChain proposed a novel verifiable processing framework that ensures query integrity without maintaining a full copy of the blockchain database. It however suffers from several limitations, including linear-scan search performance in the worst case and impractical public key management. In this paper, we propose a new searchable blockchain system, vChain+, that supports efficient verifiable boolean range queries with additional features. Specifically, we propose a sliding window accumulator index to achieve efficient query processing even for the worst case. We also design an object registration index to enable practical public key management without compromising the security guarantee. To support richer queries, we employ optimal tree-based indexes to index both keywords and numerical attributes of the data objects. Several optimizations are also proposed to further improve the query performance. Security analysis and empirical study validate the robustness and performance improvement of the proposed system. Compared with vChain, vChain+ improves the query performance by up to 913x.}
}


@inproceedings{DBLP:conf/icde/PengBLWY22,
	author = {You Peng and
                  Song Bian and
                  Rui Li and
                  Sibo Wang and
                  Jeffrey Xu Yu},
	title = {Finding Top-r Influential Communities under Aggregation Functions},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1941--1954},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00191},
	doi = {10.1109/ICDE53745.2022.00191},
	timestamp = {Sun, 12 Nov 2023 02:08:09 +0100},
	biburl = {https://dblp.org/rec/conf/icde/PengBLWY22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Community search is a problem that seeks cohesive and connected subgraphs in a graph that satisfy certain topology constraints, e.g., degree constraints. The majority of existing works focus exclusively on the topology and ignore the nodes' influence in the communities. To tackle this deficiency, influential community search is further proposed to include the node's influence. Each node has a weight, namely influence value, in the influential community search problem to represent its network influence. The influence value of a community is produced by an aggregated function, e.g., max, min, avg, and sum, over the influence values of the nodes in the same community. The objective of the influential community search problem is to locate the top-r communities with the highest influence values while satisfying the topology constraints. Existing studies on influential community search have several limitations: (i) they focus exclusively on simple aggregation functions such as min, which may fall short of certain requirements in many real-world scenarios, and (ii) they impose no limitation on the size of the community, whereas most real-world scenarios do. This motivates us to conduct a new study to fill this gap. We consider the problem of identifying the top-r influential communities with/without size constraints while using more complicated aggregation functions such as sum or avg. We give a theoretical analysis demonstrating the hardness of the problems and propose efficient and effective heuristic solutions for our top-r influential community search problems. Extensive experiments on real large graphs demonstrate that our proposed solution is significantly more efficient than baseline solutions.}
}


@inproceedings{DBLP:conf/icde/YuanPCHLCZ22,
	author = {Zhirong Yuan and
                  You Peng and
                  Peng Cheng and
                  Li Han and
                  Xuemin Lin and
                  Lei Chen and
                  Wenjie Zhang},
	title = {Efficient {\textdollar}k-{\textbackslash}text\{clique\}{\textdollar}
                  Listing with Set Intersection Speedup},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1955--1968},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00192},
	doi = {10.1109/ICDE53745.2022.00192},
	timestamp = {Mon, 26 Jun 2023 20:41:54 +0200},
	biburl = {https://dblp.org/rec/conf/icde/YuanPCHLCZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Listing all k-cliques is a fundamental problem in graph mining, with applications in finance, biology, and social network analysis. However, owing to the exponential growth of the search space as\nk\nincreases, listing all k-cliques is algorithmically challenging. DDegree and DDegCol are the state-of-the-art algorithms that exploit ordering heuristics based on degree ordering and color ordering, respectively. Both DDegree and DDegCol induce high time and space overhead for set intersections cause they construct and maintain all induced subgraphs. Meanwhile, it is non-trivial to implement the data level parallelism to further accelerate on DDegree and DDegCol. In this paper, we propose two efficient algorithms SDegree and BitCol for k-clique listing. We mainly focus on accelerating the set intersections for k-clique listing. Both SDegree and BitCol exploit the data level parallelism for further acceleration with single instruction multiple data (SIMD) or vector instruction sets. Furthermore, we propose two preprocessing techniques Pre-Core and Pre-List, which run in linear time. The preprocessing techniques significantly reduce the size of the original graph and prevent exploring a large number of invalid nodes. In the theoretical analysis, our algorithms have a comparable time complexity and a slightly lower space complexity than the state-of-the-art algorithms. The comprehensive experiments reveal that our algorithms outperform the state-of-the-art algorithms by 3.75x for degree ordering and 5.67x for color ordering on average.}
}


@inproceedings{DBLP:conf/icde/ZengYZXGL22,
	author = {Yuanyuan Zeng and
                  Wangdong Yang and
                  Xu Zhou and
                  Guoqing Xiao and
                  Yunjun Gao and
                  Kenli Li},
	title = {Distributed Set Label-Constrained Reachability Queries over Billion-Scale
                  Graphs},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1969--1981},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00193},
	doi = {10.1109/ICDE53745.2022.00193},
	timestamp = {Fri, 05 Aug 2022 16:24:00 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZengYZXGL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Set label-constrained reachability (SLCR) query in edge-labeled graphs is a building block of many graph-based applications. Formally, given two sets\nS\nand\nT\nof source and target vertices and a label set (, it returns all reachable vertex pairs (s, t) under the constraint of (, where\ns\n∊\nS\nand\nt\n∊T. There have been abundant index-based approaches to be applied to process the SLCR query. However, distributed approaches are desirable to process large-scale graphs because of the advantages of good scalability and real-time response. Now, there is no efficient distributed approach to the SLCR query. Most index-based approaches face limitations in terms of index construction and query performance when being extended to the distributed environment for processing large-scale graphs. To alleviate these problems, we first build a boundary graph-based index (BoundG) to reduce the time overhead of index construction. Consider the query performance of the BoundG-based approach has no noticeable improvement. We further construct a novel two layers 2-hop index (TL2hop), and a TL2hop-based query algorithm (TLQA) is designed by integrating an early termination strat-egy that reduces the communication overhead and boosts the query performance. Experimental results over eight data graphs demonstrate that the index time of BoundG is comparable to that of the state-of-the-art, and TL2hop significantly outperforms the state-of-the-art technique in terms of query response time (up to 4 orders of magnitude speedup).}
}


@inproceedings{DBLP:conf/icde/XiangCZMWZ22,
	author = {Sheng Xiang and
                  Dawei Cheng and
                  Jianfu Zhang and
                  Zhenwei Ma and
                  Xiaoyang Wang and
                  Ying Zhang},
	title = {Efficient Learning-based Community-Preserving Graph Generation},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1982--1994},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00194},
	doi = {10.1109/ICDE53745.2022.00194},
	timestamp = {Sat, 30 Sep 2023 09:44:52 +0200},
	biburl = {https://dblp.org/rec/conf/icde/XiangCZMWZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graph generation is beneficial to comprehend the creation of meaningful structures of networks in a broad spec-trum of applications such as social networks and biological net-works. Recent studies tend to leverage deep learning techniques to learn the topology structures in graphs. However, we notice that the community structure, which is one of the most unique and prominent features of the graph, cannot be well captured by the existing graph generators. Moreover, the existing advanced deep learning-based graph generators are not efficient and scalable, which can only handle small graphs. In this paper, we propose a novel community-preserving generative adversarial network (CPGAN) for effective and efficient (scalable) graph simulation. We employ graph convolution networks in the encoder and share parameters in the generation process to transmit information about community structures and preserve the permutation-invariance in CPGAN. We conducted extensive experiments on benchmark datasets, including six sets of real-life graphs. The results demonstrate that CPGAN can achieve a good trade-off between efficiency (scalability) and graph simulation quality for real-life graph simulation compared with state-of-the-art baselines.}
}


@inproceedings{DBLP:conf/icde/LinZFLZL22,
	author = {Chen Lin and
                  Junqing Zhuang and
                  Jiadong Feng and
                  Hui Li and
                  Xuanhe Zhou and
                  Guoliang Li},
	title = {Adaptive Code Learning for Spark Configuration Tuning},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {1995--2007},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00195},
	doi = {10.1109/ICDE53745.2022.00195},
	timestamp = {Fri, 25 Aug 2023 14:52:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LinZFLZL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Configuration tuning is vital to optimize the performance of big data analysis platforms like Spark. Existing methods (e.g. auto-tuning relational databases) are not effective for tuning Spark, because the unique characteristics of Spark pose new challenges to configuration tuning. (C1) The Spark applications own various code structures and semantics, and the code features significantly affect Spark performance and configuration selection; (C2) Spark applications are extremely time-consuming on big data. It is infeasible for approaches such as Bayesian Optimization and Reinforcement Learning to collect sufficient training instances or repeatedly execute the applications; (C3) Spark supports various analytical applications and the tuning system needs to adapt to different applications. To address these challenges, we propose a LIghtweighT knob rEcommender system (LITE) for auto-tuning Spark configurations on various analytical applications and large-scale datasets. We first propose a code learning framework that can utilize code features to learn complex correlations between application performance and knob values (addressing C1). We then propose a lightweight auto-tuning method that migrates the knowledge learned from small-scale datasets to large-scale datasets (addressing C2). Next, to generalize to different Spark applications, we propose an adaptive model update approach to fine-tune the model via adversarial learning with newly collected feedback (addressing C3). Extensive experiments showed that LITE achieves much better performance compared with state-of-the-art auto-tuning methods.}
}


@inproceedings{DBLP:conf/icde/LiuZLZCL22,
	author = {Yuhan Liu and
                  Suyun Zhao and
                  Yixuan Liu and
                  Dan Zhao and
                  Hong Chen and
                  Cuiping Li},
	title = {Collecting Triangle Counts with Edge Relationship Local Differential
                  Privacy},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {2008--2020},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00196},
	doi = {10.1109/ICDE53745.2022.00196},
	timestamp = {Mon, 19 Aug 2024 15:02:12 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LiuZLZCL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Counting subgraphs in decentralized settings has drawn increasing attention for graph analysis, wherein triangle count is one of the fundamental statistics. However, triangle counts may breach edge privacy, such as sensitive relations of individuals. Protecting edge privacy in triangle counts collection is a challenging problem due to the strong correlations among data from different clients. Decentralized Differential Privacy (DDP), as a possible option, protects edge privacy on correlated data to some extent. However, DDP provides a weak privacy guarantee by only hiding one edge in global. Unlike DDP, Local Differential Privacy (LDP) is a widely adopted standard for data collection which hides multiple data points in global at a time. But the LDP notion does not consider data correlations. With the understanding of these limitations, we introduce Edge Relationship Local Differential Privacy (Edge-RLDP), which provides a strong privacy guarantee as LDP and considers data correlations simultaneously. Based on Edge-RLDP, a baseline framework for triangle counts collection is proposed, as well as an improved two-phase framework, which strikes a better balance between privacy and data utility. Our improved framework fully utilizes the privacy budget by asking each client to only report the count of randomly sampled triangles after measuring the global data correlation. Theoretically, we rigorously prove that our framework satisfies (\nε,δ\n) -Edge-RLDP. Experimentally, we demonstrate our framework outperforms the state-of-art methods in terms of triangle count accuracy under a stricter privacy definition.}
}


@inproceedings{DBLP:conf/icde/BellomariniNS22,
	author = {Luigi Bellomarini and
                  Markus Nissl and
                  Emanuel Sallinger},
	title = {iTemporal: An Extensible Generator of Temporal Benchmarks},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {2021--2033},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00197},
	doi = {10.1109/ICDE53745.2022.00197},
	timestamp = {Fri, 05 Aug 2022 16:24:02 +0200},
	biburl = {https://dblp.org/rec/conf/icde/BellomariniNS22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {DatalogMTL is an extension of the fundamental rule language Datalog with metric temporal operators over rational numbers, whose adoption is soaring within an increasing number of communities (semantic web, databases, stream data processing, temporal logic, knowledge graphs, etc.), which are more and more willing to handle temporal data and deal with temporal database queries as a consequence. Despite the rising research efforts towards new extensions of DatalogMTL, such as the fundamental support for aggregations, and the uprising systems, we still lack a corpus of benchmarks for temporal reasoning. This paper contributes iTemporal, an extensible generator of temporal benchmarks. Our system is able to generate a very broad set of benchmarks, thanks to a white-box configuration mechanism to control and stimulate the theoretical underpinnings of DatalogMTL and its extensions, such as temporal operators in the presence of full recursion and aggregations. We provide a comprehensive presentation of the system as well as an empirical evaluation of the benchmarks within two reference reasoners.}
}


@inproceedings{DBLP:conf/icde/WangXODLZ22,
	author = {Liuyin Wang and
                  Xianghong Xu and
                  Kai Ouyang and
                  Huanzhong Duan and
                  Yanxiong Lu and
                  Hai{-}Tao Zheng},
	title = {Self-Supervised Dual-Channel Attentive Network for Session-based Social
                  Recommendation},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {2034--2045},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00198},
	doi = {10.1109/ICDE53745.2022.00198},
	timestamp = {Sun, 06 Aug 2023 20:52:07 +0200},
	biburl = {https://dblp.org/rec/conf/icde/WangXODLZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The task of Session-based Social Recommendation (SSR) aims to utilize the social networks to make recommendations in session-based scenarios. Existing SSR methods mainly focused on using graph networks to capture complex item transition patterns, ignoring the sequential information. Few studies combined two aspects of features to enhance session preferences, resulting in information loss. Besides, modeling the entire session that some items are invalid or repeatedly clicked will interfere with the results. In this paper, to address the information loss issue in SSR, we propose a novel Dual-Channel Attentive Network (DCAN) to leverage both sequential infor-mation and complex item transitions. Specifically, we construct one channel by a light graph attention layer to capture item transitions, and we elaborate a concise attention-based layer to build the other channel to learn sequential information. To solve the invalid or repeatedly clicked problem in the session, we introduce new self-supervised learning (SSL) learning method, which allows model learning to distinguish and discard these items. However, the effect of SSL in SSR has not been investigated yet. Besides, these studies require negative sampling, which makes its performance depend on negative sampling strategies. Then, we investigate the effect of adding existing SSL frameworks in DCAN, but it has not achieved good results. Besides, we propose a novel SSL framework that does not require negative sampling for SSR, denoted as Positive sampling SSL (PSSL). Furthermore, we combined DCAN and PSSL to make more accurate recommendations, denoted as DCAN - PSSL. Extensive experiments on three public benchmark datasets demonstrate that both DCAN and DCAN - PSSL consistently outperform the state-of-the-art models.}
}


@inproceedings{DBLP:conf/icde/GanZZLWLCL22,
	author = {Xinbiao Gan and
                  Yiming Zhang and
                  Ruigeng Zeng and
                  Jie Liu and
                  Ruibo Wang and
                  Tiejun Li and
                  Li Chen and
                  Kai Lu},
	title = {XTree: Traversal-Based Partitioning for Extreme-Scale Graph Processing
                  on Supercomputers},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {2046--2059},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00199},
	doi = {10.1109/ICDE53745.2022.00199},
	timestamp = {Thu, 12 Jan 2023 08:56:09 +0100},
	biburl = {https://dblp.org/rec/conf/icde/GanZZLWLCL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graph algorithms, such as Breadth First Search (BFS), Single Source Shortest Path (SSSP), PageRank (PR), and Connected Components (CC), are increasingly important in big data processing and analytics. As graph scales (numbers of vertices and edges) have increased from billions to trillions, Supercomputers have huge numbers (up to hundreds of thousands) of computing nodes (CNs) that can provide ultra-high aggregate computing power and memory capacity, thus being particularly suitable for processing extreme-scale graphs with trillions of vertices and edges. However, existing cluster-based graph-parallel systems perform poorly when deployed on supercomputers, since their partitioning methods overlook the hierarchical nature of supercomputer networks and incur prohibitive communication storm. This paper presents XTree, an efficient traversal-based partitioning method for minimizing communication overhead of graph processing on supercomputers. We observe that supercomputers' huge numbers of CNs are usually organized into hierarchical communication domains, which can be modeled as a domain tree where communication in lower-level domains is significantly faster than that in higher-level ones. Therefore, the key idea of XTree's partitioning is to exploit hierarchical locality by viewing the graph as a BFS tree and leveraging the topology knowledge to map the graph's BFS tree onto the domain tree, We evaluate the effectiveness of XTree by running various graph algorithms, on both real-world big graphs and synthetic trillion-scale graphs. XTree substantially reduces communication overhead and achieves orders of magnitude speedup against the Graph500 reference implementations with the state-of-the-art 2D-decomposition partitioning.}
}


@inproceedings{DBLP:conf/icde/DengFLLZA22,
	author = {Ting Deng and
                  Wenfei Fan and
                  Ping Lu and
                  Xiaomeng Luo and
                  Xiaoke Zhu and
                  Wanhe An},
	title = {Deep and Collective Entity Resolution in Parallel},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {2060--2072},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00200},
	doi = {10.1109/ICDE53745.2022.00200},
	timestamp = {Sun, 06 Oct 2024 21:04:57 +0200},
	biburl = {https://dblp.org/rec/conf/icde/DengFLLZA22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper studies deep and collective entity resolution (ER). As opposed to a single pass of pairwise comparison of tuples in a single table, deep ER recursively identifies tuples that refer to the same entity by making use of matches in the previous rounds, and collective ER determines matches by correlating information across multiple tables. We propose a fixpoint model for deep and collective ER, by chasing with logic rules that are collectively defined across multiple relations and may embed machine learning classifiers for ER as predicates. While powerful, we show that deep and collective ER is intractable. To scale with large datasets, we develop a data partitioning strategy and a parallel algorithm underlying the fixpoint model, which guarantee to reduce runtime when more processors are used. Using real-life data, we experimentally verify that the approach improves the ER accuracy and is parallelly scalable.}
}


@inproceedings{DBLP:conf/icde/DongCLLFZ22,
	author = {Haowen Dong and
                  Chengliang Chai and
                  Yuyu Luo and
                  Jiabin Liu and
                  Jianhua Feng and
                  Chaoqun Zhan},
	title = {RW-Tree: {A} Learned Workload-aware Framework for R-tree Construction},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {2073--2085},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00201},
	doi = {10.1109/ICDE53745.2022.00201},
	timestamp = {Fri, 05 Aug 2022 16:24:01 +0200},
	biburl = {https://dblp.org/rec/conf/icde/DongCLLFZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {R-tree is a popular index which supports efficient queries on multi-dimensional data. The performance of R-tree mostly depends on how the tree structure is built if new data instances are inserted, which has been studied for years. Existing works can be categorized into two groups. One is the bulk-loading approaches that insert data instances in batch, but they cannot support real-time insertion. Hence, our focus is on the other one that inserts each data instance individually, and thus fresh data can be instantly queried. However, existing methods do not consider the workload information, which leads to limited potential optimization opportunity. Therefore, it is important to study workload-aware R-tree construction for efficient multi-dimensional data access. There are several challenges. First, how to represent the query workload is a challenge. Second, given a workload, it is challenging to accurately measure the benefit of a data insertion choice. Third, both range queries and kNN queries should be considered in the workload. To address these challenges, we propose a novel framework that leverages a learning-based method to solve the workload-aware R-tree construction problem. First, by extracting the query workload features, we learn a distribution for the workload using the space partition. Second, considering the distribution, we design a cost model to describe the benefits (i.e., query execution time) of different insertion choices and select the best one. Third, we convert the kNN queries to range search ones, so as to support the workload including both types of queries. Experimental results show that on OpenStreetMap real datasets, compared with baselines, we improve the query efficiency by 1.17x.}
}


@inproceedings{DBLP:conf/icde/WangJXWY22,
	author = {En Wang and
                  Yiheng Jiang and
                  Yuanbo Xu and
                  Liang Wang and
                  Yongjian Yang},
	title = {Spatial-Temporal Interval Aware Sequential {POI} Recommendation},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {2086--2098},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00202},
	doi = {10.1109/ICDE53745.2022.00202},
	timestamp = {Sat, 30 Sep 2023 09:44:51 +0200},
	biburl = {https://dblp.org/rec/conf/icde/WangJXWY22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The past flourishing years of sequential point-of-interest (POI) recommendation began with the introduction of Self-Attention Network (SAN), which quickly superseded CNN or RNN as the state-of-the-art backbone. To realize the fine-grained users' behavior patterns modeling, recent works utilize modified attention mechanisms or neural network layers to process spatial-temporal factors. However, due to the significant increase on either model's parameter scale or computational burden, we argue that these methods can be further improved. In this paper, we exploit two lightweight approaches, Time Aware Position Encoder (TAPE) and Interval Aware Attention Block (IAAB), to impel SAN by considering the spatial-temporal intervals among POIs separately, where requiring neither extra parameters nor high computational cost. On the one hand, TAPE, adjusting the positions in sequences based on the timestamps dynamically and generating positional representations with sinusoidal transformation, can enhance sequence representations to reflect both the absolute order and relative temporal proximity among all POIs. On the other hand, IAAB, point-wise adding the scaled spatial-temporal intervals to the attention map, can promote the attention mechanism attaching importance to the spatial relation among all POIs under the constraints of time conditions and providing more explainable recommendation. We integrate these two modules into SAN and propose a Spatial-Temporal Interval-Aware sequential POI recommender, namely STiSAN, as an end-to-end deployment. Experimental results based on three public LBSN datasets and one real-world city transportation dataset demonstrate STiSAN's superior performance (average 13.01% improvement against the strongest baseline). Moreover, we validate the extensibility and interpretability of TAPE and IAAB through metric evaluation and visualization separately.}
}


@inproceedings{DBLP:conf/icde/GongLFLWY22,
	author = {Chaoyu Gong and
                  Yongbin Liu and
                  Di Fu and
                  Yong Liu and
                  Pei{-}hong Wang and
                  Yang You},
	title = {Self-reconstructive evidential clustering for high-dimensional data},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {2099--2112},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00203},
	doi = {10.1109/ICDE53745.2022.00203},
	timestamp = {Tue, 23 Jul 2024 08:23:08 +0200},
	biburl = {https://dblp.org/rec/conf/icde/GongLFLWY22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Although many algorithms have been presented to tackle the curse of dimensionality in high-dimensional clustering, most of these algorithms require prior knowledge of the number of clusters. Besides, these existing algorithms create only a hard or fuzzy partition for high-dimensional objects, which are often located in highly overlapping areas. The adoption of hard/fuzzy partition ignores the ambiguity in the assignment of objects and may lead to performance degradation. To address these issues, we propose a novel self-reconstructive evidential clustering (SREC) algorithm. After learning the correlations between objects from a self-reconstruction process, SREC provides a human-readable chart. Through this chart, users can select several objects existing in the dataset as the cluster centers, instead of just detecting the number of clusters. Under the framework of evidence theory, SREC derives a more flexible credal partition that improves the fault tolerance of clustering. Ablation study demonstrates the benefits of the self-reconstruction and evidence theory. Comparison experiments on real-world datasets show that SREC consumes competitive running time and performs better than other state-of-the-art algorithms. We also apply SREC in a real-world application scenario to illustrate the rationality of selecting cluster centers by human intervention.}
}


@inproceedings{DBLP:conf/icde/GongLLWY22,
	author = {Chaoyu Gong and
                  Yongbin Li and
                  Yong Liu and
                  Pei{-}hong Wang and
                  Yang You},
	title = {Joint Evidential {\textdollar}K{\textdollar}-Nearest Neighbor Classification},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {2113--2126},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00204},
	doi = {10.1109/ICDE53745.2022.00204},
	timestamp = {Sat, 27 Jul 2024 13:40:00 +0200},
	biburl = {https://dblp.org/rec/conf/icde/GongLLWY22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The performance of\nK\n-nearest neighbor (K-NN) classification depends significantly on the searched neighborhoods of test samples, namely, the neighborhood size\nK\nand the used distance metric. For the two issues, many methods either to acquire the adaptive\nK\nor to learn a variant metric have been presented and yielded appropriate performance. However, most of the existing methods ignore the fact that these two factors can be jointly learned. Besides, nearly all the metric learning methods aim to shrink intra-class distance while expanding inter-class distance. In this way, embedding the learned metric directly into the K-NN does not efficiently improve its accuracy. To address these issues, we propose a joint K-NN algorithm with the help of evidence theory, optimizing the joint learning of adaptive\nK\nand distance matrix based on the feedback from error function. Ablation study demonstrates the performance improvement from the joint learning, and comparison experiments on real-world datasets show that our approach consumes competitive running time and achieves better performance than other state-of-the-art algorithms.}
}


@inproceedings{DBLP:conf/icde/ZhongZFD22,
	author = {Ziyue Zhong and
                  Meihui Zhang and
                  Ju Fan and
                  Chenxiao Dou},
	title = {Semantics Driven Embedding Learning for Effective Entity Alignment},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {2127--2140},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00205},
	doi = {10.1109/ICDE53745.2022.00205},
	timestamp = {Fri, 05 Aug 2022 16:24:00 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhongZFD22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Knowledge-based data service has become an emerging form of service in the world wide web (WWW). To ensure the service quality, a comprehensive knowledge base has to be constructed. Knowledge base integration is often a primary way to improve the completeness. In this paper, we focus on the fundamental problem in knowledge base integration, i.e., entity alignment (EA). EA has been studied for years. Traditional approaches focus on the symbolic features of entities and propose various similarity measures to identify equivalent entities. With recent development in knowledge graph representation learning, embedding-based entity alignment has emerged, which encodes the entities into vectors according to the semantic or structural information and computes the relatedness of entities based on the vector representation. While embedding-based approaches achieve promising results, we identify some important information that are not well exploited in existing works: 1) The neighboring entities contribute differently in the EA process, and should be carefully assigned the importance in learning the relatedness of entities; 2) The attribute values (especially the long texts) contain rich semantics that can build supplementary associations between entities. To this end, we propose SDEA - a Semantics Driven entity embedding method for Entity Alignment. SDEA consists of two modules, namely attribute embedding and relation embedding. The attribute embedding captures the semantic information from attribute values with a pre-trained transformer-based language model. The relation embedding selectively aggregates the semantic information from neighbors using a GRU model equipped with an attention mechanism. Both attribute embedding and relation embedding are driven by semantics, building bridges between entities. Experimental results show that our method significantly outperforms the state-of-the-art approaches on three benchmarks.}
}


@inproceedings{DBLP:conf/icde/ChenZZYJ22,
	author = {Xuanhao Chen and
                  Yan Zhao and
                  Kai Zheng and
                  Bin Yang and
                  Christian S. Jensen},
	title = {Influence-aware Task Assignment in Spatial Crowdsourcing},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {2141--2153},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00206},
	doi = {10.1109/ICDE53745.2022.00206},
	timestamp = {Wed, 07 Dec 2022 23:09:59 +0100},
	biburl = {https://dblp.org/rec/conf/icde/ChenZZYJ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the widespread diffusion of smartphones, Spatial Crowdsourcing (SC), which aims to assign spatial tasks to mobile workers, has drawn increasing attention in both academia and industry. One of the major issues is how to best assign tasks to workers. Given a worker and a task, the worker will choose to accept the task based on her affinity towards the task, and the worker can propagate the information of the task to attract more workers to perform it. These factors can be measured as worker-task influence. Since workers' affinities towards tasks are different and task issuers may ask workers who performed tasks to propagate the information of tasks to attract more workers to perform them, it is important to analyze worker-task influence when making assignments. We propose and solve a novel influence-aware task assignment problem in SC, where tasks are assigned to workers in a manner that achieves high worker-task influence. In particular, we aim to maximize the number of assigned tasks and worker-task influence. To solve the problem, we first determine workers' affinities towards tasks by identifying workers' historical task-performing patterns. Next, a Historical Acceptance approach is developed to measure workers' willingness of performing a task, i.e., the probability of workers visiting the location of the task when they are informed. Next, we propose a Random reverse reachable-based Propagation Optimization algorithm that exploits reverse reachable sets to calculate the probability of workers being informed about tasks in a social network. Based on worker-task influence derived from the above three factors, we propose three influence-aware task assignment algorithms that aim to maximize the number of assigned tasks and worker-task influence. Extensive experiments on two real-world datasets offer detailed insight into the effectiveness of our solutions.}
}


@inproceedings{DBLP:conf/icde/AnCZ22,
	author = {Shuai An and
                  Yang Cao and
                  Wenyue Zhao},
	title = {Competitive Consistent Caching for Transactions},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {2154--2167},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00207},
	doi = {10.1109/ICDE53745.2022.00207},
	timestamp = {Sat, 30 Sep 2023 09:44:49 +0200},
	biburl = {https://dblp.org/rec/conf/icde/AnCZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper studies cache policies for transactional caches. Different from conventional caches that focus on latency, transactional caches are primarily used to augment database systems and improve their transaction throughput by offloading read load onto the cache. A read transaction commits on the cache only if it is a consistent cache hit, i.e., all of its reads see a consistent view of the database. We prove that conventional cache policies are not competitive for transactions. We then show that for the large class of batching-based transaction systems, one can break the theoretical performance barrier of conventional cache policies via transaction consistency aware cache policies, although it is NP-complete to find the optimal ones. As a proof, we develop a consistent cache policy that is theoretically competitive under common cache schemes. To further exploit batching, we propose to reorder transactions within batches while guaranteeing that each transaction sees data values with bounded staleness. Using benchmarks and real-life workloads, we experimentally verify that our policy improves the transaction throughput of Memcached atop HBase by 126.95% on average, up to 479.27% higher than existing cache policies adopted for transactions.}
}


@inproceedings{DBLP:conf/icde/ZhuWXCQYH22,
	author = {Guanghui Zhu and
                  Wenjie Wang and
                  Zhuoer Xu and
                  Feng Cheng and
                  Mengchuan Qiu and
                  Chunfeng Yuan and
                  Yihua Huang},
	title = {{PSP:} Progressive Space Pruning for Efficient Graph Neural Architecture
                  Search},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {2168--2181},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00208},
	doi = {10.1109/ICDE53745.2022.00208},
	timestamp = {Wed, 23 Nov 2022 08:13:56 +0100},
	biburl = {https://dblp.org/rec/conf/icde/ZhuWXCQYH22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recently, graph neural network (GNN) has achieved great success in many graph learning tasks such as node classifi-cation and graph classification. However, there is no single GNN architecture that can fit different graph datasets. Designing an effective GNN for a specific graph dataset requires considerable expert experience and huge computational costs. Inspired by the success of neural architecture search (NAS), searching the GNN architectures automatically has attracted more and more attention. Motivated by the fact that the search space plays a critical role in the NAS, we propose a novel and effective graph neural architecture search method called PSP from the perspective of search space design in this paper. We first propose an expressive search space composed of multiple cells. Instead of searching the entire architecture, we focus on searching the architecture of the cell. Then, we propose a progressive space pruning-based algorithm to search the architectures efficiently. Moreover, the data-specific search spaces and architectures ob-tained by PSP can be transferred to new graph datasets based on meta-learning. Extensive experimental results on different types of graph datasets reveal that PSP outperforms the state-of-the-art handcrafted architectures and the existing NAS methods in terms of effectiveness and efficiency.}
}


@inproceedings{DBLP:conf/icde/GuZXCFHDYDCH22,
	author = {Rong Gu and
                  Kai Zhang and
                  Zhihao Xu and
                  Yang Che and
                  Bin Fan and
                  Haojun Hou and
                  Haipeng Dai and
                  Li Yi and
                  Yu Ding and
                  Guihai Chen and
                  Yihua Huang},
	title = {Fluid: Dataset Abstraction and Elastic Acceleration for Cloud-native
                  Deep Learning Training Jobs},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {2182--2195},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00209},
	doi = {10.1109/ICDE53745.2022.00209},
	timestamp = {Wed, 23 Nov 2022 08:07:23 +0100},
	biburl = {https://dblp.org/rec/conf/icde/GuZXCFHDYDCH22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Nowdays, it is prevalent to train deep learning (DL) models in cloud-native platforms that actively leverage containerization and orchestration technologies for high elasticity, low and flexible operation cost, and many other benefits. However, it also faces new challenges and our work is focusing on those related to I/O throughput for training, including complex data access with complicated performance tuning, lack of cache capacity with specialized hardware to match its high and dynamic I/O requirement, and inefficient I/O resource sharing across different training jobs. We propose Fluid, a cloud-native platform that provides DL training jobs with a data abstraction called Fluid Dataset to access training data from heterogeneous sources in a unified manner with transparent and elastic data acceleration powered by auto-tuned cache runtimes. In addition, it comes with an on-the-fly cache system autoscaler that can intelligently scale up and down the cache capacity to match the online training speed of each individual DL job. To improve the overall performance of multiple DL jobs, Fluid can co-orchestrate the data cache and DL jobs by arranging job scheduling in an appropriate order. Our experimental results show significant performance improvement of each individual DL job which uses dynamic computing resources with Fluid. In addition, for scheduling multiple DL jobs with same datasets, Fluid gives around 2x performance speedup when integrated with existing widely-used and cutting-edge scheduling solutions. Fluid is now an open source project hosted by Cloud Native Computing Foundation (CNCF) with adopters in production including Alibaba Cloud, Tencent Cloud, Weibo.com, China Telecom, etc.}
}


@inproceedings{DBLP:conf/icde/ZhouLLJLWF22,
	author = {Xuanhe Zhou and
                  Luyang Liu and
                  Wenbo Li and
                  Lianyuan Jin and
                  Shifu Li and
                  Tianqing Wang and
                  Jianhua Feng},
	title = {AutoIndex: An Incremental Index Management System for Dynamic Workloads},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {2196--2208},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00210},
	doi = {10.1109/ICDE53745.2022.00210},
	timestamp = {Wed, 06 Dec 2023 13:35:23 +0100},
	biburl = {https://dblp.org/rec/conf/icde/ZhouLLJLWF22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Indexes are vital to enhance the lookup on single or multiple columns, and building proper indexes can significantly improve the database performance. Existing works focus on adding new indexes that can benefit the read queries, but they have several limitations. First, real-world workloads may have numerous queries and it is tricky to analyze their index requirements and find the most beneficial indexes within resource limit. Second, they fail to consider the update of existing indexes, which may be redundant or even have negative effects to current workload. Third, they cannot estimate the index maintenance costs, which are affected by multiple index utilization factors and can significantly affect the index benefits, especially for high-write-ratio workloads. To address those challenges, we propose an incremental index management system Autoindex for dynamic workloads. First, to support incremental index management, we map the incoming queries into query templates and efficiently generate promising candidate indexes from matched templates. And then we propose to utilize Monte Carlo Tree Search to incrementally add indexes from the candidate indexes or remove indexes from existing indexes, so as to ensure high workload performance. Besides, we propose a deep index estimation model, which integrates the practical experience to extract critical cost features and applies deep regression to estimate index benefits from historical index management data. We have implemented the modules like candidate index generation and index estimator in an open-sourced database system openGauss. Experimental re-sults showed that our method outperformed existing approaches on both testing and real-world workloads.}
}


@inproceedings{DBLP:conf/icde/CaoSCLW22,
	author = {Jiangxia Cao and
                  Jiawei Sheng and
                  Xin Cong and
                  Tingwen Liu and
                  Bin Wang},
	title = {Cross-Domain Recommendation to Cold-Start Users via Variational Information
                  Bottleneck},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {2209--2223},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00211},
	doi = {10.1109/ICDE53745.2022.00211},
	timestamp = {Fri, 05 Aug 2022 16:24:00 +0200},
	biburl = {https://dblp.org/rec/conf/icde/CaoSCLW22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recommender systems have been widely deployed in many real-world applications, but usually suffer from the long-standing user cold-start problem. As a promising way, Cross-Domain Recommendation (CDR) has attracted a surge of inter-est, which aims to transfer the user preferences observed in the source domain to make recommendations in the target domain. Previous CDR approaches mostly achieve the goal by following the Embedding and Mapping (EMCDR) idea which attempts to learn a mapping function to transfer the pre-trained user repre-sentations (embeddings) from the source domain into the target domain. However, they pre-train the user/item representations independently for each domain, ignoring to consider both domain interactions simultaneously. Therefore, the biased pre-trained representations inevitably involve the domain-specific information which may lead to negative impact to transfer information across domains. In this work, we consider a key point of the CDR task: what information needs to be shared across domains? To achieve the above idea, this paper utilizes the information bottleneck (IB) principle, and proposes a novel approach termed as CDRIB to enforce the representations encoding the domain-shared information. To derive the unbiased representations, we devise two IB regularizers to model the cross-domain/in-domain user-item interactions simultaneously and thereby CDRIB could consider both domain interactions jointly for de-biasing. With an additional contrastive information regularizer, CDRIB can also capture cross-domain user-user correlations. In this way, those regularizers encourage the representations to encode the domain-shared information, which has the capability to make recommendations in both domains directly. To the best of our knowledge, this paper is the first work to capture the domain-shared information for cold-start users via variational information bottleneck. Empirical experiments illustrate that CDRIB outperforms the state-of-the-art approaches on four real-world cross-domain datasets, demonstrating the effectiveness of adopting the information bottleneck for CDR.}
}


@inproceedings{DBLP:conf/icde/JiangCZZMHWYC22,
	author = {Yuezihan Jiang and
                  Yu Cheng and
                  Hanyu Zhao and
                  Wentao Zhang and
                  Xupeng Miao and
                  Yu He and
                  Liang Wang and
                  Zhi Yang and
                  Bin Cui},
	title = {Zoomer: Boosting Retrieval on Web-scale Graphs by Regions of Interest},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {2224--2236},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00212},
	doi = {10.1109/ICDE53745.2022.00212},
	timestamp = {Tue, 13 Aug 2024 08:04:16 +0200},
	biburl = {https://dblp.org/rec/conf/icde/JiangCZZMHWYC22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We introduce Zoomer, a system deployed at Taobao, the largest e-commerce platform in China, for training and serving GNN-based recommendations over web-scale graphs. Zoomer is designed for tackling two challenges presented by the massive user data at Taobao: low training/serving efficiency due to the huge scale of the graphs, and low recommendation quality due to the information overload which distracts the recommendation model from specific user intentions. Zoomer achieves this by introducing a key concept, Region of Interests (ROI) in GNNs for recommendations, i.e., a neighborhood region in the graph with significant relevance to a strong user intention. Zoomer narrows the focus from the whole graph and “zooms in” on the more relevant ROIs, thereby reducing the training/serving cost and mitigating the information overload at the same time. With carefully designed mechanisms, Zoomer identifies the interest expressed by each recommendation request, constructs an ROI subgraph by sampling with respect to the interest, and guides the GNN to reweigh different parts of the ROI towards the interest by a multi-level attention module. Deployed as a large-scale distributed system, Zoomer supports graphs with billions of nodes for training and thousands of requests per second for serving. Zoomer achieves up to 14x speedup when downsizing sampling scales with comparable (even better) AUC performance than baseline methods. Besides, both the offline evaluation and online A/B test demonstrate the effectiveness of Zoomer.}
}


@inproceedings{DBLP:conf/icde/YanCGKJP22,
	author = {Da Yan and
                  Md Mashiur Rahman Chowdhury and
                  Guimu Guo and
                  Jalal Khalil and
                  Zhe Jiang and
                  Sushil K. Prasad},
	title = {Distributed Task-Based Training of Tree Models},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {2237--2249},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00213},
	doi = {10.1109/ICDE53745.2022.00213},
	timestamp = {Tue, 07 May 2024 20:05:36 +0200},
	biburl = {https://dblp.org/rec/conf/icde/YanCGKJP22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Decision trees and tree ensembles are popular supervised learning models on tabular data. Two recent research trends on tree models stand out: (1) bigger and deeper models with many trees, and (2) scalable distributed training frameworks. However, existing implementations on distributed systems are IO-bound leaving CPU cores underutilized. They also only find best node-splitting conditions approximately due to row-based data partitioning scheme. In this paper, we target the exact training of tree models by effectively utilizing the available CPU cores. The resulting system called TreeServer adopts a column-based data partitioning scheme to minimize communication, and a node-centric task-based engine to fully explore the CPU parallelism. Experiments show that TreeServer is up to 10× faster than models in Spark MLlib. We also showcase TreeServer's high training throughput by using it to build big “deep forest” models.}
}


@inproceedings{DBLP:conf/icde/TianZZ22,
	author = {Yao Tian and
                  Xi Zhao and
                  Xiaofang Zhou},
	title = {{DB-LSH:} Locality-Sensitive Hashing with Query-based Dynamic Bucketing},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {2250--2262},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00214},
	doi = {10.1109/ICDE53745.2022.00214},
	timestamp = {Fri, 01 Sep 2023 11:19:57 +0200},
	biburl = {https://dblp.org/rec/conf/icde/TianZZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Among many solutions to the high-dimensional approximate nearest neighbor (ANN) search problem, locality sensitive hashing (LSH) is known for its sub-linear query time and robust theoretical guarantee on query accuracy. Traditional LSH methods can generate a small number of candidates quickly from hash tables but suffer from large index sizes and hash boundary problems. Recent studies to address these issues often incur extra overhead to identify eligible candidates or remove false positives, making query time no longer sub-linear. To address this dilemma, in this paper we propose a novel LSH scheme called DB-LSH which supports efficient ANN search for large high-dimensional datasets. It organizes the projected spaces with multi-dimensional indexes rather than using fixed-width hash buckets. Our approach can significantly reduce the space cost by avoiding the need to maintain many hash tables for different bucket sizes. During the query phase of DB-LSH, a small number of high-quality candidates can be generated efficiently by dynamically constructing query-based hypercubic buckets with the required widths through index-based window queries. For a dataset of\nn\nd-dimensional points with approximation ratio\nc\n, our rigorous theoretical analysis shows that DB-LSH achieves a smaller query cost\nO(\nn\nρ\ndlogn)\n, where\nρ\n∗\nis bounded by\n1/\nc\nα\nversus a bound of\n1/c\nin the existing work. An extensive range of experiments on real-world data demonstrate the superiority of DB-LSH over state-of-the-art methods on both efficiency and accuracy.}
}


@inproceedings{DBLP:conf/icde/MassriMPM22,
	author = {Maria Massri and
                  Zolt{\'{a}}n Mikl{\'{o}}s and
                  Philippe Raipin Parv{\'{e}}dy and
                  Pierre Meye},
	title = {Clock-G: {A} temporal graph management system with space-efficient
                  storage technique},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {2263--2276},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00215},
	doi = {10.1109/ICDE53745.2022.00215},
	timestamp = {Fri, 05 Aug 2022 16:24:00 +0200},
	biburl = {https://dblp.org/rec/conf/icde/MassriMPM22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {IoT applications can be naturally modeled as a graph where the edges represent the interactions between devices, sensors, and their environment. Thing'in 1 1 https://www.thinginthefuture.com/ is a platform, initiated by Orange 2 2 Orange is a French multinational telecommunication operator. The platform manages a graph of millions of connected and non-connected objects using a commercial graph database. The graph of Thing'in is dynamic because loT devices create temporary connections between each other. Analyzing the history of these connections paves the way to new promising applications such as object tracking, anomaly detection, and forecasting the future behavior of devices. However, existing com-mercial graph databases are not designed with native temporal support which limits their usability in such use cases. In this paper, we discuss the design of a temporal graph management system Clock-G and introduce a new space-efficient storage technique δ-Copy+Log, Clock-G is designed by the devel-opers of the Thing'in platform and is currently being deployed into production. It differentiates from existing temporal graph management systems by adopting the δ-Copy+Log technique. This technique targets the mitigation of the apparent trade-off between the conflicting goals of the reduction of space usage and acceleration of query execution time. Our experimental results demonstrate that the δ-Copy+Log presents an overall better performance as compared to traditional storage methods in terms of space usage and query evaluation time.}
}


@inproceedings{DBLP:conf/icde/KosyfakiM22,
	author = {Chrysanthi Kosyfaki and
                  Nikos Mamoulis},
	title = {Provenance in Temporal Interaction Networks},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {2277--2290},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00216},
	doi = {10.1109/ICDE53745.2022.00216},
	timestamp = {Tue, 21 Mar 2023 20:50:56 +0100},
	biburl = {https://dblp.org/rec/conf/icde/KosyfakiM22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In temporal interaction networks (TINs), vertices correspond to entities, which exchange data quantities (e.g., money, bytes, messages) over time. We study the problem of con-tinuously tracking the origins of quantities at network vertices, as interactions take place over time. We target applications, such as financial exchange networks, where the selected transferred units at each interaction are not specified. We investigate several quantity selection policies that apply to different application scenarios. For each policy, we propose space- and time-efficient meta-data propagation mechanisms for continuously tracking provenance at vertices. For the hard case of proportional selection policy, we reduce the cost of tracking in practice, by either (i) limiting provenance tracking to a subset of vertices or groups of vertices, or (ii) tracking provenance only for quantities that were generated in the near past or limiting the provenance data in each vertex by a budget constraint. Our experimental evaluation on real datasets demonstrate the efficiency and scalability of our techniques compared to baseline approaches that extend flow computation algorithms to track provenance.}
}


@inproceedings{DBLP:conf/icde/WangZLZL22,
	author = {Kai Wang and
                  Wenjie Zhang and
                  Xuemin Lin and
                  Ying Zhang and
                  Shunyang Li},
	title = {Discovering Hierarchy of Bipartite Graphs with Cohesive Subgraphs},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {2291--2305},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00217},
	doi = {10.1109/ICDE53745.2022.00217},
	timestamp = {Sun, 12 Nov 2023 02:08:10 +0100},
	biburl = {https://dblp.org/rec/conf/icde/WangZLZL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Bipartite graph is a widely used model to describe relationships between two different types of entities. Exploring graph hierarchy with cohesive subgraphs has been extensively studied on unipartite graphs, while only a few works focus on bipartite graphs. In this paper, we propose the bipartite hierarchy, which is the first model to discover the hierarchical structure of bipartite graphs based on the concept of\n(\nα\n2\nβ)−\ncore and graph connectivity. Notably,\n(α,β)−core\nis a vertex- centric model that conforms to the special structure of bipartite graphs (i.e., formed by two different vertex layers). Accordingly, the bipartite hierarchy has two parts (i.e., the upper and lower hierarchies) to record the hierarchical relationships among upper and lower vertices, respectively. We theoretically prove that the bipartite hierarchy is space-efficient (i.e., its space cost is linear to the graph size) and clearly illustrate its structure via visualization. In addition, efficient algorithms for building the bipartite hierarchy are proposed by utilizing the nested property of\n(α,β)−core\n. Since bipartite graphs can be dynamically changed in real-world scenarios, we also study the bipartite hierarchy maintenance algorithms against the edge insertion/deletion cases. These algorithms can effectively identify the affected regions to limit computation scope and avoid re-building the bipartite hierarchy from scratch. Extensive experiments on 10 real-world graphs not only demonstrate the effectiveness of the proposed bipartite hierarchy but also validate the efficiency of our hierarchy construction and maintenance algorithms.}
}


@inproceedings{DBLP:conf/icde/HeLRHBLZ22,
	author = {Huajun He and
                  Ruiyuan Li and
                  Sijie Ruan and
                  Tianfu He and
                  Jie Bao and
                  Tianrui Li and
                  Yu Zheng},
	title = {TraSS: Efficient Trajectory Similarity Search Based on Key-Value Data
                  Stores},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {2306--2318},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00218},
	doi = {10.1109/ICDE53745.2022.00218},
	timestamp = {Sat, 30 Sep 2023 09:44:50 +0200},
	biburl = {https://dblp.org/rec/conf/icde/HeLRHBLZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Similarity search has recently become an integral part of many trajectory data analysis tasks. As the number of trajectories increases, we must find similar trajectories among massive trajectories, necessitating a scalable and efficient frame-work. Typically, massive trajectory data can be managed by key-value data stores. However, existing works with key-value data stores use a coarse representation to store trajectory data. Besides, they do not provide efficient query processing to search similar trajectories. Thus, this paper proposes TraSS, an efficient framework for trajectory similarity search in key-value data stores. We propose a novel spatial index, XZ*, which utilizes fine-grained index spaces with irregular shapes and sizes to represent trajectories elaborately. Further, we devise a bijective function from the index spaces of XZ* to continuous integers, which is simple but effective for query processing. To improve the efficiency of similarity search, we employ two steps to prune dissimilar trajectories: (1) global pruning. It leverages the XZ* index to prune index spaces with no trajectories similar to the query trajectory. Our global pruning can only pick out index spaces with similar sizes and shapes to the query trajectory. Compared to the state-of-the-art index, our global pruning reduces I/O overhead up to 66.4 % during query processing; (2) local filtering. It filters dissimilar trajectories in a way with low complexity. We use a few representative features extracted from a trajectory by the Douglas-Peucker algorithm to accelerate the local filtering. We implement an open-source toolkit (TraSS) on a popular key-value data store. Extensive experiments show that TraSS outperforms state-of-the-art solutions.}
}


@inproceedings{DBLP:conf/icde/KangLS22,
	author = {Shinhwan Kang and
                  Kyuhan Lee and
                  Kijung Shin},
	title = {Personalized Graph Summarization: Formulation, Scalable Algorithms,
                  and Applications},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {2319--2332},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00219},
	doi = {10.1109/ICDE53745.2022.00219},
	timestamp = {Fri, 05 Aug 2022 16:24:02 +0200},
	biburl = {https://dblp.org/rec/conf/icde/KangLS22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Are users of an online social network interested equally in all connections in the network? If not, how can we obtain a summary of the network personalized to specific users? Can we use the summary for approximate query answering? As massive graphs (e.g., online social networks, hyperlink networks, and road networks) have become pervasive, graph compression has gained importance for the efficient processing of such graphs with limited resources. Graph summarization is an extensively-studied lossy compression method. It provides a summary graph where nodes with similar connectivity are merged into supernodes, and a variety of graph queries can be answered approximately from the summary graph. In this work, we introduce a new problem, namely personalized graph summarization, where the objective is to obtain a summary graph where more emphasis is put on connections closer to a given set of target nodes. Then, we propose Pegasus, a linear-time algorithm for the problem. Through experiments on six real-world graphs, we demonstrate that Pegasus is (a) Effective: node-similarity queries for target nodes can be answered significantly more accurately from personalized summary graphs than from non-personalized ones of similar size, (b) Scalable: it summarizes graphs with up to one billion edges, and (c) Applicable to distributed multi-query answering: it successfully replaces graph partitioning for communication-free multi-query processing.}
}


@inproceedings{DBLP:conf/icde/ZhaoWZLZH22,
	author = {Gengda Zhao and
                  Kai Wang and
                  Wenjie Zhang and
                  Xuemin Lin and
                  Ying Zhang and
                  Yizhang He},
	title = {Efficient Computation of Cohesive Subgraphs in Uncertain Bipartite
                  Graphs},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {2333--2345},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00220},
	doi = {10.1109/ICDE53745.2022.00220},
	timestamp = {Mon, 05 Feb 2024 20:31:13 +0100},
	biburl = {https://dblp.org/rec/conf/icde/ZhaoWZLZH22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Bipartite graphs are extensively used to model relationships between two different types of entities. In many real-world bipartite graphs, relationships are naturally uncertain due to various reasons such as data noise, measurement error and imprecision of data, leading to uncertain bipartite graphs. In this paper, we propose the ( $\\alpha,\\beta,\\eta$ )-core model, which is the first cohesive subgraph model on uncertain bipartite graphs. To capture the uncertainty of relationships/edges, $\\eta$ -degree is adopted to measure the vertex engagement level, which is the largest integer $k$ such that the probability of a vertex having at least $k$ neighbors is not less than $\\eta$ . Given degree constraints $\\alpha$ and $\\beta$ , and a probability threshold $\\eta$ , the ( $\\alpha, \\beta, \\eta$ )-core requires that each vertex on the upper or lower level have $\\eta$ -degree no less than $\\alpha$ or $\\beta$ , respectively. An ( $\\alpha, \\beta, \\eta$ )-core can be derived by iteratively removing a vertex with $\\eta$ -degree below the degree constraint and updating the $\\eta$ -degrees of its neighbors. This incurs prohibitively high cost due to the $\\eta$ -degree computation and updating, and is not scalable to large bipartite graphs. This motivates us to develop index-based approaches. We propose a basic full index that stores ( $\\alpha, \\beta, \\eta$ )-core for all possible $\\alpha, \\beta$ , and $\\eta$ combinations, thus supporting optimal retrieval of the vertices in any ( $\\alpha, \\beta, \\eta$ )-core. Due to its long construction time and high space complexity, we further propose a probability-aware index to achieve a balance between time and space costs. To efficiently build the probability-aware index, we design a bottom-up index construction algorithm and a top-down index construction algorithm. Extensive experiments are conducted on real-world datasets with generated edge probabilities under different distributions, which show that (1) ( $\\alpha,\\beta,\\eta$ )-core is an effective model; (2) index construction and query processing are significantly sped up by the proposed techniques.}
}


@inproceedings{DBLP:conf/icde/AbidiCLZ22,
	author = {Aman Abidi and
                  Lu Chen and
                  Chengfei Liu and
                  Rui Zhou},
	title = {On Maximising the Vertex Coverage for Top-k t-Bicliques in Bipartite
                  Graphs},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {2346--2358},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00221},
	doi = {10.1109/ICDE53745.2022.00221},
	timestamp = {Fri, 21 Jul 2023 08:42:27 +0200},
	biburl = {https://dblp.org/rec/conf/icde/AbidiCLZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Enumeration of all maximal bicliques in bipartite graphs is a well-studied fundamental problem. However, a wide range of applications need less overlapping bicliques with specific size constraints instead of all the maximal bicliques. In this paper, we study a new biclique problem, called the top-k t-biclique coverage problem. A t-biclique is a biclique with a size constraint $t$ for one vertex set and the problem aims to find $k$ t-bicliques maximising the coverage on the other vertex set. The top-k t-biclique coverage problem has novel applications such as finding top-k courses while maximising student engagement. We prove that this problem is NP-hard. A straightforward way to address the problem first needs to enumerate and store all t-bicliques and then greedily select $k$ promising t-bicliques, leading an approximate guarantee on the coverage. However, it takes exponential space, which is impractical. We then apply a fast approximation scheme to solve this problem, which shaves the exponential space consumption by progressively updating top-k results during the t-biclique enumeration. Observing that the fast approximation algorithm takes too much time on updating the results due to the coverage is computed from scratch for each update, an online index is devised to address the drawback. Due the hardness of the problem, even the fast approximation algorithm cannot scale to large dataset. To devise a scalable solution, we then propose a heuristic algorithm running in polynomial time. Thanks for four carefully designed heuristic rules, the heuristic algorithm can find large coverage top-k t-bicliques extremely fast for large datasets. Apart from that, the heuristic result with large coverage can effectively prune unpromising enumerations in the fast greedy algorithm, which improves the efficiency of the fast approximation algorithm without compromising the approximation ratio. Extensive experiments are conducted on real datasets to justify the effectiveness and efficiency of the proposed algorithms.}
}


@inproceedings{DBLP:conf/icde/QinCTLLLZ22,
	author = {Xuedi Qin and
                  Chengliang Chai and
                  Nan Tang and
                  Jian Li and
                  Yuyu Luo and
                  Guoliang Li and
                  Yaoyu Zhu},
	title = {Synthesizing Privacy Preserving Entity Resolution Datasets},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {2359--2371},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00222},
	doi = {10.1109/ICDE53745.2022.00222},
	timestamp = {Fri, 05 Aug 2022 16:24:02 +0200},
	biburl = {https://dblp.org/rec/conf/icde/QinCTLLLZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Entity resolution (ER) is a core problem in data integration. Many companies have lots of datasets where ER needs to be conducted to integrate the data. On the one hand, it is nontrivial for non-ER experts within companies to design ER solutions. On the other hand, most companies are reluctant to release their real datasets for multiple reasons (e.g., privacy issues). A typical solution from the machine learning (ML) and the statistical community is to create surrogate (a.k.a. analogous) datasets based on the real dataset, release these surrogate datasets to the public to train ML models, such that these models trained on surrogate datasets can be either directly used or be adapted for the real dataset by the companies. In this paper, we study a new problem of synthesizing surrogate ER datasets using transformer models, with the goal that the ER model trained on the synthesized dataset can be used directly on the real dataset. We propose privacy preserving methods to synthesize ER datasets: we first learn the true similarity distributions of both matching and non-matching entity pairs from real dataset. We then devise algorithms that satisfy differential privacy and can synthesize fake but semantically meaningful entities, add matching and non-matching labels to these fake entity pairs, and ensure that the fake and real datasets have similar distributions. We also describe a method for entity rejection to avoid synthesizing bad fake entities that may destroy the original distributions. Extensive experiments show that ER matchers trained on real and synthetic ER datasets have very close performance on the same test sets - their\nF1\nscores differ within 6% on 3 commonly used ER datasets, and their average precision, recall differences are less than 5%.}
}


@inproceedings{DBLP:conf/icde/ZhengWGMHZJ22,
	author = {Bolong Zheng and
                  Jingyi Wan and
                  Yongyong Gao and
                  Yong Ma and
                  Kai Huang and
                  Xiaofang Zhou and
                  Christian S. Jensen},
	title = {Workload-Aware Shortest Path Distance Querying in Road Networks},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {2372--2384},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00223},
	doi = {10.1109/ICDE53745.2022.00223},
	timestamp = {Fri, 08 Nov 2024 08:36:36 +0100},
	biburl = {https://dblp.org/rec/conf/icde/ZhengWGMHZJ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Computing shortest-path distances in road networks is core functionality in a range of applications. To enable the efficient computation of such distance queries, existing proposals frequently apply 2-hop labeling that constructs a label for each vertex and enables the computation of a query by performing only a linear scan of labels. However, few proposals take into account the spatio-temporal characteristics of query workloads. We observe that real-world workloads exhibit (1) spatial skew, meaning that only a small subset of vertices are queried frequently, and (2) temporal locality, meaning that adjacent time intervals have similar query distributions. We propose a Workload-aware Core-Forest label index (WCF) to exploit spatial skew in workloads. In addition, we develop a Reinforcement Learning based Time Interval Partitioning (RL-TIP) algorithm that exploits temporal locality to partition workloads to achieve further performance improvements. Extensive experiments with real-world data offer insights into the performance of the proposals, showing that they achieve 62% speedup on average for query processing with less preprocessing time and space overhead when compared with the state-of-the-art proposals.}
}


@inproceedings{DBLP:conf/icde/SchaferM22,
	author = {Nico Sch{\"{a}}fer and
                  Sebastian Michel},
	title = {{BETZE:} Benchmarking Data Exploration Tools with (Almost) Zero Effort},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {2385--2398},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00224},
	doi = {10.1109/ICDE53745.2022.00224},
	timestamp = {Fri, 05 Aug 2022 16:24:01 +0200},
	biburl = {https://dblp.org/rec/conf/icde/SchaferM22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we propose BETZE, a benchmark generator to evaluate the performance of data exploration solutions for semi-structured data. It is tailored to the typical query capabilities of modern JSON document stores and can be extended to match more. At its core, the query generator mimics the behavior of a data scientist through a model similar to the random surfer idea known from PageRank. We propose preset parameters that pose different query loads to the system, intended to reflect novice, intermediate, and expert users interacting with the system. The proposed approach analyzes a given JSON dataset and generates queries into an intermediate representation that is then translated to system-specific query syntax. We have implemented support for MongoDB, PostgreSQL, jq, and our own JSON processor JODA, and describe how additional tools can be supported. To get started, we report on a first experimental study, showing the versatility of the benchmark generator, using the NoBench dataset, and real-world data obtained from Twitter and Reddit.}
}


@inproceedings{DBLP:conf/icde/LiCJPGH22,
	author = {Tianyi Li and
                  Lu Chen and
                  Christian S. Jensen and
                  Torben Bach Pedersen and
                  Yunjun Gao and
                  Jilin Hu},
	title = {Evolutionary Clustering of Moving Objects},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {2399--2411},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00225},
	doi = {10.1109/ICDE53745.2022.00225},
	timestamp = {Wed, 07 Dec 2022 23:09:58 +0100},
	biburl = {https://dblp.org/rec/conf/icde/LiCJPGH22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The widespread deployment of smartphones, net-worked in-vehicle devices with geo-positioning capabilities, and vessel tracking technologies renders it feasible to collect the evolving geo-locations of populations of land- and sea-based moving objects. The continuous clustering of such data can enable a variety of real-time services, such as road traffic management and vessel collision risk assessment. However, little attention has so far been given to the quality of moving-object clusters-for example, it is beneficial to smooth short-term fluctuations in clusters to achieve robustness to exceptional data and to improve existing applications. We propose the notion of evolutionary clustering of moving objects, abbreviated ECM, that enhances the quality of moving object clustering by means of temporal smoothing that prevents abrupt changes in clusters across successive timestamps. Employing the notions of snapshot and historical costs, we formalize ECM and formulate ECM as an optimization problem. We prove that ECM can be performed approximately in linear time, thus eliminating iterative processes employed in previous studies. Further, we propose a minimal-group structure and a seed-point shifting strategy to facilitate temporal smoothing. Finally, we present all algorithms underlying ECM along with a set of optimization techniques. Extensive experiments with three real-life datasets offer insights into ECM and show that it outperforms state-of-the-art solutions in terms of both clustering quality and clustering efficiency.}
}


@inproceedings{DBLP:conf/icde/ArenasBAS22,
	author = {Marcelo Arenas and
                  Pedro Bahamondes and
                  Amir Aghasadeghi and
                  Julia Stoyanovich},
	title = {Temporal Regular Path Queries},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {2412--2425},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00226},
	doi = {10.1109/ICDE53745.2022.00226},
	timestamp = {Fri, 05 Aug 2022 16:24:01 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ArenasBAS22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the last decade, substantial progress has been made towards standardizing the syntax of graph query languages, and towards understanding their semantics and complexity of evaluation. In this paper, we consider temporal property graphs (TPGs) and propose temporal regular path queries (TRPQs) that incorporate time into TPG navigation. Starting with design principles, we propose a natural syntactic extension of the MATCH clause of popular graph query languages. We then formally present the semantics of TRPQs, and study the complexity of their evaluation. We show that TRPQs can be evaluated in polynomial time if TPGs are time-stamped with time points, and identify fragments of the TRPQ language that admit efficient evaluation over a more succinct interval-annotated representation. Finally, we implement a fragment of the language in a state-of-the-art dataflow framework, and experimentally demonstrate that TRPQ can be evaluated efficiently.}
}


@inproceedings{DBLP:conf/icde/ChowdhuryMS22,
	author = {Kanchan Chowdhury and
                  Venkata Vamsikrishna Meduri and
                  Mohamed Sarwat},
	title = {A Machine Learning-Aware Data Re-partitioning Framework for Spatial
                  Datasets},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {2426--2439},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00227},
	doi = {10.1109/ICDE53745.2022.00227},
	timestamp = {Fri, 05 Aug 2022 16:24:01 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ChowdhuryMS22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Spatial datasets are used extensively to train machine learning (ML) models for applications such as spatial regression, classification, clustering, and deep learning. Most of the real-world spatial datasets are often too large, and many spatial ML algorithms represent the geographical region as a grid consisting of several spatial cells. If the granularity of the grid is too fine, that results in a large number of grid cells leading to long training time and high memory consumption issues during the model training. To alleviate this problem, we propose a machine learning-aware spatial data re-partitioning framework that substantially reduces the granularity of the spatial grid. Our spatial data re-partitioning approach combines fine-grained, adjacent spatial cells from a grid into coarser cells prior to training an ML model. During this re-partitioning phase, we keep the information loss within a user-defined threshold without significantly degrading the accuracy of the ML model. According to the empirical evaluation performed on several real-world datasets, the best results achieved by our spatial re-partitioning framework show that we can reduce the data volume and training time by up to 81%, while keeping the difference in prediction or classification error below 5% as compared to a model that is trained on the original input dataset, for most of the ML applications. Our re-partitioned framework also outperforms the state-of-the-art data reduction baselines by 2% to 20% w.r.t. prediction and classification errors.}
}


@inproceedings{DBLP:conf/icde/FanFZPFLZ22,
	author = {Zhenan Fan and
                  Huang Fang and
                  Zirui Zhou and
                  Jian Pei and
                  Michael P. Friedlander and
                  Changxin Liu and
                  Yong Zhang},
	title = {Improving Fairness for Data Valuation in Horizontal Federated Learning},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {2440--2453},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00228},
	doi = {10.1109/ICDE53745.2022.00228},
	timestamp = {Tue, 21 Mar 2023 20:50:55 +0100},
	biburl = {https://dblp.org/rec/conf/icde/FanFZPFLZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated learning is an emerging decentralized machine learning scheme that allows multiple data owners to work collaboratively while ensuring data privacy. The success of federated learning depends largely on the participation of data owners. To sustain and encourage data owners' participation, it is crucial to fairly evaluate the quality of the data provided by the data owners as well as their contribution to the final model and reward them correspondingly. Federated Shapley value, recently proposed by Wang et al. [Federated Learning, 2020], is a measure for data value under the framework of federated learning that satisfies many desired properties for data valuation. However, there are still factors of potential unfairness in the design of federated Shapley value because two data owners with the same local data may not receive the same evaluation. We propose a new measure called completed federated Shapley value to improve the fairness of federated Shapley value. The design depends on completing a matrix consisting of all the possible contributions by different subsets of the data owners. It is shown under mild conditions that this matrix is approximately low-rank by leveraging concepts and tools from optimization. Both theoretical analysis and empirical evaluation verify that the proposed measure does improve fairness in many circumstances.}
}


@inproceedings{DBLP:conf/icde/JangK22,
	author = {Jun{-}Gi Jang and
                  U Kang},
	title = {DPar2: Fast and Scalable {PARAFAC2} Decomposition for Irregular Dense
                  Tensors},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {2454--2467},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00229},
	doi = {10.1109/ICDE53745.2022.00229},
	timestamp = {Fri, 05 Aug 2022 16:24:01 +0200},
	biburl = {https://dblp.org/rec/conf/icde/JangK22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Given an irregular dense tensor, how can we ef-ficiently analyze it? An irregular tensor is a collection of matrices whose columns have the same size and rows have different sizes from each other. PARAFAC2 decomposition is a fundamental tool to deal with an irregular tensor in applications including phenotype discovery and trend analysis. Although several PARAFAC2 decomposition methods exist, their efficiency is limited for irregular dense tensors due to the expensive computations involved with the tensor. In this paper, we propose DP AR2, a fast and scalable PARAFAC2 decomposition method for irregular dense tensors. DP AR2 achieves high efficiency by effectively compressing each slice matrix of a given irregular tensor, careful reordering of computations with the compression results, and exploiting the ir-regularity of the tensor. Extensive experiments show that DP AR2 is up to 6.0 x faster than competitors on real-world irregular tensors while achieving comparable accuracy. In addition, DP AR2 is scalable with respect to the tensor size and target rank.}
}


@inproceedings{DBLP:conf/icde/LiZPLWSWCGG22,
	author = {Ruiyuan Li and
                  Liang Zhang and
                  Juan Pan and
                  Junwen Liu and
                  Peng Wang and
                  Nianjun Sun and
                  Shanmin Wang and
                  Chao Chen and
                  Fuqiang Gu and
                  Songtao Guo},
	title = {Apache ShardingSphere: {A} Holistic and Pluggable Platform for Data
                  Sharding},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {2468--2480},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00230},
	doi = {10.1109/ICDE53745.2022.00230},
	timestamp = {Sun, 12 Mar 2023 13:55:44 +0100},
	biburl = {https://dblp.org/rec/conf/icde/LiZPLWSWCGG22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Traditional relational databases are nowadays over-whelmed by the increasing data volume and concurrent access. NoSQL databases can manage large-scale data, but most of them do not support complete transactions and standard SQL languages. NewSQL is proposed for both high scalability and transactional properties with SQL languages support. One type of NewSQL builds distributed systems from scratch, which is too radical for some critical applications. The other type of NewSQL, i.e., data sharding among relational databases, is a better option for these scenarios. This paper presents Apache ShardingSphere, the first top-level open-source platform for data sharding in Apache, which enables developers to use sharded databases like one database. Specifically Apache, ShardingSphere integrates six databases and designs and implements a complete SQL engine to route requests correctly and intelligently. Additionally it encapsulates three types of distributed transactions and provides two adaptors for different scenarios. Moreover it proposes a novel AutoTable strategy and a query language i.e DistSQL allowing database maintainers to easily configure the sharded databases. Further-more it provides many other pluggable features to better shard data. Extensive experiments are conducted using two famous benchmarking tools proving that Apache ShardingSphere is more efficient than eight state-of-the-art systems in our settings. All experimental source codes are publicly released. More than 170 companies are currently using Apache ShardingSphere.}
}


@inproceedings{DBLP:conf/icde/KangSW22,
	author = {Rui Kang and
                  Shaoxu Song and
                  Chaokun Wang},
	title = {Conditional Regression Rules},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {2481--2493},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00231},
	doi = {10.1109/ICDE53745.2022.00231},
	timestamp = {Sun, 04 Aug 2024 19:37:46 +0200},
	biburl = {https://dblp.org/rec/conf/icde/KangSW22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Mixed data distribution is widely observed, for example, the bird migration data consist of the observed locations of various birds in different years, varying in data distribution. Learning a single regression model over such a mixed data distribution is often ineffective, while manually segmenting the data, e.g., by bird, date or region, for learning individual models is truly labor-intensive. In this paper, we propose to automatically discover the regression models that apply conditionally to only a part of the data, namely conditional regression rules (CRRs), enlightened by the conditional functional dependencies (CFDs) that are FDs hold only in some data. Remarkably, a regression model may apply in different parts of data, e.g., the seasonal migration of birds is similar in different years. To capture the shared regression models, we investigate the inference of CRRs. An algorithm is devised to learn and discover CRRs from data, with the help of CRR inference. Extensive experiments on real-world datasets demonstrate that the discovered conditional regression rules are more effective than the regression models without conditions. In particular, with the inference of CRRs, the number of learned CRRs is significantly reduced without sacrificing rule semantics.}
}


@inproceedings{DBLP:conf/icde/JinDTBTC22,
	author = {Sian Jin and
                  Sheng Di and
                  Jiannan Tian and
                  Suren Byna and
                  Dingwen Tao and
                  Franck Cappello},
	title = {Improving Prediction-Based Lossy Compression Dramatically via Ratio-Quality
                  Modeling},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {2494--2507},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00232},
	doi = {10.1109/ICDE53745.2022.00232},
	timestamp = {Tue, 21 Mar 2023 20:50:56 +0100},
	biburl = {https://dblp.org/rec/conf/icde/JinDTBTC22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Error-bounded lossy compression is one of the most effective techniques for reducing scientific data sizes. However, the traditional trial-and-error approach used to configure lossy compressors for finding the optimal trade-off between reconstructed data quality and compression ratio is prohibitively expensive. To resolve this issue, we develop a general-purpose analytical ratio-quality model based on the prediction-based lossy compression framework, which can effectively foresee the reduced data quality and compression ratio, as well as the impact of lossy compressed data on post-hoc analysis quality. Our analytical model significantly improves the prediction-based lossy compression in three use-cases: (1) optimization of predictor by selecting the best-fit predictor; (2) memory compression with a target ratio; and (3) in-situ compression optimization by fine-grained tuning error-bounds for various data partitions. We evaluate our analytical model on 10 scientific datasets, demonstrating its high accuracy (93.47% accuracy on average) and low computational cost (up to 18.7x lower than the trial-and-error approach) for estimating the compression ratio and the impact of lossy compression on post-hoc analysis quality. We also verify the high efficiency of our ratio-quality model using different applications across the three use-cases. In addition, our experiment demonstrates that our modeling-based approach reduces the time to store the 3D RTM data with HDF5 by up to 3.4 x with 128 CPU cores over the traditional solution.}
}


@inproceedings{DBLP:conf/icde/PengCCX22,
	author = {Yun Peng and
                  Byron Choi and
                  Tsz Nam Chan and
                  Jianliang Xu},
	title = {{LAN:} Learning-based Approximate k-Nearest Neighbor Search in Graph
                  Databases},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {2508--2521},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00233},
	doi = {10.1109/ICDE53745.2022.00233},
	timestamp = {Fri, 05 Aug 2022 16:24:03 +0200},
	biburl = {https://dblp.org/rec/conf/icde/PengCCX22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The problem of k-nearest neighbor (k-NN) search is fundamental in graph databases, which has numerous real-world applications, such as bioinformatics, computer vision, and software engineering. Graph edit distance (GED) and maximum common subgraph (MCS)-based distance are the most widely used distance measures in k-NN search. However, computing the exact k-NNs of a query graph\nQ\nusing these measures is prohibitively time-consuming, as a large number of graph distance computations is needed, and computing GED and MCS are both NP-hard. In this paper, we study the approximate k-nearest neighbor (k-ANN) search with the aim of trading efficiency with a slight decrease in accuracy. Greedy routing on the proximity graph (PG) index is a state-of-the-art method for k-ANN search. However, such routing algorithms are not designed for graph databases, and simple adoption is inefficient. The core reason is that the exhaustive neighbor exploration at each routing step incurs a large number of distance computations (NDC). In this paper, we propose a learning-based k-ANN search method to reduce NDC. First, we propose to prune unpromising neighbors from distance computations. We use a graph learning model to rank the neighbors at each routing step and explore only the top neighbors. For the accuracy of rank prediction, we propose a neighbor ranking model that works only in the neighborhood of Q. Second, we propose a learning-based method to select the initial node for the routing. The initial node selected has a high probability of being in the neighborhood of Q, such that the neighbor ranking model can be used. Third, we propose a compressed GNN-graph to accelerate the neighbor ranking model and the initial node selection model. We prove that learning efficiency is improved without degrading the accuracy. Our extensive experiments show that our method is about 3.6x to 18.6x faster than the state-of-the-art methods on real-world datasets.}
}


@inproceedings{DBLP:conf/icde/ChenXOTZL22,
	author = {Yuedan Chen and
                  Guoqing Xiao and
                  M. Tamer {\"{O}}zsu and
                  Zhuo Tang and
                  Albert Y. Zomaya and
                  Kenli Li},
	title = {Exploiting Hierarchical Parallelism and Reusability in Tensor Kernel
                  Processing on Heterogeneous {HPC} Systems},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {2522--2535},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00234},
	doi = {10.1109/ICDE53745.2022.00234},
	timestamp = {Sat, 30 Sep 2023 09:44:49 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ChenXOTZL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Canonical Polyadic Decomposition (CPD) of sparse tensors is an effective tool in various machine learning and data analytics applications, in which sparse Matricized Tensor Times Khatri-Rao Product (MTTKRP) is the major performance bottleneck. To overcome this bottleneck and support efficient applications, this paper presents HPSpTM, an efficient sparse MTTKRP framework, to exploit the multi-level parallelism and reusability on heterogeneous HPC systems. HPSpTM incorporates: (1) a multi-level matrix-driven tiling engine that leverages the process- and thread-level parallelism of the underlying platform and data reusability based on the derived factor matrix-driven MTTKRP algorithm; (2) a tensor-driven parallel execution that enables buffering-aware scheduling and pipeline scheduling to optimize the performance in the tile granularity; (3) a partition-aware light weight data storage that exploits better data locality based on the proposed hierarchical and fine-grained execution; and (4) a performance auto-tuning technique that offers large flexibility for tile size auto-adjusting across various input datasets based on a designed runtime model. Our experiments show that HPSpTM on a Nvidia Tesla P100 obtains the average performance improvement of up to 76.46% over the state-of-the-arts, and HPSpTM achieves the speedup of up to 15.39× when scaling from 8 to 128 core groups, corresponding to processes, on the Sunway TaihuLight supercomputer.}
}


@inproceedings{DBLP:conf/icde/YuanMZW22,
	author = {Ye Yuan and
                  Delong Ma and
                  Aoqian Zhang and
                  Guoren Wang},
	title = {Consistent Subgraph Matching over Large Graphs},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {2536--2548},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00235},
	doi = {10.1109/ICDE53745.2022.00235},
	timestamp = {Sun, 06 Aug 2023 20:52:08 +0200},
	biburl = {https://dblp.org/rec/conf/icde/YuanMZW22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Subgraph matching over graphs has been extensive-ly studied, due to its wide applications in knowledge bases, social networks, and among others. To catch the inconsistency and errors that commonly exist in these graphs, this paper studies consistent subgraph matching (CSM), i.e., finding the common matches in every consistent graph repair w.r.t a set of conditional graph dependencies (CGDs). We concentrate on subset, superset and symmetric difference graph repairs. We study fundamental problems for CGDs and CSM. We show that the satisfiability, im-plication, and validation problems of CGDs are coNP-complete, coNP-complete and NP-complete, respectively. We also show that the CSM problem (under any kind of repair) is NP-complete. We provide (parallel) algorithms to solve CSM, and guarantee to reduce running time when given more processors. Using real-life and synthetic graphs, we empirically verify the efficiency and effectiveness of our algorithms.}
}


@inproceedings{DBLP:conf/icde/LiuYZGCGLWLTL22,
	author = {Xiaoze Liu and
                  Zheng Yin and
                  Chao Zhao and
                  Congcong Ge and
                  Lu Chen and
                  Yunjun Gao and
                  Dimeng Li and
                  Ziting Wang and
                  Gaozhong Liang and
                  Jian Tan and
                  Feifei Li},
	title = {PinSQL: Pinpoint Root Cause SQLs to Resolve Performance Issues in
                  Cloud Databases},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {2549--2561},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00236},
	doi = {10.1109/ICDE53745.2022.00236},
	timestamp = {Mon, 14 Nov 2022 11:04:32 +0100},
	biburl = {https://dblp.org/rec/conf/icde/LiuYZGCGLWLTL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Deploying database services on cloud systems has gained increasing popularity and has become a common practice in the industry. However, the complicated cloud environments make performance issues inevitable, which could violate the service level guarantee if not addressed in a timely manner. Among the various problems, anomalies in SQL queries are the most commonly reported sources that cause performance issues in database applications. These anomalous queries can be divided into High-impact SQLs (H-SQLs) and Root Cause SQLs (R-SQLs), representing the related SQLs that are correlated with the anomalies and the ones that are the root causes of the performance issue, respectively. In the presence of a large number of queries, to pinpoint the R-SQLs is far more difficult than to identify the H-SQLs. To address this challenge, we aim at automatically pinpointing the R-SQLs to resolve performance issues in cloud databases. This paper introduces PinSQL, an autonomous diagnosing system for Alibaba Cloud, which has four modules that are executed sequentially, including data collection and pre-processing, anomaly detection, root cause analysis, and repairing actions. First, the related performance metrics and query logs from monitored cloud database instances are collected and aggregated as the data sources. Then, based on these inputs, efficient anomaly detection is conducted in real-time. Upon the detection of an anomaly, the root cause SQLs are pinpointed through tracking the propagation chain of the involved SQLs. Finally, repairing actions are suggested and then executed on R-SQLs to address the anomalies. Extensive experiments on an Alibaba production system show that PinSQL can achieve an 80% accuracy for pinpointing the top-1 R-SQLs and successfully resolve the database performance issues resultantly.}
}


@inproceedings{DBLP:conf/icde/HaugBK22,
	author = {Johannes Haug and
                  Klaus Broelemann and
                  Gjergji Kasneci},
	title = {Dynamic Model Tree for Interpretable Data Stream Learning},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {2562--2574},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00237},
	doi = {10.1109/ICDE53745.2022.00237},
	timestamp = {Sun, 04 Aug 2024 19:37:45 +0200},
	biburl = {https://dblp.org/rec/conf/icde/HaugBK22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Data streams are ubiquitous in modern business and society. In practice, data streams may evolve over time and cannot be stored indefinitely. Effective and transparent machine learning on data streams is thus often challenging. Hoeffding Trees have emerged as a state-of-the art for online predictive modelling. They are easy to train and provide meaningful convergence guarantees under a stationary process. Yet, at the same time, Hoeffding Trees often require heuristic and costly extensions to adjust to distributional change, which may considerably impair their interpretability. In this work, we revisit Model Trees for machine learning in evolving data streams. Model Trees are able to maintain more flexible and locally robust representations of the active data concept, making them a natural fit for data stream applications. Our novel framework, called Dynamic Model Tree, satisfies desirable consistency and minimality properties. In experiments with synthetic and real-world tabular streaming data sets, we show that the proposed framework can drastically reduce the number of splits required by existing incremental decision trees. At the same time, our framework often outperforms state-of-the-art models in terms of predictive quality - especially when concept drift is involved. Dynamic Model Trees are thus a powerful online learning framework that contributes to more lightweight and interpretable machine learning in data streams.}
}


@inproceedings{DBLP:conf/icde/GongLF22,
	author = {Yonghai Gong and
                  Yichuan Li and
                  Nikolaos M. Freris},
	title = {FedADMM: {A} Robust Federated Deep Learning Framework with Adaptivity
                  to System Heterogeneity},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {2575--2587},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00238},
	doi = {10.1109/ICDE53745.2022.00238},
	timestamp = {Sun, 17 Dec 2023 20:56:19 +0100},
	biburl = {https://dblp.org/rec/conf/icde/GongLF22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated Learning (FL) is an emerging framework for distributed processing of large data volumes by edge devices subject to limited communication bandwidths, heterogeneity in data distributions and computational resources, as well as privacy considerations. In this paper, we introduce a new FL protocol termed FedADMM based on primal-dual optimization. The proposed method leverages dual variables to tackle sta-tistical heterogeneity, and accommodates system heterogeneity by tolerating variable amount of work performed by clients. FedADMM maintains identical communication costs per round as FedAvg/Prox, and generalizes them via the augmented Lagrangian. A convergence proof is established for nonconvex objectives, under no restrictions in terms of data dissimilarity or number of participants per round of the algorithm. We demon-strate the merits through extensive experiments on real datasets, under both IID and non-IID data distributions across clients. FedADMM consistently outperforms all baseline methods in terms of communication efficiency, with the number of rounds needed to reach a prescribed accuracy reduced by up to 87%. The algorithm effectively adapts to heterogeneous data distributions through the use of dual variables, without the need for hyperparameter tuning, and its advantages are more pronounced in large-scale systems.}
}


@inproceedings{DBLP:conf/icde/GaoLQCYW22,
	author = {Sen Gao and
                  Rong{-}Hua Li and
                  Hongchao Qin and
                  Hongzhi Chen and
                  Ye Yuan and
                  Guoren Wang},
	title = {Colorful h-star Core Decomposition},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {2588--2601},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00239},
	doi = {10.1109/ICDE53745.2022.00239},
	timestamp = {Fri, 05 Aug 2022 16:24:00 +0200},
	biburl = {https://dblp.org/rec/conf/icde/GaoLQCYW22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The h-clique based higher-order cohesive subgraph mining is an important operator in graph analysis. The h-clique core and h-clique densest subgraph are two representative higher-order cohesive subgraph models which have been widely used in many practical applications. However, computing these two models on large graphs is often very costly due to the hardness of counting the h-cliques. In this paper, we propose a relaxed higher-order cohesive subgraph model, called colorful h-star core, based on counting the number of colorful h-stars. Unlike the h-cliques, we show that the colorful h-stars can be counted and updated very efficiently using a novel dynamic programming (DP) algorithm. Based on the proposed DP algorithm, we develop an efficient colorful h-star core decomposition algorithm which takes O(h × m) time and uses O(h × n+m) space, where\nm\nand\nn\ndenote the number of edges and nodes of the graph respectively. In addition, we also propose a graph reduction technique based on our colorful h-star core model to accelerate the computation of the state-of-the-art approximation algorithm for h-clique densest subgraph mining. Moreover, we show that the colorful h-star core can also provide a very good approximation of the h-clique densest subgraph. The results of comprehensive experiments on 11 large real-world datasets demonstrate the efficiency, scalability and effectiveness of the proposed algorithms.}
}


@inproceedings{DBLP:conf/icde/NiCC22,
	author = {Wangze Ni and
                  Peng Cheng and
                  Lei Chen},
	title = {Mixing Transactions with Arbitrary Values on Blockchains},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {2602--2614},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00240},
	doi = {10.1109/ICDE53745.2022.00240},
	timestamp = {Mon, 26 Jun 2023 20:41:54 +0200},
	biburl = {https://dblp.org/rec/conf/icde/NiCC22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Due to the transparency of blockchain, adversaries can observe the details of a transaction, and then utilize the amount as a unique quasi-identifier to make deanonymization. Nowadays, to obscure the linkages between receivers and senders within a transaction on the blockchain, mixing services are widely applied in many real applications to enhance cryptocurrencies' anonymity. The basic idea of mixing services is to hide an output within several other outputs in a transaction such that adversaries cannot distinguish them by their amounts since they are purposely selected to have the same amount. For a set of original outputs with different amounts, mixing services need to decompose them into a set of decomposed outputs, where any decomposed output has some other decomposed outputs with the same amount. Since the transaction fee is related to the number of outputs, we are motivated to decompose original outputs into a minimal set of decomposed outputs, which is challenging to guarantee the privacy-preserving effect at the same time. In this paper, we formally define the anonymity-aware output decomposition (AA-OD) problem, which aims to find a c-decomposition with a minimum number of decomposed outputs for a given original output set. A c-decomposition guarantees that for any original output\no\n, there are at most\nc\nof all decomposed outputs with an amount of\nx\ncoming from\no\n. We prove that the AA-OD problem is NP-hard. Thus, we propose an approximation algorithm, namely Boggart 1 1 Boggart is a magical creature in J. K. Rowling's Harry Potter series who can shift his shape and no one knows what it looks like., to solve the AA-OD problem with a (2/c + 3)-approximation bound on the number of decomposed outputs. We verify the efficiency and effectiveness of our approach through comprehensive experiments on both real and synthetic data sets.}
}


@inproceedings{DBLP:conf/icde/NieMYC22,
	author = {Xiaonan Nie and
                  Xupeng Miao and
                  Zhi Yang and
                  Bin Cui},
	title = {{TSPLIT:} Fine-grained {GPU} Memory Management for Efficient {DNN}
                  Training via Tensor Splitting},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {2615--2628},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00241},
	doi = {10.1109/ICDE53745.2022.00241},
	timestamp = {Fri, 05 Aug 2022 16:24:03 +0200},
	biburl = {https://dblp.org/rec/conf/icde/NieMYC22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Since Deep Neural Networks (DNNs) are deeper and larger, performing DNNs training on existing accelerators (e.g., GPUs) is challenging due to their limited device memory capacity. Existing memory management systems reduce the mem-ory footprint via tensor offloading and recomputing. However, this coarse-grained, one-tensor-at-a-time memory management often incurs high peak GPU memory usage and cannot fully utilize available hardware resources (e.g., PCIe). In this paper, we propose TSPLIT, a fine-grained DNN memory management system that breaks apart memory bottlenecks while maintaining the efficiency of DNNs training. TSPLIT achieves this by proposing a model-guided approach to holistically exploit the tensor-split and its joint optimization with out-of-core execution methods (via offload and recompute). We further provide an efficient implementation of TSPLIT with proposed splittable tensor abstraction, profiling-based planner, and optimized DNN runtime. Evaluations on 6 DNN models show that compared to vDNN and SuperNeurons, TSPLIT can achieve maximum model scale up to 10.5× and 3.1 x and throughput improved up to 4.7× and 2.7 × under the same memory over-subscription, respectively.}
}


@inproceedings{DBLP:conf/icde/MayerOJ22,
	author = {Ruben Mayer and
                  Kamil Orujzade and
                  Hans{-}Arno Jacobsen},
	title = {Out-of-Core Edge Partitioning at Linear Run-Time},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {2629--2642},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00242},
	doi = {10.1109/ICDE53745.2022.00242},
	timestamp = {Fri, 05 Aug 2022 16:24:02 +0200},
	biburl = {https://dblp.org/rec/conf/icde/MayerOJ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graph edge partitioning is an important prepro-cessing step to optimize distributed computing jobs on graph-structured data. The edge set of a given graph is split into\nk\nequally-sized partitions, such that the replication of vertices across partitions is minimized. Out-of-core edge partitioning algorithms are able to tackle the problem with low memory over-head. Existing out-of-core algorithms mainly work in a streaming manner and can be grouped into two types. While stateless streaming edge partitioning is fast and yields low partitioning quality, stateful streaming edge partitioning yields better quality, but is expensive, as it requires a scoring function to be evaluated for every edge on every partition, leading to a time complexity of O(|E| *k). In this paper, we propose 2PS-L, a novel out-of-core edge partitioning algorithm that builds upon the stateful streaming model, but achieves linear run-time i.e.,O(|E|)). 2PS-L consists of two phases. In the first phase, vertices are separated into clusters by a lightweight streaming clustering algorithm. In the second phase, the graph is re-streamed and vertex clustering from the first phase is exploited to reduce the search space of graph partitioning to only two target partitions for every edge. Our evaluations show that 2PS-L can achieve better partitioning quality than existing stateful streaming edge partitioners while having a much lower run-time. As a consequence, the total run-time of partitioning and subsequent distributed graph processing can be significantly reduced.}
}


@inproceedings{DBLP:conf/icde/RongYZYCH22,
	author = {Dazhong Rong and
                  Shuai Ye and
                  Ruoyan Zhao and
                  Hon Ning Yuen and
                  Jianhai Chen and
                  Qinming He},
	title = {FedRecAttack: Model Poisoning Attack to Federated Recommendation},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {2643--2655},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00243},
	doi = {10.1109/ICDE53745.2022.00243},
	timestamp = {Sat, 30 Sep 2023 09:44:51 +0200},
	biburl = {https://dblp.org/rec/conf/icde/RongYZYCH22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated Recommendation (FR) has received con-siderable popularity and attention in the past few years. In FR, for each user, its feature vector and interaction data are kept locally on its own client thus are private to others. Without the access to above information, most existing poisoning attacks against recommender systems or federated learning lose validity. Benifiting from this characteristic, FR is commonly considered fairly secured. However, we argue that there is still possible and necessary security improvement could be made in FR. To prove our opinion, in this paper we present FedRecAttack, a model poisoning attack to FR aiming to raise the exposure ratio of target items. In most recommendation scenarios, apart from pri-vate user-item interactions (e.g., clicks, watches and purchases), some interactions are public (e.g., likes, follows and comments). Motivated by this point, in FedRecAttack we make use of the public interactions to approximate users' feature vectors, thereby attacker can generate poisoned gradients accordingly and control malicious users to upload the poisoned gradients in a well-designed way. To evaluate the effectiveness and side effects of FedRecAttack, we conduct extensive experiments on three real-world datasets of different sizes from two completely different scenarios. Experimental results demonstrate that our proposed FedRecAttack achieves the state-of-the-art effectiveness while its side effects are negligible. Moreover, even with small proportion (3%) of malicious users and small proportion (1%) of public interactions, FedRecAttack remains highly effective, which reveals that FR is more vulnerable to attack than people commonly considered.}
}


@inproceedings{DBLP:conf/icde/GaoCYCHD22,
	author = {Zhongqiang Gao and
                  Chuanqi Cheng and
                  Yanwei Yu and
                  Lei Cao and
                  Chao Huang and
                  Junyu Dong},
	title = {Scalable Motif Counting for Large-scale Temporal Graphs},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {2656--2668},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00244},
	doi = {10.1109/ICDE53745.2022.00244},
	timestamp = {Mon, 26 Jun 2023 20:41:55 +0200},
	biburl = {https://dblp.org/rec/conf/icde/GaoCYCHD22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {One fundamental problem in temporal graph anal-ysis is to count the occurrences of small connected subgraph patterns (i.e., motifs), which benefits a broad range of real-world applications, such as anomaly detection, structure prediction, and network representation learning. However, existing works focused on exacting temporal motif are not scalable to large-scale temporal graph data, due to their heavy computational costs or inherent inadequacy of parallelism. In this work, we propose a scalable parallel framework for exactly counting temporal motifs in large-scale temporal graphs. We first categorize the temporal motifs based on their distinct properties, and then design customized algorithms that offer efficient strategies to exactly count the motif instances of each category. Moreover, our compact data structures, namely triple and quadruple counters, enable our algorithms to directly identify the temporal motif instances of each category, according to edge information and relationship between edges, therefore significantly improving the counting efficiency. Based on the proposed counting algorithms, we design a hierarchical parallel framework that featuring both inter- and intra-node parallel strategies, and fully leverages the multi-threading capacity of modern CPU to concurrently count all temporal motifs. Extensive experiments on sixteen real-world temporal graph datasets demonstrate the superiority and capability of our proposed framework for temporal motif counting, achieving up to\n538×\nspeedup compared to the state-of-the-art methods. The source code of our method is available at: https://github.com/steven-ccq/FAST-temporal-motif.}
}


@inproceedings{DBLP:conf/icde/DoraiswamyF22,
	author = {Harish Doraiswamy and
                  Juliana Freire},
	title = {{SPADE:} GPU-Powered Spatial Database Engine for Commodity Hardware},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {2669--2681},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00245},
	doi = {10.1109/ICDE53745.2022.00245},
	timestamp = {Fri, 05 Aug 2022 16:24:00 +0200},
	biburl = {https://dblp.org/rec/conf/icde/DoraiswamyF22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Given the massive growth in the volume of spatial data, there is a great need for systems that can efficiently evaluate spatial queries over large data sets. These queries are notoriously expensive using traditional database solutions. While faster response times can be attained through powerful clusters or servers with large main-memory, these options, due to cost and complexity, are out of reach to many data scientists and analysts making up the long tail. Graphics Processing Units (GPUs), which are now widely available even in commodity desktops and laptops, provide a cost-effective alternative to support high-performance computing, opening up new opportunities to the efficient evaluation of spatial queries. While GPU-based approaches proposed in the literature have shown great improvements in performance, they are tied to specific GPU hardware and only handle specific queries over fixed geometry types. In this paper we present SPADE, a GPU-powered spatial database engine that supports a rich set of spatial queries. We discuss the challenges involved in attaining efficient query evaluation over large datasets as well as portability across different GPU hardware, and how these are addressed in SPADE. We performed a detailed experimental evaluation to assess the effectiveness of the system for wide range of queries and datasets, and report results which show that SPADE is scalable and able to handle data larger than main-memory, and its performance on a laptop is on par with that other systems that require clusters or large-memory servers.}
}


@inproceedings{DBLP:conf/icde/ZouXLK22,
	author = {Kai Zou and
                  Xike Xie and
                  Qi Li and
                  Deyu Kong},
	title = {GX-Plug: a Middleware for Plugging Accelerators to Distributed Graph
                  Processing},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {2682--2694},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00246},
	doi = {10.1109/ICDE53745.2022.00246},
	timestamp = {Fri, 05 Aug 2022 16:24:00 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZouXLK22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recently, research communities highlight the neces-sity of formulating a scalability continuum for large-scale graph processing, which gains the scale-out benefits from distributed graph systems, and the scale-up benefits from high-performance accelerators. To this end, we propose a middleware, called the GX-plug, for the ease of integrating the merits of both. As a middleware, the GX-plug is versatile in supporting different runtime environments, computation models, and programming models. More, for improving the middleware performance, we study a series of techniques, including pipeline shuffle, synchro-nization caching and skipping, and workload balancing, for intra-, inter-, and beyond-iteration optimizations, respectively. Exper-iments show that our middleware efficiently plugs accelerators to representative distributed graph systems, e.g., GraphX and Powergraph, with up-to 20x acceleration ratio.}
}


@inproceedings{DBLP:conf/icde/KalinskyHMEK22,
	author = {Oren Kalinsky and
                  Aidan Hogan and
                  Oren Mishali and
                  Yoav Etsion and
                  Benny Kimelfeld},
	title = {Exploration of Knowledge Graphs via Online Aggregation},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {2695--2708},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00247},
	doi = {10.1109/ICDE53745.2022.00247},
	timestamp = {Fri, 05 Aug 2022 16:24:03 +0200},
	biburl = {https://dblp.org/rec/conf/icde/KalinskyHMEK22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Exploration systems over large-scale RDF knowl-edge graphs often rely on aggregate count queries to indicate how many results the user can expect for the possible next steps of exploration. Such systems thus encounter a challenging computational problem: evaluating aggregate count queries efficiently enough to allow for interactive exploration. Given that precise results are not always necessary, a promising alternative is to apply online aggregation, where initially imprecise results converge towards more precise results over time. However, state-of-the-art online aggregation algorithms, such as Wander Join, fail to provide accurate results due to frequent rejected paths that slow convergence. We thus devise an algorithm for online aggregation that specializes in exploration queries on knowledge graphs; our proposal leverages the low dimension of RDF graphs, and the low selectivity of exploration queries, by augmenting random walks with exact partial computations using a worst-case optimal join algorithm. This approach reduces the number of rejected paths encountered while retaining a fast sample time. In an experimental study with random interactions exploring two large-scale knowledge graphs, our algorithm shows a clear reduction in error over time versus Wander Join.}
}


@inproceedings{DBLP:conf/icde/TeofiliFKMMS22,
	author = {Tommaso Teofili and
                  Donatella Firmani and
                  Nick Koudas and
                  Vincenzo Martello and
                  Paolo Merialdo and
                  Divesh Srivastava},
	title = {Effective Explanations for Entity Resolution Models},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {2709--2721},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00248},
	doi = {10.1109/ICDE53745.2022.00248},
	timestamp = {Fri, 05 Aug 2022 16:24:01 +0200},
	biburl = {https://dblp.org/rec/conf/icde/TeofiliFKMMS22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Entity resolution (ER) aims at matching records that refer to the same real-world entity. Although widely studied for the last 50 years, ER still represents a challenging data management problem, and several recent works have started to investigate the opportunity of applying deep learning (DL) techniques to solve this problem. In this paper, we study the fundamental problem of explainability of the DL solution for ER. Understanding the matching predictions of an ER solution is indeed crucial to assess the trustworthiness of the DL model and to discover its biases. We treat the DL model as a black box classifier and - while previous approaches to provide explanations for DL predictions are agnostic to the classification task - we propose the CERTA approach that is aware of the semantics of the ER problem. Our approach produces both saliency explanations, which associate each attribute with a saliency score, and counterfactual explanations, which provide examples of values that can flip the prediction. CERTA builds on a probabilistic framework that aims at computing the explanations evaluating the outcomes produced by using perturbed copies of the input records. We experimentally evaluate CERTA'S explanations of state-of-the-art ER solutions based on DL models using publicly available datasets, and demonstrate the effectiveness of CERTA over recently proposed methods for this problem.}
}


@inproceedings{DBLP:conf/icde/WuBRP22,
	author = {Wentao Wu and
                  Philip A. Bernstein and
                  Alex Raizman and
                  Christina Pavlopoulou},
	title = {Factor Windows: Cost-based Query Rewriting for Optimizing Correlated
                  Window Aggregates},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {2722--2734},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00249},
	doi = {10.1109/ICDE53745.2022.00249},
	timestamp = {Fri, 05 Aug 2022 16:24:00 +0200},
	biburl = {https://dblp.org/rec/conf/icde/WuBRP22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Window aggregates are ubiquitous in stream processing. In Azure Stream Analytics (ASA), a stream processing service hosted by Microsoft's Azure cloud, we see many customer queries that contain aggregate functions (such as MIN and MAX) over multiple correlated windows (e.g., tumbling windows of length five minutes and ten minutes) defined on the same event stream. In this paper, we present a cost-based optimization framework for optimizing such queries by sharing computation among multiple windows. In particular, we introduce the notion of factor windows, which are auxiliary windows that are not in the input query but may nevertheless help reduce the overall computation cost, and our cost-based optimizer can produce rewritten query plans that have lower costs than the original query plan by utilizing factor windows. Since our optimization techniques are at the level of query (plan) rewriting, they can be implemented on any stream processing system that supports a declarative, SQL-like query language without changing the underlying query execution engine. We formalize the shared computation problem, present the optimization techniques in detail, and report evaluation results over both synthetic and real datasets. Our results show that, compared to the original query plans, the rewritten plans output by our cost-based optimizer can yield significantly higher (up to 16.8×) throughput.}
}


@inproceedings{DBLP:conf/icde/ZhouANHW22,
	author = {Qi Zhou and
                  Joy Arulraj and
                  Shamkant B. Navathe and
                  William Harris and
                  Jinpeng Wu},
	title = {{SPES:} {A} Symbolic Approach to Proving Query Equivalence Under Bag
                  Semantics},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {2735--2748},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00250},
	doi = {10.1109/ICDE53745.2022.00250},
	timestamp = {Fri, 05 Aug 2022 16:24:01 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhouANHW22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In database-as-a-service platforms, automated ver-ification of query equivalence helps eliminate redundant computation in the form of overlapping sub-queries. Researchers have proposed two pragmatic techniques to tackle this problem. The first approach consists of reducing the queries to algebraic expressions and proving their equivalence using an algebraic theory. The limitations of this technique are threefold. It cannot prove the equivalence of queries with significant differences in the attributes of their relational operators (e.g., predicates in the filter operator). It does not support certain widely-used SQL features (e.g., NULL values). Its verification procedure is computationally intensive. The second approach transforms this problem to a constraint satisfaction problem and leverages a general-purpose solver to determine query equivalence. This technique consists of deriving the symbolic representation of the queries and proving their equivalence by determining the query containment relationship between the symbolic expressions. While the latter approach addresses all the limitations of the former technique, it only proves the equivalence of queries under set semantics (i.e., output tables must not contain duplicate tuples). However, in practice, database applications use bag semantics (i.e., output tables may contain duplicate tuples) In this paper, we introduce a novel symbolic approach for proving query equivalence under bag semantics. We transform the problem of proving query equivalence under bag semantics to that of proving the existence of a bijective, identity map between tuples returned by the queries on all valid inputs. We classify SQL queries into four categories, and propose a set of novel category-specific verification algorithms. We implement this symbolic approach in SPES and demonstrate that it proves the equivalence of a larger set of query pairs (95/232) under bag semantics compared to the SOTA tools based on algebraic (30/232) and symbolic approaches (67/232) under set and bag semantics, respectively. Furthermore, SPES is 3X faster than the symbolic tool that proves equivalence under set semantics.}
}


@inproceedings{DBLP:conf/icde/LiGWZKQ22,
	author = {Wentao Li and
                  Min Gao and
                  Dong Wen and
                  Hongwei Zhou and
                  Cai Ke and
                  Lu Qin},
	title = {Manipulating Structural Graph Clustering},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {2749--2761},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00251},
	doi = {10.1109/ICDE53745.2022.00251},
	timestamp = {Mon, 20 Nov 2023 13:58:36 +0100},
	biburl = {https://dblp.org/rec/conf/icde/LiGWZKQ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Structural graph clustering (SCAN) is a popular clustering technique. Using the concept of\nϵ\n-neighborhood, SCAN defines the core vertices that uniquely determine the clusters of a graph. Most existing studies assume that the graph processed by SCAN contains no controlled edges. Few studies, however, have focused on manipulating SCAN by injecting edges. Manipulation of SCAN can be used to assess its robustness and lay the groundwork for developing robust clustering algorithms. To fill this gap and considering the importance of the\nϵ\n-neighborhood for SCAN, we propose a problem, denoted as MN, for manipulating SCAN. The MN problem aims to maximize the\nϵ\n-neighborhood of the target vertex by inserting some edges. On the theoretical side, we prove that the MN problem is both NP-hard and APX-hard, and also is non-submodular and non-monotonic. On the algorithmic side, we design an algorithm by focusing on how to select vertices to join\nϵ−\nneighborhood and thus avoid enumerating edges to report a solution. As a result, our algorithm bypasses the non-monotonicity nature of the MN problem. Extensive experiments on real-world graphs show that our algorithm can effectively solve the proposed MN problem.}
}


@inproceedings{DBLP:conf/icde/QianWSGNT22,
	author = {Huajie Qian and
                  Qingsong Wen and
                  Liang Sun and
                  Jing Gu and
                  Qiulin Niu and
                  Zhimin Tang},
	title = {RobustScaler: QoS-Aware Autoscaling for Complex Workloads},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {2762--2775},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00252},
	doi = {10.1109/ICDE53745.2022.00252},
	timestamp = {Sun, 06 Oct 2024 21:04:58 +0200},
	biburl = {https://dblp.org/rec/conf/icde/QianWSGNT22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Autoscaling is a critical component for efficient resource utilization with satisfactory quality of service (QoS) in cloud computing. This paper investigates proactive autoscaling for widely-used scaling-per-query applications where scaling is required for each query, such as container registry and function-as-a-service (FaaS). In these scenarios, the workload often exhibits high uncertainty with complex temporal patterns like periodicity, noises and outliers. Conservative strategies that scale out unnecessarily many instances lead to high resource costs whereas aggressive strategies may result in poor QoS. We present RobustScaler to achieve superior trade-off between cost and QoS. Specifically, we design a novel autoscaling framework based on non-homogeneous Poisson processes (NHPP) modeling and stochastically constrained optimization. Furthermore, we develop a specialized alternating direction method of multipliers (ADMM) to efficiently train the NHPP model, and rigorously prove the QoS guarantees delivered by our optimization-based proactive strategies. Extensive experiments show that RobustScaler out-performs common baseline autoscaling strategies in various real-world traces, with large margins for complex workload patterns.}
}


@inproceedings{DBLP:conf/icde/ChenYK22,
	author = {Yueting Chen and
                  Xiaohui Yu and
                  Nick Koudas},
	title = {Ranked Window Query Retrieval over Video Repositories},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {2776--2791},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00253},
	doi = {10.1109/ICDE53745.2022.00253},
	timestamp = {Mon, 05 Feb 2024 20:31:12 +0100},
	biburl = {https://dblp.org/rec/conf/icde/ChenYK22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recent advances in Computer Vision have contributed to solid accuracy and efficiency improvements in many tasks such as object detection and tracking, enabling new opportunities for video analytics. In this paper, we initiate the study of ranked window queries that aim to retrieve clips from large video repositories in which objects co-occur in a query-specified fashion. For example, ranked window queries allow retrieval of clips of a set duration (e.g., 10 seconds) with the highest score from a long video, where at least the same 3 cars (with matching conditions based on suitably defined metadata) appear jointly. To answer such queries, we propose a two-phased approach, which builds indexes for all desired objects of the given videos during an Ingestion Phase and evaluates query answers efficiently in the Query Phase. During the Ingestion Phase, the proposed Partition-Based Index Construction (PBIC) algorithm builds indexes on partitions obtained by splitting each given video. Leveraging such indexes, queries are answered in the Query Phase using the Partition-Based Query Processing (PBQP) algorithm, which efficiently produces the desired (query-specified) number of results with the highest scores. We present the outcome of a thorough performance study on real videos that evaluates the performance of the proposed algorithms by varying parameters of interest. Our results indicate that the proposed set of techniques are capable of processing queries efficiently at scale, demonstrating multiple orders of magnitude speedups over other applicable approaches.}
}


@inproceedings{DBLP:conf/icde/ChenZCXJL22,
	author = {Ming Chen and
                  Renxiang Zhou and
                  Hanhua Chen and
                  Jiang Xiao and
                  Hai Jin and
                  Bo Li},
	title = {Horae: {A} Graph Stream Summarization Structure for Efficient Temporal
                  Range Query},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {2792--2804},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00254},
	doi = {10.1109/ICDE53745.2022.00254},
	timestamp = {Sun, 05 Mar 2023 00:29:07 +0100},
	biburl = {https://dblp.org/rec/conf/icde/ChenZCXJL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graph stream, referred to as an evolving graph with a timing sequence of updated edges through a continuous stream, is an emerging data format widely used in big data applications. Coping with a graph stream is challenging because: 1) fully storing the continuously produced and extremely large-scale datasets is difficult if not impossible; 2) supporting queries relevant to both graph topology and temporal information is nontrivial. Recently, graph stream summarization techniques have attracted much attention in providing approximate storage and query processing for a graph stream. Existing designs largely utilize hash functions to reduce the graph scale and leverage a compressive matrix to represent the graph stream. However, such designs are unable to store the time dimension information of graph streams, and thus fail to support temporal queries. In this paper, we propose Horae, a novel graph stream summarization structure for efficient temporal range query, which presents a time prefix embedded multi-layer summarization structure. Our design is based on the insight that an arbitrary temporal range of length\nL\ncan be decomposed to at most\n2logL\nsub-ranges, where all the time points in each sub-range have the same binary code prefix. We further design an efficient Binary Range Decomposition (BRD) algorithm, which achieves a logarithmic scale query processing time. Experimental results show that Horae significantly reduces the latency of various temporal range queries by two to three orders of magnitude compared to the state-of-the-art designs.}
}


@inproceedings{DBLP:conf/icde/NiuLFB22,
	author = {Yudong Niu and
                  Yuchen Li and
                  Ju Fan and
                  Zhifeng Bao},
	title = {Local Clustering over Labeled Graphs: An Index-Free Approach},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {2805--2817},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00255},
	doi = {10.1109/ICDE53745.2022.00255},
	timestamp = {Wed, 07 Dec 2022 23:09:58 +0100},
	biburl = {https://dblp.org/rec/conf/icde/NiuLFB22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we study local clustering over labeled graphs, which extracts a subgraph with nodes having high label density matched to the query labels as well as high structure density around a seed node. Despite the progress made in the last few years, we observe two major limitations of existing methods: (I) The candidate subgraphs have to comply with strict topology-driven models and better candidates can be pruned by these topological constraints; (II) The topological constraints give rise to substantial computational overheads and existing works have to construct prohibitively large indexes for online processing. To mitigate these limitations, we explore the idea of using conductance in local clustering that ensures structure density through minimizing conductance. Conductance is a well-understood metric primarily for detecting unlabeled clusters but for labeled graphs, applying conductance directly is insufficient because the label information is not taken into consideration. To this end, we propose a novel Label-Aware Motif weighted framework (LAM) to transform the labeled graph to a weighted graph so that both the label and the structure proximity of nodes are captured. We define label-aware motifs as small high-order structures of nodes with query labels. Nodes within a label-aware motif are both closely connected and relevant to query labels, which ease the process of identifying labeled clusters. Our theoretical study shows that LAM is able to better distinguish the desired candidates under the personalized pagerank distribution from the seed node on random graphs generated by the stochastic block model. Based on such nice properties of LAM, we propose an index-free peeling algorithm to efficiently search local clusters on labeled graphs. Extensive experiments on both real-world and synthetic networks show that our proposed algorithm can achieve up to 90% relative effectiveness improvements (F1 scores), while using 10 times less memory than the SOTA algorithm.}
}


@inproceedings{DBLP:conf/icde/ZhouLQTHM22,
	author = {Amelie Chi Zhou and
                  Juanyun Luo and
                  Ruibo Qiu and
                  Haobin Tan and
                  Bingsheng He and
                  Rui Mao},
	title = {Adaptive Partitioning for Large-Scale Graph Analytics in Geo-Distributed
                  Data Centers},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {2818--2830},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00256},
	doi = {10.1109/ICDE53745.2022.00256},
	timestamp = {Fri, 05 Aug 2022 16:24:02 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhouLQTHM22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graph partitioning is an important problem to the performance and cost optimization of graph analytics in geo-distributed environments. Modern hybrid-cut model is expected to obtain better performance and cost optimizations than traditional partitioning models, but can further complicate geo-distributed graph partitioning which is already a challenging problem due to large graph sizes and network heterogeneities of geo-distributed DCs. Existing studies usually adopt heuristic-based methods to achieve fast partitioning for large graphs, which unfortunately sacrifices optimization effectiveness. Further, graph structures of many applications can change at various frequencies. Dynamic partitioning methods usually focus on achieving low latency to quickly adapt to changes, which may again sacrifice partitioning effectiveness. Also, such methods are not aware of the dynamicity of graphs and can over sacrifice effectiveness for unnecessarily low latency. In this paper, we propose RLCut, which uses Reinforcement Learning (RL) to help taming the complexity of the problem. Specifically, RLCut uses multi-agent learning which is more efficient than single agent RL and incorporates a sampling based optimization to adaptively control the training process to satisfy required trade-off between partitioning effectiveness and efficiency according to graph dynamicity. Experiments using real cloud DCs and real-world graphs show that, compared to state-of-the-art static partitioning methods, RLCut improves the performance of geo-distributed graph analytics by 10%-100% with comparable overhead. When users tolerate longer partitioning overhead, we can further improve the performance by up to 43%. With varying graph changing frequencies, RLCut can improve the performance by up to 60% compared to state-of-the-art dynamic partitioning.}
}


@inproceedings{DBLP:conf/icde/MengYCLY22,
	author = {Lingkai Meng and
                  Long Yuan and
                  Zi Chen and
                  Xuemin Lin and
                  Shiyu Yang},
	title = {Index-based Structural Clustering on Directed Graphs},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {2831--2844},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00257},
	doi = {10.1109/ICDE53745.2022.00257},
	timestamp = {Sun, 04 Aug 2024 19:37:46 +0200},
	biburl = {https://dblp.org/rec/conf/icde/MengYCLY22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Structural clustering (SCAN) is one of the most popular graph clustering paradigms. However, SCAN assumes that the input graph is undirected and can not cluster the directed graphs. To address this problem, in this paper, we propose a new structural clustering model based on SCAN to cluster directed graphs. Following the new model, we propose an index-based approach to support the efficient clustering of a given graph. Moreover, we also devise efficient index maintenance algorithms to handle the case that the input graph is dynamically updated. We conduct extensive experiments on nine real directed graphs, one of which contains more than 2 billion edges. The results demonstrate the effectiveness and efficiency of our proposed methods.}
}


@inproceedings{DBLP:conf/icde/TengSYLYLC22,
	author = {Ya{-}Wen Teng and
                  Yishuo Shi and
                  De{-}Nian Yang and
                  Wang{-}Chien Lee and
                  Philip S. Yu and
                  Ying{-}Liang Lu and
                  Ming{-}Syan Chen},
	title = {Epidemic Spread Optimization for Disease Containment with NPIs and
                  Vaccination},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {2845--2858},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00258},
	doi = {10.1109/ICDE53745.2022.00258},
	timestamp = {Fri, 05 Aug 2022 16:24:01 +0200},
	biburl = {https://dblp.org/rec/conf/icde/TengSYLYLC22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The potential impact of epidemics, e.g., COVID-19, H1N1, and SARS, is severe on public health, the economy, education, and society. Before effective treatments are available and vaccines are fully deployed, combining Non-Pharmaceutical Interventions (NPIs) and vaccination strategies is the main approaches to contain the epidemic or live with the virus. Therefore, research for deciding the best containment operations to contain the epidemic based on various objectives and concerns is much needed. In this paper, we formulate the problem of Containment Operation Optimization Design (COOD) that optimizes the epidemic containment by carefully analyzing contacts between individuals. We prove the hardness of COOD and propose an approximation algorithm, named Multi-Type Action Scheduling (MTAS), with the ideas of Infected Ratio, Contact Risk, and Severity Score to select and schedule appropriate actions that implement NPIs and allocate vaccines for different groups of people. We evaluate MTAS on real epidemic data of a population with real contacts and compare it against existing approaches in epidemic and misinformation containment. Experimental results demonstrate that MTAS improves at least 200% over the baselines in the test case of sustaining public health and the economy. Moreover, the applicability of MTAS to various epidemics of different dynamics is demonstrated, i.e., MTAS can effectively slow down the peak and reduce the number of infected individuals at the peak.}
}


@inproceedings{DBLP:conf/icde/CaoLHLZHSZWWLCF22,
	author = {Wei Cao and
                  Feifei Li and
                  Gui Huang and
                  Jianghang Lou and
                  Jianwei Zhao and
                  Dengcheng He and
                  Mengshi Sun and
                  Yingqiang Zhang and
                  Sheng Wang and
                  Xueqiang Wu and
                  Han Liao and
                  Zilin Chen and
                  Xiaojian Fang and
                  Mo Chen and
                  Chenghui Liang and
                  Yanxin Luo and
                  Huanming Wang and
                  Songlei Wang and
                  Zhanfeng Ma and
                  Xinjun Yang and
                  Xiang Peng and
                  Yubin Ruan and
                  Yuhui Wang and
                  Jie Zhou and
                  Jianying Wang and
                  Qingda Hu and
                  Junbin Kang},
	title = {PolarDB-X: An Elastic Distributed Relational Database for Cloud-Native
                  Applications},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {2859--2872},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00259},
	doi = {10.1109/ICDE53745.2022.00259},
	timestamp = {Sat, 30 Sep 2023 09:44:49 +0200},
	biburl = {https://dblp.org/rec/conf/icde/CaoLHLZHSZWWLCF22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cloud computing is on the rise, which promotes new breeds of database systems to accommodate the cloud environment. The development of cloud-native databases reveals three trends. One is the adoption of multi-datacenter (DC) deployment to survive the downtime of any single site. Another is the separation of computation and storage resources to achieve higher elasticity and scalability. The last is the support of HTAP to eliminate data redundancy and system complexity from heterogeneous databases. To cater to these trends, we design a distributed relational database called PolarDB-X, which is built on top of the cloud-native database PolarDB. It hence inherits many cloud-native features, such as multi-datacenter deployment and elasticity. To achieve cross-DC capability, it leverages Paxos and hybrid logical clock to achieve durability and snapshot-isolation consistency with low coordination costs. For resource elasticity, since the underlying PolarDB supports rapid migration of tenants between nodes, PolarDB-X can quickly scale the cluster to cope with a sudden traffic increase. For HTAP support, with the help of read replicas and a HTAP executor, PolarDB-X can improve the latency and parallelism of analytical queries without impacting concurrently-running TP workloads. Using its MPP engine and an in-memory column index, the efficiency of analytical queries can be further enhanced. PolarDB-X is now a cloud database service at Alibaba Cloud. We have learned many useful lessons from its development and operation, and have incorporated those into our design and analysis.}
}


@inproceedings{DBLP:conf/icde/YangGHYTJ22,
	author = {Sean Bin Yang and
                  Chenjuan Guo and
                  Jilin Hu and
                  Bin Yang and
                  Jian Tang and
                  Christian S. Jensen},
	title = {Weakly-supervised Temporal Path Representation Learning with Contrastive
                  Curriculum Learning},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {2873--2885},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00260},
	doi = {10.1109/ICDE53745.2022.00260},
	timestamp = {Fri, 05 Aug 2022 16:24:01 +0200},
	biburl = {https://dblp.org/rec/conf/icde/YangGHYTJ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In step with the digitalization of transportation, we are witnessing a growing range of path-based smart-city applications, e.g., travel-time estimation and travel path ranking. A temporal path (TP) that includes temporal information, e.g., departure time, into the path is of fundamental to enable such applications. In this setting, it is essential to learn generic temporal path representations (TPRs) that consider spatial and temporal correlations simultaneously and that can be used in different applications, i.e., downstream tasks. Existing methods fail to achieve the goal since (i) supervised methods require large amounts of task-specific labels when training and thus fail to generalize the obtained TPRs to other tasks; (ii) though unsupervised methods can learn generic representations, they disregard the temporal aspect, leading to sub-optimal results. To contend with the limitations of existing solutions, we propose a Weakly-Supervised Contrastive learning model. We first propose a temporal path encoder that encodes both the spatial and temporal information of a temporal path into a TPR. To train the encoder, we introduce weak labels that are easy and inexpensive to obtain, and are relevant to different tasks, e.g., temporal labels indicating peak vs. off-peak hour from departure times. Based on the weak labels, we construct meaningful positive and negative temporal path samples by considering both spatial and temporal information, which facilities training the encoder using contrastive learning by pulling closer the positive samples' representations while pushing away the negative samples' representations. To better guide the contrastive learning, we propose a learning strategy based on Curriculum Learning such that the learning performs from easy to hard training instances. Experimental studies involving three downstream tasks, i.e., travel time estimation, path ranking, and path recommendation, on three road networks offer strong evidence that the proposal is superior to state-of-the-art unsupervised and supervised methods and that it can be used as a pre-training approach to enhance supervised TPR learning.}
}


@inproceedings{DBLP:conf/icde/YuanJZPW22,
	author = {Jiahao Yuan and
                  Wendi Ji and
                  Dell Zhang and
                  Jinwei Pan and
                  Xiaoling Wang},
	title = {Micro-Behavior Encoding for Session-based Recommendation},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {2886--2899},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00261},
	doi = {10.1109/ICDE53745.2022.00261},
	timestamp = {Fri, 05 Aug 2022 16:24:03 +0200},
	biburl = {https://dblp.org/rec/conf/icde/YuanJZPW22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Session-based Recommendation (SR) aims to predict the next item for recommendation based on previously recorded sessions of user interaction. The majority of existing approaches to SR focus on modeling the transition patterns of items. In such models, the so-called micro-behaviors describing how the user locates an item and carries out various activities on it (e.g., click, add-to-cart, and read-comments), are simply ignored. A few recent studies have tried to incorporate the sequential patterns of micro-behaviors into SR models. However, those sequential models still cannot effectively capture all the inherent interdependencies between micro-behavior operations. In this work, we aim to investigate the effects of the micro-behavior information in SR systematically. Specifically, we identify two different patterns of micro-behaviors: “sequential patterns” and “dyadic relational patterns”. To build a unified model of user micro-behaviors, we first devise a multigraph to aggregate the sequential patterns from different items via a graph neural network, and then utilize an extended self-attention network to exploit the pair-wise relational patterns of micro-behaviors. Extensive experiments on three public real-world datasets show the superiority of the proposed approach over the state-of-the-art baselines and confirm the usefulness of these two different micro-behavior patterns for SR.}
}


@inproceedings{DBLP:conf/icde/CirsteaYGKP22,
	author = {Razvan{-}Gabriel Cirstea and
                  Bin Yang and
                  Chenjuan Guo and
                  Tung Kieu and
                  Shirui Pan},
	title = {Towards Spatio- Temporal Aware Traffic Time Series Forecasting},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {2900--2913},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00262},
	doi = {10.1109/ICDE53745.2022.00262},
	timestamp = {Fri, 05 Aug 2022 16:24:02 +0200},
	biburl = {https://dblp.org/rec/conf/icde/CirsteaYGKP22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Traffic time series forecasting is challenging due to complex spatio-temporal dynamics-time series from different locations often have distinct patterns; and for the same time series, patterns may vary across time, where, for example, there exist certain periods across a day showing stronger temporal correlations. Although recent forecasting models, in particular deep learning based models, show promising results, they suf-fer from being spatio-temporal agnostic. Such spatio-temporal agnostic models employ a shared parameter space irrespective of the time series locations and the time periods and they assume that the temporal patterns are similar across locations and do not evolve across time, which may not always hold, thus leading to sub-optimal results. In this work, we propose a framework that aims at turning spatio-temporal agnostic models to spatio-temporal aware models. To do so, we encode time series from different locations into stochastic variables, from which we generate location-specific and time-varying model parameters to better capture the spatio-temporal dynamics. We show how to integrate the framework with canonical attentions to enable spatio-temporal aware attentions. Next, to compensate for the additional overhead introduced by the spatio-temporal aware model parameter generation process, we propose a novel window attention scheme, which helps reduce the complexity from quadratic to linear, making spatio-temporal aware attentions also have competitive efficiency. We show strong empirical evidence on four traffic time series datasets, where the proposed spatio-temporal aware attentions outperform state-of-the-art methods in term of accuracy and efficiency.}
}


@inproceedings{DBLP:conf/icde/WangKXJHF22,
	author = {Yuxiang Wang and
                  Arijit Khan and
                  Xiaoliang Xu and
                  Jiahui Jin and
                  Qifan Hong and
                  Tao Fu},
	title = {Aggregate Queries on Knowledge Graphs: Fast Approximation with Semantic-aware
                  Sampling},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {2914--2927},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00263},
	doi = {10.1109/ICDE53745.2022.00263},
	timestamp = {Tue, 21 Mar 2023 20:50:56 +0100},
	biburl = {https://dblp.org/rec/conf/icde/WangKXJHF22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A knowledge graph (KG) manages large-scale and real-world facts as a big graph in a schema-flexible manner. Aggregate query is a fundamental query over KGs, e.g., “what is the average price of cars produced in Germany?”. Despite its importance, answering aggregate queries on KGs has received little attention in the literature. Aggregate queries can be supported based on factoid queries, e.g., “find all cars produced in Germany”, by applying an additional aggregate operation on factoid queries' answers. However, this straightforward method is challenging because both the accuracy and efficiency of factoid query processing will seriously impact the performance of aggregate queries. In this paper, we propose a “sampling-estimation” model to answer aggregate queries over KGs, which is the first work to provide an approximate aggregate result with an effective accuracy guarantee, and without relying on factoid queries. Specifically, we first present a semantic-aware sampling to collect a high-quality random sample through a random walk based on knowledge graph embedding. Then, we propose unbiased estimators for COUNT, SUM, and a consistent estimator for AVG to compute the approximate aggregate results based on the random sample, with an accuracy guarantee in the form of confidence interval. We extend our approach to support iterative improvement of accuracy, and more complex queries with filter, GROUP-BY, and different graph shapes, e.g., chain, cycle, star, flower. Extensive experiments over real-world KGs demonstrate the effectiveness and efficiency of our approach.}
}


@inproceedings{DBLP:conf/icde/SantosBMF22,
	author = {A{\'{e}}cio S. R. Santos and
                  Aline Bessa and
                  Christopher Musco and
                  Juliana Freire},
	title = {A Sketch-based Index for Correlated Dataset Search},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {2928--2941},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00264},
	doi = {10.1109/ICDE53745.2022.00264},
	timestamp = {Fri, 05 Aug 2022 16:24:00 +0200},
	biburl = {https://dblp.org/rec/conf/icde/SantosBMF22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Dataset search is emerging as a critical capability in both research and industry: it has spurred many novel applications, ranging from the enrichment of analyses of real-world phenomena to the improvement of machine learning models. Recent research in this field has explored a new class of data-driven queries: queries consist of datasets and retrieve, from a large collection, related datasets. In this paper, we study a specific type of data-driven query that supports relational data augmentation through numerical data relationships: given an input query table, find the top-k tables that are both joinable with it and contain columns that are correlated with a column in the query. We propose a novel hashing scheme that allows the construction of a sketch-based index to support efficient correlated table search. We show that our proposed approach is effective and efficient, and achieves better trade-offs that significantly improve both the ranking accuracy and recall compared to the state-of-the-art solutions.}
}


@inproceedings{DBLP:conf/icde/ZhangLTXDYLS22,
	author = {Yan Zhang and
                  Changyu Li and
                  Ivor W. Tsang and
                  Hui Xu and
                  Lixin Duan and
                  Hongzhi Yin and
                  Wen Li and
                  Jie Shao},
	title = {Diverse Preference Augmentation with Multiple Domains for Cold-start
                  Recommendations},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {2942--2955},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00265},
	doi = {10.1109/ICDE53745.2022.00265},
	timestamp = {Tue, 07 May 2024 20:05:37 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhangLTXDYLS22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cold-start issues have been more and more challenging for providing accurate recommendations with the fast increase of users and items. Most existing approaches attempt to solve the intractable problems via content-aware recommendations based on auxiliary information and/or cross-domain recommendations with transfer learning. Their performances are often constrained by the extremely sparse user-item interactions, unavailable side information, or very limited domain-shared users. Recently, meta-learners with meta-augmentation by adding noises to labels have been proven to be effective to avoid overfitting and shown good performance on new tasks. Motivated by the idea of meta-augmentation, in this paper, by treating a user's preference over items as a task, we propose a so-called Diverse Preference Augmentation framework with multiple source domains based on meta-learning (referred to as MetaDPA) to i) generate diverse ratings in a new domain of interest (known as target domain) to handle overfitting on the case of sparse interactions, and to ii) learn a preference model in the target domain via a meta-learning scheme to alleviate cold-start issues. Specifically, we first conduct multi-source domain adaptation by dual conditional variational autoencoders and impose a Multi-domain InfoMax (MDI) constraint on the latent representations to learn domain-shared and domain-specific preference properties. To avoid overfitting, we add a Mutually-Exclusive (ME) constraint on the output of decoders to generate diverse ratings given content data. Finally, these generated diverse ratings and the original ratings are introduced into the meta-training procedure to learn a preference meta-learner, which produces good generalization ability on cold-start recommendation tasks. Experiments on real-world datasets show our proposed MetaDPA clearly outperforms the current state-of-the-art baselines.}
}


@inproceedings{DBLP:conf/icde/MollBMSGK22,
	author = {Oscar R. Moll and
                  Favyen Bastani and
                  Sam Madden and
                  Mike Stonebraker and
                  Vijay Gadepally and
                  Tim Kraska},
	title = {ExSample: Efficient Searches on Video Repositories through Adaptive
                  Sampling},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {2956--2968},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00266},
	doi = {10.1109/ICDE53745.2022.00266},
	timestamp = {Mon, 04 Nov 2024 22:25:43 +0100},
	biburl = {https://dblp.org/rec/conf/icde/MollBMSGK22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Capturing and processing video is increasingly common as cameras become cheaper to deploy. At the same time, rich video-understanding methods have progressed greatly in the last decade. As a result, many organizations now have massive repositories of video data, with applications in mapping, navigation, autonomous driving, and other areas. Because state-of-the-art object-detection methods are slow and expensive, our ability to process even simple ad-hoc object search queries (“find 100 traffic lights in dashcam video”) over this accumulated data lags far behind our ability to collect the data. Processing video at reduced sampling rates is a reasonable default strategy for these types of queries; however, the ideal sampling rate is both data and query dependent. We introduce ExSample, a low cost framework for object search over un-indexed video that quickly processes search queries by adapting the amount and location of sampled frames to the particular data and query being processed. ExSample prioritizes the processing of frames in a video repository so that processing is focused in portions of video that most likely contain objects of interest. It approaches searching in a similar way to a multi-arm bandit problem where each arm corresponds to a portion of a video. On large, real-world datasets, ExSample reduces processing time by 1.9x on average and up to 6x over an efficient random sampling baseline. Moreover, we show ExSample finds many results long before sophisticated, state-of-the-art baselines based on proxy scores can begin producing their first results.}
}


@inproceedings{DBLP:conf/icde/PaparrizosELEF22,
	author = {John Paparrizos and
                  Ikraduya Edian and
                  Chunwei Liu and
                  Aaron J. Elmore and
                  Michael J. Franklin},
	title = {Fast Adaptive Similarity Search through Variance-Aware Quantization},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {2969--2983},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00268},
	doi = {10.1109/ICDE53745.2022.00268},
	timestamp = {Sun, 12 Nov 2023 02:08:10 +0100},
	biburl = {https://dblp.org/rec/conf/icde/PaparrizosELEF22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the explosive growth of high-dimensional data, approximate methods emerge as promising solutions for nearest neighbor search. Among alternatives, quantization methods have gained attention due to the fast query responses and the low encoding and storage costs. Quantization methods decompose data dimensions into non-overlapping subspaces and encode data using a different dictionary per subspace. The state-of-the-art approach assigns dictionary sizes uniformly across subspaces while attempting to balance the relative importance of subspaces. Unfortunately, a uniform balance is not always achievable and may lead to unsatisfactory performance. Similarly, hardware-accelerated quantization methods may sacrifice accuracy to speed up the query execution. We propose a Variance-Aware Quantization (VAQ) method to encode data by intelligently adapting dictionary sizes to subspaces to alleviate these significant drawbacks. VAQ exploits intrinsic dimensionality reduction properties to derive the subspaces and only partially balances the importance of subspaces. Then, VAQ solves a constrained optimization problem to assign dictionary sizes proportionally to the importance of each subspace. In addition, VAQ accelerates the query execution by skipping data and subspaces through a hardware-oblivious algorithmic solution. To demonstrate the robustness of VAQ, we perform an extensive evaluation against quantization, hashing, and indexing methods using five large-scale benchmarking datasets. VAQ significantly outperforms the strongest hashing and quantization methods in accuracy while achieving up to 5× speedup. Compared to the fastest but less accurate hardware-accelerated method, VAQ achieves a speedup@recall performance up to 14×. Importantly, a rigorous statistical comparison using over one hundred datasets reveals that VAQ significantly outperforms rival methods even with a half budget. Notably, VAQ's simple data skipping solution achieves competitive or better performance against index-based methods, highlighting the need for new indices for quantization methods.}
}


@inproceedings{DBLP:conf/icde/LiHXXP22,
	author = {Zhonghang Li and
                  Chao Huang and
                  Lianghao Xia and
                  Yong Xu and
                  Jian Pei},
	title = {Spatial-Temporal Hypergraph Self-Supervised Learning for Crime Prediction},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {2984--2996},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00269},
	doi = {10.1109/ICDE53745.2022.00269},
	timestamp = {Mon, 01 May 2023 13:01:32 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LiHXXP22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Crime has become a major concern in many cities, which calls for the rising demand for timely predicting citywide crime occurrence. Accurate crime prediction results are vital for the beforehand decision-making of government to alleviate the increasing concern about the public safety. While many efforts have been devoted to proposing various spatial-temporal forecasting techniques to explore dependence across locations and time periods, most of them follow a supervised learning manner, which limits their spatial-temporal representation ability on sparse crime data. Inspired by the recent success in self-supervised learning, this work proposes a Spatial-Temporal Self-Supervised Hypergraph Learning framework (ST-HSL) to tackle the label scarcity issue in crime prediction. Specifically, we propose the cross-region hypergraph structure learning to encode region-wise crime dependency under the entire urban space. Furthermore, we design the dual-stage self-supervised learning paradigm, to not only jointly capture local- and global-level spatial-temporal crime patterns, but also supplement the sparse crime representation by augmenting region self-discrimination. We perform extensive experiments on two real-life crime datasets. Evaluation results show that our ST-HSL significantly outperforms state-of-the-art baselines. Further analysis provides insights into the superiority of our ST-HSL method in the representation of spatial-temporal crime patterns. The implementation code is available at https://github.com/LZH-YS1998/STHSL.}
}


@inproceedings{DBLP:conf/icde/BoroumandGOM22,
	author = {Amirali Boroumand and
                  Saugata Ghose and
                  Geraldo F. Oliveira and
                  Onur Mutlu},
	title = {Polynesia: Enabling High-Performance and Energy-Efficient Hybrid Transactional/Analytical
                  Databases with Hardware/Software Co-Design},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {2997--3011},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00270},
	doi = {10.1109/ICDE53745.2022.00270},
	timestamp = {Fri, 05 Aug 2022 16:24:03 +0200},
	biburl = {https://dblp.org/rec/conf/icde/BoroumandGOM22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A growth in data volume, combined with increasing demand for real-time analysis (using the most recent data), has resulted in the emergence of database systems that concurrently support transactions and data analytics. These hybrid transactional and analytical processing (HTAP) database systems can support real-time data analysis without the high costs of synchronizing across separate single-purpose databases. Unfortunately, for many applications that perform a high rate of data updates, state-of-the-art HTAP systems incur significant losses in transactional (up to 74.6%) and/or analytical (up to 49.8%) throughput compared to performing only transactional or only analytical queries in isolation, due to (1) data movement be-tween the CPU and memory, (2) data update propagation from transactional to analytical workloads, and (3) the cost to main-tain a consistent view of data across the system. We propose Polynesia, a hardware-software co-designed system for in-memory HTAP databases that avoids the large throughput losses of traditional HTAP systems. Polynesia (1) di-vides the HTAP system into transactional and analytical pro-cessing islands, (2) implements new custom hardware that un-locks software optimizations to reduce the costs of update prop-agation and consistency, and (3) exploits processing-in-memory for the analytical islands to alleviate data movement overheads. Our evaluation shows that Polynesia outperforms three state-of-the-art HTAP systems, with average transactional/analytical throughput improvements of 1.7×/3.7×, and reduces energy consumption by 48% over the prior lowest-energy HTAP sys-tem.}
}


@inproceedings{DBLP:conf/icde/ChenXK22,
	author = {Zhengyu Chen and
                  Teng Xiao and
                  Kun Kuang},
	title = {{BA-GNN:} On Learning Bias-Aware Graph Neural Network},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {3012--3024},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00271},
	doi = {10.1109/ICDE53745.2022.00271},
	timestamp = {Sun, 04 Aug 2024 19:37:45 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ChenXK22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graph Neural Networks (GNNs) show promising results for semi-supervised learning tasks on graphs, which become favorable comparing with other approaches. However, similar to other machine learning models, GNN s might suffer from the bias issue because of the distribution shift between training and testing node distributions. More importantly, the test node distribution in the graph is generally unknown during model training in practice. In this paper, we focus on how to address the bias issue on graphs and learn a graph neural network model that is robust to arbitrary unknown distribution shifts. To address this problem, we propose a novel Bias-Aware Graph Neural Network (BA-GNN) framework by learning node representations that are invariant across different distributions for invariant prediction. Specifically, our BA-GNN framework contains two interactive parts, one for bias identification and the other for invariant prediction. To learn invariant feature and aggregated representation, our BA-GNN learns multiple biased graph partitions and selects feature, neighbor, and propagation steps for nodes under multiple biased graph partitions. Extensive experiments show that our proposed BA-G NN framework can significantly improve different GNNs backbones such as GCN, GAT, APPNP and GraphSAGE on different datasets.}
}


@inproceedings{DBLP:conf/icde/ZhaoWTLWWW22,
	author = {Jing Zhao and
                  Peng Wang and
                  Bo Tang and
                  Lu Liu and
                  Chen Wang and
                  Wei Wang and
                  Jianmin Wang},
	title = {Constructing Compact Time Series Index for Efficient Window Query
                  Processing},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {3025--3037},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00272},
	doi = {10.1109/ICDE53745.2022.00272},
	timestamp = {Mon, 26 Jun 2023 20:41:54 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhaoWTLWWW22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Analyzing and mining of time series have been widely studied in both academia and industry in recent years. Given a set of long time series, data analysts can utilize the window-based similarity search to explore subsequences in arbitrary time windows. Existing techniques are not efficient for window-based query processing. In particular, the whole matching index approach needs to build an individual index for each window, which incurs huge space cost. The existing window-based approach can only cluster neighboring windows, which leads to loose bounds of each group, and thus degrades the query processing efficiency. In this paper, we propose a compact time series index (WinIdx) for efficient window query processing. Specifically, i) we propose a novel distance measurement to capture the similarity between windows, ii) WinIdx provides a compact index structure for windows within a cluster by exploiting the similarity among subsequences relationships, and iii) several optimizations (e.g., sortable summarization, summarization envelop) are equipped in WinIdx to improve the efficiency of index construction, query processing and index footprints. We conduct extensive experiments on both real and synthetic time series to demonstrate the superiority of WinIdx against state-of-the-art approaches.}
}


@inproceedings{DBLP:conf/icde/KieuYGJZHZ22,
	author = {Tung Kieu and
                  Bin Yang and
                  Chenjuan Guo and
                  Christian S. Jensen and
                  Yan Zhao and
                  Feiteng Huang and
                  Kai Zheng},
	title = {Robust and Explainable Autoencoders for Unsupervised Time Series Outlier
                  Detection},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {3038--3050},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00273},
	doi = {10.1109/ICDE53745.2022.00273},
	timestamp = {Tue, 21 Mar 2023 20:50:56 +0100},
	biburl = {https://dblp.org/rec/conf/icde/KieuYGJZHZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Time series data occurs widely, and outlier detection is a fundamental problem in data mining, which has numerous applications. Existing autoencoder-based approaches deliver state-of-the-art performance on challenging real-world data but are vulnerable to outliers and exhibit low explainability. To address these two limitations, we propose robust and explainable unsupervised auto encoder frameworks that decompose an input time series into a clean time series and an outlier time series using autoencoders. Improved explainability is achieved because clean time series are better explained with easy-to-understand patterns such as trends and periodicities. We provide insight into this by means of a post-hoc explainability analysis and empirical studies. In addition, since outliers are separated from clean time series iteratively, our approach offers improved robustness to outliers, which in turn improves accuracy. We evaluate our approach on five real-world datasets and report improvements over the state-of-the-art approaches in terms of robustness and explainability.}
}


@inproceedings{DBLP:conf/icde/Thirumuruganathan22,
	author = {Saravanan Thirumuruganathan and
                  Suraj Shetiya and
                  Nick Koudas and
                  Gautam Das},
	title = {Prediction Intervals for Learned Cardinality Estimation: An Experimental
                  Evaluation},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {3051--3064},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00274},
	doi = {10.1109/ICDE53745.2022.00274},
	timestamp = {Tue, 07 May 2024 20:05:36 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Thirumuruganathan22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cardinality estimation is a fundamental and challenging problem in query optimization. Recently, a number of learned models have been proposed for this task. Often, these models significantly outperform traditional approaches in terms of accuracy. One of the stumbling blocks that prevents their increased adoption is that the learned models do not quantify the uncertainty of their estimates. It is desirable to associate each cardinality estimate of the model with a prediction interval that will contain the true cardinality with an user-specified probability. The size of the prediction interval encodes the uncertainty allowing the query optimizer to make an informed decision. For example, knowing that the cardinality of a query $q$ lies between 1–3% of the relation size with high probability is more informative than a single point estimate of 2%. While there has been some prior work on deriving bounds for traditional methods (such as sampling or histograms), they are not directly applicable for the learned models for cardinality estimation. In this paper, we conduct a systematic investigation of potential approaches for obtaining prediction intervals. We enumerate the list of desirable properties such as the ability to wrap around a learned model without significant internal modification and providing bounds with theoretical guarantees in a distribution agnostic manner among others. Based on an extensive literature survey, we identify four practical and high quality approaches for uncertainty quantification that satisfies these criteria. They span a wide spectrum in terms of theoretical guarantees, width of prediction interval and time taken for computing the prediction intervals. We conduct extensive experimental analysis of the efficacy of these approaches over three diverse and representative cardinality estimation algorithms. Our experiments covers diverse workloads involving both point and range queries and highlights the inherent trade-offs. Our results show that it is possible to obtain accurate prediction intervals in an efficient manner thereby opening up new avenues for future research.}
}


@inproceedings{DBLP:conf/icde/MollBMSGK22a,
	author = {Oscar R. Moll and
                  Favyen Bastani and
                  Sam Madden and
                  Mike Stonebraker and
                  Vijay Gadepally and
                  Tim Kraska},
	title = {ExSample: Efficient Searches on Video Repositories through Adaptive
                  Sampling},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {3065--3077},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00275},
	doi = {10.1109/ICDE53745.2022.00275},
	timestamp = {Mon, 04 Nov 2024 22:25:43 +0100},
	biburl = {https://dblp.org/rec/conf/icde/MollBMSGK22a.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Capturing and processing video is increasingly com-mon as cameras become cheaper to deploy. At the same time, rich video-understanding methods have progressed greatly in the last decade. As a result, many organizations now have massive repositories of video data, with applications in mapping, navigation, autonomous driving, and other areas. Because state-of-the-art object-detection methods are slow and expensive, our ability to process even simple ad-hoc object search queries (“find 100 traffic lights in dashcam video”) over this accumulated data lags far behind our ability to collect the data. Processing video at reduced sampling rates is a reasonable default strategy for these types of queries; however, the ideal sampling rate is both data and query dependent. We introduce ExSample, a low cost framework for object search over un-indexed video that quickly processes search queries by adapting the amount and location of sampled frames to the particular data and query being processed. ExSample prioritizes the processing of frames in a video repository so that processing is focused in portions of video that most likely contain objects of interest. It approaches searching in a similar way to a multi-arm bandit problem where each arm corresponds to a portion of a video. On large, real-world datasets, ExSample reduces processing time by 1.9x on average and up to 6x over an efficient random sampling baseline. Moreover, we show ExSample finds many results long before sophisticated, state-of-the-art baselines based on proxy scores can begin producing their first results.}
}


@inproceedings{DBLP:conf/icde/BianA22,
	author = {Haoqiong Bian and
                  Anastasia Ailamaki},
	title = {Pixels: An Efficient Column Store for Cloud Data Lakes},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {3078--3090},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00276},
	doi = {10.1109/ICDE53745.2022.00276},
	timestamp = {Fri, 05 Aug 2022 16:24:01 +0200},
	biburl = {https://dblp.org/rec/conf/icde/BianA22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {To benefit from the cloud's higher elasticity and price-efficiency, most modern data-lake engines support S3-like cloud object storage (COS) services as their optional or preferred underlying storage. Meanwhile, the widespread column stores, such as Parquet, are applied in these data lakes to improve analytical performance. However, as these column stores were designed for on-premise HDFS, they often suffer from the high latency of COS and deliver sub-optimal query performance. We observe that by optimizing the storage layout and data access pattern, we can effectively hide and mitigate the high latency. In this paper, we present Pixels, a column store optimized for the cloud that solves the problem by (1) the workload-driven storage layout optimization within and across the row group boundaries; (2) the I/O scheduling concerning the optimized storage layout and the performance characteristics of COS. They collectively improve the analytical performance in a transparent way that does not affect data ingestion and query execution in data lakes. Evaluations show that Pixels outperforms the state-of-the-art column store on COS by more than one order of magnitude on real-world workload and by 1.93x on TPC-H. Moreover, the performance of Pixels is also portable to HDFS.}
}


@inproceedings{DBLP:conf/icde/ArroyueloHNR22,
	author = {Diego Arroyuelo and
                  Aidan Hogan and
                  Gonzalo Navarro and
                  Javiel Rojas{-}Ledesma},
	title = {Time- and Space-Efficient Regular Path Queries},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {3091--3105},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00277},
	doi = {10.1109/ICDE53745.2022.00277},
	timestamp = {Wed, 28 Feb 2024 00:16:39 +0100},
	biburl = {https://dblp.org/rec/conf/icde/ArroyueloHNR22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We introduce a time- and space-efficient technique to solve regular path queries over labeled (RDF) graphs. We combine a bit-parallel simulation of the Glushkov automaton of the regular expression with the ring index introduced by Arroyuelo et al., exploiting its wavelet tree representation in order to efficiently reach relevant states of the product graph. Our algorithm is able to simultaneously process several automaton states, as well as several graph nodes/labels. Our experiments show that our approach uses 3–5 times less space than existing state-of-the-art systems, while generally outperforming them in query times (nearly 3 times faster than the next best, on average).}
}


@inproceedings{DBLP:conf/icde/MaGWCW22,
	author = {Hanchao Ma and
                  Sheng Guan and
                  Mengying Wang and
                  Yen{-}Shuo Chang and
                  Yinghui Wu},
	title = {Subgraph Query Generation with Fairness and Diversity Constraints},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {3106--3118},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00278},
	doi = {10.1109/ICDE53745.2022.00278},
	timestamp = {Tue, 07 May 2024 20:05:36 +0200},
	biburl = {https://dblp.org/rec/conf/icde/MaGWCW22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper studies the problem of subgraph query generation with guarantees on both diversity and group fairness. Given a query template (with parameterized search predicates) and a set of node groups in a graph, it is to compute a set of sub-graph queries that instantiate the query template, and each query ensures diversified answers that meanwhile covers each group with a desired number of nodes. Such need is evident in web and social search with fairness constraints, query optimization, and query benchmarking. We formalize a bi-criteria optimization problem that aims to find a Pareto optimal set of query instances in terms of diversity and fairness measures. We show the problem is in Δ\nP\n2 and verify its hardness (NP-hard and fixed-parameter tractable). We provide (1) two efficient algorithms that can approximate Pareto optimal sets with E-dominance relations that yield representative query instances with a bounded size, and (2) an online algorithm that progressively generates and maintains fixed-size ∊-Pareto set with small delay time. We experimentally verify that our algorithms can efficiently generate queries with desired diversity and coverage properties for targeted groups.}
}


@inproceedings{DBLP:conf/icde/WangJHLH22,
	author = {Xiaoliang Wang and
                  Peiquan Jin and
                  Bei Hua and
                  Hai Long and
                  Wei Huang},
	title = {Reducing Write Amplification of LSM-Tree with Block-Grained Compaction},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {3119--3131},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00279},
	doi = {10.1109/ICDE53745.2022.00279},
	timestamp = {Fri, 05 Aug 2022 16:24:00 +0200},
	biburl = {https://dblp.org/rec/conf/icde/WangJHLH22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {LSM-tree has been widely used as a write-optimized storage engine in many key-value stores, such as LevelDB and RocksDB. However, conventional compaction operations on the LSM-tree need to read, merge, and write many SSTables, which we call Table Compaction in this paper. Table Compaction will cause two major problems, namely write amplification and block-cache invalidation. They will lower both write and read performance of the LSM-tree. To address these issues, we propose a novel compaction scheme named Block Compaction that adopts a block-grained merging policy to perform compaction operations on the LSM-tree. Block Compaction identifies the boundaries of data blocks and tries to avoid reusing data blocks, which not only reduces the write amplification but also alleviates the block-cache invalidation. We present cost analysis to theoretically demonstrate that Block Compaction is more efficient than the existing Table Compaction. Furthermore, we analyze the side-effects of Block Compaction and present three optimizations: (1) Selective Compaction is to reduce the space amplification of Block Compaction by integrating Table Compaction with Block Compaction. (2) Parallel Merging divides a compaction task into several sub-tasks and uses multiple workers to accomplish sub-tasks in parallel. (3) Lazy Deletion mitigates the overhead caused by traversing files at the tail of compaction operations. We implement a new key-value store named BlockDB based on Block Compaction and its optimizations. Then, we compare BlockDB with LevelDB, RocksDB, and L2SM using the YCSB benchmark. The results show that BlockDB can reduce write amplification up to 32% and running time by up to 43.6%, compared to its competitors. In addition, it can maintain the high performance for point lookups and range scans.}
}


@inproceedings{DBLP:conf/icde/BaiJCRWYH22,
	author = {Lu Bai and
                  Yuhang Jiao and
                  Lixin Cui and
                  Luca Rossi and
                  Yue Wang and
                  Philip S. Yu and
                  Edwin R. Hancock},
	title = {Learning Graph Convolutional Networks based on Quantum Vertex Information
                  Propagation (Extended Abstract)},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {3132--3133},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00280},
	doi = {10.1109/ICDE53745.2022.00280},
	timestamp = {Fri, 05 Aug 2022 16:24:02 +0200},
	biburl = {https://dblp.org/rec/conf/icde/BaiJCRWYH22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper proposes a novel Quantum Spatial Graph Convolutional Neural Network (QSGCNN) model that can directly learn a classification function for graphs of arbitrary sizes. The main idea is to define a new quantum-inspired spatial graph convolution associated with pre-transformed fixed-sized aligned grid structures of graphs, in terms of quantum information propagation between grid vertices of each graph. We show that the proposed QSGCNN model can significantly reduce either the information loss or the notorious tottering problem arising in existing spatially-based Graph Convolutional Network (GCN) models. Experiments on benchmark graph datasets demonstrate the effectiveness of the proposed QSGCNN model.}
}


@inproceedings{DBLP:conf/icde/TangZTYSUYZ22,
	author = {Bo Tang and
                  Jian Zeng and
                  Qiandong Tang and
                  Chuan Yang and
                  Qiaomu Shen and
                  Leong Hou U and
                  Xiao Yan and
                  Dan Zeng},
	title = {CheetahKG: {A} Demonstration for Core-based Top-{\textdollar}k{\textdollar}
                  Frequent Pattern Discovery on Knowledge Graphs},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {3134--3137},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00281},
	doi = {10.1109/ICDE53745.2022.00281},
	timestamp = {Mon, 05 Feb 2024 20:31:13 +0100},
	biburl = {https://dblp.org/rec/conf/icde/TangZTYSUYZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Knowledge graphs capture the complex relationships among various entities, which can be found in various real world applications, e.g., Amazon product graph, Freebase, and COVID-19. To facilitate the knowledge graph analytical tasks, a system that supports interactive and efficient query processing is always in demand. In this demonstration, we develop a prototype system, CheetahKG, that embeds with our state-of-the-art query processing engine for the top-\nk\nfrequent pattern discovery. Such discovered patterns can be used for two purposes, (i) identifying related patterns and (ii) guiding knowledge exploration. In the demonstration sessions, the attendees will be invited to test the efficiency and effectiveness of the query engine and use the discovered patterns to analyze knowledge graphs on CheetahKG.}
}


@inproceedings{DBLP:conf/icde/ZhangLZYZ22,
	author = {Hao Zhang and
                  Qiyan Li and
                  Kangfei Zhao and
                  Jeffrey Xu Yu and
                  Yuanyuan Zhu},
	title = {How Learning Can Help Complex Cyclic Join Decomposition},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {3138--3141},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00282},
	doi = {10.1109/ICDE53745.2022.00282},
	timestamp = {Mon, 24 Apr 2023 14:58:38 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhangLZYZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recently, machine learning (ML) and deep learning (DL) techniques have been extensively studied in database systems including cardinality/selectivity estimation for optimizing queries with selections and joins. However, the issue of how to support complex cyclic join queries by ML/DL has not yet been well studied. An important research issue in optimizing complex cyclic join queries is how to decompose complex cyclic joins into a join tree where a node in the join tree may represent a subquery with cyclic joins. The main application of complex cyclic join queries is to support subgraph matching queries, which find matches of a user-given pattern graph in a large node/edge-labeled graph by subgraph isomorphism, when a graph is stored in a relational database system. Here, when a graph is stored in an edge table, the joins will be mainly self-joins. In the existing work, such decomposition is done by estimation with AGM bound. In this work, we demonstrate how ML/DL can support such complex cyclic self-joins by providing a more accurate estimation. We build a prototyped system, LSSMatch, based on ML/DL techniques, with a GUI to provide insights to observe how ML/DL-based techniques contribute to query optimization for complex cyclic self-join queries.}
}


@inproceedings{DBLP:conf/icde/ZhuLXYMH22,
	author = {Zichen Zhu and
                  Siqiang Luo and
                  Xiaokui Xiao and
                  Yin Yang and
                  Dingheng Mo and
                  Yufei Han},
	title = {VC-Tune: Tuning and Exploring Distributed Vertex-Centric Graph Systems},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {3142--3145},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00283},
	doi = {10.1109/ICDE53745.2022.00283},
	timestamp = {Sun, 04 Aug 2024 19:37:45 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhuLXYMH22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Distributed vertex-centric graph systems, or VC-systems, have achieved tremendous success in the industry. A common usage pattern of VC-systems is multi-processing, or the concurrent processing of multiple unit tasks. Example multi-processing includes answering multiple single-source shortest path queries on a graph. However, concurrent processing of all the unit tasks may overload the system with excessive memory usage, leading to intolerable system delays. To ad-dress the important challenge, we present V C- Tune, a system with a convenient interface to help practitioners orchestrate the unit tasks for improving the overall performance within the system limit. This demonstration allows the audience to interact with our system to explore the configuration space of multi-processing in VC-systems and compare different sys-tem configurations. In addition, we embed into the system an automatic configuration search algorithm, which can directly recommend to the practitioners a suitable configuration that gives a satisfactory system performance. An introduction video is at (https://sites.google.com/view/vc-tune-video).}
}


@inproceedings{DBLP:conf/icde/MuslehM22,
	author = {Mashaal Musleh and
                  Mohamed F. Mokbel},
	title = {A Demonstration of {RASED:} {A} Scalable Dashboard for Monitoring
                  Road Network Updates in {OSM}},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {3146--3149},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00284},
	doi = {10.1109/ICDE53745.2022.00284},
	timestamp = {Tue, 07 May 2024 20:05:36 +0200},
	biburl = {https://dblp.org/rec/conf/icde/MuslehM22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Road network queries (e.g., shortest path, range, and k-NN) hinge on the road network quality, which, un-fortunately, suffer from all sorts of inaccuracy. Given that OpenStreetMap (OSM) has been the de facto open-source map for a myriad of widely used applications, this demo presents RASED; a publicly available scalable dashboard to interactively monitor and analyze billions of OSM updates worldwide. RASED provides the necessary infrastructure that is immensely needed by map analyzers to understand and assess the map quality for anywhere in the world, which is a measure of the query accuracy.}
}


@inproceedings{DBLP:conf/icde/ChenG22,
	author = {Jiazun Chen and
                  Jun Gao},
	title = {{VICS-GNN:} {A} Visual Interactive System for Community Search via
                  Graph Neural Network},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {3150--3153},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00285},
	doi = {10.1109/ICDE53745.2022.00285},
	timestamp = {Fri, 05 Aug 2022 16:24:00 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ChenG22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Community Search, which locates the desired sub-graph containing the query node, is a fundamental operation in network analysis. Most of the existing systems rely on pre-defined rules to find the community, while we argue that the target community is always specific for different purposes and the pre-defined rules may not be suitable. In this work, we demonstrate VICS-GNN, a Visual Interactive system for Community Search via graph Neural Network. VICS-GNN provides end users with a flexible, user-friendly front end to manage and explore the sub-graph around the query node, allows users labeling nodes to guide G NN models in learning community rules by combining content and structural features, and locates the community interactively and iteratively. In the demonstration, demo visitors will be invited to experience the VICS-GNN system using real-world data from Wikipedia and Sina Weibo to feel how convenient and intuitive it is to help with community search.}
}


@inproceedings{DBLP:conf/icde/MarcadetCLSA22,
	author = {Ga{\"{e}}l Marcadet and
                  Radu Ciucanu and
                  Pascal Lafourcade and
                  Marta Soare and
                  Sihem Amer{-}Yahia},
	title = {Samba: {A} System for Secure Federated Multi-Armed Bandits},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {3154--3157},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00286},
	doi = {10.1109/ICDE53745.2022.00286},
	timestamp = {Thu, 30 May 2024 13:44:35 +0200},
	biburl = {https://dblp.org/rec/conf/icde/MarcadetCLSA22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The federated learning paradigm allows several data owners to contribute to a machine learning task without exposing their potentially sensitive data. We focus on cumulative reward maximization in Multi-Armed Bandits (MAB), a classical reinforcement learning model for decision making under uncertainty. We demonstrate Samba, a generic framework for Secure federAted Multi-armed BAndits. The demonstration platform is a Web interface that simulates the distributed components of Samba, and which helps the data scientist to configure the end-to-end workflow of deploying a federated MAB algorithm. The user-friendly interface of Samba, allows the users to examine the interaction between three key dimensions of federated MAB: cumulative reward, computation time, and security guarantees. We demonstrate Samba with two real-world datasets: Google Local Reviews and Steam Video Game.}
}


@inproceedings{DBLP:conf/icde/JiCG22,
	author = {Zhengjie Ji and
                  Edward Choi and
                  Peng Gao},
	title = {A Knowledge Base Question Answering System for Cyber Threat Knowledge
                  Acquisition},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {3158--3161},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00287},
	doi = {10.1109/ICDE53745.2022.00287},
	timestamp = {Fri, 05 Aug 2022 16:24:00 +0200},
	biburl = {https://dblp.org/rec/conf/icde/JiCG22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Open-source cyber threat intelligence (OSCTI) provides a form of evidence-based knowledge about cyber threats, enabling businesses to gain visibility into the fast-evolving threat landscape. Despite the pressing need for high-fidelity threat knowledge, existing cyber threat knowledge acquisition systems have primarily focused on providing low-level, isolated indicators. These systems have ignored the rich higher-level threat knowledge entities and their relationships presented in OSCTI reports, and do not provide a flexible and intuitive way for threat analysts to acquire the desired knowledge. To bridge the gap, we propose ThreatQA, a system that facilitates cyber threat knowledge acquisition via knowledge base question answering. Particularly, ThreatQA uses a combination of AI-based techniques to (1) automatically harvest comprehensive knowledge about trending threats from massive OSCTI reports from various sources and construct a large threat knowledge base, and (2) intelligently respond to an input natural language threat knowledge acquisition question by fetching the answer from the threat knowledge base via question answering.}
}


@inproceedings{DBLP:conf/icde/LiJTBSS22,
	author = {Pei Li and
                  Jessica Jessica and
                  Naida Tania and
                  Michael H. B{\"{o}}hlen and
                  Divesh Srivastava and
                  Jaroslaw Szlichta},
	title = {abcOD: Mining Band Order Dependencies},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {3162--3165},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00288},
	doi = {10.1109/ICDE53745.2022.00288},
	timestamp = {Fri, 05 Aug 2022 16:24:01 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LiJTBSS22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We present the design of and a demonstration plan for abcOD, a tool for efficiently discovering approximate band conditional order dependencies (abcODs) from data. abcOD utilizes a dynamic programming algorithm based on a longest monotonic band. Using real datasets, we demonstrate how the discovered abcODs can help users understand ordered data semantics, identify potential data quality problems, and interactively clean the data.}
}


@inproceedings{DBLP:conf/icde/FangZZJZ22,
	author = {Min Fang and
                  Xinna Zhou and
                  Zhao Zhang and
                  Cheqing Jin and
                  Aoying Zhou},
	title = {SEFrame: An SGX-enhanced Smart Contract Execution Framework for Permissioned
                  Blockchain},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {3166--3169},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00289},
	doi = {10.1109/ICDE53745.2022.00289},
	timestamp = {Fri, 05 Aug 2022 16:24:00 +0200},
	biburl = {https://dblp.org/rec/conf/icde/FangZZJZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The current blockchain system suffers from serious scalability bottleneck, which greatly limits the application in large-scale. Furthermore, with the emergence of high-throughput consensus algorithms in permissioned blockchain, how to efficiently execute smart contracts becomes a critical challenge. To solve this issue, a two-phase concurrent execution mechanism has been adopted recently, where the primary executes a batch of transactions concurrently in the first phase, then the rest replays them in the second phase to achieve consistency. However, these works only enable intra-node concurrency, not inter-node concurrency. This demonstration showcases SEFrame, a novel execution framework for smart contracts of permissioned blockchain to achieve intra- and inter-node concurrency with the confidentiality guarantee of Intel Software Guard Extensions (SGX). We use real-time dashboards containing the output of SEFrame, which allows attendees to interactively explore how SEFrame achieves efficient inter- and intra-node concurrency.}
}


@inproceedings{DBLP:conf/icde/BernhardtTVKSHK22,
	author = {Arthur Bernhardt and
                  Sajjad Tamimi and
                  Tobias Vin{\c{c}}on and
                  Christian Kn{\"{o}}dler and
                  Florian Stock and
                  Carsten Heinz and
                  Andreas Koch and
                  Ilia Petrov},
	title = {neoDBMS: In-situ Snapshots for Multi-Version {DBMS} on Native Computational
                  Storage},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {3170--3173},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00290},
	doi = {10.1109/ICDE53745.2022.00290},
	timestamp = {Fri, 05 Aug 2022 16:24:00 +0200},
	biburl = {https://dblp.org/rec/conf/icde/BernhardtTVKSHK22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Multi-versioning and MVCC are the foundations of many modern DBMSs. Under mixed workloads and large datasets, the creation of the transactional snapshot can become very expensive, as long-running analytical transactions may request old versions, residing on cold storage, for reasons of transactional consistency. Furthermore, analytical queries operate on cold data, stored on slow persistent storage. Due to the poor data locality, snapshot creation may cause massive data transfers and thus lower performance. Given the current trend towards computational storage and near-data processing, it has become viable to perform such operations in-storage to reduce data transfers and improve scalability. neoDBMS is a DBMS designed for near-data processing and computational storage. In this paper, we demonstrate how neoDBMS performs snapshot computation in-situ. We showcase different interactive scenarios, where neoDBMS outperforms PostgreSQL 12 by up to 5×.}
}


@inproceedings{DBLP:conf/icde/PhanNWYJN22,
	author = {Thanh Cong Phan and
                  Thanh Tam Nguyen and
                  Matthias Weidlich and
                  Hongzhi Yin and
                  Jun Jo and
                  Quoc Viet Hung Nguyen},
	title = {exRumourLens: Auditable Rumour Detection with Multi-View Explanations},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {3174--3177},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00291},
	doi = {10.1109/ICDE53745.2022.00291},
	timestamp = {Fri, 26 May 2023 07:40:33 +0200},
	biburl = {https://dblp.org/rec/conf/icde/PhanNWYJN22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Hundreds of thousands of rumours emerge every day. Algorithmic models shall therefore support users of social platforms and provide alerts to prevent users from accidentally spreading rumours. However, existing alerting mechanisms are limited to post-hoc classification, and rumours are often detected after the damage has been done. This paper presents exRumourLens, a system that enables tracking and auditing of potential rumours as they emerge. To this end, it identifies local anomalies related to individual entities, as well as global anomalies on the level of subgraphs of a network of entities. exRumourLens provides various views on such local and global anomalies, thereby providing detailed explanations on emerging rumours and supporting their critical exploration. The source code is available at https://rumourlens.github.io/.}
}


@inproceedings{DBLP:conf/icde/MullerE22,
	author = {Tobias M{\"{u}}ller and
                  Pascal Engel},
	title = {How, Where, and Why Data Provenance Improves Query Debugging: {A}
                  Visual Demonstration of Fine-Grained Provenance Analysis for {SQL}},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {3178--3181},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00292},
	doi = {10.1109/ICDE53745.2022.00292},
	timestamp = {Tue, 07 Mar 2023 10:47:39 +0100},
	biburl = {https://dblp.org/rec/conf/icde/MullerE22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Data provenance is meta-information about the origin and processing history of data. We demonstrate the prove-nance analysis of SQL queries and use it for query debugging. How-provenance determines which query expressions have been relevant for evaluating selected pieces of output data. Likewise, Where- and Why-provenance determine relevant pieces of input data. The combined provenance notions can be explored visually and interactively. We support a feature-rich SQL dialect with correlated subqueries and focus on bag semantics. Our fine-grained provenance analysis derives individual data provenance for table cells and SQL expressions.}
}


@inproceedings{DBLP:conf/icde/LiuFLLSX22,
	author = {Tiantian Liu and
                  Zijin Feng and
                  Huan Li and
                  Hua Lu and
                  Lidan Shou and
                  Jianliang Xu},
	title = {{IKAROS:} An Indoor Keyword-Aware Routing System},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {3182--3185},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00293},
	doi = {10.1109/ICDE53745.2022.00293},
	timestamp = {Mon, 05 Feb 2024 20:31:13 +0100},
	biburl = {https://dblp.org/rec/conf/icde/LiuFLLSX22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As people spend large parts of their lives in indoor venues like shopping malls, airports, and office buildings, there are increasing demands of indoor keyword-aware routing, i.e., finding an indoor path that covers interesting keywords. In this work, we demonstrate an Indoor Keyword-Aware Routing System (IKAROS) which efficiently answers the indoor top-\nk\nkeyword-aware routing query (IKRQ). Given two indoor points\ns\nand\nt\n, an IKRQ returns\nk s\n-to-\nt\nroutes that do not exceed a given distance constraint but have optimal ranking scores integrating keyword relevance and spatial distance. To enable cross-platform IKRQ services for end-users, IKAROS adopts the Browser/Server system architecture. The browser provides the interface for users to specify queries and view the results, while the server manages the indoor spatial and textual information and processes queries. Specifically, IKAROS implements two search algorithms with different routing expansions through a tailored indoor space model. Our demonstration covers the major system components such as configuring a query's parameters, choosing a query search algorithm, and visualizing the returned route.}
}


@inproceedings{DBLP:conf/icde/WaterVKQM22,
	author = {Robin Van De Water and
                  Francesco Ventura and
                  Zoi Kaoudi and
                  Jorge{-}Arnulfo Quian{\'{e}}{-}Ruiz and
                  Volker Markl},
	title = {Farming Your ML-based Query Optimizer's Food},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {3186--3189},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00294},
	doi = {10.1109/ICDE53745.2022.00294},
	timestamp = {Mon, 26 Jun 2023 20:41:55 +0200},
	biburl = {https://dblp.org/rec/conf/icde/WaterVKQM22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Machine learning (ML) is becoming a core component in query optimizers, e.g., to estimate costs or cardinalities. This means large heterogeneous sets of labeled query plans or jobs (i.e., plans with their runtime or cardinality output) are needed. However, collecting such a training dataset is a very tedious and time-consuming task: It requires both developing numerous jobs and executing them to acquire ground-truth labels. We demonstrate Datafarm,a novel framework for efficiently generating and labeling training data for ML-based query optimizers to overcome these issues. Datafarmenables generating training data tailored to users' needs by learning from their existing workload patterns, input data, and computational resources. It uses an active learning approach to determine a subset of jobs to be executed and encloses the human into the loop, resulting in higher quality data. The graphical user interface of Datafarmallows users to get informative details of the generated jobs and guides them through the generation process step-by-step. We show how users can intervene and provide feedback to the system in an iterative fashion. As an output, users can download both the generated jobs to use as a benchmark and the training data (jobs with their labels).}
}


@inproceedings{DBLP:conf/icde/MageirakosMKCA22,
	author = {Vasilis Mageirakos and
                  Riccardo Mancini and
                  Srinivas Karthik and
                  Bikash Chandra and
                  Anastasia Ailamaki},
	title = {Efficient GPU-accelerated Join Optimization for Complex Queries},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {3190--3193},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00295},
	doi = {10.1109/ICDE53745.2022.00295},
	timestamp = {Fri, 05 Aug 2022 16:24:02 +0200},
	biburl = {https://dblp.org/rec/conf/icde/MageirakosMKCA22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Analytics on modern data analytic and data ware-house systems often need to run large complex queries on increasingly complex database schemas. A lot of progress has been made on executing such complex queries using techniques like scale out query processing, hardware accelerators like GPUs and code generation techniques. However, optimization of such queries remains a challenge. Existing optimal solutions either cannot be effectively parallelized, or are inefficient while doing a lot of unnecessary work. In this demonstration, we present our system, GPU-QO, which aims to demonstrate query optimization techniques for large analytical queries using GPUs. We first demonstrate Massively Parallel Dynamic Programming (MPDP) - a novel query optimization technique that can run on GPUs to generate optimal plans in a (massively) parallel and efficient manner. We then showcase IDP 2 -MPDP and UnionDP - two heuristic techniques, again using GPUs, that can even optimize queries containing 1000s of joins. Furthermore, we compare our techniques with current state-of-the-art solutions, and demonstrate how our techniques can reduce optimization time for optimal solutions by nearly two orders of magnitude and produce much better query plans for heuristics (up to 7x).}
}


@inproceedings{DBLP:conf/icde/HerodotouOCL22,
	author = {Herodotos Herodotou and
                  Lambros Odysseos and
                  Yuxing Chen and
                  Jiaheng Lu},
	title = {Automatic Performance Tuning for Distributed Data Stream Processing
                  Systems},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {3194--3197},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00296},
	doi = {10.1109/ICDE53745.2022.00296},
	timestamp = {Tue, 21 Mar 2023 20:50:56 +0100},
	biburl = {https://dblp.org/rec/conf/icde/HerodotouOCL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Distributed data stream processing systems (DSPSs) such as Storm, Flink, and Spark Streaming are now routinely used to process continuous data streams in (near) real-time. However, achieving the low latency and high throughput demanded by today's streaming applications can be a daunting task, especially since the performance of DSPSs highly depends on a large number of system parameters that control load balancing, degree of parallelism, buffer sizes, and various other aspects of system execution. This tutorial offers a comprehensive review of the state-of-the-art automatic performance tuning approaches that have been proposed in recent years. The approaches are organized into five main categories based on their methodologies and features: cost modeling, simulation-based, experiment-driven, machine learning, and adaptive tuning. The categories of approaches will be analyzed in depth and compared to each other, exposing their various strengths and weaknesses. Finally, we will identify several open research problems and challenges related to automatic performance tuning for DSPSs.}
}


@inproceedings{DBLP:conf/icde/LiZ22,
	author = {Guoliang Li and
                  Xuanhe Zhou},
	title = {Machine Learning for Data Management: {A} System View},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {3198--3201},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00297},
	doi = {10.1109/ICDE53745.2022.00297},
	timestamp = {Fri, 05 Aug 2022 16:24:03 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LiZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Machine learning techniques have been proposed to optimize data management in recent years. Compared with traditional empirical data management, learning-based methods extract knowledge from historical tasks, generalize the extracted knowledge to similar new tasks, and can achieve better performance in many scenarios (e.g., knob tuning, cardinality estimation). However, data management systems require to handle various and dynamic workloads in different scenarios, and there are some challenges in applying machine learning techniques for data management systems. First, with various workloads and hundreds of system metrics, how to select and characterize effective features for data management problems? Second, with diversified machine learning models, how to design the proper models? Third, with various data management requirements, how to validate whether the machine learning models can meet the requirements? In this tutorial, we discuss existing learning-based data management studies and how they solve the above challenges, and provide some future research directions.}
}


@inproceedings{DBLP:conf/icde/PatelPM22,
	author = {Dhaval Patel and
                  Dzung Phan and
                  Markus Mueller},
	title = {Time Series Anomaly Detection Toolkit for Data Scientist},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {3202--3204},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00298},
	doi = {10.1109/ICDE53745.2022.00298},
	timestamp = {Tue, 14 Mar 2023 14:48:46 +0100},
	biburl = {https://dblp.org/rec/conf/icde/PatelPM22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This tutorial presents a design and implementation of a scikit-compatible system for detecting anomalies from time series data for the purpose of offering a broad range of algorithms to the end user, with special focus on unsupervised/semi-supervised learning. Given an input time series, we discuss how data scientist can construct four categories of anomaly pipelines followed by an enrichment module that helps to label anomaly. The tutorial provides an hand-on-experience using a deployed system on IBM API Hub for developer communities that aim to support a wide range of execution engines to meet the diverse need of anomaly workloads such as Serveless for CPU intensive work, GPU for deep-learning model training, etc.}
}


@inproceedings{DBLP:conf/icde/TziavelisGR22,
	author = {Nikolaos Tziavelis and
                  Wolfgang Gatterbauer and
                  Mirek Riedewald},
	title = {Toward Responsive {DBMS:} Optimal Join Algorithms, Enumeration, Factorization,
                  Ranking, and Dynamic Programming},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {3205--3208},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00299},
	doi = {10.1109/ICDE53745.2022.00299},
	timestamp = {Thu, 25 Aug 2022 08:35:37 +0200},
	biburl = {https://dblp.org/rec/conf/icde/TziavelisGR22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {When processing join queries over big data, a DBMS can become unresponsive, i.e., it takes very long until any output tuples appear. Ranked enumeration addresses this problem by attempting to return the most important answers as quickly as possible, ideally in time that is linear (or quasilinear) in input size, even if the complete output is much larger. Aside from its practical usefulness, ranked enumeration is closely related to, and in a way unifies, several other problems involving joins. The common goal is the design of optimal algorithms that are guaranteed to avoid large intermediate results and thus achieve time or space complexity close to a lower bound. Arguably, avoiding query plans that produce huge intermediate results has been an overarching goal of database optimizers, which is part of the reason why optimal join algorithms, enumeration, and factorized representations have generated a lot of excitement. In this tutorial, we embark on an exploration of these topics, showing how they are intimately connected with a wide range of fundamental problems in computer science.}
}


@inproceedings{DBLP:conf/icde/PradhanLGS22,
	author = {Romila Pradhan and
                  Aditya Lahiri and
                  Sainyam Galhotra and
                  Babak Salimi},
	title = {Explainable {AI:} Foundations, Applications, Opportunities for Data
                  Management Research},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {3209--3212},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00300},
	doi = {10.1109/ICDE53745.2022.00300},
	timestamp = {Fri, 05 Aug 2022 16:24:02 +0200},
	biburl = {https://dblp.org/rec/conf/icde/PradhanLGS22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Algorithmic decision-making systems are success-fully being adopted in a wide range of domains for diverse tasks. While the potential benefits of algorithmic decision-making are many, the importance of trusting these systems has only recently attracted attention. There has been a recent resurgence of interest in explainable artificial intelligence (XAI) that aims to reduce the opacity of a model by explaining its behavior, its predictions or both, thus allowing humans to scrutinize and trust the model. A host of technical advances have been made and several explanation methods have been proposed in recent years that address the problem of model explainability. In this tutorial, we will present these novel explanation approaches, characterize their strengths and limitations, and enumerate opportunities for data management research in the context of XAI.}
}


@inproceedings{DBLP:conf/icde/TsesmelisS22,
	author = {Dimitris Tsesmelis and
                  Alkis Simitsis},
	title = {Database Optimizers in the Era of Learning},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {3213--3216},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00301},
	doi = {10.1109/ICDE53745.2022.00301},
	timestamp = {Fri, 05 Aug 2022 16:24:02 +0200},
	biburl = {https://dblp.org/rec/conf/icde/TsesmelisS22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this tutorial, we review advances made recently in a decades-old problem, namely query optimization. Along with the traditional optimization techniques many of which are still being used successfully in production, various techniques inspired by AI, such as genetic algorithms, had been explored as early as in the '90s as potential solutions, without gaining at that time much traction, especially in commercial offerings. More recently, with the rapid progress on learning, several approaches have brought this technology within the core of a database management system (DBMS) aiming at developing scalable, learning solutions to all challenging components of the system optimizer. We present the early efforts in this area, describe advancements, limitations and open issues, and discuss future research directions.}
}


@inproceedings{DBLP:conf/icde/Al-KatebEAB22,
	author = {Mohammed Al{-}Kateb and
                  Mohamed Y. Eltabakh and
                  Awny Al{-}Omari and
                  Paul G. Brown},
	title = {Analytics at Scale: Evolution at Infrastructure and Algorithmic Levels},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {3217--3220},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00302},
	doi = {10.1109/ICDE53745.2022.00302},
	timestamp = {Fri, 05 Aug 2022 16:24:03 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Al-KatebEAB22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Data Analytics is at the core of almost all modern ap-plications ranging from science and finance to healthcare and web applications. The evolution of data analytics over the last decade has been dramatic - new methods, new tools and new platforms - with no slowdown in sight. This rapid evolution has pushed the boundaries of data analytics along several axis including scalability especially with the rise of distributed infrastructures and the Big Data era, and interoperability with diverse data management systems such as relational databases, Hadoop and Spark. However, many analytic application developers struggle with the challenge of production deployment. Recent experience suggests that it is difficult to deliver modern data analytics with the level of reliability, security and manageability that has been a feature of traditional SQL DBMSs. In this tutorial, we discuss the advances and innovations introduced at both the infrastructure and algorithmic levels, directed at making analytic workloads scale, while paying close attention to the kind of quality of service guarantees different technology provide. We start with an overview of the classical centralized analytical techniques, describing the shift towards distributed analytics over non-SQL infrastructures. We contrast such approaches with systems that integrate analytic functionality inside, above or adjacent to SQL engines. We also explore how Cloud platforms' virtualization capabilities make it easier - and cheaper - for end users to apply these new analytic techniques to their data. Finally, we conclude with the learned lessons and a vision for the near future.}
}


@inproceedings{DBLP:conf/icde/WeiZ22,
	author = {Jia Wei and
                  Xingjun Zhang},
	title = {How Much Storage Do We Need for High Performance Server},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {3221--3225},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00303},
	doi = {10.1109/ICDE53745.2022.00303},
	timestamp = {Fri, 05 Aug 2022 16:24:03 +0200},
	biburl = {https://dblp.org/rec/conf/icde/WeiZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Processor, memory, and storage are the three most critical components of a High Performance Server(HPS). For a long time, given the processor and memory, how much storage capacity do we need? has been a problem that has deeply troubled the academic and enterprise communities. Especially in recent years, with the rapid development of Artificial Intelligence(AI), AI-based data-intensive tasks such as Deep Learning(DL), Re-inforcement Learning(RL), and High Performance Data Analy-sis(HPDA) have taken up the vast majority of processors, mem-ory, and storage overhead. The ability to support AI applications has become a key evaluation metric for the performance of HPS. Therefore, we propose an HPS storage design solution for typical AI applications. Furthermore, as AI models continue to grow more giant and the GPU Memory Wall problem becomes increasingly significant, using storage for offloading models and intermediate variables becomes the mainstream approach for training and inferring Extreme-Scale AI Models in the future. We need to consider the static overhead of models and datasets and the dynamic offloading requirements that may arise when AI tasks are run. We propose the Server Storage Computing Ratio (SSCR) model. The model uses DL training capabilities to characterize processor and memory performance. When config-ured for AI tasks, it can get the maximum server performance and the least amount of storage space. In other words, in the HPS mainly oriented to AI tasks, our model answers the question What is the minimum amount of Storage space that needs to be configured to maximize server performance for a given processor and memory?}
}


@inproceedings{DBLP:conf/icde/SegalH22,
	author = {Yoram Segal and
                  Ofer Hadar},
	title = {Constructing a skeleton database and enriching it using a Generative
                  Adversarial Network {(GAN)} simulator to assess human movement},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {3226--3229},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00304},
	doi = {10.1109/ICDE53745.2022.00304},
	timestamp = {Sun, 12 Nov 2023 02:08:10 +0100},
	biburl = {https://dblp.org/rec/conf/icde/SegalH22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This Ph.D. thesis develops a neural network simulator for quantifying, tagging, and inferring human gestures using an anonymized patient gesture database. Deep Learning (DL) applications require a sufficient data set for training. In this work, we propose enriching a database that contains a limited number of videos of human physiotherapy exercises by generating synthetic data. Our pose generator produces human movement in the form of skeletal vectors. We use OpenPose (OP) to convert videos and images containing multiple individuals into human skeletal. Within every video frame, OP represents each pose of the human skeleton as a vector in three-dimensional Euclidean space. We employ the Generative Adversarial Network (GAN) to generate new samples and control the motion parameters. We rearrange the joints in our skeletal model to emphasize the connections between them by using depth-first search (DFS), a tree structure search algorithm. Moreover, this research examines common challenges associated with capturing human gesture data, including synchronizing activities, temporal, and spatial relations, and how to address them. We intend to build an innovative simulator that will generate a set of human virtual choreography movements from a textual script.}
}


@inproceedings{DBLP:conf/icde/Kua22,
	author = {Kheng Kua},
	title = {Novel Methods for Aggregating Analyst Estimates},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {3230--3235},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00305},
	doi = {10.1109/ICDE53745.2022.00305},
	timestamp = {Fri, 05 Aug 2022 16:24:01 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Kua22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In equity investment management, sell side analysts provide estimates of companies' financial metrics. The capture of analyst estimates provide a systematic and quantitative proxy for market sentiment. Thus far the academic literature analysing this dataset has resolved to use relatively simple methods for aggregating the individual estimates to arrive at a consensus estimate. In this paper, we present a systematic review of academic literature relating to the study of analyst estimates. Iterative filtering algorithms are proposed as a novel alternative to the aggregation of analyst estimates. We present preliminary results of applying the algorithm to real-world datasets. The results suggest iterative filtering methods improve upon the forecast accuracy of the consensus forecast compared to a mean consensus.}
}


@inproceedings{DBLP:conf/icde/KantPS22,
	author = {Kamal Kant and
                  Sarvesh Pandey and
                  Udai Shanker},
	title = {A Journey from Commit Processing in Distributed Databases to Consensus
                  in Blockchain},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {3236--3240},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00306},
	doi = {10.1109/ICDE53745.2022.00306},
	timestamp = {Tue, 02 Apr 2024 10:25:38 +0200},
	biburl = {https://dblp.org/rec/conf/icde/KantPS22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Blockchain Technology (BT) is a futuristic data management technology that eliminates the intermediary/ third-party/central authority as it is operated over a peer-to-peer network running cryptographic protocols. It is tamper-proof as it utilizes a cryptographic hash feature. Some other features, it offers, are transparency, security, inalterability, immutability, and decentralization; these features of the BTs have acquired the wide attention of the computing research community. While a transaction is occurring between two parties, it ensures that the trust is a consensus-driven built-in technology component instead of relying on a third party for the same. With the help of a consensus algorithm, the newly generated block is appended at the end of the already existing chain. In this paper, a thorough analysis of the various blockchain consensus algorithms is conducted including their benefits and drawbacks. Finally, it enlists the challenges and opportunities in designing blockchain consensus algorithms. Further, it proposes an idea for designing a blockchain consensus algorithm and concludes the discussion.}
}


@inproceedings{DBLP:conf/icde/RuanLYHLBCWCZ22,
	author = {Sijie Ruan and
                  Cheng Long and
                  Xiaodu Yang and
                  Tianfu He and
                  Ruiyuan Li and
                  Jie Bao and
                  Yiheng Chen and
                  Shengnan Wu and
                  Jiangtao Cui and
                  Yu Zheng},
	title = {Discovering Actual Delivery Locations from Mis-Annotated Couriers'
                  Trajectories},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {3241--3253},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00307},
	doi = {10.1109/ICDE53745.2022.00307},
	timestamp = {Tue, 22 Oct 2024 20:38:20 +0200},
	biburl = {https://dblp.org/rec/conf/icde/RuanLYHLBCWCZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Delivery locations are fundamental data source for intelligent logistics, which can be used in route planning, arrival time estimation, parcel allocation, etc. Using the Geocoded way-bill location of an address as the delivery location is not sufficient, due to wrong address parsing, coarse-grained POI database, or different preferences of customers. To mitigate the insufficiency of Geocoding, some methods have been proposed, which utilize couriers' locations when waybills are confirmed to be delivered for delivery location inference. Nevertheless, these methods highly rely on the quality of couriers' annotations and fail when couriers confirm deliveries with delays. We propose to infer actual delivery locations of addresses from couriers' trajectories. This idea lies on an observation that the semantics of delivering a parcel are well captured by couriers' trajectories (e.g., a stay point would be generated when a delivery occurs), which holds even couriers confirm deliveries with delays. Specifically, we design Delivery Location Inference under Mis-Annotation (DLInfMA), which (1)generates location candidates from stay points in couriers' trajectories; (2) extracts features from both an address and its location candidates; and (3) uses an attention-based neural network model LocMatcher to predict the delivery location for each address. Experiments on two real-world datasets from JD Logistics as well as synthetic datasets demonstrate the effectiveness, robustness and scalability of DLInfMA. We also present a deployed system along with two applications based on DLInfMA.}
}


@inproceedings{DBLP:conf/icde/WangCLLSHZZZGL22,
	author = {Weifan Wang and
                  Xiaocheng Cheng and
                  Ziqi Liu and
                  Yu Lin and
                  Yue Shen and
                  Binbin Hu and
                  Zhiqiang Zhang and
                  Xiaodong Zeng and
                  Jun Zhou and
                  Jinjie Gu and
                  Minnan Luo},
	title = {Intent Mining: {A} Social and Semantic Enhanced Topic Model for Operation-Friendly
                  Digital Marketing},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {3254--3267},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00308},
	doi = {10.1109/ICDE53745.2022.00308},
	timestamp = {Mon, 08 Aug 2022 11:28:42 +0200},
	biburl = {https://dblp.org/rec/conf/icde/WangCLLSHZZZGL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we study the digital marketing where marketing officers (MOs) have to commit to creating brand new promotion ads/contents based on understandings of users' needs or preferences. Users' behaviors are typically high dimensional and hard to understand. Therefore, dimension reduction of users' behaviors from high dimensions and explainability are important to help MOs launch operation-friendly marketings. As such, it is natural to exploit topic models to help MOs understand users' intents from users' behaviors (e.g., user-item visits) in case we treat each user as a document and users' behaviors of visiting an item as a word. However, users of low activities and items followed by power law distributions are common in user-item visit data, which pose significant challenges to traditional topic models. We present a social and semantic enhanced topic model (S 2 TM) for users' intent mining. We optimize the user-intent estimates based on a graph neural network atop of a social network, and optimize the intent-item estimates based on a skip-gram word embedding approach by linking the semantics of items to pre-trained word embeddings. We propose an efficient stochastic vari-ational inference algorithm for the inference of latent variables and learning of parameters. Extensive experiments on real-world data show the effectivenesses of S 2 TM in terms of perplexities, topic coherence and semantic coherence compared with state-of-the-art topic models. We further show how MOs interact with our operation-friendly intent mining system, and results on real-world marketing campaigns in terms of click-through rate at Alipay.}
}


@inproceedings{DBLP:conf/icde/WangLCLFLXSLGC22,
	author = {Shendi Wang and
                  Haoyang Li and
                  Caleb Chen Cao and
                  Xiao{-}Hui Li and
                  Ng Ngai Fai and
                  Jianxin Liu and
                  Xun Xue and
                  Hu Song and
                  Jinyu Li and
                  Guangye Gu and
                  Lei Chen},
	title = {Tower Bridge Net (TB-Net): Bidirectional Knowledge Graph Aware Embedding
                  Propagation for Explainable Recommender Systems},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {3268--3279},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00309},
	doi = {10.1109/ICDE53745.2022.00309},
	timestamp = {Mon, 05 Aug 2024 15:14:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/WangLCLFLXSLGC22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recently, neural networks based models have been widely used for recommender systems (RS). Unfortunately, the existing neural network based RS solutions are often treated as black-boxes, which gain little trust and confidence from users. Thus, there is an increasing demand of explainability. Several explainable recommendation methods have been introduced to RS. However, there is a trade-off between explainability and performance among these methods. In this paper, we propose a novel framework, the Tower Bridge Net (TB-Net), using the proposed bidirectional embedding propagation approach to achieve both superior recommendation and explainability performances. Extensive validation on three public datasets shows that the performance of TB-Net dominates the state-of-the-art models. We quantitatively evaluate the explainability by using numerical metrics and experimentally prove that TB-Net achieves a significant improvement on explainability compared with existing methods. More importantly, TB-Net has been deployed and offers explainable recommendation service for the largest bank in China, Industrial and Commercial Bank of China Limited (ICBC). Results on a billion-scale dataset (1.2 billion nodes and edges) from ICBC show that TB-Net can provide both accurate recommendations and semantic explanations, and is very effective and deployable in practice.}
}


@inproceedings{DBLP:conf/icde/ChengGLXWX22,
	author = {Sijie Cheng and
                  Zhouhong Gu and
                  Bang Liu and
                  Rui Xie and
                  Wei Wu and
                  Yanghua Xiao},
	title = {Learning What You Need from What You Did: Product Taxonomy Expansion
                  with User Behaviors Supervision},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {3280--3293},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00310},
	doi = {10.1109/ICDE53745.2022.00310},
	timestamp = {Wed, 21 Aug 2024 20:51:44 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ChengGLXWX22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Taxonomies have been widely used in various domains to underpin numerous applications. Specially, product taxonomies serve an essential role in the e-commerce domain for the recommendation, browsing, and query understanding. However, taxonomies need to constantly capture the newly emerged terms or concepts in e-commerce platforms to keep up-to-date, which is expensive and labor-intensive if it relies on manual maintenance and updates. Therefore, we target the taxonomy expansion task to attach new concepts to existing taxonomies automatically. In this paper, we present a self-supervised and user behavior-oriented product taxonomy expansion framework to append new concepts into existing taxonomies. Our framework extracts hyponymy relations that conform to users' intentions and cognition. Specifically, i) to fully exploit user behavioral information, we extract candidate hyponymy relations that match user interests from query-click concepts; ii) to enhance the semantic information of new concepts and better detect hyponymy relations, we model concepts and relations through both user-generated content and structural information in existing taxonomies and user click logs, by leveraging Pre-trained Language Models and Graph Neural Network combined with Contrastive Learning; iii) to reduce the cost of dataset construction and overcome data skews, we construct a high-quality and balanced training dataset from existing taxonomy with no supervision. Extensive experiments on real-world product taxonomies in Meituan Platform, a leading Chinese vertical e-commerce platform to order take-out with more than 70 million daily active users, demonstrate the superiority of our proposed framework over state-of-the-art methods. Notably, our method enlarges the size of real-world product taxonomies from 39,263 to 94,698 relations with 88% precision. Our implementation is available: https://github.com/AdaCheng/Product_Taxonomy_Expansion.}
}


@inproceedings{DBLP:conf/icde/LiuXRHHBZZ22,
	author = {Shuncheng Liu and
                  Zhi Xu and
                  Huimin Ren and
                  Tianfu He and
                  Boyang Han and
                  Jie Bao and
                  Kai Zheng and
                  Yu Zheng},
	title = {Detecting Loaded Trajectories for Hazardous Chemicals Transportation},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {3294--3306},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00311},
	doi = {10.1109/ICDE53745.2022.00311},
	timestamp = {Fri, 05 Aug 2022 16:24:02 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LiuXRHHBZZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Hazardous chemicals transportation (HCT) brings significant financial, environmental, and health-related risks. It is imperative that a robust regulatory system is in place to reduce the risk of accidents occurring while such hazardous chemicals are being transported. Governments around the world use GPS sensors to monitor the raw trajectories of HCT trucks, but they have difficulty detecting the loaded trajectories, which is of utmost importance for the management of H CT processes. The loaded trajectory refers to the subtrajectory generated by tracking an HCT truck when it is loaded with hazardous chemical in an HCT process. The stay points in the raw trajectory provide some feasibility to detect the loaded trajectory as they reflect the potential loading and unloading actions of the HCT truck. However, directly using the stay points to detect the loaded trajectory usually leads to unsatisfactory results due to two chal-lenges: (1) complex staying scenarios, and (2) numerous loading and unloading locations. To tackle the challenges, we propose a LoadEd trAjectory Detectlon framework, called LEAD, to detect the loaded trajectory from the raw HCT trajectory accurately and efficiently. LEAD processes a raw trajectory into a set of candidate trajectories, encodes each candidate trajectory into a latent representation, and detects the loaded trajectory using the latent representations of candidate trajectories. Extensive experiments based on a real-world dataset from Nantong, China confirm the effectiveness of our framework. The results show that the detection accuracy of LEAD exceeds 83 % which outperforms competing baselines by over 42 %.}
}


@inproceedings{DBLP:conf/icde/WangLLZLO22,
	author = {Sinan Wang and
                  Yumeng Li and
                  Hongyan Li and
                  Tanchao Zhu and
                  Zhao Li and
                  Wenwu Ou},
	title = {Multi-Task Learning with Calibrated Mixture of Insightful Experts},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {3307--3319},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00312},
	doi = {10.1109/ICDE53745.2022.00312},
	timestamp = {Fri, 02 Sep 2022 08:42:23 +0200},
	biburl = {https://dblp.org/rec/conf/icde/WangLLZLO22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Multi-task learning has been established as an important machine learning framework for leveraging shared knowledge among multiple different but related tasks, with the generalization performance of models enhanced. As a promising learning paradigm, multi-task learning has been widely adopted by various real-world applications, such as recommendation systems. Multi-gate Mixture-of-Experts (MMoE), a well-received multi-task learning method in industry, based on the classic and inspiring Mixture-of-Experts (MoE) structure, explicitly models task relationships and learns task-specific functionalities, generating significant improvements. However, in our applications, negative transfer, which confuses considerable existing multi-task learning methods, is still observed to happen to MMoE. In this paper, an in-depth empirical investigation into negative transfer is launched. And it reveals that, incompetent experts, which play fundamental roles under the learning framework of MoE, are the key technique bottleneck. To tackle this dilemma, we propose the Calibrated Mixture of Insightful Experts (CMoIE), with three novel modules (Conflict Resolution, Expert Communication, and Mixture Calibration), customed for multi-task learning. Hence a group of insightful experts are constructed with enhanced diversity, communication and specialization. To validate the proposed method CMoIE, experiments are conducted on three public datasets and one real-world click-through-rate prediction dataset we construct based on traffic logs collected from a large-scale online product recommendation system. Our approach yields best performance across all of these benchmarks, demonstrating the superiority of it.}
}


@inproceedings{DBLP:conf/icde/YeYHZHHZF22,
	author = {Borui Ye and
                  Shuo Yang and
                  Binbin Hu and
                  Zhiqiang Zhang and
                  Youqiang He and
                  Kai Huang and
                  Jun Zhou and
                  Yanming Fang},
	title = {Gaia: Graph Neural Network with Temporal Shift aware Attention for
                  Gross Merchandise Value Forecast in E-commerce},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {3320--3326},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00313},
	doi = {10.1109/ICDE53745.2022.00313},
	timestamp = {Fri, 05 Aug 2022 16:24:00 +0200},
	biburl = {https://dblp.org/rec/conf/icde/YeYHZHHZF22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {E-commerce has gone a long way in empowering merchants through the internet. In order to store the goods efficiently and arrange the marketing resource properly, it is important for them to make the accurate gross merchandise value (GMV) prediction. However, it's nontrivial to make accurate prediction with the deficiency of digitized data. In this article, we present a solution to better forecast GMV inside Alipay app. Thanks to graph neural networks (G NN) which has great ability to correlate different entities to enrich information, we propose Gaia, a graph neural network (GNN) model with temporal shift aware attention. Gaia leverages the relevant e-seller’ sales information and learn neighbor correlation based on temporal dependencies. By testing on Alipay's real dataset and comparing with other baselines, Gaia has shown the best performance. And Gaia is deployed in the simulated online environment, which also achieves great improvement compared with baselines.}
}


@inproceedings{DBLP:conf/icde/ShiTZXTL22,
	author = {Dingyuan Shi and
                  Yongxin Tong and
                  Zimu Zhou and
                  Ke Xu and
                  Wenzhe Tan and
                  Hongbo Li},
	title = {Adaptive Task Planning for Large-Scale Robotized Warehouses},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {3327--3339},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00314},
	doi = {10.1109/ICDE53745.2022.00314},
	timestamp = {Sun, 06 Oct 2024 21:04:58 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ShiTZXTL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Robotized warehouses are deployed to automatically distribute millions of items brought by the massive logistic orders from e-commerce. A key to automated item distribution is to plan paths for robots, also known as task planning, where each task is to deliver racks with items to pickers for processing and then return the rack back. Prior solutions are unfit for large-scale robotized warehouses due to the inflexibility to time-varying item arrivals and the low efficiency for high throughput. In this paper, we propose a new task planning problem called TPRW, which aims to minimize the end-to-end makespan that incorporates the entire item distribution pipeline, known as a fulfilment cycle. Direct extensions from state-of-the-art path finding methods are ineffective to solve the TPRW problem because they fail to adapt to the bottleneck variations of fulfillment cycles. In response, we propose Efficient Adaptive Task Planning, a framework for large-scale robotized warehouses with time-varying item arrivals. It adaptively selects racks to fulfill at each timestamp via rein-forcement learning, accounting for the time-varying bottleneck of the fulfillment cycles. Then it finds paths for robots to transport the selected racks. The framework adopts a series of efficient optimizations on both time and memory to handle large-scale item throughput. Evaluations on both synthesized and real data show an improvement of 37.1% in effectiveness and 75.5% in efficiency over the state-of-the-arts.}
}


@inproceedings{DBLP:conf/icde/KangHSZQWWF22,
	author = {Yuyuan Kang and
                  Xiangdong Huang and
                  Shaoxu Song and
                  Lingzhe Zhang and
                  Jialin Qiao and
                  Chen Wang and
                  Jianmin Wang and
                  Julian Feinauer},
	title = {Separation or Not: On Handing Out-of-Order Time-Series Data in Leveled
                  LSM-Tree},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {3340--3352},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00315},
	doi = {10.1109/ICDE53745.2022.00315},
	timestamp = {Mon, 09 Sep 2024 19:07:30 +0200},
	biburl = {https://dblp.org/rec/conf/icde/KangHSZQWWF22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {LSM-Tree is widely adopted for storing time-series data in Internet of Things. According to conventional policy (denoted by\nπ\nc\n), when writing, the data will first be buffered in MemTable in memory. When it is full, the data will be written to the disk to form SSTables. Compaction is triggered to sort the data in each layer of the LSM-Tree on the disk. However, the arrival of data can be unordered due to reasons such as transition delay. Apache IoTDB uses in-order and out-of-order MemTables to separately buffer the in-order and out-of-order data to accelerate queries, namely the separation policy (denoted by\nπ\ns\n). However, given a specific space of memory budget to buffer the data, write amplification (WA) of the leveled LSM-Tree will be influenced by\nπ\ns\n. Whether the influence by separation is positive or negative, and how intense WA is influenced, depend on the properties of workloads and the capacity of the in-order and out-of-order MemTables. It is highly demanded to build robust models for estimating the expected amount of data rewritten in each compaction, and predicting the WA under\nπ\nc\nand\nπ\ns\n. Note that as an industrial paper, rather than proposing novel techniques for research problems, we focus on the practice of whether separating or not for lower write amplification. Experiments on synthetic and real-world datasets show that the models for estimating WA are accurate under various delay distributions. In addition, based on the estimation models, we implement an analyzer module in the open-source Apache IoTDB, for choosing the policy with lower WA. We apply the method in the use case of our industrial partner, a service provider of engineering machinery. The use case verifies the effectiveness of deciding whether separation or not by WA estimation.}
}


@inproceedings{DBLP:conf/icde/KimSLCHPK22,
	author = {Namhyuk Kim and
                  Junho Song and
                  Siyoung Lee and
                  Jaewon Choe and
                  Kyungsik Han and
                  Sunghwan Park and
                  Sang{-}Wook Kim},
	title = {{APOTS:} {A} Model for Adversarial Prediction of Traffic Speed},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {3353--3359},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00316},
	doi = {10.1109/ICDE53745.2022.00316},
	timestamp = {Mon, 05 Feb 2024 20:31:12 +0100},
	biburl = {https://dblp.org/rec/conf/icde/KimSLCHPK22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Many global automakers strive to develop technologies towards the next-generation of intelligent transportation systems (ITS). One of the primary goals of ITS is predicting future traffic speeds to optimize a driver's route, which can lead to not only alleviating traffic flow but also increasing user satisfaction with an ITS service. While prior studies have applied deep learning models to traffic speed prediction and improved model performance, existing models did not well capture abrupt speed changes. In this paper, we propose a novel model, named as adversarial prediction of traffic speed (APOTS), based on adversarial training, data augmentation, and hybrid deep learning modeling. Through the experiments with real traffic data provided by Hyundai Motor Company, we demonstrate that APOTS effectively learns dynamics of traffic speed changes and predicts traffic speed up to 40% higher in accuracy than existing prediction models.}
}


@inproceedings{DBLP:conf/icde/LiuCLLFT22,
	author = {Jiabin Liu and
                  Chengliang Chai and
                  Yuyu Luo and
                  Yin Lou and
                  Jianhua Feng and
                  Nan Tang},
	title = {Feature Augmentation with Reinforcement Learning},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {3360--3372},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00317},
	doi = {10.1109/ICDE53745.2022.00317},
	timestamp = {Fri, 05 Aug 2022 16:24:02 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LiuCLLFT22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Sufficient good features are indispensable to train well-performed machine learning models. However, it is com-mon that good features are not always enough, where feature augmentation is necessary to enrich high-quality features by joining with other tables. There are two main challenges for the problem. Given a set of tables where we can augment features from, the first challenge is that there are a lot of ways of joining multiple tables and deciding which features (or attributes) to use - selecting the best set of features to augment is hard. Moreover, we may need to materialize the join results for different join options, doing full materialization might be time consuming - efficient but approximate methods are needed. In this paper, we first introduce the design space of the feature augmentation problem. Then, to address the above challenges, we propose a reinforcement learning based framework, namely AutoFeature, to augment the features following an exploration-exploitation strategy. AutoFeature keeps exploring the features in tables that have led to performance improvement. At the same time, AutoFeature also exploits the tables (features) that are rarely selected. In this way, the search space of tables (features) to be augmented can be well explored and a subset of good features can be selected. AutoFeature utilizes sampling techniques to achieve high efficiency. We implement two algorithms, one with multi-arm bandit and the other with branch Deep Q Networks (branch DQN), to realize the framework of AutoFeature. We conducted experiments on three real-world datasets School/XuetangE/Air using 16/23/34 candidate tables with 695/204/338 candidate features. Extensive results show that AutoFeature outperforms other methods by 12.4% and 9.8% on AUC values on two classification datasets (School and XuetangE) and by 0.113 on the MSE value on Air in terms of the model performance.}
}


@inproceedings{DBLP:conf/icde/WuSSVG22,
	author = {Lianlong Wu and
                  Emanuel Sallinger and
                  Evgeny Sherkhonov and
                  Sahar Vahdati and
                  Georg Gottlob},
	title = {Rule Learning over Knowledge Graphs with Genetic Logic Programming},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {3373--3385},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00318},
	doi = {10.1109/ICDE53745.2022.00318},
	timestamp = {Fri, 05 Aug 2022 16:24:02 +0200},
	biburl = {https://dblp.org/rec/conf/icde/WuSSVG22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Declarative rules such as Prolog and Datalog rules are common formalisms to express expert knowledge and facts. They play an important role in Knowledge Graph (KG) construction and completion. Such rules not only encode the expert background knowledge and the relational patterns among the data, but also infer new knowledge and insights from them. Formalizing rules is often a laborious manual process, while learning them from data automatically can ease this process. Within the rule hypothesis space, current approaches resort to exhaustive search with a number of heuristics and syntactic restrictions on the rule language, which impacts the efficiency and quality of the outcome rules. In this paper, we extend the rule hypothesis space from usual path rules to general Datalog rule space by proposing a novel Genetic Logic Programming algorithm named Evoda. It is an iterative process to learn high-quality rules over large scale KG for a matter of seconds. We have performed experiments over multiple real-world KGs and various evaluation metrics to show its mining capabilities for higher quality rules and more precise predictions. Additionally, we have applied it on the KG completion tasks to illustrate its competitiveness with several state-of-the-art embedding or neural-based models. The experiments demonstrate the feasibility, effectiveness and efficiency of the Evoda algorithm.}
}


@inproceedings{DBLP:conf/icde/LimLLHKJKKHCKLC22,
	author = {Hongjun Lim and
                  Yeon{-}Chang Lee and
                  Jin{-}Seo Lee and
                  Sanggyu Han and
                  Seunghyeon Kim and
                  Yeon Jeong Jeong and
                  Changbong Kim and
                  Jaehun Kim and
                  Sunghoon Han and
                  Solbi Choi and
                  Hanjong Ko and
                  Dokyeong Lee and
                  Jaeho Choi and
                  Yungi Kim and
                  Hong{-}Kyun Bae and
                  Taeho Kim and
                  Jeewon Ahn and
                  Hyun{-}Soung You and
                  Sang{-}Wook Kim},
	title = {AiRS: {A} Large-Scale Recommender System at {NAVER} News},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {3386--3398},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00319},
	doi = {10.1109/ICDE53745.2022.00319},
	timestamp = {Mon, 26 Jun 2023 20:41:56 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LimLLHKJKKHCKLC22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Online news providers such as Google News, Bing News, and NAVER News collect a large number of news articles from a variety of presses and distribute these articles to users via their portals. Dynamic nature of a news domain causes the problem of information overload that makes it difficult for a user to find her preferable news articles. Motivated by this situation, NAVER Corp., the largest portal company in South Korea, identified four design considerations (DCs) for news recommendation that reflect the unique characteristics of a news domain. In this paper, we introduce a large-scale news recommender system named as AiRS, present how it jointly leverages the four DCs for NAVER News service. Specifically, AiRS first generates candidate articles for recommendation to a target user based on collaborative filtering (CF), quality estimation (QE), and social impact (SI) models; then, it ranks the candidate articles based on the scores computed by considering their multi-type feature scores (e.g., user's section preference and article's recency), finally recommending the top-\nk\nnews articles that a target user is likely to prefer. Also, we present how to build the architecture for online deployment of AiRS at NAVER News. Through extensive offline and online A/B tests using the real-world datasets, we validate that AiRS successfully reflects all of the DCs into the news recommendation process, all design choices employed in AiRS help improve the recommendation accuracy, and AiRS significantly outperforms five state-of-the-art news recommendation approaches in terms of accuracy.}
}


@inproceedings{DBLP:conf/icde/WuZLCZF22,
	author = {Han Wu and
                  Hongzhe Zhang and
                  Liangyue Li and
                  Zulong Chen and
                  Fanwei Zhu and
                  Xiao Fang},
	title = {Cheaper Is Better: Exploring Price Competitiveness for Online Purchase
                  Prediction},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {3399--3412},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00320},
	doi = {10.1109/ICDE53745.2022.00320},
	timestamp = {Fri, 05 Aug 2022 16:24:00 +0200},
	biburl = {https://dblp.org/rec/conf/icde/WuZLCZF22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Price, a crucial factor determining whether a user will purchase an item, has attracted considerable attention in personalized ranking and recommendation. Existing studies commonly assume that only item price affects user online purchase decisions. However, in reality, users not only focus on the price of an item itself but also compare the price with the item's “comparison prices,” including its past prices, prices of similar items, and prices on other e-commerce platforms. Without carefully considering these comparison prices, methods fail to capture the purchase motivation attributable to prices comprehensively. To address this problem, in this paper, we introduce the concept of item price competitiveness. An item's price competitiveness measures the advantage of the item's price over its comparison prices. Then, a novel Price Competitiveness-aware Network (PCNet) is proposed to predict users' purchase behaviors by explicitly considering the price competitiveness of items. Specifically, PCNet consists of three key modules, and each module exploits one corresponding facet of price competitiveness. We leverage prior knowledge discovered from a real-world dataset to guide module designs, thus enhancing the performance and interpretability of the PCNet. Offline experiments show the superiority of the PCNet and verify the effectiveness of each module. Moreover, PCNet has been deployed online in a hotel search engine at Fliggy and benefits both the platform and users.}
}


@inproceedings{DBLP:conf/icde/FanZCLXLPG22,
	author = {Ge Fan and
                  Chaoyun Zhang and
                  Junyang Chen and
                  Baopu Li and
                  Zenglin Xu and
                  Yingjie Li and
                  Luyu Peng and
                  Zhiguo Gong},
	title = {Field-aware Variational Autoencoders for Billion-scale User Representation
                  Learning},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {3413--3425},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00321},
	doi = {10.1109/ICDE53745.2022.00321},
	timestamp = {Thu, 08 Aug 2024 12:56:51 +0200},
	biburl = {https://dblp.org/rec/conf/icde/FanZCLXLPG22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {User representation learning plays an essential role in Internet applications, such as recommender systems. Though developing a universal embedding for users is demanding, only few previous works are conducted in an unsupervised learning manner. The unsupervised method is however important as most of the user data is collected without specific labels. In this paper, we harness the unsupervised advantages of Variational Autoencoders (VAEs), to learn user representation from large-scale, high-dimensional, and multi-field data. We extend the traditional VAE by developing Field-aware VAE (FVAE) to model each feature field with an independent multinomial distribution. To reduce the complexity in training, we employ dynamic hash tables, a batched softmax function, and a feature sampling strategy to improve the efficiency of our method. We conduct experiments on multiple datasets, showing that the proposed FVAE significantly outperforms baselines on several tasks of data reconstruction and tag prediction. Moreover, we deploy the proposed method in real-world applications and conduct online A/B tests in a look-alike system. Results demonstrate that our method can effectively improve the quality of recommendation. To the best of our knowledge, it is the first time that the VAE-based user representation learning model is applied to real-world recommender systems.}
}


@inproceedings{DBLP:conf/icde/DingXOZZLZL22,
	author = {Jiayuan Ding and
                  Tong Xiang and
                  Zijing Ou and
                  Wangyang Zuo and
                  Ruihui Zhao and
                  Chenhua Lin and
                  Yefeng Zheng and
                  Bang Liu},
	title = {Tell Me How to Survey: Literature Review Made Simple with Automatic
                  Reading Path Generation},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {3426--3438},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00322},
	doi = {10.1109/ICDE53745.2022.00322},
	timestamp = {Fri, 05 Aug 2022 16:24:03 +0200},
	biburl = {https://dblp.org/rec/conf/icde/DingXOZZLZL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recent years have witnessed the dramatic growth of paper volumes with plenty of new research papers published every day, especially in the area of computer science. How to glean papers worth reading from the massive literature to do a quick survey or keep up with the latest advancement about a specific research topic has become a challenging task. Existing academic search engines return relevant papers by individually calculating the relevance between each paper and query. However, such systems usually omit the prerequisite chains of a research topic and cannot form a meaningful reading path. In this paper, we introduce a new task named Reading Path Generation (RPG) which aims at automatically producing a path of papers to read for a given query. To serve as a research benchmark, we further propose SurveyBank, a dataset consisting of large quantities of survey papers in the field of computer science as well as their citation relationships. Furthermore, we propose a graph-optimization-based approach for reading path generation which takes the relationship between papers into account. Extensive evaluations demonstrate that our approach outperforms other baselines. A real-time Reading Path Generation (RePaGer) system has been also implemented with our designed model. Our source code and SurveyBank dataset can be found here 1 1 https://github.com/JiayuanDing100/Reading-Path-Generation.}
}


@inproceedings{DBLP:conf/icde/XuWWLWYDZZXZ22,
	author = {Zhirong Xu and
                  Shiyang Wen and
                  Junshan Wang and
                  Guojun Liu and
                  Liang Wang and
                  Zhi Yang and
                  Lei Ding and
                  Yan Zhang and
                  Di Zhang and
                  Jian Xu and
                  Bo Zheng},
	title = {{AMCAD:} Adaptive Mixed-Curvature Representation based Advertisement
                  Retrieval System},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {3439--3452},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00323},
	doi = {10.1109/ICDE53745.2022.00323},
	timestamp = {Thu, 08 Aug 2024 08:05:57 +0200},
	biburl = {https://dblp.org/rec/conf/icde/XuWWLWYDZZXZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graph embedding based retrieval has become one of the most popular techniques in the information retrieval community and search engine industry. The classical paradigm mainly relies on the flat Euclidean geometry. In recent years, hyperbolic (negative curvature) and spherical (positive curvature) representation methods have shown their superiority to capture hierarchical and cyclic data structures respectively. However, in industrial scenarios such as e-commerce sponsored search platforms, the large-scale heterogeneous query-item-advertisement interaction graphs often have multiple structures coexisting. Existing methods either only consider a single geometry space, or combine several spaces manually, which are incapable and inflexible to model the complexity and heterogeneity in the real scenario. To tackle this challenge, we present a web-scale Adaptive Mixed-Curvature ADvertisement retrieval system (AM-CAD) to automatically capture the complex and heterogeneous graph structures in non-Euclidean spaces. Specifically, entities are represented in adaptive mixed-curvature spaces, where the types and curvatures of the subspaces are trained to be optimal combinations. Besides, an attentive edge-wise space projector is designed to model the similarities between heterogeneous nodes according to local graph structures and the relation types. Moreover, to deploy AMCAD in Taobao, one of the largest e-commerce platforms with hundreds of million users, we design an efficient two-layer online retrieval framework for the task of graph based advertisement retrieval. Extensive evaluations on real-world datasets and A/B tests on online traffic are conducted to illustrate the effectiveness of the proposed system.}
}


@inproceedings{DBLP:conf/icde/ZhangCYYYZWDXSL22,
	author = {Yuanxing Zhang and
                  Langshi Chen and
                  Siran Yang and
                  Man Yuan and
                  Huimin Yi and
                  Jie Zhang and
                  Jiamang Wang and
                  Jianbo Dong and
                  Yunlong Xu and
                  Yue Song and
                  Yong Li and
                  Di Zhang and
                  Wei Lin and
                  Lin Qu and
                  Bo Zheng},
	title = {{PICASSO:} Unleashing the Potential of GPU-centric Training for Wide-and-deep
                  Recommender Systems},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {3453--3466},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00324},
	doi = {10.1109/ICDE53745.2022.00324},
	timestamp = {Thu, 18 Jul 2024 08:28:31 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhangCYYYZWDXSL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The development of personalized recommendation has significantly improved the accuracy of information matching and the revenue of e-commerce platforms. Recently, it has two trends: 1) recommender systems must be trained timely to cope with ever-growing new products and ever-changing user interests from online marketing and social network; 2) state-of-the-art recommendation models introduce deep neural network (DNN) modules to improve prediction accuracy. Traditional CPU-based recommender systems cannot meet these two trends, and GPU-centric training has become a trending approach. However, we observe that GPU devices in training recommender systems are underutilized, and they cannot attain an expected throughput improvement as what it has achieved in Computer Vision (CV) and Neural Language Processing (NLP) areas. This issue can be explained by two characteristics of these recommendation models: First, they contain up to a thousand of input feature fields, introducing fragmentary and memory-intensive operations; Second, the multiple constituent feature interaction submodules introduce substantial small-sized compute kernels. To remove this roadblock to the development of recommender systems, we propose a novel framework named PICASSO to accelerate the training of recommendation models on commodity hardware. Specifically, we conduct a systematic analysis to reveal the bottlenecks encountered in training recommendation models. We leverage the model structure and data distribution to unleash the potential of hardware through our packing, interleaving, and caching optimization. Experiments show that PICASSO increases the hardware utilization by an order of magnitude on the basis of state-of-the-art baselines and brings up to 6× throughput improvement for a variety of industrial recommendation models. Using the same hardware budget in production, PICASSO on average shortens the walltime of daily training tasks by 7 hours, significantly reducing the delay of continuous delivery.}
}


@inproceedings{DBLP:conf/icde/YaoZQWZX22,
	author = {Kaichun Yao and
                  Jingshuai Zhang and
                  Chuan Qin and
                  Peng Wang and
                  Hengshu Zhu and
                  Hui Xiong},
	title = {Knowledge Enhanced Person-Job Fit for Talent Recruitment},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {3467--3480},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00325},
	doi = {10.1109/ICDE53745.2022.00325},
	timestamp = {Mon, 26 Jun 2023 20:41:55 +0200},
	biburl = {https://dblp.org/rec/conf/icde/YaoZQWZX22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As an essential task of talent recruitment, person-job fit aims to measure the matching degree between talent qualifi-cation and the job requirements of a position. Existing studies usually formulate this task as a long text matching problem with a focus on learning effective representations of both job postings and resumes. However, it is commonly known that there exists a semantic gap between textual job postings and textual resumes. Therefore, in this paper, we study how to improve person-job fit by bridging this semantic gap with the help of prior knowledge. To this end, we first design a distantly supervised skill extraction model to identify the skill entities from the given job postings and resumes using only unlabeled data and skill entity dictionaries. The identified skill entities will be used to construct a skill knowledge graph (KG) on the global corpus, which can provide the prior knowledge. Also, we propose a knowledge enhanced person-job fit approach for talent recruitment. Here, we model job postings and resumes as two graphs and fuse the prior external knowledge into the graph representation learning. Specifically, we first build the graphs from job posting and resume text. Then, we design a knowledge-aware graph encoder that can not only capture the contextual word relationships within each job posting or resume, but also incorporate the prior knowledge into node representation learning. In addition, we propose an interactive learning method to perform effective graph matching in both graph-level and node-level, respectively. Meanwhile, a multi-task learning strategy is introduced to facilitate the graph representation learning. Finally, extensive experiments conducted on real-world datasets have clearly validated the effectiveness of our approaches compared with state-of-the-art baselines.}
}


@inproceedings{DBLP:conf/icde/XuHCLTX22,
	author = {Jia Xu and
                  Jin Huang and
                  Zulong Chen and
                  Yang Li and
                  Wanjie Tao and
                  Chuanfei Xu},
	title = {{ODNET:} {A} Novel Personalized Origin-Destination Ranking Network
                  for Flight Recommendation},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {3481--3493},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.00326},
	doi = {10.1109/ICDE53745.2022.00326},
	timestamp = {Fri, 05 Aug 2022 16:24:01 +0200},
	biburl = {https://dblp.org/rec/conf/icde/XuHCLTX22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Origin-Destination recommendation that recom-mends personalized origin city (O) and destination city (D) of flight itinerary is of great value for both Online Travel Platforms (OTPs) and users. Existing studies on next location recommendation propose to model the sequential regularity of users' check-in location sequences, but cannot well solve two new challenges facing OTPs, namely the necessity of exploring O&D and learning O&D as a whole. To this end, we propose a novel personalized Origin-Destination ranking NETwork (ODNET) for flight recommendation. In particular, a heterogeneous spatial graph (HSG) which models historical interactions between users and cities is designed at first. HSG is then deployed in ODNET to identify user preference Os and Ds by exploring the neighbor-hood information in HSG. To cope with the second challenge, the idea of multi-task learning is employed by ODNET to learn\nO\nand\nD\njointly so as to capture their correlations. Moreover, temporal information of Os and Ds are also considered to further improve the accuracy of origin-destination recommendation. An offline experiment on multiple real-world datasets and an online A/B test both show the superiority of ODNET towards the state-of-the-art methods. Further, the implementation and deployment details of the proposed ODNET at Fliggy, one of the most popular OTPs in China, are also described. ODNET has now been successfully applied to provide high-quality flight recommendation service at Fliggy, serving tens of millions of users.}
}


@inproceedings{DBLP:conf/icde/AzzaliniCT22a,
	author = {Fabio Azzalini and
                  Chiara Criscuolo and
                  Letizia Tanca},
	title = {{FAIR-DB:} {A} system to discover unfairness in datasets},
	booktitle = {38th {IEEE} International Conference on Data Engineering, {ICDE} 2022,
                  Kuala Lumpur, Malaysia, May 9-12, 2022},
	pages = {3494--3497},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/ICDE53745.2022.9866857},
	doi = {10.1109/ICDE53745.2022.9866857},
	timestamp = {Fri, 02 Sep 2022 18:51:53 +0200},
	biburl = {https://dblp.org/rec/conf/icde/AzzaliniCT22a.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In our everyday lives, technologies based on data play an increasingly important role. With the widespread adoption of decision making systems also in very sensitive environments, fairness has become a very important topic of discussion within the data science community. In this context, it is crucial to ensure that the data on which we base these decisions, are fair, and do not reflect historical biases. In this demo, we propose FAIR-DB (FunctionAl dependencIes to discoveR Data Bias), a system that exploiting the notion of Functional Dependency, a particular type of constraint on the data, can discover unethical behaviours in a dataset. The proposed solution is implemented as a web-based application, that, given an input dataset, generates such dependencies, walks the user trough their analysis, and finally provides many insights about bias present in the data. Our tool uses a novel metric to evaluate the unfairness present in datasets, identifies the attributes that encompass discrimination (e.g. ethnicity, sex or religion), and provides very precise information about the groups treated unequally. We also provide a detailed description of the system architecture and present a demonstration scenario, based on a real-world dataset frequently used in the field of computer ethics.}
}
