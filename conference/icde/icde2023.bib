@inproceedings{DBLP:conf/icde/TrungCLYB23,
	author = {Tran Ba Trung and
                  Lijun Chang and
                  Nguyen Tien Long and
                  Kai Yao and
                  Huynh Thi Thanh Binh},
	title = {Verification-Free Approaches to Efficient Locally Densest Subgraph
                  Discovery},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {1--13},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00008},
	doi = {10.1109/ICDE55515.2023.00008},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/TrungCLYB23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Finding dense subgraphs from a large graph is a fundamental graph mining task with many applications. The notion is recently formulated of locally densest subgraph (LDS) is recently formulated to identify multiple dense subgraphs that cover different regions of a large graph. Informally, an LDS is a subgraph with the highest density in its local region. The state-of-the-art algorithm for computing top-k LDSes with the highest densities is LDS. It iteratively computes the densest subgraph and removes it from the graph, where all the computed densest subgraphs form the candidates of LDSes. Then, each candidate is verified through a costly maximum flow computation. Although advanced pruning techniques are proposed in LDS, the verification step is still time consuming especially for not-so-small k values. In this paper, we aim to improve the efficiency of finding top-k LDSes by designing verification-free approaches. Our algorithms are based on our observation that the set of maximal λ-compact subgraphs for all possible λ values form a hierarchical structure, and LDSes are simply leaves in the hierarchical structure. Thus, we propose a divide-and-conquer algorithm LDS-DC as well as an optimized algorithm LDS-Opt to efficiently identify top-k LDSes without constructing the entire hierarchical structure. Both of our algorithms have lower time complexities than LDS. Extensive empirical studies on real graphs show that our optimized algorithm LDS-Opt outperforms LDS for all k values, and the improvement is up-to several orders of magnitude.}
}


@inproceedings{DBLP:conf/icde/LiuKY0MCZT023,
	author = {Zirui Liu and
                  Chaozhe Kong and
                  Kaicheng Yang and
                  Tong Yang and
                  Ruijie Miao and
                  Qizhi Chen and
                  Yikai Zhao and
                  Yaofeng Tu and
                  Bin Cui},
	title = {HyperCalm Sketch: One-Pass Mining Periodic Batches in Data Streams},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {14--26},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00009},
	doi = {10.1109/ICDE55515.2023.00009},
	timestamp = {Thu, 24 Oct 2024 16:57:14 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LiuKY0MCZT023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Batch is an important pattern in data streams, which refers to a group of identical items that arrive closely. We find that some special batches that arrive periodically are of great value. In this paper, we formally define a new pattern, namely periodic batches. A group of periodic batches refers to several batches of the same item, where these batches arrive periodically. Studying periodic batches is important in many applications, such as caches, financial markets, online advertisements, networks, etc. We propose a one-pass sketching algorithm, namely the HyperCalm sketch, which takes two phases to detect periodic batches in real time. In phase 1, we propose a time-aware Bloom filter, namely HyperBloomFilter (HyperBF), to detect the start of batches. In phase 2, we propose an enhanced top-k algorithm, called Calm Space-Saving (CalmSS), to report top-k periodic batches. We theoretically derive the error bounds for HyperBF and CalmSS. Extensive experiments show HyperCalm outperforms the strawman solutions 4× in term of average relative error and 13.2× in term of speed. We also apply HyperCalm to a cache system and integrate HyperCalm into Apache Flink. All related codes are open-sourced.}
}


@inproceedings{DBLP:conf/icde/GaoHZ00C23,
	author = {Yuanning Gao and
                  Xiuqi Huang and
                  Xuanhe Zhou and
                  Xiaofeng Gao and
                  Guoliang Li and
                  Guihai Chen},
	title = {DBAugur: An Adversarial-based Trend Forecasting System for Diversified
                  Workloads},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {27--39},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00385},
	doi = {10.1109/ICDE55515.2023.00385},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/GaoHZ00C23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Trend forecasting is vital to optimize the workload performance. It becomes even more urgent with an increasing number of applications and database configurations. However, DBAs mainly target at historical workloads and may give suboptimal configuration advice when the workload trends have changed. Although there are some studies on trend forecasting, they have several limitations. First, they mainly predict the changes of query numbers, which do not combine other critical factors (e.g., disk utilization) and cannot fully reflect the future workload trends. Besides, there are numerous queries in the workloads and exact clustering algorithms like K-means cannot effectively merge similar queries which contain noises like time shifts. Second, basic machine learning models like RNN may have relatively low prediction accuracy on complex workloads (e.g., no cycles but random bursts). Third, real-world workloads may have diverse patterns, while previous models cannot efficiently and reliably predict for all the different workload patterns.To address these challenges, we propose a trend forecasting system (DBAugur) that utilizes adversarial neural networks to predict the trends of different workloads. First, DBAugur collects the important features (e.g., queries, resource metrics) to characterize workloads, and reduces the number of involved queries by separately merging similar queries based on the SQL semantics and trend patterns. Second, DBAugur utilizes Generative Adversarial Networks (GANs) to capture the latent patterns, correlations between different metrics, and occasional bursts within the complicated and time-varying workloads. Moreover, we further propose a time-sensitive ensemble algorithm that takes advantage of various machine learning models (e.g., generative models, convolutional models, feed-forward models) to accommodate the various workload patterns. The experimental results show that DBAugur outperformed state-of-the-art methods on various real-world workloads.}
}


@inproceedings{DBLP:conf/icde/WangCZDDW23,
	author = {Zhenlei Wang and
                  Xu Chen and
                  Rui Zhou and
                  Quanyu Dai and
                  Zhenhua Dong and
                  Ji{-}Rong Wen},
	title = {Sequential Recommendation with User Causal Behavior Discovery},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {28--40},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00010},
	doi = {10.1109/ICDE55515.2023.00010},
	timestamp = {Wed, 17 Jul 2024 07:49:05 +0200},
	biburl = {https://dblp.org/rec/conf/icde/WangCZDDW23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The key of sequential recommendation lies in the accurate item correlation modeling. Previous models infer such information based on item co-occurrences, which may fail to capture the real causal relations, and impact the recommendation performance and explainability. In this paper, we equip sequential recommendation with a novel causal discovery module to capture causalities among user behaviors. Our general idea is firstly assuming a causal graph underlying item correlations, and then we learn the causal graph jointly with the sequential recommender model by fitting the real user behavior data. More specifically, in order to satisfy the causality requirement, the causal graph is regularized by a differentiable directed acyclic constraint. Considering that the number of items in recommender systems can be very large, we represent different items with a unified set of latent clusters, and the causal graph is defined on the cluster level, which enhances the model scalability and robustness. In addition, we provide theoretical analysis on the identifiability of the learned causal graph. To the best of our knowledge, this paper makes a first step towards combining sequential recommendation with causal discovery. For evaluating the recommendation performance, we implement our framework with different neural sequential architectures, and compare them with many state-of-the-art methods based on real-world datasets. Empirical studies manifest that our model can on average improve the performance by about 6.1% and 11.3% on F 1 and NDCG, respectively. To evaluate the model explainability, we build a new dataset with human labeled explanations for both quantitative and qualitative analysis.}
}


@inproceedings{DBLP:conf/icde/Chen0HC23,
	author = {Zhijun Chen and
                  Hailong Sun and
                  Haoqian He and
                  Pengpeng Chen},
	title = {Learning from Noisy Crowd Labels with Logics},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {41--52},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00011},
	doi = {10.1109/ICDE55515.2023.00011},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Chen0HC23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper explores the integration of symbolic logic knowledge into deep neural networks for learning from noisy crowd labels. We introduce Logic-guided Learning from Noisy Crowd Labels (Logic-LNCL), an EM-alike iterative logic knowledge distillation framework that learns from both noisy labeled data and logic rules of interest. Unlike traditional EM methods, our framework contains a "pseudo-E-step" that distills from the logic rules a new type of learning target, which is then used in the "pseudo-M-step" for training the classifier. Extensive evaluations on two real-world datasets for text sentiment classification and named entity recognition demonstrate that the proposed framework improves the state-of-the-art and provides a new solution to learning from noisy crowd labels.}
}


@inproceedings{DBLP:conf/icde/0003YLW0GYL0X23,
	author = {Long Zheng and
                  Xiangyu Ye and
                  Haifeng Liu and
                  Qinggang Wang and
                  Yu Huang and
                  Chuangyi Gui and
                  Pengcheng Yao and
                  Xiaofei Liao and
                  Hai Jin and
                  Jingling Xue},
	title = {AFaVS: Accurate Yet Fast Version Switching for Graph Processing Systems},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {53--66},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00012},
	doi = {10.1109/ICDE55515.2023.00012},
	timestamp = {Wed, 13 Sep 2023 20:47:31 +0200},
	biburl = {https://dblp.org/rec/conf/icde/0003YLW0GYL0X23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Multi-version graph processing has been widely used to solve many real-world problems. The process of the multi-version graph processing typically includes: (1) a history graph version switching at a specific time and (2) graph processing on this history graph. Existing multi-version graph systems assume ideally that every request for a particular graph version at a particular time will have a corresponding snapshot available. However, in most cases, this is not true. Then existing solutions usually have to settle with an "approximating" version as a substitute, leading to unexpected results for the underlying graph algorithm and thus reducing the practicality of a multi-version graph system for many application scenarios significantly.In this paper, we observe that only a few graph updates have a great impact on the final results. We therefore present AFaVS, a novel multi-version graph system that can improve accuracy effectively in both time- and memory-efficient manners. The cornerstone of AFaVS lies in a novel concept "value" that characterizes the importance of graph updates. AFaVS proposes differential management of updates based on their values and achieves higher accuracy while preserving processing and memory efficiency. AFaVS is also equipped with value-guided version switching and locality-aware optimizations to boost its overall efficiency. Our results on a variety of real-world datasets show that AFaVS outperforms four state-of-the-art multi-version graph systems by 74.35%~95.72% in terms of accuracy improvement and 57.03%~90.44% in terms of memory reduction while introducing less than 2.96% extra computing time. We have deployed AFaVS in a disaster recovery system on the production cluster of Alibaba, achieving 78.8%~90.1% fewer error rates than advanced systems at a comparable efficiency.}
}


@inproceedings{DBLP:conf/icde/ZhangBKHL23,
	author = {Chao Zhang and
                  Angela Bonifati and
                  Hugo Kapp and
                  Vlad Ioan Haprian and
                  Jean{-}Pierre Lozi},
	title = {A Reachability Index for Recursive Label-Concatenated Graph Queries},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {67--81},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00013},
	doi = {10.1109/ICDE55515.2023.00013},
	timestamp = {Fri, 28 Jul 2023 08:44:28 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhangBKHL23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Reachability queries checking the existence of a path from a source node to a target node are fundamental operators for querying and processing graph data. Current approaches for index-based evaluation of reachability queries either focus on plain reachability or constraint-based reachability with the alternation of edge labels only. In this paper, we study for the first time the problem of index-based processing for recursive label-concatenated reachability queries, referred to as RLC queries. These queries check the existence of a path that can satisfy the constraint defined by a concatenation of at most k edge labels under the Kleene plus. Many practical graph database and network analysis applications exhibit RLC queries. However, their evaluation remains prohibitive in current graph database engines.We introduce the RLC index, the first reachability index to efficiently process RLC queries. The RLC index checks whether the source vertex can reach an intermediate vertex that can also reach the target vertex under a recursive label-concatenated constraint. We propose an indexing algorithm to build the RLC index, which guarantees the soundness and the completeness of query execution and avoids recording redundant index entries. Comprehensive experiments on real-world graphs show that the RLC index can significantly reduce both the offline processing cost and the memory overhead of computing and storing transitive closure, while improving query processing up to six orders of magnitude over online traversals. Finally, our open-source implementation of the RLC index significantly outperforms current mainstream graph engines for evaluating RLC queries.}
}


@inproceedings{DBLP:conf/icde/WuWXFGWSZWZ23,
	author = {Cheng Wu and
                  Chaokun Wang and
                  Jingcao Xu and
                  Ziwei Fang and
                  Tiankai Gu and
                  Changping Wang and
                  Yang Song and
                  Kai Zheng and
                  Xiaowei Wang and
                  Guorui Zhou},
	title = {Instant Representation Learning for Recommendation over Large Dynamic
                  Graphs},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {82--95},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00014},
	doi = {10.1109/ICDE55515.2023.00014},
	timestamp = {Tue, 01 Oct 2024 08:25:47 +0200},
	biburl = {https://dblp.org/rec/conf/icde/WuWXFGWSZWZ23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recommender systems are able to learn user preferences based on user and item representations via their historical behaviors. To improve representation learning, recent recommendation models start leveraging information from various behavior types exhibited by users. In real-world scenarios, the user behavioral graph is not only multiplex but also dynamic, i.e., the graph evolves rapidly over time, with various types of nodes and edges added or deleted, which causes the Neighborhood Disturbance. Nevertheless, most existing methods neglect such streaming dynamics and thus need to be retrained once the graph has significantly evolved, making them unsuitable in the online learning environment. Furthermore, the Neighborhood Disturbance existing in dynamic graphs deteriorates the performance of neighbor-aggregation based graph models. To this end, we propose SUPA, a novel graph neural network for dynamic multiplex heterogeneous graphs. Compared to neighbor-aggregation architecture, SUPA develops a sample-update-propagate architecture to alleviate neighborhood disturbance. Specifically, for each new edge, SUPA samples an influenced subgraph, updates the representations of the two interactive nodes, and propagates the interaction information to the sampled subgraph. Furthermore, to train SUPA incrementally online, we propose InsLearn, an efficient workflow for single-pass training of large dynamic graphs. Extensive experimental results on six real-world datasets show that SUPA has a good generalization ability and is superior to sixteen state-of-the-art baseline methods. The source code is available at https://github.com/shatter15/SUPA.}
}


@inproceedings{DBLP:conf/icde/Zheng0QYCZ23,
	author = {Shangfei Zheng and
                  Weiqing Wang and
                  Jianfeng Qu and
                  Hongzhi Yin and
                  Wei Chen and
                  Lei Zhao},
	title = {{MMKGR:} Multi-hop Multi-modal Knowledge Graph Reasoning},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {96--109},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00015},
	doi = {10.1109/ICDE55515.2023.00015},
	timestamp = {Sun, 04 Aug 2024 19:37:46 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Zheng0QYCZ23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Multi-modal knowledge graphs (MKGs) include not only the relation triplets, but also related multi-modal auxiliary data (i.e., texts and images), which enhance the diversity of knowledge. However, the natural incompleteness has significantly hindered the applications of MKGs. To tackle the problem, existing studies employ the embedding-based reasoning models to infer the missing knowledge after fusing the multi-modal features. However, the reasoning performance of these methods is limited due to the following problems: (1) ineffective fusion of multi-modal auxiliary features; (2) lack of complex reasoning ability as well as inability to conduct the multi-hop reasoning which is able to infer more missing knowledge. To overcome these problems, we propose a novel model entitled MMKGR (Multi-hop Multi-modal Knowledge Graph Reasoning). Specifically, the model contains the following two components: (1) a unified gate-attention network which is designed to generate effective multi-modal complementary features through sufficient attention interaction and noise reduction; (2) a complementary feature-aware reinforcement learning method which is proposed to predict missing elements by performing the multi-hop reasoning process, based on the features obtained in component (1). The experimental results demonstrate that MMKGR outperforms the state-of-the-art approaches in the MKG reasoning task.}
}


@inproceedings{DBLP:conf/icde/FanHRGCZCJZW23,
	author = {Yuankai Fan and
                  Zhenying He and
                  Tonghui Ren and
                  Dianjun Guo and
                  Lin Chen and
                  Ruisi Zhu and
                  Guanduo Chen and
                  Yinan Jing and
                  Kai Zhang and
                  X. Sean Wang},
	title = {Gar: {A} Generate-and-Rank Approach for Natural Language to {SQL}
                  Translation},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {110--122},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00016},
	doi = {10.1109/ICDE55515.2023.00016},
	timestamp = {Sun, 06 Oct 2024 21:04:57 +0200},
	biburl = {https://dblp.org/rec/conf/icde/FanHRGCZCJZW23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A Natural Language (NL) Interface to Databases (NLIDB) aims to help end-users access databases. State-of-the-art approaches primarily construct language translation models to convert NL queries to SQL queries. While these models exhibit good performance on NLIDB benchmarks, the translation accuracy seems to have stalled at between 70%-75%, and most erroneous translations happen with complex queries that require an understanding of the structure and semantics specific to a database. This paper proposes a Generate-And-Rank approach called Gar. Gar assumes that a set of sample SQL queries is given to represent the possible user-intended queries to the database. In order to provide a broad coverage, akin to avoiding over-fitting, Gar extracts the basic components from the sample set to form the basic building blocks to generate a set of generalized SQL queries. By leveraging a simple rule-based SQL to NL technique, a less natural NL expression called a dialect expression for each sample and generalized SQL query is obtained. Finally, a learning-to-rank method is used for a given NL query to retrieve the best dialect expression and hence the resulting SQL query. Extensive experiments are performed to study Gar in comparison with other approaches. The results show that Gar achieves better performance on the NLIDB benchmarks, including in particular a 78.5% translation accuracy on the popular Spider benchmark, outperforming the best reported accuracy in the literature. An extension to Gar, called Gar-j, is further introduced to aid the translation by annotating join semantics in the sample queries. The experimental results show that Gar-j can further improve translation accuracy on queries with joins. Code for Gar can be found at https://github.com/Kaimary/GAR.}
}


@inproceedings{DBLP:conf/icde/Zheng00S23,
	author = {Zetao Zheng and
                  Jie Shao and
                  Jia Zhu and
                  Heng Tao Shen},
	title = {Relational Temporal Graph Convolutional Networks for Ranking-Based
                  Stock Prediction},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {123--136},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00017},
	doi = {10.1109/ICDE55515.2023.00017},
	timestamp = {Sun, 12 Nov 2023 02:08:09 +0100},
	biburl = {https://dblp.org/rec/conf/icde/Zheng00S23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Stock prediction is an attractive topic in fintech. However, traditional solutions for stock prediction have two drawbacks: (1) Some focus on the temporal patterns of stocks and model each stock as an independent individual but neglect their relations. Some models consider the relations among stocks, but work in a two-step format (i.e., capturing the temporal patterns first and then considering the relation dependency), which makes them complex and inefficient; (2) They model the stock prediction as a regression (predicting stock price) or classification task (predicting stock trend), which cannot optimize the target of investment, i.e., selecting the best stocks from the exchange market with the highest expected revenue in the future. To fully utilize the relations among stocks and achieve the highest revenue, a relation-temporal graph convolutional network (RT-GCN) is proposed. We first model the relations among stocks and their daily features into a relation-temporal graph. Then, we apply RT-GCN and three relation-aware strategies to realize the relation-temporal feature extraction for each stock. Finally, the features are fed for score calculation in a learning-to-rank way, and the stock with the highest score represents the highest investment revenue in the future. Extensive experiments demonstrate the effectiveness and efficiency of our method.}
}


@inproceedings{DBLP:conf/icde/Peng0Y0023,
	author = {You Peng and
                  Xuemin Lin and
                  Michael Yu and
                  Wenjie Zhang and
                  Lu Qin},
	title = {{TDB:} Breaking All Hop-Constrained Cycles in Billion-Scale Directed
                  Graphs},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {137--150},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00018},
	doi = {10.1109/ICDE55515.2023.00018},
	timestamp = {Sun, 04 Aug 2024 19:37:46 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Peng0Y0023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The feedback vertex set is one of 21 Np-complete problems proposed by Karp, aiming at breaking all cycles in a given graph. It could be used in numerous areas, e.g., program analysis, database systems. In reality, users are concerned the cycles with constraints, e.g., the cycles with a hop constraint. For instance, in the E-commerce networks, the fraud detection team would discard cycles with a high number of hops since they are less relevant and grow exponentially in size. Thus, it is quite reasonable to investigate the feedback vertex set problem with hop-constrained cycles, namely hop-constrained cycle cover problem. It is concerned with determining a vertex set that covers all hop-constrained cycles in a given directed graph. A common method is to use a bottom-up algorithm, where it iteratively selects cover vertices into the result set. Based on this paradigm, the existing works mainly focus on the vertices orders and several heuristic strategies. In this paper, a totally opposite cover process top-down is proposed and bounds are presented on it. Surprisingly, both theoretical and practical performance are improved. On the theoretical side, this work is the first to achieve O(k•n•m) time complexity, whereas the state-of-the-art method achieves time complexity of O(n k ). 1 On the practical level, the proposed algorithm, namely TDB++, outperforms the state-of-the-art by 2 to 3 orders of magnitude on average while preserving the minimal property. As a result, the method in this paper outperforms the state-of-the-art approaches in terms of both running time and theoretical time complexity. The hop-constrained cycle cover problem on billion-scale networks has been solved with a minimal 2 cover set for k > 3.}
}


@inproceedings{DBLP:conf/icde/YangQTKHX23,
	author = {Zhenkun Yang and
                  Chen Qian and
                  Xuwang Teng and
                  Fanyu Kong and
                  Fusheng Han and
                  Quanqing Xu},
	title = {{LCL:} {A} Lock Chain Length-based Distributed Algorithm for Deadlock
                  Detection and Resolution},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {151--163},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00019},
	doi = {10.1109/ICDE55515.2023.00019},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/YangQTKHX23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The problem of deadlock detection and resolution in database systems has been studied for decades. While it has long been a mature feature of classical centralized database systems for many years, its use in distributed database systems remains in its infancy. Don P. Mitchell and Michael J. Merritt (M&M) proposed a simple and fully distributed deadlock detection and resolution algorithm, but its assumption that each process waits on only one resource at a time prevents it from being generally applicable. Inspired by this algorithm, we design and implement LCL (Lock Chain Length), an elegant and generally applicable algorithm for resource deadlock detection and resolution in distributed environments without a restriction of the above kind. Our extensive emulation experiments show that the proposed approach LCL significantly outperforms the state-of-the-art competitor M&M. In addition, it has been applied to the OceanBase distributed relational database system, and our extensive experiments in OceanBase illustrate that LCL is also more efficient than M&M in deadlock detection and resolution.}
}


@inproceedings{DBLP:conf/icde/ChaoCK023,
	author = {Daren Chao and
                  Yueting Chen and
                  Nick Koudas and
                  Xiaohui Yu},
	title = {Track Merging for Effective Video Query Processing},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {164--176},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00020},
	doi = {10.1109/ICDE55515.2023.00020},
	timestamp = {Mon, 05 Feb 2024 20:31:13 +0100},
	biburl = {https://dblp.org/rec/conf/icde/ChaoCK023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Video analysis frameworks supporting declarative queries are actively researched in recent years. A major prerequisite in executing such queries is the ability to accurately extract metadata at the frame level utilizing various computer vision algorithms, including object tracking models. Tracking models are of profound importance as they establish unique identifiers for the objects across frames.Despite the maturity of tracking algorithms, they still face challenges (such as occlusions, object glaze etc.) which diminish their quality and accuracy. This gives rise to the track fragmentation problem in which a single track is fragmented into multiple smaller tracks. This impacts downstream temporal querying applications degrading query accuracy.In this paper, we propose an algorithm, TMerge for identifying and merging fragmented tracks that constitutes a pre-processing step during data ingestion for video query processing. The algorithm exploits the properties of the problem and utilizes a sampling methodology that significantly reduces the time required to pre-process and ingest the video sequence.We comprehensively describe and analyze our proposals utilizing real data sets and also present the results of a detailed experimental evaluation varying parameters of interest. We demonstrate performance savings of up to two orders of magnitude without loss in accuracy.}
}


@inproceedings{DBLP:conf/icde/Sun000C23,
	author = {Qingqiang Sun and
                  Xuemin Lin and
                  Ying Zhang and
                  Wenjie Zhang and
                  Chaoqi Chen},
	title = {Towards Higher-order Topological Consistency for Unsupervised Network
                  Alignment},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {177--190},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00021},
	doi = {10.1109/ICDE55515.2023.00021},
	timestamp = {Tue, 07 May 2024 20:05:36 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Sun000C23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Network alignment task, which aims to identify corresponding nodes in different networks, is of great significance for many subsequent applications. Without the need for labeled anchor links, unsupervised alignment methods have been attracting more and more attention. However, the topological consistency assumptions defined by existing methods are generally low-order and less accurate because only the edge-indiscriminative topological pattern is considered, which is especially risky in an unsupervised setting. To reposition the focus of the alignment process from low-order to higher-order topological consistency, in this paper, we propose a fully unsupervised network alignment framework named HTC. The proposed higher-order topological consistency is formulated based on edge orbits, which is merged into the information aggregation process of a graph convolutional network so that the alignment consistencies are transformed into the similarity of node embeddings. Furthermore, the encoder is trained to be multi-orbit-aware and then is refined to identify more trusted anchor links. Node correspondence is comprehensively evaluated by integrating all different orders of consistency. In addition to sound theoretical analysis, the superiority of the proposed method is also empirically demonstrated through extensive experimental evaluation. On three pairs of real-world datasets and two pairs of synthetic datasets, our HTC consistently outperforms a wide variety of unsupervised and supervised methods with the least or comparable time consumption. It also exhibits robustness to structural noise as a result of our multiorbit-aware training mechanism.}
}


@inproceedings{DBLP:conf/icde/MengGLTYZ23,
	author = {Ke Meng and
                  Liang Geng and
                  Xue Li and
                  Qian Tao and
                  Wenyuan Yu and
                  Jingren Zhou},
	title = {Efficient Multi-GPU Graph Processing with Remote Work Stealing},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {191--204},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00022},
	doi = {10.1109/ICDE55515.2023.00022},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/MengGLTYZ23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graph algorithms support a broad spectrum of big data applications. A typical approach to scale graph algorithms is to run in a distributed and parallel setting with multiple processing devices. The approach requires balanced and effective utilization of computation, memory, and communication resources across devices. To address the problem, a large number of studies have been conducted, such as graph partitioning and asynchronous computation. However, there are still many outstanding issues yet to be solved. For example, the workloads can be skewed differently across devices, and between iterations, even with the state-of-the-art graph partitioners. As the graph partitions are typically static, they fall short in capturing the dynamic characteristics with different algorithms, inputs, and progress, leading to poor utilization of resources. Recently, GPUs have been increasingly used to accelerate various graph algorithms. Their highly efficient interconnection technologies, such as NVLink, open new opportunities for us to achieve better resource utilization. In this paper, we analyze the dynamic load-imbalance (DLB) problem and the long tail (LT) problem in multi-GPUs and solve them by adaptive remote work stealing on-the-fly. We first introduce a frontier stealing algorithm to solve the DLB problem, then an ownership stealing algorithm to solve the LT problem. Based on these two algorithms, we developed Gum — a multi-GPU graph processing system with high device utilization. We evaluated Gum on four typical graph algorithms (BFS, WCC, PR, SSSP). The results show that Gum can run up to an order of magnitude faster than Gunrock and Groute, with fewer stragglers and less synchronization overhead.}
}


@inproceedings{DBLP:conf/icde/YeLD00W023,
	author = {Yuxiao Ye and
                  Chi Harold Liu and
                  Zipeng Dai and
                  Jianxin Zhao and
                  Ye Yuan and
                  Guoren Wang and
                  Jian Tang},
	title = {Exploring both Individuality and Cooperation for Air-Ground Spatial
                  Crowdsourcing by Multi-Agent Deep Reinforcement Learning},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {205--217},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00023},
	doi = {10.1109/ICDE55515.2023.00023},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/YeLD00W023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Spatial crowdsourcing (SC) has proven as a promising paradigm to employ human workers to collect data from diverse Point-of-Interests (PoIs) in a given area. Different from using human participants, we propose a novel air-ground SC scenario to fully take advantage of benefits brought by unmanned vehicles (UVs), including unmanned aerial vehicles (UAVs) with controllable high mobility and unmanned ground vehicles (UGVs) with abundant sensing resources. The objective is to maximize the amount of collected data, geographical fairness among all PoIs, and minimize the data loss and energy consumption, integrated as one single metric called "efficiency". We explicitly explore both individuality and cooperation natures of UAVs and UGVs by proposing a multi-agent deep reinforcement learning (MADRL) framework called "h/i-MADRL". Compatible with all multi-agent actor-critic methods, h/i-MADRL adds two novel plug-in modules: (a) h-CoPO, which models the cooperation preference among heterogeneous UAVs and UGVs; and (b) i-EOI, which extracts the UV’s individuality and encourages a better spatial division of work by adding intrinsic reward. Extensive experimental results on two real-world datasets on Purdue and NCSU campuses confirm that h/i-MADRL achieves a better exploration of both individuality and cooperation simultaneously, resulting in a better performance in terms of efficiency compared with five baselines.}
}


@inproceedings{DBLP:conf/icde/RenggliRK0023,
	author = {C{\'{e}}dric Renggli and
                  Luka Rimanic and
                  Luka Kolar and
                  Wentao Wu and
                  Ce Zhang},
	title = {Automatic Feasibility Study via Data Quality Analysis for {ML:} {A}
                  Case-Study on Label Noise},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {218--231},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00024},
	doi = {10.1109/ICDE55515.2023.00024},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/RenggliRK0023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In our experience of working with domain experts who are using today’s AutoML systems, a common problem we encountered is what we call "unrealistic expectations" – when users are facing a very challenging task with a noisy data acquisition process, while being expected to achieve startlingly high accuracy with machine learning (ML). Many of these are predestined to fail from the beginning. In traditional software engineering, this problem is addressed via a feasibility study, an indispensable step before developing any software system. In this paper, we present Snoopy, with the goal of supporting data scientists and machine learning engineers performing a systematic and theoretically founded feasibility study before building ML applications. We approach this problem by estimating the irreducible error of the underlying task, also known as the Bayes error rate (BER), which stems from data quality issues in datasets used to train or evaluate ML models. We design a practical Bayes error estimator that is compared against baseline feasibility study candidates on 6 datasets (with additional real and synthetic noise of different levels) in computer vision and natural language processing. Furthermore, by including our systematic feasibility study with additional signals into the iterative label cleaning process, we demonstrate in end-to-end experiments how users are able to save substantial labeling time and monetary efforts.}
}


@inproceedings{DBLP:conf/icde/LiM0LYQ0Z23,
	author = {Xue Li and
                  Ke Meng and
                  Lu Qin and
                  Longbin Lai and
                  Wenyuan Yu and
                  Zhengping Qian and
                  Xuemin Lin and
                  Jingren Zhou},
	title = {Flash: {A} Framework for Programming Distributed Graph Processing
                  Algorithms},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {232--244},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00025},
	doi = {10.1109/ICDE55515.2023.00025},
	timestamp = {Sun, 04 Aug 2024 19:37:45 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LiM0LYQ0Z23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As a result of decades of studies, a broad spectrum of graph algorithms have been developed for graph analytics, including clustering, centrality, traversal, matching, mining, etc. However, the majority of recent graph processing frameworks only focus on a handful of fix-point graph algorithms such as breadth-first search, PageRank, shortest path, etc. It leaves the distributed computation of a large variety of graph algorithms suffering from low efficiency, limited expressiveness, or high implementation complexity with existing frameworks.In this paper, we propose Flash, a framework for programming distributed graph processing algorithms, which achieves good expressiveness, productivity and efficiency at the same time. Thanks to its high-level interface, Flash allows users to implement complex distributed graph algorithms with high performance with only a few lines of code. We have implemented 72 graph algorithms for 49 different problems in Flash. In further evaluations, we found that Flash beats other state-of-the-art graph processing frameworks with the speedups of up to 2 orders of magnitudes while takes up to 92% less lines of code.}
}


@inproceedings{DBLP:conf/icde/QinL0WD23,
	author = {Hongchao Qin and
                  Rong{-}Hua Li and
                  Ye Yuan and
                  Guoren Wang and
                  Yongheng Dai},
	title = {Explainable Hyperlink Prediction: {A} Hypergraph Edit Distance-Based
                  Approach},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {245--257},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00386},
	doi = {10.1109/ICDE55515.2023.00386},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/QinL0WD23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Link prediction is a significant technique to generate latent interactions for the applications of recommendation in large graphs. As the interactions to be predicted often occur among more than two objects, we pay attention to solving the novel problem of predicting the interactions in hypergraphs. Previous studies focus mainly on predicting binary relations; most of those techniques cannot be directly applied to predict multiple relations. In this work, we study the problem of edge prediction in hypergraphs, where we use a concept, Hypergraph Edit Distance (abbreviated as HGED), to measure the similarity of two nodes. Based on HGED, we can record a Hypergraph Edit Path while searching the optimal edit distance, thus this path enables to explain why one node is similar to another node since their neighborhood structure can be edited to be isomorphic following the edit path. We first propose a general framework which can compute the edit distance of neighborhood structure for two nodes in hypergraph. To improve the efficiency, we propose a BFS search-based method with several tightening lower bounds and upper bounds estimation. To predict the multiple relations, we introduce a cluster model in which nodes in each hyperedge are restricted by the hypergraph edit distance. We further present an on-demand algorithm for computing HGED, which substantially avoids redundant computations. Finally, we conduct extensive empirical studies on real hypergraph datasets, and the results demonstrate the effectiveness, efficiency and scalability of our algorithms.}
}


@inproceedings{DBLP:conf/icde/Zhang0LHYLCS23,
	author = {Qianru Zhang and
                  Zheng Wang and
                  Cheng Long and
                  Chao Huang and
                  Siu{-}Ming Yiu and
                  Yiding Liu and
                  Gao Cong and
                  Jieming Shi},
	title = {Online Anomalous Subtrajectory Detection on Road Networks with Deep
                  Reinforcement Learning},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {246--258},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00026},
	doi = {10.1109/ICDE55515.2023.00026},
	timestamp = {Wed, 23 Oct 2024 08:55:27 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Zhang0LHYLCS23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Detecting anomalous trajectories has become an important task in many location-based applications. While many approaches have been proposed for this task, they suffer from various issues including (1) incapability of detecting anomalous subtrajectories, which are finer-grained anomalies in trajectory data, and/or (2) non-data driven, and/or (3) requirement of suﬃcient supervision labels which are costly to collect. In this paper, we propose a novel reinforcement learning based solution called RL4OASD, which avoids all aforementioned issues of existing approaches. RL4OASD involves two networks, one responsible for learning features of road networks and trajectories and the other responsible for detecting anomalous subtrajectories based on the learned features, and the two networks can be trained iteratively without labeled data. Extensive experiments are conducted on two real datasets, and the results show that our solution can significantly outperform the state-of-the-art methods (with 20-30% improvement) and is eﬃcient for online detection (it takes less than 0.1ms to process each newly generated data point).}
}


@inproceedings{DBLP:conf/icde/AmiriLPL0Z23,
	author = {Mohammad Javad Amiri and
                  Ziliang Lai and
                  Liana Patel and
                  Boon Thau Loo and
                  Eric Lo and
                  Wenchao Zhou},
	title = {Saguaro: An Edge Computing-Enabled Hierarchical Permissioned Blockchain},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {259--272},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00027},
	doi = {10.1109/ICDE55515.2023.00027},
	timestamp = {Tue, 07 May 2024 20:05:36 +0200},
	biburl = {https://dblp.org/rec/conf/icde/AmiriLPL0Z23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We present Saguaro, a permissioned blockchain system designed specifically for edge computing networks. Saguaro leverages the hierarchical structure of edge computing networks to reduce the overhead of wide-area communication by presenting several techniques. First, Saguaro proposes coordinator-based and optimistic protocols to process cross-domain transactions with low latency where the lowest common ancestor of the involved domains coordinates the protocol or detects inconsistency. Second, data are collected over hierarchy enabling higher-level domains to aggregate their sub-domain data. Finally, transactions initiated by mobile edge devices are processed without relying on high-level fog and cloud servers. Our experimental results across a wide range of workloads demonstrate the scalability of Saguaro in supporting a range of cross-domain and mobile transactions.}
}


@inproceedings{DBLP:conf/icde/Hu0O23,
	author = {Lin Hu and
                  Lei Zou and
                  M. Tamer {\"{O}}zsu},
	title = {{GAMMA:} {A} Graph Pattern Mining Framework for Large Graphs on {GPU}},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {273--286},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00028},
	doi = {10.1109/ICDE55515.2023.00028},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Hu0O23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graph pattern mining (GPM) is getting increasingly important recently. There are many parallel frameworks for GPM, many of which suffer from performance. GPU is a powerful option for graph processing, which has excellent potential for performance improvement; however, parallel GPM algorithms produce a large number of intermediate results, limiting GPM implementations on GPU.In this paper, we present GAMMA, an out-of-core GPM framework on GPU, and it makes full use of host memory to process large graphs. Specifically, GAMMA adopts a self-adaptive implicit host memory access manner to achieve high bandwidth, which is transparent to users. GAMMA provides flexible and effective interfaces for users to build their algorithms. We also propose several optimizations over primitives provided by GAMMA in the out-of-core GPU system. Experimental results show that GAMMA has scalability advantages in graph size over the state-of-the-art by an order of magnitude, and is also faster than existing GPM systems.}
}


@inproceedings{DBLP:conf/icde/LuoTF0Z23,
	author = {Wensheng Luo and
                  Zhuo Tang and
                  Yixiang Fang and
                  Chenhao Ma and
                  Xu Zhou},
	title = {Scalable Algorithms for Densest Subgraph Discovery},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {287--300},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00029},
	doi = {10.1109/ICDE55515.2023.00029},
	timestamp = {Sun, 26 Nov 2023 00:57:49 +0100},
	biburl = {https://dblp.org/rec/conf/icde/LuoTF0Z23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As a fundamental problem in graph data mining, Densest Subgraph Discovery (DSD) aims to find the subgraph with the highest density from a graph. It has been studied for several decades and found a large number of real-world applications, such as network community detection, regulatory motif discovery in DNA, graph index construction, and fake follower detection. Although there are many existing DSD algorithms, they are often not scalable or efficient to process large-scale graphs, since most of them are serial algorithms and can only leverage the computing resource of a single CPU core. To tackle these issues, in this paper we propose efficient parallel algorithms for solving the DSD problems on both undirected and directed graphs at scale. Our main idea is to use the k-cores (a kind of dense subgraph) to approximate the densest subgraph in the undirected graphs, and then propose efficient parallel algorithms for computing the cores by optimizing the iterative process and also reducing the number of iterations. We further extend this idea for directed graphs by introducing a novel concept, named w-induced subgraph, to avoid unnecessary enumerations of x or y when searching [x,y]-cores (a kind of directed dense subgraph to approximate the densest). To verify the scalability and efficiency of the proposed algorithms, we have conducted extensive experiments on 12 large real-world graphs, and four of them are billion-scale. The experimental results show that our proposed algorithms outperform the state-of-the-art algorithms on both undirected and directed graphs, in terms of scalability and efficiency.}
}


@inproceedings{DBLP:conf/icde/GuptaRLNS23,
	author = {Suyash Gupta and
                  Sajjad Rahnama and
                  Erik Linsenmayer and
                  Faisal Nawab and
                  Mohammad Sadoghi},
	title = {Reliable Transactions in Serverless-Edge Architecture},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {301--314},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00030},
	doi = {10.1109/ICDE55515.2023.00030},
	timestamp = {Tue, 01 Oct 2024 16:56:08 +0200},
	biburl = {https://dblp.org/rec/conf/icde/GuptaRLNS23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Modern edge applications demand novel solutions where edge applications do not have to rely on a single cloud provider (which cannot be in the vicinity of every edge device) or dedicated edge servers (which cannot scale as clouds) for processing compute-intensive tasks. A recent computing philosophy, Sky computing, proposes giving each user ability to select between available cloud providers.In this paper, we present our serverless-edge co-design, which extends the Sky computing vision. In our serverless-edge co-design, we expect edge devices to collaborate and spawn required number of serverless functions. This raises several key challenges: (1) how will this collaboration take place, (2) what if some edge devices are compromised, and (3) what if a selected cloud provider is malicious. Hence, we design ServerlessBFT, the first protocol to guarantee Byzantine fault-tolerant (Bft) transactional flow between edge devices and serverless functions. We present an exhaustive list of attacks and their solutions on our serverless-edge co-design. Further, we extensively benchmark our architecture on a variety of parameters.}
}


@inproceedings{DBLP:conf/icde/GeSCLGHC23,
	author = {Jiake Ge and
                  Boyu Shi and
                  Yanfeng Chai and
                  Yuanhui Luo and
                  Yunda Guo and
                  Yinxuan He and
                  Yunpeng Chai},
	title = {Cutting Learned Index into Pieces: An In-depth Inquiry into Updatable
                  Learned Indexes},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {315--327},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00031},
	doi = {10.1109/ICDE55515.2023.00031},
	timestamp = {Sat, 30 Sep 2023 09:44:50 +0200},
	biburl = {https://dblp.org/rec/conf/icde/GeSCLGHC23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Numerous high-performance updatable learned indexes have recently been designed to support the writing requirements in practical systems. Researchers have proposed various strategies to improve the availability of updatable learned indexes. However, it is unclear which strategy is more profitable. Therefore, we deconstruct the design of learned indexes into multiple dimensions and in-depth evaluate their impacts on the overall performance, respectively. Through the in-depth exploration of learned indexes, we reckon that the approximation algorithm is the most crucial design dimension for improving the performance of the learned indexes rather than the popular works that focus on the learned index structure. Moreover, this paper makes a comprehensive end-to-end evaluation based on a high-performance key-value store to answer people’s concerns about which learned index is better and whether learned indexes can outperform traditional ones. Finally, according to end-to-end and in-depth evaluation results, we give some constructive suggestions on designing a better learned index in these dimensions, especially how to design an excellent approximate algorithm to improve the lookup and insertion performance of learned indexes.}
}


@inproceedings{DBLP:conf/icde/LiZZLLXTQ23,
	author = {Youhuan Li and
                  Hangyu Zheng and
                  Lei Zou and
                  Xiaosen Li and
                  Ziming Li and
                  Pin Xiao and
                  Yangyu Tao and
                  Zheng Qin},
	title = {{VEND:} Vertex Encoding for Edge Nonexistence Determination},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {328--340},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00032},
	doi = {10.1109/ICDE55515.2023.00032},
	timestamp = {Wed, 14 Aug 2024 07:38:00 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LiZZLLXTQ23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We propose to design vertex encoding for determinations of no-result edge queries that should not be executed. Edge query is one of the core operations in mainstream graph databases, which is to retrieve the corresponding edges connecting two given vertices. Real-world graphs may be too large to be stored in memory and frequently accessing edge data on disk usually incurs much overhead. Average degree of real-world graph tends to be much less than the vertex number, and edges may not exist in most pairs of vertices. Efficiently avoiding no-result edge query executions will certainly improve performance of graph database. In this paper, we propose a new and important problem for determining no-result edge queries: vertex encoding for edge nonexistence determination (VEND, for short). We build a low dimensional vertex encoding for all vertices, and we can efficiently determine most vertex pairs that are connected by no edges just with their corresponding codes. With VEND, we can utilize in-memory efficient operations to filter no-result disk accesses for edge query. We also design maintenance algorithms for the proposed solution when data updates happen. Extensive experiments on many real-world datasets confirm the ability of our solution on determining a quite high proportion of non-edge vertex pairs, as well as the acceleration for edge queries.}
}


@inproceedings{DBLP:conf/icde/Luopan0ZLWC23,
	author = {Yaxin Luopan and
                  Rui Han and
                  Qinglong Zhang and
                  Chi Harold Liu and
                  Guoren Wang and
                  Lydia Y. Chen},
	title = {FedKNOW: Federated Continual Learning with Signature Task Knowledge
                  Integration at Edge},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {341--354},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00033},
	doi = {10.1109/ICDE55515.2023.00033},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Luopan0ZLWC23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Deep Neural Networks (DNNs) have been ubiquitously adopted in internet of things and are becoming an integral of our daily life. When tackling the evolving learning tasks in real world, such as classifying different types of objects, DNNs face the challenge to continually retrain themselves according to the tasks on different edge devices. Federated continual learning is a promising technique that offers partial solutions but yet to overcome the following difficulties: the significant accuracy loss due to the limited on-device processing, the negative knowledge transfer caused by the limited communication of non-IID data, and the limited scalability on the tasks and edge devices. In this paper, we propose FedKNOW, an accurate and scalable federated continual learning framework, via a novel concept of signature task knowledge. FedKNOW is a client side solution that continuously extracts and integrates the knowledge of signature tasks which are highly influenced by the current task. Each client of FedKNOW is composed of a knowledge extractor, a gradient restorer and, most importantly, a gradient integrator. Upon training for a new task, the gradient integrator ensures the prevention of catastrophic forgetting and mitigation of negative knowledge transfer by effectively combining signature tasks identified from the past local tasks and other clients’ current tasks through the global model. We implement FedKNOW in PyTorch and extensively evaluate it against state-of-the-art techniques using popular federated continual learning benchmarks. Extensive evaluation results on heterogeneous edge devices show that FedKNOW improves model accuracy by 63.24% without increasing model training time, reduces communication cost by 34.28%, and achieves more improvements under difficult scenarios such as large numbers of tasks or clients, and training different complex networks.}
}


@inproceedings{DBLP:conf/icde/MeiSFWFL23,
	author = {Yinan Mei and
                  Shaoxu Song and
                  Chenguang Fang and
                  Ziheng Wei and
                  Jingyun Fang and
                  Jiang Long},
	title = {Discovering Editing Rules by Deep Reinforcement Learning},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {355--367},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00034},
	doi = {10.1109/ICDE55515.2023.00034},
	timestamp = {Mon, 05 Feb 2024 20:31:13 +0100},
	biburl = {https://dblp.org/rec/conf/icde/MeiSFWFL23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Editing rules specify the conditions of applying high quality master data to repair low quality input data. Discovering editing rules, however, is challenging, since it considers not only the well curated master data but also the large-scale input data, an extremely large search space. A natural baseline, namely EnuMiner, costly enumerates the rules with possible conditions from both master and input data. Although several pruning strategies are enabled, the algorithm still takes a long time when the enumeration space is large. To avoid enumerating all candidate rules during mining, we argue to model the rule discovery process as a Markov Decision Process. Specifically, we discover editing rules by growing a rule tree where each node corresponds to a rule. The algorithm generates a new rule from the current node as a child node. We propose a reinforcement learning-based editing rule discovery algorithm, RLMiner, which trains an agent to wisely make decisions on branches when traversing the tree. Following the idea of evaluating rules, we design a reward function that is more in line with rule discovery scenarios and makes our algorithm perform effectively and efficiently. The experimental results show that our proposed RLMiner can mine high-utility editing rules like EnuMiner and scale well on the datasets with many attributes and large domains.}
}


@inproceedings{DBLP:conf/icde/LiXLHZ023,
	author = {Jiajia Li and
                  Xing Xiong and
                  Lei Li and
                  Dan He and
                  Chuanyu Zong and
                  Xiaofang Zhou},
	title = {Finding Top-k Optimal Routes with Collective Spatial Keywords on Road
                  Networks},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {368--380},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00035},
	doi = {10.1109/ICDE55515.2023.00035},
	timestamp = {Tue, 07 May 2024 20:05:36 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LiXLHZ023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As more detailed POI (Point of Interest) information has been incorporated into road network, routing has evolved from finding paths from one place to another, to satisfying users’ needs (keywords) along the trip. However, the existing solutions either only support one keyword per POI, or require a fixed visiting order, or only provide one option to choose from. Therefore, we study the top-k Optimal Routes with Collective Spatial Keywords (k-ORCSK) problem, which is the most general keyword-aware routing problem that supports multiple keywords, arbitrary orders, and top-k results. To solve this problem, we apply an enumeration framework and reduce the complexity by contracting non POI-related vertices and taking the keywords into account. After that, we propose a best-first path expansion method DA-CSK based on deviation to convert the enumeration paradigm from the distance-oriented to the keyword-oriented. Finally, several optimization techniques are provided to further improve the query efficiency. Extensive experiments conducted on multiple real-life road networks show that our method can provide higher quality results more efficiently.}
}


@inproceedings{DBLP:conf/icde/ZhangWYZCZ23,
	author = {Yufeng Zhang and
                  Weiqing Wang and
                  Hongzhi Yin and
                  Pengpeng Zhao and
                  Wei Chen and
                  Lei Zhao},
	title = {Disconnected Emerging Knowledge Graph Oriented Inductive Link Prediction},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {381--393},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00036},
	doi = {10.1109/ICDE55515.2023.00036},
	timestamp = {Sun, 06 Oct 2024 21:04:59 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhangWYZCZ23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Inductive link prediction (ILP) is to predict links for unseen entities in emerging knowledge graphs (KGs), considering the evolving nature of KGs. A more challenging scenario is that emerging KGs consist of only unseen entities without any edge connected to original KGs, called as disconnected emerging KGs (DEKGs). Existing studies for DEKGs only focus on predicting enclosing links, i.e., predicting links inside the emerging KG. The bridging links, which carry the evolutionary information from the original KG to DEKG, have not been investigated by previous work so far. To fill in the gap, we propose a novel model entitled DEKG-ILP (Disconnected Emerging Knowledge Graph Oriented Inductive Link Prediction) that consists of the following two components. (1) The module CLRM (Contrastive Learning-based Relation-specific Feature Modeling) is developed to extract global relation-based semantic features that are shared between original KGs and DEKGs with a novel sampling strategy. (2) The module GSM (GNN-based Subgraph Modeling) is proposed to extract the local subgraph topological information around each link in KGs. The extensive experiments conducted on several benchmark datasets demonstrate that DEKG-ILP has obvious performance improvements compared with state-of-the-art methods for both enclosing and bridging link prediction.}
}


@inproceedings{DBLP:conf/icde/ZhangLX023,
	author = {Jianing Zhang and
                  Zhaojing Luo and
                  Quanqing Xu and
                  Meihui Zhang},
	title = {{PA-FEAT:} Fast Feature Selection for Structured Data via Progress-Aware
                  Multi-Task Deep Reinforcement Learning},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {394--407},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00037},
	doi = {10.1109/ICDE55515.2023.00037},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhangLX023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Feature selection is an effective technique for structured data analytics, aiming to eliminate redundant features and irrelevant features for downstream tasks (e.g., classification). With the deepening of data-driven decision-making applications in various industries, the demand for real-time structured data analysis is constantly increasing. At this time, high requirements are placed on the time cost of feature selection. However, existing feature selection methods may easily fall into the dilemma of efficiency and effectiveness when faced with this situation due to the huge feature space. In this paper, we study a novel fast feature selection scenario, which is to generalize the knowledge of feature selection from historical structured data analytics tasks (seen tasks) and then quickly apply it to the process of feature selection for future structured data analytics tasks (unseen tasks). We propose a novel Progress-Aware multi-task deep reinforcement learning method for Fast fEAture selecTion (PA-FEAT), which makes full use of various progress-related information generated during the knowledge generalization process to achieve efficiency and effectiveness simultaneously. Extensive results on eight real-world datasets show that PA-FEAT consistently outperforms eight baselines in terms of efficiency and effectiveness.}
}


@inproceedings{DBLP:conf/icde/ZhangZLZD23,
	author = {Yu Zhang and
                  Feng Zhang and
                  Hourun Li and
                  Shuhao Zhang and
                  Xiaoyong Du},
	title = {CompressStreamDB: Fine-Grained Adaptive Stream Processing without
                  Decompression},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {408--422},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00038},
	doi = {10.1109/ICDE55515.2023.00038},
	timestamp = {Sun, 06 Oct 2024 21:04:59 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhangZLZD23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Stream processing prevails and SQL query on streams has become one of the most popular application scenarios. For example, in 2021, the global number of active IoT endpoints reaches 12.3 billion. Unfortunately, the increasing scale of data and strict user requests place much pressure on existing stream processing systems, requiring high processing throughput with low latency. To further improve the performance of current stream processing systems, we propose a compression-based stream processing engine, called CompressStreamDB, which enables adaptive fine-grained stream processing directly on compressed streams, without decompression. Particularly, CompressStreamDB involves eight compression methods targeting various data types in streams, and it also provides a cost model for dynamically selecting the appropriate compression methods. By exploring data redundancy among streams, CompressStreamDB not only saves space in data transmission between client and server, but also achieves high throughput with low latency in SQL query on stream processing. Our experimental results show that compared to the state-of-the-art stream processing system on uncompressed streams, CompressStreamDB achieves 3.24× throughput improvement and 66.0% lower latency on average. Besides, CompressStreamDB saves 66.8% space.}
}


@inproceedings{DBLP:conf/icde/LuoYLZ0023,
	author = {Qi Luo and
                  Dongxiao Yu and
                  Yu Liu and
                  Yanwei Zheng and
                  Xiuzhen Cheng and
                  Xuemin Lin},
	title = {Finer-Grained Engagement in Hypergraphs},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {423--435},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00039},
	doi = {10.1109/ICDE55515.2023.00039},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LuoYLZ0023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Vertex engagement has extraordinary significance for social resilience and network stability. There have been lots of existing work studying this fundamental problem in pairwise graphs, but in the more generalized hypergraphs, it has not been well explored, due to the great challenges of sparsity, complex connectivity and dynamicity of hypergraphs. In this work, we initialize the study of the vertex engagement problem in hypergraphs. Based on the observation that the engagement of vertices in hypergraphs needs to consider two critical parameters, group engagement and neighbor engagement, we propose a vertex engagement model integrating the merits of these two measures, called constrained core, to address the ineffectiveness and incomprehensiveness caused by just using a single engagement factor. By giving an algorithm for the constrained core decomposition, we show that the constrained core number of vertices can be computed in linear time. Furthermore, by showing a localized property of contained core, efficient maintenance algorithms for updating the constrained core number of vertices in dynamic hypergraphs are proposed, to avoid the large amount of redundant computations caused by the decomposition from scratch. Extensive experiments conducted on real-world hypergraphs well exhibit the effectiveness of our model and the efficiency of the proposed algorithms.}
}


@inproceedings{DBLP:conf/icde/HuangT23,
	author = {Qiang Huang and
                  Anthony K. H. Tung},
	title = {Lightweight-Yet-Efficient: Revitalizing Ball-Tree for Point-to-Hyperplane
                  Nearest Neighbor Search},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {436--449},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00040},
	doi = {10.1109/ICDE55515.2023.00040},
	timestamp = {Sat, 30 Sep 2023 09:44:50 +0200},
	biburl = {https://dblp.org/rec/conf/icde/HuangT23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Finding the nearest neighbor to a hyperplane (or Point-to-Hyperplane Nearest Neighbor Search, simply P2HNNS) is a new and challenging problem with applications in many research domains. While existing state-of-the-art hashing schemes (e.g., NH and FH) are able to achieve sublinear time complexity without the assumption of the data being in a unit hypersphere, they require an asymmetric transformation, which increases the data dimension from d to Ω(d 2 ). This leads to considerable overhead for indexing and incurs significant distortion errors.In this paper, we investigate a tree-based approach for solving P2HNNS using the classical Ball-Tree index. Compared to hashing-based methods, tree-based methods usually require roughly linear costs for construction, and they provide different kinds of approximations with excellent flexibility. A simple branch-and-bound algorithm with a novel lower bound is first developed on Ball-Tree for performing P2HNNS. Then, a new tree structure named BC-Tree, which maintains the Ball and Cone structures in the leaf nodes of Ball-Tree, is described together with two effective strategies, i.e., point-level pruning and collaborative inner product computing. BC-Tree inherits both the low construction cost and lightweight property of Ball-Tree while providing a similar or more efficient search. Experimental results over 16 real-world data sets show that Ball-Tree and BC-Tree are around 1.1~10× faster than NH and FH, and they can reduce the index size and indexing time by about 1~3 orders of magnitudes on average. The code is available at https://github.com/HuangQiang/BC-Tree.}
}


@inproceedings{DBLP:conf/icde/VeltriB0P23,
	author = {Enzo Veltri and
                  Gilbert Badaro and
                  Mohammed Saeed and
                  Paolo Papotti},
	title = {Data Ambiguity Profiling for the Generation of Training Examples},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {450--463},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00041},
	doi = {10.1109/ICDE55515.2023.00041},
	timestamp = {Sat, 30 Sep 2023 09:44:51 +0200},
	biburl = {https://dblp.org/rec/conf/icde/VeltriB0P23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Several applications, such as text-to-SQL and computational fact checking, exploit the relationship between relational data and natural language text. However, state of the art solutions simply fail in managing "data-ambiguity", i.e., the case when there are multiple interpretations of the relationship between text and data. Given the ambiguity in language, text can be mapped to different subsets of data, but existing training corpora only have examples in which every sentence/question is annotated precisely w.r.t. the relation. This unrealistic assumption leaves the target applications unable to handle ambiguous cases. To tackle this problem, we present an end-to-end solution that, given a table D, generates examples that consist of text, annotated with its data evidence, with factual ambiguities w.r.t. D. We formulate the problem of profiling relational tables to identify row and attribute data ambiguity. For the latter, we propose a deep learning method that identifies every pair of data ambiguous attributes and a label that describes both columns. Such metadata is then used to generate examples with data ambiguities for any input table. To enable scalability, we finally introduce a SQL approach that can generate millions of examples in seconds. We show the high accuracy of our solution in profiling relational tables and report on how our automatically generated examples lead to drastic quality improvements in two fact-checking applications, including a website with thousands of users, and in a text-to-SQL system.}
}


@inproceedings{DBLP:conf/icde/LangouriMCW23,
	author = {Morteza Alipour Langouri and
                  Adam Mansfield and
                  Fei Chiang and
                  Yinghui Wu},
	title = {Inconsistency Detection with Temporal Graph Functional Dependencies},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {464--476},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00042},
	doi = {10.1109/ICDE55515.2023.00042},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LangouriMCW23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Data dependencies have been extended to graphs to characterize topological and value constraints. Existing data dependencies are defined to capture inconsistencies in static graphs. Nevertheless, inconsistencies may occur over evolving graphs and only for certain time periods. The need for capturing such inconsistencies in temporal graphs is evident in anomaly detection and predictive dynamic network analysis. This paper introduces a class of data dependencies called Temporal Graph Functional Dependencies (TGFDs). TGFDs generalize functional dependencies to temporal graphs as a sequence of graph snapshots that are induced by time intervals, and enforce both topological constraints and attribute value dependencies that must be satisfied by these snapshots. (1) We establish the complexity results for the satisfiability and implication problems of TGFDs. (2) We propose a sound and complete axiomatization system for TGFDs. (3) We also present efficient parallel algorithms to detect inconsistencies in temporal graphs as violations of TGFDs. The algorithm exploits data and temporal locality induced by time intervals, and uses incremental pattern matching and load balancing strategies to enable feasible error detection in large temporal graphs. Using real datasets, we experimentally verify that our algorithms achieve lower runtimes compared to existing baselines, while improving the accuracy over error detection using existing graph data constraints, e.g., GFDs and GTARs with 55% and 74% gain in F 1 -score, respectively.}
}


@inproceedings{DBLP:conf/icde/Tao0L23,
	author = {Yuechen Tao and
                  Bo Li and
                  Baochun Li},
	title = {On Sharding Across Heterogeneous Blockchains},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {477--489},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00043},
	doi = {10.1109/ICDE55515.2023.00043},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Tao0L23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Heterogeneous blockchains are expected to be increasingly deployed in real-world applications, making cross-chain transaction confirmations essential. Currently, confirmations for cross-chain transactions are usually accomplished through an intermediary, such as a relay chain, which may well become a performance bottleneck. Sharding has been widely used to improve the blockchain throughput through parallel transaction validations by distributing transactions into multiple sub-communities, Yet, when sharding technique is directly applied over a relay chain, it results in an excessive number of cross-shard transactions, offsetting the throughput improvement.In this paper, we propose Sliver, a novel transaction distribution mechanism specifically designed for improving the relay chain throughput for the first time. We first capture and leverage the unique characterization of transaction dependency on the relay chain, and place those transactions with dependency into one shard. Consequently, this completely eliminates cross-shard transactions. However, due to the varying nature of transaction dependency, such a transaction placement can lead to a highly skewed distribution in terms of the number of transactions (i.e., shard size) to be validated in different shards, which negatively affects the relay chain throughput. We proceed to formulate the transaction distribution as an integer optimization problem with a lexicographical minimization objective for achieving a balanced shard size. While such a problem is proved to be NP-hard, we are able to mathematically transform it to a linear programming (LP) formulation by incorporating several unique properties in the integer optimization formulation, which can then be efficiently solved using off-the-shelf LP solvers. Theoretical and experimental analyses show that Sliver is extremely efficient in solving the assignment problem and the throughput can be 5 × that of the state-of-the-art under various configurations.}
}


@inproceedings{DBLP:conf/icde/AmiriSMAA23,
	author = {Mohammad Javad Amiri and
                  Daniel Shu and
                  Sujaya Maiyya and
                  Divyakant Agrawal and
                  Amr El Abbadi},
	title = {Ziziphus: Scalable Data Management Across Byzantine Edge Servers},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {490--502},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00044},
	doi = {10.1109/ICDE55515.2023.00044},
	timestamp = {Tue, 07 May 2024 20:05:36 +0200},
	biburl = {https://dblp.org/rec/conf/icde/AmiriSMAA23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Edge computing while bringing computation and data closer to users in order to improve response time, distributes edge servers in wide area networks resulting in increased communication latency between the servers. Synchronizing globally distributed edge servers, especially in the presence of Byzantine servers, becomes costly due to the high communication complexity of Byzantine fault-tolerant consensus protocols. In this paper, we present Ziziphus, a geo-distributed system that partitions edge servers into fault-tolerant zones where each zone processes transactions initiated by nearby clients locally. Global synchronization among zones is required only in special situations, e.g., migration of clients from one zone to another. On the one hand, the two-level architecture of Ziziphus confines the malicious behavior of nodes within zones requiring a much cheaper protocol at the top level for global synchronization. On the other hand, Ziziphus processes local transactions within zones by edge servers closer to clients resulting in enhanced performance. Ziziphus further introduces zone clusters to enhance scalability where instead of running global synchronization among all zones, only zones of a single cluster are synchronized.}
}


@inproceedings{DBLP:conf/icde/GongZGF23,
	author = {Yue Gong and
                  Zhiru Zhu and
                  Sainyam Galhotra and
                  Raul Castro Fernandez},
	title = {Ver: View Discovery in the Wild},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {503--516},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00045},
	doi = {10.1109/ICDE55515.2023.00045},
	timestamp = {Sun, 04 Aug 2024 19:37:45 +0200},
	biburl = {https://dblp.org/rec/conf/icde/GongZGF23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We present Ver 1 , a data discovery system that identifies project-join views over large repositories of tables that do not contain join path information, and even when input queries are inaccurate. Ver implements a reference architecture to solve both the technical (scale and search) and human (semantic ambiguity, navigating a large number of results) problems of view discovery. We demonstrate users find the view they want when using Ver with a user study and we demonstrate its performance with large-scale end-to-end experiments on real-world datasets containing tens of millions of join paths.}
}


@inproceedings{DBLP:conf/icde/FangQL0XZ023,
	author = {Yuchen Fang and
                  Yanjun Qin and
                  Haiyong Luo and
                  Fang Zhao and
                  Bingbing Xu and
                  Liang Zeng and
                  Chenxing Wang},
	title = {When Spatio-Temporal Meet Wavelets: Disentangled Traffic Forecasting
                  via Efficient Spectral Graph Attention Networks},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {517--529},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00046},
	doi = {10.1109/ICDE55515.2023.00046},
	timestamp = {Wed, 04 Sep 2024 08:13:03 +0200},
	biburl = {https://dblp.org/rec/conf/icde/FangQL0XZ023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Traffic forecasting is crucial for public safety and resource optimization, yet is very challenging due to the temporal changes and the dynamic spatial correlations of the traffic data. To capture these intricate dependencies, spatio-temporal networks, such as recurrent neural networks with graph convolution networks, graph convolution networks with temporal convolution networks, and temporal attention networks with full graph attention networks, are applied. However, previous spatio-temporal networks are based on end-to-end training and thus fail to handle the distribution shift in the non-stationary traffic time series. On the other hand, the efficient and effective algorithm for modeling spatial correlations is still lacking in prior networks.In this paper, rather than proposing yet another end-to-end model, we aim to provide a novel disentangle-fusion framework STWave to mitigate the distribution shift issue. The framework first decouples the complex traffic data into stable trends and fluctuating events, followed by a dual-channel spatio-temporal network to model trends and events, respectively. Finally, reasonable future traffic can be predicted through the fusion of trends and events. Besides, we incorporate a novel query sampling strategy and graph wavelet-based graph positional encoding into the full graph attention network to efficiently and effectively model dynamic spatial correlations. Extensive experiments on six traffic datasets show the superiority of our approach, i.e., the higher forecasting accuracy with lower computational cost.}
}


@inproceedings{DBLP:conf/icde/GaiNB0W23,
	author = {Fangyu Gai and
                  Jianyu Niu and
                  Ivan Beschastnikh and
                  Chen Feng and
                  Sheng Wang},
	title = {Scaling Blockchain Consensus via a Robust Shared Mempool},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {530--543},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00047},
	doi = {10.1109/ICDE55515.2023.00047},
	timestamp = {Sun, 06 Aug 2023 16:12:39 +0200},
	biburl = {https://dblp.org/rec/conf/icde/GaiNB0W23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Leader-based Byzantine fault-tolerant (BFT) consensus protocols used by permissioned blockchains have limited scalability and robustness. To alleviate the leader bottleneck in BFT consensus, we introduce Stratus, a robust shared mempool protocol that decouples transaction distribution from consensus. Our idea is to have replicas disseminate transactions in a distributed manner and have the leader only propose transaction ids. Stratus uses a provably available broadcast (PAB) protocol to ensure the availability of the referenced transactions. To deal with unbalanced load across replicas, Stratus adopts a distributed load balancing protocol.We implemented and evaluated Stratus by integrating it with state-of-the-art BFT-based blockchain protocols. Our evaluation of these protocols in both LAN and WAN settings shows that Stratus-based protocols achieve 5× to 20× higher throughput than their native counterparts in a network with hundreds of replicas. In addition, the performance of Stratus degrades gracefully in the presence of network asynchrony, Byzantine attackers, and unbalanced workloads.}
}


@inproceedings{DBLP:conf/icde/SahaK0L23,
	author = {Arkaprava Saha and
                  Xiangyu Ke and
                  Arijit Khan and
                  Laks V. S. Lakshmanan},
	title = {Voting-based Opinion Maximization},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {544--557},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00048},
	doi = {10.1109/ICDE55515.2023.00048},
	timestamp = {Tue, 07 May 2024 20:05:37 +0200},
	biburl = {https://dblp.org/rec/conf/icde/SahaK0L23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We investigate the novel problem of voting-based opinion maximization in a social network: Find a given number of seed nodes for a target campaigner, in the presence of other competing campaigns, so as to maximize a voting-based score for the target campaigner at a given time horizon.The bulk of the influence maximization literature assumes that social network users can switch between only two discrete states, inactive and active, and the choice to switch is frozen upon one-time activation. In reality, even when having a preferred opinion, a user may not completely despise the other opinions, and the preference level may vary over time due to social influence. To this end, we employ models rooted in opinion formation and diffusion, and use several voting-based scores to determine a user’s vote for each of the multiple campaigners at a given time horizon.Our problem is NP-hard and non-submodular for various scores. We design greedy seed selection algorithms with quality guarantees for our scoring functions via sandwich approximation. To improve the efficiency, we develop random walk and sketch-based opinion computation, with quality guarantees. Empirical results validate our effectiveness, efficiency, and scalability.}
}


@inproceedings{DBLP:conf/icde/Wang0ZC023,
	author = {Qiange Wang and
                  Xin Ai and
                  Yanfeng Zhang and
                  Jing Chen and
                  Ge Yu},
	title = {HyTGraph: GPU-Accelerated Graph Processing with Hybrid Transfer Management},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {558--571},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00049},
	doi = {10.1109/ICDE55515.2023.00049},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Wang0ZC023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Processing large graphs with memory-limited GPU needs to resolve issues of host-GPU data transfer, which is a key performance bottleneck. Existing GPU-accelerated graph processing frameworks reduce the data transfers by managing the active subgraph transfer at runtime. Some frameworks adopt explicit transfer management approaches based on explicit memory copy with filter or compaction. In contrast, others adopt implicit transfer management approaches based on on-demand access with zero-copy or unified-memory. Having made intensive analysis, we find that as the active vertices evolve, the performance of the two approaches varies in different workloads. Due to heavy redundant data transfers, high CPU compaction overhead, or low bandwidth utilization, adopting a single approach often results in suboptimal performance.In this work, we propose a hybrid transfer management approach to take the merits of both the two approaches at runtime, with an objective to achieve the shortest execution time in each iteration. Based on the hybrid approach, we present HyTGraph, a GPU-accelerated graph processing framework, which is empowered by a set of effective task scheduling optimizations to improve the performance. Our experimental results on real-world and synthesized graphs demonstrate that HyTGraph achieves up to 10.27X speedup over existing GPU-accelerated graph processing systems including Grus, Subway, and EMOGI.}
}


@inproceedings{DBLP:conf/icde/0002SK23,
	author = {Xi Liang and
                  Stavros Sintos and
                  Sanjay Krishnan},
	title = {JanusAQP: Efficient Partition Tree Maintenance for Dynamic Approximate
                  Query Processing},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {572--584},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00050},
	doi = {10.1109/ICDE55515.2023.00050},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/0002SK23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Approximate query processing over dynamic databases, i.e., under insertions/deletions, has applications ranging from high-frequency trading to internet-of-things analytics. We present JanusAQP, a new dynamic AQP system, which supports SUM, COUNT, AVG, MIN, and MAX queries under insertions and deletions to the dataset. JanusAQP extends static partition tree synopses, which are hierarchical aggregations of datasets, into the dynamic setting. This paper contributes new methods for: (1) efficient initialization of the data synopsis in the presence of incoming data, (2) maintenance of the data synopsis under insertions/deletions, and (3) re-optimization of the partitioning to reduce the approximation error. JanusAQP reduces the error of a state-of-the-art baseline by more than 60% using only 10% storage cost. JanusAQP can process more than 100K updates per second in a single node setting and keep the query latency at a millisecond level.}
}


@inproceedings{DBLP:conf/icde/0010LQD0W23,
	author = {Qi Zhang and
                  Rong{-}Hua Li and
                  Hongchao Qin and
                  Yongheng Dai and
                  Ye Yuan and
                  Guoren Wang},
	title = {Neighborhood Skyline on Graphs: Concepts, Algorithms and Applications},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {585--598},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00051},
	doi = {10.1109/ICDE55515.2023.00051},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/0010LQD0W23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Neighborhood inclusion, representing that all the neighbors of a vertex are also adjacent to another vertex, has been recognized as an important relationship between two vertices in a graph. We call a vertex u dominating v, denoted by v ≤ u, if N(v) \\subseteq N(u) \\cup \\{ u\\} holds, where (v) denotes the set of neighbors of v. Based on such a domination relationship, we propose a concept called neighborhood skyline. The neighborhood skyline is a set of vertices in which any vertex u cannot be dominated by the other nodes in the graph G, i.e., \\nexists v \\in G,u \\leq v. We study a new problem, called neighborhood skyline computation, and develop a filter-refine search framework, FilterRefineSky, to efficiently find the neighborhood skyline by searching the vertices in a small candidate set instead of in the entire graph. We show that our neighborhood skyline technique can be used to speed up the computation of two well-studied group centrality maximization problems and the maximum clique search problem in graphs. Extensive experimental studies conducted on five large real-life datasets demonstrate the effectiveness of neighborhood skyline, and the efficiency and scalability of our algorithms.}
}


@inproceedings{DBLP:conf/icde/ZhangG0YL23,
	author = {Qianzhen Zhang and
                  Deke Guo and
                  Xiang Zhao and
                  Long Yuan and
                  Lailong Luo},
	title = {Discovering Frequency Bursting Patterns in Temporal Graphs},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {599--611},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00052},
	doi = {10.1109/ICDE55515.2023.00052},
	timestamp = {Sun, 04 Aug 2024 19:37:46 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhangG0YL23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A frequency bursting pattern (FBP) in temporal graphs represents some interaction behavior that accumulates its frequency at the fastest rate. Mining FBPs is essential to early warning of emergencies. However, existing studies on frequency-based pattern mining in graphs do not consider the temporal information and bursting features of a subgraph pattern. As a result, they may not provide effective and efficient mining algorithms for FBP discovery. In this paper, we study the problem of discovering top-k FBPs in temporal graphs. We present a novel model, referred to as maximal (m, θ)-bursting pattern, to describe FBPs in a temporal graph, which is a subgraph with a size larger than m that accumulates its frequency at the fastest rate during a time interval of length no less than θ. A naive solution for top-k FBPs discovery is to use the best-first search algorithm, where the burstiness threshold changes as more patterns are mined. However, this method will result in huge search space since we need to check every possible time interval for a candidate pattern in the temporal graph. To tackle this problem, we devise an online top-k framework in which k candidate results are maintained from the initial timestamp to the end in the temporal graph. Under the new framework, we further conceive two optimization strategies by exploiting incremental subgraph matching and Evolutionary Game Theory to boost the performance. Extensive experiment results on five real temporal graphs show that our algorithm has higher efficiency, effectiveness and scalability.}
}


@inproceedings{DBLP:conf/icde/KuoCK23,
	author = {Ai{-}Te Kuo and
                  Haiquan Chen and
                  Wei{-}Shinn Ku},
	title = {BERT-Trip: Effective and Scalable Trip Representation using Attentive
                  Contrast Learning},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {612--623},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00053},
	doi = {10.1109/ICDE55515.2023.00053},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/KuoCK23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Trip recommendation has drawn considerable attention over the past decade. In trip recommendation, a sequence of point-of-interests (POIs) are recommended for a given query which includes an origin and a destination. Recently the emergence of the attention mechanism and many attention-incorporated models have achieved great success in various fields. Trip recommendation problems demonstrate similar characteristics that can potentially benefit from the attention mechanism. However, applying the attention mechanism for trip recommendation is non-trivial. We are motivated to answer the following two research questions. (1) How can we learn trip representation effectively without labels? Unlike most of the natural language processing tasks, there are no ground-truth labels available for trip recommendation. (2) How can we learn trip representation effectively without handcrafting negative samples? In this paper, we cast the trip representation learning into a natural language processing (NLP) task. We propose BERT-Trip, a self-supervised contrast learning framework, to learn effective and scalable trip representation in support of time-sensitive and user-personalized trip recommendation. BERT-Trip builds on a Siamese network to maximize the similarity between the augmentations of trips with BERT as the backbone encoder. We utilize the masking strategy for generating augmented views (positive sample pairs) of trips in the Siamese network and employ the stop-gradient on one side of the Siamese network to eliminate the need to use any negative sample pairs or momentum encoders. Extensive experiments on real-world datasets demonstrate that BERT-Trip consistently outperformed the state-of-the-art methods in terms of all effectiveness metrics. Compared with the state-of-the-art methods, BERT-Trip is able to yield up to 24 percent and 40 percent increases in F 1 score on the Flickr and the Weeplaces datasets, respectively. A rigorous performance evaluation of BERT-Trip on scalability up to 12800 POIs is also provided.}
}


@inproceedings{DBLP:conf/icde/AnirbanW023,
	author = {Shikha Anirban and
                  Junhu Wang and
                  Md. Saiful Islam},
	title = {Experimental Evaluation of Indexing Techniques for Shortest Distance
                  Queries on Road Networks},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {624--636},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00054},
	doi = {10.1109/ICDE55515.2023.00054},
	timestamp = {Tue, 07 May 2024 20:05:36 +0200},
	biburl = {https://dblp.org/rec/conf/icde/AnirbanW023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Shortest distance calculation between two locations in road networks is an important problem and has many applications. This problem has been widely researched for over two decades. Several advanced algorithms have been developed since the last formal evaluation. This paper provides a comprehensive experimental evaluation of these state-of-the-art algorithms. Our evaluation provides several important insights on the advantage/disadvantages of these algorithms, and it enables us to recommend the most suitable algorithm for some application scenarios. We are able to confirm some previous experimental results and raise questions on some others. We also evaluate the effect of a simple path compression technique on these algorithms.}
}


@inproceedings{DBLP:conf/icde/SunLW23,
	author = {Zewen Sun and
                  Zhifang Li and
                  Chuliang Weng},
	title = {Co-Utilizing {SIMD} and Scalar to Accelerate the Data Analytics Workloads},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {637--649},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00387},
	doi = {10.1109/ICDE55515.2023.00387},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/SunLW23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The increasing capacity and reducing cost of the main memory made in-memory data analytics systems widely deployed as they could provide higher throughput and lower latency. Since the data resides in memory, computational throughput becomes a crucial factor in the performance of these systems rather than disk accesses. Single instruction multiple data (SIMD) is an effective mechanism to improve computational performance, which has been well studied to accelerate data analytics systems. However, the state-of-the-art methods focus on using SIMD more efficiently while neglecting scalar execution units.In this paper, we present the hybrid execution framework (HEF) to co-utilize SIMD and scalar execution units for the data analytics workload. We also extend the concept of pack to eliminate the data dependency between adjacent instructions, achieving shorter instruction execution intervals. Experimental results show that the hybrid execution achieves up to 2.38× and 1.45× better performance compared with the purely scalar and SIMD implementation on the star schema benchmark (SSB) queries, respectively. Besides, HEF performs better than the state-of-the-art system Voila for a majority of queries in SSB under all data scales.}
}


@inproceedings{DBLP:conf/icde/KimuraHKKG23,
	author = {Genki Kimura and
                  Yuto Hayamizu and
                  Rage Uday Kiran and
                  Masaru Kitsuregawa and
                  Kazuo Goda},
	title = {Efficient Parallel Mining of High-utility Itemsets on Multicore Processors},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {638--652},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00388},
	doi = {10.1109/ICDE55515.2023.00388},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/KimuraHKKG23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {High-utility itemset mining is a generalized problem of well-known frequent itemset mining, which considers not only the frequency of occurrence but also quantitative criteria such as unit profit. Because it can be applied to a wider spectrum of knowledge discovery work, various algorithmic improvements have been studied over the past two decades. On the other hand, limited efforts have been made to take advantage of hardware performance despite significant changes in hardware trends. This paper presents a novel parallelization method called DPHIM (Dynamic Parallelization for High-utility Itemset Mining). DPHIM dynamically decomposes the execution of high-utility itemset mining into subtasks in order to leverage logical data parallelism, and carefully assigns the subtasks and their related data to physical resources such as processing cores and nearby memory in the NUMA-aware manner. Our intensive and extensive experiments have confirmed that DPHIM performs up to 65.23 times faster than the fully-tuned serial execution, up to 23.54 times faster than static partitioning, and up to 2.51 times faster than the best case of alternative dynamic parallel executions for a variety of datasets and configurations on DRAM. As well, we have demonstrated that DPHIM effectively worked on persistent memory; it offered similar thread scalability trends and was 1.07 to 2.43 times slower on persistent memory.}
}


@inproceedings{DBLP:conf/icde/0006XSL0P023,
	author = {Jiayao Zhang and
                  Haocheng Xia and
                  Qiheng Sun and
                  Jinfei Liu and
                  Li Xiong and
                  Jian Pei and
                  Kui Ren},
	title = {Dynamic Shapley Value Computation},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {639--652},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00055},
	doi = {10.1109/ICDE55515.2023.00055},
	timestamp = {Sat, 30 Sep 2023 09:44:49 +0200},
	biburl = {https://dblp.org/rec/conf/icde/0006XSL0P023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the prevalence of data-driven research, data valuation has attracted attention from the computer science field. How to appraise a single datum becomes an imperative problem, especially in the context of machine learning. Shapley value is widely used to fairly measure the contribution of data points in machine learning since it is the unique definition that satisfies all four desired properties: balance, symmetry, additivity, and zero element. However, computing Shapley value is known to be a #P-hard problem. As data is subject to changes, dynamic data exists pervasively in real-world scenarios. Pricing such dynamic data is more challenging due to the prohibitively expensive cost of recalculation from scratch. In this paper, we study the problem of Dynamic Shapley Value Computation, which updates Shapley value when dynamically adding/deleting data points. For adding data points, to prune unnecessary computation of overlapping model utilities, we propose the pivot-based algorithm that can reduce half computation time in general. We also propose the delta-based algorithm to capture Shapley value changes, which requires a smaller sample size to converge. For deleting data points, we present the YN-NN algorithm that derives the new Shapley value from the data structure of precomputed model utilities in an efficient way. Based on Shapley value changes, we give another version of the delta-based algorithm for deleting data points. Besides, we propose heuristic algorithms to draw on experimental observations for both adding and deleting data points. Extensive experimental results demonstrate the efficiency and effectiveness of our proposed algorithms.}
}


@inproceedings{DBLP:conf/icde/0001FSMAN23,
	author = {George Papadakis and
                  Marco Fisichella and
                  Franziska Schoger and
                  George Mandilaras and
                  Nikolaus Augsten and
                  Wolfgang Nejdl},
	title = {Benchmarking Filtering Techniques for Entity Resolution},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {653--666},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00389},
	doi = {10.1109/ICDE55515.2023.00389},
	timestamp = {Mon, 05 Feb 2024 20:31:11 +0100},
	biburl = {https://dblp.org/rec/conf/icde/0001FSMAN23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Entity Resolution is the task of identifying pairs of entity profiles that represent the same real-world object. To avoid checking a quadratic number of entity pairs, various filtering techniques have been proposed that fall into two main categories: (i) blocking workflows group together entity profiles with identical or similar signatures, and (ii) nearest-neighbor methods convert all entity profiles into vectors and identify the closest ones to every query entity. Unfortunately, the main techniques from these two categories have rarely been compared in the literature and, thus, their relative performance is unknown. We perform the first systematic experimental study that investigates the relative performance of the main representatives per category over numerous established datasets. Comparing techniques from different categories turns out to be a non-trivial task due to the various configuration parameters that are hard to fine-tune, but have a significant impact on performance. We consider a plethora of parameter configurations, optimizing each technique with respect to recall and precision targets. Both schema-agnostic and schema-based settings are evaluated. The experimental results provide novel insights into the effectiveness, the time efficiency and the scalability of the considered techniques.}
}


@inproceedings{DBLP:conf/icde/FanXJLTWLT0A23,
	author = {Wenqi Fan and
                  Han Xu and
                  Wei Jin and
                  Xiaorui Liu and
                  Xianfeng Tang and
                  Suhang Wang and
                  Qing Li and
                  Jiliang Tang and
                  Jianping Wang and
                  Charu C. Aggarwal},
	title = {Jointly Attacking Graph Neural Network and its Explanations},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {654--667},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00056},
	doi = {10.1109/ICDE55515.2023.00056},
	timestamp = {Sun, 04 Aug 2024 19:37:46 +0200},
	biburl = {https://dblp.org/rec/conf/icde/FanXJLTWLT0A23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graph Neural Networks (GNNs) have boosted the performance for many graph-related tasks. Despite the great success, recent studies have shown that GNNs are still vulnerable to adversarial attacks, where adversaries can mislead the GNNs' prediction by modifying graphs. On the other hand, the explanation of GNNs (GnnExplainer for short) provides a better understanding of a trained GNN model by generating a small subgraph and features that are most influential for its prediction. In this paper, we first perform empirical studies to validate that GnnExplainer can act as an inspection tool and have the potential to detect the adversarial perturbations for graphs. This finding motivates us to further investigate a new problem: Whether a graph neural network and its explanations can be jointly attacked by modifying graphs with malicious desires? It is challenging to answer this question since the goals of adversarial attack and bypassing the GnnExplainer essentially contradict with each other. In this work, we give a confirmative answer for this question by proposing a novel attack framework (GEAttack) for graphs, which can attack both a GNN model and its explanations by exploiting their vulnerabilities simultaneously. To the best of our knowledge, this is the very first effort to attack both GNNs and explanations on graph-structured data for the trustworthiness of GNNs. Comprehensive experiments on various real-world datasets demonstrate the effectiveness of the proposed method.}
}


@inproceedings{DBLP:conf/icde/LiangCWFWJHCWL23,
	author = {Jie Liang and
                  Yaoguang Chen and
                  Zhiyong Wu and
                  Jingzhou Fu and
                  Mingzhe Wang and
                  Yu Jiang and
                  Xiangdong Huang and
                  Ting Chen and
                  Jiashui Wang and
                  Jiajia Li},
	title = {Sequence-Oriented {DBMS} Fuzzing},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {668--681},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00057},
	doi = {10.1109/ICDE55515.2023.00057},
	timestamp = {Wed, 11 Sep 2024 17:25:15 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LiangCWFWJHCWL23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The SQL specification consists of hundreds of statement types, which leads to difficulties in DBMS fuzzing: state-of-the-art works generally reuse the statements of predefined types; the limited types cannot cover the full input space and test the corresponding logic consequently. In this paper, we propose Lego, a fuzzer to generate SQL sequences with abundant types to improve DBMS fuzzing coverage. The key idea of sequence generation is type-affinity, which indicates the meaningful occurrence of SQL type pairs (e.g., INSERT and SELECT). During each fuzzing iteration, Lego first proactively explores SQL statements of different types and analyzes affinities with coverage feedback. Next, when a new affinity is discovered, Lego synthesizes new SQL sequences containing the types progressively.We evaluate Lego on PostgreSQL, MySQL, MariaDB, and Comdb2 against SQLancer, SQLsmith, and Squirrel. The sequence-oriented fuzzing helps Lego outperform other fuzzers on branch coverage by 44%–198%. More importantly, in the continuous fuzzing, Lego has discovered 102 new vulnerabilities confirmed by the corresponding vendors, including 6 bugs in PostgreSQL, 21 bugs in MySQL, 42 bugs in MariaDB, and 33 bugs in Comdb2. Among them, 22 CVEs have been assigned due to their severe security influences.}
}


@inproceedings{DBLP:conf/icde/Yang023,
	author = {Carl Yang and
                  Jiawei Han},
	title = {Revisiting Citation Prediction with Cluster-Aware Text-Enhanced Heterogeneous
                  Graph Neural Networks},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {682--695},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00058},
	doi = {10.1109/ICDE55515.2023.00058},
	timestamp = {Thu, 15 Feb 2024 16:22:21 +0100},
	biburl = {https://dblp.org/rec/conf/icde/Yang023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Numerous papers get published all the time. However, some papers are born to be well-cited while others are not. In this work, we revisit the important problem of citation prediction, by focusing on the important yet realistic prediction on the average number of citations a paper will attract per year. The task is nonetheless challenging because many correlated factors underlie the potential impact of a paper, such as the prestige of its authors, the authority of its publishing venue, and the significance of the problems/techniques/applications it studies. To jointly model these factors, we propose to construct a heterogeneous publication network of nodes including papers, authors, venues, and terms. Moreover, we devise a novel heterogeneous graph neural network (HGN) to jointly embed all types of nodes and links, towards the modeling of research impact and its propagation. Beyond graph heterogeneity, we find it also important to consider the latent research domains, because the same nodes can have different impacts within different communities. Therefore, we further devise a novel cluster-aware (CA) module, which models all nodes and their interactions under the proper contexts of research domains. Finally, to exploit the information-rich texts associated with papers, we devise a novel text-enhancing (TE) module for automatic quality term mining. With the real-world publication data of DBLP, we construct three different networks and conduct comprehensive experiments to evaluate our proposed CATE-HGN framework, against various state-of-the-art models. Rich quantitative results and qualitative case studies demonstrate the superiority of CATE-HGN in citation prediction on publication networks, and indicate its general advantages in various relevant downstream tasks on text-rich heterogeneous networks.}
}


@inproceedings{DBLP:conf/icde/XuSM0ZZ23,
	author = {Yiming Xu and
                  Bin Shi and
                  Teng Ma and
                  Bo Dong and
                  Haoyi Zhou and
                  Qinghua Zheng},
	title = {{CLDG:} Contrastive Learning on Dynamic Graphs},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {696--707},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00059},
	doi = {10.1109/ICDE55515.2023.00059},
	timestamp = {Sun, 06 Oct 2024 21:04:59 +0200},
	biburl = {https://dblp.org/rec/conf/icde/XuSM0ZZ23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The graph with complex annotations is the most potent data type, whose constantly evolving motivates further exploration of the unsupervised dynamic graph representation. One of the representative paradigms is graph contrastive learning. It constructs self-supervised signals by maximizing the mutual information between the statistic graph’s augmentation views. However, the semantics and labels may change within the augmentation process, causing a significant performance drop in downstream tasks. This drawback becomes greatly magnified on dynamic graphs. To address this problem, we designed a simple yet effective framework named CLDG. Firstly, we elaborate that dynamic graphs have temporal translation invariance at different levels. Then, we proposed a sampling layer to extract the temporally-persistent signals. It will encourage the node to maintain consistent local and global representations, i.e., temporal translation invariance under the timespan views. The extensive experiments demonstrate the effectiveness and efficiency of the method on seven datasets by outperforming eight unsupervised state-of-the-art baselines and showing competitiveness against four semi-supervised methods. Compared with the existing dynamic graph method, the number of model parameters and training time is reduced by an average of 2,001.86 times and 130.31 times on seven datasets, respectively. The code and data are available at: https://github.com/yimingxu24/CLDG.}
}


@inproceedings{DBLP:conf/icde/ChenH23,
	author = {Yiru Chen and
                  Silu Huang},
	title = {TSExplain: Explaining Aggregated Time Series by Surfacing Evolving
                  Contributors},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {708--720},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00060},
	doi = {10.1109/ICDE55515.2023.00060},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ChenH23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Aggregated time series are generated effortlessly everywhere, e.g., "total confirmed covid-19 cases since 2019" and "total liquor sales over time". Understanding "how" and "why" these key performance indicators (KPI) evolve over time is critical to making data-informed decisions. Existing explanation engines focus on explaining one aggregated value or the difference between two relations. However, this falls short of explaining KPIs’ continuous changes over time. Motivated by this, we propose TSExplain, a system that explains aggregated time series by surfacing the underlying evolving top contributors. Under the hood, we leverage priworks on two-relations diff as a building block and formulate a K-Segmentation problem to segment the time series such that each segment after segmentation shares consistent explanations, i.e., contributors. To quantify consistency in each segment, we propose a novel within-segment variance design that is explanation-aware; to derive the optimal K-Segmentation scheme, we develop an efficient dynamic programming algorithm. Experiments on synthetic and real-world datasets show that our explanation-aware segmentation can effectively identify evolving explanations for aggregated time series and outperform explanation-agnostic segmentation. Further, we proposed an optimal selection strategy of K and several optimizations to speed up TSExplain for interactive user experience, achieving up to 13× efficiency improvement.}
}


@inproceedings{DBLP:conf/icde/ZhangPY23,
	author = {Yuanzhe Zhang and
                  Shirui Pan and
                  Jiangshan Yu},
	title = {TxAllo: Dynamic Transaction Allocation in Sharded Blockchain Systems},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {721--733},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00390},
	doi = {10.1109/ICDE55515.2023.00390},
	timestamp = {Sun, 12 Nov 2023 02:08:10 +0100},
	biburl = {https://dblp.org/rec/conf/icde/ZhangPY23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The scalability problem has been one of the most significant barriers limiting the adoption of blockchains. Blockchain sharding is a promising approach to this problem. However, the sharding mechanism introduces a significant number of cross-shard transactions, which are expensive to process.This paper focuses on the transaction allocation problem to reduce the number of cross-shard transactions for better scalability. In particular, we systematically formulate the transaction allocation problem and convert it to the community detection problem on a graph. A deterministic and fast allocation scheme TxAllo is proposed to dynamically infer the allocation of accounts and their associated transactions. It directly optimizes the system throughput, considering both the number of cross-shard transactions and the workload balance among shards.We evaluate the performance of TxAllo on an Ethereum dataset containing over 91 million transactions. Our evaluation results show that for a blockchain with 60 shards, TxAllo reduces the cross-shard transaction ratio from 98% (by using traditional hash-based allocation) to about 12%. In the meantime, the workload balance is well maintained. Compared with other methods, the execution time of TxAllo is almost negligible. For example, when updating the allocation every hour, the execution of TxAllo only takes 0.5 seconds on average, whereas other concurrent works, such as BrokerChain (INFOCOM’22) leveraging the classic METIS method, require 422 seconds.}
}


@inproceedings{DBLP:conf/icde/LiWLNYZZLHQZ23,
	author = {Keqiang Li and
                  Siyang Weng and
                  Peiyuan Liu and
                  Lyu Ni and
                  Chengcheng Yang and
                  Rong Zhang and
                  Xuan Zhou and
                  Jianghang Lou and
                  Gui Huang and
                  Weining Qian and
                  Aoying Zhou},
	title = {Leopard: {A} Black-Box Approach for Efficiently Verifying Various
                  Isolation Levels},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {722--735},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00061},
	doi = {10.1109/ICDE55515.2023.00061},
	timestamp = {Sun, 06 Oct 2024 21:04:58 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LiWLNYZZLHQZ23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Isolation Levels (IL) act as correct contracts between applications and database management systems (DBMSs). The complex code logic and concurrent interactions among transactions make it a hard problem to expose violations of various ILs stated by DBMSs. With the recent proliferation of new DBMSs, especially the cloud ones, there is an urgent demand for a general way to verify various ILs. The core challenges come from the requirements of: (a) lightweight (verifying without modifying the application logic in workloads and the source code of DBMSs), (b) generality (verifying various ILs), and (c) efficiency (performing efficient verification on a long running workload). For lightweight, we propose to deduce transaction dependencies based on time intervals of operations collected from client-sides without touching the source code of DBMSs. For generality, based on a thorough analysis of existing concurrency control protocols, we summarize and abstract four mechanisms which can implement ILs in all commercial DBMSs we have investigated. For efficiency, we design a two-level pipeline to organize and sort massive time intervals in a time and memory conservative way; we propose a mechanism-mirrored verification to simulate the concurrency control protocols implemented in DBMSs for high throughputs. Leopard outperforms existing methods by up to 114× in verification time with a relative small memory usage. In practice, Leopard has a superpower to verify various ILs on any workload running on all commercial DBMSs. Moreover, it has successfully discovered 23 bugs that cannot be found by other existing methods.}
}


@inproceedings{DBLP:conf/icde/XiaoZHZ0D023,
	author = {Congxi Xiao and
                  Jingbo Zhou and
                  Jizhou Huang and
                  Hengshu Zhu and
                  Tong Xu and
                  Dejing Dou and
                  Hui Xiong},
	title = {A Contextual Master-Slave Framework on Urban Region Graph for Urban
                  Village Detection},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {736--748},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00062},
	doi = {10.1109/ICDE55515.2023.00062},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/XiaoZHZ0D023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Urban villages (UVs) refer to the underdeveloped informal settlement falling behind the rapid urbanization in a city. Since there are high levels of social inequality and social risks in these UVs, it is critical for city managers to discover all UVs for making appropriate renovation policies. Existing approaches to detecting UVs are labor-intensive or have not fully addressed the unique challenges in UV detection such as the scarcity of labeled UVs and the diverse urban patterns in different regions. To this end, we first build an urban region graph (URG) to model the urban area in a hierarchically structured way. Then, we design a novel contextual master-slave framework to effectively detect the urban village from the URG. The core idea of such a framework is to firstly pre-train a basis (or master) model over the URG, and then to adaptively derive specific (or slave) models from the basis model for different regions. The proposed framework can learn to balance the generality and specificity for UV detection in an urban area. Finally, we conduct extensive experiments in three cities to demonstrate the effectiveness of our approach.}
}


@inproceedings{DBLP:conf/icde/LiuW23,
	author = {Bin Liu and
                  Bang Wang},
	title = {Bayesian Negative Sampling for Recommendation},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {749--761},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00063},
	doi = {10.1109/ICDE55515.2023.00063},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LiuW23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {How to sample high quality negative instances from unlabeled data, i.e., negative sampling, is important for training implicit collaborative filtering and contrastive learning models. Although previous studies have proposed some approaches to sample informative instances, discriminating false negative from true negative for unbiased negative sampling remains an unsolved problem. On the basis of our order relation analysis of negatives’ scores, we first derive the class conditional density of true negatives and that of false negatives. We next design a Bayesian classifier for negative classification, from which we define a model-agnostic posterior probability estimate of an instance being true negative as a quantitative negative signal measure. We also propose a Bayesian optimal sampling rule to sample high-quality negatives. The proposed Bayesian Negative Sampling (BNS) algorithm has a linear time complexity. Experimental studies validate the superiority of BNS over the peers in terms of better sampling quality and better recommendation performance. 1}
}


@inproceedings{DBLP:conf/icde/ZhangYO00Y23,
	author = {Jiujing Zhang and
                  Shiyu Yang and
                  Dian Ouyang and
                  Fan Zhang and
                  Xuemin Lin and
                  Long Yuan},
	title = {Hop-Constrained s-t Simple Path Enumeration on Large Dynamic Graphs},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {762--775},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00064},
	doi = {10.1109/ICDE55515.2023.00064},
	timestamp = {Sun, 04 Aug 2024 19:37:45 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhangYO00Y23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Hop-constrained s-t simple path (k-st path) enumeration is a fundamental problem in graph databases and plays an important role in many real-world applications. Given a dynamic graph G, a source-target pair s-t, and a hop constraint k, we aim to efficiently compute k-st paths: list all simple paths within length k from s to t, and then continuously maintain the results against edge updates. Although the k-st path enumeration has been well studied in static setting, the existing works on static graphs cannot be applied or adapted to handle dynamic graphs efficiently. To address the challenges on dynamic computation, we propose a partial path-based index structure and an efficient enumeration algorithm based on the index. We also propose several well-designed techniques to efficiently maintain the index and locate the affected results with graph updates. Comprehensive experiments verify that our proposed CPE update algorithm outperforms the state-of-the-art methods by up to 4 orders of magnitude on dynamic graphs. The experiment results also show that the time cost of our initialization step CPE startup (including index construction) is similar to the state-of-the-art static method.}
}


@inproceedings{DBLP:conf/icde/WeiTZLZZY23,
	author = {Shuyue Wei and
                  Yongxin Tong and
                  Zimu Zhou and
                  Qiaoyang Liu and
                  Lulu Zhang and
                  Yuxiang Zeng and
                  Jieping Ye},
	title = {Towards Capacity-Aware Broker Matching: From Recommendation to Assignment},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {776--788},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00065},
	doi = {10.1109/ICDE55515.2023.00065},
	timestamp = {Tue, 07 May 2024 20:05:37 +0200},
	biburl = {https://dblp.org/rec/conf/icde/WeiTZLZZY23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Online real estate platforms are gaining increasing popularity, where a central issue is to match brokers with clients for potential housing transactions. Mainstream platforms match brokers via top-k recommendation. Yet we observe through extensive data analysis that such top-k recommendation tends to overload the top brokers, which notably degrades their service quality. In this paper, we propose to avoid such overloading in broker matching via the paradigm shift from recommendation to assignment. To this end, we design learned assignment with contextual bandits (LACB), a data-driven capacity-aware assignment scheme for broker matching which estimates broker-specific workload capacity in an online fashion and assigns brokers to clients from a global perspective to maximize the overall service quality. Extensive evaluations on synthetic and real-world datasets from an industrial online real estate platform validate the efficiency and effectiveness of our solution.}
}


@inproceedings{DBLP:conf/icde/0002ZW0023,
	author = {Jiadong Xie and
                  Fan Zhang and
                  Kai Wang and
                  Xuemin Lin and
                  Wenjie Zhang},
	title = {Minimizing the Influence of Misinformation via Vertex Blocking},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {789--801},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00066},
	doi = {10.1109/ICDE55515.2023.00066},
	timestamp = {Sun, 12 Nov 2023 02:08:10 +0100},
	biburl = {https://dblp.org/rec/conf/icde/0002ZW0023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Information cascade in online social networks can be rather negative, e.g., the spread of rumors may trigger panic. To limit the influence of misinformation in an effective and efficient manner, the influence minimization (IMIN) problem is studied in the literature: given a graph G and a seed set S, blocking at most b vertices such that the influence spread of the seed set is minimized. In this paper, we are the first to prove the IMIN problem is NP-hard and hard to approximate. Due to the hardness of the problem, existing works resort to greedy solutions and use Monte-Carlo Simulations to solve the problem. However, they are cost-prohibitive on large graphs since they have to enumerate all the candidate blockers and compute the decrease of expected spread when blocking each of them. To improve the efficiency, we propose the AdvancedGreedy algorithm (AG) based on a new graph sampling technique that applies the dominator tree structure, which can compute the decrease of the expected spread of all candidate blockers at once. Besides, we further propose the GreedyReplace algorithm (GR) by considering the relationships among candidate blockers. Extensive experiments on 8 real-life graphs demonstrate that our AG and GR algorithms are significantly faster than the state-of-the-art by up to 6 orders of magnitude, and GR can achieve better effectiveness with its time cost close to AG.}
}


@inproceedings{DBLP:conf/icde/LiuXQDTL0023,
	author = {Weiwen Liu and
                  Yunjia Xi and
                  Jiarui Qin and
                  Xinyi Dai and
                  Ruiming Tang and
                  Shuai Li and
                  Weinan Zhang and
                  Rui Zhang},
	title = {Personalized Diversification for Neural Re-ranking in Recommendation},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {802--815},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00067},
	doi = {10.1109/ICDE55515.2023.00067},
	timestamp = {Sun, 06 Oct 2024 21:04:58 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LiuXQDTL0023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Re-ranking, as the final stage of the multi-stage recommender systems (MRS), aims at modeling the listwise context and the cross-item interactions between the candidate items. The objective is usually the overall utility (e.g., total clicks or revenue) of the re-ranked list, which is determined not only by the relevance, but also by the diversity of the list. However, existing methods equally promote diversity for all users and often compromise the relevance ranking. In reality, users have different diversity preferences and we should diversify the list tailored to individual users’ interests and needs. Users’ behavior history contains rich information which may be used for inferring their diversity preferences, but has rarely been explored in existing work. In this work, we propose a novel neural re-ranking with personalized diversification method (dubbed RAPID) to address the above challenge. RAPID explicitly models each user’s preference distribution over different topics by exploiting the intra- and inter-topic interactions from the user’s behavior history. The personalized diversity gain brought by each candidate item is then measured by the item’s marginal diversity and the learned personalized preference. The relevance and the personalized diversity are jointly optimized in an end-to-end manner to automatically manage the relevance-diversity tradeoff. Experimental results on two public datasets and a proprietary dataset show that RAPID outperforms the state-of-the-art with the highest utility and the best relevance-diversity tradeoff. We further prove that RAPID has a regret bound of\nO\n~\n(\nn\n−\n−\n√\n)\non utility, which provides theoretical guarantee that its performance is near-optimal.}
}


@inproceedings{DBLP:conf/icde/HeT00ZLX23,
	author = {Xiao He and
                  Jian Tan and
                  Bin Wu and
                  Feifei Li and
                  Xinping Zhang and
                  Gaozhong Liang and
                  Jinfeng Xu},
	title = {Active Sampling for Sparse Table by Bayesian Optimization with Adaptive
                  Resolution},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {816--828},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00068},
	doi = {10.1109/ICDE55515.2023.00068},
	timestamp = {Sun, 14 Apr 2024 13:23:48 +0200},
	biburl = {https://dblp.org/rec/conf/icde/HeT00ZLX23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Open-source relational database systems have become increasingly popular in the cloud era. However, practitioners are often beset with query performance issues. Thus a general-purpose database performance tuning tool independent of the various DBMS kernels becomes desired to lower the bar of using these systems. The first mandatory step in developing such a tool is to design an effective sampling method that collects representative records from different tables. Although one could leverage standard SQL statements and indexes to achieve this, sampling performance and statistical efficiency are not guaranteed when the underlying tables are frequently updated, especially for Sparse Tables where the range of index values is significantly greater than the table size.To this end, we propose a novel Active Sampling algorithm that queries regions more likely to contain data records from Sparse Tables. It relies on Gaussian process regression to characterize the probability density of whether a data record is non-null at a given index value. With the help of this estimated density function, the proposed method achieves efficient sampling by actively querying records with adaptive resolutions of interval lengths and provides an unbiased estimator for histogram construction. Comprehensive experiments on synthetic and real-world datasets demonstrate that the proposed Active Sampling method can effectively improve the estimation accuracy and use less query cost than other commonly used sampling methods.}
}


@inproceedings{DBLP:conf/icde/0018Z0Z23,
	author = {Yuqi Chen and
                  Hanyuan Zhang and
                  Weiwei Sun and
                  Baihua Zheng},
	title = {RNTrajRec: Road Network Enhanced Trajectory Recovery with Spatial-Temporal
                  Transformer},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {829--842},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00069},
	doi = {10.1109/ICDE55515.2023.00069},
	timestamp = {Sat, 30 Sep 2023 09:44:49 +0200},
	biburl = {https://dblp.org/rec/conf/icde/0018Z0Z23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {GPS trajectories are the essential foundations for many trajectory-based applications. Most applications require a large number of high sample rate trajectories to achieve a good performance. However, many real-life trajectories are collected with low sample rate due to energy concern or other constraints. We study the task of trajectory recovery in this paper as a means to increase the sample rate of low sample trajectories. Most existing works on trajectory recovery follow a sequence-to-sequence diagram, with an encoder to encode a trajectory and a decoder to recover real GPS points in the trajectory. However, these works ignore the topology of road network and only use grid information or raw GPS points as input. Therefore, the encoder model is not able to capture rich spatial information of the GPS points along the trajectory, making the prediction less accurate and less spatial consistent. In this paper, we propose a road network enhanced transformer-based framework, namely RNTrajRec, for trajectory recovery. RNTrajRec first uses a graph model, namely GridGNN, to learn the embedding features of each road segment. It next develops a spatial-temporal transformer model, namely GPSFormer, to learn rich spatial and temporal features along with a Sub-Graph Generation module to capture the spatial features for each GPS point in the trajectory. It finally forwards the outputs of encoder model to a multi-task decoder model to recover the missing GPS points. Extensive experiments based on three large-scale real-life trajectory datasets confirm the effectiveness of our approach.}
}


@inproceedings{DBLP:conf/icde/JiangPRJLW23,
	author = {Jiawei Jiang and
                  Dayan Pan and
                  Houxing Ren and
                  Xiaohan Jiang and
                  Chao Li and
                  Jingyuan Wang},
	title = {Self-supervised Trajectory Representation Learning with Temporal Regularities
                  and Travel Semantics},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {843--855},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00070},
	doi = {10.1109/ICDE55515.2023.00070},
	timestamp = {Wed, 28 Aug 2024 10:14:15 +0200},
	biburl = {https://dblp.org/rec/conf/icde/JiangPRJLW23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Trajectory Representation Learning (TRL) is a powerful tool for spatial-temporal data analysis and management. TRL aims to convert complicated raw trajectories into low-dimensional representation vectors, which can be applied to various downstream tasks, such as trajectory classification, clustering, and similarity computation. Existing TRL works usually treat trajectories as ordinary sequence data, while some important spatial-temporal characteristics, such as temporal regularities and travel semantics, are not fully exploited. To fill this gap, we propose a novel Self-supervised trajectory representation learning framework with TemporAl Regularities and Travel semantics, namely START. The proposed method consists of two stages. The first stage is a Trajectory Pattern-Enhanced Graph Attention Network (TPE-GAT), which converts the road network features and travel semantics into representation vectors of road segments. The second stage is a Time-Aware Trajectory Encoder (TAT-Enc), which encodes representation vectors of road segments in the same trajectory as a trajectory representation vector, meanwhile incorporating temporal regularities with the trajectory representation. Moreover, we also design two self-supervised tasks, i.e., span-masked trajectory recovery and trajectory contrastive learning, to introduce spatial-temporal characteristics of trajectories into the training process of our START framework. The effectiveness of the proposed method is verified by extensive experiments on two large-scale real-world datasets for three downstream tasks. The experiments also demonstrate that our method can be transferred across different cities to adapt heterogeneous trajectory datasets.}
}


@inproceedings{DBLP:conf/icde/PengM000C23,
	author = {You Peng and
                  Zhuo Ma and
                  Wenjie Zhang and
                  Xuemin Lin and
                  Ying Zhang and
                  Xiaoshuang Chen},
	title = {Efficiently Answering Quality Constrained Shortest Distance Queries
                  in Large Graphs},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {856--868},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00071},
	doi = {10.1109/ICDE55515.2023.00071},
	timestamp = {Tue, 07 May 2024 20:05:36 +0200},
	biburl = {https://dblp.org/rec/conf/icde/PengM000C23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {One of the fundamental concept in the graph-related problem is the shortest path distance. This problem is widely studied for decades, and has numerous real-life applications. Nevertheless, quality constraints are naturally associated with edges. For instance, finding the distance between two vertices along valid edges (i.e., edges that satisfy a given quality constraint) is also critical. To fill this research gap, we investigate this vital problem, i.e., the quality constraint shortest distance problems. An efficient index structure is proposed based on 2-hop labeling approaches. By using a path dominance relationship into both quality and length information, it is demonstrated that the new index could ensure the minimal property. To further speed up the performance, we present an efficient query processing algorithm. Extensive experimental studies over real-life datasets demonstrates efficiency and effectiveness of our techniques.}
}


@inproceedings{DBLP:conf/icde/ShiZTZX023,
	author = {Dingyuan Shi and
                  Nan Zhou and
                  Yongxin Tong and
                  Zimu Zhou and
                  Yi Xu and
                  Ke Xu},
	title = {Collision-Aware Route Planning in Warehouses Made Efficient: {A} Strip-based
                  Framework},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {869--881},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00072},
	doi = {10.1109/ICDE55515.2023.00072},
	timestamp = {Sun, 06 Oct 2024 21:04:58 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ShiZTZX023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Multi-robot systems are deployed in modern warehouses to reduce operational cost. The robots are tasked to deliver items stored on racks to pickers for fast distribution. A central algorithmic problem is collision-aware route planning, which aims to plan shortest routes for robots to deliver racks while avoiding collision with racks, pickers, and other robots. Prior solutions are inefficient in real-world warehouses, where route planning requests emerge online and at large scale. In this paper, we identify collision judgement in grid-based warehouse representation as the primary efficiency bottleneck, and propose a novel Strip-based Route Planning framework (SRP). Specifically, we exploit the regularity in warehouse layouts, and aggregate grids into strips. The strip-based representation also converts collisions of 3-dimensional (2-dimensional space and 1-dimensional time) routes into 2-dimensional (1-dimensional space and 1-dimensional time) segment intersections, which can be fast checked via computational geometry. We further accelerate the collision judgement via indexing on segments within strips. Theoretical analysis shows a reduction of time complexity from square to linear-logarithmic. Experimental results on datasets collected from real-world robotized warehouses show that our SRP is up to 227× faster than existing methods.}
}


@inproceedings{DBLP:conf/icde/Xing0WXL23,
	author = {Yipeng Xing and
                  Yongkun Li and
                  Zhiqiang Wang and
                  Yinlong Xu and
                  John C. S. Lui},
	title = {LightTraffic: On Optimizing {CPU-GPU} Data Traffic for Efficient Large-scale
                  Random Walks},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {882--895},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00073},
	doi = {10.1109/ICDE55515.2023.00073},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Xing0WXL23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As a fundamental tool for graph analysis, random walk receives extensive attention in both industry and academia. For computing massive random walks, recent works show that GPUs provide a good option to accelerate the performance. However, due to the limited memory space of modern GPUs, it is infeasible to have both the graph data and walk index fully reside in GPU memory when running large-scale random walks. Thus, it necessitates an out-of-GPU-memory design, but this inevitably induces large amounts of CPU-GPU data transmission traffic and thus hinders the overall performance. In this paper, we develop LightTraffic, which optimizes the data transmission between CPU and GPU memory under the constraint of GPU memory capacity with various system designs, including a memory-efficient scheme for partition-based management and multiple scheduling techniques. LightTraffic is a fully out-of-GPU-memory design, so it supports running large-scale random walks on GPUs. Experiments on our prototype show that LightTraffic outperforms various state-of-the-art CPU-based in-memory systems which also support large-scale random walks. For example, compared to the CPU-based systems FlashMob and ThunderRW, which are highly optimized for random walks, LightTraffic achieves 1.7−5.0× and 1.4 − 12.8× performance speedup, respectively. It also achieves up to an order of magnitude speedup when compared to the GPU-based system Subway which also supports large-scale random walks with an out-of-GPU-memory design for graph data.}
}


@inproceedings{DBLP:conf/icde/PengY023,
	author = {You Peng and
                  Jeffrey Xu Yu and
                  Sibo Wang},
	title = {{PSPC:} Efficient Parallel Shortest Path Counting on Large-Scale Graphs},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {896--908},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00074},
	doi = {10.1109/ICDE55515.2023.00074},
	timestamp = {Sun, 12 Nov 2023 02:08:08 +0100},
	biburl = {https://dblp.org/rec/conf/icde/PengY023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In graph analysis area, the shortest path is vital, and recent research shows that the shortest paths counting is crucial in applications like potential friend recommendation and betweenness analysis. Nevertheless, the existing works mainly focus on how to speed up it in a single machine with single core, which do not consider the scalability of it. It limits applications and wastes potential performance. The main bottleneck is dependency between their index is no considered. To fill this research gap, we provide a parallel method. The main approach is to release the dependency between the index as well as optimizations during the process. Moreover, our method could achieve a nearly linear speedup with the number of threads increase in terms of index time. The experimental results demonstrate the effectiveness and efficiency of our method than the baselines.}
}


@inproceedings{DBLP:conf/icde/LiuLHXG23,
	author = {Qing Liu and
                  Xuankun Liao and
                  Xin Huang and
                  Jianliang Xu and
                  Yunjun Gao},
	title = {Distributed ({\(\alpha\)}, {\(\beta\)})-Core Decomposition over Bipartite
                  Graphs},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {909--921},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00075},
	doi = {10.1109/ICDE55515.2023.00075},
	timestamp = {Tue, 21 May 2024 17:42:38 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LiuLHXG23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {(α, β)-core is an important cohesive subgraph model for bipartite graphs. Given a bipartite graph G, the problem of (α, β)-core decomposition is to compute non-empty (α, β)-cores for all possible values of α and β. The state-of-the-art (α, β)-core decomposition algorithm is a peeling-based algorithm, which iteratively deletes the vertex from high degree to low degree. However, as the peeling-based algorithm is designed for centralized environments, it cannot be applied to distributed environments, where graphs are partitioned and stored in different machines. Motivated by this, in this paper, we study the distributed (α, β)-core decomposition problem, aiming to develop new algorithms to support (α, β)-core decomposition in distributed environments. To this end, first, we analyze the local properties of (α, β)-core, and devise n-order Bi-indexes for the vertex, which are iteratively defined using the vertex neighbors’ (n − 1)-order Bi-indexes. Next, we propose an algorithm for (α, β)-core decomposition through iteratively calculating n-order Bi-indexes for every vertex. To further improve the efficiency of the algorithm, we propose two optimizations. Then, we extend our proposed algorithms to different distributed graph processing frameworks to make them run in distributed environments. Finally, extensive experimental results on both real and synthetic bipartite graphs demonstrate the efficiency of our proposed algorithms.}
}


@inproceedings{DBLP:conf/icde/KarimovJ23,
	author = {Jeyhun Karimov and
                  Hans{-}Arno Jacobsen},
	title = {{SASPAR:} Shared Adaptive Stream Partitioning},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {922--935},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00076},
	doi = {10.1109/ICDE55515.2023.00076},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/KarimovJ23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Data partitioning induces network transfers and dominates the cost of stream data analytics. Moreover, partitioning streaming data for multiple stream queries in the same cluster can easily saturate the network bandwidth and lead to high end-to-end latencies.The goal of this paper is to share the partition operation in streaming workloads and maximize the sharing opportunities for multiple stream queries. However, there are several challenges, such as minimizing data copy, optimizing the partitioning strategy for multiple queries, and minimizing latency.We propose SASPAR, Shared Adaptive Stream Partitioner, which is able to share data partitioning among multiple stream queries. Our contributions are threefold. First, we propose a new technique to optimize the partitioning strategy for multiple stream queries. Second, we present an adaptive query execution framework that performs optimizations at run-time, without stopping the query execution plan. Third, we utilize meta-heuristics and machine learning when solving the underlying optimization problem takes more time than expected.SASPAR is designed as a versatile layer to sit on top of a stream processing engine (SPE). We operate SASPAR on top of three state-of-the-art SPEs with hundreds of stream queries. Our experimental results show that SASPAR improves the performance (throughput and latency) of all underlying SPEs by up to 3x.}
}


@inproceedings{DBLP:conf/icde/BehmeTMQM23,
	author = {Lennart Behme and
                  Saravanan Thirumuruganathan and
                  Alireza Rezaei Mahdiraji and
                  Jorge{-}Arnulfo Quian{\'{e}}{-}Ruiz and
                  Volker Markl},
	title = {The Art of Losing to Win: Using Lossy Image Compression to Improve
                  Data Loading in Deep Learning Pipelines},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {936--949},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00077},
	doi = {10.1109/ICDE55515.2023.00077},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/BehmeTMQM23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Training deep learning (DL) models often takes a significant amount of time and is thus typically performed on expensive GPUs to speed up the process. However, data loading has recently been identified as one of the main performance bottlenecks in DL, resulting in GPU under-utilization. Looking forward, the combination of larger datasets and faster GPUs will exacerbate the problem. The data management community has started to address this by proposing data loading optimization techniques, including lossy image compression. While lossy compression is a conceptually promising approach for mitigating data loading bottlenecks in DL, there is only limited understanding of its efficacy in terms of impact on model throughput and accuracy. In this paper, we present an extensive experimental analysis of lossy image compression as a means to improve the performance of neural network training. We find that lossy compression can improve both throughput and accuracy of DL pipelines if resources such as time or storage capacity are limited. Furthermore, the choice of compression quality and codec are important hyperparameters when training deep neural networks.}
}


@inproceedings{DBLP:conf/icde/Zeng023,
	author = {Xianzhi Zeng and
                  Shuhao Zhang},
	title = {Parallelizing Stream Compression for IoT Applications on Asymmetric
                  Multicores},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {950--964},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00078},
	doi = {10.1109/ICDE55515.2023.00078},
	timestamp = {Mon, 05 Feb 2024 20:31:13 +0100},
	biburl = {https://dblp.org/rec/conf/icde/Zeng023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Data stream compression attracts much attention recently due to the rise of IoT applications. Thanks to the balanced computational power and energy consumption, asymmetric multicores are widely used in IoT devices. This paper introduces CStream, a novel framework for parallelizing stream compression on asymmetric multicores to minimize energy consumption without violating the user-specified compressing latency constraint. Existing works cannot effectively utilize asymmetric multicores for stream compression, primarily due to the non-trivial asymmetric computation and asymmetric communication effects. To this end, CStream is developed with the following two novel designs: 1) fine-grained decomposition, which decomposes a stream compression procedure into multiple fine-grained tasks to better expose the task-core affinities under the asymmetric computation effects; and 2) asymmetry-aware task scheduling, which schedules the decomposed tasks based on a novel cost model to exploit the exposed task-core affinities while considering asymmetric communication effects. To validate our proposal, we evaluate CStream with five competing mechanisms of parallelizing stream compression algorithms on a recent asymmetric multicore processor. We evaluate CStream with five competing mechanisms of parallelizing stream compression algorithms to validate our proposal on a recent asymmetric multicore processor. Our extensive experiments based on a benchmark of three algorithms and four datasets show that CStream outperforms alternative approaches by up to 53% lower energy consumption without compressing latency constraint violation.}
}


@inproceedings{DBLP:conf/icde/Zhu00CXHL23,
	author = {Huaijie Zhu and
                  Wei Liu and
                  Jian Yin and
                  Ningning Cui and
                  Jianliang Xu and
                  Xin Huang and
                  Wang{-}Chien Lee},
	title = {Keyword-based Socially Tenuous Group Queries},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {965--977},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00079},
	doi = {10.1109/ICDE55515.2023.00079},
	timestamp = {Fri, 28 Jul 2023 08:52:23 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Zhu00CXHL23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Socially tenuous groups (or simply tenuous groups) in a social network/graph refer to subgraphs with few social interactions and weak relationships among members. However, existing studies on tenuous group queries do not consider the user profiles (keywords) of the members whereas in many social network applications, e.g., finding reviewers for paper selection and recommending seed users in social advertising, keywords also need to be considered. Thus, in this paper, we investigate the problem of keywords-based socially tenous group (KTG) queries. A KTG query is to find top N tenuous groups in which the members of each group jointly cover the most number of query keywords. To address the KTG problem, we first propose two exact algorithms, namely KTG-VKC and KTG-VKC-DEG, which give priority to the valid keyword coverage and the combination of valid keyword coverage and degree, respectively, to select members to form a feasible group by adopting a branch and bound (BB) strategy. Moreover, we propose keyword pruning and k-line filtering to accelerate the algorithms. To yield diversified KTG results, we also study the problem of diversified keywords-based socially tenous group (DKTG) queries. To deal with the DKTG problem, we propose a DKTG-Greedy algorithm by exploiting a greedy heuristic in combination with KTG-VKC-DEG. Furthermore, we design two alternative indexes, namely NL and NLRNL, to efficiently check whether the social distance of any two members is greater than the social constraint k in the above algorithms. We conduct extensive experiments using real datasets to validate our ideas and evaluate the proposed algorithms. Experimental results show that the NLRNL index achieves a better performance than the NL index.}
}


@inproceedings{DBLP:conf/icde/ZhaiLYX23,
	author = {Shuoyao Zhai and
                  Baichuan Liu and
                  Deqing Yang and
                  Yanghua Xiao},
	title = {Group Buying Recommendation Model Based on Multi-task Learning},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {978--991},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00080},
	doi = {10.1109/ICDE55515.2023.00080},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhaiLYX23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent years, group buying has become one popular kind of online shopping activities, thanks to its larger sales and lower unit price. Unfortunately, seldom research focuses on the recommendations specifically for group buying by now. Although some recommendation models have been proposed for group recommendation, they can not be directly used to achieve the real-world group buying recommendation, due to the essential difference between group recommendation and group buying recommendation. In this paper, we first formalize the task of group buying recommendation into two sub-tasks. Then, based on our insights into the correlations and interactions between the two sub-tasks, we propose a novel recommendation model for group buying, namely MGBR, which is built mainly with a multi-task learning module. To improve recommendation performance further, we devise some collaborative expert networks and adjusted gates in the multi-task learning module, to promote the information interaction between the two sub-tasks. Furthermore, we propose two auxiliary losses corresponding to the two sub-tasks, to refine the representation learning in our model. Our extensive experiments not only demonstrate that the augmented representations learned in our model result in better performance than previous recommendation models, but also justify the impacts of the specially designed components in our model. To reproduce our model’s recommendation results conveniently, we have provided our model’s source code and dataset on https://github.com/DeqingYang/MGBR.}
}


@inproceedings{DBLP:conf/icde/Qian0ZZY23,
	author = {Weizhu Qian and
                  Dalin Zhang and
                  Yan Zhao and
                  Kai Zheng and
                  James J. Q. Yu},
	title = {Uncertainty Quantification for Traffic Forecasting: {A} Unified Approach},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {992--1004},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00081},
	doi = {10.1109/ICDE55515.2023.00081},
	timestamp = {Tue, 23 Jul 2024 08:21:59 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Qian0ZZY23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Uncertainty is an essential consideration for time series forecasting tasks. In this work, we specifically focus on quantifying the uncertainty of traffic forecasting. To achieve this, we develop Deep Spatio-Temporal Uncertainty Quantification (DeepSTUQ), which can estimate both aleatoric and epistemic uncertainty. We first leverage a spatio-temporal model to model the complex spatio-temporal correlations of traffic data. Subsequently, two independent sub-neural networks maximizing the heterogeneous log-likelihood are developed to estimate aleatoric uncertainty. For estimating epistemic uncertainty, we combine the merits of variational inference and deep ensembling by integrating the Monte Carlo dropout and the Adaptive Weight Averaging re-training methods, respectively. Finally, we propose a post-processing calibration approach based on Temperature Scaling, which improves the model’s generalization ability to estimate uncertainty. Extensive experiments are conducted on four public datasets, and the empirical results suggest that the proposed method outperforms state-of-the-art methods in terms of both point prediction and uncertainty quantification.}
}


@inproceedings{DBLP:conf/icde/Li0YSS23,
	author = {Zichong Li and
                  Lan Zhang and
                  Mu Yuan and
                  Miaohui Song and
                  Qi Song},
	title = {Efficient Deep Ensemble Inference via Query Difficulty-dependent Task
                  Scheduling},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {1005--1018},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00082},
	doi = {10.1109/ICDE55515.2023.00082},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Li0YSS23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Deep ensemble learning has been widely adopted to boost accuracy through combing outputs from multiple deep models prepared for the same task. However, the extra computation and memory cost it entails could impose an unacceptably high deadline miss rate in latency-sensitive tasks. Conventional approaches, including ensemble selection, focus on accuracy while ignoring deadline constraints, and thus cannot smartly cope with bursty query traffic and queries with different hardness. This paper explores redundancy in deep ensemble model inference and presents Schemble, a query difficulty-dependent task scheduling framework. Schemble treats ensemble inference progress as multiple base model inference tasks and schedules tasks for queries based on their difficulty and queuing status. We evaluate Schemble on real-world datasets, considering intelligent Q&A system, video analysis and image retrieval as the running applications. Experimental results show that Schemble achieves a 5× lower deadline miss rate and improves the accuracy by 30.8% given deadline constraints.}
}


@inproceedings{DBLP:conf/icde/QuZCZH0ZHW23,
	author = {Wenwen Qu and
                  Weixi Zhang and
                  Ji Cheng and
                  Chaorui Zhang and
                  Wei Han and
                  Bo Bai and
                  Chen Jason Zhang and
                  Liang He and
                  Xiaoling Wang},
	title = {Optimizing Graph Partition by Optimal Vertex-Cut: {A} Holistic Approach},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {1019--1031},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00083},
	doi = {10.1109/ICDE55515.2023.00083},
	timestamp = {Thu, 01 Aug 2024 19:56:56 +0200},
	biburl = {https://dblp.org/rec/conf/icde/QuZCZH0ZHW23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graph partitioning is crucial in distributed graph-parallel computing systems, and it is challenging for graph partitioning to optimize the communication cost and load balancing together. Existing state-of-the-art works, such as Powerlyra and TopoX, optimize the load balancing by randomly distributing the edges of high-degree vertices, which inevitably brings a high communication cost that is unbounded. This paper proposes a graph partition model that can minimize communication cost while maximizing load balancing. More specifically, we model the graph partition as the combinatorial design problem. Our proposed model can provide high-quality partition that guarantees that the computing load can be evenly distributed to each worker and minimizes the communication cost with a near-optimal theoretical boundary.Based on the proposed model, we extend the hybrid-cut partitioning algorithm for the power-law graph and propose HCPD, a hybrid-cut partitioning algorithm based on combinatorial design. HCPD uses the proposed model to optimize the load balancing and communication cost simultaneously for high-degree vertices, and assigns the high-degree vertices and their low-degree neighbors to the same workers by label propagation to reduce the overall communication cost. In this way, we partition the low-degree and high-degree vertices holistically and further improve the partition quality, unlike Powerlyra and TopoX, which deal with the two parts independently. Our experiments show that HCPD outperforms Powerlyra on PageRank task by up to 2× faster on real-world power-law graphs with billions of edges.}
}


@inproceedings{DBLP:conf/icde/Mu0ZLWSL23,
	author = {Tianyu Mu and
                  Hongzhi Wang and
                  Shenghe Zheng and
                  Zhiyu Liang and
                  Chunnan Wang and
                  Xinyue Shao and
                  Zheng Liang},
	title = {TSC-AutoML: Meta-learning for Automatic Time Series Classification
                  Algorithm Selection},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {1032--1044},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00084},
	doi = {10.1109/ICDE55515.2023.00084},
	timestamp = {Sun, 04 Aug 2024 19:37:46 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Mu0ZLWSL23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With years of development, a significant number of Time Series Classification (TSC) algorithms have been proposed and applied to various fields such as scientific research and industry scenarios, including traditional statistical methods, machine learning methods, and recently deep learning models. However, choosing a suitable model along with good parameter values that perform well on a given task, which is also known as Combined Algorithm Selection and Hyperparameter optimization problem (CASH), is still challenging. How to automatically select the appropriate algorithm according to the task during analyzing is a topic worthy of further research. Nevertheless, for TSC, a field that has been developed for decades, there is no effective and efficient approach for automatic algorithm selection. To the best of our knowledge, the current approach is based on genetic search, which is very computationally intensive and time-consuming. Therefore, in this paper, we propose TSC-AutoML, a zero-configuration and meta-learning-based approach for the automatic Time Series Classification algorithm CASH (also known as TSC-CASH). TSC-AutoML extracts knowledge from historical tasks and performs automatic feature selection and knowledge filtering with a reinforcement learning policy. The experience extracted is filtered and transformed into metadata. The meta-learner trained on the metadata together with our proposed warm start strategy will select an optimal algorithm for tasks uploaded by users, and then our proposed Hyperparameter Optimization method based on the Fast Warm Start strategy searches for hyperparameter combinations of the selected algorithm and adjusts parameter configuration to achieve top performance. The entire process is pre-trained, automated for the new task, and parameter-free for the user to decide, making it easy for users with the little domain experience to get started easily. Experimental results illustrate that TSC-AutoML outperforms existing methods in terms of both time and accuracy of optimum algorithm selection.}
}


@inproceedings{DBLP:conf/icde/WidmoserKAM23,
	author = {Manuel Widmoser and
                  Daniel Kocher and
                  Nikolaus Augsten and
                  Willi Mann},
	title = {MetricJoin: Leveraging Metric Properties for Robust Exact Set Similarity
                  Joins},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {1045--1058},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00085},
	doi = {10.1109/ICDE55515.2023.00085},
	timestamp = {Sun, 04 Aug 2024 19:37:45 +0200},
	biburl = {https://dblp.org/rec/conf/icde/WidmoserKAM23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Given two collections of sets, the set similarity join reports all pairs of sets that are within a given distance threshold. State-of-the-art solutions employ an inverted list index and several heuristics to compute the join result efficiently. Prefix-based solutions benefit from infrequent set elements, known as tokens, and spend considerable time scanning long lists if the token frequency is not sufficiently skewed. Partition-based methods are less sensitive to the token distribution but suffer from a significantly larger memory footprint, limiting their applicability as the threshold or the set sizes grow. Solutions from the domain of metric-based similarity search are designed to reduce the overall number of distance computations. Generic metric techniques cannot compete with state-of-the-art similarity joins tailored to sets, which in turn do not exploit metric filter opportunities.We propose MetricJoin, the first exact set similarity join technique that leverages the metric properties of set distance functions. In contrast to its competitors, MetricJoin is robust, i.e., datasets with different characteristics can be joined efficiently in terms of runtime and memory. Our algorithm embeds sets in vector space, organizes long inverted lists in spatial indexes, and employs an effective metric filter to prune unqualified sets. MetricJoin requires only linear space in the collection size and substantially reduces the number of sets that must be considered. In our performance studies, MetricJoin outperforms state-of-the-art solutions by up to an order of magnitude in runtime and generates up to five orders of magnitude fewer candidates.}
}


@inproceedings{DBLP:conf/icde/HuangHT23,
	author = {Huiqun Huang and
                  Suining He and
                  Mahan Tabatabaie},
	title = {Extreme-Aware Local-Global Attention for Spatio-Temporal Urban Mobility
                  Learning},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {1059--1070},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00086},
	doi = {10.1109/ICDE55515.2023.00086},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/HuangHT23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The occurrence of special contexts or events (e.g., extreme weather conditions, festival events, other urban anomalies) can significantly influence the movement patterns of urban mobility (e.g., human crowds, transportation systems). Accurate mobility modeling and prediction under the occurrences of such anomaly events is therefore imperative for city management and urban resource allocation. In this study, we propose EALGAP, a novel Extreme-Aware Local-Global Attention urban mobility Prediction model. Specifically, EALGAP models the spatio-temporal global and local impacts of mobility in different regions and time steps for mobility prediction at various city regions. EALGAP takes into account the global impacts by extracting the overall or regular spatial dependencies and temporal patterns of mobility systems for different regions. We have designed a temporally-varying normalization and data-driven technique to quantify the extreme degrees, i.e., how significantly the extreme events have impacted the local mobility trend, of the patterns within different regions and time steps. We have conducted ex-tensive experimental studies upon four different mobility datasets (over 13 million trips in total) harvested from two metropolitan cities in U.S. with anomalous natural or social events (e.g., hurricane events, other extreme weather conditions, and the Federal holidays). Our results have demonstrated the accuracy, effectiveness, and extreme-awareness of our proposed EALGAP with more than 44.12% error reduction on average compared with other state-of-the-art approaches.}
}


@inproceedings{DBLP:conf/icde/WangS23,
	author = {Zhikai Wang and
                  Yanyan Shen},
	title = {Incremental Learning for Multi-Interest Sequential Recommendation},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {1071--1083},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00087},
	doi = {10.1109/ICDE55515.2023.00087},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/WangS23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent years, sequential recommendation has been widely researched, which aims to predict the next item of interest based on user’s previously interacted item sequence. Existing works utilize capsule network and self-attention method to explicitly capture multiple underlying interests from a user’s interaction sequence, achieving the state-of-the-art sequential recommendation performance. In practice, the lengths of user interaction sequences are ever-increasing and users might develop new interests from new interactions, and a model should be updated or even expanded continuously to capture the new user interests. We refer to this problem as incremental multi-interest sequential recommendation, which has not yet been well investigated in the existing literature. In this paper, we propose an effective incremental learning framework for multi-interest sequential recommendation called IMSR, which augments the traditional fine-tuning strategy with the existing-interests retainer (EIR), new-interests detector (NID), and projection-based interests trimmer (PIT) to adaptively expand the model to accommodate user’s new interests and prevent it from forgetting user’s existing interests. Extensive experiments on real-world datasets verify the effectiveness of the proposed IMSR on incremental multi-interest sequential recommendation, compared with various baseline approaches.}
}


@inproceedings{DBLP:conf/icde/WangL00J23,
	author = {Kaixin Wang and
                  Cheng Long and
                  Da Yan and
                  Jie Zhang and
                  H. V. Jagadish},
	title = {Reinforcement Learning Enhanced Weighted Sampling for Accurate Subgraph
                  Counting on Fully Dynamic Graph Streams},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {1084--1097},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00088},
	doi = {10.1109/ICDE55515.2023.00088},
	timestamp = {Tue, 22 Oct 2024 20:38:20 +0200},
	biburl = {https://dblp.org/rec/conf/icde/WangL00J23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As the popularity of graph data increases, there is a growing need to count the occurrences of subgraph patterns of interest, for a variety of applications. Many graphs are massive in scale and also fully dynamic (with insertions and deletions of edges), rendering exact computation of these counts to be infeasible. Common practice is, instead, to use a small set of edges as a sample to estimate the counts. Existing sampling algorithms for fully dynamic graphs sample the edges with uniform probability. In this paper, we show that we can do much better if we sample edges based on their individual properties. Specifically, we propose a weighted sampling algorithm called WSD for estimating the subgraph count in a fully dynamic graph stream, which samples the edges based on their weights that indicate their importance and reflect their properties. We determine the weights of edges in a data-driven fashion, using a novel method based on reinforcement learning. We conduct extensive experiments to verify that our technique can produce estimates with smaller errors while often running faster compared with existing algorithms.}
}


@inproceedings{DBLP:conf/icde/ZhongSYS23,
	author = {Yijie Zhong and
                  Zhirong Shen and
                  Zixiang Yu and
                  Jiwu Shu},
	title = {Redesigning High-Performance LSM-based Key-Value Stores with Persistent
                  {CPU} Caches},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {1098--1111},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00089},
	doi = {10.1109/ICDE55515.2023.00089},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhongSYS23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {By providing non-volatility with DRAM-comparable performance, the emerging persistent memory (PMem) is propelling new key-value (KV) store designs. The recently released Intel Optane DC PMem now shifts the persistent boundary from memory up to CPU caches, which further eliminates the needs of cacheline flush instructions used in extensive KV stores. However, we uncover via testbed experiments that this change can even degrade the performance of existing KV stores once directly deploying them atop the new generation of the Optane PMem, stemming mainly from the mismatch of access granularities and heavy software designs.In this paper, we present CacheKV, the first KV store built atop persistent CPU caches. CacheKV allocates per-core sub-MemTable in CPU caches with a lazy index update mechanism, so as to fast absorb incoming writes. It then proposes a copy-based flush mechanism to convert small-sized cacheline evictions into large-sized flushes to suppress the write amplification. CacheKV finally accelerates read operations via periodically compacting the sub-skiplists. Extensive testbed experiments show that CacheKV improves the write throughput by 19.5× on average in the write-dominated environment without compromising the read performance, when compared to the state-of-the-art KV stores for the PMem.}
}


@inproceedings{DBLP:conf/icde/Wu00GTLC23,
	author = {Haolun Wu and
                  Yingxue Zhang and
                  Chen Ma and
                  Wei Guo and
                  Ruiming Tang and
                  Xue Liu and
                  Mark Coates},
	title = {Intent-aware Multi-source Contrastive Alignment for Tag-enhanced Recommendation},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {1112--1125},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00090},
	doi = {10.1109/ICDE55515.2023.00090},
	timestamp = {Sun, 06 Oct 2024 21:04:59 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Wu00GTLC23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {To offer accurate and diverse recommendation services, recent methods use auxiliary information to foster the learning process of user and item representations. Many state-of-the-art (SOTA) methods fuse different sources of information (user, item, knowledge graph, tags, etc.) into a graph and use Graph Neural Networks (GNNs) to introduce the auxiliary information through the message passing paradigm. In this work, we seek an alternative framework that is light and effective through self-supervised learning across different sources of information, particularly for the commonly accessible item tag information. We use a self-supervision signal to pair users with the auxiliary information (tags) associated with the items they have interacted with before. To achieve the pairing, we create a proxy training task. For a given item, the model predicts which is the correct pairing between the representations obtained from the users that have interacted with this item and the tags assigned to it. This design provides an efficient solution, using the auxiliary information directly to enhance the quality of user and item embeddings. User behavior in recommendation systems is driven by the complex interactions of many factors behind the users’ decision-making processes. To make the pairing process more fine-grained and avoid embedding collapse, we propose a user intent-aware self-supervised pairing process where we split the user embeddings into multiple sub-embedding vectors. Each sub-embedding vector captures a specific user intent via self-supervised alignment with a particular cluster of tags. We integrate our designed framework with various recommendation models, demonstrating its flexibility and compatibility. Through comparison with numerous SOTA methods on seven real-world datasets, we show that our method can achieve better performance while requiring less training time. This indicates the potential of applying our approach on web-scale datasets.}
}


@inproceedings{DBLP:conf/icde/ZhangL00ZCFCYX23,
	author = {Guangyu Zhang and
                  Chunhua Li and
                  Ke Zhou and
                  Li Liu and
                  Ce Zhang and
                  Wancheng Chen and
                  Haotian Fang and
                  Bin Cheng and
                  Jie Yang and
                  Jiashu Xing},
	title = {DBCatcher: {A} Cloud Database Online Anomaly Detection System based
                  on Indicator Correlation},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {1126--1139},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00091},
	doi = {10.1109/ICDE55515.2023.00091},
	timestamp = {Tue, 19 Nov 2024 20:28:42 +0100},
	biburl = {https://dblp.org/rec/conf/icde/ZhangL00ZCFCYX23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Anomaly detection system plays an important role in maintaining the stability of cloud database. Existing studies mainly focus on significant deviations in multivariate time series, such as a combination of CPU utilization, transactions per second, etc, to detect abnormal issues. Due to the complexity of cloud database structure and functions, these approaches are difficult to achieve a balance among detection performance, detection efficiency and workload adaptability. In this paper, we propose DBCatcher, a cloud database online anomaly detection system based on indicator correlation. Through extensive analysis of real-world cloud database time series, we find the correlations among trends in the same key performance indicators across databases within the same unit, which inspires us to explore a time series correlation measurement method that can efficiently detect abnormal issues. Meanwhile, we design a flexible time window observation mechanism and an adaptive threshold learning policy to minimize misjudgment caused by key performance indicator fluctuations, greatly enhancing the detection performance and workload adaptability. We conduct extensive experiments under real-world and synthetic workloads. Experimental results show that DBCatcher significantly improves the detection performance and detection efficiency compared to existing methods.}
}


@inproceedings{DBLP:conf/icde/JiangHS00LS23,
	author = {Tian Jiang and
                  Xiangdong Huang and
                  Shaoxu Song and
                  Chen Wang and
                  Jianmin Wang and
                  Ruibo Li and
                  Jincheng Sun},
	title = {Non-Blocking Raft for High Throughput IoT Data},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {1140--1152},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00092},
	doi = {10.1109/ICDE55515.2023.00092},
	timestamp = {Mon, 09 Sep 2024 19:07:30 +0200},
	biburl = {https://dblp.org/rec/conf/icde/JiangHS00LS23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Raft consensus protocol naturally fits time series databases, owing to the resemblance between its continuous log and the time series data. While the serialization of appending entries reduces the state space for ease design and implementation, it blocks the subsequent requests and thus limits the parallelism and throughput of Raft. Intuitively, once an entry arrives the follower, we may notice the leader and the client to unblock the subsequent as early, rather than waiting for its appending and committing. In this way, more requests can be processed in parallel, and thus the throughput increases, essential for IoT applications often with vast sensors and fast data ingestion. Of course, with higher parallelism, the risk of persistence for in-processing entries increases. It is a worthwhile trade-off in the IoT scenario since tiny data loss during leader failure is more acceptable than shutting out most data due to a low throughput. Our Non-Blocking Raft (NB-Raft) is implemented as the consensus protocol of Apache IoTDB, a commodity time series database management system, supporting various applications in Alibaba Cloud. Extensive evaluation shows that the throughput is improved by about 30% using our NB-Raft compared to the original Raft, a considerable amount of further data saved.}
}


@inproceedings{DBLP:conf/icde/GurumurthyBDPS23,
	author = {Bala Gurumurthy and
                  David Broneske and
                  Gabriel Campero Durand and
                  Thilo Pionteck and
                  Gunter Saake},
	title = {{ADAMANT:} {A} Query Executor with Plug-In Interfaces for Easy Co-processor
                  Integration},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {1153--1166},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00093},
	doi = {10.1109/ICDE55515.2023.00093},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/GurumurthyBDPS23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Today’s processor landscape is increasingly heterogeneous with the availability of co-processors. This landscape impacts query engines, as they need to be reworked to keep competitive performance by leveraging the underlying architectures. Such a rework might be costly if, for each external processor or SDK, peripheral components needed to be developed as well; resulting in redundant effort and adoption difficulties. In this paper, we propose an approach to overcome these shortcomings through ADAMANT – a query executor equipped with interfaces to plug-in new co-processors without reworking other components of a query engine. ADAMANT consists of 1) pluggable interfaces that allow interaction with co-processors, encapsulating operator implementations, and 2) a unified runtime that handles the execution on arbitrary co-processors, with a chunked execution model for scalable query processing. To evaluate ADAMANT’s versatility, we plug different implementations of a CPU/GPU-based system (using OpenCL, OpenMP, & CUDA) and analyze their performance on TPC-H queries. We identify a 4x performance difference between an arbitrary chunked execution vs. a more architecturally conscious pipelined execution. Furthermore, our comparisons with HeavyDB show complex performance variations from speed-ups up to a factor of 2x from our hardware-conscious execution. We envision initiatives like ADAMANT to ease the study of complex optimizations required in co-processor systems, paving the way for efficient and portable data management tools without cutbacks.}
}


@inproceedings{DBLP:conf/icde/GaoWZCMWL23,
	author = {Yunjun Gao and
                  Pengfei Wang and
                  Xiaocan Zeng and
                  Lu Chen and
                  Yuren Mao and
                  Ziheng Wei and
                  Miao Li},
	title = {Towards Explainable Table Interpretation Using Multi-view Explanations},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {1167--1179},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00094},
	doi = {10.1109/ICDE55515.2023.00094},
	timestamp = {Mon, 21 Aug 2023 14:38:41 +0200},
	biburl = {https://dblp.org/rec/conf/icde/GaoWZCMWL23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Table interpretation (TI), which aims to predict the column types and relations of tables, plays an essential role in necessary decision-making actions for data management systems. Typically, TI is followed by a manual verification, where experts manually verify the correctness of TI’s predictions. Manual verification is able to ensure the quality of decision-making actions but labor-intensive. To reduce the labour costs, providing explanations for TI’s predictions is necessary as these explanations can help them do faster and more accurate verification. However, existing TI approaches overlook the manual verification process and lack explainability 1 . To fill this gap, this paper explores the challenging explainable table interpretation problem, which aims to provide faithful explanations and meanwhile achieve high prediction performance. Furthermore, we propose ExplainTI framework. ExplainTI consists of two phases: (i) tables are converted to sequences and lightweight column graphs; and (ii) a pre-trained transformer encoder is fine-tuned to provide multi-view explanations and aggregate contextual information. Extensive experiments on both real Web tables and database tables confirm that ExplainTI outperforms competitive baselines. Moreover, systematical analysis of explainability demonstrates that our framework can provide faithful explanations to facilitate the manual verification process.}
}


@inproceedings{DBLP:conf/icde/YangCY0W23,
	author = {Yi Yang and
                  Yurong Cheng and
                  Yeru Yang and
                  Ye Yuan and
                  Guoren Wang},
	title = {Batch-Based Cooperative Task Assignment in Spatial Crowdsourcing},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {1180--1192},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00095},
	doi = {10.1109/ICDE55515.2023.00095},
	timestamp = {Wed, 13 Sep 2023 07:37:48 +0200},
	biburl = {https://dblp.org/rec/conf/icde/YangCY0W23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The rapid development of the spatial crowdsourcing platform in the fields of express delivery, food delivery, and intelligent transportation has attracted widespread attention. As a typical problem in spatial crowdsourcing, online task matching problem has been widely studied. Most of the existing researches are based on the task allocation of different optimizations under one single platform. Recently, in order to solve the situation of non-uniform distribution of tasks and crowd workers on a single platform, cross online task assignment has been proposed aiming at increasing the mutual benefit through cooperations. However, existing methods lead to the situation where the local platform lends workers to other platforms, resulting in a lack of workers of itself. In this paper, we propose a Batch-Based Cooperative Task Assignment(BCTA) problem, which enables multi-platform task assignment to be completed within a tolerant time. We design a BCTA model and propose fixed-t BCTA(FT-BCTA) algorithm and adaptive BCTA(Adt-BCTA) algorithm to solve the BCTA problem. FT-BCTA focuses on a fixed batching strategy, while Adt-BCTA considers the batching strategy adaptively according to the supply and demand of multi-platforms. Extensive experiments on both real datasets and synthetic datasets show the effectiveness and efficiency of our algorithms.}
}


@inproceedings{DBLP:conf/icde/ZhangZCCH023,
	author = {Chenyang Zhang and
                  Feng Zhang and
                  Kuangyu Chen and
                  Mingjun Chen and
                  Bingsheng He and
                  Xiaoyong Du},
	title = {EdgeNN: Efficient Neural Network Inference for {CPU-GPU} Integrated
                  Edge Devices},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {1193--1207},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00096},
	doi = {10.1109/ICDE55515.2023.00096},
	timestamp = {Mon, 05 Feb 2024 20:31:12 +0100},
	biburl = {https://dblp.org/rec/conf/icde/ZhangZCCH023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the development of the architectures and the growth of AIoT application requirements, data processing on edge has become popular. Neural network inference is widely employed for data analytics on edge devices. This paper extensively explores neural network inference on integrated edge devices and proposes EdgeNN, the first neural network inference solution on CPU-GPU integrated edge devices. EdgeNN has three novel characteristics. First, EdgeNN can adaptively utilize the unified physical memory and conduct the zero-copy optimization. Second, EdgeNN involves a novel inference-targeted inter- and intra-kernel CPU-GPU hybrid execution approach, which co-runs the CPU with the GPU to fully utilize the edge device’s computing resources. Third, EdgeNN adopts a fine-grained adaptive inference tuning approach, which can divide the complicated inference structure into sub-tasks mapped to the CPU and the GPU. Experiments show that on six popular neural network inference tasks, EdgeNN brings an average of 3.97×, 3.12×, and 8.80× speedups to inference on the CPU of the integrated device, inference on a mobile phone CPU, and inference on an edge CPU device. Additionally, it achieves 22.02% time benefits to the direct execution of the original programs. Specifically, 9.93% comes from better utilization of unified memory, and 10.76% comes from CPU-GPU hybrid execution. Besides, EdgeNN can deliver 29.14× and 5.70× higher energy efficiency than the edge CPU and the discrete GPU, respectively. We have made EdgeNN available at https://github.com/ChenyangZhang-cs/EdgeNN.}
}


@inproceedings{DBLP:conf/icde/SaxenaGII23,
	author = {Hemant Saxena and
                  Lukasz Golab and
                  Stratos Idreos and
                  Ihab F. Ilyas},
	title = {Real-Time LSM-Trees for {HTAP} Workloads},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {1208--1220},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00097},
	doi = {10.1109/ICDE55515.2023.00097},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/SaxenaGII23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Real-time analytics systems employ hybrid data layouts in which data are stored in different formats throughout their lifecycle. Recent data are stored in a row-oriented format to serve OLTP workloads and support high insert rates, while older data are transformed to a column-oriented format for OLAP access patterns. We observe that a Log-Structured Merge (LSM) Tree is a natural fit for a lifecycle-aware storage engine due to its high write throughput and level-oriented structure, in which records propagate from one level to the next over time. To build a lifecycle-aware storage engine using an LSM-Tree, we make a crucial modification to allow different data layouts in different levels, ranging from purely row-oriented to purely column-oriented, leading to a Real-Time LSM-Tree. We give a cost model and an algorithm to design a Real-Time LSM-Tree that is suitable for a given workload, followed by an experimental evaluation of LASER - a prototype implementation of our idea built on top of the RocksDB key-value store.}
}


@inproceedings{DBLP:conf/icde/GengCPCJZC23,
	author = {Yuxia Geng and
                  Jiaoyan Chen and
                  Jeff Z. Pan and
                  Mingyang Chen and
                  Song Jiang and
                  Wen Zhang and
                  Huajun Chen},
	title = {Relational Message Passing for Fully Inductive Knowledge Graph Completion},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {1221--1233},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00098},
	doi = {10.1109/ICDE55515.2023.00098},
	timestamp = {Mon, 03 Jun 2024 15:23:14 +0200},
	biburl = {https://dblp.org/rec/conf/icde/GengCPCJZC23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In knowledge graph completion (KGC), predicting triples involving emerging entities and/or relations, which are unseen when the KG embeddings are learned, has become a critical challenge. Subgraph reasoning with message passing is a promising and popular solution. Some recent methods have achieved good performance, but they (i) usually can only predict triples involving unseen entities alone, failing to address more realistic fully inductive situations with both unseen entities and unseen relations, and (ii) often conduct message passing over the entities with the relation patterns not fully utilized. In this study, we propose a new method named RMPI which uses a novel Relational Message Passing network for fully Inductive KGC. It passes messages directly between relations to make full use of the relation patterns for subgraph reasoning with new techniques on graph transformation, graph pruning, relation-aware neighborhood attention, addressing empty subgraphs, etc., and can utilize the relation semantics defined in the KG’s ontological schema. Extensive evaluation on multiple benchmarks has shown the effectiveness of RMPI’s techniques and its better performance compared with the existing methods that support fully inductive KGC. RMPI is also comparable to the state-of-the-art partially inductive KGC methods with very promising results achieved. Our codes, data and some supplementary experiment results are available at https://github.com/zjukg/RMPI.}
}


@inproceedings{DBLP:conf/icde/ZhangHSCJFZLW23,
	author = {Haodi Zhang and
                  Wenxi Huang and
                  Zhenhan Su and
                  Junyang Chen and
                  Di Jiang and
                  Lixin Fan and
                  Chen Zhang and
                  Defu Lian and
                  Kaishun Wu},
	title = {Hierarchical Crowdsourcing for Data Labeling with Heterogeneous Crowd},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {1234--1246},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00099},
	doi = {10.1109/ICDE55515.2023.00099},
	timestamp = {Mon, 04 Nov 2024 08:18:05 +0100},
	biburl = {https://dblp.org/rec/conf/icde/ZhangHSCJFZLW23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the rapid and continuous development of data-driven technologies such as supervised learning, high-quality labeled data sets are commonly required by many applications. Due to the easiness of crowdsourcing small tasks with low cost, a straightforward solution for label quality improvement is to collect multiple labels from a crowd, and then aggregate the answers. The aggregation strategies include majority voting and its many variants, EM-based approaches, Graph Neural Nets and so on. However, due to the uncertainty information loss and commonly existing task correlations, the aggregated labels usually contain errors and may damnify the downstream model training.To address the above problem, we propose a hierarchical crowdsourcing framework 1 for data labeling with noisy answers about correlated data. We make use of the heterogeneity of the labeling crowd and form an initialization-checking-update loop to improve the quality of labeled data. We formalize and successfully solve the core optimization problem, namely, selecting a proper set of checking tasks for each round. We prove that maximizing the expected quality improvement is equivalent to minimizing the conditional entropy of the observations given the crowdsourced answer families for the selected task set, which is NP-hard to solve. Therefore, we design an efficient approximation algorithm and conduct a series of experiments on real data. The experimental results show that the proposed method effectively improves the quality of the labeled data sets as well as the SOTA performance, yet without extra human labor costs.}
}


@inproceedings{DBLP:conf/icde/ZhouL0M23,
	author = {Xin Zhou and
                  Donghui Lin and
                  Yong Liu and
                  Chunyan Miao},
	title = {Layer-refined Graph Convolutional Networks for Recommendation},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {1247--1259},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00100},
	doi = {10.1109/ICDE55515.2023.00100},
	timestamp = {Mon, 14 Aug 2023 16:36:38 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhouL0M23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recommendation models utilizing Graph Convolutional Networks (GCNs) have achieved state-of-the-art performance, as they can integrate both the node information and the topological structure of the user-item interaction graph. However, these GCN-based recommendation models not only suffer from over-smoothing when stacking too many layers but also bear performance degeneration resulting from the existence of noise in user-item interactions. In this paper, we first identify a recommendation dilemma of over-smoothing and solution collapsing in current GCN-based models. Specifically, these models usually aggregate all layer embeddings for node updating and achieve their best recommendation performance within a few layers because of over-smoothing. Conversely, if we place learnable weights on layer embeddings for node updating, the weight space will always collapse to a fixed point, at which the weighting of the ego layer almost holds all. We propose a layer-refined GCN model, dubbed LayerGCN, that refines layer representations during information propagation and node updating of GCN. Moreover, previous GCN-based recommendation models aggregate all incoming information from neighbors without distinguishing the noise nodes, which deteriorates the recommendation performance. Our model further prunes the edges of the user-item interaction graph following a degree-sensitive probability instead of the uniform distribution. Experimental results show that the proposed model outperforms the state-of-the-art models significantly on four public datasets with fast training convergence. The implementation code of the proposed method is available at https://github.com/enoche/ImRec.}
}


@inproceedings{DBLP:conf/icde/Wu0SGKO23,
	author = {Huizi Wu and
                  Hui Fang and
                  Zhu Sun and
                  Cong Geng and
                  Xinyu Kong and
                  Yew{-}Soon Ong},
	title = {A Generic Reinforced Explainable Framework with Knowledge Graph for
                  Session-based Recommendation},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {1260--1272},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00101},
	doi = {10.1109/ICDE55515.2023.00101},
	timestamp = {Thu, 30 May 2024 00:10:53 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Wu0SGKO23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Session-based recommendation (SR) has gained increasing attention in recent years. Quite a great amount of studies have been devoted to designing complex algorithms to improve recommendation performance, where deep learning methods account for the majority. However, most of these methods are black-box ones and ignore to provide moderate explanations to facilitate users’ understanding, which thus might lead to lowered user satisfaction and reduced system revenues. Therefore, in our study, we propose a generic Reinforced Explainable framework with Knowledge graph for Session-based recommendation (i.e., REKS), which strives to improve the existing black-box SR models (denoted as non-explainable ones) with Markov decision process. In particular, we construct a knowledge graph with session behaviors and treat SR models as part of the policy network of Markov decision process. Based on our particularly designed state vector, reward strategy, and loss function, the reinforcement learning (RL)-based framework not only achieves improved recommendation accuracy, but also provides appropriate explanations at the same time. Finally, we instantiate the REKS in five representative, state-of-the-art SR models (i.e., GRU4REC, NARM, SR-GNN, GCSAN, BERT4REC), whereby extensive experiments towards these methods on four datasets demonstrate the effectiveness of our framework on both recommendation and explanation tasks.}
}


@inproceedings{DBLP:conf/icde/ZhangZWY23,
	author = {Lingling Zhang and
                  Zhiwei Zhang and
                  Guoren Wang and
                  Ye Yuan},
	title = {Efficiently Sampling and Estimating Hypergraphs By Hybrid Random Walk},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {1273--1285},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00102},
	doi = {10.1109/ICDE55515.2023.00102},
	timestamp = {Thu, 10 Oct 2024 07:59:37 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhangZWY23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Hypergraphs provide a powerful tool for representing group interactions in complicated networks. Analyzing statical properties of hypergraphs by sampling is an increasing fundamental research problem in the field of data processing. However, the state-of-the-art sampling methods either focus on pairwise graphs or are insensitive to the structures formed by vertices and hyperedges, resulting in estimations with low accuracy and efficiency. To efficiently characterize the properties of both vertices and hyperedges, this paper first proposes a hybrid random walk based Markov Chain Monte Carlo (MCMC) model theoretically by carefully designing its mixture states and the transition matrix. For simplifying the implementation of this model, we develop an algorithm formed by vertex and hyperedge transitions saving costs for constructing mixture states in practice along with an estimating method for accurate estimations. Furthermore, we employ a non-backtracking strategy in the vertex transitions to accelerate the convergence of the hybrid random walk and propose to skip the sampled vertices in the hyperedge transitions to avoid being trapped in the local subgraph for improving accuracy and reducing query cost. Extensive experimental results on the real-world datasets confirm the higher accuracy and efficiency of our proposed methods than the sophisticated sampling methods.}
}


@inproceedings{DBLP:conf/icde/TonshoffFGK23,
	author = {Jan T{\"{o}}nshoff and
                  Neta Friedman and
                  Martin Grohe and
                  Benny Kimelfeld},
	title = {Stable Tuple Embeddings for Dynamic Databases},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {1286--1299},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00103},
	doi = {10.1109/ICDE55515.2023.00103},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/TonshoffFGK23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We study the problem of computing an embedding of the tuples of a relational database in a manner that is extensible to dynamic changes of the database. In this problem, the embedding should be stable in the sense that it should not change on the existing tuples due to the embedding of newly inserted tuples (as database applications might already rely on existing embeddings); at the same time, the embedding of all tuples, old and new, should retain high quality. This task is challenging since inter-dependencies among the embeddings of different entities are inherent in state-of-the-art embedding techniques for structured data.We study two approaches to solving the problem. The first is an adaptation of Node2Vec to dynamic databases. The second is the FoRWaRD algorithm (Foreign Key Random Walk Embeddings for Relational Databases) that draws from embedding techniques for general graphs and knowledge graphs, and is inherently utilizing the schema and its key and foreign-key constraints. We evaluate the embedding algorithms using a collection of downstream tasks of column prediction over geographical and biological domains. We find that in the traditional static setting, our two embedding methods achieve comparable results that are compatible with the state-of-the-art for the specific applications. In the dynamic setting, we find that the FoRWaRD algorithm generally outperforms and runs faster than the alternatives, and moreover, it features only a mild reduction of quality even when the database consists of more than half newly inserted tuples after the initial training of the embedding.}
}


@inproceedings{DBLP:conf/icde/XuW23,
	author = {Jianqiu Xu and
                  Raymond Chi{-}Wing Wong},
	title = {Efficiently Answering Top-k Window Aggregate Queries: Calculating
                  Coverage Number Sequences over Hierarchical Structures},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {1300--1312},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00104},
	doi = {10.1109/ICDE55515.2023.00104},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/XuW23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Given a set of spatio-temporal objects, a top-k window aggregate query reports top-k tuples that are ordered with respect to the number of objects during a given time interval and within a spatial range. For example, when analyzing traffic density in a city, one wishes to retrieve top-k time intervals in a certain area that are decreasingly ordered according to the number of vehicles passing by. As simply performing sequential scan over all objects is a costly procedure, an index structure is typically built to enhance the query performance. A crucial step during the evaluation is to determine the number of objects in an arbitrary node, called coverage number sequence. This is a challenging task since objects appear and disappear at different time points such that the number of objects in the query node changes over time. Also, as a hierarchical index structure, the value of a node at high level is achieved by performing the aggregation over its child nodes. Simply enumerating all objects rooted in the query node suffers from performance issues mainly due to (i) traversing the sub-tree to retrieve a large number of time points and (ii) repeatedly performing the aggregation at certain time points. We propose an efficient approach to solve the performance issue for both R-tree and Octree and support updating for new arrival data objects being inserted into the index. Our approach outperforms alternative methods in general according to a thorough analysis on the complexity. Coverage number sequences as well as proposed optimization techniques are utilized to enhance the performance of window aggregate queries. We confirm the superiority of our approach over alternative methods by performing a comprehensive experimental evaluation over large real datasets in a database system.}
}


@inproceedings{DBLP:conf/icde/Sun0W0Z023,
	author = {Renjie Sun and
                  Chen Chen and
                  Xiaoyang Wang and
                  Wenjie Zhang and
                  Ying Zhang and
                  Xuemin Lin},
	title = {Efficient Maximum Signed Biclique Identification},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {1313--1325},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00105},
	doi = {10.1109/ICDE55515.2023.00105},
	timestamp = {Tue, 07 May 2024 20:05:37 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Sun0W0Z023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Maximum biclique identification, which aims to find the biclique with the largest size, can find a wide spectrum of applications in different domains, such as E-Commerce, healthcare and bioinformatics. However, the previous studies mainly focus on unsigned bipartite graphs. The signed information naturally exists in real applications, such as like and dislike. The neglect of signed information may fail to discover the inherent properties of networks. In this paper, we propose a novel model, named signed (k,l)-biclique (SKLB), by enforcing constraints over the number of positive and negative connections. Specifically, given a signed bipartite graph and two positive integers k,l, SKLB is a biclique, where each vertex has no less than k positive neighbors and no more than l negative neighbors. We prove the problem of finding the maximum signed (k,l)-biclique (MaxSKLB) is NP-hard. Moreover, we show that the problem is still NP-hard, even if the input graph is a biclique itself. A baseline algorithm is first presented through biclique enumeration, which tries to find the MaxSKLB for each encountered biclique and return the largest one. However, considering that the extraction of MaxSKLB from a biclique is still NP-hard, a greedy strategy is developed to accelerate the processing with competitive result. Furthermore, to efficiently handle large graphs, we optimize the algorithm from different perspectives, including unnecessary search branches and unpromising vertices filtering. Finally, comprehensive experiments are conducted over 10 graphs to validate the efficiency and effectiveness of proposed techniques and model.}
}


@inproceedings{DBLP:conf/icde/PaponA23,
	author = {Tarikul Islam Papon and
                  Manos Athanassoulis},
	title = {ACEing the Bufferpool Management Paradigm for Modern Storage Devices},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {1326--1339},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00106},
	doi = {10.1109/ICDE55515.2023.00106},
	timestamp = {Sun, 12 Nov 2023 02:08:09 +0100},
	biburl = {https://dblp.org/rec/conf/icde/PaponA23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Over the past few decades, solid-state drives (SSDs) have been replacing hard disk drives (HDDs) due to their faster reads and writes, as well as their superior random access performance. Further, when compared to HDDs, SSDs have two fundamentally different properties: (i) read/write asymmetry (writes are slower than reads) and (ii) access concurrency (multiple I/Os can be executed in parallel to saturate the device bandwidth). However, several database operators are designed without considering storage asymmetry and concurrency resulting in device underutilization, which is typically addressed opportunistically by device-specific tuning during deployment. As a key example and the focus of our work, the bufferpool management of a Database Management System (DBMS) is tightly connected to the underlying storage device, yet, state-of-the-art approaches treat reads and writes equally, and do not expressly exploit the device concurrency, leading to subpar performance.In this paper, we propose a new Asymmetry & Concurrency-aware bufferpool management (ACE) that batches writes based on device concurrency and performs them in parallel to amortize the asymmetric write cost. In addition, ACE performs parallel prefetching to exploit the device’s read concurrency. ACE does not modify the existing bufferpool replacement policy, rather, it is a wrapper that can be integrated with any replacement policy. We implement ACE in PostgreSQL and evaluate its benefits using a synthetic benchmark and TPC-C for several popular eviction policies (Clock Sweep, LRU, CFLRU, LRU-WSR). The ACE counterparts of all four policies lead to significant performance improvements, exhibiting up to 32.1% lower runtime for mixed workloads (33.8% for write-intensive TPC-C transactions) with a negligible increase in total disk writes and buffer misses, which shows that incorporating asymmetry and concurrency in algorithm design leads to more faithful storage modeling and, ultimately, to better device utilization.}
}


@inproceedings{DBLP:conf/icde/CuiLDZZ0023,
	author = {Yue Cui and
                  Shuhao Li and
                  Wenjin Deng and
                  Zhaokun Zhang and
                  Jing Zhao and
                  Kai Zheng and
                  Xiaofang Zhou},
	title = {ROI-demand Traffic Prediction: {A} Pre-train, Query and Fine-tune
                  Framework},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {1340--1352},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00107},
	doi = {10.1109/ICDE55515.2023.00107},
	timestamp = {Mon, 26 Aug 2024 13:33:33 +0200},
	biburl = {https://dblp.org/rec/conf/icde/CuiLDZZ0023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Traffic prediction has drawn increasing attention due to its essential role in smart city applications. To achieve precise predictions, a large number of approaches have been proposed to model spatial dependencies and temporal dynamics. Despite their superior performance, most existing studies focus datasets that are usually in large geographic scales, e.g., citywide, while ignoring the results on specific regions. However, in many scenarios, for example, route planning on time-dependent road networks, only small regions are of interest. We name the task of answering forecasting requests from any query region of interest (ROI) as ROI-demand traffic prediction (RTP). In this paper, we make a primary observation that existing methods fail to jointly achieve effectiveness and efficiency for RTP. To address this issue, a novel model-agnostic framework based on pre-Training, Querying and fine-Tuning, named TQT, is proposed, which first customizes input data given an ROI, and then makes fast adaptation from pre-trained traffic prediction backbone models by fine-tuning. We evaluate TQT on two real-world traffic datasets, performing both flow and speed prediction tasks. Extensive experiment results demonstrate the effectiveness and efficiency of the proposed method.}
}


@inproceedings{DBLP:conf/icde/PengM0GY23,
	author = {Huanhuan Peng and
                  Xiaoye Miao and
                  Lu Chen and
                  Yunjun Gao and
                  Jianwei Yin},
	title = {Pricing Prediction Services for Profit Maximization with Incomplete
                  Information},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {1353--1365},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00108},
	doi = {10.1109/ICDE55515.2023.00108},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/PengM0GY23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Trading the machine learning-based prediction services has been up-and-coming for individuals and small companies. It serves to directly provide the predictions, e.g., classifications, for consumers without domain knowledge. Existing prediction service pricing methods closely rely on the strong assumption of completely known information on service quality and consumers’ valuations. In this paper, we study the profit maximization problem of pricing prediction services under incomplete information for the first time. We propose a novel Service Market model, named SMELT, considering multiple types of customers with dEmand and quaLity-aware valuaTions. We first derive the theoretical optimal solution to maximize service profit with complete information. Then, we develop an effective framework PSPricer under the profit ratio guarantee to solve the profit maximization problem with incomplete information. It is capable of not only efficiently getting the sub-optimal service price with bounded revenue loss, but also effectively estimating the service quality function with the maximum likelihood estimation. Extensive experiments on real-life datasets demonstrate our theoretical findings and the effectiveness and efficiency of PSPricer, compared with the state-of-the-art approaches.}
}


@inproceedings{DBLP:conf/icde/ChenHDLLTYX23,
	author = {Qi Chen and
                  Hao Hu and
                  Cai Deng and
                  Dingbang Liu and
                  Shiyi Li and
                  Bo Tang and
                  Ting Yao and
                  Wen Xia},
	title = {{EEPH:} An Efficient Extendible Perfect Hashing for Hybrid PMem-DRAM},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {1366--1378},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00109},
	doi = {10.1109/ICDE55515.2023.00109},
	timestamp = {Mon, 05 Feb 2024 20:31:13 +0100},
	biburl = {https://dblp.org/rec/conf/icde/ChenHDLLTYX23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent years, the performance of hash indexes has been significantly improved by exploiting emerging persistent memory (PMem). However, the performance improvement of hash indexes mainly comes from exploiting the hardware features of PMem. Only a few studies optimize the hash index itself to fully exploit the potential of PMem. Interestingly, many of these studies improve the performance of write, but disregard the performance of read, of hash indexes on PMem. With extensive experimental evaluation, we find the major reason for inefficient read in the hash index on PMem is that the overhead of hash collision processing is expensive.To address that, we propose a novel Efficient Extendible Perfect Hashing (EEPH) on PMem-DRAM hybrid data layout to improve read performance of hash indexes. Specifically, we reduce the overhead of dynamic perfect hashing extension on PMem by combing extendible hashing. We then design a hybrid data layout to unlock the inherent read strengths of perfect hashing (i.e., zero collision). Last, we devise a complement move algorithm to efficiently guarantee the zero collision of perfect hashing when data move is conducted on PMem. We compare EEPH with the state-of-the-art hash indexes on PMem by conducting comprehensive experiments on several real-world read-intensive and read-skew workloads. The experimental results confirm the superiority of our EEPH as it achieves up to 2.21× higher throughput and about 1/3 of the 99th percentile latency than state-of-the-art hash indexes.}
}


@inproceedings{DBLP:conf/icde/ChaoK023,
	author = {Daren Chao and
                  Nick Koudas and
                  Xiaohui Yu},
	title = {Marshalling Model Inference in Video Streams},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {1379--1392},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00110},
	doi = {10.1109/ICDE55515.2023.00110},
	timestamp = {Mon, 05 Feb 2024 20:31:13 +0100},
	biburl = {https://dblp.org/rec/conf/icde/ChaoK023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Numerous cloud platforms are available to deploy and train deep models as well as process data, such as Amazon Rekognition and Azure custom Vision Service, which have made it easy for companies to adopt deep learning technologies in their operations. Commonly such services price usage per image or frame in typical applications that consume video streams and as a result the costs rapidly accumulate. In this paper we introduce a model, named EventHit, that is able to marshal model inference requests in such services by making predictions over the video stream about events of interest. As such only relevant video segments are sent for analysis to the cloud infrastructure and irrelevant parts are filtered from further processing. We introduce the architecture and fully describe its components. We present two novel optimizations in this context that aim to provide control over the trade-off between prediction accuracy (especially regarding the probability of missing an event of interest) and processing cost at the cloud infrastructure. We fully describe and analyze our proposals in the context of real datasets. We also present the results of a detailed experimental evaluation varying parameters of interest and demonstrate the practical utility of our proposals.}
}


@inproceedings{DBLP:conf/icde/BreveCCDP23,
	author = {Bernardo Breve and
                  Loredana Caruccio and
                  Stefano Cirillo and
                  Vincenzo Deufemia and
                  Giuseppe Polese},
	title = {IndiBits: Incremental Discovery of Relaxed Functional Dependencies
                  using Bitwise Similarity},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {1393--1405},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00111},
	doi = {10.1109/ICDE55515.2023.00111},
	timestamp = {Tue, 07 May 2024 20:05:37 +0200},
	biburl = {https://dblp.org/rec/conf/icde/BreveCCDP23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {One of the main challenges in data profiling is to efficiently extract metadata from dynamic information sources, by avoiding the processing of the whole dataset from scratch upon modifications. In this paper, we present IndiBits, an algorithm for discovering relaxed functional dependencies (RFDs for short), which represent data relationships relying on approximate matching paradigms. IndiBits is able to dynamically infer and update the RFDs holding on a dataset upon modification operations performed on it. It exploits a binary representation of data similarities, a new validation method, and specific search methods, to dynamically update the set of RFDs, based on previously holding RFDs and the type of modifications performed over data. Experimental results demonstrate the effectiveness of IndiBits on real-world datasets, even in comparison with FD and RFD discovery algorithms in both static and dynamic scenarios.}
}


@inproceedings{DBLP:conf/icde/ZhuGGZL23,
	author = {Haoren Zhu and
                  Hao Ge and
                  Xiaodong Gu and
                  Pengfei Zhao and
                  Dik Lun Lee},
	title = {Influential Recommender System},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {1406--1419},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00112},
	doi = {10.1109/ICDE55515.2023.00112},
	timestamp = {Mon, 31 Jul 2023 08:35:14 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhuGGZL23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Traditional recommender systems are typically passive in that they try to adapt their recommendations to the user’s historical interests. However, it is highly desirable for commercial applications, such as e-commerce, advertisement placement, and news portals, to be able to expand the users’ interests so that they would accept items that they were not originally aware of or interested in to increase customer interactions. In this paper, we present Influential Recommender System (IRS), a new recommendation paradigm that aims to proactively lead a user to like a given objective item by progressively recommending to the user a sequence of carefully selected items (called an influence path). We propose the Influential Recommender Network (IRN), which is a Transformer-based sequential model to encode the items’ sequential dependencies. Since different people react to external influences differently, we introduce the Personalized Impressionability Mask (PIM) to model how receptive a user is to external influence to generate the most effective influence path for the user. To evaluate IRN, we design several performance metrics to measure whether or not the influence path can smoothly expand the user interest to include the objective item while maintaining the user’s satisfaction with the recommendation. Experimental results show that IRN significantly outperforms the baseline recommenders and demonstrates its capability of influencing users’ interests.}
}


@inproceedings{DBLP:conf/icde/RenZ0GZ023,
	author = {Tianyue Ren and
                  Xu Zhou and
                  Kenli Li and
                  Yunjun Gao and
                  Ji Zhang and
                  Keqin Li},
	title = {Efficient Cross Dynamic Task Assignment in Spatial Crowdsourcing},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {1420--1432},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00113},
	doi = {10.1109/ICDE55515.2023.00113},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/RenZ0GZ023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As a novel intelligent sensing paradigm, spatial crowdsourcing has received extensive attention. Task assignment is a key issue in spatial crowdsourcing. In practice, tasks are unevenly distributed in time and space. Accordingly, the problem of cross task assignment attracts growing attention in both industry and academia. Although there has been a research on this problem, it focuses only on maximizing total revenues for inner platforms. Therefore, it can also be improved to bring a multi-win situation for outer workers and task requesters as well as the inner platform. Inspired by this, we first formulate a new cross dynamic task assignment (CDTA) problem by introducing the reputation scores of workers, and prove it to be NP-hard. For the CDTA problem, a hybrid batch-based framework is presented on the basis of a new cross-platform incentive mechanism and a hybrid batch processing strategy, which are efficient in solving the problem of uneven spatial and time distribution of tasks, respectively. After that, a KM-based algorithm and a density-aware greedy algorithm are proposed to gain an accurate assignment result of tasks in each batch and good performance, respectively. Furthermore, the CDTA problem is modeled as a potential game that is proven to have at least a pure Nash Equilibrium theoretically. Last but not least, a game-theoretic approach is developed to maximize the revenues of the inner platform and outer workers at the same time. Extensive experiments on both real and synthetic datasets are conducted to demonstrate the effectiveness and efficiency of the proposed algorithms.}
}


@inproceedings{DBLP:conf/icde/DablainBKC23,
	author = {Damien A. Dablain and
                  Colin Bellinger and
                  Bartosz Krawczyk and
                  Nitesh V. Chawla},
	title = {Efficient Augmentation for Imbalanced Deep Learning},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {1433--1446},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00114},
	doi = {10.1109/ICDE55515.2023.00114},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/DablainBKC23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Deep learning models may not effectively generalize across under-represented or minority classes. We empirically study a convolutional neural network’s (CNN) internal representation of imbalanced image data and measure the generalization gap between a model’s feature embeddings in the training and test sets, showing that the gap is wider for minority classes. This insight enables us to design an efficient three-phase CNN training framework for imbalanced data. The framework involves training the network end-to-end on imbalanced data to learn feature embeddings, performing data augmentation in the learned embedding space to balance the training data distribution, and fine-tuning the classifier head on the embedded balanced training data. We develop Expansive Over-Sampling (EOS) as a data augmentation technique to utilize in the training framework. EOS forms synthetic training instances as convex combinations between the minority class samples and their nearest adversaries in the embedding space to reduce the generalization gap. The proposed framework improves the accuracy over leading cost-sensitive and resampling methods commonly used in imbalanced learning. Moreover, it is more computationally efficient than standard data pre-processing methods, such as SMOTE and GAN-based over-sampling, as it requires fewer parameters and less training time. The source code for the proposed framework is available at: https://github.com/dd1github/EOS.}
}


@inproceedings{DBLP:conf/icde/SahaK0L23a,
	author = {Arkaprava Saha and
                  Xiangyu Ke and
                  Arijit Khan and
                  Cheng Long},
	title = {Most Probable Densest Subgraphs},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {1447--1460},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00115},
	doi = {10.1109/ICDE55515.2023.00115},
	timestamp = {Tue, 22 Oct 2024 20:38:20 +0200},
	biburl = {https://dblp.org/rec/conf/icde/SahaK0L23a.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Computing the densest subgraph is a primitive graph operation with critical applications in detecting communities, events, and anomalies in biological, social, Web, and financial networks. In this paper, we study the novel problem of Most Probable Densest Subgraph (MPDS) discovery in uncertain graphs: Find the node set that is the most likely to induce a densest subgraph in an uncertain graph. We further extend our problem by considering various notions of density, e.g., clique and pattern densities, studying the top-k MPDSs, and finding the node set with the largest containment probability within densest subgraphs. We show that it is #P-hard to compute the probability of a node set inducing a densest subgraph. We then devise sampling-based efficient algorithms, with end-to-end accuracy guarantees, to compute the MPDS. Our thorough experimental results and real-world case studies on brain and social networks validate the effectiveness, efficiency, and usefulness of our solution.}
}


@inproceedings{DBLP:conf/icde/RahmanD0ULC23,
	author = {Md Hasanur Rahman and
                  Sheng Di and
                  Kai Zhao and
                  Robert Underwood and
                  Guanpeng Li and
                  Franck Cappello},
	title = {A Feature-Driven Fixed-Ratio Lossy Compression Framework for Real-World
                  Scientific Datasets},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {1461--1474},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00116},
	doi = {10.1109/ICDE55515.2023.00116},
	timestamp = {Tue, 16 Jul 2024 16:34:10 +0200},
	biburl = {https://dblp.org/rec/conf/icde/RahmanD0ULC23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Today’s scientific applications and advanced instruments are producing extremely large volumes of data everyday, so that error-controlled lossy compression has become a critical technique to the scientific data storage and management. Existing lossy scientific data compressors, however, are designed mainly based on error-control driven mechanism, which cannot be efficiently applied in the fixed-ratio use-case, where a desired compression ratio needs to be reached because of the restricted data processing/management resources such as limited memory/storage capacity and network bandwidth. To address this gap, we propose a low-cost compressor-agnostic feature-driven fixed-ratio lossy compression framework (FXRZ). The key contributions are three-fold. (1) We perform an in-depth analysis of the correlation between diverse data features and compression ratios based on a wide range of application datasets, which is a fundamental work for our framework. (2) We propose a series of optimization strategies that can enable the framework to reach a fairly high accuracy in identifying the expected error configuration with very low computational cost. (3) We comprehensively evaluate our framework using 4 state-of-the-art error-controlled lossy compressors on 10 different snapshots and simulation configuration-based real-world scientific datasets from 4 different applications across different domains. Our experiment shows that FXRZ outperforms the state-of-the-art related work by 108×. The experiments with 4,096 cores on a supercomputer show a performance gain of 1.18∼8.71× than the related work in overall parallel data dumping.}
}


@inproceedings{DBLP:conf/icde/RamanSOA23,
	author = {Aneesh Raman and
                  Subhadeep Sarkar and
                  Matthaios Olma and
                  Manos Athanassoulis},
	title = {Indexing for Near-Sorted Data},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {1475--1488},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00117},
	doi = {10.1109/ICDE55515.2023.00117},
	timestamp = {Sun, 12 Nov 2023 02:08:10 +0100},
	biburl = {https://dblp.org/rec/conf/icde/RamanSOA23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Indexing in modern data systems facilitates efficient query processing when the selection predicate is on an indexed key. As new data is ingested, indexes are gradually populated with incoming entries. In that respect, indexing can be perceived as the process of adding structure to incoming, otherwise unsorted data. Adding structure, however, comes at a cost. Instead of simply appending the incoming entries, we insert them into the index. If the ingestion order matches the indexed attribute order, the ingestion cost is entirely redundant and can be avoided altogether (e.g., via bulk loading in a B + -tree). However, classical tree index designs do not benefit when incoming data comes with an implicit ordering that is close to being sorted, but not fully sorted.In this paper, we study how indexes can exploit near-sortedness. Particularly, we identify sortedness as a resource that can accelerate index ingestion. We propose a new sortedness-aware (SWARE) design paradigm that combines opportunistic bulk loading, index appends, variable node fill and split factors, and an intelligent buffering scheme, to optimize ingestion and read queries in a tree index in the presence of near-sortedness. We apply SWARE to two state-of-the-art search trees (B + -tree and B ϵ -tree), and we demonstrate that their Sortedness-Aware counterparts (SA B + -tree and SA B ϵ -tree) outperform their respective baselines by up to 8.8× (SA B+-tree) and 7.8× (SA B ϵ -tree) for a write-heavy workload in the presence of data sortedness, while offering competitive read performance, leading to overall benefits between 1.3× – 5× for mixed read/write workloads with near-sorted data. Overall, we highlight that SWARE can be applied to other tree-like data structures to accelerate index ingestion and improve their performance in the presence of data sortedness.}
}


@inproceedings{DBLP:conf/icde/BenouaretT23,
	author = {Karim Benouaret and
                  Kian{-}Lee Tan},
	title = {Probabilistic Majority Rule-Based Group Recommendation},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {1489--1501},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00118},
	doi = {10.1109/ICDE55515.2023.00118},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/BenouaretT23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Group recommendation has received increased attention over the past decade. The fundamental challenge in group recommendation is how to aggregate the preferences of group members to select a set of items maximizing the overall satisfaction of the group. Different aggregation methods with different semantics have been proposed. In this paper, we explore a novel semantics of group recommendation, that is, probabilistic majority rule, allowing group members to make a "democratic" decision on which items are appropriate. Specifically, we propose a probabilistic model that captures the probability that a given item satisfies the majority of the group. We show that the naive strategy for computing such a probability is exponential time complexity, and propose an efficient dynamic programming approach to avoid this shortcoming. Furthermore, we design and develop an efficient algorithm, which leverages effective pruning techniques, for recommending the k items with the highest majority satisfaction probabilities. Finally, we demonstrate both the retrieval effectiveness and the efficiency of our approach through extensive experimental evaluation on real datasets.}
}


@inproceedings{DBLP:conf/icde/Wang0023,
	author = {Runhui Wang and
                  Yuliang Li and
                  Jin Wang},
	title = {Sudowoodo: Contrastive Self-supervised Learning for Multi-purpose
                  Data Integration and Preparation},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {1502--1515},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00391},
	doi = {10.1109/ICDE55515.2023.00391},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Wang0023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Machine learning (ML) is playing an increasingly important role in data management tasks, particularly in Data Integration and Preparation (DI&P). The success of ML-based approaches, however, heavily relies on the availability of large-scale, high-quality labeled datasets for different tasks. Moreover, the wide variety of DI&P tasks and pipelines oftentimes requires customizing ML solutions at a significant cost for model engineering and experimentation. These factors inevitably hold back the adoption of ML-based approaches to new domains and tasks.In this paper, we propose Sudowoodo, a multi-purpose DI&P framework based on contrastive representation learning. Sudowoodo features a unified, matching-based problem definition capturing a wide range of DI&P tasks including Entity Matching (EM) in data integration, error correction in data cleaning, semantic type detection in data discovery, and more. Contrastive learning enables Sudowoodo to learn similarity-aware data representations from a large corpus of data items (e.g., entity entries, table columns) without using any labels. The learned representations can later be either directly used or facilitate fine-tuning with only a few labels to support different DI&P tasks. Our experiment results show that Sudowoodo achieves multiple state-of-the-art results on different levels of supervision and outperforms previous best specialized blocking or matching solutions for EM. Sudowoodo also achieves promising results in data cleaning and column matching tasks showing its versatility in DI&P applications.}
}


@inproceedings{DBLP:conf/icde/SaifuddinBTA23,
	author = {Khaled Mohammed Saifuddin and
                  Briana Bumgardner and
                  Farhan Tanvir and
                  Esra Akbas},
	title = {HyGNN: Drug-Drug Interaction Prediction via Hypergraph Neural Network},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {1503--1516},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00119},
	doi = {10.1109/ICDE55515.2023.00119},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/SaifuddinBTA23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Drug-Drug Interactions (DDIs) may hamper the functionalities of drugs, and in the worst scenario, they may lead to adverse drug reactions (ADRs). Predicting all DDIs is a challenging and critical problem. Most existing computational models integrate drug-centric information from different sources and leverage them as features in machine learning classifiers to predict DDIs. However, these models have a high chance of failure, especially for new drugs when all the information is not available. This paper proposes a novel Hypergraph Neural Network (HyGNN) model based on only the Simplified Molecular Input Line Entry System (SMILES) string of drugs, available for any drug, for the DDI prediction problem. To capture the drug chemical structure similarities, we create a hypergraph from drugs’ chemical substructures extracted from the SMILES strings. Then, we develop HyGNN consisting of a novel attention-based hypergraph edge encoder to get the representation of drugs as hyperedges and a decoder to predict the interactions between drug pairs. Furthermore, we conduct extensive experiments to evaluate our model and compare it with several state-of-the-art methods. Experimental results demonstrate that our proposed HyGNN model effectively predicts DDIs and impressively outperforms the baselines with a maximum F1 score, ROC-AUC, and PR-AUC of 94.61%, 98.69%, and 98.68%, respectively. Finally, we show that our models also work well for new drugs.}
}


@inproceedings{DBLP:conf/icde/WangGLLY23,
	author = {Guangjing Wang and
                  Hanqing Guo and
                  Anran Li and
                  Xiaorui Liu and
                  Qiben Yan},
	title = {Federated IoT Interaction Vulnerability Analysis},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {1517--1530},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00120},
	doi = {10.1109/ICDE55515.2023.00120},
	timestamp = {Wed, 30 Aug 2023 15:34:14 +0200},
	biburl = {https://dblp.org/rec/conf/icde/WangGLLY23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {IoT devices provide users with great convenience in smart homes. However, the interdependent behaviors across devices may yield unexpected interactions. To analyze the potential IoT interaction vulnerabilities, in this paper, we propose a federated and explicable IoT interaction data management system FexIoT. To address the lack of information in the closed-source platforms, FexIoT captures causality information by fusing multi-domain data, including the descriptions of apps and real-time event logs, into interaction graphs. The interaction graph representation is encoded by graph neural networks (GNNs). To collaboratively train the GNN model without sharing the raw data, we design a layer-wise clustering-based federated GNN framework for learning intrinsic clustering relationships among GNN model weights, which copes with the statistical heterogeneity and the concept drift problem of graph data. In addition, we propose the Monte Carlo beam search with the SHAP method to search and measure the risk of subgraphs, in order to explain the potential vulnerability causes. We evaluate our prototype on datasets collected from five IoT automation platforms. The results show that FexIoT achieves more than 90% average accuracy for interaction vulnerability detection, outperforming the existing methods. Moreover, FexIoT offers an explainable result for the detected vulnerabilities.}
}


@inproceedings{DBLP:conf/icde/MundraZNA23,
	author = {Pranay Mundra and
                  Jianhao Zhang and
                  Fatemeh Nargesian and
                  Nikolaus Augsten},
	title = {Koios: Top-k Semantic Overlap Set Search},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {1531--1543},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00121},
	doi = {10.1109/ICDE55515.2023.00121},
	timestamp = {Tue, 07 May 2024 20:05:36 +0200},
	biburl = {https://dblp.org/rec/conf/icde/MundraZNA23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We study the top-k set similarity search problem using semantic overlap. While vanilla overlap requires exact matches between set elements, semantic overlap allows elements that are syntactically different but semantically related to increase the overlap. The semantic overlap is the maximum matching score of a bipartite graph, where an edge weight between two set elements is defined by a user-defined similarity function, e.g., cosine similarity between embeddings. Common techniques like token indexes fail for semantic search since similar elements may be unrelated at the character level. Further, verifying candidates is expensive (cubic versus linear for syntactic overlap), calling for highly selective filters. We propose Koios, the first exact and efficient algorithm for semantic overlap search. Koios leverages sophisticated filters to minimize the number of required graph-matching calculations. Our experiments show that for medium to large sets less than 5% of the candidate sets need verification, and more than half of those sets are further pruned without requiring the expensive graph matching. We show the efficiency of our algorithm on four real datasets and demonstrate the improved result quality of semantic over vanilla set similarity search.}
}


@inproceedings{DBLP:conf/icde/BhowmickDM23,
	author = {Satadisha Saha Bhowmick and
                  Eduard C. Dragut and
                  Weiyi Meng},
	title = {Globally Aware Contextual Embeddings for Named Entity Recognition
                  in Social Media Streams},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {1544--1557},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00122},
	doi = {10.1109/ICDE55515.2023.00122},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/BhowmickDM23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {An important task for Information Extraction from Microblogs is Named Entity Recognition (NER) that extracts mentions of real-world entities from microblog messages and meta-information like entity type for better entity characterization. A lot of microblog NER systems have rightly sought to prioritize modeling the non-literary nature of microblog text. These systems are trained on offline static datasets and extract a combination of surface-level features – orthographic, lexical, and semantic – from individual messages for noisy text modeling and entity extraction. But given the constantly evolving nature of microblog streams, detecting all entity mentions from such varying yet limited context in short messages remains a difficult problem to generalize. In this paper, we propose the NER Globalizer pipeline better suited for NER on microblog streams. It characterizes the isolated message processing by existing NER systems as modeling local contextual embeddings, where learned knowledge from the immediate context of a message is used to suggest seed entity candidates. Additionally, it recognizes that messages within a microblog stream are topically related and often repeat mentions of the same entity. This suggests building NER systems that go beyond localized processing. By leveraging occurrence mining, the proposed system therefore follows up traditional NER modeling by extracting additional mentions of seed entity candidates that were previously missed. Candidate mentions are separated into well-defined clusters which are then used to generate a pooled global embedding drawn from the collective context of the candidate within a stream. The global embeddings are utilized to separate false positives from entities whose mentions are produced in the final NER output. Our experiments show that the proposed NER system exhibits superior effectiveness on multiple NER datasets with an average Macro F1 improvement of 47.04% over the best NER baseline while adding only a small computational overhead.}
}


@inproceedings{DBLP:conf/icde/ZhangFCKMBPP23,
	author = {Yunjia Zhang and
                  Avrilia Floratou and
                  Joyce Cahoon and
                  Subru Krishnan and
                  Andreas C. M{\"{u}}ller and
                  Dalitso Banda and
                  Fotis Psallidas and
                  Jignesh M. Patel},
	title = {Schema Matching using Pre-Trained Language Models},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {1558--1571},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00123},
	doi = {10.1109/ICDE55515.2023.00123},
	timestamp = {Mon, 09 Sep 2024 14:52:21 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhangFCKMBPP23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Schema matching over relational data has been studied for more than two decades. However, the state-of-the-art methods do not address key modern-day challenges encountered in real customer scenarios, namely: 1) no access to the source (customer) data due to privacy constraints, 2) target schema with a much larger number of entities and attributes compared to the source schema, and 3) different but semantically equivalent entity and attribute names in the source and target schemata. In this paper, we address these shortcomings. Using real-world customer schemata, we demonstrate that existing linguistic matching approaches have low accuracy. Next, we propose the Learned Schema Mapper (LSM), a novel linguistic schema matching system that leverages the natural language understanding capabilities of pre-trained language models to improve the overall accuracy. Combining this with active learning and a smart attribute selection strategy that selects the most informative attributes for users to label, LSM can significantly reduce the overall human labeling cost. Experimental results demonstrate that users can correctly match their full schema while saving as much as 81% of the labeling cost compared to manual labeling.}
}


@inproceedings{DBLP:conf/icde/Liu0J0K23,
	author = {Guanli Liu and
                  Jianzhong Qi and
                  Christian S. Jensen and
                  James Bailey and
                  Lars Kulik},
	title = {Efficiently Learning Spatial Indices},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {1572--1584},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00124},
	doi = {10.1109/ICDE55515.2023.00124},
	timestamp = {Sat, 30 Sep 2023 09:44:51 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Liu0J0K23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Learned indices can leverage the high prediction accuracy and efficiency of modern deep learning techniques. They are capable of delivering better query performance than traditional indices over one-dimensional data. Recent studies demonstrate that we can also achieve query-efficient learned in-dices for spatial data by partitioning and subsequently transforming spatial data to one-dimensional values, after which existing techniques can be applied. While enabling efficient querying, building and rebuilding learned spatial indices efficiently remains largely unaddressed. As the model training needed to learn a spatial index is costly, efficient building and rebuilding of learned spatial indices on large data sets is challenging if performed by means of model training and retraining.To advance the practicality of learned spatial indices, we propose a system named ELSI that enables the efficient building and rebuilding of a class of learned spatial indices that follow two simple design principles. The core idea is to reduce the model (re-)building times by engineering reduced training sets that preserve key data distribution patterns. ELSI encompasses a suite of methods for constructing small and distribution-preserving training sets from input data sets. Further, given an input data set, ELSI can adaptively select a method that produces a learned index with high query efficiency. Experiments on real data sets of 100+ million points show that ELSI can reduce the build times of four different learned spatial indices consistently (by up to two orders of magnitude) without jeopardizing query efficiency.}
}


@inproceedings{DBLP:conf/icde/0001LGWZSHW23,
	author = {Shengnan Guo and
                  Youfang Lin and
                  Letian Gong and
                  Chenyu Wang and
                  Zeyu Zhou and
                  Zekai Shen and
                  Yiheng Huang and
                  Huaiyu Wan},
	title = {Self-Supervised Spatial-Temporal Bottleneck Attentive Network for
                  Efficient Long-term Traffic Forecasting},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {1585--1596},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00125},
	doi = {10.1109/ICDE55515.2023.00125},
	timestamp = {Sun, 06 Oct 2024 21:04:56 +0200},
	biburl = {https://dblp.org/rec/conf/icde/0001LGWZSHW23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In intelligent transportation systems, accurate long-term traffic forecasting is informative for administrators and travelers to make wise decisions in advance. Recently proposed spatial-temporal forecasting models perform well for short-term traffic forecasting, but two challenges hinder their applications for long-term forecasting in practice. Firstly, existing traffic forecasting models do not have satisfactory scalability on effectiveness and efficiency, i.e., as the prediction time spans extend, existing models either cannot capture the long-term spatial-temporal dynamics of traffic data or equip global receptive fields at the cost of quadratic computational complexity. Secondly, the dilemma between the models’ strong appetite for high-quality training data and their generalization ability is also a challenge we have to face. Thus how to improve data utilization efficiency deserves thoughtful thinking. Aiming at solving the long-term traffic forecasting problem and facilitating the deployment of traffic forecasting models in practice, this paper proposes an efficient and effective Self-supervised Spatial-Temporal Bottleneck Attentive Network (SSTBAN). Specifically, SSTBAN follows a multi-task framework by incorporating a self-supervised learner to produce robust latent representations for historical traffic data, so as to improve its generalization performance and robustness for forecasting. Besides, we design a spatial-temporal bottleneck attention mechanism, reducing the computational complexity meanwhile encoding global spatial-temporal dynamics. Extensive experiments on real-world long-term traffic forecasting tasks, including traffic speed forecasting and traffic flow forecasting under nine scenarios, demonstrate that SSTBAN not only achieves the overall best performance but also has good computation efficiency and data utilization efficiency.}
}


@inproceedings{DBLP:conf/icde/GuZBCZY23,
	author = {Zishan Gu and
                  Ke Zhang and
                  Guangji Bai and
                  Liang Chen and
                  Liang Zhao and
                  Carl Yang},
	title = {Dynamic Activation of Clients and Parameters for Federated Learning
                  over Heterogeneous Graphs},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {1597--1610},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00126},
	doi = {10.1109/ICDE55515.2023.00126},
	timestamp = {Thu, 15 Feb 2024 16:22:21 +0100},
	biburl = {https://dblp.org/rec/conf/icde/GuZBCZY23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The data generated in many real-world applications can be modeled as heterogeneous graphs of multi-typed entities (nodes) and relations (links). Nowadays, such data are commonly generated and stored by distributed clients, making direct centralized model training unpractical. While the data in each client are prone to biased local distributions, generalizable global models are still in frequent need for large-scale applications. However, the large number of clients enforce significant computational overhead due to the communication and synchronization among the clients, whereas the biased local data distributions indicate that not all clients and parameters should be computed and updated at all times. Motivated by specifically designed preliminary studies on training a state-of-the-art heterogeneous graph neural network (HGN) with the vanilla FedAvg framework, in this work, we propose to leverage the characteristics of heterogeneous graphs by designing dynamic activation strategies for the clients and parameters during the federated training of HGN, named FedDA. Moreover, we design a novel disentangled model D-HGN to enable type-oriented activation of model parameters for FedDA. The effectiveness and efficiency of our proposed techniques are backed by both theoretical and empirical analysis– We theoretically analyze the validity and convergence of FedDA and mathematically illustrate its efficiency gain; meanwhile, we demonstrate the significant performance gains of FedDA and corroborate its efficiency gains with extensive experiments over multiple realistic FL settings synthesized based on real-world heterogeneous graphs.}
}


@inproceedings{DBLP:conf/icde/LiLXTSJD23,
	author = {Yan Li and
                  Xinjiang Lu and
                  Haoyi Xiong and
                  Jian Tang and
                  Jiantao Su and
                  Bo Jin and
                  Dejing Dou},
	title = {Towards Long-Term Time-Series Forecasting: Feature, Pattern, and Distribution},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {1611--1624},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00127},
	doi = {10.1109/ICDE55515.2023.00127},
	timestamp = {Sun, 06 Oct 2024 21:04:58 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LiLXTSJD23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Long-term time-series forecasting (LTTF) has become a pressing demand in many applications, such as wind power supply planning. Transformer models have been adopted to deliver high prediction capacity because of the high computational self-attention mechanism. Though one could lower the complexity of Transformers by inducing the sparsity in point-wise self-attentions for LTTF, the limited information utilization prohibits the model from exploring the complex dependencies comprehensively. To this end, we propose an efficient Transformer-based model, named Conformer, which differentiates itself from existing methods for LTTF in three aspects: (i) an encoder-decoder architecture incorporating a linear complexity without sacrificing information utilization is proposed on top of sliding-window attention and Stationary and Instant Recurrent Network (SIRN); (ii) a module derived from the normalizing flow is devised to further improve the information utilization by inferring the outputs with the latent variables in SIRN directly; (iii) the inter-series correlation and temporal dynamics in time-series data are modeled explicitly to fuel the downstream self-attention mechanism. Extensive experiments on seven real-world datasets demonstrate that Conformer outperforms the state-of-the-art methods on LTTF and generates reliable prediction results with uncertainty quantification.}
}


@inproceedings{DBLP:conf/icde/WangW023,
	author = {Kafeng Wang and
                  Pengyang Wang and
                  Chengzhong Xu},
	title = {Toward Efficient Automated Feature Engineering},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {1625--1637},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00128},
	doi = {10.1109/ICDE55515.2023.00128},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/WangW023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Automated Feature Engineering (AFE) refers to automatically generate and select optimal feature sets for downstream tasks, which has achieved great success in real-world applications. Current AFE methods mainly focus on improving the effectiveness of the produced features, but ignoring the low-efficiency issue for large-scale deployment. Therefore, in this work, we propose a generic framework to improve the efficiency of AFE. Specifically, we construct the AFE pipeline based on reinforcement learning setting, where each feature is assigned an agent to perform feature transformation and selection, and the evaluation score of the produced features in downstream tasks serve as the reward to update the policy. We improve the efficiency of AFE in two perspectives. On the one hand, we develop a Feature Pre-Evaluation (FPE) Model to reduce the sample size and feature size that are two main factors on undermining the efficiency of feature evaluation. On the other hand, we devise a two-stage policy training strategy by running FPE on the pre-evaluation task as the initialization of the policy to avoid training policy from scratch. We conduct comprehensive experiments on 36 datasets in terms of both classification and regression tasks. The results show 2.9% higher performance in average and 2x higher computational efficiency comparing to state-of-the-art AFE methods.}
}


@inproceedings{DBLP:conf/icde/TangZLZTL23,
	author = {Jianheng Tang and
                  Weiqi Zhang and
                  Jiajin Li and
                  Kangfei Zhao and
                  Fugee Tsung and
                  Jia Li},
	title = {Robust Attributed Graph Alignment via Joint Structure Learning and
                  Optimal Transport},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {1638--1651},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00129},
	doi = {10.1109/ICDE55515.2023.00129},
	timestamp = {Tue, 02 Apr 2024 11:10:01 +0200},
	biburl = {https://dblp.org/rec/conf/icde/TangZLZTL23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graph alignment, which aims at identifying corresponding entities across multiple networks, has been widely applied in various domains. As the graphs to be aligned are usually constructed from different sources, the inconsistency issues of structures and features between two graphs are ubiquitous in real-world applications. Most existing methods follow the "embed-then-cross-compare" paradigm which computes node embeddings in each graph and then processes node correspondences based on cross-graph embedding comparison. However, we find these methods are unstable and sub-optimal when structure or feature inconsistency appears. To this end, we propose SLOTAlign, an unsupervised graph alignment framework that jointly performs Structure Learning and Optimal Transport Alignment. We convert graph alignment to an optimal transport problem between two intra-graph matrices without the requirement of cross-graph comparison. We further incorporate multi-view structure learning to enhance graph representation power and reduce the effect of structure and feature inconsistency inherited across graphs. Moreover, an alternating scheme based algorithm has been developed to address the joint optimization problem in SLOTAlign and the provable convergence result are also established. Finally, we conduct extensive experiments on six unsupervised graph alignment datasets and the DBP15K knowledge graph (KG) alignment benchmark dataset. The proposed SLOTAlign shows superior performance and strongest robustness over seven unsupervised graph alignment methods and five specialized KG alignment methods. 1}
}


@inproceedings{DBLP:conf/icde/YeZC23,
	author = {Junhao Ye and
                  Yuanyuan Zhu and
                  Lu Chen},
	title = {Top-r keyword-based community search in attributed graphs},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {1652--1664},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00130},
	doi = {10.1109/ICDE55515.2023.00130},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/YeZC23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Community search on attributed graphs has been widely studied recently. Most earlier works aim to retrieve communities relevant to the query nodes Q U and query keywords Q W , and some recent works begin to focus on keyword-based attributed community search (KACS) with only query keywords Q W , aiming to return a structural cohesive community with the highest score relevant to Q W . However, these scores only consider the semantic similarity between user attributes and Q W and neglect the semantic similarity between users in the community. Thus, we propose a new community model which considers both semantic similarities and uses triangle-connected k-truss to ensure structural cohesiveness, and study the top-r keyword-based attributed community search (rKACS) problem for a given Q W to provide more candidates for users to choose the preferred communities. To find the top-r communities, we first propose the Basic algorithm, which gradually finds the communities with large scores through maximal clique enumerations. Then, we further propose an improved algorithm Incremental based on two novel optimization techniques, which can significantly reduce the search space and find the maximal cliques incrementally. Extensive experimental studies on four real-world datasets validated the effectiveness and efficiency of our methods.}
}


@inproceedings{DBLP:conf/icde/YinZZLW23,
	author = {Ziqi Yin and
                  Qi Zhang and
                  Wentao Zhang and
                  Rong{-}Hua Li and
                  Guoren Wang},
	title = {Fairness-aware Maximal Biclique Enumeration on Bipartite Graphs},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {1665--1677},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00131},
	doi = {10.1109/ICDE55515.2023.00131},
	timestamp = {Sun, 06 Oct 2024 21:04:59 +0200},
	biburl = {https://dblp.org/rec/conf/icde/YinZZLW23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Maximal biclique enumeration is a fundamental problem in bipartite graph data analysis. Existing biclique enumeration methods mainly focus on non-attributed bipartite graphs and also ignore the fairness of graph attributes. In this paper, we introduce the concept of fairness into the biclique model for the first time and study the problem of fairness-aware biclique enumeration. Specifically, we propose two fairness-aware biclique models, called single-side fair biclique and bi-side fair biclique respectively. To efficiently enumerate all single-side fair bicliques, we first present two non-trivial pruning techniques, called fair α-β core pruning and colorful fair α-β core pruning, to reduce the graph size without losing accuracy. Then, we develop a branch and bound algorithm, called FairBCEM, to enumerate all single-side fair bicliques on the reduced bipartite graph. To further improve the efficiency, we propose an efficient branch and bound algorithm with a carefully-designed combinatorial enumeration technique. Note that all of our techniques can also be extended to enumerate all bi-side fair bicliques. We also extend the two fairness-aware biclique models by constraining the ratio of the number of vertices of each attribute to the total number of vertices and present corresponding enumeration algorithms. Extensive experimental results on five large real-world datasets demonstrate our methods’ efficiency, effectiveness, and scalability.}
}


@inproceedings{DBLP:conf/icde/ZhengMWGH0J23,
	author = {Bolong Zheng and
                  Yong Ma and
                  Jingyi Wan and
                  Yongyong Gao and
                  Kai Huang and
                  Xiaofang Zhou and
                  Christian S. Jensen},
	title = {Reinforcement Learning based Tree Decomposition for Distance Querying
                  in Road Networks},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {1678--1690},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00132},
	doi = {10.1109/ICDE55515.2023.00132},
	timestamp = {Fri, 08 Nov 2024 08:36:36 +0100},
	biburl = {https://dblp.org/rec/conf/icde/ZhengMWGH0J23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Computing the shortest path distance between two vertices in a road network is a building block in numerous applications. To do so efficiently, the state-of-the-art proposals adopt a tree decomposition process with heuristic strategies to build 2-hop label indexes. However, these indexes suffer from large space overheads caused by either tree imbalance or a large tree height. Independently of this, reinforcement learning has recently show impressive performance at sequential decision making in spatial data management tasks. We observe that tree decomposition is naturally a sequential decision making problem that decides which vertex to process at each step. In this paper, we propose a reinforcement learning based tree decomposition (RLTD) approach that reduces the space overhead significantly. We model tree decomposition as a Markov Decision Process, exploiting features of both the network topological structure and the tree structure. We further optimize the tree decomposition process by taking the network density into account, which yields a great generalization of the model on large road networks. Extensive experiments with real-world data offer insights into the performance of the proposals, showing that they are able to reduce the space overhead by about 51% and achieve on average about 14% speedup for queries with almost the same preprocessing time when compared with the state-of-the-art proposals.}
}


@inproceedings{DBLP:conf/icde/LiLDD0023,
	author = {Zhenyu Li and
                  Xiuxing Li and
                  Zhichao Duan and
                  Bowen Dong and
                  Ning Liu and
                  Jianyong Wang},
	title = {Toward a Unified Framework for Unsupervised Complex Tabular Reasoning},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {1691--1704},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00133},
	doi = {10.1109/ICDE55515.2023.00133},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LiLDD0023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Structured tabular data exist across nearly all fields. Reasoning task over these data aims to answer questions or determine the truthiness of hypothesis sentences by understanding the semantic meaning of a table. While previous works have devoted significant efforts to the tabular reasoning task, they always assume there are sufficient labeled data. However, constructing reasoning samples over tables (and related text) is labor-intensive, especially when the reasoning process is complex. When labeled data is insufficient, the performance of models will suffer an unendurable decline. In this paper, we propose a unified framework for unsupervised complex tabular reasoning (UCTR), which generates sufficient and diverse synthetic data with complex logic for tabular reasoning tasks, assuming no human-annotated data at all. Specifically, we first utilize a random sampling strategy to collect diverse programs of different types and execute them on tables based on a "Program-Executor" module. To bridge the gap between the programs and natural language sentences, we design a powerful "NL-Generator" module to generate natural language sentences with complex logic from these programs. Since a table often occurs with its surrounding texts, we further propose novel "Table-to-Text" and "Text-to-Table" operators to handle joint table-text reasoning scenarios. This way, we can adequately exploit the unlabeled table resources to obtain a well-performed reasoning model under an unsupervised setting. Our experiments cover different tasks (question answering and fact verification) and different domains (general and specific), showing that our unsupervised methods can achieve at most 93% performance compared to supervised models. The impressive performance demonstrates that UCTR can significantly reduce the dependence on manual annotation. Moreover, we also find that it can substantially boost the supervised performance in low-resourced domains as a data augmentation technique.}
}


@inproceedings{DBLP:conf/icde/GuanMWW23,
	author = {Sheng Guan and
                  Hanchao Ma and
                  Mengying Wang and
                  Yinghui Wu},
	title = {{GALE:} Active Adversarial Learning for Erroneous Node Detection in
                  Graphs},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {1705--1718},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00134},
	doi = {10.1109/ICDE55515.2023.00134},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/GuanMWW23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We introduce GALE, an active adversarial learning framework to detect nodes with erroneous information in attributed graphs. GALE is empowered by a new adversarial active error detection framework, which interacts active learning with a graph generative adversarial model to best exploit limited labeled examples of erroneous nodes. It dynamically determines diversified query nodes in batches with bounded size in terms of node typicality to enrich a pool of examples, which in turn provides representative examples to best train an adversarial classifier to capture different types of errors. Moreover, GALE provides an annotation algorithm to suggest a context of possible correct attribute values and error types, to facilitate the labeling of query nodes. We show that using limited queries and examples, GALE significantly improves competing methods such as constraint-based detection, outlier detection, and Graph Neural Networks (e.g. GCNs), with 32%, 31%, and 17% gain in F-1 score on average, and is feasible in learning cost for large graphs.}
}


@inproceedings{DBLP:conf/icde/GaoWJS0C23,
	author = {Yucen Gao and
                  Xikai Wei and
                  Xi Jing and
                  Yangguang Shi and
                  Xiaofeng Gao and
                  Guihai Chen},
	title = {Online Shipping Container Pricing Strategy Achieving Vanishing Regret
                  with Limited Inventory},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {1719--1731},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00392},
	doi = {10.1109/ICDE55515.2023.00392},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/GaoWJS0C23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the growing demand for global trade transportation, the shipping container market has gained an increasingly important position. As a key issue of the market, container pricing is regarded as an important indicator to adjust the market supply and demand as well as the revenue of liner enterprises. Although various methods aimed at increasing enterprise revenue, such as expert pricing and dynamic pricing, have been proposed by industry and academia in recent years, these approaches rarely yield worst-case performance guarantee for the double-sided online scenarios of commodities and buyers.To cater to the double-sided online scenario and provide theoretical performance guarantee, we propose an online learning-based pricing framework named Balancing Inventory and Revenue with -chasing Decider (BIRD). BIRD determines container price by combining advantages of given multiple online pricing strategies. We utilize a strategy selector A to select a proper target strategy and use an ϵ-chasing decider {{{\\mathfrak{D}}}^{Cha\\operatorname{s} ing}}\nto determine the price. BIRD is proven to combine the advantages of multiple online pricing strategies to achieve the performance close to the posterior optimal strategy for any sequence of online buyers on realistic sales platforms with inventory limitation. BIRD is proved to yield a vanishing regret for the online posted pricing problem with the features of limited inventory and multi-unit demand. Based on the historical data provided by COSCO, one of the largest liner enterprises in the world, we experimentally demonstrate the effectiveness of the proposed algorithm.}
}


@inproceedings{DBLP:conf/icde/CaoXH23,
	author = {Yukun Cao and
                  Xike Xie and
                  Kexin Huang},
	title = {Learn to Explore: on Bootstrapping Interactive Data Exploration with
                  Meta-learning},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {1720--1733},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00135},
	doi = {10.1109/ICDE55515.2023.00135},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/CaoXH23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Interactive data exploration (IDE) is an effective way of comprehending big data, whose volume and complexity are beyond human abilities. The main goal of IDE is to discover user interest regions from a database through multi-rounds of user labelling. Existing IDEs adopt active-learning framework, where users iteratively discriminate or label the interestingness of selected tuples. The process of data exploration can be viewed as the process of training of a classifier, which determines whether a database tuple is interesting to a user. An efficient exploration thus takes very few iterations of user labelling to reach the data region of interest. In this work, we consider the data exploration as the process of few-shot learning, where the classifier is learned with only a few training examples, or exploration iterations. To this end, we propose a learning-to-explore framework, based on meta-learning, which learns how to learn a classifier with automatically generated meta-tasks, so that the exploration process can be much shortened. Extensive experiments on real datasets show that our proposal outperforms existing explore-by-example solutions in terms of accuracy and efficiency.}
}


@inproceedings{DBLP:conf/icde/WangNC23,
	author = {TaiNing Wang and
                  Yunpeng Niu and
                  Chee{-}Yong Chan},
	title = {Complete Join Reordering for Null-Intolerant Joins},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {1734--1746},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00136},
	doi = {10.1109/ICDE55515.2023.00136},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/WangNC23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The join reordering problem is a core task in query optimization to find the most efficient evaluation order for join operations. The Enhanced Compensation-based Approach (ECA) is the state-of-the-art approach for this problem which is based on using new operators called compensation operators to enlarge the query plan search space with more join reorderings. However, ECA cannot provide complete join reorderability for queries involving one or more full outerjoins. In this paper, we present the first complete join reordering solution, named CJR. By introducing a new and more expressive compensation operator and an enhanced set of rewriting rules, CJR is able to provide complete join reorderability for all join queries with null-intolerant join predicates. Our experimental results on the Join Order Benchmark demonstrate that CJR can improve query performance by a factor of 12.32.}
}


@inproceedings{DBLP:conf/icde/HuangHQCH23,
	author = {Zhengjie Huang and
                  Yunyang Huang and
                  Peng Qian and
                  Jianhai Chen and
                  Qinming He},
	title = {Demystifying Bitcoin Address Behavior via Graph Neural Networks},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {1747--1760},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00137},
	doi = {10.1109/ICDE55515.2023.00137},
	timestamp = {Sat, 30 Sep 2023 09:44:50 +0200},
	biburl = {https://dblp.org/rec/conf/icde/HuangHQCH23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Bitcoin is one of the decentralized cryptocurrencies powered by a peer-to-peer blockchain network. Parties who trade in the bitcoin network are not required to disclose any personal information. Such property of anonymity, however, precipitates potential malicious transactions to a certain extent. Indeed, various illegal activities such as money laundering, dark network trading, and gambling in the bitcoin network are nothing new now. While a proliferation of work has been developed to identify malicious bitcoin transactions, the behavior analysis and classification of bitcoin addresses are largely overlooked by existing tools. In this paper, we propose BAClassifier, a tool that can automatically classify bitcoin addresses based on their behaviors. Technically, we come up with the following three key designs. First, we consider casting the transactions of the bitcoin address into an address graph structure, of which we introduce a graph node compression technique and a graph structure augmentation method to characterize a unified graph representation. Furthermore, we leverage a graph feature network to learn the graph representations of each address and generate the graph embeddings. Finally, we aggregate all graph embeddings of an address into the address-level representation, and engage in a classification model to give the address behavior classification. As a side contribution, we construct and release a large-scale annotated dataset that consists of over 2 million real-world bitcoin addresses and concerns 4 types of address behaviors. Experimental results demonstrate that our proposed framework outperforms state-of-the-art bitcoin address classifiers and existing classification models, where the precision and F1-score are 96% and 95%, respectively. Our implementation and dataset are released, hoping to inspire others.}
}


@inproceedings{DBLP:conf/icde/Liu0X0023,
	author = {Kangzheng Liu and
                  Feng Zhao and
                  Guandong Xu and
                  Xianzhi Wang and
                  Hai Jin},
	title = {{RETIA:} Relation-Entity Twin-Interact Aggregation for Temporal Knowledge
                  Graph Extrapolation},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {1761--1774},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00138},
	doi = {10.1109/ICDE55515.2023.00138},
	timestamp = {Sun, 06 Oct 2024 21:04:58 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Liu0X0023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Temporal knowledge graph (TKG) extrapolation aims to predict future unknown events (facts) based on historical information, and has attracted considerable attention due to its great practical significance. Accurate representations (embeddings) of entities and relations form the basis of TKG extrapolation. Recent work has been devoted to improving the rationality of entity representations. However, on the one hand, ignoring relation modeling results in incomplete relation representations; therefore, some approaches aggregate only immediately adjacent entities of relations, but this can lead to the "message islands" problem of relation modeling. On the other hand, ignoring the association constraints between relations and entities can make the embeddings of both relations and entities prone to overfitting. To address the abovementioned challenges, we propose an advanced method, namely, RETIA. For the former issue, we generate twin hyperrelation subgraphs for each historical subgraph and then aggregate both the adjacent entities and relations in the hyperrelation subgraphs through a graph convolutional network (GCN). About the latter concern, we propose a twin-interact module (TIM), which provides communication channels for relation aggregation and entity aggregation during the evolution of the historical sequence. Experiments conducted on five public datasets show that RETIA has made great improvements across several evaluation metrics. Our released code is available at https://github.com/CGCL-codes/RETIA.}
}


@inproceedings{DBLP:conf/icde/0001DZZF0NW023,
	author = {Yuhan Wu and
                  Siyuan Dong and
                  Yi Zhou and
                  Yikai Zhao and
                  Fangcheng Fu and
                  Tong Yang and
                  Chaoyue Niu and
                  Fan Wu and
                  Bin Cui},
	title = {KVSAgg: Secure Aggregation of Distributed Key-Value Sets},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {1775--1789},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00139},
	doi = {10.1109/ICDE55515.2023.00139},
	timestamp = {Fri, 19 Jul 2024 09:25:41 +0200},
	biburl = {https://dblp.org/rec/conf/icde/0001DZZF0NW023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In global data analysis, the central server needs the global statistic of the user data stored in local clients. In such cases, an Honest-but-Curious central server might put user privacy at risk in trying to collect individual statistics of each user. In response, the secure aggregation provides a solution for calculating global statistics without revealing users’ privacy data. However, existing secure aggregation protocols only focus on the data in the form of vectors or common sets, which limits their application scope. We formalize a general problem—key-value set secure aggregation—that not only includes secure vector aggregation and private set union but also supports more applications. To address the proposed problem, we devise our solution (called the KVSAgg framework) that promises satisfactory performance in security, efficiency, and accuracy. Our key technique is a homomorphic transform algorithm (called HyperIBLT) that is not only capable of bidirectionally transforming data between key-value sets and vectors, but also able to transform sum operation of sets to addition of vectors. We implement KVSAgg on both CPU and GPU platforms and perform the evaluation on three use cases including federated learning, distributed data counting, and finding global hot items. Compared with our baselines, KVSAgg simultaneously achieves the best security, efficiency higher by orders of magnitude, and zero-error in nearly all cases. All codes are open-source anonymously.}
}


@inproceedings{DBLP:conf/icde/0003WHL000W23,
	author = {Yu Wang and
                  Jingfei Wu and
                  Xingyuan Hua and
                  Chi Harold Liu and
                  Guozheng Li and
                  Jianxin Zhao and
                  Ye Yuan and
                  Guoren Wang},
	title = {Air-Ground Spatial Crowdsourcing with {UAV} Carriers by Geometric
                  Graph Convolutional Multi-Agent Deep Reinforcement Learning},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {1790--1802},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00140},
	doi = {10.1109/ICDE55515.2023.00140},
	timestamp = {Mon, 23 Oct 2023 08:10:15 +0200},
	biburl = {https://dblp.org/rec/conf/icde/0003WHL000W23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Spatial Crowdsourcing (SC) has been proved as an effective paradigm for data acquisition in urban environments. Apart from using human participants, with the rapid development of unmanned vehicles (UVs) technologies, unmanned aerial or ground vehicles (UAVs, UGVs) are equipped with various high-precision sensors, enabling them to become new types of data collectors. However, UGVs’ operational range is constrained by the road network, and UAVs are limited by power supply, it is thus natural to use UGVs and UAVs together as a coalition, and more precisely, UGVs behave as the UAV carriers for range extensions to achieve complicated air-ground SC tasks. In this paper, we propose a novel communication-based multi-agent deep reinforcement learning method called "GARL", which consists of a multi-center attention-based graph convolutional network (GCN) to accurately extract UGV specific features from UGV stop network called "MC-GCN", and a novel GNN-based communication mechanism called "E-Comm" to make the cooperation among UGVs adaptive to constant changing of geometric shapes formed by UGVs. Extensive simulation results on two campuses of KAIST and UCLA campuses show that GARL consistently outperforms eight other baselines in terms of overall efficiency.}
}


@inproceedings{DBLP:conf/icde/ChenW23,
	author = {Qixu Chen and
                  Raymond Chi{-}Wing Wong},
	title = {Finding Best Tuple via Error-prone User Interaction},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {1803--1816},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00141},
	doi = {10.1109/ICDE55515.2023.00141},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ChenW23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the literature of the database community, there are a lot of studies about finding a utility function from a user (representing the user’s preference), via interaction with the user by asking a number of questions each requiring him/her to compare 2 points for choosing a more preferred point, in order to find the best tuple in the database containing a lot of tuples. In the real world, the user may make mistakes (carelessly), which means that s/he may answer some of the questions wrongly. Unfortunately, existing interaction algorithms may find the undesirable point based on the wrongly learnt utility function because they assume that all answers from the user are 100% correct. In particular, even if the user answers only 1 wrong answer, the output of the existing algorithms may be far away from the users’ real need. Motivated by this, in this paper, we propose a new problem of finding the most interesting point via interaction which is robust to possible mistakes made by a user. Besides, we propose (1) an algorithm that asks an asymptotically optimal number of questions when the dataset contains 2 dimensions and (2) two algorithms with provable performance guarantee when the dataset contains d dimensions where d≥ 2. Experiments on real and synthetic datasets show that our algorithms outperform the existing ones with a higher accuracy with only a small number of questions asked.}
}


@inproceedings{DBLP:conf/icde/AhmadY0GCZ23,
	author = {Akhlaque Ahmad and
                  Lyuheng Yuan and
                  Da Yan and
                  Guimu Guo and
                  Jieyang Chen and
                  Chengcui Zhang},
	title = {Accelerating k-Core Decomposition by a {GPU}},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {1818--1831},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00142},
	doi = {10.1109/ICDE55515.2023.00142},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/AhmadY0GCZ23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The k-core of a graph is the largest induced sub-graph with minimum degree k. The problem of k-core decomposition finds the k-cores of a graph for all valid values of k, and it has many applications such as network analysis, computational biology and graph visualization. Currently, there are two types of parallel algorithms for k-core decomposition: (1) degree-based vertex peeling, and (2) iterative h-index refinement. There is, however, few studies on accelerating k-core decomposition using GPU. In this paper, we propose a highly optimized peeling algorithm on a GPU, and compare it with possible implementations on top of think-like-a-vertex graph-parallel GPU systems as well as existing serial and parallel k-core decomposition algorithms on CPUs. Extensive experiments show that our GPU algorithm is the overall winner in both time and space. Our source code is released at https://github.com/akhlaqueak/KCoreGPU.}
}


@inproceedings{DBLP:conf/icde/AngHTH23,
	author = {Yihao Ang and
                  Qiang Huang and
                  Anthony K. H. Tung and
                  Zhiyong Huang},
	title = {A Stitch in Time Saves Nine: Enabling Early Anomaly Detection with
                  Correlation Analysis},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {1832--145},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00143},
	doi = {10.1109/ICDE55515.2023.00143},
	timestamp = {Sat, 30 Sep 2023 09:44:49 +0200},
	biburl = {https://dblp.org/rec/conf/icde/AngHTH23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Early detection of anomalies from sensor-based Multivariate Time Series (MTS) is vital for timely response to the signs of operation failures and errors. While many interesting works have been done toward solving this problem, existing methods typically detect such anomalies as outliers by making certain assumptions that allow efficient and easily understandable solutions to be used but might not be applicable to time series. Meanwhile, unsupervised deep learning-based methods might be highly accurate but often lead to challenges for real-time industrial scenarios, e.g., requiring a large amount of training data and producing unstable output.In this paper, we propose a new approach, CAD, to detect anomalies from sensor-based MTS. We aim to leverage the latent correlations between sensors by first converting the MTS into a sequence of Time-Series Graphs (TSGs) that connect sensors to their highly correlated neighbors within a certain time period. Then, we track the unusual correlation variations between sensors on the sequence of TSGs. By analyzing the correlation variations with a theoretical guarantee, CAD can detect the time of occurrence for the anomalies simultaneously with the sensors that are affected as early as possible.Extensive experiments over eight real-world datasets show that CAD is effective, scalable, yet stable compared to nine state-of-the-art methods while keeping comparable efficiency. Moreover, it maintains above 85% accuracy on large-scale datasets with over 1,000 sensors. Notably, CAD can determine relevant sensors in a very early stage of the anomaly so that timely predictive maintenance can be done. The code is available at https://github.com/YihaoAng/CAD.}
}


@inproceedings{DBLP:conf/icde/YoungmannCMS23,
	author = {Brit Youngmann and
                  Michael J. Cafarella and
                  Yuval Moskovitch and
                  Babak Salimi},
	title = {On Explaining Confounding Bias},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {1846--1859},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00144},
	doi = {10.1109/ICDE55515.2023.00144},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/YoungmannCMS23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {When analyzing large datasets, analysts are often interested in the explanations for unexpected results produced by their queries. In this work, we focus on aggregate SQL queries that expose correlations in the data. A major challenge that hinders the interpretation of such queries is confounding bias, which can lead to an unexpected correlation. We generate explanations in terms of a set of potential confounding variables that explain the unexpected correlation observed in a query. We propose to mine candidate confounding variables from external sources since, in many real-life scenarios, the explanations are not solely contained in the input data. We present an efficient algorithm that finds a concise subset of attributes (mined from external sources and the input dataset) that explain the unexpected correlation. This algorithm is embodied in a system called MESA. We demonstrate experimentally over multiple real-life datasets and through a user study that our approach generates insightful explanations, outperforming existing methods even when are given with the extracted attributes. We further demonstrate the robustness of our system to missing data and the ability of MESA to handle input datasets containing millions of tuples and an extensive search space of candidate confounding attributes.}
}


@inproceedings{DBLP:conf/icde/JiLB23,
	author = {Daomin Ji and
                  Hui Luo and
                  Zhifeng Bao},
	title = {Visualization Recommendation Through Visual Relation Learning and
                  Visual Preference Learning},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {1860--1873},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00145},
	doi = {10.1109/ICDE55515.2023.00145},
	timestamp = {Sun, 06 Oct 2024 21:04:57 +0200},
	biburl = {https://dblp.org/rec/conf/icde/JiLB23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Visualization recommendation (VisRec) is to automatically generate the most relevant visualization for a table of interest to a user. In this paper, we present a novel machine learning-based VisRec method, VisFormer, which solves VisRec in three stages: 1) Table representation learning, which is to learn accurate column-level representations for a table. To achieve it, we resort to Transformer, a powerful language model that can learn accurate word embeddings by modeling context. Specifically, we propose a hierarchical Transformer-based architecture to learn expressive column representations by capturing two types of context, intra-column context and cross-column context; 2) Visual Relation Learning, which is to capture column relations. To achieve it, we regard each visualization as a relation tuple with a special relation, visual relation, between the columns. Then for each visual relation, we use a neural network to evaluate the corresponding visualizations; 3) Visual Preference Learning, which is to extract visual preference features that can affect users’ decision from a visualization. To achieve so, we use a Convolution Neural Network to extract such features and explore how to use them to refine the recommendation results. We conduct experiments to compare with three state-of-the-art ML-based methods on a large real-world dataset, Plotly community feed. The experimental results show that compared with the most competitive baseline, the relative improvements of VisFormer on Recall@1, Recall@2, and Recall@3 are 8.8%, 20.6%, and 21.0%, respectively.}
}


@inproceedings{DBLP:conf/icde/WuZZZ0J23,
	author = {Zuohan Wu and
                  Libin Zheng and
                  Chen Jason Zhang and
                  Huaijie Zhu and
                  Jian Yin and
                  Di Jiang},
	title = {Opponent-aware Order Pricing towards Hub-oriented Mobility Services},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {1874--1886},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00146},
	doi = {10.1109/ICDE55515.2023.00146},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/WuZZZ0J23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Hub-oriented mobility services have gained great developments in recent years, enabling riders to simultaneously call vehicles from multiple mobility-supply companies (agents) on a single APP (which we call "hub"). Competing with others on such a hub, to obtain an order, an agent company first needs to get admitted by the requester, which is in turn affected by its quotation. The quotation needs to be attractively low compared to those of the opposing agents. Thus, an opponent-aware pricing strategy is needed for an agent to play well in the hub scenario, which is rarely discussed in existing works. To address the aforementioned issue, in this work, we first propose a quotation prediction model, which employs a neural network with a customized loss function to predict the opponents’ quotations. Based on the predictions, we then propose multi-arm bandit based methods to decide a proper quotation for the agent, in order to obtain orders while retaining profits. We finally conduct extensive experiments on real data, where the quotation-determining method integrated with the prediction model has achieved a remarkable profit improvement up to 85.5% compared to baseline methods, demonstrating their effectiveness.}
}


@inproceedings{DBLP:conf/icde/FangMS23,
	author = {Chenguang Fang and
                  Yinan Mei and
                  Shaoxu Song},
	title = {Matrix Factorization with Landmarks for Spatial Data},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {1887--1899},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00147},
	doi = {10.1109/ICDE55515.2023.00147},
	timestamp = {Mon, 05 Feb 2024 20:31:12 +0100},
	biburl = {https://dblp.org/rec/conf/icde/FangMS23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Matrix factorization (MF) is widely adopted to learn from data, e.g., for data representation and recommendation as well as many database applications such as data imputation and repairing. While it works for numerical values in general, for spatial data, without considering the locality w.r.t. the spatial information, the learned features could vary in spatial distribution. Even if smoothness in terms of close neighbors could be considered in the objective function to leverage the spatial information, the learned features are still uncontrolled in locations, and thus do not help much in learning from the data that are geographically distant. Therefore, in this study, we propose to introduce landmarks to control the locations of learned features and make them geographically close to the data observations. The proposed SMFL, Spatial Matrix Factorization with Landmarks, benefits from landmarks in more accurate learned features, along with better interpretability, and reduced computation cost. Our major contributions include (1) introducing landmarks to guide the locations of learned features and enhance the performance as well as the interpretability of the MF model, (2) proposing the SMFL method that cooperates landmarks with NMF and spatial regularization, for better utilizing the spatial information, and (3) devising updating rules with landmarks and proving the convergence for the proposed method. Experiments on real-world datasets highlight the advance of our proposal in various applications.}
}


@inproceedings{DBLP:conf/icde/Qi0ZXZ0JZ0023,
	author = {Xiaodong Qi and
                  Zhihao Chen and
                  Haizhen Zhuo and
                  Quanqing Xu and
                  Chengyu Zhu and
                  Zhao Zhang and
                  Cheqing Jin and
                  Aoying Zhou and
                  Ying Yan and
                  Hui Zhang},
	title = {SChain: Scalable Concurrency over Flexible Permissioned Blockchain},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {1901--1913},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00148},
	doi = {10.1109/ICDE55515.2023.00148},
	timestamp = {Sat, 30 Sep 2023 09:44:51 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Qi0ZXZ0JZ0023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Permissioned blockchains are being widely applied to solve the trust problem in enterprise collaboration. However, most of these systems suffer from low throughput and flexibility lacking issues. In this paper, we present a blockchain system SChain with scalable concurrent execution based on a flexible architecture. SChain separates the functionality of a complete "node" into three sub-functions and assigns them to different peers within every organization. Then each organization can scale each sub-function flexibly with no need for negotiation between organizations. Based on this architecture, SChain explores scalable concurrent execution from two levels. First, SChain takes the advantage of multiple peers to execute transactions collectively, while promising they make the same results as one peer does serially. Second, SChain enables concurrent transaction execution across blocks to utilize the resources of peers fully, breaking up the block-by-block process manner, based on a pipelined workflow. The extensive evaluation results demonstrate that SChain significantly outperforms the serial execution and other competing systems-level approaches.}
}


@inproceedings{DBLP:conf/icde/PanZC23,
	author = {Qiying Pan and
                  Yifei Zhu and
                  Lingyang Chu},
	title = {Lumos: Heterogeneity-aware Federated Graph Learning over Decentralized
                  Devices},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {1914--1926},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00149},
	doi = {10.1109/ICDE55515.2023.00149},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/PanZC23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graph neural networks (GNN) have been widely deployed in real-world networked applications and systems due to their capability to handle graph-structured data. However, the growing awareness of data privacy severely challenges the traditional centralized model training paradigm, where a server holds all the graph information. Federated learning is an emerging collaborative computing paradigm that allows model training without data centralization. Existing federated GNN studies mainly focus on systems where clients hold distinctive graphs or sub-graphs. The practical node-level federated situation, where each client is only aware of its direct neighbors, has yet to be studied. In this paper, we propose the first federated GNN framework called Lumos that supports supervised and unsupervised learning with feature and degree protection on node-level federated graphs. We first design a tree constructor to improve the representation capability given the limited structural information. We further present a Monte Carlo Markov Chain-based algorithm to mitigate the workload imbalance caused by degree heterogeneity with theoretically-guaranteed performance. Based on the constructed tree for each client, a decentralized tree-based GNN trainer is proposed to support versatile training. Extensive experiments demonstrate that Lumos outperforms the baseline with significantly higher accuracy and greatly reduced communication cost and training time.}
}


@inproceedings{DBLP:conf/icde/LiuHFS0F23,
	author = {Mingzhe Liu and
                  Han Huang and
                  Hao Feng and
                  Leilei Sun and
                  Bowen Du and
                  Yanjie Fu},
	title = {PriSTI: {A} Conditional Diffusion Framework for Spatiotemporal Imputation},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {1927--1939},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00150},
	doi = {10.1109/ICDE55515.2023.00150},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LiuHFS0F23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Spatiotemporal data mining plays an important role in air quality monitoring, crowd flow modeling, and climate forecasting. However, the originally collected spatiotemporal data in real-world scenarios is usually incomplete due to sensor failures or transmission loss. Spatiotemporal imputation aims to fill the missing values according to the observed values and the underlying spatiotemporal dependence of them. The previous dominant models impute missing values autoregressively and suffer from the problem of error accumulation. As emerging powerful generative models, the diffusion probabilistic models can be adopted to impute missing values conditioned by observations and avoid inferring missing values from inaccurate historical imputation. However, the construction and utilization of conditional information are inevitable challenges when applying diffusion models to spatiotemporal imputation. To address above issues, we propose a conditional diffusion framework for spatiotemporal imputation with enhanced prior modeling, named PriSTI. Our proposed framework provides a conditional feature extraction module first to extract the coarse yet effective spatiotemporal dependencies from conditional information as the global context prior. Then, a noise estimation module transforms random noise to realistic values, with the spatiotemporal attention weights calculated by the conditional feature, as well as the consideration of geographic relationships. PriSTI outperforms existing imputation methods in various missing patterns of different real-world spatiotemporal data, and effectively handles scenarios such as high missing rates and sensor failure. The implementation code is available at https://github.com/LMZZML/PriSTI.}
}


@inproceedings{DBLP:conf/icde/You0WBWD23,
	author = {Xuanke You and
                  Lan Zhang and
                  Junyang Wang and
                  Zhimin Bao and
                  Yunfei Wu and
                  Shuaishuai Dong},
	title = {{ENLD:} Efficient Noisy Label Detection for Incremental Datasets in
                  Data Lake},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {1940--1952},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00151},
	doi = {10.1109/ICDE55515.2023.00151},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/You0WBWD23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Due to the difficulty of obtaining high-quality data in real-world scenarios, datasets inevitably contain noisy labeled data, leading to inefficient data usage and poor model performance. Thus, noisy label detection is an important research topic. Previous efforts mainly focus on noisy label detection on specific datasets that have been collected. Some works select clean samples based on relations between representations during the training process; some works utilize confidence outputs of a pre-trained model for noisy label detection. However, how to perform efficient and fine-grained noisy label detection on constantly arriving datasets in a data lake with a large amount of inventory data has not been explored. The rapidly growing volume and changing distribution of data make conventional methods either incur large computation overhead due to repeated training or become increasingly ineffective on newly arriving data. To address these challenges, in this work, we propose a novel approach ENLD to perform efficient and accurate noisy label detection on incremental datasets. Our extensive experiments demonstrate that ENLD outperforms the next best method in both efficiency and accuracy, which achieves 3.65 ×-4.97× detection speedup and higher average f1 scores with various noise rate settings.}
}


@inproceedings{DBLP:conf/icde/FanGL0Z00XUZ23,
	author = {Zhuochen Fan and
                  Jiarui Guo and
                  Xiaodong Li and
                  Tong Yang and
                  Yikai Zhao and
                  Yuhan Wu and
                  Bin Cui and
                  Yanwei Xu and
                  Steve Uhlig and
                  Gong Zhang},
	title = {Finding Simplex Items in Data Streams},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {1953--1966},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00152},
	doi = {10.1109/ICDE55515.2023.00152},
	timestamp = {Fri, 24 Nov 2023 13:37:52 +0100},
	biburl = {https://dblp.org/rec/conf/icde/FanGL0Z00XUZ23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we propose a new type of item in data streams, called simplex items. Simplex items have frequencies in consecutive p windows that can be approximated by a polynomial of degree at most k, where k = 0, 1, 2. These low-order representable simplex items have a wide range of potential applications. For example, when k = 1, we can leverage these items whose frequency has obvious linear increase or decrease to speed up the running time of a class of machine learning models and detect network attacks such as distributed denial-of-service (DDoS), etc. To find k-degree simplex items in real time, we propose a novel sketch, namely X-Sketch, to accurately record simplex items in a compact space. The key idea of X-Sketch is to effectively filter out non-simplex items with less memory overhead, and then monitor the remaining potential simplex items and keep those items with more consecutive windows. We conduct extensive experiments, and the experimental results show that the F1 Score of X-Sketch is on average 68.6%, 57.9%, and 42.2% higher than the baseline solution for k = 0, 1, 2, respectively. Finally, we also provide a case study that applies X-Sketch to "accelerate" the two machine learning models through end-to-end experiments. We have released our source code at GitHub.}
}


@inproceedings{DBLP:conf/icde/YuS23,
	author = {Shangdi Yu and
                  Julian Shun},
	title = {Parallel Filtered Graphs for Hierarchical Clustering},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {1967--1980},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00153},
	doi = {10.1109/ICDE55515.2023.00153},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/YuS23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Given all pairwise weights (distances) among a set of objects, filtered graphs provide a sparse representation by only keeping an important subset of weights. Such graphs can be passed to graph clustering algorithms to generate hierarchical clusters. In particular, the directed bubble hierarchical tree (DBHT) algorithm on filtered graphs has been shown to produce good hierarchical clusters for time series data.We propose a new parallel algorithm for constructing triangulated maximally filtered graphs (TMFG), which produces valid inputs for DBHT, and a scalable parallel algorithm for generating DBHTs that is optimized for TMFG inputs. In addition to parallelizing the original TMFG construction, which has limited parallelism, we also design a new algorithm that inserts multiple vertices on each round to enable more parallelism. We show that the graphs generated by our new algorithm have similar quality compared to the original TMFGs, while being much faster to generate. Our new parallel algorithms for TMFGs and DBHTs are 136-2483x faster than state-of-the-art implementations, while achieving up to 41.56x self-relative speedup on 48 cores with hyper-threading, and achieve better clustering results compared to the standard average-linkage and complete-linkage hierarchical clustering algorithms. We show that on a stock data set, our algorithms produce clusters that align well with human experts’ classification.}
}


@inproceedings{DBLP:conf/icde/LiPP23,
	author = {Zhaoheng Li and
                  Xinyu Pi and
                  Yongjoo Park},
	title = {{S/C:} Speeding up Data Materialization with Bounded Memory},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {1981--1994},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00393},
	doi = {10.1109/ICDE55515.2023.00393},
	timestamp = {Sun, 04 Aug 2024 19:37:46 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LiPP23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With data pipeline tools and the expressiveness of SQL, managing interdependent materialized views (MVs) are becoming increasingly easy. These MVs are updated repeatedly upon new data ingestion (e.g., daily), from which database admins can observe performance metrics (e.g., refresh time of each MV, size on disk) in a consistent way for different types of updates (full vs. incremental) and for different systems (single node, distributed, cloud-hosted). One missed opportunity is that existing data systems treat those MV updates as independent SQL statements without fully exploiting their dependency information and performance metrics. However, if we know that the result of a SQL statement will be consumed immediately after for subsequent operations, those subsequent operations do not have to wait until the early results are fully materialized on storage because the results are already readily available in memory. Of course, this may come at a cost because keeping those results in memory (even temporarily) will reduce the amount of available memory; thus, our decision should be careful.In this paper, we introduce a new system, called S/C, which tackles this problem through efficient creation and update of a set of MVs with acyclic dependencies among them. S/C judiciously uses bounded memory to reduce the end-to-end MV refresh time by short-circuiting expensive reads and writes; S/C’s objective function accurately estimates the time savings from keeping intermediate data in memory for particular periods. Our solution jointly optimizes an MV refresh order, what data to keep in memory, and when to release the data from memory. At a high level, S/C still materializes all data exactly as defined in MV definitions; thus, it does not impact any service-level agreements. In our experiments with TPC-DS datasets (up to 1TB), we show that S/C's optimization can speedup end-to-end runtime by 1.04×–5.08× with (only) 1.6GB memory.}
}


@inproceedings{DBLP:conf/icde/MaGWSW23,
	author = {Hanchao Ma and
                  Sheng Guan and
                  Mengying Wang and
                  Qi Song and
                  Yinghui Wu},
	title = {Fair Group Summarization with Graph Patterns},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {1982--1994},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00154},
	doi = {10.1109/ICDE55515.2023.00154},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/MaGWSW23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Given a set of node groups in a graph (e.g., gender or race groups), how to succinctly summarize their neighbors, and meanwhile ensure a "fair" representation to mitigate under- or over-representation of a certain group? We propose a novel framework to compute concise summaries of node groups with fairness guarantees. (1) We introduce a pattern-correction structure called r-summaries. An r-summary uses a graph pattern set to specify representative nodes and an auxiliary edge correction set to losslessly describe their r-hop neighbors. (2) We formulate the fair group summarization problem, which is to compute an r-summary that can select and accurately describe high quality nodes and their neighbors with small edge corrections, and meanwhile guarantee a desirable coverage for each group. The need for generating such summaries is evident in social recommendation, healthcare and graph search. We show that the problem is\nΣ\np\n2\n-complete with the verification problem already NP-complete. (3) We present approximation algorithms that can generate r-summaries with (a) guaranteed quality and coverage properties, and (b) relative approximations on optimal edge correction costs. For large groups, we introduce an efficient algorithm that interleaves node selection and localized pattern discovery to reduce unnecessary computation. In addition, we introduce an algorithm to incrementally maintain the r-summaries over dynamic graphs with evolving edges. Using real-world data, we experimentally verify the efficiency and effectiveness of our algorithms and verify their applications.}
}


@inproceedings{DBLP:conf/icde/AlsaediSMT23,
	author = {Abdullah Alsaedi and
                  Nasrin Sohrabi and
                  Md. Redowan Mahmud and
                  Zahir Tari},
	title = {{RADAR:} Reactive Concept Drift Management with Robust Variational
                  Inference for Evolving IoT Data Streams},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {1995--2007},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00155},
	doi = {10.1109/ICDE55515.2023.00155},
	timestamp = {Sun, 12 Nov 2023 02:08:10 +0100},
	biburl = {https://dblp.org/rec/conf/icde/AlsaediSMT23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The accuracy and performance of Machine Learning (ML) models can gradually or even suddenly degrade when the underlying statistical distribution of data streams changes over time; this is known as concept drift. This phenomenon could adversely affect the IoT data management and analysis landscape that relies intensely on data-driven cognitive technologies. Therefore, concept drift should be detected immediately, which is challenging due to the increasing number of dimensional features and lack of ground truth. Its adaptive countermeasures also become difficult to design when data streams are being generated frequently and require latency-sensitive responses. The uncertainty and time dependencies characteristics of IoT data streams further intensify the complexity of concept drift management. This work proposes a reactive drift management framework named RADAR for streaming IoT applications that can simultaneously detect and react to concept drift using two novel methods: temporal discrepancy measure, and intensity-aware analyser. Collectively, these methods help to determine the adaptation decision to ensure reliable performance, thereby limiting the scope of the frequent ML model update. Experiments conducted using synthetic and real-world setups comprising end-to-end systems demonstrate that RADAR outperforms other benchmarks in achieving better improvement of the performance with the best F-score of 0.86, and obtaining efficient runtime with large data streams.}
}


@inproceedings{DBLP:conf/icde/HeZ023,
	author = {Jintao He and
                  Jiaqi Zhu and
                  Qun Huang},
	title = {HistSketch: {A} Compact Data Structure for Accurate Per-Key Distribution
                  Monitoring},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {2008--2021},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00156},
	doi = {10.1109/ICDE55515.2023.00156},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/HeZ023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Stream processing is critical to data analytics. However, one important class of characteristics namely per-key distribution (i.e., the item distribution of every key) remains unsolved. Traditional stream processing methods such as sampling and histogram do not focus on per-key distribution. Though sketch is widely applied to deal with huge and high-speed streaming data, it mainly computes singular-value characteristics. However, per-key distribution needs to deal with multiple values for each key, which amplifies the needed resources.To this end, we present a novel sketch-based algorithm HistSketch for per-key distribution. Its key idea is to differentiate hot keys from infrequent keys and use different components to deal with them. For hot keys, HistSketch allocates dedicated counters. For infrequent keys, HistSketch allows counter sharing to alleviate memory usage. In addition, we propose two optimization mechanisms for HistSketch: the histogram shedding mechanism further reduces the storage overheads, while the equation-based decoding compensates for the error caused by counter sharing. Our evaluation compares HistSketch with nine state-of-the-art sketch-based solutions using five datasets. Our results show that HistSketch achieves both high accuracy and low resource usage.}
}


@inproceedings{DBLP:conf/icde/MiaoDZZ0Y0023,
	author = {Ruijie Miao and
                  Fenghao Dong and
                  Yikai Zhao and
                  Yiming Zhao and
                  Yuhan Wu and
                  Kaicheng Yang and
                  Tong Yang and
                  Bin Cui},
	title = {SketchConf: {A} Framework for Automatic Sketch Configuration},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {2022--2035},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00157},
	doi = {10.1109/ICDE55515.2023.00157},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/MiaoDZZ0Y0023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Sketches have risen as promising solutions for frequency estimation, which is one of the most fundamental tasks in approximate data stream processing. In many scenarios, users have a strong demand to apply sketches under the expected error constraints. In this paper, we explore how to configure sketch parameters to satisfy user-defined error constraints. We propose SketchConf, an automatic sketch configuration framework, which efficiently generates memory-optimal configurations for the first time. We show that SketchConf can be applied to order-independent sketches, including CM, Count, Tower, and Nitro sketches. We further discuss how to deal with the unknown and changeable workloads when applying SketchConf to the real scenarios of streaming data processing. Experimental results show that SketchConf can be up to 715.51 times faster than the baseline algorithm, and the outputted configurations save up to 99.99% memory and achieve up to 27.44 times throughput, compared with the theory-based configurations. The code is open sourced at Github.}
}


@inproceedings{DBLP:conf/icde/WangZG0L0TZ023,
	author = {Ziwei Wang and
                  Zheng Zhong and
                  Jiarui Guo and
                  Yuhan Wu and
                  Haoyu Li and
                  Tong Yang and
                  Yaofeng Tu and
                  Huanchen Zhang and
                  Bin Cui},
	title = {REncoder: {A} Space-Time Efficient Range Filter with Local Encoder},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {2036--2049},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00158},
	doi = {10.1109/ICDE55515.2023.00158},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/WangZG0L0TZ023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A range filter is a data structure to answer range membership queries. Range queries are common in modern applications, and range filters have gained rising attention for improving the performance of range queries by ruling out empty range queries. However, state-of-the-art range filters, such as SuRF and Rosetta, suffer either high false positive rate or low throughput. In this paper, we propose a novel range filter, called REncoder. It organizes all prefixes of keys into a segment tree, and locally encodes the segment tree into a Bloom filter to accelerate queries. REncoder supports diverse workloads by adaptively choosing how many levels of the segment tree to store. We theoretically prove that the error of REncoder is bounded and derive the asymptotic space complexity under the bounded error. We conduct extensive experiments on both synthetic datasets and real datasets. The experimental results show that REncoder outperforms all state-of-the-art range filters.}
}


@inproceedings{DBLP:conf/icde/KuiperM23,
	author = {Laurens Kuiper and
                  Hannes M{\"{u}}hleisen},
	title = {These Rows Are Made for Sorting and That's Just What We'll Do},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {2050--2062},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00159},
	doi = {10.1109/ICDE55515.2023.00159},
	timestamp = {Sun, 04 Aug 2024 19:37:46 +0200},
	biburl = {https://dblp.org/rec/conf/icde/KuiperM23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Sorting is one of the most well-studied problems in computer science and a vital operation for relational database systems. Despite this, little research has been published on implementing an efficient relational sorting operator. In this work, we explore the design space of sorting in a relational database system. We use micro-benchmarks to explore how to sort relational data efficiently in analytical database systems, taking into account different query execution engines as well as row and columnar data formats. We show that, regardless of architectural differences between query engines, sorting rows is almost always more efficient than sorting columnar data, even if this requires converting the data from columns to rows and back. Sorting rows efficiently is challenging for systems with an interpreted execution engine, as their implementation has to stay generic. We show that these challenges can be overcome with several existing techniques. Based on our findings, we implement a highly optimized row-based sorting approach in the DuckDB open-source in-process analytical database management system, which has a vectorized interpreted query engine. We compare DuckDB with four analytical database systems and find that DuckDB’s sort implementation outperforms query engines that sort using a columnar data format.}
}


@inproceedings{DBLP:conf/icde/000100ZL23,
	author = {Zhengyi Yang and
                  Wenjie Zhang and
                  Xuemin Lin and
                  Ying Zhang and
                  Shunyang Li},
	title = {HGMatch: {A} Match-by-Hyperedge Approach for Subgraph Matching on
                  Hypergraphs},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {2063--2076},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00160},
	doi = {10.1109/ICDE55515.2023.00160},
	timestamp = {Sun, 04 Aug 2024 19:37:45 +0200},
	biburl = {https://dblp.org/rec/conf/icde/000100ZL23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Hypergraphs are a generalisation of graphs in which a hyperedge can connect any number of vertices. It can describe n-ary relationships and high-order information among entities compared to conventional graphs. In this paper, we study the fundamental problem of subgraph matching on hypergraphs (i.e., subhypergraph matching). Existing methods directly extend sub-graph matching algorithms to the case of hypergraphs. However, this approach delays hyperedge verification and underutilises the high-order information in hypergraphs, which leads to large search space and high enumeration costs. Furthermore, with the growing size of hypergraphs, it is becoming hard to compute subhypergraph matching sequentially. Thus, we propose an efficient and parallel subhypergraph matching system, HGMatch, to handle subhypergraph matching in massive hypergraphs. We propose a novel match-by-hyperedge framework to utilise high-order information in hypergraphs and use set operations for efficient candidate generation. Moreover, we develop an optimised parallel execution engine in HGMatch based on the dataflow model, which features a task-based scheduler and fine-grained dynamic work stealing to achieve bounded memory execution and better load balancing. Experimental evaluation on 10 real-world datasets shows that HGMatch outperforms the extended version of the state-of-the-art subgraph matching algorithms (CFL, DAF, CECI, and RapidMatch) by orders of magnitude when using a single thread, and achieves almost linear scalability when the number of threads increases.}
}


@inproceedings{DBLP:conf/icde/DanPZ023,
	author = {Tangpeng Dan and
                  Xiao Pan and
                  Bolong Zheng and
                  Xiaofeng Meng},
	title = {Double Hierarchical Labeling Shortest Distance Querying in Time-dependent
                  Road Networks},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {2077--2089},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00161},
	doi = {10.1109/ICDE55515.2023.00161},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/DanPZ023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A shortest distance query is a fundamental operation of various real-time response applications in time-dependent road networks. Unfortunately, existing methods (e.g., G-treelike, 2-hop labeling-like) are prohibitively expensive in terms of space/time. To this end, we propose a novel Double Hierarchical Labeling (DHL) index, which consists of a Hierarchical Graph Partition (HGP) tree and a hierarchical border labeling list. For HGP-tree, we first use a hierarchical graph partitioning to split the entire road network into hierarchical subgraphs and then index these subgraphs by a balanced tree. To preserve all connectivity information between border vertices of subgraphs, a Time-based Distance Inverted File (TDIF) is constructed for each leaf node of the HGP-tree. For the hierarchical labeling list, we construct it only for border vertices and use it to speed up query processing. Moreover, a label propagation update is proposed to manage label updating when weights change. Finally, we propose a phase-aware search algorithm for different search situations between given query vertices to guarantee query efficiency. Extensive experiments are conducted to demonstrate the superiority of the proposed proposals on query processing and index maintenance.}
}


@inproceedings{DBLP:conf/icde/QiuMHL023,
	author = {Rui Qiu and
                  Yi Ming and
                  Yisen Hong and
                  Haoyu Li and
                  Tong Yang},
	title = {Wind-Bell Index: Towards Ultra-Fast Edge Query for Graph Databases},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {2090--2098},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00162},
	doi = {10.1109/ICDE55515.2023.00162},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/QiuMHL023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graphs are good at presenting relational and structural information, making it powerful in the representation of various data. For the efficient storage and processing of graph-like data, graph databases have been rapidly developed and extensively studied. However, graph databases mostly use adjacency lists as their basic data structure (e.g., Neo4j), which could result in poor performance of edge due to the skewed degree distribution of graphs.We design the Wind-Bell Index to address this problem. Wind-Bell Index is a memory-efficient index data structure, which can be attached to existing graph databases to speed up the edge. We have fully implemented our data structure in Neo4j, the most popular graph database today, and conduct theoretical and experimental analysis to evaluate the performance. Theoretical results prove the high query efficiency of our algorithm. And experimental results show that the average edge query speed is increased by hundreds of times compared with the original query interface of Neo4j. We believe that the excellent performance and scalability of Wind-Bell Index make it suitable for the application in a variety of graph databases.}
}


@inproceedings{DBLP:conf/icde/SuL023,
	author = {Xunbin Su and
                  Yinnian Lin and
                  Lei Zou},
	title = {{FASI:} FPGA-friendly Subgraph Isomorphism on Massive Graphs},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {2099--2112},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00163},
	doi = {10.1109/ICDE55515.2023.00163},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/SuL023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Subgraph isomorphism plays a significant role in many applications, such as social networks and bioinformatics. However, due to the inherent NP-hardness, it becomes challenging to compute matches efficiently in large real-world graphs. Many researchers have attempted to solve this problem with the help of new hardware. Nevertheless, most of them focus on GPU. Due to the dataflow feature and burst I/O optimization, FPGA is a potential competitor to speed up subgraph isomorphism. However, there are very few subgraph matching algorithms on FPGA. In this paper, we present an efficient FPGA-friendly Subgraph Isomorphism algorithm FASI, designed on CPU- FPGA heterogeneous platform which leverages FPGA's features. Unlike the existing FPGA-based method FAST, we adopt the worst-case-optimal-join-based pipeline design. First, we propose an FPGA-friendly data structure LPCSR for efficient access to neighbor lists. Second, we offer a joint parallelized pipeline strategy to accelerate matching process. Third, we propose a memory coalescing mechanism and a space-saving pre-allocated write back strategy. Our experiments on both synthetic and real graphs show that FASI outperforms other state-of-the-art subgraph matching algorithms on CPU, GPU and FPGA.}
}


@inproceedings{DBLP:conf/icde/WangTZZPF023,
	author = {Yansheng Wang and
                  Yongxin Tong and
                  Zimu Zhou and
                  Ruisheng Zhang and
                  Sinno Jialin Pan and
                  Lixin Fan and
                  Qiang Yang},
	title = {Distribution-Regularized Federated Learning on Non-IID Data},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {2113--2125},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00164},
	doi = {10.1109/ICDE55515.2023.00164},
	timestamp = {Tue, 07 May 2024 20:05:36 +0200},
	biburl = {https://dblp.org/rec/conf/icde/WangTZZPF023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated learning (FL) has emerged as a popular machine learning paradigm recently. Compared with traditional distributed learning, its unique challenges mainly lie in communication efficiency and non-IID (heterogeneous data) problem. While the widely adopted framework FedAvg can reduce communication overhead significantly, its effectiveness on non-IID data still lacks exploration. In this paper, we study the non-IID problem of FL from the perspective of domain adaptation. We propose a distribution regularization for FL on non-IID data such that the discrepancy of data distributions between clients is reduced. To further reduce the communication cost, we devise two novel distributed learning algorithms, namely rFedAvg and rFedAvg+, for efficiently learning with the distribution regularization. More importantly, we theoretically establish their convergence for strongly convex objectives. Extensive experiments on 4 datasets with both CNN and LSTM as learning models verify the effectiveness and efficiency of the proposed algorithms.}
}


@inproceedings{DBLP:conf/icde/Wang0SL23,
	author = {Jing Wang and
                  Xiaojun Ning and
                  Wangjun Shi and
                  Youfang Lin},
	title = {A Bayesian Graph Neural Network for {EEG} Classification - {A} Win-Win
                  on Performance and Interpretability},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {2126--2139},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00165},
	doi = {10.1109/ICDE55515.2023.00165},
	timestamp = {Tue, 01 Aug 2023 18:06:05 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Wang0SL23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the deepening of neuroscience research, data mining of brain signals is becoming an emerging topic. Among various brain signals, electroencephalography (EEG) has attracted more and more attention due to its advantages of non-invasiveness, portability, and low cost. EEG modeling and analysis play a vital role in human healthcare. Although many machine learning algorithms have been successfully applied to data mining of EEG signals, few of them achieve a win-win in classification performance and interpretability. In this paper, we propose a Bayesian graph neural network named BayesEEGNet. Considering an electrical impulse between two nodes in the brain as a Poisson process, the countless electrical impulses generated by the brain in a period are represented as an infinite number of connection probability graphs. After coupling and transforming these probability graphs, we interpret the brain’s electrical activity state as the brain’s perceptual state. Benefiting from the joint optimization of Bayesian modules and deep neural networks, our model shows superior classification performance in sleep stage classification and emotion recognition tasks. Meanwhile, our model is able to learn interpretable functional connectivity relationships between EEG channels without any prior knowledge.}
}


@inproceedings{DBLP:conf/icde/0002EFK23,
	author = {Rui Liu and
                  Aaron J. Elmore and
                  Michael J. Franklin and
                  Sanjay Krishnan},
	title = {Rotary: {A} Resource Arbitration Framework for Progressive Iterative
                  Analytics},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {2140--2153},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00166},
	doi = {10.1109/ICDE55515.2023.00166},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/0002EFK23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Increasingly modern computing applications employ progressive iterative analytics, as best exemplified by two prevalent cases, approximate query processing (AQP) and deep learning training (DLT). In comparison to classic computing applications that only return the results after processing all the input data, progressive iterative analytics keep providing approximate or partial results to users by performing computations on a subset of the entire dataset until either the users are satisfied with the results, or the predefined completion criteria are achieved. Typically, progressive iterative analytic jobs have various completion criteria, produce diminishing returns, and process data at different rates, which necessitates a novel resource arbitration that can continuously prioritize the progressive iterative analytic jobs and determine if/when to reallocate and preempt the resources. We propose and design a resource arbitration framework, Rotary, and implement two resource arbitration systems, Rotary-AQP and Rotary-DLT, for approximate query processing and deep learning training. We build a TPC-H based AQP workload and a survey-based DLT workload to evaluate the two systems, respectively. The evaluation results demonstrate that Rotary-AQP and Rotary-DLT outperform the state-of-the-art systems and confirm the generality and practicality of the proposed resource arbitration framework.}
}


@inproceedings{DBLP:conf/icde/XuLHGMLCZ23,
	author = {Wujiang Xu and
                  Shaoshuai Li and
                  Mingming Ha and
                  Xiaobo Guo and
                  Qiongxu Ma and
                  Xiaolei Liu and
                  Linxun Chen and
                  Zhenfeng Zhu},
	title = {Neural Node Matching for Multi-Target Cross Domain Recommendation},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {2154--2166},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00167},
	doi = {10.1109/ICDE55515.2023.00167},
	timestamp = {Tue, 07 May 2024 20:05:36 +0200},
	biburl = {https://dblp.org/rec/conf/icde/XuLHGMLCZ23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Multi-Target Cross Domain Recommendation(CDR) has attracted a surge of interest recently, which intends to improve the recommendation performance in multiple domains (or systems) simultaneously. Most existing multi-target CDR frameworks primarily rely on the existence of the majority of overlapped users across domains. However, general practical CDR scenarios cannot meet the strictly overlapping requirements and only share a small margin of common users across domains. Additionally, the majority of users have quite a few historical behaviors in such small-overlapping CDR scenarios. To tackle the aforementioned issues, we propose a simple-yet-effective neural node matching based framework for more general CDR settings, i.e., only (few) partially overlapped users exist across domains and most overlapped as well as non-overlapped users do have sparse interactions. The present framework mainly contains two modules: (i) intra-to-inter node matching module, and (ii) intra node complementing module. Concretely, the first module conducts intra-knowledge fusion within each domain and subsequent inter-knowledge fusion across domains by fully connected user-user homogeneous graph information aggregating. By doing this, the knowledge of all users, especially the non-overlapping users, could be well extracted and transferred without relying heavily on overlapping users. The second module introduces user-item matching to complement the potential missing interactions for each user and correct his/her under-represented representations, especially for the users with observed sparse interactions. Essentially, companion objectives are also inserted into each module to guide the knowledge transferring procedures, which leads to positive effects on multiple domains simultaneously. Extensive experiments on four multi-target CDR tasks from both public and real-world large-scale financial industry datasets demonstrate the remarkable performance of our proposed approach. Our code is publicly available at the link: https://github.com/WujiangXu/NMCDRR.}
}


@inproceedings{DBLP:conf/icde/LiMJ23,
	author = {Jinyang Li and
                  Yuval Moskovitch and
                  H. V. Jagadish},
	title = {Detection of Groups with Biased Representation in Ranking},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {2167--2179},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00168},
	doi = {10.1109/ICDE55515.2023.00168},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LiMJ23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Real-life tools for decision-making in many critical domains are based on ranking results. With the increasing awareness of algorithmic fairness, recent works have presented measures for fairness in ranking. Many of those definitions consider the representation of different "protected groups", in the top-k ranked items, for any reasonable k. Given the protected groups, confirming algorithmic fairness is a simple task. However, the groups’ definitions may be unknown in advance.In this paper, we study the problem of detecting groups with biased representation in the top-k ranked items, eliminating the need to pre-define protected groups. The number of such groups possible can be exponential, making the problem hard. We propose efficient search algorithms for two different fairness measures: global representation bounds, and proportional representation. Then we propose a method to explain the bias in the representations of groups utilizing the notion of Shapley values. We conclude with an experimental study, showing the scalability of our approach and demonstrating the usefulness of the proposed algorithms.}
}


@inproceedings{DBLP:conf/icde/Du0F00FS23,
	author = {Rong Du and
                  Qingqing Ye and
                  Yue Fu and
                  Haibo Hu and
                  Jin Li and
                  Chengfang Fang and
                  Jie Shi},
	title = {Differential Aggregation against General Colluding Attackers},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {2180--2193},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00169},
	doi = {10.1109/ICDE55515.2023.00169},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Du0F00FS23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Local Differential Privacy (LDP) is now widely adopted in large-scale systems to collect and analyze sensitive data while preserving users’ privacy. However, almost all LDP protocols rely on a semi-trust model where users are curious-but-honest, which rarely holds in real-world scenarios. Recent works [6], [11], [62] show poor estimation accuracy of many LDP protocols under malicious threat models. Although a few works have proposed some countermeasures to address these attacks, they all require prior knowledge of either the attacking pattern or the poison value distribution, which is impractical as they can be easily evaded by the attackers.In this paper, we adopt a general opportunistic-and-colluding threat model and propose a multi-group Differential Aggregation Protocol (DAP) to improve the accuracy of mean estimation under LDP. Different from all existing works that detect poison values on individual basis, DAP mitigates the overall impact of poison values on the estimated mean. It relies on a new probing mechanism EMF (i.e., Expectation-Maximization Filter) to estimate features of the attackers. In addition to EMF, DAP also consists of two EMF post-processing procedures (EMF* and CEMF*), and a group-wise mean aggregation scheme to optimize the final estimated mean to achieve the smallest variance. Extensive experimental results on both synthetic and real-world datasets demonstrate the superior performance of DAP over state-of-the-art solutions.}
}


@inproceedings{DBLP:conf/icde/Chen0ZWLW023,
	author = {Jian Chen and
                  Hong Gao and
                  Kaiqi Zhang and
                  Jiachi Wang and
                  Yubo Luo and
                  Zhenqing Wu and
                  Jianzhong Li},
	title = {Towards Efficient {MIT} query in Trajectory Data},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {2194--2206},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00170},
	doi = {10.1109/ICDE55515.2023.00170},
	timestamp = {Fri, 14 Jun 2024 12:30:22 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Chen0ZWLW023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Maximizing Influence (Max-Inf) query is a fundamental operation in spatial data management. Given a set of weighted objects, this query aims to find an optimal location from a candidate set to maximize its influence, which is the total weight of its reverse nearest neighbors. Existing work commonly assumes that every object is in a fixed location. In real life, however, there are a wide variety of drive-in services (e.g., food joints, fuel stations, ATMs, etc.) that are widely accessed by mobile users (i.e., trajectories) instead of the fixed ones. It is urgent and challenging to solve the Max-Inf query in trajectory data (MIT). In this paper, we first define the MIT query which aims to find the optimal location to maximize the total weight of influenced trajectories. We propose a novel index structure, QB-tree to hierarchically group trajectories with similar activity regions together for subsequent unified processing, and classify trajectories inside the same node into multiple buckets according to their motion patterns. For each bucket, we construct a rectilinear polygon using the trajectories in it to exclude some irrelevant areas in the minimum boundary rectangle. Moreover, we develop a branch-and-bound approach called BBM to efficiently solve the MIT query. The algorithm adaptively partitions the candidates into disjoint regions and prunes the regions without containing optimal results. Then, by exploiting the QB-tree, the upper and lower bounds are efficiently computed with three-level pruning technique. Finally, we conduct extensive experiments on real and synthetic datasets to evaluate our index and algorithms, and the experimental results demonstrate that our algorithm has high performance in terms of efficiency, scalability, and genericity.}
}


@inproceedings{DBLP:conf/icde/ChenCYH0ZJQ23,
	author = {Lixiang Chen and
                  Ruihao Chen and
                  Chengcheng Yang and
                  Yuxing Han and
                  Rong Zhang and
                  Xuan Zhou and
                  Peiquan Jin and
                  Weining Qian},
	title = {Workload-Aware Log-Structured Merge Key-Value Store for {NVM-SSD}
                  Hybrid Storage},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {2207--2219},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00171},
	doi = {10.1109/ICDE55515.2023.00171},
	timestamp = {Thu, 19 Oct 2023 11:19:36 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ChenCYH0ZJQ23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The log-structured merge tree (LSM-tree) has been widely adopted as a backbone of modern key-value stores. However, the multiple exponentially increased levels of LSM-tree makes it suffer from high write amplification. Existing studies often improve the write performance by sacrificing the read performance, which is inefficient to make trade-offs between the update and search efficiency. In this paper, we exploit nonvolatile memory (NVM) to address the write amplification issue for systems with NVM-SSD hybrid storage, and further propose a reinforcement learning method to navigate between update and search efficiency on the varying workloads. Specifically, we first propose a lightweight hot data identification method to efficiently capture access recency as well as frequency in NVM with relative large capacity. On this basis, we can eliminate different versions of frequently updated data in high-performance NVM without pushing them to SSD. To improve the data access locality and facilitate fine-grained index tuning in each level, we devise a virtual-split method to partition the key space gradually without extra write amplification. Finally, we propose a cost based Q-learning algorithm to adaptively tune the data organizations of each partition according to the changing access patterns. Experimental results show that our approach outperforms existing methods by up to 2.67×.}
}


@inproceedings{DBLP:conf/icde/Pang0L23,
	author = {Yue Pang and
                  Lei Zou and
                  Yu Liu},
	title = {{IFCA:} Index-Free Community-Aware Reachability Processing Over Large
                  Dynamic Graphs},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {2220--2234},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00172},
	doi = {10.1109/ICDE55515.2023.00172},
	timestamp = {Sun, 04 Aug 2024 19:37:45 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Pang0L23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Reachability is a fundamental graph operator. State-of-the-art index-based reachability processing frameworks can efficiently handle static graphs, but the recent advent of dynamic graph data poses new challenges. To address these challenges, we propose an index-free, community-aware (IFCA) reachability processing framework inspired by efficient Personalized PageRank approximation algorithms, which identifies community structures on-the-fly to accelerate query processing. On top of it, we devise a community contraction technique to bridge the gap between vertices in distinct communities, and a cost-based strategy selection procedure to efficiently handle the resulting reduced graph. We conduct experiments with realistic query workloads over large-scale real dynamic graphs, showing our approach’s superior efficiency compared with index-based and index-free state-of-the-art methods.}
}


@inproceedings{DBLP:conf/icde/Li0C0J23,
	author = {Xiao Li and
                  Huan Li and
                  Harry Kai{-}Ho Chan and
                  Hua Lu and
                  Christian S. Jensen},
	title = {Data Imputation for Sparse Radio Maps in Indoor Positioning},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {2235--2248},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00173},
	doi = {10.1109/ICDE55515.2023.00173},
	timestamp = {Wed, 29 Nov 2023 13:14:19 +0100},
	biburl = {https://dblp.org/rec/conf/icde/Li0C0J23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Indoor location-based services rely on the availability of sufficiently accurate positioning in indoor spaces. A popular approach to positioning relies on so-called radio maps that contain pairs of a vector of Wi-Fi signal strength indicator values (RSSIs), called a fingerprint, and a location label, called a reference point (RP), in which the fingerprint was observed. The positioning accuracy depends on the quality of the radio maps and their fingerprints. Radio maps are often sparse, with many pairs containing vectors missing many RSSIs as well as RPs. Aiming to improve positioning accuracy, we present a complete set of techniques to impute such missing values in radio maps. We differentiate two types of missing RSSIs: missing not at random (MNAR) and missing at random (MAR). Specifically, we design a framework encompassing a missing RSSI differentiator followed by a data imputer for missing values. The differentiator identifies MARs and MNARs via clustering-based fingerprint analysis. Missing RSSIs and RPs are then imputed jointly by means of a novel encoder-decoder architecture that leverages temporal dependencies in data collection as well as correlations among fingerprints and RPs. A time-lag mechanism is used to consider the aging of data, and a sparsity-friendly attention mechanism is used to focus attention score calculation on observed data. Extensive experiments with real data from two buildings show that our proposal outperforms the alternatives with significant advantages in terms of imputation accuracy and indoor positioning accuracy.}
}


@inproceedings{DBLP:conf/icde/HoHP23,
	author = {Van Long Ho and
                  Nguyen Ho and
                  Torben Bach Pedersen},
	title = {Mining Seasonal Temporal Patterns in Time Series},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {2249--2261},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00174},
	doi = {10.1109/ICDE55515.2023.00174},
	timestamp = {Sat, 30 Sep 2023 09:44:50 +0200},
	biburl = {https://dblp.org/rec/conf/icde/HoHP23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As IoT-enabled sensors become more pervasive, very large time series data are increasingly generated and made available for advanced data analytics. By mining temporal patterns from the available data, valuable insights can be extracted to support decision making. A useful type of patterns found in many real-world applications exhibits periodic occurrences, and is thus called seasonal temporal patterns (STP). Compared to regular patterns, mining seasonal temporal patterns is more challenging since traditional measures such as support and confidence do not capture the seasonality characteristics. Further, the anti-monotonicity property does not hold for STPs, and thus, resulting in an exponential search space. We propose a first solution for seasonal temporal pattern mining (STPM) from time series that can mine STP at different data granularities. We design efficient data structures and use two pruning techniques for the STPM algorithm that downsize the search space and accelerate the mining process. Further, based on the mutual information measure, we propose an approximate version of STPM that only mine seasonal patterns on the promising time series. Finally, extensive experiments with real-world and synthetic datasets show that STPM outperforms the baseline in terms of runtime and memory usage, and can scale to large datasets. The approximate STPM is up to an order of magnitude faster and less memory-consuming than the baseline, while maintaining high accuracy.}
}


@inproceedings{DBLP:conf/icde/0012FFJOY23,
	author = {Yang Cao and
                  Wenfei Fan and
                  Wenzhi Fu and
                  Ruochun Jin and
                  Weijie Ou and
                  Wenliang Yi},
	title = {Extracting Graphs Properties with Semantic Joins},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {2262--2275},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00175},
	doi = {10.1109/ICDE55515.2023.00175},
	timestamp = {Sat, 30 Sep 2023 09:44:49 +0200},
	biburl = {https://dblp.org/rec/conf/icde/0012FFJOY23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper proposes an approach to querying a relational database \\mathcal{D}\nand a graph G taken together in SQL. We introduce a semantic extension of joins across \\mathcal{D}\nand G such that if a tuple t in \\mathcal{D}\nand a vertex v in G refer to the same real-world entity, then we join t and v to correlate their information and complement tuple t with additional properties of vertex v from the graph. Moreover, we extract hidden relationships between t and other entities by exploring paths from v. To support the semantic joins, we develop an extraction scheme based on LSTM, path clustering and ranking, to fetch important properties from graphs, and incrementally maintain the extracted data in response to updates. We also provide methods for implementing static joins when t is a tuple in \\mathcal{D}\n, dynamic joins when t comes from the intermediate result of a sub-query, and heuristic joins to strike a balance between the complexity and accuracy. Using real-life data and queries, we experimentally verify the effectiveness, scalability and efficiency of the methods.}
}


@inproceedings{DBLP:conf/icde/WangWX23,
	author = {Weicheng Wang and
                  Raymond Chi{-}Wing Wong and
                  Min Xie},
	title = {Interactive Search with Mixed Attributes},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {2276--2288},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00176},
	doi = {10.1109/ICDE55515.2023.00176},
	timestamp = {Mon, 12 Aug 2024 18:35:46 +0200},
	biburl = {https://dblp.org/rec/conf/icde/WangWX23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The problem of extracting the user’s favorite tuple from a large dataset attracts a lot of attention in the database community. Existing studies attempt to search for the target tuple with the help of user interaction. Specifically, they ask a user several questions, each of which consists of two tuples and asks the user to indicate which one s/he prefers. Based on the feedback, the user preference is learned implicitly and the target tuple w.r.t. the learned preference is returned. However, they mainly consider datasets with numerical attributes (e.g., price). In practice, tuples can also be described by categorical attributes (e.g., color), where there is no trivial order in the attribute values. Even if the categorical attributes can be reduced into numerical ones using conventional strategies (e.g., one-hot encoding), existing methods do not work well. In this paper, we study how to find the user’s favorite tuple from datasets with mixed attributes (including both numerical and categorical attributes) by interacting with the user.We study our problem progressively. Firstly, we inquiry a special case in which tuples are only described by categorical attributes. We present algorithm SP-Tree that asks an asymptotically optimal number of questions. Secondly, we explore the general case in which tuples are described by numerical and categorical attributes. We propose algorithm GE-Graph that performs well theoretically and empirically. Experiments are conducted on synthetic and real datasets. The results show that our algorithms outperform existing ones on both the execution time and the number of questions asked. Under typical settings, we reduce dozens of questions asked and speed up by several orders of magnitude.}
}


@inproceedings{DBLP:conf/icde/ChenXXH23,
	author = {Min Chen and
                  Yang Xu and
                  Hongli Xu and
                  Liusheng Huang},
	title = {Enhancing Decentralized Federated Learning for Non-IID Data on Heterogeneous
                  Devices},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {2289--2302},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00177},
	doi = {10.1109/ICDE55515.2023.00177},
	timestamp = {Fri, 25 Aug 2023 12:57:38 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ChenXXH23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Data generated at the network edge can be processed locally by leveraging the emerging technology of Federated Learning (FL). However, non-IID local data will lead to degradation of model accuracy and the heterogeneity of edge nodes inevitably slows down model training efficiency. Moreover, to avoid the potential communication bottleneck in the parameter-server-based FL, we concentrate on the Decentralized Federated Learning (DFL) that performs distributed model training in Peer-to-Peer (P2P) manner. To address these challenges, we propose an asynchronous DFL system by incorporating neighbor selection and gradient push, termed AsyNG. Specifically, we require each edge node to push gradients only to a subset of neighbors for resource efficiency. Herein, we first give a theoretical convergence analysis of AsyNG under the complicated non-IID and heterogeneous scenario, and further design a priority-based algorithm to dynamically select neighbors for each edge node so as to achieve the trade-off between communication cost and model performance. We evaluate the performance of AsyNG through extensive experiments on a physical platform. Evaluation results show that AsyNG can reduce the communication cost by 60% and the completion time by about 30% for achieving the same test accuracy, compared to the baselines.}
}


@inproceedings{DBLP:conf/icde/ZhaoLJC0023,
	author = {Yusheng Zhao and
                  Xiao Luo and
                  Wei Ju and
                  Chong Chen and
                  Xian{-}Sheng Hua and
                  Ming Zhang},
	title = {Dynamic Hypergraph Structure Learning for Traffic Flow Forecasting},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {2303--2316},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00178},
	doi = {10.1109/ICDE55515.2023.00178},
	timestamp = {Tue, 16 Jul 2024 08:57:29 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhaoLJC0023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper studies the problem of traffic flow forecasting, which aims to predict future traffic conditions on the basis of road networks and traffic conditions in the past. The problem is typically solved by modeling complex spatio-temporal correlations in traffic data using spatio-temporal graph neural networks (GNNs). However, the performance of these methods is still far from satisfactory since GNNs usually have limited representation capacity when it comes to complex traffic networks. Graphs, by nature, fall short in capturing non-pairwise relations. Even worse, existing methods follow the paradigm of message passing that aggregates neighborhood information linearly, which fails to capture complicated spatio-temporal high-order interactions. To tackle these issues, in this paper, we propose a novel model named Dynamic Hypergraph Structure Learning (DyHSL) for traffic flow prediction. To learn non-pairwise relationships, our DyHSL extracts hypergraph structural information to model dynamics in the traffic networks, and updates each node representation by aggregating messages from its associated hyperedges. Additionally, to capture high-order spatio-temporal relations in the road network, we introduce an interactive graph convolution block, which further models the neighborhood interaction for each node. Finally, we integrate these two views into a holistic multi-scale correlation extraction module, which conducts temporal pooling with different scales to model different temporal patterns. Extensive experiments on four popular traffic benchmark datasets demonstrate the effectiveness of our proposed DyHSL compared with a broad range of competing baselines.}
}


@inproceedings{DBLP:conf/icde/LaiFZMPL023,
	author = {Ziliang Lai and
                  Hua Fan and
                  Wenchao Zhou and
                  Zhanfeng Ma and
                  Xiang Peng and
                  Feifei Li and
                  Eric Lo},
	title = {Knock Out 2PC with Practicality Intact: a High-performance and General
                  Distributed Transaction Protocol},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {2317--2331},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00179},
	doi = {10.1109/ICDE55515.2023.00179},
	timestamp = {Mon, 05 Feb 2024 20:31:13 +0100},
	biburl = {https://dblp.org/rec/conf/icde/LaiFZMPL023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Two-phase-commit (2PC) has been widely adopted for distributed transaction processing, but it also jeopardizes throughput by introducing two rounds of network communications and two durable log writes to a transaction's critical path. Despite the various proposals that eliminate 2PC such as deterministic database and access localization, 2PC remains the de facto standard since the alternatives often lack generality (e.g., requiring workloads without branches based on query results). In this paper, we present Primo, a distributed transaction protocol that supports a more general set of workloads without 2PC. Primo features write-conflict-free concurrency control that guarantees once a transaction enters the commit phase, no concurrency conflict (e.g., deadlock) would occur when installing the write-set — hence the prepare phase is no longer needed to account for any potential conflict from any partition. In addition, Primo further optimizes the transaction path using asynchronous group commit. With that, the durability delay is also taken off the transaction's critical path. Empirical results on Primo are encouraging – in YCSB and TPC-C, Primo attains 1.42× to 8.25× higher throughput than state-of-the-art general protocols including Sundial and COCO, while having similar latency as COCO which also employs group commit.}
}


@inproceedings{DBLP:conf/icde/XiaSH0XP23,
	author = {Lianghao Xia and
                  Yizhen Shao and
                  Chao Huang and
                  Yong Xu and
                  Huance Xu and
                  Jian Pei},
	title = {Disentangled Graph Social Recommendation},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {2332--2344},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00180},
	doi = {10.1109/ICDE55515.2023.00180},
	timestamp = {Sat, 30 Sep 2023 09:44:52 +0200},
	biburl = {https://dblp.org/rec/conf/icde/XiaSH0XP23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Social recommender systems have drawn a lot of attention in many online web services, because of the incorporation of social information between users in improving recommendation results. Despite the significant progress made by existing solutions, we argue that current methods fall short in two limitations: (1) Existing social-aware recommendation models only consider collaborative similarity between items, how to incorporate item-wise semantic relatedness is less explored in current recommendation paradigms. (2) Current social recommender systems neglect the entanglement of the latent factors over heterogeneous relations (e.g., social connections, user-item interactions). Learning the disentangled representations with relation heterogeneity poses great challenge for social recommendation. In this work, we design a Disentangled Graph Neural Network (DGNN) with the integration of latent memory units, which empowers DGNN to maintain factorized representations for heterogeneous types of user and item connections. Additionally, we devise new memory-augmented message propagation and aggregation schemes under the graph neural architecture, allowing us to recursively distill semantic relatedness into the representations of users and items in a fully automatic manner. Extensive experiments on three benchmark datasets verify the effectiveness of our model by achieving great improvement over state-of-the-art recommendation techniques. The source code is publicly available at: https://github.com/HKUDS/DGNN.}
}


@inproceedings{DBLP:conf/icde/Wu00Z23,
	author = {Yuhan Wu and
                  Yuanyuan Xu and
                  Xuemin Lin and
                  Wenjie Zhang},
	title = {A Holistic Approach for Answering Logical Queries on Knowledge Graphs},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {2345--2357},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00181},
	doi = {10.1109/ICDE55515.2023.00181},
	timestamp = {Sat, 30 Sep 2023 09:44:52 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Wu00Z23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Logical queries on Knowledge Graphs (KGs) is a fundamental sub-task of knowledge graph reasoning. A promising paradigm for answering logical queries, recently, has been proposed based on versatile deep learning techniques. In this line, the query is first broken down into a series of first-order logical predicates, and then both the query and knowledge graph entities are jointly encoded in the same embedding space. Some approaches are able to support the full range of traditional First-Order Logic (FOL) operations for complex queries in real-world scenarios, while others have attempted to create a new combination of FOL operations by replacing the negation operation with the difference operation due to the poor performance of the negation operation. Our empirical observations show that the difference operator is more effective for multi-hop reasoning, while the negation operator is better suited for use as the final operation in the query, particularly in single-hop settings. In addition, other fundamental limitations such as linear transformation assumption for negation operator and the fixed-lossy problem for difference operator further degrade the performance of these methods. In light of these, we propose the HaLk, a holistic approach for answering logical queries that, to our knowledge, is the first to support a full set of logical operators in a unified end-to-end framework. In this approach, we propose specific neural models for each operator by considering their own intrinsic properties, based on which HaLk effectively mitigates the cascading error of projection and negation operators as well as delicately provides closed-formed solutions for difference operator. Extensive experimental results on three datasets demonstrate that HaLk outperforms all competitors and achieves up to 32% improvement in accuracy.}
}


@inproceedings{DBLP:conf/icde/FangZLY23,
	author = {Shuheng Fang and
                  Kangfei Zhao and
                  Guanghua Li and
                  Jeffrey Xu Yu},
	title = {Community Search: {A} Meta-Learning Approach},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {2358--2371},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00182},
	doi = {10.1109/ICDE55515.2023.00182},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/FangZLY23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Community Search (CS) is one of the fundamental graph analysis tasks, which is a building block of various real applications. Given any query nodes, CS aims to find cohesive subgraphs that query nodes belong to. Recently, a large number of CS algorithms are designed. These algorithms adopt predefined subgraph patterns to model the communities, which cannot find ground-truth communities that do not have such pre-defined patterns in real-world graphs. Thereby, machine learning (ML) and deep learning (DL) based approaches are proposed to capture flexible community structures by learning from ground-truth communities in a data-driven fashion. These approaches rely on sufficient training data to provide enough generalization for ML models, however, the ground-truth cannot be comprehensively collected beforehand.In this paper, we study ML/DL-based approaches for CS, under the circumstance of small training data. Instead of directly fitting the small data, we extract prior knowledge which is shared across multiple CS tasks via learning a meta model. Each CS task is a graph with several queries that possess corresponding partial ground-truth. The meta model can be swiftly adapted to a task to be predicted by feeding a few task-specific training data. We find that trivially applying multiple classical meta-learning algorithms to CS suffers from problems regarding prediction effectiveness, generalization capability and efficiency. To address such problems, we propose a novel meta-learning based framework, Conditional Graph Neural Process (CGNP), to fulfill the prior extraction and adaptation procedure. A meta CGNP model is a task-common node embedding function for clustering, learned by metric-based graph learning, which fully exploits the characteristics of CS. We compare CGNP with CS algorithms and ML baselines on real graphs with ground-truth communities. Our experiments verify that CGNP outperforms the other native graph algorithms and ML/DL baselines 0.33 and 0.26 on F1 score by average.}
}


@inproceedings{DBLP:conf/icde/GuiSWHH23,
	author = {Jie Gui and
                  Yuchen Song and
                  Zezhou Wang and
                  Chenhong He and
                  Qun Huang},
	title = {SK-Gradient: Efficient Communication for Distributed Machine Learning
                  with Data Sketch},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {2372--2385},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00183},
	doi = {10.1109/ICDE55515.2023.00183},
	timestamp = {Mon, 31 Jul 2023 08:35:14 +0200},
	biburl = {https://dblp.org/rec/conf/icde/GuiSWHH23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the explosive growth of data volume, distributed machine learning has become the mainstream approach for training deep neural networks. However, distributed machine learning incurs non-trivial communication overhead. To this end, various compression schemes are proposed to alleviate the communication volume among nodes. Nevertheless, existing compression schemes, such as gradient quantization or gradient sparsification, suffer from low compression ratios and/or high computational overheads. Recent studies advocate leveraging sketch techniques to assist these schemes. However, the limitations of gradient quantization and gradient sparsification remain. In this paper, we propose SK-Gradient, a novel gradient compression scheme that solely builds on sketch. The core component of SK-Gradient is a novel sketch namely FGC Sketch that is tailored for gradient compression. FGC Sketch precomputes the costly hash functions to alleviate computational overheads. Its simplified design makes it convenient for GPU acceleration. In addition, SK-Gradient leverages various techniques including selective gradient compression and periodic synchronization strategy to improve computational efficiency and compression accuracy. Compared with the state-of-the-art schemes, SK-Gradient achieves up to 92.9% reduction in computational overhead and up to 95.2% improvement in training speedups at the same compression ratio.}
}


@inproceedings{DBLP:conf/icde/FangHCHSLG23,
	author = {Ziquan Fang and
                  Changhao He and
                  Lu Chen and
                  Danlei Hu and
                  Qichen Sun and
                  Linsen Li and
                  Yunjun Gao},
	title = {A Lightweight Framework for Fast Trajectory Simplification},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {2386--2399},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00184},
	doi = {10.1109/ICDE55515.2023.00184},
	timestamp = {Mon, 21 Aug 2023 14:38:41 +0200},
	biburl = {https://dblp.org/rec/conf/icde/FangHCHSLG23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The ubiquitous GPS sensors collect massive trajectory data from moving objects, which is useful in data mining applications. However, trajectory data is enormous in volume, and thus, directly storing and processing the raw data is expensive. Using trajectory simplification, a trajectory can be reduced to a set of continuous line segments with acceptable data loss, which is an efficient method. Although many algorithms are proposed, they still suffer from the following issues including (i) non-data driven capability as most studies rely on human-crafted rules or pre-defined parameters, (ii) bound with error measures that yield high computational cost, and (iii) focusing only on the local information preservation in trajectories, but failing in capturing the global mobility patterns for trajectory compression.To address the above issues, we propose a Seq2Seq2Seq framework, abbreviated S3, which consists of two chained Seq2Seq. With differentiable reconstruction learning, S3 enables self-supervised trajectory simplification in a lightweight manner. Besides, we deploy S3 over the graph neural architecture to capture the context-aware mobility patterns and enhance the representation paradigm of trajectories with geographical semantics, where a context-aware distance measure is designed for quality evaluation. An online extension of S3 is also developed to enable streaming trajectory simplifications. Finally, extensive experiments using two real-world datasets in both offline and online scenarios show that S3 achieves much higher efficiency (e.g., it achieves up to one order of magnitude speed-up gains) and comparable compression quality, compared with both non-learning and state-of-the-art learning-based methods.}
}


@inproceedings{DBLP:conf/icde/MerkelMFJ23,
	author = {Nikolai Merkel and
                  Ruben Mayer and
                  Tawkir Ahmed Fakir and
                  Hans{-}Arno Jacobsen},
	title = {Partitioner Selection with {EASE} to Optimize Distributed Graph Processing},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {2400--2414},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00185},
	doi = {10.1109/ICDE55515.2023.00185},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/MerkelMFJ23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {For distributed graph processing on massive graphs, a graph is partitioned into multiple equally-sized parts which are distributed among machines in a compute cluster. In the last decade, many partitioning algorithms have been developed which differ from each other with respect to the partitioning quality, the run-time of the partitioning and the type of graph for which they work best. The plethora of graph partitioning algorithms makes it a challenging task to select a partitioner for a given scenario. Different studies exist that provide qualitative insights into the characteristics of graph partitioning algorithms that support a selection. However, in order to enable automatic selection, a quantitative prediction of the partitioning quality, the partitioning run-time and the run-time of subsequent graph processing jobs is needed. In this paper, we propose a machine learning-based approach to provide such a quantitative prediction for different types of edge partitioning algorithms and graph processing workloads. We show that training based on generated graphs achieves high accuracy, which can be further improved when using real-world data. Based on the predictions, the automatic selection reduces the end-to-end run-time on average by 11.1% compared to a random selection, by 17.4% compared to selecting the partitioner that yields the lowest cut size, and by 29.1% compared to the worst strategy, respectively. Furthermore, in 35.7% of the cases, the best strategy was selected.}
}


@inproceedings{DBLP:conf/icde/WengZFT023,
	author = {Tongfeng Weng and
                  Xu Zhou and
                  Yixiang Fang and
                  Kian{-}Lee Tan and
                  Kenli Li},
	title = {Finding Top-k Important Edges on Bipartite Graphs: Ego-betweenness
                  Centrality-based Approaches},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {2415--2428},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00186},
	doi = {10.1109/ICDE55515.2023.00186},
	timestamp = {Sun, 12 Nov 2023 02:08:10 +0100},
	biburl = {https://dblp.org/rec/conf/icde/WengZFT023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Bipartite graph is an important data structure that widely exists in disease prevention and control, community detection, and other real-life applications. In a bipartite graph, edges not only connect entries of different types but also are bridges of different communities in the above applications. However, research to date has not yet focused on edge importance in bipartite graphs. Inspired by this, we study a new problem of top-k edge search in bipartite graphs with the goal of finding k most important edges for a given bipartite graph; these edges are crucial bridges among communities. In particular, we introduce the measure of ego-betweenness for evaluating the importance of edges. To handle this problem effectively, a lazy bound-based algorithm is first proposed by integrating an upper bound pruning strategy. After that, to further get better efficiency, a greedy bound-based heuristic algorithm is explored on the basis of a tighter upper bound which contributes to reducing redundant computation for calculating ego-betweenness. Last but not least, two parallel techniques with different levels of granularity, called P -src and P -task, are respectively introduced to further improve the search efficiency. The experimental results on both real-world and synthetic graphs demonstrate the efficiency and scalability of the proposed algorithms.}
}


@inproceedings{DBLP:conf/icde/Shi0FC0023,
	author = {Weijie Shi and
                  Jiajie Xu and
                  Junhua Fang and
                  Pingfu Chao and
                  An Liu and
                  Xiaofang Zhou},
	title = {{LHMM:} {A} Learning Enhanced {HMM} Model for Cellular Trajectory
                  Map Matching},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {2429--2442},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00187},
	doi = {10.1109/ICDE55515.2023.00187},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Shi0FC0023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Map matching is a problem to align recorded location data to a digital map. It has been well studied to map GPS data collected from vehicles to paths in a road network. The problem of Cellular Trajectory Map-Matching (CTMM) is a new problem that deals with trajectories of cellular-based positioning data. It has a wide range of applications, for example, for telecommunication companies to understand and predict traffic information based on telecom tokens obtained from vehicles. CTMM is a significantly more challenging task that faces much lower data precision and higher positioning errors. While Hidden Markov Model (HMM) based methods can achieve satisfactory results for GPS-based map matching, we show that they cannot be directly applied to the CTMM problem. In this paper, we aim at reducing the impact of positioning errors by incorporating knowledge obtained by neural networks into learned probabilities. A multi-relational graph learning method is developed to generate meaningful embedding, with multi-relational useful information fully preserved in a shared space. An attentive neural network is then designed as the learner for observation probability, incorporating the knowledge of the dynamic correlation between roads and cell towers under varying trajectory contexts. A transition probability learner is used to capture implicit deep features for enhanced transition probability modeling. Finally, the learned observation and transition probabilities are seamlessly integrated into HMM to guide more accurate path-finding. Extensive experiments on two large-scale cellular datasets reveal that our approach achieves high accuracy and robustness on CTMM.}
}


@inproceedings{DBLP:conf/icde/WangW23,
	author = {Libin Wang and
                  Raymond Chi{-}Wing Wong},
	title = {Efficient Public Transport Planning on Roads},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {2443--2455},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00188},
	doi = {10.1109/ICDE55515.2023.00188},
	timestamp = {Sun, 12 Nov 2023 02:08:10 +0100},
	biburl = {https://dblp.org/rec/conf/icde/WangW23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Public transport contributes significantly to addressing some city issues such as air pollution and traffic congestion. As the public transport demand changes in urban development, we need to plan new routes to match the demand. Existing methods of planning new bus routes either are inefficient in using the path’s cost or use other inaccurate cost measurements. This paper focuses on finding a new bus route efficiently on road networks. Specifically, we first propose the Bus Routing on Roads (BRR) problem which combines two common goals of minimizing the walking costs of passengers and maximizing the connectivity of the new route to the existing transit network. They are consistent with matching the demand and facilitating the transfer. We first show the NP-hardness of the BRR and design an approximation algorithm called Efficient Bus Routing on Roads (EBRR). We theoretically analyzed its approximation ratio and time complexity. Extensive evaluations with state-of-the-art solutions on three real-world datasets validate the effectiveness and efficiency of EBRR. It could recommend a new bus route with high quality in around 10 seconds, 60x faster than the baselines.}
}


@inproceedings{DBLP:conf/icde/ParkKJK023,
	author = {Taehyeong Park and
                  Seokwon Kang and
                  Myung{-}Hwan Jang and
                  Sang{-}Wook Kim and
                  Yongjun Park},
	title = {Orchestrating Large-Scale SpGEMMs using Dynamic Block Distribution
                  and Data Transfer Minimization on Heterogeneous Systems},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {2456--2459},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00189},
	doi = {10.1109/ICDE55515.2023.00189},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ParkKJK023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Sparse general matrix-matrix multiplication (SpGEMM) is a major kernel in various emerging applications, such as database management systems, deep learning, graph analysis, and recommendation systems. Since SpGEMM requires extensive computation, many SpGEMM techniques have been implemented based on graphics processing units (GPUs) to exploit massive data parallelism completely. However, traditional SpGEMM techniques usually do not fully utilize the GPU because most non-zero elements of the target sparse matrices exist in a few hub nodes, and non-hub nodes barely have non-zero elements. The data-related characteristics (power law) result in a significant degradation in performance because of the load imbalance between the GPU cores and the low utilization of each core. Many attempts have been made through recent implementations to solve this problem using smart pre-/post-processing. However, the net performance hardly improves and sometimes even deteriorates owing to the large overheads. Additionally, non-hub nodes are inherently not suitable for GPU computing, even after optimization. Furthermore, the performance is no longer dominated by kernel execution, but by data transfers such as device-to-host (D2H) data transfers and file I/Os, owing to the rapid growth in the computing power of GPUs and input data size.Therefore, this work proposes a Dynamic Block Distributor (DBD), a novel full-system-level SpGEMM orchestration framework for heterogeneous systems, improving the overall performance by enabling an efficient CPU-GPU collaboration and further minimizing the overhead in data transfer between all the system elements. This framework first divides the target matrix into smaller blocks and then offloads the computation of each block to an appropriate computing unit between a GPU and CPU based on its workload type and the status of resource utilization at runtime. It also minimizes the overhead in data transfer with simple but suitable techniques, such as Row Collecting, I/O Overlapping, and I/O Binding. Our experiments showed that this framework increased the execution latency of SpGEMM, which included both the kernel execution and D2H transfers, by 3.24x on average, and the overall execution time by 2.07x on average, compared to that of the baseline cuSPARSE library.}
}


@inproceedings{DBLP:conf/icde/PellizzoniV23,
	author = {Paolo Pellizzoni and
                  Fabio Vandin},
	title = {VC-dimension and Rademacher Averages of Subgraphs, with Applications
                  to Graph Mining},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {2470--2482},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00190},
	doi = {10.1109/ICDE55515.2023.00190},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/PellizzoniV23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Frequent subgraph mining is a fundamental task in the analysis of collections of graphs. While several exact approaches have been proposed, it remains computationally challenging on large graph datasets due to its inherent link to the subgraph isomorphism problem and the huge number of candidate patterns even for fairly small subgraphs.In this work, we study two statistical learning measures of complexity, VC-dimension and Rademacher averages, for subgraphs, and derive efficiently computable bounds for both. We show how such bounds can be applied to devise efficient sampling-based approaches for rigorously approximating the solution of the frequent subgraph mining problem. We also show that our bounds can be used for true frequent subgraph mining, which requires to identify subgraphs generated with probability above a given threshold from an unknown generative process using samples from such process. Our extensive experimental evaluation on real datasets shows that our bounds lead to efficiently computable, high-quality approximations for both applications.}
}


@inproceedings{DBLP:conf/icde/LiLZSWQ23,
	author = {Ling Li and
                  Siqiang Luo and
                  Yuhai Zhao and
                  Caihua Shan and
                  Zhengkui Wang and
                  Lu Qin},
	title = {{COCLEP:} Contrastive Learning-based Semi-Supervised Community Search},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {2483--2495},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00191},
	doi = {10.1109/ICDE55515.2023.00191},
	timestamp = {Sun, 04 Aug 2024 19:37:46 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LiLZSWQ23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Community search is a fundamental graph processing task that aims to find a community containing the given query node. Recent studies show that machine learning (ML)-based community search can return higher-quality communities than the classic methods such as k-core and k-truss. However, the state-of-the-art ML-based models require a large number of labeled data (i.e., nodes in ground-truth communities) for training that are difficult to obtain in real applications, and incur unaffordable memory costs or query time for large datasets. To address these issues, in this paper, we present the community search based on contrastive learning with partition, namely COCLEP, which only requires a few labels and is both memory and query efficient. In particular, given a small collection of query nodes and a few (e.g., three) corresponding ground-truth community nodes for each query, COCLEP learns a query-dependent model through the proposed graph neural network and the designed label-aware contrastive learner. The former perceives query node information, low-order neighborhood information, and high-order hypergraph structure information, the latter contrasts low-order intra-view, high-order intra-view, and low-high-order inter-view representations of the nodes. Further, we theoretically prove that COCLEP can be scalable to large datasets with the min-cut over the graph. To the best of our knowledge, this is the first attempt to adopt contrastive learning for community search task that is nontrivial. Extensive experiments on real-world datasets show that COCLEP simultaneously achieves better community effectiveness and comparably high query efficiency while using fewer labels compared with the-state-of-the-art approaches and is scalable for large datasets.}
}


@inproceedings{DBLP:conf/icde/AmsterdamerDMRS23,
	author = {Yael Amsterdamer and
                  Susan B. Davidson and
                  Tova Milo and
                  Kathy Razmadze and
                  Amit Somech},
	title = {Selecting Sub-tables for Data Exploration},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {2496--2509},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00192},
	doi = {10.1109/ICDE55515.2023.00192},
	timestamp = {Sun, 06 Oct 2024 21:04:56 +0200},
	biburl = {https://dblp.org/rec/conf/icde/AmsterdamerDMRS23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Data scientists frequently examine the raw content of large tables when exploring an unknown dataset. In such cases, small subsets of the full tables (sub-tables) that accurately capture table contents are useful. We present a framework which, given a large data table T, creates a sub-table of small, fixed dimensions by selecting a subset of T’s rows and projecting them over a subset of T’s columns. The question is: Which rows and columns should be selected to yield an informative sub-table?Our first contribution is an informativeness metric for sub-tables with two complementary dimensions: cell coverage, which measures how well the sub-table captures prominent data patterns in T, and diversity. We use association rules as the patterns captured by sub-tables, and show that computing optimal sub-tables directly using this metric is infeasible. We then develop an efficient algorithm that indirectly accounts for association rules using table embedding. The resulting framework produces sub-tables for the full table as well as for the results of queries over the table, enabling the user to quickly understand results and determine subsequent queries. Experimental results show that high-quality sub-tables can be efficiently computed, and verify the soundness of our metrics as well as the usefulness of selected sub-tables through user studies.}
}


@inproceedings{DBLP:conf/icde/YehCYLYC23,
	author = {Chin{-}Yuan Yeh and
                  Hsi{-}Wen Chen and
                  De{-}Nian Yang and
                  Wang{-}Chien Lee and
                  Philip S. Yu and
                  Ming{-}Syan Chen},
	title = {Planning Data Poisoning Attacks on Heterogeneous Recommender Systems
                  in a Multiplayer Setting},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {2510--2523},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00193},
	doi = {10.1109/ICDE55515.2023.00193},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/YehCYLYC23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Data poisoning attacks against recommender systems (RecSys) often assume a single seller as the adversary. However, in reality, there are usually multiple sellers attempting to promote their items through RecSys manipulation. To obtain the best data poisoning plan, it is important for an attacker to anticipate and withstand the actions of his opponents. This work studies the problem of Multiplayer Comprehensive Attack (MCA) from the perspective of the attacker, considering the subsequent attacks by his opponents. In MCA, we target the Heterogeneous RecSys, where user-item interaction records, user social network, and item correlation graph are used for recommendations. To tackle MCA, we present the Multilevel Stackelberg Optimization over Progressive Differentiable Surrogate (MSOPDS). The Multilevel Stackelberg Optimization (MSO) method is used to form the optimum strategies by solving the Stackelberg game equilibrium between the attacker and his opponents, while the Progressive Differentiable Surrogate (PDS) addresses technical challenges in deriving gradients for candidate poisoning actions. Experiments on Heterogeneous RecSys trained with public datasets show that MSOPDS outperforms all examined prior works by up to 10.6% in average predicted ratings and up to 11.4% in HitRate@3 for an item targeted by an attacker facing one opponent. Source code provided in https://github.com/jimmy-academia/MSOPDS.}
}


@inproceedings{DBLP:conf/icde/XuL0X023,
	author = {Yehong Xu and
                  Lei Li and
                  Mengxuan Zhang and
                  Zizhuo Xu and
                  Xiaofang Zhou},
	title = {Global Routing Optimization In Road Networks},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {2524--2537},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00194},
	doi = {10.1109/ICDE55515.2023.00194},
	timestamp = {Sat, 30 Sep 2023 09:44:52 +0200},
	biburl = {https://dblp.org/rec/conf/icde/XuL0X023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Route planning plays an increasingly important role in our society, and the routing results, which are the paths that vehicles actually travel in a road network, which influence the traffic condition naturally. However, the existing routing algorithms cannot consider the routing results and their influence simultaneously, so traffic congestion could be created when many vehicles are directed to follow similar routes. In this paper, we propose the Global Routing Optimization problem that aims to minimize traffic congestion by continuously evaluating traffic conditions for a set of routing tasks. It is non-trivial to achieve this global optimization goal, as routing and traffic condition evaluation is both time-consuming and interdependent. To break this dependency, we propose a global routing optimization paradigm that can evaluate the routing results’ influence on the traffic condition, and then plan the routes accordingly. To implement it, we first propose a serial model to optimize the next route, followed by a batch model to improve processing efficiency. After that, an iterative model is proposed to further optimize route qualities. Extensive experiments on large real-world networks with synthetic and real workloads validate the effectiveness and efficiency of our methods.}
}


@inproceedings{DBLP:conf/icde/WangWZZ023,
	author = {Xubo Wang and
                  Dong Wen and
                  Wenjie Zhang and
                  Ying Zhang and
                  Lu Qin},
	title = {Distributed Near-Maximum Independent Set Maintenance over Large-scale
                  Dynamic Graphs},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {2538--2550},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00195},
	doi = {10.1109/ICDE55515.2023.00195},
	timestamp = {Sun, 04 Aug 2024 19:37:45 +0200},
	biburl = {https://dblp.org/rec/conf/icde/WangWZZ023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Computing the maximum independent set (MIS) in a graph is a fundamental NP-hard problem, which is widely adopted in many real-world applications. Extensive works have been done on computing an approximate MIS. While the highly dynamic property of real-world graphs calls for efficient MIS maintenance solutions, existing works for dynamic MIS computation in the literature mainly focus on the single-machine scenario. The assumption that a single machine can access the whole graph makes them difficult to be straightforwardly applied for large-scale graphs in distributed environment. Motivated by this, in this paper, we study the problem of maintaining approximate MIS over large-scale dynamic graphs in distributed environments. We propose a new vertex centric algorithm OIMIS. Compared with existing solutions, OIMIS avoids the strong order dependency in distributed computation, which makes it easy to handle dynamic graph updates. OIMIS computes and maintains MIS with high effectiveness and efficiency. In terms of high effectiveness, OIMIS maintains consistent MIS results with the state-of-the-art distributed algorithm to compute MIS in static graphs. In terms of high efficiency, each vertex in OIMIS only updates MIS status according to its neighbor attributes. Novel optimization techniques are also designed to reduce communication and computation cost. We conduct extensive experiments to prove the effectiveness and efficiency of our distributed algorithms.}
}


@inproceedings{DBLP:conf/icde/LiuWLF23,
	author = {Ziyang Liu and
                  Chaokun Wang and
                  Yunkai Lou and
                  Hao Feng},
	title = {Fast Unsupervised Graph Embedding via Graph Zoom Learning},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {2551--2564},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00196},
	doi = {10.1109/ICDE55515.2023.00196},
	timestamp = {Mon, 05 Feb 2024 20:31:12 +0100},
	biburl = {https://dblp.org/rec/conf/icde/LiuWLF23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Unsupervised graph representation learning, i.e., learning node or graph embeddings from graph data in an unsupervised manner, has become an important problem when we study graph data. With the development of self-supervised learning, researchers have designed graph-level self-supervised learning paradigms and learn embeddings under these paradigms. The learned embeddings can serve as a fine initial solution to downstream tasks such as node classification or graph classification. In this paper, we propose a fast unsupervised graph embedding method, which follows the way of self-supervised learning. This method performs representation learning on the graph under a novel concept called Graph Zoom Learning (abbr. GZL), which is orthogonal to the existing concepts of unsupervised graph embedding, such as random walk and contrastive learning. Two crucial components, graph zoom-out and point-to-point contrast, help GZL reduce the overall training time cost. Specifically, on the one hand, a lightweight miniature graph is generated from the raw graph by graph zoom-out and the learning on the miniature graph is more efficient than the learning on the raw graph; on the other hand, we design the miniature-scale learning on the miniature graph and introduce community structure into this learning pattern, which contributes to the final point-to-point contrast. Since point-to-point contrast is independent of negatives, it makes the whole training more efficient. We conduct extensive experiments to verify the advantage of GZL on representation learning. On two downstream tasks of node classification and graph classification, GZL outperforms the state-of-the-art unsupervised graph embedding methods. Particularly, on the largest experimental graph dataset (ogbn-arxiv) with 169k nodes and 1.1m edges, GZL outperforms the runner-up by 3.3% relative accuracy and achieves up to 22.6x speedup over it.}
}


@inproceedings{DBLP:conf/icde/Huang0Z023,
	author = {Yihong Huang and
                  Liping Wang and
                  Fan Zhang and
                  Xuemin Lin},
	title = {Unsupervised Graph Outlier Detection: Problem Revisit, New Insight,
                  and Superior Method},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {2565--2578},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00197},
	doi = {10.1109/ICDE55515.2023.00197},
	timestamp = {Tue, 09 Jul 2024 09:08:29 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Huang0Z023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A large number of studies on Graph Outlier Detection (GOD) have emerged in recent years due to its wide applications, in which Unsupervised Node Outlier Detection (UNOD) on attributed networks is an important area. UNOD focuses on detecting two kinds of typical outliers in graphs: the structural outlier and the contextual outlier. Most existing works conduct experiments based on datasets with injected outliers. However, we find that the most widely-used outlier injection approach has a serious data leakage issue. By only utilizing such data leakage, a simple approach can achieve state-of-the-art performance in detecting outliers. In addition, we observe that existing algorithms have a performance drop with the mitigated data leakage issue. The other major issue is on balanced detection performance between the two types of outliers, which has not been considered by existing studies.In this paper, we analyze the cause of the data leakage issue in depth since the injection approach is a building block to advance UNOD. Moreover, we devise a novel variance-based model to detect structural outliers, which outperforms existing algorithms significantly and is more robust at kinds of injection settings. On top of this, we propose a new framework, Variance-based Graph Outlier Detection (VGOD), which combines our variance-based model and attribute reconstruction model to detect outliers in a balanced way. Finally, we conduct extensive experiments to demonstrate the effectiveness and efficiency of VGOD. The results on 5 real-world datasets validate that VGOD achieves not only the best performance in detecting outliers but also a balanced detection performance between structural and contextual outliers.}
}


@inproceedings{DBLP:conf/icde/WangYC00L23,
	author = {Yiqi Wang and
                  Long Yuan and
                  Zi Chen and
                  Wenjie Zhang and
                  Xuemin Lin and
                  Qing Liu},
	title = {Towards Efficient Shortest Path Counting on Billion-Scale Graphs},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {2579--2592},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00198},
	doi = {10.1109/ICDE55515.2023.00198},
	timestamp = {Sun, 04 Aug 2024 19:37:46 +0200},
	biburl = {https://dblp.org/rec/conf/icde/WangYC00L23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Shortest path counting computes the number of shortest paths between two vertices on a graph, which can be used in the applications such as social network search and POI (Point of Interest) recommendation. The state-of-the-art approach leverages index to speed up the query processing. However, this approach incurs not only significant space overheads but also prohibitive indexing time, which makes it inapplicable to handle such queries on large graphs. Motivated by this, in this paper, we aim to propose a new solution to scale up the shortest path counting. To achieve this goal, we first propose a novel size-tunable indexing framework, which allows users to tune the index space consumption based on their requirements for query processing efficiency and available memory. Based on the size-tunable indexing framework, we devise a new parallel paradigm to accelerate index construction. We conduct experiments on 15 real graphs and the experimental results demonstrate that our new approach significantly outperforms the state-of-the-art approach regarding the index space cost and index construction cost, and is able to handle billion-scale graphs that the state-of-the-art approach cannot process with less than 5 milliseconds query processing time on all test cases.}
}


@inproceedings{DBLP:conf/icde/Ye0SCZGZC023,
	author = {Hangting Ye and
                  Zhining Liu and
                  Xinyi Shen and
                  Wei Cao and
                  Shun Zheng and
                  Xiaofan Gui and
                  Huishuai Zhang and
                  Yi Chang and
                  Jiang Bian},
	title = {{UADB:} Unsupervised Anomaly Detection Booster},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {2593--2606},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00199},
	doi = {10.1109/ICDE55515.2023.00199},
	timestamp = {Sat, 05 Aug 2023 17:58:52 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Ye0SCZGZC023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Unsupervised Anomaly Detection (UAD) is a key data mining problem owing to its wide real-world applications. Due to the complete absence of supervision signals, UAD methods rely on implicit assumptions about anomalous patterns (e.g., scattered/sparsely/densely clustered) to detect anomalies. However, real-world data are complex and vary significantly across different domains. No single assumption can describe such complexity and be valid in all scenarios. This is also confirmed by recent research that shows no UAD method is omnipotent [1]. Based on above observations, instead of searching for a magic universal winner assumption, we seek to design a general UAD Booster (UADB) that empowers any UAD models with adaptability to different data. This is a challenging task given the heterogeneous model structures and assumptions adopted by existing UAD methods. To achieve this, we dive deep into the UAD problem and find that compared to normal data, anomalies (i) lack clear structure/pattern in feature space, thus (ii) harder to learn by model without a suitable assumption, and finally, leads to (iii) high variance between different learners. In light of these findings, we propose to (i) distill the knowledge of the source UAD model to an imitation learner (booster) that holds no data assumption, then (ii) exploit the variance between them to perform automatic correction, and thus (iii) improve the booster over the original UAD model. We use a neural network as the booster for its strong expressive power as a universal approximator and ability to perform flexible posthoc tuning. Note that UADB is a model-agnostic framework that can enhance heterogeneous UAD models in a unified way. Extensive experiments on over 80 tabular datasets demonstrate the effectiveness of UADB. To facilitate further research, code, figures, and datasets are available at UADB’s Github repository 1 .}
}


@inproceedings{DBLP:conf/icde/AnadiotisMM23,
	author = {Angelos{-}Christos G. Anadiotis and
                  Ioana Manolescu and
                  Madhulika Mohanty},
	title = {Integrating Connection Search in Graph Queries},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {2607--2620},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00200},
	doi = {10.1109/ICDE55515.2023.00200},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/AnadiotisMM23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {When graph database users explore unfamiliar graphs, potentially with heterogeneous structure, users may need to find how two or more groups of nodes are connected in a graph, even when users are not able to describe the connections. This is only partially supported by existing query languages, which allow searching for paths, but not for trees connecting three or more node groups.In this work, we formally show how to integrate connecting tree patterns (CTPs, in short) with a graph query language such as GPML [1], SPARQL or Cypher, leading to Extended Queries (or EQs, in short). We then study a set of algorithms for evaluating CTPs; we generalize prior keyword search work to be complete, most importantly by (i) considering bidirectional edge traversal, (ii) allowing users to select any score function for ranking CTP results and (iii) returning all results. To cope with very large search spaces, we propose efficient pruning techniques and formally establish a large set of cases where our best algorithm, MOLESP, is complete even with pruning. Our experiments validate the performance of our algorithms on many synthetic and real-world workloads.}
}


@inproceedings{DBLP:conf/icde/ZhangZ0C23,
	author = {Jintao Zhang and
                  Chao Zhang and
                  Guoliang Li and
                  Chengliang Chai},
	title = {AutoCE: An Accurate and Efficient Model Advisor for Learned Cardinality
                  Estimation},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {2621--2633},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00201},
	doi = {10.1109/ICDE55515.2023.00201},
	timestamp = {Fri, 29 Mar 2024 13:04:57 +0100},
	biburl = {https://dblp.org/rec/conf/icde/ZhangZ0C23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cardinality estimation (CE) plays a crucial role in many database-related tasks such as query generation, cost estimation, and join ordering. Lately, we have witnessed the emergence of numerous learned CE models. However, no single CE model is invincible when it comes to the datasets with various data distributions. To facilitate data-intensive applications with accurate and efficient cardinality estimation, it is important to have an approach that can judiciously and efficiently select the most suitable CE model for an arbitrary dataset.In this paper, we study a new problem of selecting the best CE models for a variety of datasets. This problem is rather challenging as it is hard to capture the relationship from various datasets to the performance of disparate models. To address this problem, we propose a model advisor, named AutoCE, which can adaptively select the best model for a dataset. The main contribution of AutoCE is the learning-based model selection, where deep metric learning is used to learn a recommendation model and incremental learning is proposed to reduce the labeling overhead and improve the model robustness. We have integrated AutoCE into PostgreSQL and evaluated its impact on query optimization. The results showed that AutoCE achieved the best performance (27% better) and outperformed the baselines concerning accuracy (2.1x better) and efficacy (4.2x better).}
}


@inproceedings{DBLP:conf/icde/TangCLWYSP23,
	author = {Dixin Tang and
                  Fanchao Chen and
                  Christopher De Leon and
                  Tana Wattanawaroon and
                  Jeaseok Yun and
                  Srinivasan Seshadri and
                  Aditya G. Parameswaran},
	title = {Efficient and Compact Spreadsheet Formula Graphs},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {2634--2646},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00202},
	doi = {10.1109/ICDE55515.2023.00202},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/TangCLWYSP23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Spreadsheets are one of the most popular data analysis tools, wherein users can express computation as formulae alongside data. The ensuing dependencies are tracked as formula graphs. Efficiently querying and maintaining these formula graphs is critical for interactivity across multiple settings. Unfortunately, formula graphs are often large and complex such that querying and maintaining them is time-consuming, reducing interactivity. We propose TACO, a framework for efficiently compressing formula graphs, thereby reducing the time for querying and maintenance. The efficiency of TACO stems from a key spreadsheet property: tabular locality, which means that cells close to each other are likely to have similar formula structures. We leverage four such tabular locality-based patterns, and develop algorithms for compressing formula graphs using these patterns, directly querying the compressed graph without decompression, and incrementally maintaining the graph during updates. We integrate TACO into an open-source spreadsheet system and show that TACO can significantly reduce formula graph sizes. For querying formula graphs, the speedups of TACO over a baseline implemented in our framework and a commercial spreadsheet system are up to 34,972 × and 632 ×, respectively.}
}


@inproceedings{DBLP:conf/icde/PastorBA23,
	author = {Eliana Pastor and
                  Elena Baralis and
                  Luca de Alfaro},
	title = {A Hierarchical Approach to Anomalous Subgroup Discovery},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {2647--2659},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00203},
	doi = {10.1109/ICDE55515.2023.00203},
	timestamp = {Mon, 05 Feb 2024 20:31:12 +0100},
	biburl = {https://dblp.org/rec/conf/icde/PastorBA23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Understanding peculiar and anomalous behavior of machine learning models for specific data subgroups is a fundamental building block of model performance and fairness evaluation. The analysis of these data subgroups can provide useful insights into model inner working and highlight its potentially discriminatory behavior. Current approaches to subgroup exploration ignore the presence of hierarchies in the data, and can only be applied to discretized attributes. The discretization process required for continuous attributes may significantly affect the identification of relevant subgroups.We propose a hierarchical subgroup exploration technique to identify anomalous subgroup behavior at multiple granularity levels, along with a technique for the hierarchical discretization of data attributes. The hierarchical discretization produces, for each continuous attribute, a hierarchy of intervals. The subsequent hierarchical exploration can exploit data hierarchies, selecting for each attribute the optimal granularity to identify subgroups that are both anomalous, and with enough elements to be statistically and practically significant. Compared to non- hierarchical approaches, we show that our hierarchical approach is more powerful in identifying anomalous subgroups and more stable with respect to discretization and exploration parameters.}
}


@inproceedings{DBLP:conf/icde/WangW0N0TG023,
	author = {Ning Wang and
                  Yaohua Wang and
                  Zhigang Wang and
                  Jie Nie and
                  Zhiqiang Wei and
                  Peng Tang and
                  Yu Gu and
                  Ge Yu},
	title = {PrivNUD: Effective Range Query Processing under Local Differential
                  Privacy},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {2660--2672},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00204},
	doi = {10.1109/ICDE55515.2023.00204},
	timestamp = {Fri, 11 Aug 2023 09:05:29 +0200},
	biburl = {https://dblp.org/rec/conf/icde/WangW0N0TG023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Local differential privacy (LDP) has been established as a strong privacy standard for collecting sensitive information from users. Although it has attracted much research attention in recent years, the majority of existing works focus on applying LDP to frequency distribution estimation for each individual value in a discrete domain. This paper concerns the important range queries involving multiple discrete values. Till now, only a few works target this problem. They all rely on the B-ary tree to construct a uniform and hierarchical decomposition, so as to decrease the error when answering large range queries. However, the uniform splitting manner ignores the properties of decomposed sub-domains and processes them equally without preferences, which leads to significant performance penalty.In this paper, we tackle the problem head on: our proposal, privNUD, is a novel domain hierarchical decomposition mechanism. It dynamically decomposes each domain with a tailored granularity into some sub-domains, which sensitively considers the potential chances to answer one range query. The issue of granularity is carefully analyzed for better performance. It also can smartly prune the sub-domains with small frequencies. Besides, an adaptive user allocation technique is designed to dynamically decide the scale of users that are involved in each sub-domain’s frequency estimation. Extensive experiments using real and synthetic datasets demonstrate that privNUD achieves significantly higher result accuracy compared to the up-to-date solutions.}
}


@inproceedings{DBLP:conf/icde/DuYZF0LS023,
	author = {Xinyu Du and
                  Huanhuan Yuan and
                  Pengpeng Zhao and
                  Junhua Fang and
                  Guanfeng Liu and
                  Yanchi Liu and
                  Victor S. Sheng and
                  Xiaofang Zhou},
	title = {Contrastive Enhanced Slide Filter Mixer for Sequential Recommendation},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {2673--2685},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00205},
	doi = {10.1109/ICDE55515.2023.00205},
	timestamp = {Sun, 06 Oct 2024 21:04:57 +0200},
	biburl = {https://dblp.org/rec/conf/icde/DuYZF0LS023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Sequential recommendation (SR) aims to model user preferences by capturing behavior patterns from their item historical interaction data. Most existing methods model user preference in the time domain, omitting the fact that users’ behaviors are also influenced by various frequency patterns that are difficult to separate in the entangled chronological items. However, few attempts have been made to train SR in the frequency domain, and it is still unclear how to use the frequency components to learn an appropriate representation for the user. To solve this problem, we shift the viewpoint to the frequency domain and propose a novel Contrastive Enhanced SLIde Filter MixEr for Sequential Recommendation, named SLIME4Rec. Specifically, we design a frequency ramp structure to allow the learnable filter slide on the frequency spectrums across different layers to capture different frequency patterns. Moreover, a Dynamic Frequency Selection (DFS) and a Static Frequency Split (SFS) module are proposed to replace the self-attention module for effectively extracting frequency information in two ways. DFS is used to select helpful frequency components dynamically, and SFS is combined with the dynamic frequency selection module to provide a more fine-grained frequency division. Finally, contrastive learning is utilized to improve the quality of user embedding learned from the frequency domain. Extensive experiments conducted on five widely used benchmark datasets demonstrate our proposed model performs significantly better than the state-of-the-art approaches. Our code is available at https://github.com/sudaada/SLIME4Rec.}
}


@inproceedings{DBLP:conf/icde/LuZWW23,
	author = {Jing Lu and
                  Yuhai Zhao and
                  Zhengkui Wang and
                  Guoren Wang},
	title = {Skyline Micro-Cluster Query: {A} Novel and Practical Spatial Query},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {2686--2698},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00206},
	doi = {10.1109/ICDE55515.2023.00206},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LuZWW23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper presents a novel spatial query, skyline micro-cluster (SMC) query. Given a set of data points P, a query point q, a radius γ and a density parameter k, the SMC query returns the skyline micro-clusters (MCs), where MC is a set of points in P that can be covered by a circle with radius γ and the number of points in MC is at least k. In this paper, we formally define the SMC query. As the brute-force approach to solving the SMC query in massive datasets has high computation and memory costs, we propose a basic skyline micro-cluster query algorithm, BSMC, which can reduce the time complexity from O(2 N ) to O(N 3 ). Furthermore, on top of BSMC, we propose an efficient skyline micro-cluster query algorithm (ESMC). In ESMC, we use the z-value index and propose a filter to remove the invalid micro-clusters, which reduces significant computation overhead. To reduce the memory overhead, we propose an incremental skyline query method. A comprehensive performance study is conducted on real datasets and the experimental results show that our proposed method, ESMC, can significantly improve the SMC query performance.}
}


@inproceedings{DBLP:conf/icde/ChenZY0W23,
	author = {Zi Chen and
                  Yiwei Zhao and
                  Long Yuan and
                  Xuemin Lin and
                  Kai Wang},
	title = {Index-Based Biclique Percolation Communities Search on Bipartite Graphs},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {2699--2712},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00207},
	doi = {10.1109/ICDE55515.2023.00207},
	timestamp = {Sun, 04 Aug 2024 19:37:45 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ChenZY0W23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Biclique percolation community (BPC) search is a fundamental problem in bipartite graph analysis and have many applications. Existing online approach has to enumerate all the maximal bicliques and compute the results based on these bicliques. Considering the large number of maximal bicliques in real graphs and the high frequency of BPC search requests issued in real applications, existing approach is cost prohibitive to obtain the result. Motivated by this, we devise an index-based (BPC-Index) approach to address the problem. Based on the index, we can obtain the result in near-optimal time with well-bounded index space. We further devise an efficient index construction algorithm. Moreover, we also extend our indexing method to address the personalized BPC search problem, which is one of the most common variants of BPC search. We conduct extensive experiments on 10 real bipartite graphs, and the experimental results demonstrate the effectiveness of the BPC model, and the efficiency of our BPC search algorithms and index construction algorithms. Remarkably, our approach can achieve up to 8 orders of magnitude speedup compared to the existing online approach.}
}


@inproceedings{DBLP:conf/icde/ZhuoCCTSCHL23,
	author = {Weipeng Zhuo and
                  Ka Ho Chiu and
                  Jierun Chen and
                  Jiajie Tan and
                  Edmund Sumpena and
                  S.{-}H. Gary Chan and
                  Sangtae Ha and
                  Chul{-}Ho Lee},
	title = {Semi-supervised Learning with Network Embedding on Ambient {RF} Signals
                  for Geofencing Services},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {2713--2726},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00208},
	doi = {10.1109/ICDE55515.2023.00208},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhuoCCTSCHL23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In applications such as elderly care, dementia anti-wandering and pandemic control, it is important to ensure that people are within a predefined area for their safety and well-being. We propose GEM, a practical, semi-supervised Geofencing system with network EMbedding, which is based only on ambient radio frequency (RF) signals. GEM models measured RF signal records as a weighted bipartite graph. With access points on one side and signal records on the other, it is able to precisely capture the relationships between signal records. GEM then learns node embeddings from the graph via a novel bipartite network embedding algorithm called BiSAGE, based on a Bipartite graph neural network with a novel bi-level SAmple and aggreGatE mechanism and non-uniform neighborhood sampling. Using the learned embeddings, GEM finally builds a one-class classification model via an enhanced histogram-based algorithm for in-out detection, i.e., to detect whether the user is inside the area or not. This model also keeps on improving with newly collected signal records. We demonstrate through extensive experiments in diverse environments that GEM shows state-of-the-art performance with up to 34% improvement in F-score. BiSAGE in GEM leads to a 54% improvement in F-score, as compared to the one without BiSAGE.}
}


@inproceedings{DBLP:conf/icde/Wang0WCGHWKPL23,
	author = {Jinzhen Wang and
                  Xin Liang and
                  Ben Whitney and
                  Jieyang Chen and
                  Qian Gong and
                  Xubin He and
                  Lipeng Wan and
                  Scott Klasky and
                  Norbert Podhorszki and
                  Qing Liu},
	title = {Improving Progressive Retrieval for {HPC} Scientific Data using Deep
                  Neural Network},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {2727--2739},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00209},
	doi = {10.1109/ICDE55515.2023.00209},
	timestamp = {Tue, 28 May 2024 21:05:06 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Wang0WCGHWKPL23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As the disparity between compute and I/O on high-performance computing systems has continued to widen, it has become increasingly difficult to perform post-hoc data analytics on full-resolution scientific simulation data due to the high I/O cost. Error-bounded data decomposition and progressive data retrieval framework has recently been developed to address such a challenge by performing data decomposition before storage and reading only part of the decomposed data when necessary. However, the performance of the progressive retrieval framework has been suffering from the over-pessimistic error control theory, such that the achieved maximum error of recomposed data is significantly lower than the required error. Therefore, more data than required is fetched for recomposition, incurring additional I/O overhead. In order to tackle this issue, we propose a DNN-based progressive retrieval framework that can better identify the minimum amount of data to be retrieved. Our contributions are as follows: 1) We provide an in-depth investigation of the recently developed progressive retrieval framework; 2) We propose two designs of prediction models (named D-MGARD and E-MGARD) to estimate the amount of retrieved data size based on error bounds. 3) We evaluate our proposed solutions using scientific datasets generated by real-world simulations from two domains. Evaluation results demonstrate the effectiveness of our solution in accurately predicting the amount of retrieval data size, as well as the advantages of our solution over the traditional approach to reducing the I/O overhead. Based on our evaluation, our solution is shown to read significantly less data (5% - 40% with D-MGARD, 20% - 80% with E-MGARD).}
}


@inproceedings{DBLP:conf/icde/DuCZX00F23,
	author = {Leilei Du and
                  Peng Cheng and
                  Libin Zheng and
                  Wei Xi and
                  Xuemin Lin and
                  Wenjie Zhang and
                  Jing Fang},
	title = {Dynamic Private Task Assignment under Differential Privacy},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {2740--2752},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00210},
	doi = {10.1109/ICDE55515.2023.00210},
	timestamp = {Tue, 07 May 2024 20:05:36 +0200},
	biburl = {https://dblp.org/rec/conf/icde/DuCZX00F23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Data collection is indispensable for spatial crowd-sourcing services, such as resource allocation, policymaking, and scientific explorations. However, privacy issues make it challenging for users to share their information unless receiving sufficient compensation. Differential Privacy (DP) is a promising mechanism to release helpful information while protecting individuals’ privacy. However, most DP mechanisms only consider a fixed compensation for each user’s privacy loss. In this paper, we design a task assignment scheme that allows workers to dynamically improve their utility with dynamic distance privacy leakage. Specifically, we propose two solutions to improve the total utility of task assignment results, namely Private Utility Conflict-Elimination (PUCE) approach and Private Game Theory (PGT) approach, respectively. We prove that PUCE achieves higher utility than the state-of-the-art works. We demonstrate the efficiency and effectiveness of our PUCE and PGT approaches on both real and synthetic data sets compared with the recent distance-based approach, Private Distance Conflict-Elimination (PDCE). PUCE is always better than PDCE slightly. PGT is 50% to 63% faster than PDCE and can improve 16% utility on average when worker range is large enough.}
}


@inproceedings{DBLP:conf/icde/SongZQZZPC23,
	author = {Xun Song and
                  Jiaqi Zheng and
                  Hao Qian and
                  Shiju Zhao and
                  Hongxuan Zhang and
                  Xuntao Pan and
                  Guihai Chen},
	title = {Couper: Memory-Efficient Cardinality Estimation under Unbalanced Distribution},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {2753--2765},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00211},
	doi = {10.1109/ICDE55515.2023.00211},
	timestamp = {Wed, 22 Nov 2023 12:10:46 +0100},
	biburl = {https://dblp.org/rec/conf/icde/SongZQZZPC23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Estimating per-flow cardinality from high-speed data streams has many applications such as anomaly detection and resource allocation. Yet despite tracking single flow cardinality with approximation algorithms offered, there remain algorithmical challenges for monitoring multi-flows especially under unbalanced cardinality distribution: existing methods adopt a uniform sketch layout and incur a large memory footprint to achieve high accuracy. Furthermore, they are hard to implement in the compact hardware used for line-rate processing.In this paper, we propose Couper, a memory-efficient measurement framework that can estimate cardinality for multi-flows under unbalanced cardinality distribution. We propose a two-layer structure based on a classic coupon collector’s principle, where numerous mice flows are confined to the first layer and only the potential elephant flows are allowed to enter the second layer. Our two-layer structure can better fit the unbalanced cardinality distribution in practice and achieve much higher memory efficiency. We implement Couper in both software and hardware. Extensive evaluation under real-world and synthetic data traces show more than 20× improvements in terms of memory-efficiency compared to state-of-the-art.}
}


@inproceedings{DBLP:conf/icde/YuGZY00TY0Z23,
	author = {Song Yu and
                  Shufeng Gong and
                  Yanfeng Zhang and
                  Wenyuan Yu and
                  Qiang Yin and
                  Chao Tian and
                  Qian Tao and
                  Yongze Yan and
                  Ge Yu and
                  Jingren Zhou},
	title = {Layph: Making Change Propagation Constraint in Incremental Graph Processing
                  by Layering Graph},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {2766--2779},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00212},
	doi = {10.1109/ICDE55515.2023.00212},
	timestamp = {Thu, 24 Oct 2024 11:33:42 +0200},
	biburl = {https://dblp.org/rec/conf/icde/YuGZY00TY0Z23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Real-world graphs are constantly evolving, which demands updates of the previous analysis results to accommodate graph changes. By using the memoized previous computation state, incremental graph computation can reduce unnecessary recomputation. However, a small change may propagate over the whole graph and lead to large-scale iterative computations. To address this problem, we propose Layph, a two-layered graph framework. The upper layer is a skeleton of the graph which is much smaller than the original graph, and the lower layer has some disjoint subgraphs. Layph limits costly global iterative computations on the original graph to the small graph skeleton and a few subgraphs updated with the input graph changes. In this way, many vertices and edges are not involved in iterative computations, which significantly reduces the computation overhead and improves the performance of incremental graph processing. Our experimental results show that Layph outperforms current state-of-the-art incremental graph systems by 9.08× on average (up to 36.66×) in response time.}
}


@inproceedings{DBLP:conf/icde/GalhotraGF23,
	author = {Sainyam Galhotra and
                  Yue Gong and
                  Raul Castro Fernandez},
	title = {Metam: Goal-Oriented Data Discovery},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {2780--2793},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00213},
	doi = {10.1109/ICDE55515.2023.00213},
	timestamp = {Sun, 04 Aug 2024 19:37:46 +0200},
	biburl = {https://dblp.org/rec/conf/icde/GalhotraGF23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Data is a central component of machine learning and causal inference tasks. The availability of large amounts of data from sources such as open data repositories, data lakes and data marketplaces creates an opportunity to augment data and boost those tasks’ performance. However, augmentation techniques rely on a user manually discovering and shortlisting useful candidate augmentations. Existing solutions do not leverage the synergy between discovery and augmentation, thus underexploiting data.In this paper, we introduce Metam, a novel goal-oriented framework that queries the downstream task with a candidate dataset, forming a feedback loop that automatically steers the discovery and augmentation process. To select candidates efficiently, Metam leverages properties of the: i) data, ii) utility function, and iii) solution set size. We show Metam’s theoretical guarantees and demonstrate those empirically on a broad set of tasks. All in all, we demonstrate the promise of goal-oriented data discovery to modern data science applications.}
}


@inproceedings{DBLP:conf/icde/GavriilidisBQM23,
	author = {Haralampos Gavriilidis and
                  Kaustubh Beedkar and
                  Jorge{-}Arnulfo Quian{\'{e}}{-}Ruiz and
                  Volker Markl},
	title = {In-Situ Cross-Database Query Processing},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {2794--2807},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00214},
	doi = {10.1109/ICDE55515.2023.00214},
	timestamp = {Mon, 05 Feb 2024 20:31:12 +0100},
	biburl = {https://dblp.org/rec/conf/icde/GavriilidisBQM23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Today’s organizations utilize a plethora of heterogeneous and autonomous DBMSes, many of those being spread across different geo-locations. It is therefore crucial to have effective and efficient cross-database query processing capabilities. We present XDB, an efficient middleware system that runs cross-database analytics over existing DBMSes. In contrast to traditional query processing systems, XDB does not rely on any mediating execution engine to perform cross-database operations (e.g., joining data from two DBMSes). It delegates an entire query execution including cross-database operations to underlying DBMSes. At its core, it comprises an optimizer and a delegation engine: the optimizer rewrites cross-database queries into a delegation plan, which captures the semantics as well as the mechanics of a fully decentralized query execution; the delegation engine then deploys the plan to the underlying DBMSes via their declarative interfaces. Our experimental study based on the TPC-H benchmark data shows that XDB outperforms state-of-the-art systems (Garlic and Presto) by up to 6× in terms of runtime and up to 3 orders of magnitude in terms of data transfer.}
}


@inproceedings{DBLP:conf/icde/ZhuZWXY023,
	author = {Guanghui Zhu and
                  Zhennan Zhu and
                  Wenjie Wang and
                  Zhuoer Xu and
                  Chunfeng Yuan and
                  Yihua Huang},
	title = {AutoAC: Towards Automated Attribute Completion for Heterogeneous Graph
                  Neural Network},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {2808--2821},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00215},
	doi = {10.1109/ICDE55515.2023.00215},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhuZWXY023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Many real-world data can be modeled as heterogeneous graphs that contain multiple types of nodes and edges. Meanwhile, due to excellent performance, heterogeneous graph neural networks (GNNs) have received more and more attention. However, the existing work mainly focuses on the design of novel GNN models, while ignoring another important issue that also has a large impact on the model performance, namely the missing attributes of some node types. The handcrafted attribute completion requires huge expert experience and domain knowledge. Also, considering the differences in semantic characteristics between nodes, the attribute completion should be fine-grained, i.e., the attribute completion operation should be node-specific. Moreover, to improve the performance of the downstream graph learning task, attribute completion and the training of the heterogeneous GNN should be jointly optimized rather than viewed as two separate processes. To address the above challenges, we propose a differentiable attribute completion framework called AutoAC for automated completion operation search in heterogeneous GNNs. We first propose an expressive completion operation search space, including topology-dependent and topology-independent completion operations. Then, we propose a continuous relaxation schema and further propose a differentiable completion algorithm where the completion operation search is formulated as a bi-level joint optimization problem. To improve the search efficiency, we leverage two optimization techniques: discrete constraints and auxiliary unsupervised graph node clustering. Extensive experimental results on real-world datasets reveal that AutoAC outperforms the SOTA handcrafted heterogeneous GNNs and the existing attribute completion method.}
}


@inproceedings{DBLP:conf/icde/BaeLHK23,
	author = {Hong{-}Kyun Bae and
                  Yeon{-}Chang Lee and
                  Kyungsik Han and
                  Sang{-}Wook Kim},
	title = {A Competition-Aware Approach to Accurate {TV} Show Recommendation},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {2822--2834},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00216},
	doi = {10.1109/ICDE55515.2023.00216},
	timestamp = {Mon, 05 Feb 2024 20:31:13 +0100},
	biburl = {https://dblp.org/rec/conf/icde/BaeLHK23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As the number of TV shows increases, designing recommendation systems to provide users with their favorable TV shows becomes more important. In a TV show domain, watching a TV show (i.e., giving implicit feedback to the show) among the TV shows broadcast at the same time frame implies that the currently watching show is the winner in the competition with others (i.e., losers). However, in previous studies, such a notion of limited competitions has not been considered in estimating the user’s preferences for TV shows. In this paper, we propose a new recommendation framework to take this new notion into account based on pair-wise models. Our framework is composed of the following ideas: (i) identify winners and losers by determining pairs of competing TV shows; (ii) learn the pairs of competing TV shows based on the confidence for the pair-wise preference between the winner and the loser; (iii) recommend the most favorable TV shows by considering the time factors with respect to users and TV shows. Using a real-world TV show dataset, our experimental results show that our proposed framework consistently improves the accuracy of recommendation by up to 38%, compared with the best state-of-the-art method. The code and datasets of our framework are available in an external link (https://github.com/hongkyun-bae/tvshow_rs).}
}


@inproceedings{DBLP:conf/icde/Wang0KOA23,
	author = {Ruihong Wang and
                  Jianguo Wang and
                  Prishita Kadam and
                  M. Tamer {\"{O}}zsu and
                  Walid G. Aref},
	title = {dLSM: An LSM-Based Index for Memory Disaggregation},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {2835--2849},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00217},
	doi = {10.1109/ICDE55515.2023.00217},
	timestamp = {Sun, 12 Nov 2023 02:08:10 +0100},
	biburl = {https://dblp.org/rec/conf/icde/Wang0KOA23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The emerging trend of memory disaggregation where CPU and memory are physically separated from each other and are connected via ultra-fast networking, e.g., over RDMA, allows elastic and independent scaling of compute (CPU) and main memory. This paper investigates how indexing can be efficiently designed in the memory disaggregated architecture. Although existing research has optimized the B-tree for this new architecture, its performance is moderate. This paper focuses on LSM-based indexing and proposes dLSM, the first highly optimized LSM-tree for disaggregated memory. dLSM introduces a suite of optimizations including reducing software overhead, leveraging near-data computing, tuning for byte-addressability, and an instantiation over RDMA as a case study with RDMA-specific customizations to improve system performance. Experiments illustrate that dLSM achieves 1.6× to 11.7× higher write throughput than running the optimized B-tree and four adaptations of existing LSM-tree indexes over disaggregated memory. dLSM is written in C++ (with approximately 41,000 LOC), and is open-sourced.}
}


@inproceedings{DBLP:conf/icde/0003SLRD23,
	author = {Xiao Qin and
                  Nasrullah Sheikh and
                  Chuan Lei and
                  Berthold Reinwald and
                  Giacomo Domeniconi},
	title = {{SEIGN:} {A} Simple and Efficient Graph Neural Network for Large Dynamic
                  Graphs},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {2850--2863},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00218},
	doi = {10.1109/ICDE55515.2023.00218},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/0003SLRD23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graph neural networks (GNNs) have accomplished great success in learning complex systems of relations arising in broad problem settings ranging from e-commerce, social networks to data management. Training GNNs over large-scale graphs poses challenges for constrained compute resources due to the heavy data dependencies between the nodes. Moreover, modern relational data is constantly evolving, which creates an additional layer of learning challenges with respect to the model scalability and expressivity. This paper introduces a simple and efficient learning algorithm for large discrete-time dynamic graphs (DTDGs) – a widely adopted data model for many applications. We particularly tackle two critical challenges: (1) how the model can be efficiently trained on large-scale DTDGs to exploit hardware accelerators with small memory footprint, and (2) how the model can effectively capture the changing dynamics of the graphs. To the best of our knowledge, existing GNNs fail to address both challenges in their models. Hence, we propose a scalable evolving inception GNN, called SEIGN. Specifically, SEIGN features two connected evolving components that adapt the graph model to the arriving snapshot and capture the changing dynamics of the node embeddings, respectively. To scale up the model training, SEIGN introduces a parameter-free message passing step for DTDGs to substantially remove the data dependencies in training. Furthermore, it significantly reduces the training memory footprint and allows us to construct a succinct graph mini-batch without performing neighborhood sampling. We further optimize the proposed evolving strategies by extracting features from neighbors at varying scales to increase the expressive power of the node representations. Our experimental evaluation, on both public benchmark and real industrial datasets, demonstrates that SEIGN achieves 2%–20% improvement in Area Under Curve (AUC) and Average Precision (AP) on the prediction task over the state-of-the-art baselines. SEIGN also supports efficient graph mini-batch training and gains 2–16 times speedup in epoch computation time over the entire DTDGs.}
}


@inproceedings{DBLP:conf/icde/DongWYXZ0023,
	author = {Zhiyuan Dong and
                  Zhaoguo Wang and
                  Chuanwei Yi and
                  Xian Xu and
                  Jinyuan Zhang and
                  Jinyang Li and
                  Haibo Chen},
	title = {Database Deadlock Diagnosis for Large-Scale ORM-Based Web Applications},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {2864--2877},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00219},
	doi = {10.1109/ICDE55515.2023.00219},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/DongWYXZ0023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Today, most database-backed web applications depend on the database to handle deadlocks. At runtime, the database monitors the progress of transaction execution to detect deadlocks and abort affected transactions. However, this common detect-and-recover strategy is costly to performance as aborted transactions waste CPU resources.To avoid deadlock-induced performance degradation, developers aim to reorganize the application code to remove deadlocks. Unfortunately, doing so is difficult for web applications. Not only do their implementations include hundreds of thousands of LoCs, but they also use third-party object-relational mapping (ORM) frameworks which hide database access details. Consequently, it is hard for developers to accurately diagnose deadlocks.We propose WeSEER, a deadlock diagnosis tool for web applications. To overcome the opacity of ORMs, WeSEER performs concolic execution on unit tests to extract a web application’s transactions as a sequence of template statements with symbolic inputs as well as path conditions that enable the sequence. WeSEER then analyzes the extracted transactions based on fine-grained lock modeling to identify potential deadlocks and report the code locations that cause them. We implement WeSEER for Java-based (OpenJDK) web applications, and use it to analyze two popular open-source e-commerce applications, Broadleaf and Shopizer. WeSEER has successfully identified 18 potential deadlocks in Broadleaf and Shopizer. Eliminating these identified deadlocks can result in up to 39.5× and 4.5× throughput improvement for Broadleaf and Shopizer, respectively.}
}


@inproceedings{DBLP:conf/icde/LinGSL00WPWL23,
	author = {Qiongqiong Lin and
                  Yunfan Gu and
                  Jingyan Sai and
                  Jinfei Liu and
                  Kui Ren and
                  Li Xiong and
                  Tianzhen Wang and
                  Yanbei Pang and
                  Sheng Wang and
                  Feifei Li},
	title = {EulerFD: An Efficient Double-Cycle Approximation of Functional Dependencies},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {2878--2891},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00220},
	doi = {10.1109/ICDE55515.2023.00220},
	timestamp = {Sun, 06 Aug 2023 16:12:39 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LinGSL00WPWL23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Functional dependencies (FDs) have been extensively employed in discovering inferential relationships in databases, which provide feasible approaches for many data mining tasks, such as data obfuscation, query optimization, and schema normalization. Since the explosive growth of data leads to a rapid increase of FDs on large datasets, existing algorithms that pay more attention to the exact FD discovery cannot extract FDs efficiently. To bridge this gap, we propose an Efficient double-cycle approximation of Functional Dependency (EulerFD) discovery algorithm, which ensures both efficiency and accuracy of FD discovery. EulerFD induces FDs from invalid ones as invalidating an FD only requires comparing and verifying some pairs of tuples (that violate the dependency) while validating an FD requires examining and verifying all tuples. Considering the abundant tuple pairs in large datasets, a novel sampling strategy is employed in EulerFD to quickly extract invalid FDs by revising the sampling range according to previous sampling results. Furthermore, EulerFD evaluates the stopping criteria in a double-cycle structure as feedback for further sampling. The sampling strategy and the double-cycle structure complement each other to achieve a more efficient sampling effect. Experimental results on real-world and synthetic datasets, especially the massive datasets from DMS of Alibaba Cloud, justify the design and verify the efficiency and effectiveness of the proposed EulerFD.}
}


@inproceedings{DBLP:conf/icde/Shen0M23,
	author = {Tong Shen and
                  Yang Li and
                  Jos{\'{e}} M. F. Moura},
	title = {Forecasting {COVID-19} Dynamics: Clustering, Generalized Spatiotemporal
                  Attention, and Impacts of Mobility and Geographic Proximity},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {2892--2904},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00221},
	doi = {10.1109/ICDE55515.2023.00221},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Shen0M23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Forecasting the dynamics of COVID-19 enables government agencies and public health administrators to take proactive measures to combat the pandemic. This forecasting task faces several key challenges: First, the dynamics of COVID-19 exhibit complex spatial and temporal dependencies. The current growing trend at a location may be similar to that at another location in the past. Second, numerous factors, such as population mobility and geographic proximity between regions, mask usage, vaccine coverage, etc., significantly impact the dynamics. Third, we need to find the appropriate granularity for the forecasting task. The granularity should not be too coarse that we ignore the idiosyncrasies of individual regions. Still, the granularity should not be too fine that the prediction results are seriously vulnerable to noise.This paper addresses these challenges. We propose a simple but effective clustering algorithm that finds the appropriate granularity for the forecasting task. We invent generalized spatiotemporal attention, an attention mechanism that is generalized enough to capture the complex spatial and temporal dependencies and to flexibly account for intra- and inter-region characteristics such as geographic proximity and population mobility. Based on this generalized spatiotemporal attention, we designed COVID-Forecaster, a lightweight deep learning model for forecasting the dynamics of COVID-19. Experimental results demonstrate that COVID-Forecaster significantly outperforms state-of-the-art models. For example, COVID-Forecaster reduces the mean absolute percentage error (MAPE) by 6.8% and the weighted absolute percentage error (WAPE) by 13.5% in forecasting the COVID-19 dynamics at the 3141 counties of the United States.}
}


@inproceedings{DBLP:conf/icde/XieWL0LS0S23,
	author = {Songjie Xie and
                  Youlong Wu and
                  Kewen Liao and
                  Lu Chen and
                  Chengfei Liu and
                  Haifeng Shen and
                  MingJian Tang and
                  Lu Sun},
	title = {Fed-SC: One-Shot Federated Subspace Clustering over High-Dimensional
                  Data},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {2905--2918},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00222},
	doi = {10.1109/ICDE55515.2023.00222},
	timestamp = {Tue, 26 Mar 2024 13:06:23 +0100},
	biburl = {https://dblp.org/rec/conf/icde/XieWL0LS0S23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recent work has explored federated clustering and developed an efficient k-means based method. However, it is well known that k-means clustering underperforms in high-dimensional space due to the so-called "curse of dimensionality". In addition, high-dimensional data (e.g., generated from healthcare, medical, and biological sectors) are pervasive in the big data era, which poses critical challenges to federated clustering in terms of, but not limited to, clustering effectiveness and communication efficiency. To fill this significant gap in federated clustering, we propose a one-shot federated subspace clustering scheme Fed-SC that can achieve remarkable clustering effectiveness on high-dimensional data while keeping communication cost low using only one round of communication for each local device. We further establish theoretical guarantees on the clustering effectiveness of one-shot Fed-SC and exploit the benefits of statistical heterogeneity across distributed data. Extensive experiments on synthetic and real-world datasets demonstrate significant effectiveness gains of Fed-SC compared with both subspace clustering and one-shot federated clustering methods.}
}


@inproceedings{DBLP:conf/icde/MukherjeeSSSKKB23,
	author = {Koyel Mukherjee and
                  Raunak Shah and
                  Shiv Kumar Saini and
                  Karanpreet Singh and
                  Khushi and
                  Harsh Kesarwani and
                  Kavya Barnwal and
                  Ayush Chauhan},
	title = {Towards Optimizing Storage Costs on the Cloud},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {2919--2932},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00223},
	doi = {10.1109/ICDE55515.2023.00223},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/MukherjeeSSSKKB23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We study the problem of optimizing data storage and access costs on the cloud while ensuring that the desired performance or latency is unaffected. We first propose an optimizer that optimizes the data placement tier (on the cloud) and the choice of compression schemes to apply, for given data partitions with temporal access predictions. Secondly, we propose a model to learn the compression performance of multiple algorithms across data partitions in different formats to generate compression performance predictions on the fly, as inputs to the optimizer. Thirdly, we propose to approach the data partitioning problem fundamentally differently than the current default in most data lakes where partitioning is in the form of ingestion batches. We propose access pattern aware data partitioning and formulate an optimization problem that optimizes the size and reading costs of partitions subject to access patterns.We study the various optimization problems theoretically as well as empirically, and provide theoretical bounds as well as hardness results. We propose a unified pipeline of cost minimization, called SCOPe that combines the different modules. We extensively compare the performance of our methods with related baselines from the literature on TPC-H data as well as enterprise datasets (ranging from GB to PB in volume) and show that SCOPe substantially improves over the baselines. We show significant cost savings compared to platform baselines, of the order of 50% to 83% on enterprise Data Lake datasets that range from terabytes to petabytes in volume.}
}


@inproceedings{DBLP:conf/icde/Chang0LT23,
	author = {Yanchuan Chang and
                  Jianzhong Qi and
                  Yuxuan Liang and
                  Egemen Tanin},
	title = {Contrastive Trajectory Similarity Learning with Dual-Feature Attention},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {2933--2945},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00224},
	doi = {10.1109/ICDE55515.2023.00224},
	timestamp = {Sat, 30 Sep 2023 09:44:49 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Chang0LT23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Trajectory similarity measures act as query predicates in trajectory databases, making them the key player in determining the query results. They also have a heavy impact on the query efficiency. An ideal measure should have the capability to accurately evaluate the similarity between any two trajectories in a very short amount of time. Towards this aim, we propose a contrastive learning-based trajectory modeling method named TrajCL. We present four trajectory augmentation methods and a novel dual-feature self-attention-based trajectory backbone encoder. The resultant model can jointly learn both the spatial and the structural patterns of trajectories. Our model does not involve any recurrent structures and thus has a high efficiency. Besides, our pre-trained backbone encoder can be fine-tuned towards other computationally expensive measures with minimal supervision data. Experimental results show that TrajCL is consistently and significantly more accurate than the state-of-the-art trajectory similarity measures. After fine-tuning, i.e., to serve as an estimator for heuristic measures, TrajCL can even outperform the state-of-the-art supervised method by up to 56% in the accuracy for processing trajectory similarity queries.}
}


@inproceedings{DBLP:conf/icde/Abdallah023,
	author = {Hussein Abdallah and
                  Essam Mansour},
	title = {Towards a GML-Enabled Knowledge Graph Platform},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {2946--2954},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00225},
	doi = {10.1109/ICDE55515.2023.00225},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Abdallah023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This vision paper proposes KGNet, an on-demand graph machine learning (GML) as a service on top of RDF engines to support GML-enabled SPARQL queries. KGNet automates the training of GML models on a KG by identifying a task-specific subgraph. This helps reduce the task-irrelevant KG structure and properties for better scalability and accuracy. While training a GML model on KG, KGNet collects metadata of trained models in the form of an RDF graph called KGMeta, which is interlinked with the relevant subgraphs in KG. Finally, all trained models are accessible via a SPARQL-like query. We call it a GML-enabled query and refer to it as SPARQL ML . KGNet supports SPARQL ML on top of existing RDF engines as an interface for querying and inferencing over KGs using GML models. The development of KGNet poses research opportunities in several areas, including meta-sampling for identifying task-specific subgraphs, GML pipeline automation with computational constraints, such as limited time and memory budget, and SPARQL ML query optimization. KGNet supports different GML tasks, such as node classification, link prediction, and semantic entity matching. We evaluated KGNet using two real KGs of different application domains. Compared to training on the entire KG, KGNet significantly reduced training time and memory usage while maintaining comparable or improved accuracy. The KGNet source-code 1 is available for further study.}
}


@inproceedings{DBLP:conf/icde/ZhangLXLY0XCM23,
	author = {Yixin Zhang and
                  Yong Liu and
                  Hao Xiong and
                  Yi Liu and
                  Fuqiang Yu and
                  Wei He and
                  Yonghui Xu and
                  Lizhen Cui and
                  Chunyan Miao},
	title = {Cross-Domain Disentangled Learning for E-Commerce Live Streaming Recommendation},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {2955--2968},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00226},
	doi = {10.1109/ICDE55515.2023.00226},
	timestamp = {Sun, 06 Oct 2024 21:04:59 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhangLXLY0XCM23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {E-commerce live streaming as an increasingly popular sales model has generated a significant amount of gross merchandise value (GMV) for e-commerce platforms. Live streaming recommendation systems (LSRS) of e-commerce aim to recommend the most appropriate live channels for users to motivate them to buy products. Existing LSRS methods focus only on the user’s interaction behaviors on the live channel (live domain) while ignoring the user’s behaviors and intentions on the e-commerce product (product domain). As a result, the user’s consistent purchase intentions in the cross-domain are not being fully captured, especially when user present differentiated purchase intentions in the cross-domain. How to disentangle user’s consistent intentions and domain-specific intentions in the cross-domain poses a challenge to the LSRS of e-commerce platforms. In this paper, we present a live channel recommendation method, named eLiveRec, developed for Taobao, one of the largest e-commerce platform in the world. Specifically, eLiveRec employs the disentangled encoder module to learn user’s cross-domain consistent intentions and domain-specific intentions. Then, an adaptive multi-task learning framework is developed to jointly optimize the multiple objectives (e.g., stay time, click goods bag, and click products after entering channel) related to live streaming recommendation. In this way, the performance of live streaming recommendation can be further improved and con-form to standard industry RS paradigms. Extensive experiments are conducted on a large-scale industry dataset collected from Taobao Live platform have been performed. Both online and offline experimental results indicate that eLiveRec consistently outperforms existing state-of-the-art baseline methods.}
}


@inproceedings{DBLP:conf/icde/ZhouCLBZLY23,
	author = {Jie Zhou and
                  Xianshuai Cao and
                  Wenhao Li and
                  Lin Bo and
                  Kun Zhang and
                  Chuan Luo and
                  Qian Yu},
	title = {HiNet: Novel Multi-Scenario {\&} Multi-Task Learning with Hierarchical
                  Information Extraction},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {2969--2975},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00227},
	doi = {10.1109/ICDE55515.2023.00227},
	timestamp = {Sun, 06 Oct 2024 21:05:00 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhouCLBZLY23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Multi-scenario & multi-task learning has been widely applied to many recommendation systems in industrial applications, wherein an effective and practical approach is to carry out multi-scenario transfer learning on the basis of the Mixture-of-Expert (MoE) architecture. However, the MoE-based method, which aims to project all information in the same feature space, cannot effectively deal with the complex relationships inherent among various scenarios and tasks, resulting in unsatisfactory performance. To tackle the problem, we propose a Hierarchical information extraction Network (HiNet) for multi-scenario and multi-task recommendation, which achieves hierarchical extraction based on coarse-to-fine knowledge transfer scheme. The multiple extraction layers of the hierarchical network enable the model to enhance the capability of transferring valuable information across scenarios while preserving specific features of scenarios and tasks. Furthermore, a novel scenario-aware attentive network module is proposed to model correlations between scenarios explicitly. Comprehensive experiments conducted on real-world industrial datasets from Meituan Meishi platform demonstrate that HiNet achieves a new state-of-the-art performance and significantly outperforms existing solutions. HiNet is currently fully deployed in two scenarios and has achieved 2.87% and 1.75% order quantity gain respectively.}
}


@inproceedings{DBLP:conf/icde/ChenWYLLZHWYSZH23,
	author = {Cheng Chen and
                  Yilin Wang and
                  Jun Yang and
                  Yiming Liu and
                  Mian Lu and
                  Zhao Zheng and
                  Bingsheng He and
                  Weng{-}Fai Wong and
                  Liang You and
                  Penghao Sun and
                  Yuping Zhao and
                  Fenghua Hu and
                  Andy Rudoff},
	title = {OpenEmbedding: {A} Distributed Parameter Server for Deep Learning
                  Recommendation Models using Persistent Memory},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {2976--2987},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00228},
	doi = {10.1109/ICDE55515.2023.00228},
	timestamp = {Tue, 30 Jul 2024 08:18:21 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ChenWYLLZHWYSZH23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we present OpenEmbedding, a distributed parameter server system for deep learning recommendation models (DLRM) workloads. In order to support rapid growth in the number of features and the model size (Terabytes are common) of DLRM workloads, OpenEmbedding takes advantage of emerging persistent memory (PMem) to address scalability and reliability issues in training DLRMs. Compared to DRAM, PMem can have much lower per-GB cost, higher density, and non-volatility, while with slightly low access performance to DRAM. OpenEmbedding uses DRAM as cache and PMem as storage for the sparse features and develops a simple but effective pipeline processing approach to optimize the access latency of the sparse features in PMem. For reliability, we develop a lightweight synchronous checkpointing scheme that is specially co-designed with the pipelined cache to reduce the run-time overhead of checkpointing. Our evaluations on a real-world industry workload consisting of billions of parameters demonstrate 1) the effectiveness of our PMem-aware optimizations, 2) checkpointing mechanism with near-zero run-time overhead to the training performance and 3) fast recovery with up to 3.97× speedup compared to the state-of-the-art. OpenEmbedding has been deployed in hundreds of scenarios in industry within 4Paradigm, and is open-sourced 1 .}
}


@inproceedings{DBLP:conf/icde/DengWL0DCXYCCCP23,
	author = {Shumin Deng and
                  Chengming Wang and
                  Zhoubo Li and
                  Ningyu Zhang and
                  Zelin Dai and
                  Hehong Chen and
                  Feiyu Xiong and
                  Ming Yan and
                  Qiang Chen and
                  Mosha Chen and
                  Jiaoyan Chen and
                  Jeff Z. Pan and
                  Bryan Hooi and
                  Huajun Chen},
	title = {Construction and Applications of Billion-Scale Pre-Trained Multimodal
                  Business Knowledge Graph},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {2988--3002},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00229},
	doi = {10.1109/ICDE55515.2023.00229},
	timestamp = {Mon, 03 Jun 2024 15:23:14 +0200},
	biburl = {https://dblp.org/rec/conf/icde/DengWL0DCXYCCCP23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Business Knowledge Graphs (KGs) are important to many enterprises today, providing factual knowledge and structured data that steer many products and make them more intelligent. Despite their promising benefits, building business KG necessitates solving prohibitive issues of deficient structure and multiple modalities. In this paper, we advance the understanding of the practical challenges related to building KG in non-trivial real-world systems. We introduce the process of building an open business knowledge graph (OpenBG) derived from a well-known enterprise, Alibaba Group. Specifically, we define a core ontology to cover various abstract products and consumption demands, with fine-grained taxonomy and multimodal facts in deployed applications. OpenBG is an open business KG of unprecedented scale: 2.6 billion triples with more than 88 million entities covering over 1 million core classes/concepts and 2,681 types of relations. We release all the open resources (OpenBG benchmarks) derived from it for the community and report experimental results of KG-centric tasks. We also run up an online competition based on OpenBG benchmarks, and has attracted thousands of teams. We further pre-train OpenBG and apply it to many KG-enhanced downstream tasks in business scenarios, demonstrating the effectiveness of billion-scale multimodal knowledge for e-commerce. All the resources with codes have been released at https://github.com/OpenBGBenchmark/OpenBG.}
}


@inproceedings{DBLP:conf/icde/LyuWHWYLZ23,
	author = {Wenjun Lyu and
                  Haotian Wang and
                  Zhiqing Hong and
                  Guang Wang and
                  Yu Yang and
                  Yunhuai Liu and
                  Desheng Zhang},
	title = {{REDE:} Exploring Relay Transportation for Efficient Last-mile Delivery},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3003--3016},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00230},
	doi = {10.1109/ICDE55515.2023.00230},
	timestamp = {Wed, 15 May 2024 08:05:14 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LyuWHWYLZ23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Last-mile delivery from delivery stations to customers’ places is now mainly finished by dedicated couriers. In practice, each courier generally collects orders destined for one delivery area at the delivery station and delivers orders to customers. However, the long distance between the delivery station and the delivery area due to practical reasons, e.g., expensive delivery station rental fee in the downtown area, increases the delivery courier’s travel time and decreases the efficiency of the state-of-the-practice last-mile delivery scheme. In this paper, we solve the problem with relay transportation, where a relay courier collects orders at the delivery station and sends them to delivery couriers, and delivery couriers focus on the order delivery at corresponding delivery areas. We design a real-time relay courier scheduling system called REDE to minimize the average relay order delivery time (ARODT) considering the relay and delivery couriers’ mobility and the order destination distribution. First, a heterogeneous task aware route prediction algorithm is proposed to characterize the delivery courier’s mobility. Then a distance-aware greedy algorithm and an ARODT-constrained exchange algorithm are designed to generate the relay route, which is updated with real-time order pickup requests. Extensive evaluation results with real-world logistics data from 100 delivery stations in 38 cities show that REDE reduces ARODT by up to 8.4% compared to baseline methods. The online A/B tests show that compared to the state-of-the-practice method, REDE improves the delivery courier’s working efficiency and the daily number of pickup orders by 20.13% and 4.51%, respectively.}
}


@inproceedings{DBLP:conf/icde/ZhangZRZYLSL23,
	author = {Ya{-}Lin Zhang and
                  Jun Zhou and
                  Yankun Ren and
                  Yue Zhang and
                  Xinxing Yang and
                  Meng Li and
                  Qitao Shi and
                  Longfei Li},
	title = {{ALT:} An Automatic System for Long Tail Scenario Modeling},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3017--3030},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00231},
	doi = {10.1109/ICDE55515.2023.00231},
	timestamp = {Mon, 27 Nov 2023 18:50:39 +0100},
	biburl = {https://dblp.org/rec/conf/icde/ZhangZRZYLSL23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we consider the problem of long tail scenario modeling with budget limitation, i.e., insufficient human resources for model training stage and limited time and computing resources for model inference stage. This problem is widely encountered in various applications, yet has received deficient attention so far. We present an automatic system named ALT to deal with this problem. Several efforts are taken to improve the algorithms used in our system, such as employing various automatic machine learning related techniques, adopting the meta learning philosophy, and proposing an essential budget-limited neural architecture search method, etc. Moreover, to build the system, many optimizations are performed from a systematic perspective, and essential modules are armed, making the system more feasible and efficient. We perform abundant experiments to validate the effectiveness of our system and demonstrate the usefulness of the critical modules in our system. Moreover, online results are provided, which fully verified the efficacy of our system.}
}


@inproceedings{DBLP:conf/icde/ZhangZZLLZ23,
	author = {Hao Zhang and
                  Xianzhi Zeng and
                  Shuhao Zhang and
                  Xinyi Liu and
                  Mian Lu and
                  Zhao Zheng},
	title = {Scalable Online Interval Join on Modern Multicore Processors in OpenMLDB},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3031--3042},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00232},
	doi = {10.1109/ICDE55515.2023.00232},
	timestamp = {Mon, 15 Jul 2024 14:12:42 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhangZZLLZ23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {OpenMLDB is an open-source machine learning database, that provides a feature platform computing consistent features for training and inference. The online interval join (OIJ), i.e., joining two input streams over relative time intervals, is becoming a core operation in OpenMLDB. Its costly nature and intrinsic parallelism opportunities have created significant interest in accelerating OIJ on modern multicore processors. In this work, we first present an in-depth empirical study on an existing parallel OIJ algorithm (Key-OIJ), which applies a key-partitioned parallelization strategy. Key-OIJ has been implemented in Apache Flink and used in real-world applications. However, our study points out the limitations of Key-OIJ, and reveals that Key-OIJ is not capable of fully exploiting modern multicore processors. Based on our analysis, we propose a new approach, the Scale-OIJ algorithm with a set of optimization techniques. Compared with Key-OIJ, Scale-OIJ is particularly efficient for handling workloads involving fewer keys, large time intervals, and large lateness configurations. The extensive experiments using real workloads have demonstrated the superior performance of Scale-OIJ. Furthermore, we have partially integrated and tested Scale-OIJ in the latest version of OpenMLDB, demonstrating its practicality in a machine learning database.}
}


@inproceedings{DBLP:conf/icde/SunMZLSLWBZNCZL23,
	author = {Jason Sun and
                  Haoxiang Ma and
                  Li Zhang and
                  Huicong Liu and
                  Haiyang Shi and
                  Shangyu Luo and
                  Kai Wu and
                  Kevin Bruhwiler and
                  Cheng Zhu and
                  Yuanyuan Nie and
                  Jianjun Chen and
                  Lei Zhang and
                  Yuming Liang},
	title = {Accelerating Cloud-Native Databases with Distributed PMem Stores},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3043--3057},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00233},
	doi = {10.1109/ICDE55515.2023.00233},
	timestamp = {Thu, 23 Nov 2023 09:06:00 +0100},
	biburl = {https://dblp.org/rec/conf/icde/SunMZLSLWBZNCZL23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Relational databases have gone through a phase of architectural transition from a monolithic to a distributed architecture to take full advantage of cloud technology. These distributed databases can leverage remote storage to maintain larger amounts of data than monolithic databases at the cost of increased latency. At ByteDance, we have built a distributed database called veDB based on the popular compute-storage separation architecture, however we have observed the system is unable to provide both low latency and high throughput required by some business critical applications, such as batched order processing.In this paper we present our novel approaches to tackle this problem. We have modified our system’s storage to utilize persistent memory (PMem) coupled with a remote direct memory access (RDMA) network to reduce read/write latency and increase the throughput. We also propose a query push-down framework to push partial computations to the PMem storage layer to accelerate analytical queries and reduce the impact of the transaction workload in the computation layer. Our experiments show that our methods improve the throughput by up to 1.5× and reduce latency by up to 20× for standard benchmarks and real-world applications.}
}


@inproceedings{DBLP:conf/icde/XieNDWZWBCC23,
	author = {Xu Xie and
                  Jin Niu and
                  Lifang Deng and
                  Dan Wang and
                  Jiandong Zhang and
                  Zhihua Wu and
                  Kaigui Bian and
                  Gang Cao and
                  Bin Cui},
	title = {Hierarchical Interest Modeling of Long-tailed Users for Click-Through
                  Rate Prediction},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3058--3071},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00234},
	doi = {10.1109/ICDE55515.2023.00234},
	timestamp = {Fri, 28 Jul 2023 08:43:57 +0200},
	biburl = {https://dblp.org/rec/conf/icde/XieNDWZWBCC23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Click-through rate (CTR) prediction, whose purpose is to predict the probability of a user clicking on an item, plays a pivotal role in recommender systems. Capturing users’ accurate preferences from their historical interactions (e.g., clicks) is an essential step for handling this task and has aroused wide concern in both academia and industry. However, most of the previous methods focus on the users with abundant clicks and ill-serve the users who rarely click or purchase items. Though the ratio of these long-tailed users may be small on popular platforms, such as Amazon and Taobao, they are the majority on the newborn e-commerce company like Lazada. To extract the interests of long-tailed users, several works attempt to integrate the side information, such as demographic features. Nevertheless, these features are usually not available and may even lead to privacy concerns. Therefore, how to utilize the noisy and limited clicks becomes the key challenge.In this paper, we propose a novel model called Hierarchical Interest Modeling (HIM). It hierarchically utilizes long-tailed users’ limited behaviors and captures their preferences from both personalized and group-wise perspectives. HIM consists of two main components, including User Behavior Pyramid (UBP) and User Behavior Clustering (UBC). The UBP module utilizes additional negative feedback to reduce the noises in positive feedback, thus obtaining reliable user personalized representations. Then, the UBC module automatically discovers latent user groups with self-supervised reconstruction loss and learns another interest representation for each user in a group-wise aspect. Extensive experiments on both public and industrial datasets verify the superiority of HIM compared with the state-of-the-art baselines. Moreover, HIM has already been deployed on Lazada recommendation scenario and gains 3.38% on CTR prediction on average on the online A/B test. Our codes are available in https://github.com/xiaojin-nj/HIM.}
}


@inproceedings{DBLP:conf/icde/LiG23,
	author = {Pengfei Li and
                  Gaurav},
	title = {Automatic Synonym Extraction and Context-based Query Reformulation
                  for Points-of-Interest Search},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3072--3078},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00235},
	doi = {10.1109/ICDE55515.2023.00235},
	timestamp = {Thu, 03 Aug 2023 15:52:36 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LiG23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In modern search engines, synonyms are widely used for query reformulation to improve search recall and relevance. The search query is reformulated based on the synonymous terms that are semantically related to the original query. The reformulated queries are used for improving or augmenting the original query to retrieve more relevant results. However, there are four main challenges in production environments: (1) How to obtain high-quality synonyms and validate their effectiveness, especially for low-resource languagesƒ (2) How to prevent search intent drift caused by over-reformulating the correct queryƒ (3) How to efficiently keep the synonyms and models up-to-date for large-scale production systemsƒ (4) How to ensure the latency introduced by query reformulation does not affect user’s search experienceƒ In this paper, we address these challenges by introducing a context-based query reformulation system for Points-of-Interest (POI) search based on the synonyms automatically extracted from search logs and language models. The synonyms are automatically validated using historical query samples. We also propose a lightweight term identification model to prevent over-reformulation by considering query context during reformulation. The proposed methods are unsupervised/self-supervised that can be easily applied to large-scale production systems. We deploy our system to eight Southeast Asia countries that have both English and low-resource languages. Both offline evaluations and online A/B tests show that our system enhances search recall and relevance significantly.}
}


@inproceedings{DBLP:conf/icde/LuoLGTWLZLLP23,
	author = {Linhao Luo and
                  Yumeng Li and
                  Buyu Gao and
                  Shuai Tang and
                  Sinan Wang and
                  Jiancheng Li and
                  Tanchao Zhu and
                  Jiancai Liu and
                  Zhao Li and
                  Shirui Pan},
	title = {{MAMDR:} {A} Model Agnostic Learning Framework for Multi-Domain Recommendation},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3079--3092},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00236},
	doi = {10.1109/ICDE55515.2023.00236},
	timestamp = {Thu, 18 Jul 2024 08:28:31 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LuoLGTWLZLLP23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Large-scale e-commercial platforms in the real-world usually contain various recommendation scenarios (domains) to meet demands of diverse customer groups. Multi-Domain Recommendation (MDR), which aims to jointly improve recommendations on all domains and easily scales to thousands of domains, has attracted increasing attention from practitioners and researchers. Existing MDR methods usually employ a shared structure and several specific components to respectively leverage reusable features and domain-specific information. However, data distribution differs across domains, making it challenging to develop a general model that can be applied to all circumstances. Additionally, during training, shared parameters often suffer from domain conflict while specific parameters are inclined to overfitting on data sparsity domains. In this paper, we first present a scalable MDR platform served in Taobao that enables to provide services for thousands of domains without specialists involved. To address the problems of MDR methods, we propose a novel model agnostic learning framework, namely MAMDR, for the multi-domain recommendation. Specifically, we first propose a Domain Negotiation (DN) strategy to alleviate the conflict between domains. Then, we develop a Domain Regularization (DR) to improve the generalizability of specific parameters by learning from other domains. We integrate these components into a unified framework and present MAMDR, which can be applied to any model structure to perform multi-domain recommendation. Finally, we present a large-scale implementation of MAMDR in the Taobao application and construct various public MDR benchmark datasets which can be used for following studies. Extensive experiments on both benchmark datasets and industry datasets demonstrate the effectiveness and generalizability of MAMDR.}
}


@inproceedings{DBLP:conf/icde/0001WLQ0Z23,
	author = {Yilun Huang and
                  Dong Wen and
                  Longbin Lai and
                  Zhengping Qian and
                  Lu Qin and
                  Ying Zhang},
	title = {Efficient and Effective Path Compression in Large Graphs},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3093--3105},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00237},
	doi = {10.1109/ICDE55515.2023.00237},
	timestamp = {Tue, 07 May 2024 20:05:36 +0200},
	biburl = {https://dblp.org/rec/conf/icde/0001WLQ0Z23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A path in a graph is a walk from one vertex to the other via edges. Many tasks for graph analytics may produce numerous paths, which record critical intermediate information or results. On the platform of Alibaba Cloud, a transaction (e.g., user purchase and money transfer) usually involves network communication via multiple servers. The server communication history is recorded as a path, where each vertex is an IP address. It is of significance to record such paths in Alibaba Cloud for daily maintenance tasks, such as anomaly server detection and network routing optimization. Motivated by the considerable data scale of IP paths, this paper proposes a compression method Overlap-Free Frequent Subpath (OFFS) to reduce the overall size. Meanwhile, the compressed paths should allow retrievals of any individual path, which is required by applications in our scenarios. We build a lookup table to match a series of frequent common subpaths to supernodes. Each path is shortened by replacing subpaths with corresponding supernodes in the table. We adopt a bottom-up framework to construct the lookup table in given iterations. Several optimizations are proposed to improve the compression ratio and speed. We conduct extensive experiments to show our effectiveness and efficiency based on several real datasets from Alibaba Cloud.}
}


@inproceedings{DBLP:conf/icde/QiangWWMWWH23,
	author = {Yuting Qiang and
                  Haomin Wen and
                  Lixia Wu and
                  Xiaowei Mao and
                  Fan Wu and
                  Huaiyu Wan and
                  Haoyuan Hu},
	title = {Modeling Intra- and Inter-community Information for Route and Time
                  Prediction in Last-mile Delivery},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3106--3112},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00238},
	doi = {10.1109/ICDE55515.2023.00238},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/QiangWWMWWH23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Last-mile delivery, which refers to delivering packages from the depot to customers, is a crucial step for logistics service. The Route and Time Prediction (RTP) in last-mile package delivery is beneficial to improve customers’ experience and supervise couriers’ behavior. However, the limited raw information brings great challenges to accurately predict the route and delivery time. In this paper, we propose a deep model named I 2 RTP, which explores the heterogeneous representation of the package’s community to help predict the delivery route and estimate the arrival time of each package. Specifically, for the entire delivery route prediction, we model the inter- and intra-community information to learn the route features from global and local perspectives. Besides, by integrating the community representation with package features, our model could make more accurate predictions of the next-delivery package and its time duration. Experiments on the offline dataset and the online deployment on Cainiao’s Delivery System demonstrate the effectiveness of our proposed method, as well as validate the rationality of the global and local prediction pipeline.}
}


@inproceedings{DBLP:conf/icde/ZhuZYL0ZZ0W0W23,
	author = {Feng Zhu and
                  Mingjie Zhong and
                  Xinxing Yang and
                  Longfei Li and
                  Lu Yu and
                  Tiehua Zhang and
                  Jun Zhou and
                  Chaochao Chen and
                  Fei Wu and
                  Guanfeng Liu and
                  Yan Wang},
	title = {{DCMT:} {A} Direct Entire-Space Causal Multi-Task Framework for Post-Click
                  Conversion Estimation},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3113--3125},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00239},
	doi = {10.1109/ICDE55515.2023.00239},
	timestamp = {Sun, 06 Oct 2024 21:05:00 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhuZYL0ZZ0W0W23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recommendation scenarios, there are two long-standing challenges, i.e., selection bias and data sparsity, which lead to a significant drop in prediction accuracy for both Click-Through Rate (CTR) and post-click Conversion Rate (CVR) tasks. To cope with these issues, existing works emphasize on leveraging Multi-Task Learning (MTL) frameworks (Category 1) or causal debiasing frameworks (Category 2) to incorporate more auxiliary data in the entire exposure/inference space\nD\nor debias the selection bias in the click/training space\nO\n. However, these two kinds of solutions cannot effectively address the not-missing-at-random problem and debias the selection bias in\nO\nto fit the inference in\nD\n. To fill the research gaps, we propose a Direct entire-space Causal Multi-Task framework, namely DCMT, for post-click conversion prediction in this paper. Specifically, inspired by users’ decision process of conversion, we propose a new counterfactual mechanism to debias the selection bias in\nD\n, which can predict the factual CVR and the counterfactual CVR under the soft constraint of a counterfactual prior knowledge. Extensive experiments demonstrate that our DCMT can improve the state-of-the-art methods by an average of 1.07% in term of CVR AUC on the offline datasets and 0.75% in term of PV-CVR on the online A/B test (the Alipay Search). Such improvements can increase millions of conversions per week in real industrial applications, e.g., the Alipay Search.}
}


@inproceedings{DBLP:conf/icde/Zhu0WWZM23,
	author = {Guanzhou Zhu and
                  Dong Zhao and
                  Yizong Wang and
                  Haotian Wang and
                  Desheng Zhang and
                  Huadong Ma},
	title = {{COME:} Learning to Coordinate Crowdsourcing and Regular Couriers
                  for Offline Delivery During Online Mega Sale Days},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3126--3139},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00240},
	doi = {10.1109/ICDE55515.2023.00240},
	timestamp = {Wed, 17 Apr 2024 06:59:28 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Zhu0WWZM23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Crowd logistics, as an emerging delivery paradigm, provides a cost-efficient way of leveraging crowdsourcing couriers to help express enterprises to match the surging delivery demands that are hard to be addressed by regular couriers only during online mega sale days. However, it is a challenging problem how to recruit an appropriate number of crowdsourcing couriers and assign an appropriate number of parcels to them and regular couriers, as many practical issues need to be considered, such as the dynamic competitive crowdsourcing market, the turnover of crowdsourcing couriers, and unique workload patterns of regular couriers. We design a crowdsourcing-assisted express system called COME to coordinate crowdsourcing and regular couriers for minimizing the overall cost of labor payment and parcel backlog. In COME, we design an Opponent-Aware Reinforcement Learning model to learn the recruitment difficulty in a competitive crowdsourcing market to make an appropriate recruitment plan, and design a four-staged approach to make an appropriate parcel assignment plan, which can address not only the dynamic recruitment difficulty but also the dynamic number of couriers. We have implemented and deployed COME on a real-world crowdsourcing-assisted express system in China involving 1358 delivery stations over 145 cities, and extensively evaluated it with a four-year real-world dataset, demonstrating its great advantage over other alternative solutions and showing high feasibility and generality.}
}


@inproceedings{DBLP:conf/icde/Zeng0FCPCWG23,
	author = {Zhihao Zeng and
                  Yuntao Du and
                  Ziquan Fang and
                  Lu Chen and
                  Shiliang Pu and
                  Guodong Chen and
                  Hui Wang and
                  Yunjun Gao},
	title = {FLBooster: {A} Unified and Efficient Platform for Federated Learning
                  Acceleration},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3140--3153},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00241},
	doi = {10.1109/ICDE55515.2023.00241},
	timestamp = {Mon, 21 Aug 2023 14:38:41 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Zeng0FCPCWG23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated learning (FL) has emerged as a paradigm to train a global machine learning model in a distributed manner while taking privacy concerns and data protection regulations into consideration. Although a variety of FL algorithms have been proposed, the training efficiency of FL remains challenging due to massive mathematical computations and expensive client-server communication costs. However, existing FL-acceleration studies are limited as they can only solve the computation and communication overheads separately, which is suboptimal and constrains their acceleration ability. Moreover, previous studies are typically designed for specific FL scenarios and can support only one or two FL models, thus exhibiting poor generality.To fill these critical voids, we propose FLBooster, which provides unified and efficient acceleration capacity for a broad range of FL models. This is the first proposal to solve the computation and communication overheads simultaneously. Specifically, we utilize GPUs to boost the computation-intensive homomorphic encryption (HE) operations in a parallel manner, which significantly reduces the computation costs. On the other hand, a simple but efficient compression method is designed to lighten the exchange of data volumes between client and server. Extensive experiments using four standard FL models on three datasets show that FLBooster acquires superior speed-up gains (i.e., 14.3× – 138×) over state-of-the-art acceleration systems. Finally, we integrate FLBooster into the open-source FL benchmark FATE and offer user-friendly APIs for development.}
}


@inproceedings{DBLP:conf/icde/YaoZ0SWZX23,
	author = {Kaichun Yao and
                  Jingshuai Zhang and
                  Chuan Qin and
                  Xin Song and
                  Peng Wang and
                  Hengshu Zhu and
                  Hui Xiong},
	title = {ResuFormer: Semantic Structure Understanding for Resumes via Multi-Modal
                  Pre-training},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3154--3167},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00242},
	doi = {10.1109/ICDE55515.2023.00242},
	timestamp = {Sat, 30 Sep 2023 09:44:52 +0200},
	biburl = {https://dblp.org/rec/conf/icde/YaoZ0SWZX23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Understanding the semantic structure of resumes plays an important role for various intelligent recruitment related applications. However, due to the unique characteristics of resume documents (e.g., diverse writing styles and multi-page) and the lack of labeled data, it has been a long-standing challenge to effectively extract the structural information of resumes through machine learning models. While considerable efforts have been made in this direction, existing methods only focus on the textual information in the document where the rich multi-modal information (e.g., the visual and layout information) is largely ignored. To this end, in this paper, we propose ResuFormer for understanding the semantic structure of resumes. Specifically, ResuFormer focuses on two typical tasks in this direction, namely resume block classification and intra-block information extraction respectively. For the first task, we propose a multi-modal pre-training model with a hierarchical Transformer encoder, in which we design three self-supervised training objectives, i.e., masked layout-language model, self-supervised contrastive learning and dynamic next-sentence prediction, to pre-train the model parameters, and fine-tune the model only using a small amount of training data. For the second task, we introduce a self-distillation based self-training learning framework to make the distantly supervised model more robust to the noise data. Finally, extensive experiments conducted on real-world resume datasets have clearly validated the performance of our ResuFormer compared with state-of-the-art (SOTA) baselines.}
}


@inproceedings{DBLP:conf/icde/SunGZJZCZ23,
	author = {Luming Sun and
                  Shijin Gong and
                  Tieying Zhang and
                  Fuxin Jiang and
                  Zhibing Zhao and
                  Jianjun Chen and
                  Xinyu Zhang},
	title = {{SUFS:} {A} Generic Storage Usage Forecasting Service Through Adaptive
                  Ensemble Learning},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3168--3181},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00243},
	doi = {10.1109/ICDE55515.2023.00243},
	timestamp = {Sat, 30 Sep 2023 09:44:51 +0200},
	biburl = {https://dblp.org/rec/conf/icde/SunGZJZCZ23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Storage space usage forecasting is critical for the scalability and stability of storage systems. Cloud providers estimate storage usages based on the forecast and allocate resources accordingly. Overestimated space usages require a redundant storage buffer that brings unnecessary cost, and underestimated space usages will cause capacity shortages that may lead to data loss and Service-Level Agreement (SLA) failures. While accurate storage forecasting is important, it is highly challenging due to various storage usage patterns on different workloads and storage systems. Moreover, some operations from users or administrators may cause transient workload burst in historical data, which makes forecasting even harder.In this paper, we propose the Storage Usage Forecasting Service (SUFS) that combines deep neural networks and statistical models adaptively to make predictions for multiple major storage systems in ByteDance. SUFS carries comprehensive analyses of storage usage time series from various storage systems in real business scenarios. To handle workload bursts in historical data, we enhance regular LSTMs using a control signal that is installed on the input gate. When the burst is detected, the control signal reduces the input influences to the cell state. To further improve the prediction accuracy, SUFS integrates the Enhanced-LSTM (ELSTM) with a novel adaptive ensemble method. Different from previous works, our approach learns dynamic ensemble weights for each prediction step on-the-fly, making our model more accurate for multiple-step predictions. SUFS has been deployed to serve more than 150,000 storage instances. We conducted extensive experiments on the storage systems that are widely-used in ByteDance, and the results show that SUFS outperforms the state-of-the-art methods and significantly reduces storage cost.}
}


@inproceedings{DBLP:conf/icde/0005HPZZLZZ23,
	author = {Weifan Wang and
                  Binbin Hu and
                  Zhicheng Peng and
                  Mingjie Zhong and
                  Zhiqiang Zhang and
                  Zhongyi Liu and
                  Guannan Zhang and
                  Jun Zhou},
	title = {{GARCIA:} Powering Representations of Long-tail Query with Multi-granularity
                  Contrastive Learning},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3182--3195},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00244},
	doi = {10.1109/ICDE55515.2023.00244},
	timestamp = {Fri, 25 Aug 2023 19:04:16 +0200},
	biburl = {https://dblp.org/rec/conf/icde/0005HPZZLZZ23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recently, the growth of service platforms brings great convenience to both users and merchants, where the service search engine plays a vital role in improving the user experience by quickly obtaining desirable results via textual queries. Unfortunately, users’ uncontrollable search customs usually bring vast amounts of long-tail queries, which severely threaten the capability of search models. Inspired by recently emerging graph neural networks (GNNs) and contrastive learning (CL), several efforts have been made in alleviating the long-tail issue and achieve considerable performance. Nevertheless, they still face a few major weaknesses. Most importantly, they do not explicitly utilize the contextual structure between heads and tails for effective knowledge transfer, and intention-level information is commonly ignored for more generalized representations.To this end, we develop a novel framework GARCIA, which exploits the graph based knowledge transfer and intention based representation generalization in a contrastive setting. In particular, we employ an adaptive encoder to produce informative representations for queries and services, as well as hierarchical structure aware representations of intentions. To fully understand tail queries and services, we equip GARCIA with a novel multi-granularity contrastive learning module, which powers representations through knowledge transfer, structure enhancement and intention generalization. Subsequently, the complete GARCIA is well trained in a pre-training&fine-tuning manner. At last, we conduct extensive experiments on both offline and online environments, which demonstrates the superior capability of GARCIA in improving tail queries and overall performance in service search scenarios.}
}


@inproceedings{DBLP:conf/icde/ZhangZSHWW23,
	author = {Xiaojian Zhang and
                  Hongyin Zhang and
                  Shaoxu Song and
                  Xiangdong Huang and
                  Chen Wang and
                  Jianmin Wang},
	title = {Backward-Sort for Time Series in Apache IoTDB},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3196--3208},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00245},
	doi = {10.1109/ICDE55515.2023.00245},
	timestamp = {Mon, 09 Sep 2024 19:07:30 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhangZSHWW23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {While time series data are naturally ordered by timestamps for efficient storage and query processing, the data points in a time series often come out-of-order. We identify two unique features of out-of-order arrivals in Apache IoTDB, i.e., delay-only and not-too-distant. It is not surprising that data points can only be delayed but should never come "earlier" before the generation of its succeeding ones. Moreover, the system employs a separation policy to handle those points delayed for a very long period, and thus only sorts data points delayed to not-too-distant future. Motivated by such unique features, we devise a new algorithm for sorting time series data, Backward-Sort. Intuitively, the delay-only feature leads to the strategy of moving points backward in sorting. Moreover, the not-too-distant feature results in blocks of data points, such that moving points are expected to occur locally inside the blocks. To our best knowledge, this is the first sorting algorithm specially designed for out-of-order arrivals in time series. The algorithm becomes a fundamental component of sorting time series data in Apache IoTDB. The evaluation is conducted over real and synthetic datasets, using IoTDB-benchmark.}
}


@inproceedings{DBLP:conf/icde/ZhengYHYLX0J23,
	author = {Bolong Zheng and
                  Ziyang Yue and
                  Qi Hu and
                  Xiaomeng Yi and
                  Xiaofan Luan and
                  Charles Xie and
                  Xiaofang Zhou and
                  Christian S. Jensen},
	title = {Learned Probing Cardinality Estimation for High-Dimensional Approximate
                  {NN} Search},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3209--3221},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00246},
	doi = {10.1109/ICDE55515.2023.00246},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhengYHYLX0J23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Approximate nearest neighbor (ANN) search in high-dimensional space plays an essential role in a variety of real-world applications. A well-known solution to ANN search, inverted file product quantization (IVFPQ) adopts inverted files to avoid exhaustive examination and compresses vectors using product quantization to reduce the space overhead. However, existing implementations use the same fixed probing cardinality (i.e., the number of cells to probe) setting for all queries, which leads to too many or too few cell examinations, thus increasing the average query latency or reducing the recall. To achieve a better trade-off between latency and accuracy, we enable probing cardinality estimation for high-dimensional ANN search by using deep learning techniques. We develop HBK-means, a hierarchical balanced clustering algorithm that reduces the data distribution imbalance of cells to enable a better estimation. Next, we develop PCE-Net, an encoder-decoder based neural network for estimating query-dependent minimum probing cardinality. In addition, we introduce two query optimization strategies: lower bound sorting based pruning (LBS-Pruning) and early termination (ET), to further reduce query latency. Extensive experiments with real-world data offer evidence that the proposed solution is capable of achieving better performance than IVFPQ and its variants.}
}


@inproceedings{DBLP:conf/icde/GongCMXWTLXLJ23,
	author = {Juan Gong and
                  Zhenlin Chen and
                  Chaoyi Ma and
                  Zhuojian Xiao and
                  Haonan Wang and
                  Guoyu Tang and
                  Lin Liu and
                  Sulong Xu and
                  Bo Long and
                  Yunjiang Jiang},
	title = {Attention Weighted Mixture of Experts with Contrastive Learning for
                  Personalized Ranking in E-commerce},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3222--3234},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00247},
	doi = {10.1109/ICDE55515.2023.00247},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/GongCMXWTLXLJ23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Ranking model plays an essential role in e-commerce search and recommendation. An effective ranking model should give a personalized ranking list for each user according to the user preference. Existing algorithms usually extract a user representation vector from the user behavior sequence, then feed the vector into a feed-forward network (FFN) together with other features for feature interactions, and finally produce a personalized ranking score. Despite tremendous progress in the past, there is still room for improvement. Firstly, the personalized patterns of feature interactions for different users are not explicitly modeled. Secondly, most of existing algorithms have poor personalized ranking results for long-tail users with few historical behaviors due to the data sparsity.To overcome the two challenges, we propose Attention Weighted Mixture of Experts (AW-MoE) with contrastive learning for personalized ranking. Firstly, AW-MoE leverages the MoE framework to capture personalized feature interactions for different users. To model the user preference, the user behavior sequence is simultaneously fed into expert networks and the gate network. Within the gate network, one gate unit and one activation unit are designed to adaptively learn the fine-grained activation vector for experts using an attention mechanism. Secondly, a random masking strategy is applied to the user behavior sequence to simulate long-tail users, and an auxiliary contrastive loss is imposed to the output of the gate network to improve the model generalization for these users. This is validated by a higher performance gain on the long-tail user test set.Experiment results on a JD real production dataset and a public dataset demonstrate the effectiveness of AW-MoE, which significantly outperforms state-of-art methods. Notably, AW-MoE has been successfully deployed in the JD e-commerce search engine, serving the real traffic of hundreds of millions of active users.}
}


@inproceedings{DBLP:conf/icde/ZhangSHLTHWZZ23,
	author = {Dalong Zhang and
                  Xianzheng Song and
                  Zhiyang Hu and
                  Yang Li and
                  Miao Tao and
                  Binbin Hu and
                  Lin Wang and
                  Zhiqiang Zhang and
                  Jun Zhou},
	title = {InferTurbo: {A} Scalable System for Boosting Full-graph Inference
                  of Graph Neural Network over Huge Graphs},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3235--3247},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00248},
	doi = {10.1109/ICDE55515.2023.00248},
	timestamp = {Fri, 25 Aug 2023 19:04:16 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhangSHLTHWZZ23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the rapid development of Graph Neural Networks (GNNs), more and more studies focus on system design to improve training efficiency while ignoring the efficiency of GNN inference. Actually, GNN inference is a non-trivial task, especially in industrial scenarios with giant graphs, given three main challenges, i.e., scalability tailored for full-graph inference on huge graphs, inconsistency caused by stochastic acceleration strategies (e.g., sampling), and the serious redundant computation issue. To address the above challenges, we propose a scalable system named InferTurbo to boost the GNN inference tasks in industrial scenarios. Inspired by the philosophy of "think-like-a-vertex", a GAS-like (Gather-Apply-Scatter) schema is proposed to describe the computation paradigm and data flow of GNN inference. The computation of GNNs is expressed in an iteration manner, in which a vertex would gather messages via in-edges and update its state information by forwarding an associated layer of GNNs with those messages and then send the updated information to other vertexes via out-edges. Following the schema, the proposed InferTurbo can be built with alternative backends (e.g., batch processing system or graph computing system). Moreover, InferTurbo introduces several strategies like shadow-nodes and partial-gather to handle nodes with large degrees for better load balancing. With InferTurbo, GNN inference can be hierarchically conducted over the full graph without sampling and redundant computation. Experimental results demonstrate that our system is robust and efficient for inference tasks over graphs containing some hub nodes with many adjacent edges. Meanwhile, the system gains a remarkable performance compared with the traditional inference pipeline, and it can finish a GNN inference task over a graph with tens of billions of nodes and hundreds of billions of edges within 2 hours.}
}


@inproceedings{DBLP:conf/icde/YangHYSZGZ23,
	author = {Dan Yang and
                  Binbin Hu and
                  Xiaoyan Yang and
                  Yue Shen and
                  Zhiqiang Zhang and
                  Jinjie Gu and
                  Guannan Zhang},
	title = {Who Would be Interested in Services? An Entity Graph Learning System
                  for User Targeting},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3248--3254},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00249},
	doi = {10.1109/ICDE55515.2023.00249},
	timestamp = {Sun, 06 Aug 2023 16:26:52 +0200},
	biburl = {https://dblp.org/rec/conf/icde/YangHYSZGZ23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the growing popularity of various mobile devices, user targeting has received a growing amount of attention, which aims at effectively and efficiently locating target users that are interested in specific services. Most pioneering works for user targeting tasks commonly perform similarity-based expansion with a few active users as seeds, suffering from the following major issues: the unavailability of seed users for new-coming services and the unfriendliness of black-box procedures towards marketers. In this paper, we design an Entity Graph Learning (EGL) system to provide explainable user targeting ability meanwhile applicable to addressing the cold-start issue. EGL System follows the hybrid online-offline architecture to satisfy the requirements of scalability and timeliness. Specifically, in the offline stage, the system focuses on the heavyweight entity graph construction and user entity preference learning, in which we propose a Three-stage Relation Mining Procedure (TRMP), breaking loose from the expensive seed users. At the online stage, the system offers the ability of user targeting in real-time based on the entity graph from the offline stage. Since the user targeting process is based on graph reasoning, the whole process is transparent and operation-friendly to marketers. Finally, extensive offline experiments and online A/B testing demonstrate the superior performance of the proposed EGL System.}
}


@inproceedings{DBLP:conf/icde/0001X0XS023,
	author = {Shuncheng Liu and
                  Yuyang Xia and
                  Xu Chen and
                  Jiandong Xie and
                  Han Su and
                  Kai Zheng},
	title = {Impact-aware Maneuver Decision with Enhanced Perception for Autonomous
                  Vehicle},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3255--3268},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00250},
	doi = {10.1109/ICDE55515.2023.00250},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/0001X0XS023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Autonomous driving is an emerging technology that has developed rapidly over the last decade. There have been numerous interdisciplinary challenges imposed on the current transportation system by autonomous vehicles. In this paper, we conduct an algorithmic study on the autonomous vehicle decision-making process, which is a fundamental problem in the vehicle automation field and the root cause of most traffic congestion. We propose a perception-and-decision framework, called HEAD, which consists of an enHanced pErception module and a mAneuver Decision module. HEAD aims to enable the autonomous vehicle to perform safe, efficient, and comfortable maneuvers with minimal impact on other vehicles. In the enhanced perception module, a graph-based state prediction model with a strategy of phantom vehicle construction is proposed to predict the one-step future states for multiple surrounding vehicles in parallel, which deals with sensor limitations such as limited detection range and poor detection accuracy under occlusions. Then in the maneuver decision module, a deep reinforcement learning-based model is designed to learn a policy for the autonomous vehicle to perform maneuvers in continuous action space w.r.t. a parameterized action Markov decision process. A hybrid reward function takes into account aspects of safety, efficiency, comfort, and impact to guide the autonomous vehicle to make optimal maneuver decisions. Extensive experiments offer evidence that HEAD can advance the state of the art in terms of both macroscopic and microscopic effectiveness.}
}


@inproceedings{DBLP:conf/icde/ShenWMCCZZZ23,
	author = {Wenyi Shen and
                  Wenyu Wu and
                  Jiali Mao and
                  Jie Chen and
                  Shaosheng Cao and
                  Lisheng Zhao and
                  Aoying Zhou and
                  Lin Zhou},
	title = {{SAMI:} {A} Shape-Aware Cycling Map Inference Framework for Designated
                  Driving Service},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3269--3281},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00251},
	doi = {10.1109/ICDE55515.2023.00251},
	timestamp = {Thu, 15 Aug 2024 07:54:18 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ShenWMCCZZZ23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Along with the increase in strict regulation of drunk driving behavior in China, the demands for designated driving services have risen in popularity. In the absence of specialized cycling map for the designated drivers who use foldable electric bicycles, they tend to take a detour or are lost on the way to the car owners’ appointed parking places. With gradual popularization of chauffeur services, cycling trajectories generated by designated drivers almost spread all over the city. It provides a chance for inferring the cycling map dedicated to the designated drivers. However, to infer an accurate map using trajectories faces severe challenges stemming from random cycling behaviors of designated drivers, including (i) trajectories contain a lot of noises and incomplete segments, (ii) turning trajectories at minor intersections are very sparse and (iii) trajectories on the roads of distinct shapes are obviously different. To address the above challenges, we propose a three-phase map inference framework, called SAMI, consisting of trajectory refinement, intersection pinpointing, and road curve interlinking. Specifically, cycling behavioral differences from neighbor regions are incorporated into intersection identification process to ensure obtaining high detection precision even when trajectory data is sparse. Further, shape-aware based centerline fitting strategy is put forward to guarantee that inferred road curves are consistent with real road shape as possible. Finally, extensive comparative experiments on two real data sets demonstrate that SAMI significantly outperforms state-of-the-art methods by 13.31% in F1-score of map inference and by 44.88% in recall rate of minor intersection detection.}
}


@inproceedings{DBLP:conf/icde/Wilhelm0GKM23,
	author = {Yannick Wilhelm and
                  Peter Reimann and
                  Wolfgang Gauchel and
                  Steffen Klein and
                  Bernhard Mitschang},
	title = {Pusion - {A} Generic and Automated Framework for Decision Fusion},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3282--3295},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00252},
	doi = {10.1109/ICDE55515.2023.00252},
	timestamp = {Sun, 06 Oct 2024 21:04:59 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Wilhelm0GKM23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Combining two or more classifiers into an ensemble and fusing the individual classifier decisions to a consensus decision can improve the accuracy for a classification problem. The classification improvement of the fusion result depends on numerous factors, such as the data set, the combination scenario, the decision fusion algorithm, as well as the prediction accuracies and diversity of the multiple classifiers to be combined. Due to these factors, the best decision fusion algorithm for a given decision fusion problem cannot be generally determined in advance. In order to support the user in combining classifiers and to achieve the best possible fusion result, we propose the PUSION (Python Universal fuSION) framework, a novel generic and automated framework for decision fusion of classifiers. The framework includes 14 decision fusion algorithms and covers a total of eight different combination scenarios for both multi-class and multi-label classification problems. The introduced concept of AutoFusion detects the combination scenario for a given use case, automatically selects the applicable decision fusion algorithms and returns the decision fusion algorithm that leads to the best fusion result. The framework is evaluated with two real-world case studies in the field of fault diagnosis. In both case studies, the consensus decision of multiple classifiers and heterogeneous fault diagnosis methods significantly increased the overall classification accuracy. Our evaluation results show that our framework is of practical relevance and reliably finds the best performing decision fusion algorithm for a given combination task.}
}


@inproceedings{DBLP:conf/icde/CaiWWW0WHL23,
	author = {Tianyue Cai and
                  Huaiyu Wan and
                  Fan Wu and
                  Haomin Wen and
                  Shengnan Guo and
                  Lixia Wu and
                  Haoyuan Hu and
                  Youfang Lin},
	title = {M\({}^{\mbox{2}}\)G4RTP: {A} Multi-Level and Multi-Task Graph Model
                  for Instant-Logistics Route and Time Joint Prediction},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3296--3308},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00253},
	doi = {10.1109/ICDE55515.2023.00253},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/CaiWWW0WHL23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Instant-logistics (e.g., food delivery and package pick-up) is increasingly calling for Route and Time Prediction (RTP), which aims to predict both future route and arrival time of a courier’s unvisited locations. Accurate RTP can greatly benefit the platform, such as optimizing order dispatching and improving user experience. Although recent years have witnessed various works for solving the RTP problem, they still suffer from the following three limitations: i) Failing to consider the high-level transfer mode of couriers between AOIs (Areas Of Interest, such as residential quarters or office buildings), which can help to build more accurate RTP. ii) Failing to simultaneously make the route and time prediction. Existing works either separately predict route/time or predict them in a two-step way. However, since route and time are strongly correlated (nearby locations in the route should have similar arrival times), jointly predicting them should be more effective. iii) The widely adopted tree-based or sequence-based architecture fails to fully encode the spatial relationship between different locations. To address the above limitations, we propose a multi-level and multi-task graph model, named M 2 G4RTP, for instant-logistics route and time joint prediction. Specifically, we propose a multi-level graph encoder equipped with a newly-designed GAT-e encoding module to capture couriers’ both high-level transfer modes between AOIs and low-level transfer modes between locations. Moreover, a multi-task decoder is presented to jointly predict the route and time at different levels. Finally, a loss weighting method based on homoscedastic uncertainty is designed to balance the two tasks adaptively. Extensive experiments on an industry-scale real-world dataset, as well as the online deployment on Cainiao Alibaba, demonstrate the superiority of our proposed model.}
}


@inproceedings{DBLP:conf/icde/ZhaoLDJSWLX23,
	author = {Qifang Zhao and
                  Tianyu Li and
                  Meng Du and
                  Yu Jiang and
                  Qinghui Sun and
                  Zhongyao Wang and
                  Hong Liu and
                  Huan Xu},
	title = {UniMatch: {A} Unified User-Item Matching Framework for the Multi-purpose
                  Merchant Marketing},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3309--3321},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00254},
	doi = {10.1109/ICDE55515.2023.00254},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhaoLDJSWLX23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {When doing private domain marketing with cloud services, the merchants usually have to purchase different machine learning models for the multiple marketing purposes, leading to a very high cost. We present a unified user-item matching framework to simultaneously conduct item recommendation and user targeting with just one model. We empirically demonstrate that the above concurrent modeling is viable via modeling the user-item interaction matrix with the multinomial distribution, and propose a bidirectional bias-corrected NCE loss for the implementation. The proposed loss function guides the model to learn the user-item joint probability p(u,i) instead of the conditional probability p(i|u) or p(u|i) through correcting both the users and items’ biases caused by the in-batch negative sampling. In addition, our framework is model-agnostic enabling a flexible adaptation of different model architectures. Extensive experiments demonstrate that our framework results in significant performance gains in comparison with the state-of-the-art methods, with greatly reduced cost on computing resources and daily maintenance.}
}


@inproceedings{DBLP:conf/icde/WongTHTSS23,
	author = {Tony Wong and
                  Smriti Thakkar and
                  Kao{-}Feng Hsieh and
                  Zachary Tom and
                  Hetaben Saraiya and
                  Philip Shilane},
	title = {Dataset Similarity Detection for Global Deduplication in the {DD}
                  File System},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3322--3335},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00255},
	doi = {10.1109/ICDE55515.2023.00255},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/WongTHTSS23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Deduplication has become a widely used technique to reduce space requirements for storage systems by replacing redundant chunks of data with references. While storage systems continue to grow in size, there remain practical limits to the size of any deduplication node, and enterprise businesses may have dozens to hundreds of nodes. It is important to place datasets on nodes in a multi-node environment to take advantage of deduplication savings globally. For customers of the DD File System (DDFS) 1 , we provide the Global Deduplication Service that advises customers on data placement to maximize deduplication-related space savings. This paper describes our currently shipping approach that uses a Fingerprint Dictionary to intelligently cluster customer data and generate a plan to relocate datasets to improve global deduplication. We report results from thousands of deployed systems at customer sites. We have also developed a further improvement using MinHashes that lowers resource requirements, and we provide proofs of the similarity estimates. Our results on a real-world dataset show that MinHashes improve the clustering speed up to 400X relative to our previous method and reduce memory consumption up to 260X.}
}


@inproceedings{DBLP:conf/icde/MagnanimiBCM23,
	author = {Davide Magnanimi and
                  Luigi Bellomarini and
                  Stefano Ceri and
                  Davide Martinenghi},
	title = {Reactive Company Control in Company Knowledge Graphs},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3336--3348},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00256},
	doi = {10.1109/ICDE55515.2023.00256},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/MagnanimiBCM23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Company Control Problem consists in understanding who exerts decision power in companies. Central banks, financial intelligence units, and market regulators are all interested in this problem, which is crucial for their core goals. In the context where these actors operate, changes in company control call for immediate reactions.Yet, computing control relationships is a computationally expensive problem that involves traversing the entire shareholding structure and aggregating shares over multiple paths.In the context of the joint European banking supervision, the Bank of Italy will soon handle the shareholding graph of all European companies, which comprises hundreds of millions of entities (firms and individuals) and billions of edges and properties. This graph is highly volatile as the Bank continuously receives updates about shareholding relationships with unpredictable high frequency. This makes the straightforward bulk solution, where all the company control relationships are computed and materialized whenever a change occurs, unaffordable in practice.In this work, we present an incremental rule-based formalization of the problem, adopting the Vadalog fragment of the Datalog+/- families of languages. Our approach analyzes the specific change, singles out the portions of the graph that are affected by it, and selectively updates them. This allows one both to timely evaluate the impact of ownership variations on an extensive European-scale shareholding graph and to enable economists to perform the so-called "what-if analysis", i.e., simulation scenarios to proactively study the consequences of potential share acquisition operations, that currently are prohibitively time expensive. We provide an extensive experimental evaluation on very large company graphs, comparatively confirming the scalability of our technique in a real production setting.}
}


@inproceedings{DBLP:conf/icde/YadavVZ23,
	author = {Ritwik Yadav and
                  Satyanarayana R. Valluri and
                  Mohamed Za{\"{\i}}t},
	title = {{AIM:} {A} practical approach to automated index management for {SQL}
                  databases},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3349--3362},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00257},
	doi = {10.1109/ICDE55515.2023.00257},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/YadavVZ23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper describes AIM (Automatic Index Manager), a configurable index management system, which identifies impactful secondary indexes for SQL databases to efficiently use available resources such as CPU, I/O and storage. It has been validated on thousands of databases which support production systems. With AIM, the physical design of the database adapts itself to the changes in the workload.We lay out the end to end design of AIM while calling out the guarantees and tradeoffs associated with our design choices. Some of the salient features of AIM include fast convergence even while recommending wide composite indexes, reduced reliance on the query optimizer and a "no regression" guarantee for production workloads. Each index recommendation from AIM is accompanied with a metrics driven explanation, making it easier to verify machine driven changes.AIM is one of the few industrial strength index recommendation engines that is deployed on production databases at a large scale. The experimental results show that AIM is quick in identifying the most effective indexes and the resulting physical design is close to optimal.}
}


@inproceedings{DBLP:conf/icde/ZhangHZXRJ23,
	author = {Yinan Zhang and
                  Huiqi Hu and
                  Xuan Zhou and
                  Enlong Xie and
                  Hongdi Ren and
                  Le Jin},
	title = {PM-Blade: {A} Persistent Memory Augmented LSM-tree Storage for Database},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3363--3375},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00258},
	doi = {10.1109/ICDE55515.2023.00258},
	timestamp = {Tue, 01 Aug 2023 14:11:16 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhangHZXRJ23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we present PM-Blade, an LSM-tree structured storage augmented with persistent memory (or non-volatile memory). PM-Blade utilizes persistent memory to optimize read performance and reduce write amplification, which are essential to Meituan’s online retail applications. Distinguished from existing designs, PM-Blade leverages persistent memory to drastically increase the capacity of the level-0 layer of LSM-tree. An enlarged level-0 layer allows a large amount of hot or warm data to be retained in persistent memory, enabling high read performance. At the same time, it works as a large write buffer that absorbs write amplification. To make the best of the design, we devised an internal compaction method and used a cost-based compaction strategy to maximize the utility of the level-0 layer. We implemented the compaction method using coroutines to improve its efficiency and resource utilization. We evaluated PM-Blade through extensive experiments, in which PM-Blade outperformed several open-source alternatives on standard benchmarks and a real-world workload of Meituan.}
}


@inproceedings{DBLP:conf/icde/KesavanGTSM23,
	author = {Ram Kesavan and
                  David Gay and
                  Daniel Thevessen and
                  Jimit Shah and
                  C. Mohan},
	title = {Firestore: The NoSQL Serverless Database for the Application Developer},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3376--3388},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00259},
	doi = {10.1109/ICDE55515.2023.00259},
	timestamp = {Thu, 03 Aug 2023 15:52:36 +0200},
	biburl = {https://dblp.org/rec/conf/icde/KesavanGTSM23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The recent years have seen an explosive growth in web and mobile application development. Such applications typically have rapid development cycles, and their developers expect mobile-friendly features and serverless characteristics such as rapid deployment capabilities (with minimal initialization), scalability to handle workload spikes, and flexible pay-as-you-go billing. Google’s Firestore is a NoSQL serverless database with real-time notification capability, and together with the Firebase ecosystem greatly simplifies common app development challenges by letting application developers focus primarily on their business logic and user experience. This paper presents the Firestore architecture, how it satisfies the aforementioned requirements, and how its real-time notification system works in tandem with Firebase client libraries to allow mobile applications to provide a smooth user experience even in the presence of network connectivity issues.}
}


@inproceedings{DBLP:conf/icde/ChenH0LQSYM23,
	author = {Xiong{-}Hui Chen and
                  Bowei He and
                  Yang Yu and
                  Qingyang Li and
                  Zhiwei Tony Qin and
                  Wenjie Shang and
                  Jieping Ye and
                  Chen Ma},
	title = {Sim2Rec: {A} Simulator-based Decision-making Approach to Optimize
                  Real-World Long-term User Engagement in Sequential Recommender Systems},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3389--3402},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00260},
	doi = {10.1109/ICDE55515.2023.00260},
	timestamp = {Sat, 30 Sep 2023 09:44:49 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ChenH0LQSYM23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Long-term user engagement (LTE) optimization in sequential recommender systems (SRS) is shown to be suited by reinforcement learning (RL) which finds a policy to maximize long-term rewards. Meanwhile, RL has its shortcomings, particularly requiring a large number of online samples for exploration, which is risky in real-world applications. One of the appealing ways to avoid the risk is to build a simulator and learn the optimal recommendation policy in the simulator. In LTE optimization, the simulator is to simulate multiple users’ daily feedback for given recommendations. However, building a user simulator with no reality-gap, i.e., can predict user’s feedback exactly, is unrealistic because the users’ reaction patterns are complex and historical logs for each user are limited, which might mislead the simulator-based recommendation policy. In this paper, we present a practical simulator-based recommender policy training approach, Simulation-to-Recommendation (Sim2Rec) to handle the reality-gap problem for LTE optimization. Specifically, Sim2Rec introduces a simulator set to generate various possibilities of user behavior patterns, then trains an environment-parameter extractor to recognize users’ behavior patterns in the simulators. Finally, a context-aware policy is trained to make the optimal decisions on all of the variants of the users based on the inferred environment-parameters. The policy is transferable to unseen environments (e.g., the real world) directly as it has learned to recognize all various user behavior patterns and to make the correct decisions based on the inferred environment-parameters. Experiments are conducted in synthetic environments and a real-world large-scale ride-hailing platform, DidiChuxing. The results show that Sim2Rec achieves significant performance improvement, and produces robust recommendations in unseen environments.}
}


@inproceedings{DBLP:conf/icde/ZhangZZCXWWLC023,
	author = {Lei Zhang and
                  Xin Zhou and
                  Zhiwei Zeng and
                  Yiming Cao and
                  Yonghui Xu and
                  Mingliang Wang and
                  Xingyu Wu and
                  Yong Liu and
                  Lizhen Cui and
                  Zhiqi Shen},
	title = {Delivery Time Prediction Using Large-Scale Graph Structure Learning
                  Based on Quantile Regression},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3403--3416},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00261},
	doi = {10.1109/ICDE55515.2023.00261},
	timestamp = {Wed, 24 Jul 2024 07:50:46 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhangZZCXWWLC023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Predicting Estimated Time of Arrival (ETA) for packages is a critical problem in e-commerce. The prediction is often made based on spatial (sending and receiving addresses), temporal (payment time), and context (merchants) attributes. Existing methods usually formalize this task as an Origin-Destination (OD) ETA prediction problem and exploit the attribute relations with graph learning. However, most existing methods make use of fixed and manually defined graph structures, which are often not optimal for downstream ETA task and hence lead to unsatisfactory prediction results. In addition, current ETA models tend to focus on prediction accuracy without considering fulfillment rate. This may lead to a low fulfillment rate in practice, i.e., actual delivery time is much longer than estimations provided by models, which consequently exacerbates the frustrating experiences for users. To address these issues, we propose a novel Graph Structure Learning-based Quantile Regression (GSL-QR) model for e-commerce ETA prediction in this paper. Specifically, we utilize graph structure learning to dynamically update the spatial and temporal relation graphs of orders and learn optimal graph structures and graph embeddings guided by downstream ETA prediction task. To guarantee both prediction accuracy and order fulfillment rate, we design a multi-objective quantile regression in GSL-QR that can find the Pareto solution of the problem. In order to extend GSL to large-scale real-world graphs, we devise a Fast Sampling-based Graph Structure Learning (FS-GSL) method, which can significantly reduce the computational complexity of graph structure learning. Finally, we conduct comprehensive experiments on three industrial datasets collected from Alibaba e-commerce platform. The results demonstrate that the proposed model can significantly outperform baselines on both ETA prediction accuracy and order fulfillment rate.}
}


@inproceedings{DBLP:conf/icde/SangGZTLCTGZRY23,
	author = {Bo Sang and
                  Shuwei Gu and
                  Xiaojun Zhan and
                  Mingjie Tang and
                  Jian Liu and
                  Xuan Chen and
                  Jie Tan and
                  Haoyuan Ge and
                  Ke Zhang and
                  Ruoyi Ruan and
                  Wei Yan},
	title = {Cougar: {A} General Framework for Jobs Optimization In Cloud},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3417--3429},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00262},
	doi = {10.1109/ICDE55515.2023.00262},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/SangGZTLCTGZRY23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the cloud environment, different kinds of jobs (Flink, PyTorch, TensorFlow, AI-Serving) are running in the same cluster with different service-level agreements (SLA). To manage large amounts of jobs in a cloud environment efficiently, it is critical to build a system to optimize the job performance in consideration of multiple predefined objectives. For example, one kind of optimization target is improving the resource utilization of jobs, other kinds of objectives are to guarantee the system SLA (e.g., system throughput, response time, and so on). Currently, most of the existing frameworks are working on one aspect of optimization, and can not support different kinds of optimization targets via a uniform framework or system. In Antgroup, we have designed and implemented a general framework (named Cougar) to improve jobs and cluster performance to meet such requirements. Cougar provides the ability to support different optimization scenarios like the initial and runtime optimization for one job, and cross-job optimization for multiple jobs. Nowadays, Cougar has widely used in the production environment of Antgroup including 110,000 jobs and 800,000 Pods daily, and has successfully improved the CPU/Memory/GPU utilization by more than 20% and performance (i.e., throughput or completion time or latency) by around 10%. In the end, we also like to share our best practice on how to tune Flink and Deep Learning Job (GPU collocate) in the production environment.}
}


@inproceedings{DBLP:conf/icde/ChuLR023,
	author = {Zhixuan Chu and
                  Ruopeng Li and
                  Stephen L. Rathbun and
                  Sheng Li},
	title = {Continual Causal Inference with Incremental Observational Data},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3430--3439},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00263},
	doi = {10.1109/ICDE55515.2023.00263},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ChuLR023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The era of big data has witnessed an increasing availability of observational data from mobile and social networking, online advertising, web mining, healthcare, education, public policy, marketing campaigns, and so on, which facilitates the development of causal effect estimation. Although significant advances have been made to overcome the challenges in the academic area, such as missing counterfactual outcomes and selection bias, they only focus on source-specific and stationary observational data, which is unrealistic in most industrial applications. In this paper, we investigate a new industrial problem of causal effect estimation from incrementally available observational data and present three new evaluation criteria accordingly, including extensibility, adaptability, and accessibility. We propose a Continual Causal Effect Representation Learning method for estimating causal effects with observational data, which are incrementally available from non-stationary data distributions. Instead of having access to all seen observational data, our method only stores a limited subset of feature representations learned from previous data. Combining selective and balanced representation learning, feature representation distillation, and feature transformation, our method achieves the continual causal effect estimation for new data without compromising the estimation capability for original data. Extensive experiments demonstrate the significance of continual causal effect estimation and the effectiveness of our method.}
}


@inproceedings{DBLP:conf/icde/JinLL0TW23,
	author = {Jipeng Jin and
                  Guangben Lu and
                  Sijia Li and
                  Xiaofeng Gao and
                  Ao Tan and
                  Lifeng Wang},
	title = {Automatic Fusion Network for Cold-start {CVR} Prediction with Explicit
                  Multi-Level Representation},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3440--3452},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00264},
	doi = {10.1109/ICDE55515.2023.00264},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/JinLL0TW23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Estimating conversion rate (CVR) accurately has been one of the most central problems in online advertising. Existing methods in production focus on learning effective interactions among features to boost the model performance. Despite great success, these methods treat all the features equally without distinction. However, different features suffer differently from cold-start issues. Tail elements in those high-cardinality features, which we denote as fine-grained features, tend to have inadequate samples and thus fail to obtain semantically meaningful embeddings. Interacting with those features leads astray and impairs the accuracy of new ads in a cold-start scenario. In this paper, we propose Automatic Fusion Network (AutoFuse) to better tackle the challenge. AutoFuse explicitly separates features into groups based on their granularity and learns multiple levels of representation conditioned on different combinations of feature groups. Concretely, AutoFuse learns an ad-level representation to depict the unique individual character and a group-level representation to portray the collective information by discarding the fine-grained features. The final robust and general ad representation is obtained by integrating these two level representations adaptively. Such a combination encompasses a wider amount of information, and thereby mitigates the cold-start issue. Extensive experiments on two industrial-scale datasets and three public datasets show that AutoFuse significantly and consistently outperforms a spectrum of competitive methods including our currently deployed model. Meanwhile, the remarkable improvement on new ads validates the effectiveness of our method in cold-start scenarios. We design AutoFuse as a generic approach and thus it can be seamlessly transferred into other domains. Our method has been deployed online to serve billions of users and ads and has achieved significant GMV gain of 2.84%.}
}


@inproceedings{DBLP:conf/icde/00070HCGYBZYSWY23,
	author = {Zhuo Chen and
                  Wen Zhang and
                  Yufeng Huang and
                  Mingyang Chen and
                  Yuxia Geng and
                  Hongtao Yu and
                  Zhen Bi and
                  Yichi Zhang and
                  Zhen Yao and
                  Wenting Song and
                  Xinliang Wu and
                  Yi Yang and
                  Mingyi Chen and
                  Zhaoyang Lian and
                  Yingying Li and
                  Lei Cheng and
                  Huajun Chen},
	title = {Tele-Knowledge Pre-training for Fault Analysis},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3453--3466},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00265},
	doi = {10.1109/ICDE55515.2023.00265},
	timestamp = {Tue, 01 Oct 2024 09:59:34 +0200},
	biburl = {https://dblp.org/rec/conf/icde/00070HCGYBZYSWY23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this work, we share our experience on tele-knowledge pre-training for fault analysis, a crucial task in telecommunication applications that requires a wide range of knowledge normally found in both machine log data and product documents. To organize this knowledge from experts uniformly, we propose to create a Tele-KG (tele-knowledge graph). Using this valuable data, we further propose a tele-domain language pre-training model TeleBERT and its knowledge-enhanced version, a tele-knowledge re-training model KTeleBERT. which includes effective prompt hints, adaptive numerical data encoding, and two knowledge injection paradigms. Concretely, our proposal includes two stages: first, pre-training TeleBERT on 20 million tele-related corpora, and then re-training it on 1 million causal and machine-related corpora to obtain KTeleBERT. Our evaluation on multiple tasks related to fault analysis in tele-applications, including root-cause analysis, event association prediction, and fault chain tracing, shows that pretraining a language model with tele-domain data is beneficial for downstream tasks. Moreover, the KTeleBERT re-training further improves the performance of task models, highlighting the effectiveness of incorporating diverse tele-knowledge into the model.}
}


@inproceedings{DBLP:conf/icde/BianJLXRSKM023,
	author = {Tian Bian and
                  Yuli Jiang and
                  Jia Li and
                  Tingyang Xu and
                  Yu Rong and
                  Yi Su and
                  Timothy C. Y. Kwok and
                  Helen Meng and
                  Hong Cheng},
	title = {Decision Support System for Chronic Diseases Based on Drug-Drug Interactions},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3467--3480},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00266},
	doi = {10.1109/ICDE55515.2023.00266},
	timestamp = {Sun, 06 Oct 2024 21:04:56 +0200},
	biburl = {https://dblp.org/rec/conf/icde/BianJLXRSKM023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Many patients with chronic diseases resort to multiple medications to relieve various symptoms, which raises concerns about the safety of multiple medication use, as severe drug-drug antagonism can lead to serious adverse effects or even death. This paper presents a Decision Support System, called DSSDDI, based on drug-drug interactions to support doctors prescribing decisions. DSSDDI contains three modules, Drug-Drug Interaction (DDI) module, Medical Decision (MD) module and Medical Support (MS) module. The DDI module learns safer and more effective drug representations from the drug-drug interactions. To capture the potential causal relationship between DDI and medication use, the MD module considers the representations of patients and drugs as context, DDI and patients’ similarity as treatment, and medication use as outcome to construct counterfactual links for the representation learning. Furthermore, the MS module provides drug candidates to doctors with explanations. Experiments on the chronic data collected from the Hong Kong Chronic Disease Study Project and a public diagnostic data MIMIC-III demonstrate that DSSDDI can be a reliable reference for doctors in terms of safety and efficiency of clinical diagnosis, with significant improvements compared to baseline methods. Source code of the proposed DSSDDI is publicly available at https://github.com/TianBian95/DSSDDI.}
}


@inproceedings{DBLP:conf/icde/ChenLLJ23,
	author = {Junlin Chen and
                  Xin Liu and
                  Weidong Liu and
                  Hai Jiang},
	title = {Two-Sided Instant Incentive Optimization under a Shared Budget in
                  Ride-Hailing Services},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3481--3493},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00267},
	doi = {10.1109/ICDE55515.2023.00267},
	timestamp = {Sat, 30 Sep 2023 09:44:49 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ChenLLJ23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Ride-hailing has become a popular service in recent years. For each ride-hailing request, after the platform determines the fare for the passenger and the commission for the driver, it is not uncommon for the platform to set aside a promotional budget and give instant incentives to both sides, that is, a discount to the passenger and a bonus to the driver, to further improve the match between the two sides. Although there is a proliferation of studies on the determination of the fare and the commission in ride-hailing services, they cannot address the instant incentive problem because their approaches do not deal with budget constraints. In this research, we investigate this two-sided instant incentive problem under a shared promotional budget, which is new to the literature. We formulate this problem as a binary integer linear programming problem, whose goal is to find the optimal incentives for both sides given predicted trip completion probabilities. We first assume that the predicted trip completion probabilities are accurate and develop a Lagrangian-dual-based approach to decompose the problem into a series of subproblems that can be efficiently solved. We then proceed to accommodate the inaccuracy in the predictions and develop a robust instant incentive optimization approach that exploits the prediction error reflected by historical data. We conduct numerical experiments using real data in the city of Nanjing from a leading ride-hailing platform in China. Results show that compared to the baseline approach: (i) Before we account for prediction inaccuracy, our solution approach can improve the number of completed requests by at most 8.30% with a decision error of 8.31%; and (ii) After we account for prediction inaccuracy, our solution approach can improve the number of completed requests by at most 9.81% while reducing the decision error to 7.03%.}
}


@inproceedings{DBLP:conf/icde/JiangZGWF023,
	author = {Meng Jiang and
                  Yang Zhang and
                  Yuan Gao and
                  Yansong Wang and
                  Fuli Feng and
                  Xiangnan He},
	title = {LightMIRM: Light Meta-learned Invariant Risk Minimization for Trustworthy
                  Loan Default Prediction},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3494--3507},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00268},
	doi = {10.1109/ICDE55515.2023.00268},
	timestamp = {Mon, 19 Aug 2024 14:54:52 +0200},
	biburl = {https://dblp.org/rec/conf/icde/JiangZGWF023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Machine learning models are increasingly applied to loan default prediction to reduce the labor cost of financial institutions and the waiting time of lenders. We find that existing loan default prediction models remain lack minimax fairness, i.e., encountering significant performance drops on underrepresented subpopulations. The main cause of this trustworthy issue is pursuing Empirical Risk Minimization over the whole population, which will overlook the underrepresented subpopulations. To tackle this issue, we split the training data into subpopulations (a.k.a. environments) and conduct Invariant Risk Minimization (IRM) to learn the optimal prediction model across environments. A technical challenge is the computation cost of directly using existing IRM methods suitable for loan default prediction, such as meta-IRM, which quadratically increases as the number of environments. To reduce the complexity in training, we propose a light meta-IRM method which reduces time complexity to be linear through environment sampling and loss replaying strategies. We apply the light meta-IRM to train a representative loan default prediction model and conduct both online and offline evaluations on a large auto loan platform. Extensive experiment results validate the advantage of the proposed light meta-IRM w.r.t. the overall accuracy, minimax fairness, and training cost.}
}


@inproceedings{DBLP:conf/icde/BarryMBWMHCJSFD23,
	author = {Mariam Barry and
                  Jacob Montiel and
                  Albert Bifet and
                  Sameer Wadkar and
                  Nikolay Manchev and
                  Max Halford and
                  Raja Chiky and
                  Saad El Jaouhari and
                  Katherine B. Shakman and
                  Joudi Al Fehaily and
                  Fabrice Le Deit and
                  Vinh{-}Thuy Tran and
                  Eric Guerizec},
	title = {StreamMLOps: Operationalizing Online Learning for Big Data Streaming
                  {\&} Real-Time Applications},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3508--3521},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00272},
	doi = {10.1109/ICDE55515.2023.00272},
	timestamp = {Sun, 06 Oct 2024 21:04:56 +0200},
	biburl = {https://dblp.org/rec/conf/icde/BarryMBWMHCJSFD23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Continuously learning and serving from evolving streaming data and serving in real-time is a challenging problem. Traditionally, data is partitioned and processed in batches to train machine learning (ML) models. In industrial applications, static models’ performance drops over time (model degradation, concept drift), requiring new models to be trained with recent data and redeployed in production. The scientific community has been studying online and adaptive methods to address batch-learning limitations and continuously train AI tasks for industrial applications such as cyber-security, AIOps, anomaly scoring, and drift detection in stock markets. This paper deals with the MLOps aspects of deploying such online and dynamic models to address the requirements in the production systems for real-time applications. Our architectures - based on open-source tools such as Kafka and River - demonstrated how online learning methods could be scaled horizontally in production to meet the demands of a high-velocity streaming pipeline. We demonstrate an MLOps strategy to perform incremental learning from streaming data and continuously deploy the online learning model without pausing the inference pipeline. Indeed, the design satisfies requirements such as model versioning, monitoring, audibility and reproducibility of prediction in both a supervised and semi-supervised setting. Our experiments - for malicious URLs detection task - performed on high-dimensional and feature-evolving streaming data (more than 3 million features) establish the effectiveness and efficiency of online learning models compared to batch (static) machine learning regarding both time and space complexity. Finally, we provide some best practices on data engineering for deploying online models to process a real-time feature stream in production environments. Code is publicly available for reproducibility.}
}


@inproceedings{DBLP:conf/icde/Wang00Z23,
	author = {Hai Wang and
                  Shuai Wang and
                  Yu Yang and
                  Desheng Zhang},
	title = {{GCRL:} Efficient Delivery Area Assignment for Last-mile Logistics
                  with Group-based Cooperative Reinforcement Learning},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3522--3534},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00269},
	doi = {10.1109/ICDE55515.2023.00269},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Wang00Z23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Last-mile logistics is the final step of the delivery process from a transit station to customers. In last-mile logistics systems, a city is divided into many delivery areas for couriers to finish the parcel transition tasks. In recent years, last-mile logistics faces huge challenges in system efficiency and customer experience due to highly dynamic logistics service demand across different delivery areas. How to design a proper mechanism to improve the system efficiency and customer experience has become an important task. In this paper, we formulate the delivery area assignment problem and propose a Group-based Cooperative Reinforcement Learning (GCRL) framework to optimize the last-mile logistics system. Firstly, we design a multi-level attention mechanism to construct an optimal courier team that provides cooperative pick-up and delivery services. Secondly, A graph generator and graph-based strategy are proposed to represent the decision dependency and coordinate the dependent behaviors among couriers, respectively. Finally, we design a simultaneous training mechanism to maximize the discounted return and guide the delivery area for each courier. Being formulated in a multi-agent way, GCRL focuses on the cooperation among couriers while considering the system context and couriers’ preferences. Experiments on real-world data show that GCRL achieves an average of 12% improvements compared with state-of-the-art models.}
}


@inproceedings{DBLP:conf/icde/Li00HGDDL23,
	author = {Meng Li and
                  Jun Zhou and
                  Lu Yu and
                  Xiaoguang Huang and
                  Yongfeng Gu and
                  Yi Ding and
                  Hao Ding and
                  Longfei Li},
	title = {A Rule-based Decision System for Financial Applications},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3535--3548},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00270},
	doi = {10.1109/ICDE55515.2023.00270},
	timestamp = {Wed, 24 Jul 2024 07:51:33 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Li00HGDDL23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Decision rules have been widely applied in industrial applications such as finance, medicine, and biology, due to the critical requirement of interpretability. In order to make decision rules easier and more widely used in financial scenarios, an automatic intelligent rule system with rule learning and rule management capabilities is needed. However, the rule system for financial applications has distinctive challenges both in algorithms and systems. From the algorithm perspective, due to the characteristics of the financial data and scenarios, the rule learning algorithm faces the class-imbalanced issue, the scalability issue, and the diversity of optimization objectives. From the system perspective, a flexible rule learning and management framework is needed to adapt to fast-changing financial applications with heterogenous data, and engineering optimization is required to ensure the time and space efficiency of rule learning. In this work, we focus on developing a Rule-based Decision System (RDS) to deal with the algorithmic and systematic challenges mentioned above. RDS covers the full life cycle of the decision rules, including the rule learning module, rule management module, and rule deployment module. Moreover, the rule system offers an interactive interface to allow users to integrate the expert experiences into the decision rules and realize the human-in-the-loop. The RDS has been deployed on one of the world’s largest trading and money transfer platforms, serving hundreds of millions of users and transactions.}
}


@inproceedings{DBLP:conf/icde/DuLGJWZHJH23,
	author = {Boya Du and
                  Shaochuan Lin and
                  Jiong Gao and
                  Xiyu Ji and
                  Mengya Wang and
                  Taotao Zhou and
                  Hengxu He and
                  Jia Jia and
                  Ning Hu},
	title = {{BASM:} {A} Bottom-up Adaptive Spatiotemporal Model for Online Food
                  Ordering Service},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3549--3562},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00271},
	doi = {10.1109/ICDE55515.2023.00271},
	timestamp = {Thu, 02 Nov 2023 17:35:44 +0100},
	biburl = {https://dblp.org/rec/conf/icde/DuLGJWZHJH23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Online Food Ordering Service (OFOS) is a popular location-based service that helps people order what they want. Compared with traditional e-commerce recommendation systems, users’ interests may be diverse under different spatiotemporal contexts, leading to various spatiotemporal data distributions, which increases the difficulty of model learning. However, numerous current works simply mix all samples to train a set of model parameters, which makes it challenging to capture the diversity in different spatiotemporal contexts. Therefore, we address this challenge by proposing a Bottom-up Adaptive Spatiotemporal Model(BASM) to adaptively fit the spatiotemporal data distribution, further improving the fitting capability of the model. Specifically, a spatiotemporal-aware embedding layer performs weight adaptation on field granularity in feature embedding to achieve the purpose of dynamically perceiving spatiotemporal contexts. Meanwhile, we propose a spatiotemporal semantic transformation layer to explicitly convert the concatenated input of the raw semantic to the spatiotemporal semantic, which can further enhance the semantic representation under different spatiotemporal contexts. Furthermore, we introduce a novel spatiotemporal adaptive bias tower to capture diverse spatiotemporal bias, reducing the difficulty of modeling spatiotemporal distinction. To further verify the effectiveness of BASM, we propose two new metrics, Time-period-wise AUC (TAUC) and City-wise AUC (CAUC). Extensive offline evaluations on public and industrial datasets are conducted to demonstrate the effectiveness of our proposed model. The online A/B experiment also further illustrates the practicability of the model online service. This proposed method has now been implemented on Ele.me, a major online food ordering platform in China, serving more than 100 million online users.}
}


@inproceedings{DBLP:conf/icde/KimuraHKKG23a,
	author = {Genki Kimura and
                  Yuto Hayamizu and
                  Rage Uday Kiran and
                  Masaru Kitsuregawa and
                  Kazuo Goda},
	title = {Efficient Parallel Mining of High-utility Itemsets on Multicore Processors},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3563--3577},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00384},
	doi = {10.1109/ICDE55515.2023.00384},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/KimuraHKKG23a.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {High-utility itemset mining is a generalized problem of well-known frequent itemset mining, which considers not only the frequency of occurrence but also quantitative criteria such as unit profit. Because it can be applied to a wider spectrum of knowledge discovery work, various algorithmic improvements have been studied over the past two decades. On the other hand, limited efforts have been made to take advantage of hardware performance despite significant changes in hardware trends. This paper presents a novel parallelization method called DPHIM (Dynamic Parallelization for High-utility Itemset Mining). DPHIM dynamically decomposes the execution of high-utility itemset mining into subtasks in order to leverage logical data parallelism, and carefully assigns the subtasks and their related data to physical resources such as processing cores and nearby memory in the NUMA-aware manner. Our intensive and extensive experiments have confirmed that DPHIM performs up to 65.23 times faster than the fully-tuned serial execution, up to 23.54 times faster than static partitioning, and up to 2.51 times faster than the best case of alternative dynamic parallel executions for a variety of datasets and configurations on DRAM. As well, we have demonstrated that DPHIM effectively worked on persistent memory; it offered similar thread scalability trends and was 1.07 to 2.43 times slower on persistent memory.}
}


@inproceedings{DBLP:conf/icde/SarkarDA23,
	author = {Subhadeep Sarkar and
                  Niv Dayan and
                  Manos Athanassoulis},
	title = {The {LSM} Design Space and its Read Optimizations},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3578--3584},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00273},
	doi = {10.1109/ICDE55515.2023.00273},
	timestamp = {Sun, 12 Nov 2023 02:08:10 +0100},
	biburl = {https://dblp.org/rec/conf/icde/SarkarDA23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Log-structured merge (LSM) trees have emerged as one of the most commonly used storage-based data structures in modern data systems as they offer high throughput for writes and good utilization of storage space. However, LSM-trees were not originally designed to facilitate efficient reads. Thus, state-of-the-art LSM engines employ numerous optimization techniques to make reads efficient. The goal of this tutorial is to present the fundamental principles of the LSM paradigm along with the various optimization techniques and hybrid designs adopted by LSM engines to accelerate reads.Toward this, we first discuss the basic LSM operations and their access patterns. We then discuss techniques and designs that optimize point and range lookups in LSM-trees: (i) index and (ii) filter data structures, (iii) caching, and (iv) read-friendly data layouts. Next, we present the performance tradeoff between writes and reads, outlining the rich design space of the LSM paradigm and how one can navigate it to improve query performance. We conclude by discussing practical problems and open research challenges. This will be a 1.5-hour tutorial.}
}


@inproceedings{DBLP:conf/icde/SanghiH23,
	author = {Anupam Sanghi and
                  Jayant R. Haritsa},
	title = {Synthetic Data Generation for Enterprise {DBMS}},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3585--3588},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00274},
	doi = {10.1109/ICDE55515.2023.00274},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/SanghiH23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A critical need for enterprise DBMS vendors is to generate synthetic databases for testing their engines and applications in a range of environments. These synthetic databases are targeted toward capturing the desired schematic properties, and the statistical profiles of the data hosted on these schemas.Several data generation frameworks have been proposed for OLAP over the past three decades. The early efforts focused on ab initio generation based on standard mathematical distributions. Subsequently, there was a shift to database-dependent regeneration, which aims to create a database with similar statistical properties to a specific client database. This client-specific perspective has been taken further in recent times through workload-dependent database regeneration, where the databases generated ensure similar query executions to those observed at the client site.In this tutorial, we present a holistic coverage of synthetic data generation, highlighting the strengths and limitations of the above-mentioned framework classes. At the end, a suite of open technical problems and future research directions are enumerated.}
}


@inproceedings{DBLP:conf/icde/LiTL23,
	author = {Cheng{-}Te Li and
                  Yu{-}Che Tsai and
                  Jay Chiehen Liao},
	title = {Graph Neural Networks for Tabular Data Learning},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3589--3592},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00275},
	doi = {10.1109/ICDE55515.2023.00275},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LiTL23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Deep learning-based approaches to Tabular Data Learning (TDL) have shown promising performance compared to their conventional counterparts. However, these methods often fail to account for the latent correlation among data instances and feature values. Recently, graph neural networks (GNNs) have gained attention across various application domains, including TDL, for their ability to model relations and interactions between different data entities. By creating appropriate graph structures from the input tabular data and employing GNNs for learning, the performance of TDL can be improved significantly. In this tutorial, we systematically introduce the methodologies of designing and applying GNNs to TDL. Our discussion covers the foundations and overview of GNN-based TDL methods, with a focus on formulating TDL as different graph structures. We also provide a comprehensive taxonomy of constructing graph structures and representation learning in GNN-based TDL methods. We describe the TDL model training framework, which includes different auxiliary tasks and supports open-world learning. Additionally, we discuss how to apply GNNs to various TDL application scenarios and tasks. Finally, we outline the limitations of current research and future directions for this field.}
}


@inproceedings{DBLP:conf/icde/FoufoulasS23,
	author = {Yannis Foufoulas and
                  Alkis Simitsis},
	title = {User-Defined Functions in Modern Data Engines},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3593--3598},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00276},
	doi = {10.1109/ICDE55515.2023.00276},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/FoufoulasS23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Modern data management applications involve complex processing tasks over large volumes of data. Although this falls naturally within the scope of relational databases, many such tasks cannot be expressed in SQL and require additional expressive power achieved via user-defined functions (UDFs). However, efficient processing of UDFs in data engines hinge on dealing with the impedance mismatch between UDF execution and SQL processing. In recent years, the problem of efficient UDF execution in modern data engines has gained significant traction. In this tutorial, we present recent advancements in this area, involving a broad scope of solutions ranging from algebraic, cost-based optimization to low level, physical query optimization, compilation, and execution. We also describe limitations and open issues, and discuss promising future research directions.}
}


@inproceedings{DBLP:conf/icde/ChaoCK23,
	author = {Daren Chao and
                  Kaiwen Chen and
                  Nick Koudas},
	title = {{SVQ-ACT:} Querying for Actions over Videos},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3599--3602},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00277},
	doi = {10.1109/ICDE55515.2023.00277},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ChaoCK23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We present SVQ-ACT, a system capable of evaluating declarative action and object queries over input videos. Our approach is independent of the underlying object and action detection models utilized. Users may issue queries involving action and specific objects (e.g., a human riding a bicycle, close to a traffic light and a car left of the bicycle) and identify video clips that satisfy query constraints. Our system is capable of operating in two main settings, namely online and offline. In the online setting, the user specifies a video source (e.g., a surveillance video) and a declarative query containing an action and object predicates. Our system will identify and label in real-time all frame sequences that match the query. In the offline mode, the system accepts a video repository as input, preprocesses all the video in an offline manner and extracts suitable metadata. Following this step, users can execute any query they wish interactively on the video repository (containing actions and objects supported by the underlying detection models) to identify sequences of frames from videos that satisfy the query. In this case, to limit the number of results produced, we introduce novel result ranking algorithms that can produce the k most relevant results efficiently.We demonstrate that SVQ-ACT can correctly capture the desired query semantics and execute queries efficiently and correctly, delivering a high degree of accuracy.}
}


@inproceedings{DBLP:conf/icde/FanRHWZL23,
	author = {Yuankai Fan and
                  Tonghui Ren and
                  Zhenying He and
                  X. Sean Wang and
                  Ye Zhang and
                  Xingang Li},
	title = {GenSql: {A} Generative Natural Language Interface to Database Systems},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3603--3606},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00278},
	doi = {10.1109/ICDE55515.2023.00278},
	timestamp = {Sun, 06 Oct 2024 21:04:57 +0200},
	biburl = {https://dblp.org/rec/conf/icde/FanRHWZL23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {To make databases more accessible to a much broader audience of non-technical users, many applications, such as chatbots and search engines, have developed a natural language (NL) interface for the underlying databases (NLIDB). With the advances in machine learning techniques, most recent research employs language translation models to build NLIDB systems. In this demonstration, we introduce GenSql, a generative NLIDB system that enables users to query databases using NL. Unlike most existing NLIDB systems that attempt to leverage a generalized language translation model to convert NL to SQL queries (NL2SQL) for any database, GenSql utilizes a set of sample queries to capture the specific structure and semantics of a given database and thus to provide more accurate translation results. The underlying NL2SQL model in GenSql is a novel generate-and-rank model named Gar designed by the authors, which first generates a set of generalized SQL queries with corresponding NL expressions from the given sample queries, and ranks the NL expressions to get the best matching one, and hence the SQL query. This demonstration shows the effectiveness of GenSql, especially in answering complex queries, which proves its utility in practice.}
}


@inproceedings{DBLP:conf/icde/BrahmanageKZ23,
	author = {Janaka Chathuranga Brahmanage and
                  Thivya Kandappu and
                  Baihua Zheng},
	title = {MetroWatch: {A} Predictive System to Estimate Travel Attributes Using
                  Smart Card Data},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3607--3610},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00279},
	doi = {10.1109/ICDE55515.2023.00279},
	timestamp = {Sat, 30 Sep 2023 09:44:49 +0200},
	biburl = {https://dblp.org/rec/conf/icde/BrahmanageKZ23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this demonstration, we present a fully data driven solution to retrieve passengers’ actual paths within a metro system that are not captured by an Automated Fare Collection (AFC) system. The majority of public transit systems employ AFC systems with smart cards, which record the exact origin, destination, admission time, and exit time of each passenger’s metro trip. Our solution uses AFC data to first infer travel times and route preferences and then estimates the passengers’ travel paths for all trips to provide a statistical view of passengers’ crowdedness inside a metro network over time.}
}


@inproceedings{DBLP:conf/icde/BottoniT0MBPGT23,
	author = {Simone Bottoni and
                  Alberto Trombetta and
                  Flavio Bertini and
                  Danilo Montesi and
                  Francesca Bonin and
                  Alessandra Pascale and
                  Martin Gleize and
                  Pierpaolo Tommasi},
	title = {Graph-based Tool for Exploring PubMed Knowledge Base},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3611--3614},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00280},
	doi = {10.1109/ICDE55515.2023.00280},
	timestamp = {Mon, 05 Feb 2024 20:31:13 +0100},
	biburl = {https://dblp.org/rec/conf/icde/BottoniT0MBPGT23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Studies have shown that data retrieval and visualization tools can help health professionals to improve their understanding and communication with patients, their relationship with stakeholders, and their decision-making process. However, not many efforts have been made in this direction. In this paper, we present a prototype system for the indexing, annotation, and visualization of the PubMed knowledge base to enable the search and retrieval of health-related evidence. The proposed tool builds and keeps updated an enriched graph based on PubMed articles associating them with concepts extracted from the Unified Medical Language System (UMLS) Metathesaurus. Moreover, it allows a full-text search and graph-based navigation and supports an overview of concepts and related publications. The proposed architecture enables scale-up thanks to its containerized nature and parallelization capabilities. The code is open-source under the Apache V2 license.}
}


@inproceedings{DBLP:conf/icde/HendersonCGMSZ23,
	author = {Connor Henderson and
                  Vincent Corvinelli and
                  Parke Godfrey and
                  Piotr Mierzejewski and
                  Jaroslaw Szlichta and
                  Calisto Zuzarte},
	title = {BLUTune: Tuning Up {IBM} Db2 with {ML}},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3615--3618},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00281},
	doi = {10.1109/ICDE55515.2023.00281},
	timestamp = {Sun, 04 Aug 2024 19:37:45 +0200},
	biburl = {https://dblp.org/rec/conf/icde/HendersonCGMSZ23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Nowadays, data systems, including IBM Db2 have dozens of knobs (configuration parameters). These knobs significantly affect the runtime of queries. We present the design of and a demonstration plan for a query-informed, efficient tuning system, BLUTune, which utilizes deep reinforcement learning to tune configurations. Using synthetic and real workloads, we demonstrate how BLUTune can help users to understand the semantics of analytical queries, including their execution plans, and interactively tune data systems to improve performance.}
}


@inproceedings{DBLP:conf/icde/HalsteadKRPB23,
	author = {Ben Halstead and
                  Yun Sing Koh and
                  Patricia Riddle and
                  Mykola Pechenizkiy and
                  Albert Bifet},
	title = {{FALL:} {A} Modular Adaptive Learning Platform for Streaming Data},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3619--3622},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00282},
	doi = {10.1109/ICDE55515.2023.00282},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/HalsteadKRPB23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A growing number of tasks require adaptive machine learning systems capable of learning continuously from incoming data and adapting to changes in their environment. In order to enable the widespread adoption of machine learning for streaming data, it is crucial that practitioners and researchers have the tools to efficiently build and evaluate adaptive learning systems. In this paper we demonstrate FALL, a Framework for Adaptive Life-long Learning, which we have developed to enable the full adaptive learning pipeline to be built using modular, reusable components, enabling users to easily and efficiently develop, implement, and evaluate state-of-the-art adaptive learning systems. Source code, documentation, and examples may be found at https://benhalstead.dev/FALL/.}
}


@inproceedings{DBLP:conf/icde/BianchiKGGKSS23,
	author = {Alexander Bianchi and
                  Reza Karegar and
                  Parke Godfrey and
                  Lukasz Golab and
                  Mehdi Kargar and
                  Divesh Srivastava and
                  Jaroslaw Szlichta},
	title = {iORDER: Mining Implicit Domain Orders},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3623--3626},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00283},
	doi = {10.1109/ICDE55515.2023.00283},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/BianchiKGGKSS23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this demonstration paper, we describe iORDER, a tool that identifies implicit domain orders in data, such as Small Medium Large. iORDER extends the machinery of order dependency discovery to identify and rank interesting orders. Using real-world data, we showcase how implicit orders help users interpret the semantics of ordered data, how to interactively validate implicit orders to aid in the discovery process, and how to apply implicit orders to applications including data profiling, data mining and knowledge bases.}
}


@inproceedings{DBLP:conf/icde/0005AS23,
	author = {Paulo Martins and
                  Ariel Afonso and
                  Altigran S. da Silva},
	title = {PyLatheDB - {A} Library for Relational Keyword Search with Support
                  to Schema References},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3627--3630},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00284},
	doi = {10.1109/ICDE55515.2023.00284},
	timestamp = {Sat, 30 Sep 2023 09:44:49 +0200},
	biburl = {https://dblp.org/rec/conf/icde/0005AS23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Relational Keyword Search (R-KwS) systems enable naive/informal users to explore and retrieve information from relational databases without knowing schema details or query languages. These systems take the keywords from the input query, locate the elements of the target database that correspond to these keywords, and look for ways to "connect" these elements using the information on key/foreign key pairs. Although several such systems have been proposed, most of them only support queries whose keywords refer to the contents of the target database and only a few support queries in which keywords may also refer to elements of the database schema. We showcase PyLatheDB, a Python library for Relational Keyword Search with Support to Schema References. PyLatheDB is based on Lathe, an R-KwS framework that generalizes the well-known concepts of Query Matches (QMs) and Candidate Joining Networks (CJNs) to handle keywords referring to schema elements and introduces new algorithms to generate them. Lathe also introduced a novel approach to automatically select the CJNs that are more likely to represent the user intent when issuing a keyword query. This approach includes two major innovations: a ranking algorithm for selecting better QMs, yielding the generation of fewer but better CJNs, and an eager evaluation strategy for pruning useless CJNs. We demonstrate through a Jupyter 1 notebook the functioning of PyLatheDB for two representative application scenarios, showing each step of the keyword query processing. The users can interact with the notebook by running keyword queries and experimenting with configuration parameters to see how they affect the results. The notebook, a video, and the code of PyLatheDB are available at https://github.com/pr3martins/PyLatheDB.}
}


@inproceedings{DBLP:conf/icde/RorsethGGKSS23,
	author = {Joel Rorseth and
                  Parke Godfrey and
                  Lukasz Golab and
                  Mehdi Kargar and
                  Divesh Srivastava and
                  Jaroslaw Szlichta},
	title = {{CREDENCE:} Counterfactual Explanations for Document Ranking},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3631--3634},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00285},
	doi = {10.1109/ICDE55515.2023.00285},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/RorsethGGKSS23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Towards better explainability in the field of information retrieval, we present CREDENCE, an interactive tool capable of generating counterfactual explanations for document rankers. Embracing the unique properties of the ranking problem, we present counterfactual explanations in terms of document perturbations, query perturbations, and even other documents. Additionally, users may build and test their own perturbations, and extract insights about their query, documents, and ranker.}
}


@inproceedings{DBLP:conf/icde/YewLML23,
	author = {Jun Xuan Yew and
                  Ningyi Liao and
                  Dingheng Mo and
                  Siqiang Luo},
	title = {Example Searcher: {A} Spatial Query System via Example},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3635--3638},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00286},
	doi = {10.1109/ICDE55515.2023.00286},
	timestamp = {Sun, 04 Aug 2024 19:37:45 +0200},
	biburl = {https://dblp.org/rec/conf/icde/YewLML23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Location search in spatial services such as online maps nowadays is usually based on criteria filtering methods. Due to its algorithmic design, the traditional method only searches for one target location per query, ignoring the relation among multiple objects. In large-scale tasks of finding a number of targets, it is particularly inconvenient as users are required to specify each criterion. To address this issue, we present Example Searcher, a system that allows users to search more efficiently in such tasks. Example Searcher adopts a novel way of location search that allows rich and interactive user inputs and searches for multiple target locations simultaneously. The system is powered by the state-of-the-art spatial search algorithm LORA, which efficiently performs spatial queries and searches for a set of locations that are similar to the given input examples as a whole. An introduction video of Example Searcher is available at: https://sites.google.com/view/examplesearcher.}
}


@inproceedings{DBLP:conf/icde/LeY0023,
	author = {Thai Le and
                  Yiran Ye and
                  Yifan Hu and
                  Dongwon Lee},
	title = {CrypText: Database and Interactive Toolkit of Human-Written Text Perturbations
                  in the Wild},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3639--3642},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00287},
	doi = {10.1109/ICDE55515.2023.00287},
	timestamp = {Tue, 07 May 2024 20:05:36 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LeY0023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {User-generated textual contents on the Internet are often noisy, erroneous, and not in correct grammar. In fact, some online users choose to express their opinions online through carefully perturbed texts, especially in controversial topics (e.g., politics, vaccine mandate) or abusive contexts (e.g., cyberbullying, hate-speech). However, to the best of our knowledge, there is no framework that explores these online "human-written" perturbations (as opposed to algorithm-generated perturbations). Therefore, we introduce an interactive system called CrypText. CrypText is a data-intensive application that provides the users with a database and several tools to extract and interact with human-written perturbations. Specifically, CrypText helps look up, perturb, and normalize (i.e., de-perturb) texts. CrypText also provides an interactive interface to monitor and analyze text perturbations online. The demo is available at: https://lethaiq.github.io/anthro.}
}


@inproceedings{DBLP:conf/icde/Zhang0LWC23,
	author = {Qinglong Zhang and
                  Rui Han and
                  Chi Harold Liu and
                  Guoren Wang and
                  Lydia Y. Chen},
	title = {EdgeVisionBench: {A} Benchmark of Evolving Input Domains for Vision
                  Applications at Edge},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3643--3646},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00288},
	doi = {10.1109/ICDE55515.2023.00288},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Zhang0LWC23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Vision applications powered by deep neural networks (DNNs) are widely deployed on edge devices and solve the learning tasks of incoming data streams whose class label and input feature continuously evolve, known as domain shift. Despite its prominent presence in real-world edge scenarios, existing benchmarks used by domain adaptation methods overlook evolving domains and under represent their shifts in label and feature distributions. To address this gap, we present EdgeVisionBench, a benchmark seeking to generate evolving domains of various types and reflect their realistic label and feature shifts encountered by edge-based vision applications. To facilitate evaluating domain adaptation methods on edge devices, we provide an open-source package that automates workload generation, contains popular DNN models and compression techniques, and standardizes evaluations with interactive interfaces. Code and datasets are available at https://github.com/LINC-BIT/EdgeVisionBench.}
}


@inproceedings{DBLP:conf/icde/RathS23,
	author = {Timo R{\"{a}}th and
                  Kai{-}Uwe Sattler},
	title = {Traveling Back in Time: {A} Visual Debugger for Stream Processing
                  Applications},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3647--3650},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00289},
	doi = {10.1109/ICDE55515.2023.00289},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/RathS23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Stream processing takes on an important role as a hot topic of our time. More and more applications generate large amounts of heterogeneous data that need to be processed in real-time. However, the dynamic and high frequent nature of stream processing applications complicates the debugging process since the constant flow of data can not be slowed down, paused, or reverted to previous states to analyze the execution step-by-step. In this demonstration, we present StreamVizzard’s visual and interactive pipeline debugger that allows reverting the pipeline state to any arbitrary point in the past to review or repeat critical parts of the pipeline step by step. During this process, our extensive visualizer allows to explore the processed data and statistics of each operator to retrace and understand the data flow and behavior of the pipeline.}
}


@inproceedings{DBLP:conf/icde/WuMLHYY23,
	author = {Yangyang Wu and
                  Xiaoye Miao and
                  Zilinghan Li and
                  Shilan He and
                  Xinkai Yuan and
                  Jianwei Yin},
	title = {An Efficient Generative Data Imputation Toolbox with Adversarial Learning},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3651--3654},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00290},
	doi = {10.1109/ICDE55515.2023.00290},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/WuMLHYY23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The dramatically increasing volume of incomplete data makes the imputation models computationally infeasible in many real-life applications. In this demonstration, we propose a scalable and extendible data imputation toolbox, SEMI, to deal with large-scale incomplete data imputation efficiently and visually. SEMI consists of three modules: data preprocessing, data imputation, and post-imputation prediction. It is built upon SCIS, a scalable imputation system, to significantly speed up the training of generative adversarial imputation models under accuracy-guarantees for large-scale incomplete data. Using a public real-world large-scale incomplete weather dataset, we demonstrate that, SEMI is capable of assisting users to efficiently address real-life large-scale imputation issues, from the aspects of high-efficient imputation system, user-friendly performance visualization, and easy-to-use interaction operation.}
}


@inproceedings{DBLP:conf/icde/AdamakisBBMGS23,
	author = {Emmanouil Adamakis and
                  Michael Boch and
                  Alexandros Bampoulidis and
                  George Margetis and
                  Stefan Gindl and
                  Constantine Stephanidis},
	title = {DaRAV: {A} Tool for Visualizing De-Anonymization Risks},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3655--3658},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00291},
	doi = {10.1109/ICDE55515.2023.00291},
	timestamp = {Fri, 22 Mar 2024 08:49:30 +0100},
	biburl = {https://dblp.org/rec/conf/icde/AdamakisBBMGS23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Personal data is any information that relates to an individual. Before disclosing such data to third parties, data controllers must be aware of the de-anonymization risks associated with their datasets and take appropriate anonymization measures. To carry out such actions, data controllers require tools that can analyze the risks in their datasets while also providing the necessary anonymization methods for addressing those risks. Existing tools of this type are insufficient for handling high-dimensional data as well as visualizing their risks. In this paper, we demonstrate DaRAV (De-anonymization Risk Analysis through Visualizations), a tool that addresses these limitations by providing risk analysis methods for five types of complex, high-dimensional data through interactive visualizations, as well as anonymization methods that allow users to create anonymized versions of their data.}
}


@inproceedings{DBLP:conf/icde/NegiBAKLGI23,
	author = {Parimarjan Negi and
                  Laurent Bindschaedler and
                  Mohammad Alizadeh and
                  Tim Kraska and
                  Jyoti Leeka and
                  Anja Gruenheid and
                  Matteo Interlandi},
	title = {Unshackling Database Benchmarking from Synthetic Workloads},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3659--3662},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00292},
	doi = {10.1109/ICDE55515.2023.00292},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/NegiBAKLGI23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Introducing new (learned) features into a DBMS requires considerable experimentation and benchmarking to avoid regressions in production (customer) workloads. Using standard benchmarks such as TPC-H and TCH-DS is common practice, but, unfortunately, these do not represent the complexity of real production workloads. To solve this problem, in this demo, we propose a technique that generates a synthetic dataset from query logs and metadata—without touching the original data. The keystone of our approach is to map the data generation as a SAT problem where constraints, such as runtime cardinalities, are extracted from query logs and metadata. We show that our approach can generate representative benchmarks mirroring the performance of the original data without trading off privacy. The demo will guide the attendees through the various steps involved in the data generation and testing process.}
}


@inproceedings{DBLP:conf/icde/ShenHGGGRS23,
	author = {Fangzhu Shen and
                  Kayvon Heravi and
                  Oscar Gomez and
                  Sainyam Galhotra and
                  Amir Gilad and
                  Sudeepa Roy and
                  Babak Salimi},
	title = {Causal What-If and How-To Analysis Using HypeR},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3663--3666},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00293},
	doi = {10.1109/ICDE55515.2023.00293},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ShenHGGGRS23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {What-if and How-to queries are fundamental data analysis questions that provide insights about the effects of a hypothetical update without actually making changes to the database. Traditional systems assume independence across differ¬ent tuples and non-updated attributes of the database. However, different attributes and tuples are generally dependent in real-world scenarios. We propose to demonstrate HypeR, a novel system to efficiently answer what-if and how-to queries while capturing causal dependencies among different attributes and tuples in the database. To compute the results, HypeR leverages a suite of optimizations along with techniques from causal inference to effectively estimate the answers. HypeR allows users to formulate complex hypothetical queries by using a novel SQL-like syntax and presents the output as interactive visualizations that can be explored and analyzed with ease.}
}


@inproceedings{DBLP:conf/icde/PappachanMQSO23,
	author = {Primal Pappachan and
                  Vishnu Sharma Hunsur Manjunath and
                  Chenxi Qiu and
                  Anna Cinzia Squicciarini and
                  Hailey Onweller},
	title = {{CORGI:} An interactive framework for Customizable and Robust Location
                  Obfuscation},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3667--3670},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00294},
	doi = {10.1109/ICDE55515.2023.00294},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/PappachanMQSO23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Customizing the location obfuscation functions generated by existing systems can result in weakening the privacy guarantees offered by these functions as they are not robust against such updates. In this demo, we present a new framework called, CORGI, i.e., CustOmizable Robust Geo Indistinguishability. The demonstration platform is a web application which is built on top on a real world dataset (Gowalla). The user-friendly interface of the demo allows participants to easily specify their customization preferences and generate a customizable and robust location obfuscation function. They can also examine the trade-offs among privacy, utility, and customization; visualized on a map for comparison between CORGI and a state of the art baseline.}
}


@inproceedings{DBLP:conf/icde/ZhuWXWJWMZ23,
	author = {Xinyi Zhu and
                  Liping Wang and
                  Hao Xin and
                  Xiaohan Wang and
                  Zhifeng Jia and
                  Jiyao Wang and
                  Chunming Ma and
                  Yuxiang Zengt},
	title = {T-FinKB: {A} Platform of Temporal Financial Knowledge Base Construction},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3671--3674},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00295},
	doi = {10.1109/ICDE55515.2023.00295},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhuWXWJWMZ23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent years, domain-specific knowledge bases (KBs) have attracted more attention in academics and industry because of their expertise and in-depth representation in a specific domain. However, when constructing a domain-specific KB, one needs to address not only the challenges in constructing a general KB, but also the difficulties raised by the nature of domain-specific raw data. Considering the usability of financial Knowledge Bases (KBs) in many downstream applications, such as financial risk analysis and fraud detection, we aim to build a Temporal Financial KB. However, the complex, time-varying financial knowledge and the volatile financial market evolution make construction quite challenging. Thus, we propose a Platform for Temporal Financial KB Construction, T-FinKB Platform 1 . This platform consists of three fundamental modules, i.e., evolved knowledge extraction module, temporal record linkage and conflicts resolution module, and dynamic knowledge update module designed for financial knowledge. Generated temporal financial KBs (T-FinKBs) from T-FinKB Platform can be updated automatically. T-FinKB has been successfully applied to a downstream application, stock trend prediction with backtesting evaluation. In addition, T-FinKB Platform provides several APIs for visualization, queries and analytics.}
}


@inproceedings{DBLP:conf/icde/Ooi0STTXYZ023,
	author = {Beng Chin Ooi and
                  Gang Chen and
                  Mike Zheng Shou and
                  Kian{-}Lee Tan and
                  Anthony K. H. Tung and
                  Xiaokui Xiao and
                  James Wei Luen Yip and
                  Bingxue Zhang and
                  Meihui Zhang},
	title = {The Metaverse Data Deluge: What Can We Do About It?},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3675--3687},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00296},
	doi = {10.1109/ICDE55515.2023.00296},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Ooi0STTXYZ023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the metaverse the physical space and the virtual space co-exist, and interact simultaneously. While the physical space is virtually enhanced with information, the virtual space is continuously refreshed with real-time, real-world information. To allow users to process and manipulate information seamlessly between the real and digital spaces, novel technologies must be developed. These include smart interfaces, new augmented realities, and efficient data storage, management, and dissemination techniques. In this paper, we first discuss some promising co-space applications. These applications offer opportunities that neither of the spaces can realize on its own. We then discuss challenges. Finally, we discuss and envision what are likely to be required from the database and system perspectives.}
}


@inproceedings{DBLP:conf/icde/PaponMRHSD0A23,
	author = {Tarikul Islam Papon and
                  Ju Hyoung Mun and
                  Shahin Roozkhosh and
                  Denis Hoornaert and
                  Ahmed Sanaullah and
                  Ulrich Drepper and
                  Renato Mancuso and
                  Manos Athanassoulis},
	title = {Relational Fabric: Transparent Data Transformation},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3688--3698},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00297},
	doi = {10.1109/ICDE55515.2023.00297},
	timestamp = {Sun, 12 Nov 2023 02:08:10 +0100},
	biburl = {https://dblp.org/rec/conf/icde/PaponMRHSD0A23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A key design decision for data systems is whether they follow the row-store or the column-store paradigm. The former supports transactional workloads, while the latter is better for analytical queries. This decision has a significant impact on the entire data system architecture. The multiple-decade-long journey of these two designs has led to a new family of hybrid transactional/analytical processing (HTAP) architectures. Several efforts have been proposed to reap the benefits of both worlds by proposing systems that maintain multiple copies of data (in different physical layouts) and convert them into the desired layout as required. Due to data duplication, the additional necessary bookkeeping, and the cost of converting data between different layouts, these systems compromise between efficient analytics and data freshness. We depart from existing designs by proposing a radically new approach. We ask the question:"What if we could access any layout and ship only the relevant data through the memory hierarchy by transparently converting rows to (arbitrary groups of) columns?".To achieve this functionality, we capitalize on the reinvigorated trend of hardware specialization (that has been accelerated due to the tapering of Moore\'s law) to propose Relational Fabric, a near-data vertical partitioner that allows memory or storage components to perform on-the-fly transparent data transformation. By exposing an intuitive API, Relational Fabric pushes vertical partitioning to the hardware, which profoundly impacts the process of designing and building data systems. (A) There is no need for data duplication and layout conversion, making HTAP systems viable using a single layout. (B) It simplifies the memory and storage manager that needs to maintain and update a single data layout. (C) It reduces unnecessary data movement through the memory hierarchy allowing for better hardware utilization and, ultimately, better performance. In this paper, we present Relational Fabric for both memory and storage. We present our initial results on Relational Fabric for in-memory systems and discuss the challenges of building this hardware and the opportunities it brings for simplicity and innovation in the data system software stack, including physical design, query optimization, query evaluation, and concurrency control.}
}


@inproceedings{DBLP:conf/icde/SancaA23,
	author = {Viktor Sanca and
                  Anastasia Ailamaki},
	title = {Analytical Engines With Context-Rich Processing: Towards Efficient
                  Next-Generation Analytics},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3699--3707},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00298},
	doi = {10.1109/ICDE55515.2023.00298},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/SancaA23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As modern data pipelines continue to collect, produce, and store a variety of data formats, extracting and combining value from traditional and context-rich sources such as strings, text, video, audio, and logs becomes a manual process where such formats are unsuitable for RDBMS. To tap into the dark data, domain experts analyze and extract insights and integrate them into the data repositories. This process can involve out-of-DBMS, ad-hoc analysis, and processing resulting in ETL, engineering effort, and suboptimal performance. While AI systems based on ML models can automate the analysis process, they often further generate context-rich answers. Using multiple sources of truth, for either training the models or in the form of knowledge bases, further exacerbates the problem of consolidating the data of interest.We envision an analytical engine co-optimized with components that enable context-rich analysis. Firstly, as the data from different sources or resulting from model answering cannot be cleaned ahead of time, we propose using online data integration via model-assisted similarity operations. Secondly, we aim for a holistic pipeline cost- and rule-based optimization across relational and model-based operators. Thirdly, with increasingly heterogeneous hardware and equally heterogeneous workloads ranging from traditional relational analytics to generative model inference, we envision a system that just-in-time adapts to the complex analytical query requirements. To solve increasingly complex analytical problems, ML offers attractive solutions that must be combined with traditional analytical processing and benefit from decades of database community research to achieve scalability and performance effortless for the end user.}
}


@inproceedings{DBLP:conf/icde/YamadaGK23,
	author = {Hiroyuki Yamada and
                  Kazuo Goda and
                  Masaru Kitsuregawa},
	title = {Nested Loops Revisited Again},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3708--3717},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00299},
	doi = {10.1109/ICDE55515.2023.00299},
	timestamp = {Sat, 30 Sep 2023 09:44:52 +0200},
	biburl = {https://dblp.org/rec/conf/icde/YamadaGK23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Hash joins and sort-merge joins have been considered the algorithms of choice for analytical relational queries in most parallel database systems because of their performance robustness and ease of parallelization. On the other hand, nested loop joins have been considered less attractive and are conservatively used. In this paper, we revisit the potential of nested loop joins in a cluster environment. We focus on exploring the parallelism aspect of nested loop joins because there could still be space for improvement by fully exploiting the parallelism of current commodity hardware, which could handle more than thousands of concurrent IOs. We also introduce scalable massively-parallel execution as one of the approaches for achieving massive parallelism in nested loop joins to explore how it widens the potential benefit of nested loop joins. Finally, we discuss future research directions based on our exploration.}
}


@inproceedings{DBLP:conf/icde/AzcoitiaIL23,
	author = {Santiago Andr{\'{e}}s Azcoitia and
                  Costas Iordanou and
                  Nikolaos Laoutaris},
	title = {Understanding the Price of Data in Commercial Data Marketplaces},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3718--3728},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00300},
	doi = {10.1109/ICDE55515.2023.00300},
	timestamp = {Mon, 05 Feb 2024 20:31:13 +0100},
	biburl = {https://dblp.org/rec/conf/icde/AzcoitiaIL23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A large number of Data Marketplaces (DMs) have appeared in the last few years to help owners monetize their data, and data buyers optimize their marketing campaigns, train their ML models, and facilitate other data-driven decision processes. In this paper, we present a first of its kind measurement study of the growing DM ecosystem, focused on understanding which features of data are actually driving their prices in the market. We show that data products listed in commercial DMs may cost from few to hundreds of thousands of US dollars. We analyze the prices of different categories of data and show that products about telecommunications, manufacturing, automotive, and gaming command the highest prices. We also develop classifiers for comparing data products across different DMs, as well as a regression analysis for revealing features that correlate with data product prices of specific categories, such as update rate or history for financial data, and volume and geographical scope for marketing data.}
}


@inproceedings{DBLP:conf/icde/0003KILSSKK23,
	author = {Rihan Hai and
                  Christos Koutras and
                  Andra Ionescu and
                  Ziyu Li and
                  Wenbo Sun and
                  Jessie van Schijndel and
                  Yan Kang and
                  Asterios Katsifodimos},
	title = {Amalur: Data Integration Meets Machine Learning},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3729--3739},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00301},
	doi = {10.1109/ICDE55515.2023.00301},
	timestamp = {Sun, 06 Oct 2024 21:04:56 +0200},
	biburl = {https://dblp.org/rec/conf/icde/0003KILSSKK23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Machine learning (ML) training data is often scattered across disparate collections of datasets, called data silos. This fragmentation poses a major challenge for data-intensive ML applications: integrating and transforming data residing in different sources demand a lot of manual work and computational resources. With data privacy and security constraints, data often cannot leave the premises of data silos, hence model training should proceed in a decentralized manner. In this work, we present a vision of how to bridge the traditional data integration (DI) techniques with the requirements of modern machine learning. We explore the possibilities of utilizing metadata obtained from data integration processes for improving the effectiveness and efficiency of ML models. Towards this direction, we analyze two common use cases over data silos, feature augmentation and federated learning. Bringing data integration and machine learning together, we highlight new research opportunities from the aspects of systems, representations, factorized learning and federated learning.}
}


@inproceedings{DBLP:conf/icde/BonczCFHL0NSSZ23,
	author = {Peter A. Boncz and
                  Yannis Chronis and
                  Jan Finis and
                  Stefan Halfpap and
                  Viktor Leis and
                  Thomas Neumann and
                  Anisoara Nica and
                  Caetano Sauer and
                  Knut Stolze and
                  Marcin Zukowski},
	title = {{SPA:} Economical and Workload-Driven Indexing for Data Analytics
                  in the Cloud},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3740--3746},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00302},
	doi = {10.1109/ICDE55515.2023.00302},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/BonczCFHL0NSSZ23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Selective queries are not uncommon in large-scale data analytics, for example, when drilling down into a specific customer in a dashboard. Traditionally, selective queries are accelerated by creating secondary indexes. However, because of their large size, expensive maintenance, and difficulty to tune and automate, indexes are typically not used in modern cloud data warehouses or data lakes. Instead, such systems rely mostly on full table scans and lightweight optimizations like min/max filtering, whose effectiveness depends heavily on the data layout and value distributions.We propose SPA as the vision for automatically optimizing selective queries for immutable copy-on-write data formats. SPA adaptively indexes subsets of the data in an incremental and workload-driven manner. It makes fine-grained decisions and continuously monitors their benefit, dynamically allocating an optimization budget in a way that bounds the additional cost of indexing. Furthermore, it guarantees a performance improvement in the cases where indexes—potentially partial ones—prove to be beneficial. When indexes lose their benefit due to a shifting workload, they are gradually deconstructed in favor of optimizations that accommodate recent trends. As SPA does not require information about updates performed on the data, it can also be employed as an accelerator for systems that do not control the data, e.g., in cloud data lakes.}
}


@inproceedings{DBLP:conf/icde/GuhaKSS23,
	author = {Shubha Guha and
                  Falaah Arif Khan and
                  Julia Stoyanovich and
                  Sebastian Schelter},
	title = {Automated Data Cleaning Can Hurt Fairness in Machine Learning-based
                  Decision Making},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3747--3754},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00303},
	doi = {10.1109/ICDE55515.2023.00303},
	timestamp = {Sun, 12 Nov 2023 02:08:10 +0100},
	biburl = {https://dblp.org/rec/conf/icde/GuhaKSS23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we interrogate whether data quality issues track demographic characteristics such as sex, race and age, and whether automated data cleaning — of the kind commonly used in production ML systems — impacts the fairness of predictions made by these systems. To the best of our knowledge, the impact of data cleaning on fairness in downstream tasks has not been investigated in the literature.We first analyze the tuples flagged by common error detection strategies in five research datasets. We find that, while specific data quality issues, such as higher rates of missing values, are associated with membership in historically disadvantaged groups, poor data quality does not generally track demographic group membership. As a follow-up, we conduct a large-scale empirical study on the impact of automated data cleaning on fairness, involving more than 26,000 model evaluations on five datasets. We observe that, while automated data cleaning has an insignificant impact on both accuracy and fairness in the majority of cases, it is more likely to worsen fairness than to improve it, especially when the cleaning techniques are not carefully chosen. This finding is both significant and worrying, given that it potentially implicates many production ML systems. We make our code and experimental results publicly available.The analysis we conducted in this paper is difficult, primarily because it requires that we think holistically about disparities in data quality, disparities in the effectiveness of data cleaning methods, and impacts of such disparities on ML model performance for different demographic groups. Such holistic analysis can and should be supported with the help of data engineering research. Towards this goal, we envision the development of fairness-aware data cleaning methods, and their integration into complex pipelines for ML-based decision making.}
}


@inproceedings{DBLP:conf/icde/Guo0JLNW23,
	author = {Yangyang Guo and
                  Zhiyong Cheng and
                  Jiazheng Jing and
                  Yanpeng Lin and
                  Liqiang Nie and
                  Meng Wang},
	title = {Enhancing Factorization Machines with Generalized Metric Learning
                  (Extended Abstract)},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3755--3756},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00304},
	doi = {10.1109/ICDE55515.2023.00304},
	timestamp = {Tue, 23 Jul 2024 08:23:08 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Guo0JLNW23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Factorization Machines (FMs) have been proven effective in modeling the second-order interactions between attributes. Nevertheless, existing methods often fall short of learning the complex and rich intra-attribute feature interactions, which are abundantly exhibited in real-world recommendation data. To address this problem, we propose an FM framework equipped with generalized metric learning to better handle the essential feature correlations. In particular, based on this framework, we present a Mahalanobis distance and a deep neural network method, which can effectively model the linear and non-linear correlations between features, respectively. Besides, we design an efficient approach for simplifying the model functions. Experiments on several benchmark datasets demonstrate that our proposed framework outperforms several state-of-the-art baselines by a significant margin.}
}


@inproceedings{DBLP:conf/icde/WenLHX23,
	author = {Zeyi Wen and
                  Mingyu Liang and
                  Bingsheng He and
                  Zexin Xia},
	title = {A High-Performance Index for Real-Time Matrix Retrieval (Extended
                  Abstract)},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3757--3758},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00305},
	doi = {10.1109/ICDE55515.2023.00305},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/WenLHX23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Embedding techniques can be used to represent words using word embedding [1] , images using image-to-vector techniques [2] , [3] and even database queries [4] . As a result, many more real-world objects can be represented by matrices. For example, a matrix can represent a document where each row (i.e., each vector) of the matrix stands for a word in the document. Figure 1 shows the key steps of representing an object (e.g., a document, a video or an audio stream) by a matrix. The intermediate step is to divide the object into small pieces and to convert the small pieces into vectors. The vectors of the object are then put together to form a matrix. These objects represented by matrices require new data management systems to support efficient indexing and retrieval.}
}


@inproceedings{DBLP:conf/icde/LiWZMC023,
	author = {Haoyang Li and
                  Xin Wang and
                  Ziwei Zhang and
                  Jianxin Ma and
                  Peng Cui and
                  Wenwu Zhu},
	title = {Intention-aware Sequential Recommendation with Structured Intent Transition
                  : (Extended Abstract)},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3759--3760},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00306},
	doi = {10.1109/ICDE55515.2023.00306},
	timestamp = {Wed, 09 Oct 2024 07:56:56 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LiWZMC023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Human behaviors in recommendation systems are driven by many high-level, complex, and evolving intentions behind their decision making processes. In order to achieve better performance, it is important for recommendation systems to be aware of user intentions besides considering the historical interaction behaviors. However, user intentions are seldom fully or easily observed in practice, so that the existing works are incapable of fully tracking and modeling user intentions, not to mention using them effectively into recommendation. In this paper, we present the Intention-Aware Sequential Recommendation (ISRec) method, for capturing the underlying intentions of each user that may lead to her next consumption behavior and improving recommendation performance. Specifically, we first extract the intentions of the target user from sequential contexts, then take complex intent transition into account through the message-passing mechanism on an intention graph, and finally obtain the future intentions of this target user from inference on the intention graph. The sequential recommendation for a user will be made based on the predicted user intentions, offering more transparent and explainable intermediate results for each recommendation. Extensive experiments on various real-world datasets demonstrate the superiority of our method against several state-of-the-art baselines in sequential recommendation in terms of different metrics.}
}


@inproceedings{DBLP:conf/icde/BouKA23,
	author = {Savong Bou and
                  Hiroyuki Kitagawa and
                  Toshiyuki Amagasa},
	title = {CPiX: Real-Time Analytics Over Out-of-Order Data Streams by Incremental
                  Sliding-Window Aggregation},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3759--3760},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00310},
	doi = {10.1109/ICDE55515.2023.00310},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/BouKA23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Stream processing is used in various fields. In the field of big data, stream aggregation is a popular processing technique, but it suffers serious setbacks when the order of events (e.g., stream elements) occurring is different from the order of events arriving to the systems. Such data streams are called "non-FIFO steams". This phenomenon usually occurs in a distributed environment due to many factors, such as network disruptions, delays, etc. Many analyzing scenarios require efficient processing of such non-FIFO streams to meet various data processing requirements. This paper proposes an efficient scalable checkpoint-based bidirectional indexing approach, called CPiX , for faster real-time analysis over non-FIFO streams. CPiX maintains the partial aggregation results in an on-demand manner. CPiX needs less time and space than the state-of-the-art approach. Extensive experiments confirm that CPiX can deal with out-of-order streams very efficiently and is, on average, about 3.8 times faster than the state-of-the-art approach while consuming less memory. CPiX and the existing approaches support the distributive and algebraic aggregation functions, such as min, average, standard deviation, etc. Holistic aggregation is beyond the scope.}
}


@inproceedings{DBLP:conf/icde/0008L0ZZZC23,
	author = {Pei Zhang and
                  Xinwang Liu and
                  Jian Xiong and
                  Sihang Zhou and
                  Wentao Zhao and
                  En Zhu and
                  Zhiping Cai},
	title = {Consensus One-step Multi-view Subspace Clustering (Extended abstract)},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3761--3762},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00307},
	doi = {10.1109/ICDE55515.2023.00307},
	timestamp = {Fri, 16 Feb 2024 11:29:49 +0100},
	biburl = {https://dblp.org/rec/conf/icde/0008L0ZZZC23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Multi-view clustering has attracted increasing attention in data mining communities. Despite superior clustering performance, we observe that existing multi-view subspace clustering methods directly fuse multi-view information in the similarity level by merging noisy affinity matrices; and isolate the processes of affinity learning, multiple information fusion and clustering. Both factors may cause insufficient utilization of multi-view information, leading to unsatisfying clustering performance. This paper proposes a novel consensus one-step multi-view subspace clustering (COMVSC) method to address these issues. Instead of directly fusing affinity matrices, COMVSC optimally integrates discriminative partition-level information, which is helpful in eliminating noise among data. Moreover, the affinity matrices, consensus representation and final clustering labels are learned simultaneously in a unified framework. Extensive experiment results on benchmark datasets demonstrate the superiority of our method over other state-of-the-art approaches.}
}


@inproceedings{DBLP:conf/icde/WuYYZ23,
	author = {Weichang Wu and
                  Junchi Yan and
                  Xiaokang Yang and
                  Hongyuan Zha},
	title = {Discovering Temporal Patterns for Event Sequence Clustering via Policy
                  Mixture Model (Extended Abstract)},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3763--3764},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00308},
	doi = {10.1109/ICDE55515.2023.00308},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/WuYYZ23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We focus on the problem of event sequence clustering with different temporal patterns from the view of Reinforcement Learning (RL), whereby the observed sequences are assumed to be generated from a mixture of latent policies. We propose an Expectation-Maximization (EM) based algorithm to cluster the sequences with different temporal patterns into the underlying policies while simultaneously learning each of the policy model, in E-step estimating the cluster labels for each sequence, in M-step learning the respective policy. For each policy learning, we resort to Inverse Reinforcement Learning (IRL) by decomposing the observed sequence into states (hidden embedding of event history) and actions (time interval to next event) in order to learn a reward function. Experiments on synthetic and real-world datasets show the efficacy of our method against the state-of-the-arts.}
}


@inproceedings{DBLP:conf/icde/Guo0T23,
	author = {Wentian Guo and
                  Yuchen Li and
                  Kian{-}Lee Tan},
	title = {Exploiting Reuse for {GPU} Subgraph Enumeration (Extended Abstract)},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3765--3766},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00309},
	doi = {10.1109/ICDE55515.2023.00309},
	timestamp = {Mon, 05 Feb 2024 20:31:12 +0100},
	biburl = {https://dblp.org/rec/conf/icde/Guo0T23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Subgraph enumeration is important for many applications such as network motif discovery, community detection, and frequent subgraph mining. To accelerate the execution, recent works utilize graphics processing units (GPUs) to parallelize subgraph enumeration. The performances of these parallel schemes are dominated by the set intersection operations which account for up to 95% of the total processing time. (Un)surprisingly, a significant portion (as high as 99%) of these operations is actually redundant, i.e., the same set of vertices is repeatedly encountered and evaluated. Therefore, in this paper, we seek to salvage and recycle the results of such operations to avoid repeated computation. Our solution consists of two phases. In the first phase, we generate a reusable plan that determines the opportunity for reuse. The plan is based on a novel reuse discovery mechanism that can identify available results to prevent redundant computation. In the second phase, the plan is executed to produce the subgraph enumeration results. This processing is based on a newly designed reusable parallel search strategy that can efficiently maintain and retrieve the results of set intersection operations. Our implementation on GPUs shows that our approach can achieve up to 5 times speedups compared with the state-of-the-art GPU solutions.}
}


@inproceedings{DBLP:conf/icde/Wan023,
	author = {Xiaolong Wan and
                  Hongzhi Wang},
	title = {Reachability Queries with Label and Substructure Constraints on Knowledge
                  Graphs (Extended abstract)},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3769--3770},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00311},
	doi = {10.1109/ICDE55515.2023.00311},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Wan023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Since knowledge graphs (KGs) describe and model the relationships between entities and concepts in the real world, reasoning on KGs often corresponds to the r eachability queries with l abel and s ubstructure c onstraints (LSCR queries). Specifically, for a search path p , LSCR queries not only require that the labels of the edges passed by p are in a label set, but also claim that a vertex in p could satisfy a substructure constraint.}
}


@inproceedings{DBLP:conf/icde/ZhangZWLHT23,
	author = {Yifan Zhang and
                  Peilin Zhao and
                  Qingyao Wu and
                  Bin Li and
                  Junzhou Huang and
                  Mingkui Tan},
	title = {Cost-Sensitive Portfolio Selection via Deep Reinforcement Learning
                  (Extended Abstract)},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3771--3772},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00312},
	doi = {10.1109/ICDE55515.2023.00312},
	timestamp = {Thu, 18 Jul 2024 08:28:32 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhangZWLHT23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Portfolio Selection is an important real-world financial task and has attracted extensive attention in artificial intelligence communities. This task, however, has two main difficulties: (i) the non-stationary price series and complex asset correlations make the learning of feature representation very hard; (ii) the practicality principle in financial markets requires controlling both transaction and risk costs. Most existing methods adopt handcraft features and/or consider no constraints for the costs, which may make them perform unsatisfactorily and fail to control both costs in practice. In this paper, we propose a cost-sensitive portfolio selection method with deep reinforcement learning. Specifically, a novel two-stream portfolio policy network is devised to extract both price series patterns and asset correlations, while a new cost-sensitive reward function is developed to maximize the accumulated return and constrain both costs via reinforcement learning. We theoretically analyze the near-optimality of the proposed reward, which shows that the growth rate of the policy regarding this reward function can approach the theoretical optimum. We also empirically evaluate the proposed method on real-world datasets. Promising results demonstrate the effectiveness and superiority of the proposed method in terms of profitability, cost-sensitivity and representation abilities.}
}


@inproceedings{DBLP:conf/icde/GengC23,
	author = {Chuanxing Geng and
                  Songcan Chen},
	title = {Collective Decision for Open Set Recognition (Extended Abstract)},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3773--3774},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00313},
	doi = {10.1109/ICDE55515.2023.00313},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/GengC23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In open set recognition (OSR), almost all existing methods are designed specially for recognizing individual instances, even these instances are collectively coming in batch. Recognizers in decision either reject or categorize them to some known class using empirically-set threshold. Thus the decision threshold plays a key role. However, the selection for it usually depends on the knowledge of known classes, inevitably incurring risks due to lacking available information from unknown classes. On the other hand, a more realistic OSR system should NOT just rest on a reject decision but should go further, especially for discovering the hidden unknown classes among the reject instances, whereas existing OSR methods do not pay special attention. In this paper, we introduce a novel collective/batch decision strategy with an aim to extend existing OSR for new class discovery while considering correlations among the testing instances. Specifically, a collective decision-based OSR framework (CD-OSR) is proposed by slightly modifying the Hierarchical Dirichlet process (HDP). Thanks to HDP, our CD-OSR does not need to define the decision threshold and can implement the open set recognition and new class discovery simultaneously. Finally, extensive experiments on benchmark datasets indicate the validity of CD-OSR.}
}


@inproceedings{DBLP:conf/icde/LiWLS23,
	author = {Hui Li and
                  Yanlin Wang and
                  Ziyu Lyu and
                  Jieming Shi},
	title = {Multi-task Learning for Recommendation over Heterogeneous Information
                  Network (Extended abstract)},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3775--3776},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00314},
	doi = {10.1109/ICDE55515.2023.00314},
	timestamp = {Tue, 19 Dec 2023 15:15:54 +0100},
	biburl = {https://dblp.org/rec/conf/icde/LiWLS23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Heterogeneous Information Network based Recommender Systems (HIN-based RS) can model the complex interactions between different objects in RS. However, existing models assume HIN is invariable and merely use HIN as a data source for assisting recommendation. In this paper, we summarize our multi-task learning framework MTRec for recommendation over HIN. MTRec relies on the self-attention mechanism to learn the semantics of meta-paths in HIN and jointly optimizes the tasks of both recommendation and link prediction. Using a Bayesian task weight learner, MTRec is able to achieve the balance of two tasks during optimization automatically. Moreover, MTRec provides good interpretability of recommendation through a “translation” mechanism which is used to model the three-way interactions among users, items and the meta-paths connecting them. Experimental results demonstrate the effectiveness and the robustness of MTRec over state-of-the-art models.}
}


@inproceedings{DBLP:conf/icde/Liu0C0WWZ23,
	author = {Fan Liu and
                  Xingshe Zhou and
                  Jinli Cao and
                  Zhu Wang and
                  Tianben Wang and
                  Hua Wang and
                  Yanchun Zhang},
	title = {Anomaly Detection in Quasi-Periodic Time Series based on Automatic
                  Data Segmentation and Attentional {LSTM-CNN} (Extended Abstract)},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3777--3778},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00315},
	doi = {10.1109/ICDE55515.2023.00315},
	timestamp = {Fri, 26 Jul 2024 07:36:54 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Liu0C0WWZ23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Quasi-periodic time series (QTS) exists widely in the real world, and it is important to detect the anomalies of QTS. In this paper, we propose an automatic QTS anomaly detection framework (AQADF) consisting of a two-level clustering-based QTS segmentation algorithm (TCQSA) and a hybrid attentional LSTM-CNN model (HALCM). TCQSA first automatically splits the QTS into quasi-periods which are then classified by HALCM into normal periods or anomalies. Notably, TCQSA integrates a hierarchical clustering and the k-means technique, making itself highly universal and noise-resistant. HALCM hybridizes LSTM and CNN to simultaneously extract the overall variation trends and local features of QTS for modeling its fluctuation pattern. Furthermore, we embed a trend attention gate (TAG) into the LSTM, a feature attention mechanism (FAM) and a location attention mechanism (LAM) into the CNN to finely tune the extracted variation trends and local features according to their true importance to yield a better representation of the fluctuation pattern of the QTS. On four public datasets, HALCM exceeds four state-of-the-art baselines and obtains at least 97.3% accuracy, TCQSA exceeds two cutting-edge QTS segmentation algorithms and can be applied to different types of QTSs.}
}


@inproceedings{DBLP:conf/icde/TangHYLL23,
	author = {Shanjiang Tang and
                  Bingsheng He and
                  Ce Yu and
                  Yusen Li and
                  Kun Li},
	title = {A Survey on Spark Ecosystem: Big Data Processing Infrastructure, Machine
                  Learning, and Applications (Extended abstract)},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3779--3780},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00316},
	doi = {10.1109/ICDE55515.2023.00316},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/TangHYLL23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the explosive increase of big data in industry and academic fields, it is important to apply large-scale data processing systems to analyze Big Data. Arguably, Spark is the state-of-the-art in large-scale data computing systems nowadays, due to its good properties including generality, fault tolerance, high performance of in-memory data processing, and scalability. Spark adopts a flexible Resident Distributed Dataset (RDD) programming model with a set of provided transformation and action operators whose operating functions can be customized by users according to their applications. It is originally positioned as a fast and general data processing system. A large body of research efforts have been made to make it more efficient (faster) and general by considering various circumstances since its introduction. In this survey, we aim to have a thorough review of various kinds of optimization techniques on the generality and performance improvement of Spark. We introduce various data management and processing systems, machine learning algorithms and applications supported by Spark. Additionally, we make a discussion on the open issues and challenges for large-scale in-memory data processing with Spark.}
}


@inproceedings{DBLP:conf/icde/ZhongP23,
	author = {Guo Zhong and
                  Chi{-}Man Pun},
	title = {Data Representation by Joint Hypergraph Embedding and Sparse Coding
                  (Extended Abstract)},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3781--3782},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00317},
	doi = {10.1109/ICDE55515.2023.00317},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhongP23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Matrix factorization (MF), a popular unsupervised learning technique for data representation, has been widely applied in data mining and machine learning. According to different application scenarios, one can impose different constraints on the factorization to find the desired basis, which captures high-level semantics for the given data, and learns the compact representation corresponding to the basis. We note that almost all previous work on MF in data mining has ignored to find such a basis, which can carry high-order semantics in the data. In this work, we propose a novel MF framework called Joint Hypergraph Embedding and Sparse Coding, in which the obtained basis captures high-order semantic information in data. Experimental results on data clustering demonstrate that the proposed method consistently outperforms the other state-of-the-art matrix factorization methods.}
}


@inproceedings{DBLP:conf/icde/QianL0023,
	author = {Tieyun Qian and
                  Yile Liang and
                  Qing Li and
                  Hui Xiong},
	title = {Attribute Graph Neural Networks for Strict Cold Start Recommendation
                  : Extended Abstract},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3783--3784},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00318},
	doi = {10.1109/ICDE55515.2023.00318},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/QianL0023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recently, deep learning based methods, especially graph neural network (GNN), have made impressive progress on rating prediction problem in recommender systems. However, the performance of existing methods drops quickly in the cold start scenario. More importantly, such methods are unable to learn the preference embedding of a strict cold start user/item since there is no interaction for this user/item. In this work, we develop a novel framework Attribute Graph Neural Networks (AGNN) by exploiting the attribute graph rather than the commonly used interaction graph. AGNN can produce the preference embedding for a strict cold user/item by learning on the distribution of attributes with an extended variational auto-encoder (eVAE) structure. It also contains a new graph neural network variant (gated-GNN) to effectively aggregate various attributes of different dimensions in a neighborhood. Empirical results demonstrate that AGNN achieves the new state-of-the-art performance.}
}


@inproceedings{DBLP:conf/icde/001100GZ23,
	author = {Wei Wu and
                  Bin Li and
                  Ling Chen and
                  Junbin Gao and
                  Chengqi Zhang},
	title = {A Review for Weighted MinHash Algorithms (Extended abstract)},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3785--3786},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00319},
	doi = {10.1109/ICDE55515.2023.00319},
	timestamp = {Sat, 30 Sep 2023 09:44:49 +0200},
	biburl = {https://dblp.org/rec/conf/icde/001100GZ23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Data similarity computation is a fundamental research topic which underpins many high-level applications based on similarity measures. However, the exact similarity computation has become daunting in large-scale real-world scenarios. Currently, MinHash is a popular technique for efficiently estimating the Jaccard similarity of binary sets and, furthermore, weighted MinHash is utilized to estimate the generalized Jaccard similarity of weighted sets. This review focuses on categorizing and discussing the existing works of weighted MinHash algorithms. Also, we have developed a Python toolbox for the algorithms, and released it in our github.}
}


@inproceedings{DBLP:conf/icde/Al-BaghdadiSL23,
	author = {Ahmed Al{-}Baghdadi and
                  Gokarna Sharma and
                  Xiang Lian},
	title = {Efficient Processing of Group Planning Queries Over Spatial-Social
                  Networks (Extended Abstract)},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3787--3788},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00320},
	doi = {10.1109/ICDE55515.2023.00320},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Al-BaghdadiSL23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recently, location-based social networks, that involve both social and spatial information, have received much attention in many real-world applications such as location-based services (LBS), map utilities, business planning, and so on. In this paper, we seamlessly integrate both social networks and spatial road networks, resulting in a so-called spatial-social network, and study an important and novel query type, named group planning query over spatial-social networks (GP-SSN), which is very useful for applications such as trip recommendations. In particular, a GP-SSN query retrieves a group of friends with common interests on social networks and a number of spatially close points of interest (POIs) on spatial road networks that best match group’s preferences and have the smallest traveling distances to the group. In order to tackle the GP-SSN problem, we design effective pruning methods, matching score pruning, user pruning, and distance pruning, to rule out false alarms of GP-SSN query answers and reduce the problem search space. We also propose effective indexing mechanisms to facilitate the GP-SSN query processing and develop efficient GP-SSN query answering algorithms via index traversals. Extensive experiments have been conducted to evaluate the efficiency and effectiveness of our proposed GP-SSN query processing approaches.}
}


@inproceedings{DBLP:conf/icde/ZhaoPRPDYL23,
	author = {Huanyu Zhao and
                  Chaoyi Pang and
                  Kotagiri Ramamohanarao and
                  Christopher Kuo Pang and
                  Ke Deng and
                  Jian Yang and
                  Tongliang Li},
	title = {An Optimal Online Semi-connected {PLA} Algorithm with Maximum Error
                  Bound (Extended Abstract)},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3789--3790},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00321},
	doi = {10.1109/ICDE55515.2023.00321},
	timestamp = {Thu, 23 Nov 2023 13:25:05 +0100},
	biburl = {https://dblp.org/rec/conf/icde/ZhaoPRPDYL23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Piecewise Linear Approximation (PLA) is one of the most widely used approaches for representing a time series with a set of approximated line segments. With this compressed form of representation, many large complicated time series can be efficiently stored, transmitted and analyzed. In this article, with the introduced concept of "semi-connection" that allowing two representation lines to be connected at a point between two consecutive time stamps, we propose a new optimal linear-time PLA algorithm SemiOptConnAlg for generating the least number of semi-connected line segments with guaranteed maximum error bound. With extended experimental tests, we demonstrate that the proposed algorithm is very efficient in execution and achieves better performances than the state-of-art solutions.}
}


@inproceedings{DBLP:conf/icde/NguyenDY0MAN23,
	author = {Thanh Tam Nguyen and
                  Chi Thang Duong and
                  Hongzhi Yin and
                  Matthias Weidlich and
                  Son Thai Mai and
                  Karl Aberer and
                  Quoc Viet Hung Nguyen},
	title = {Efficient and Effective Multi-Modal Queries through Heterogeneous
                  Network Embedding (Extended Abstract)},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3791--3792},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00322},
	doi = {10.1109/ICDE55515.2023.00322},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/NguyenDY0MAN23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recent information retrieval (IR) systems answer a multi-modal query by considering it as a set of separate uni-modal queries. However, depending on the chosen operationalisation, such an approach is inefficient or ineffective. It either requires multiple passes over the data or leads to inaccuracies since the relations between data modalities are neglected in the relevance assessment. To mitigate these challenges, we present an IR system that has been designed to answer genuine multi-modal queries. It relies on a heterogeneous network embedding, so that features from diverse modalities can be incorporated when representing both, a query and the data over which it shall be evaluated. An experimental evaluation using diverse real-world and synthetic datasets illustrates that our approach returns twice the amount of relevant information compared to baseline techniques, while scaling to large multi-modal databases.}
}


@inproceedings{DBLP:conf/icde/00010MZ023,
	author = {Zuowei Zhang and
                  Zhe Liu and
                  Zongfang Ma and
                  Yiru Zhang and
                  Hao Wang},
	title = {A New Belief-Based Incomplete Pattern Unsupervised Classification
                  Method : Extended Abstract},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3793--3794},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00323},
	doi = {10.1109/ICDE55515.2023.00323},
	timestamp = {Sat, 30 Sep 2023 09:44:49 +0200},
	biburl = {https://dblp.org/rec/conf/icde/00010MZ023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Imputing the incomplete patterns in clustering tasks is a common but risky procedure, because the estimated values may affect the real distribution of the data and deteriorate the results. To address this problem, a new belief-based incomplete pattern unsupervised classification method (BPC) with uncertainty and imprecision reasoning is proposed in this paper. First, the complete patterns are grouped into a few clusters to obtain the corresponding reliable centers, and thereby are divided into reliable patterns and unreliable ones by an optimization method. Second, a basic classifier trained by reliable patterns is employed to classify unreliable patterns and incomplete patterns edited by the neighbors. Finally, some imprecise patterns are carefully reassigned again by a new distance-based rule depending on the obtained reliable centers and belief functions theory. The simulation results show that the BPC has the potential to deal with real datasets.}
}


@inproceedings{DBLP:conf/icde/TedjopurnomoBZC23,
	author = {David Alexander Tedjopurnomo and
                  Zhifeng Bao and
                  Baihua Zheng and
                  Farhana Murtaza Choudhury and
                  A. Kai Qin},
	title = {A Survey on Modern Deep Neural Network for Traffic Prediction: Trends,
                  Methods and Challenges (Extended Abstract)},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3795--3796},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00324},
	doi = {10.1109/ICDE55515.2023.00324},
	timestamp = {Tue, 26 Sep 2023 20:31:47 +0200},
	biburl = {https://dblp.org/rec/conf/icde/TedjopurnomoBZC23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this modern era, traffic congestion has become a major source of negative economic and environmental impact for urban areas worldwide. One of the most efficient ways to mitigate this issue is through traffic prediction. This research field has evolved greatly ever since its inception in the late 70s. Recently, deep neural network models have gained popularity thanks to its predictive power, but despite this, literature surveys of such methods are rare; making it difficult to ascertain the progress of this research field. In this work, we address this issue by presenting an up-to-date survey of deep neural network for traffic prediction. We provide detailed explanations of popular deep neural network architectures used in the traffic flow prediction literatures, categorize and describe the literatures themselves, present an overview of the commonalities and differences among different works, and finally provide a discussion regarding the challenges and future directions for this field.}
}


@inproceedings{DBLP:conf/icde/TangFLL023,
	author = {Jianchao Tang and
                  Shaojing Fu and
                  Ximeng Liu and
                  Yuchuan Luo and
                  Ming Xu},
	title = {Achieving Privacy-preserving and Lightweight Truth Discovery in Mobile
                  Crowdsensing (Extended abstract)},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3797--3798},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00325},
	doi = {10.1109/ICDE55515.2023.00325},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/TangFLL023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {To obtain reliable results from conflicting data in mobile crowdsensing, numerous truth discovery protocols have been proposed in the past decade. However, most of them do not consider the data privacy of entities involved (e.g., workers and servers), and several existing privacy-preserving truth discovery protocols either provide limited privacy protection or have heavy computation and communication overheads due to iterative computation and transmission over large ciphertexts.In this paper, we aim to propose privacy-preserving and lightweight truth discovery protocols to tackle the above problems. Specifically, we carefully design an anonymization protocol named AnonymTD to delink workers from their data, where workers’ data are computed and transmitted without complicated encryption. To further reduce each worker’s overheads in the scenarios where workers are willing to share their weights, we resort to the perturbation technology to propose a more lightweight truth discovery protocol named PerturbTD. Based on workers’ perturbed data, two cloud servers in PerturbTD complete most of the workload of truth discovery together, which avoids the frequent involvement of workers. The theoretical analysis and the comparative experiments in this paper demonstrate that our two protocols can achieve our security goals with low computation and communication overheads.}
}


@inproceedings{DBLP:conf/icde/PengLLXZ23,
	author = {Zhen Peng and
                  Minnan Luo and
                  Jundong Li and
                  Luguo Xue and
                  Qinghua Zheng},
	title = {A Deep Multi-View Framework for Anomaly Detection on Attributed Networks
                  (Extended Abstract)},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3799--3800},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00326},
	doi = {10.1109/ICDE55515.2023.00326},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/PengLLXZ23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Many existing anomaly detection methods on attributed networks do not seriously tackle the inherent multi-view property in attribute space but concatenate multiple views into a single feature vector, which inevitably ignores the incompatibility between heterogeneous views caused by their own statistical properties. In practice, the distinct but complementary information brought by multi-view data promises the potential for more effective anomaly detection than the efforts only based on single-view data. Furthermore, abnormal patterns naturally behave diversely in different views, which coincides with people’s desire to discover specific abnormalities according to their preferences for views (attributes). Most existing methods cannot adapt to people’s requirements as they fail to consider the idiosyncrasy of user preferences. Thus, in this paper, we propose a multi-view framework ALARM to incorporate user preferences into anomaly detection and simultaneously tackle heterogeneous attribute characteristics through multiple graph encoders and a well-designed aggregator that supports self-learning and user-guided learning. Experiments on synthetic and real-world datasets corroborate the desirable performance of ALARM and its effectiveness in supporting user-oriented anomaly detection.}
}


@inproceedings{DBLP:conf/icde/YuLYCCM23,
	author = {Runlong Yu and
                  Qi Liu and
                  Yuyang Ye and
                  Mingyue Cheng and
                  Enhong Chen and
                  Jianhui Ma},
	title = {Collaborative List-and-Pairwise Filtering from Implicit Feedback :
                  Extended Abstract},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3801--3802},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00327},
	doi = {10.1109/ICDE55515.2023.00327},
	timestamp = {Sat, 30 Sep 2023 09:44:52 +0200},
	biburl = {https://dblp.org/rec/conf/icde/YuLYCCM23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Collaborative filtering (CF) from implicit datasets has attracted much attention in recent years. The current mainstream pairwise methods optimize the Area Under the Curve (AUC) and are empirically proven to be helpful to exploit implicit feedback, but lead to not addressing the rank-biased scenarios where positive items are supposed to be placed on the top-k positions. Although there exist listwise methods, they have low efficiency and are not particularly adequate for general implicit feedback situations. To that end, in this paper, we propose a new framework, namely Collaborative List-and-Pairwise Filtering (CLAPF), which aims to introduce pairwise thinking into listwise methods. Specifically, we first smooth a well-known rank-biased measure called Mean Average Precision (MAP) as a low-bound version to make it can be optimized. After that, we combined the objective functions of optimizing the MAP with pairwise comparisons. The CLAPF framework is a new hybrid model that provides the idea of utilizing a listwise measure in a pairwise way on implicit feedback.}
}


@inproceedings{DBLP:conf/icde/GuoZQZ00023,
	author = {Qingyu Guo and
                  Fuzhen Zhuang and
                  Chuan Qin and
                  Hengshu Zhu and
                  Xing Xie and
                  Hui Xiong and
                  Qing He},
	title = {A Survey on Knowledge Graph-Based Recommender Systems : Extended Abstract},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3803--3804},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00328},
	doi = {10.1109/ICDE55515.2023.00328},
	timestamp = {Mon, 31 Jul 2023 08:35:14 +0200},
	biburl = {https://dblp.org/rec/conf/icde/GuoZQZ00023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {To solve the information explosion problem and enhance user experience in various online applications, recommender systems have been developed to model users’ preferences. Although numerous efforts have been made toward more personalized recommendations, recommender systems still suffer from several challenges, such as data sparsity and cold-start problems. In recent years, generating recommendations with the knowledge graph as side information has attracted considerable interest. Such an approach can not only alleviate the above mentioned issues for a more accurate recommendation, but also provide explanations for recommended items. In this paper, we conduct a systematical survey of knowledge graph-based recommender systems. We collect recently published papers in this field, and group them into three categories, i.e., embedding-based methods, connection-based methods, and propagation-based methods. Also, we further subdivide each category according to the characteristics of these approaches. Moreover, we investigate the proposed algorithms by focusing on how the papers utilize the knowledge graph for accurate and explainable recommendation. Finally, we propose several potential research directions in this field.}
}


@inproceedings{DBLP:conf/icde/LiCFW23,
	author = {Jing Li and
                  Billy Chiu and
                  Shanshan Feng and
                  Hao Wang},
	title = {Few-Shot Named Entity Recognition via Meta-Learning (Extended Abstract)},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3805--3806},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00329},
	doi = {10.1109/ICDE55515.2023.00329},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LiCFW23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Named entity recognition (NER) is typically framed as a sequence labeling problem where the entity classes are inherently entangled together because the entity number and classes in a sentence are not known in advance, leaving the N-way K-shot NER problem so far unexplored. In our TKDE paper, we first formally define a more suitable N-way K-shot setting for NER. Then we propose FewNER, a novel meta-learning approach for few-shot NER. FewNER separates the entire network into a task-independent part and a task-specific part. During training in FewNER, the task-independent part is meta-learned across multiple tasks and the task-specific part is learned for each individual task in a low-dimensional space. At test time, FewNER keeps the task-independent part fixed and adapts to a new task via gradient descent by updating only the task-specific part, resulting in it being less prone to overfitting and more computationally efficient. Compared with pre-trained language models (e.g., BERT and ELMo) which obtain the transferability in an implicit manner (i.e., relying on large-scale corpora), FewNER explicitly optimizes the capability of "learning to adapt quickly" through meta-learning. The results demonstrate that FewNER achieves state-of-the-art performance against nine baseline methods by significant margins on three adaptation experiments (i.e., intra-domain cross-type, cross-domain intra-type and cross-domain cross-type).}
}


@inproceedings{DBLP:conf/icde/MezniBB23,
	author = {Haithem Mezni and
                  Djamal Benslimane and
                  Ladjel Bellatreche},
	title = {Context-aware Service Recommendation based on Knowledge Graph Embedding
                  (Extended Abstract)},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3807--3808},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00330},
	doi = {10.1109/ICDE55515.2023.00330},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/MezniBB23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As a class of context-aware systems, context-aware service recommendation (CASR) aims to bind high-quality services to users, w.r.t. their context requirements (e.g., invocation time, location, social profiles, connectivity). However, current CASR lacks a rich context modelling and does not allow for multi-relational interactions between users and services in different contexts. We propose a context-sensitive service recommendation, by constructing a contextual service knowledge graph (C-SKG), which we translated into a low-dimensional vector space to facilitate its processing. Dilated Recurrent Neural Networks are applied to allow a context-aware C-SKG embedding, based on the principles of subgraph-aware proximity. A recommendation algorithm, finally, returns the top-rated services w.r.t. the target user’s context and the proximity degrees.}
}


@inproceedings{DBLP:conf/icde/NishioAH23,
	author = {Shunya Nishio and
                  Daichi Amagata and
                  Takahiro Hara},
	title = {Lamps: Location-Aware Moving Top-k Pub/Sub (Extended abstract)},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3809--3810},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00331},
	doi = {10.1109/ICDE55515.2023.00331},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/NishioAH23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We propose a novel system, called Lamps (Location-Aware Moving Top-k Pub/Sub), which continuously monitors the top-k most relevant spatio-textual objects for a large number of moving top-k spatio-textual subscriptions simultaneously. Lamps employs the concept of a safe region to monitor top-k results. However, unlike with existing works that assume static objects, top-k result updates may be triggered by newly generated objects. To continuously monitor the top-k results for massive moving subscriptions efficiently, we propose SQ-tree, a novel index based on safe regions, to filter subscriptions whose top-k results do not change. Moreover, to reduce the expensive cost of safe region re-evaluation, we develop a novel approximation technique for safe region construction. Our experimental results on real datasets show that Lamps achieves higher performance than baseline approaches.}
}


@inproceedings{DBLP:conf/icde/Chu0LG023,
	author = {Jielei Chu and
                  Hongjun Wang and
                  Jing Liu and
                  Zhiguo Gong and
                  Tianrui Li},
	title = {Unsupervised Feature Learning Architecture with Multi-clustering Integration
                  {RBM}},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3811--3812},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00332},
	doi = {10.1109/ICDE55515.2023.00332},
	timestamp = {Mon, 05 Feb 2024 20:31:13 +0100},
	biburl = {https://dblp.org/rec/conf/icde/Chu0LG023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Feature learning is a crucial phase machine learning [1] – [3] . How to obtain appropriate features distribution without any background is still a hard problem in machine learning. In this paper, we present a novel unsupervised feature learning architecture (see Fig. 1 ), which consists of a multi-clustering integration module and a variant of RBM termed multi-clustering integration RBM (MIRBM). In the multi-clustering integration module, we choose three clusterers to obtain three different global clustering partitions (CPs). Then, an unanimous voting strategy is used to generate the local clustering partition (LCP) of visible layer data. Hence, the LCP only has partial visible layer data. The novel MIRBM model is a core feature encoding part of the proposed unsupervised feature learning architecture. The novelty of it is that the LCP as an unsupervised guidance is integrated into the CD 1 learning to guide the distribution of the hidden layer features. For the instance in the same LCP cluster, the hidden and reconstructed hidden layer features of the MIRBM model in the proposed architecture tend to constrict together in the training process. Meanwhile, each LCP center tends to disperse from each other as much as possible in the hidden and reconstructed hidden layer during training. This work has three main contributions: 1) A novel unsupervised feature learning architecture is proposed, which consists of a multi-clustering integration module and an MIRBM model. 2) In the multi-clustering integration module of the proposed architecture, three unsupervised algorithms are employed to obtain three different global CPs without any background knowledge or label. 3) The MIRBM model in the proposed architecture uses the LCP as an unsupervised guidance to guide the distribution of the hidden layer features by integrating the LCP into the CD 1 learning.}
}


@inproceedings{DBLP:conf/icde/0003000023,
	author = {Meng Chen and
                  Yan Zhao and
                  Yang Liu and
                  Xiaohui Yu and
                  Kai Zheng},
	title = {Modeling Spatial Trajectories with Attribute Representation Learning
                  (Extended Abstract)},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3813--3814},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00333},
	doi = {10.1109/ICDE55515.2023.00333},
	timestamp = {Mon, 05 Feb 2024 20:31:12 +0100},
	biburl = {https://dblp.org/rec/conf/icde/0003000023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The widespread use of positioning devices has given rise to many trajectories, with each having three explicit attributes: user ID, location ID, and time-stamp and an implicit attribute: activity type (akin to "topic" in text mining). To model these trajectories, existing works learn different attribute representations by either introducing latent activity types based on topic models or transforming the location and time context into a low-dimensional space via embedding techniques. In this paper, we propose a holistic approach named Human Mobility Representation Model (HMRM) to simultaneously produce the vector representations of all four (explicit and implicit) attributes. We evaluate HMRM on two real check-in datasets collected from Foursquare. Experimental results show that HMRM could not only improve the performance of capturing latent activity types, but also learn better trajectory embeddings.}
}


@inproceedings{DBLP:conf/icde/02000D00023,
	author = {Yang Liu and
                  Xiang Ao and
                  Linfeng Dong and
                  Chao Zhang and
                  Jin Wang and
                  Qing He},
	title = {Spatiotemporal Activity Modeling via Hierarchical Cross-Modal Embedding
                  : Extended Abstract},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3815--3816},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00334},
	doi = {10.1109/ICDE55515.2023.00334},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/02000D00023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the ever-increasing urbanization process, modeling people’s spatiotemporal activities from their online traces has become a crucial task. State-of-the-art methods for this task rely on cross-modal embedding, which maps items from different modalities (e.g., location, time, text) into the same latent space. Despite their inspiring results, existing cross-modal embedding methods merely capture co-occurrences between items without modeling their high-order interactions. In this paper, we first construct the user interaction graph and the activity graph from raw data records and propose a hierarchical cross-modal embedding method that takes the high-order relationships into consideration. We introduce both inter-record and intra-record meta-graph structures, which enable learning distributed representations that preserve high-order proximities across graphs from different layers. Our empirical experiments on three real-world datasets demonstrate that our method not only outperforms state-of-the-art methods for spatiotemporal activity prediction but also captures cross-modal proximity at a finer granularity.}
}


@inproceedings{DBLP:conf/icde/LiSHL23,
	author = {Jing Li and
                  Aixin Sun and
                  Jianglei Han and
                  Chenliang Li},
	title = {A Survey on Deep Learning for Named Entity Recognition : Extended
                  Abstract},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3817--3818},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00335},
	doi = {10.1109/ICDE55515.2023.00335},
	timestamp = {Tue, 13 Aug 2024 08:01:40 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LiSHL23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Named entity recognition (NER) is the task to identify text spans that mention named entities, and to classify them into predefined categories such as person, location, organization, etc. In recent years, deep learning, empowered by continuous real-valued vector representations and semantic composition through nonlinear processing, has been employed in NER systems, yielding stat-of-the-art performance. In our TKDE paper, we provide a comprehensive review on existing deep learning techniques for NER. We first introduce NER resources, including tagged NER corpora and off-the-shelf NER tools. Then, we systematically categorize existing solutions based on a taxonomy along three axes: distributed representations for input, context encoder, and tag decoder. Next, we survey the most representative methods for deep learning in new NER problem settings and applications. Finally, we present readers with the challenges faced by NER systems and outline future directions in this area.}
}


@inproceedings{DBLP:conf/icde/SongGHW23,
	author = {Shaoxu Song and
                  Fei Gao and
                  Ruihong Huang and
                  Chaokun Wang},
	title = {Data Dependencies Extended for Variety and Veracity: {A} Family Tree
                  (Extended abstract)},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3819--3820},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00336},
	doi = {10.1109/ICDE55515.2023.00336},
	timestamp = {Mon, 05 Feb 2024 20:31:13 +0100},
	biburl = {https://dblp.org/rec/conf/icde/SongGHW23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {To address the variety and veracity issues of big data, data dependencies have been extended as data quality rules to adapt to various data types, ranging from (1) categorical data with equality relationships to (2) heterogeneous data with similarity relationships, and (3) numerical data with order relationships. In this survey, we briefly review the recent proposals on data dependencies categorized into the aforesaid types of data. In addition to (a) the concepts of these data dependency notations, we investigate (b) the extension relationships between data dependencies. It forms a family tree of extensions, mostly rooted in FDs. Moreover, we summarize (c) the discovery of dependencies from data, and (d) the applications of the extended data dependencies. Finally, we conclude with several directions of future studies on the emerging data.}
}


@inproceedings{DBLP:conf/icde/024500PZ023,
	author = {Yang Liu and
                  Liang Chen and
                  Xiangnan He and
                  Jiaying Peng and
                  Zibin Zheng and
                  Jie Tang},
	title = {Modelling High-Order Social Relations for Item Recommendation (Extended
                  Abstract)},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3821--3822},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00337},
	doi = {10.1109/ICDE55515.2023.00337},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/024500PZ023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Personalized recommendation is becoming increasingly important in online information systems in the current era of information explosion. In real-world scenarios, when a user considers which items to consume, the decision choice may be affected by her friends. For example, she may ask her friends for suggestions or be attracted by products purchased by one friend. As such, to provide satisfactory recommendation service, it is important to account for the evidence in social relations when they are available to use. Several prior efforts have been made to leverage social relations to build the recommender system and verified their utility. However, most existing methods, such as the well-known TrustSVD, leverage only first-order social relations, i.e., the direct neighbors that are connected to the target user. The high-order social relations, e.g., the friends of friends, which are very informative to reveal user preference, have been largely ignored.}
}


@inproceedings{DBLP:conf/icde/LinR0L0WL23,
	author = {Lihui Lin and
                  Yanghui Rao and
                  Haoran Xie and
                  Raymond Y. K. Lau and
                  Jian Yin and
                  Fu Lee Wang and
                  Qing Li},
	title = {Copula Guided Parallel Gibbs Sampling for Nonparametric and Coherent
                  Topic Discovery (Extended Abstract)},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3823--3824},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00338},
	doi = {10.1109/ICDE55515.2023.00338},
	timestamp = {Tue, 14 Nov 2023 16:56:09 +0100},
	biburl = {https://dblp.org/rec/conf/icde/LinR0L0WL23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In terms of the generative process, the Gamma-Gamma-Poisson Process (G2PP) is equivalent to the nonparametric topic model of Hierarchical Dirichlet Process (HDP). Considering the high computational cost of estimating parameters in HDP, a parallel G2PP was developed to generate topics efficiently via multi-threading. Unfortunately, the above model needs to predefine the number of topics. To address this issue, we first propose a Topic Self-Adaptive Model (TSAM) for nonparametric and parallel topic discovery. In TSAM, a monitor-executor mechanism is developed to manage the global topic information using a hierarchical structure of threads. Based on the apparatus of copulas, we further extend our TSAM to TSAMcop for coherent topic modeling by exploiting a copula guided parallel Gibbs sampling algorithm. Extensive experiments validate the effectiveness of both TSAM and TSAMcop.}
}


@inproceedings{DBLP:conf/icde/WangRGWLG23,
	author = {Chenxu Wang and
                  Wei Rao and
                  Wenna Guo and
                  Pinghui Wang and
                  Jun Liu and
                  Xiaohong Guan},
	title = {Towards Understanding the Instability of Network Embedding (Extended
                  Abstract)},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3825--3826},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00339},
	doi = {10.1109/ICDE55515.2023.00339},
	timestamp = {Wed, 14 Aug 2024 08:22:04 +0200},
	biburl = {https://dblp.org/rec/conf/icde/WangRGWLG23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Network embedding algorithms learn a mapping from the discrete representation of nodes to continuous vector spaces that preserve node proximity. Despite recent efforts to design novel models, little attention has been given to understanding the instability of network embedding. In this paper, we define the stability of node embeddings as the invariance of the nearest neighbors of nodes in different instantiations. We find that existing embedding approaches have significant amounts of instability. In addition, network structures and algorithm models influence the stability of node embeddings significantly. We also examine the implications of embedding instability for downstream tasks and find remarkable impacts on performance.}
}


@inproceedings{DBLP:conf/icde/Byun23,
	author = {Jaewook Byun},
	title = {Enabling Time-Centric Computation for Efficient Temporal Graph Traversals
                  From Multiple Sources (Extended abstract)},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3827--3828},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00340},
	doi = {10.1109/ICDE55515.2023.00340},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Byun23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Temporal graph traversal is an approach for analyzing how information spreads throughout a network over time. A system has been recently proposed as an initial effort for efficient analyses against higher time complexity and infinitely evolving data unlike static graph. However, with the system, the response time for traversals from multiple sources is proportional to the number of sources; thus, application domains of the system can be limited. To resolve this problem, the state-of-the-art vertex-centric paradigm can be considered; however, we have found that the paradigm is not fitted into this computation. The paper proposes a novel time-centric computation approach for efficient all-pairs temporal graph traversals. One benefit of this approach is that users only need to focus on designing a repetitive task for graph elements that are valid at each sliding time, which simplifies the program logic and alleviates the burden of writing codes. Another benefit is that the approach is expected to enhance the performance by facilitating the reuse of intermediate results of multiple sources. The proposed approach is evaluated with a prototyped system, the recipes for existing algorithms, and the experiments with open temporal datasets. In addition, we also discuss how to handle ever-evolving real-world temporal networks.}
}


@inproceedings{DBLP:conf/icde/WuYL00W23,
	author = {Hanrui Wu and
                  Yuguang Yan and
                  Guosheng Lin and
                  Min Yang and
                  Michael K. Ng and
                  Qingyao Wu},
	title = {Iterative Refinement for Multi-Source Visual Domain Adaptation (Extended
                  abstract)},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3829--3830},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00341},
	doi = {10.1109/ICDE55515.2023.00341},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/WuYL00W23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Multi-source domain adaptation (MSDA) aims to leverage the knowledge in multiple source domains to assist the prediction in a target domain, where the source and target domains have different data distributions. This paper presents a MSDA model to investigate both domain discrepancy and domain relevance, whose interactions are also exploited to gradually refine the learning performance. Particularly, the proposed model contains two components, i.e., feature spaces learning and transferred weights learning. The former one minimizes the domain discrepancy and the latter one evaluates the domain relevance. Experimental results on several real-world datasets demonstrate the effectiveness of the proposed model.}
}


@inproceedings{DBLP:conf/icde/0001AJS23,
	author = {Wei Ye and
                  Omid Askarisichani and
                  Alex T. Jones and
                  Ambuj K. Singh},
	title = {Learning Deep Graph Representations via Convolutional Neural Networks
                  (Extended abstract)},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3831--3832},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00342},
	doi = {10.1109/ICDE55515.2023.00342},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/0001AJS23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {R-convolution graph kernels are positive-semidefinite functions that decompose graphs into substructures and compare them. One problem in the effective implementation of this idea is that the substructures are not independent, which leads to high-dimensional feature space. In addition, graph kernels cannot capture the high-order complex interactions between vertices. To mitigate these two problems, we propose a framework called DeepMap to learn deep representations for graph feature maps used in graph kernels. The learned deep representation for a graph is a dense and low-dimensional vector that captures complex high-order interactions in a vertex neighborhood. We empirically validate DeepMap on various graph classification benchmarks and demonstrate that it achieves state-of-the-art performance.}
}


@inproceedings{DBLP:conf/icde/0001MBSP23,
	author = {Wei Ye and
                  Dominik Mautz and
                  Christian B{\"{o}}hm and
                  Ambuj K. Singh and
                  Claudia Plant},
	title = {Incorporating User's Preference into Attributed Graph Clustering :
                  Extended abstract},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3833--3834},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00343},
	doi = {10.1109/ICDE55515.2023.00343},
	timestamp = {Sun, 04 Aug 2024 19:37:45 +0200},
	biburl = {https://dblp.org/rec/conf/icde/0001MBSP23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In contrast to global graph clustering, local graph clustering aims to find only one cluster that is concentrating on the given seed vertex (and also on the designated attributes for attributed graphs). Currently, very few methods can deal with this kind of task. To this end, we propose two quality measures for a local graph cluster: Graph Unimodality (GU) and Attribute Unimodality (AU). They measure the homogeneity/unimodality of the graph structure and the subspace that is composed of the designated attributes, respectively. We call their linear combination Compactness. Further, we propose LOCLU to optimize the Compactness score in order to find a good local graph cluster. The local graph cluster detected by LOCLU concentrates on the region of interest, provides efficient information flow in the graph, and exhibits a unimodal data distribution in the subspace of the designated attributes.}
}


@inproceedings{DBLP:conf/icde/YangL023,
	author = {Xinghao Yang and
                  Weifeng Liu and
                  Wei Liu},
	title = {Tensor Canonical Correlation Analysis Networks for Multi-view Remote
                  Sensing Scene Recognition (Extended Abstract)},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3835--3836},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00344},
	doi = {10.1109/ICDE55515.2023.00344},
	timestamp = {Thu, 03 Aug 2023 20:31:44 +0200},
	biburl = {https://dblp.org/rec/conf/icde/YangL023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Remote sensing (RS) images are frequently observed from multiviews. In this paper, we propose the tensor canonical correlation analysis network (TCCANet) to tackle the multiview RS recognition problem. Particularly, TCCANet learns filter banks by simultaneously maximizing arbitrary number of views with high-order-correlation and solves the optimization problem by decomposing a covariance tensor. After the convolutional stage, we utilize binarization and block-wise histogram strategies to generate the final feature. Furthermore, we also develop a Multiple Scale version of TCCANet, i.e., MS-TCCANet, to extract enriched representation of the RS data by incorporating all previous convolutional layers. Numerical experiment results on RSSCN7 and SAT-6 datasets demonstrate the advantages of TCCANet and MS-TCCANet for RS scene recognition.}
}


@inproceedings{DBLP:conf/icde/Wu0CN0Y23,
	author = {Bin Wu and
                  Xiangnan He and
                  Yu Chen and
                  Liqiang Nie and
                  Kai Zheng and
                  Yangdong Ye},
	title = {Modeling Product's Visual and Functional Characteristics for Recommender
                  Systems (Extended Abstract)},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3837--3838},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00345},
	doi = {10.1109/ICDE55515.2023.00345},
	timestamp = {Thu, 08 Aug 2024 08:11:02 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Wu0CN0Y23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recommender systems aim at helping users to discover interesting items and assisting business owners to obtain more profits. Nonetheless, traditional recommendations fail to explore the varying importance of product characteristics for different product domains. In light of this, we propose a novel probabilistic model for recommendation, which could learn products’ characteristics in a fine-grained manner. Specifically, a user’s preference for a given product is modeled as a combination of visual and functional aspects. To make our method practical in large-scale industrial scenarios, we devise a computationally efficient learning algorithm to optimize VFPMF’s parameters. Experiments on four real-world datasets demonstrate the effectiveness and efficiency of our solution, compared with several state-of-the-art methods.}
}


@inproceedings{DBLP:conf/icde/YaoDNW23,
	author = {Jing Yao and
                  Zhicheng Dou and
                  Jian{-}Yun Nie and
                  Ji{-}Rong Wen},
	title = {Looking Back on the Past: Active Learning with Historical Evaluation
                  Results : Extended Abstract},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3839--3840},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00346},
	doi = {10.1109/ICDE55515.2023.00346},
	timestamp = {Mon, 05 Feb 2024 20:31:12 +0100},
	biburl = {https://dblp.org/rec/conf/icde/YaoDNW23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Active learning is effective for tasks with limited labeled data by annotating a small set of data actively. It utilizes the current trained model to evaluate all unlabeled samples and annotates the best samples scored by a specific query strategy to update the underlying model iteratively. Most active learning approaches rely on only the current evaluation score but ignore the results from previous iterations. In this paper, we propose using more historical evaluation results which can provide additional information to help better select samples. First, we apply two heuristic features of the historical evaluation results, i.e. the weighted sum and the fluctuation of history sequences. Next, to make fuller use of the information contained in the historical results, we design a query strategy that learns to select samples based on the history sequence automatically. Our proposed idea is general and can be combined with both basic and state-of-the-art query strategies to achieve improvements. Experimental results show that our methods significantly promote existing methods.}
}


@inproceedings{DBLP:conf/icde/ZhuLW023,
	author = {Jiajing Zhu and
                  Yongguo Liu and
                  Chuanbiao Wen and
                  Xindong Wu},
	title = {{DGDFS:} Dependence Guided Discriminative Feature Selection for Predicting
                  Adverse Drug-Drug Interaction : Extended Abstract},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3841--3842},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00347},
	doi = {10.1109/ICDE55515.2023.00347},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhuLW023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Adverse drug-drug interaction (ADDI) is a significant life-threatening issue for public health. The current methods for ADDI prediction usually work in a "nondiscriminatory" manner by treating each feature without discrimination and equally employing all features into ADDI modeling. Driven by this issue, we propose a Dependence Guided Discriminative Feature Selection (DGDFS) model for ADDI prediction, in which molecular structure and side effect are adopted with the incorporation of l 2,0 -norm equality constraints to select discriminative molecular substructures and side effects and three dependence based terms among molecular structure, side effect, and ADDIs to guide feature selection. Extensive experiments demonstrate the superior performance of DGDFS compared with fourteen state-of-the-art ADDI prediction and feature selection models.}
}


@inproceedings{DBLP:conf/icde/AkujuobiSP023,
	author = {Uchenna Akujuobi and
                  Michael Spranger and
                  Sucheendra K. Palaniappan and
                  Xiangliang Zhang},
	title = {{T-PAIR:} Temporal Node pair Embedding for Automatic Biomedical Hypothesis
                  Generation (Extended abstract)},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3843--3844},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00348},
	doi = {10.1109/ICDE55515.2023.00348},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/AkujuobiSP023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we study an automatic hypothesis generation (HG) problem, which refers to the discovery of meaningful implicit connections between scientific terms, including but not limited to diseases, chemicals, drugs, and genes extracted from databases of biomedical publications. Most prior studies of this problem focused on using static information of terms and largely ignored the temporal dynamics of scientific term relations. Even when the dynamics were considered in a few recent studies, they learned the representations for the scientific terms rather than focusing on the term-pair relations. Since the HG problem is to predict term-pair connections, it is not enough to know with whom the terms are connected; it is more important to know how the connections have been formed (in a dynamic process). We formulate this HG problem as a future connectivity prediction in a dynamic attributed graph and propose an inductive edge (node pair) embedding method named T-PAIR, utilizing both the graphical structure and node attribute to encode the temporal node pair relationship. We demonstrate the efficiency of the proposed model on real-world biomedical datasets in predicting future term-pair relations between millions of seen terms (in the transductive setting), as well as on the relations involving unseen terms (in the inductive setting).}
}


@inproceedings{DBLP:conf/icde/0007Y0X23,
	author = {Hong Yu and
                  Qian Yang and
                  Guoyin Wang and
                  Yongfang Xie},
	title = {A Novel Discriminative Dictionary Pair Learning Constrained by Ordinal
                  Locality for Mixed Frequency Data Classification : Extended abstract},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3845--3846},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00349},
	doi = {10.1109/ICDE55515.2023.00349},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/0007Y0X23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A dilemma faced by classification is that the data is not collected at the same frequency in some applications. We investigate the mixed frequency data in a new way and recognize them as a special style of multi-view data, in which each view data is collected at a different sampling frequency. This paper proposes a discriminative dictionary pair learning method constrained by ordinal locality for mixed frequency data classification (shorted by DPLOL-MF). This method integrates synthesis dictionary and analysis dictionary into a dictionary pair, which not only improves computational cost caused by the ℓ 0 or ℓ 1 -norm constraint, but also can deal with the sampling frequency inconsistency. The DPLOL-MF utilizes a synthesis dictionary to learn class-specified reconstruction information and employs an analysis dictionary to generate coding coefficients by analyzing samples. Particularly, the ordinal locality preserving term is leveraged to constrain the atoms of dictionaries pair to further facilitate the learned dictionary pair to be more discriminative. Besides, we design a specific classification scheme for the inconsistent sample size of mixed frequency data. This paper illustrates a novel idea to solve the classification task of mixed frequency data and the experimental results demonstrate the effectiveness of the proposed method.}
}


@inproceedings{DBLP:conf/icde/RongSM0A23,
	author = {Huan Rong and
                  Victor S. Sheng and
                  Tinghuai Ma and
                  Yang Zhou and
                  Mznah Al{-}Rodhaan},
	title = {A Self-play and Sentiment-Emphasized Comment Integration Framework
                  Based on Deep Q-Learning in a Crowdsourcing Scenario : Extended Abstract},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3847--3848},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00350},
	doi = {10.1109/ICDE55515.2023.00350},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/RongSM0A23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Crowdsourcing is a sourcing model where individuals or organizations obtain goods and services from a large, relatively open and often rapidly evolving group of internet users. The most common way that crowdsourcing can facilitate machine learning is to annotate instances with labels [1] . However, the same instance may have inconsistent class labels, in the eyes of various annotators. Therefore, current efforts in crowdsourcing mainly focus on the truth inference or label integration, to remove inconsistent labels or to alleviate biased labeling. In turn, instances with the integrated labels could facilitate the training on machine learning models. The future direction of crowdsourcing is to apply more fine-grained truth inference methods to different application domains [2] . Consequently, we evolve toward another challenging problem of comment integration. That is, how can we integrate or summarize the core opinions of multiple product comments obtained from users, rather than the discrete labels.}
}


@inproceedings{DBLP:conf/icde/0003CJZ23,
	author = {Wei Song and
                  Zhen Chang and
                  Hans{-}Arno Jacobsen and
                  Pengcheng Zhang},
	title = {Discovering Structural Errors From Business Process Event Logs (Extended
                  Abstract)},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3849--3850},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00351},
	doi = {10.1109/ICDE55515.2023.00351},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/0003CJZ23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {While process mining has gained much attention in the past decade, surprisingly, discovering structural errors (i.e., deadlock and lack of synchronization) from event logs has seldom been studied. Since event logs may involve erroneous event occurrences caused by unsynchronized activities, discovering deadlocks and lack of synchronization errors may influence each other. To this end, we first extract from the original event log two independent event logs which are employed to discover deadlocks and lack of synchronization errors, respectively. We then discard the erroneous event occurrences in the two event logs, from which our event relation based mining rules can discover the corresponding structural errors. We have implemented our approach, and the experimental results corroborate that our approach can effectively and efficiently discover process structural errors from the event logs involving sufficient event sequences.}
}


@inproceedings{DBLP:conf/icde/LiG23a,
	author = {Dichao Li and
                  Zhiguo Gong},
	title = {A Deep Neural Network for Crossing-City {POI} Recommendations : (Extended
                  Abstract)},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3851--3852},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00352},
	doi = {10.1109/ICDE55515.2023.00352},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LiG23a.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {THE popularity of location-aware devices such as smart phones makes users freely share their activities through various location-based social networks (LBSNs), such as Foursquare and Yelp. A large amount of user-contributed data enable to develop effective point-of-interest (POI) recommender systems. It not only guides users to explore more interesting attractions, but also helps the location service providers deliver targeted advertising. Now most of existing studies focus on recommending POIs in the same city or region, named as traditional POI recommender systems. However, they fail to deal with the increasingly popular case: users travel to new cities to explore more attractions. This raises the problem that how we shall recommend POIs in a target city to a new visitor based on her/his check-in records in source cities. We refer to this problem as crossing-city POI recommendations. Compared with traditional POI recommender systems, crossing-city POI recommender systems are more challenging due to the following aspects:}
}


@inproceedings{DBLP:conf/icde/HannulaZSL23,
	author = {Miika Hannula and
                  Zhuoxing Zhang and
                  Bor{-}Kuan Song and
                  Sebastian Link},
	title = {Discovery of Cross Joins (Extended Abstract)},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3853--3854},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00353},
	doi = {10.1109/ICDE55515.2023.00353},
	timestamp = {Mon, 05 Feb 2024 20:31:13 +0100},
	biburl = {https://dblp.org/rec/conf/icde/HannulaZSL23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We present exact complexity bounds on the discovery of cross joins from database relations, and algorithms that work evidently well on real-world data sets within those bounds.}
}


@inproceedings{DBLP:conf/icde/YanWYBLLWN23,
	author = {Yuguang Yan and
                  Hanrui Wu and
                  Yuzhong Ye and
                  Chaoyang Bi and
                  Min Lu and
                  Dapeng Liu and
                  Qingyao Wu and
                  Michael Kwok{-}Po Ng},
	title = {Transferable Feature Selection for Unsupervised Domain Adaptation
                  : Extended Abstract},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3855--3856},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00354},
	doi = {10.1109/ICDE55515.2023.00354},
	timestamp = {Mon, 21 Aug 2023 11:05:49 +0200},
	biburl = {https://dblp.org/rec/conf/icde/YanWYBLLWN23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Domain adaptation aims at extracting knowledge from auxiliary source domains to assist the learning task in a target domain. Since the distributions of the source and target domains are different, directly using source data to build a classifier for the target domain may hamper the classification performance on the target data. In this paper, we propose to find a feature subset that is both transferable and discriminative, so that both the domain discrepancy and the classification loss measured on the selected features can be reduced. To achieve this, we formulate a new sparse learning model that is able to jointly reduce the domain discrepancy and select informative features for classification. Extensive experiments on real-world data sets demonstrate the effectiveness of the proposed method.}
}


@inproceedings{DBLP:conf/icde/00080TWZ023,
	author = {Yong Chen and
                  Hui Zhang and
                  Zhibao Tian and
                  Jun Wang and
                  Dell Zhang and
                  Xuelong Li},
	title = {Enhanced Discrete Multi-modal Hashing: More Constraints yet Less Time
                  to Learn (Extended Abstract)},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3857--3858},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00355},
	doi = {10.1109/ICDE55515.2023.00355},
	timestamp = {Thu, 25 Jan 2024 13:31:42 +0100},
	biburl = {https://dblp.org/rec/conf/icde/00080TWZ023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper proposes a novel method, Enhanced Discrete Multi-modal Hashing (EDMH), which learns binary codes and hash functions simultaneously from the pairwise similarity matrix of data for large-scale cross-view retrieval. EDMH distinguishes itself from existing methods by considering not just the binarization constraint but also the balance and decorrelation constraints. Although those additional discrete constraints make the optimization problem of EDMH look a lot more complicated, we are actually able to develop a fast iterative learning algorithm in the alternating optimization framework for it, as after introducing a couple of auxiliary variables each subproblem of optimization turns out to have closed-form solutions. It has been confirmed by extensive experiments that EDMH can consistently deliver better retrieval performances than state-of-the-art MH methods at lower computational costs.}
}


@inproceedings{DBLP:conf/icde/Qiu00W23,
	author = {Tao Qiu and
                  Xiaochun Yang and
                  Bin Wang and
                  Wei Wang},
	title = {Efficient Regular Expression Matching Based on Positional Inverted
                  Index : (Extended Abstract)},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3859--3860},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00356},
	doi = {10.1109/ICDE55515.2023.00356},
	timestamp = {Mon, 04 Sep 2023 16:54:29 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Qiu00W23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We study the efficient regular expression (regex) matching problem. Existing algorithms are scanning-based algorithms that typically use an equivalent automaton compiled from the regex query to verify a document. Although some works propose various strategies to quickly jump to candidate locations in a document where a query result may appear, they still need to utilize the scanning-based method to verify these candidate locations. These methods become inefficient when there are still many candidate locations needed to be verified. In this paper, we propose a novel approach to efficiently compute all matching positions for a regex query purely based on a positional q-gram inverted index. We propose a gram-driven NFA to represent the language of a regex and show all regex matching locations can be obtained by finding positions on q-grams of GNFA that satisfy certain positional constraints. Then we propose several GNFA-based query plans to answer the query using the positional inverted index. In order to improve the query efficiency, we design the algorithm to build a tree-based query plan by carefully choosing a checking order for positional constraints. Experimental results on real-world datasets show that our method outperforms state-of-the-art methods by up to an order of magnitude in query efficiency.}
}


@inproceedings{DBLP:conf/icde/Liu0PD0W023,
	author = {Chi Harold Liu and
                  Yu Wang and
                  Chengzhe Piao and
                  Zipeng Dai and
                  Ye Yuan and
                  Guoren Wang and
                  Dapeng Wu},
	title = {Time-Aware Location Prediction by Convolutional Area-of-Interest Modeling
                  and Memory-Augmented Attentive {LSTM} (Extended abstract)},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3861--3862},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00357},
	doi = {10.1109/ICDE55515.2023.00357},
	timestamp = {Tue, 07 May 2024 20:05:36 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Liu0PD0W023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Personalized location prediction is key to many mobile applications and services. In this paper, motivated by both statistical and visualized preliminary analysis on three real datasets, we observe a strong spatiotemporal correlation for user trajectories among the visited area-of-interests (AoIs) and different time periods on both weekly and daily basis, which directly motivates our time-aware location prediction model design called "t-LocPred". It models the spatial correlations among AoIs by coarse-grained convolutional processing of the user trajectories in AoIs of different time periods ("ConvAoI"); and predicts his/her fine-grained next visited PoI using a novel memory-augmented attentive LSTM model ("mem-attLSTM") to capture long-term behavior patterns. Experimental results show that t-LocPred outperforms 8 baselines. We also show the impact of hyperparameters and the benefits ConvAoI can bring to these baselines.}
}


@inproceedings{DBLP:conf/icde/UngerT23,
	author = {Moshe Unger and
                  Alexander Tuzhilin},
	title = {Hierarchical Contextual Embeddings for Context-Aware Recommendations
                  (Extended Abstract)},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3863--3864},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00358},
	doi = {10.1109/ICDE55515.2023.00358},
	timestamp = {Sat, 30 Sep 2023 09:44:51 +0200},
	biburl = {https://dblp.org/rec/conf/icde/UngerT23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recommender systems (RSs) have become one of the major applications that aim to tailor items to the user’s preferences. Traditional recommendation algorithms capture users’ interests and their interactions with items without taking into account contextual information, such as time and location. However, user interests may change depending on the context [1] . In real-life applications, there is plenty of information regarding user’s circumstances and surroundings (e.g., the activity of the user, time, location, weather, etc.). Such contextual information can be high-dimensional and is gathered from multiple sources, such as web pages, mobile devices, and more. RSs taking context information into account are called context-aware recommender systems (CARSs) [1] .}
}


@inproceedings{DBLP:conf/icde/Wang0QZ23,
	author = {Qunbo Wang and
                  Wenjun Wu and
                  Yuxing Qi and
                  Yongchi Zhao},
	title = {Deep Bayesian Active Learning for Learning to Rank: {A} Case Study
                  in Answer Selection (Extended Abstract)},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3865--3866},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00359},
	doi = {10.1109/ICDE55515.2023.00359},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Wang0QZ23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Active learning can select informative data for model training to reduce the amount of labelling efforts required. Because traditional active learning methods cannot be directly used for deep learning, researchers have proposed multiple deep active learning methods. However, none of the previous research efforts on deep active learning algorithms presents a specific framework for learning-to-rank tasks. In this work, we introduce a novel deep active learning framework based on Deep Expected Loss Optimization (DELO) for the answer selection task.}
}


@inproceedings{DBLP:conf/icde/FangZSW23,
	author = {Wei Fang and
                  Qiang Zhang and
                  Jun Sun and
                  Xiaojun Wu},
	title = {Mining High Quality Patterns Using Multi-Objective Evolutionary Algorithm
                  (Extended Abstract)},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3867--3868},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00360},
	doi = {10.1109/ICDE55515.2023.00360},
	timestamp = {Sun, 06 Oct 2024 21:04:57 +0200},
	biburl = {https://dblp.org/rec/conf/icde/FangZSW23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Most studies on pattern mining have considered only one pattern, such as frequent pattern or high-utility pattern, which is difficult to meet the increasingly diverse needs of users. In this paper, a novel multi-objective problem model for high quality pattern mining (HQPM) is proposed, where the objectives are support, occupancy, and utility. In order to solve the proposed three-objective problem efficiently, an improved multi-objective evolutionary algorithm for HQPM (MOEA-PM) is proposed with two kinds of population initialization strategies and an auxiliary tool. Experimental results on real-world datasets show that the proposed three-objective problem model with the MOEA-PM algorithm can discover patterns that are both frequently occurring and has a high utility in the transaction datasets, while at the same time being relatively complete. The proposed algorithm outperforms the state-of-the-art in terms of efficiency, quality, and convergence speed.}
}


@inproceedings{DBLP:conf/icde/ZhangHT23,
	author = {Tianru Zhang and
                  Andreas Hellander and
                  Salman Toor},
	title = {Efficient Hierarchical Storage Management Empowered by Reinforcement
                  Learning Extended Abstract},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3869--3870},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00361},
	doi = {10.1109/ICDE55515.2023.00361},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhangHT23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the rapid development of big data and cloud computing, data management has become increasingly challenging. A possible solution is to use an intelligent hierarchical (multi-tier) storage system (HSS). An HSS is a meta solution that consists of different storage frameworks organized as a jointly constructed storage pool. A built-in data migration policy that determines the optimal placement of the datasets in the hierarchy is essential. Placement decisions are a non-trivial task since they should be made according to the characteristics of the dataset, the tier status in a hierarchy, and access patterns. This paper presents an open-source hierarchical storage framework with a dynamic migration policy based on reinforcement learning (RL).}
}


@inproceedings{DBLP:conf/icde/GuanZLGHF23,
	author = {Renchu Guan and
                  Hao Zhang and
                  Yanchun Liang and
                  Fausto Giunchiglia and
                  Lan Huang and
                  Xiaoyue Feng},
	title = {Deep Feature-Based Text Clustering and Its Explanation},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3871--3872},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00362},
	doi = {10.1109/ICDE55515.2023.00362},
	timestamp = {Mon, 14 Aug 2023 14:58:11 +0200},
	biburl = {https://dblp.org/rec/conf/icde/GuanZLGHF23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Text clustering is a critical step in text data analysis and has been extensively studied by the text mining community. Most existing text clustering algorithms are based on the bag-of-words model, which faces the high-dimensional and sparsity problems and ignores text structural and sequence information. Deep learning-based models such as convolutional neural networks and recurrent neural networks regard texts as sequences but lack supervised signals and explainable results. In this paper, we propose a deep feature-based text clustering (DFTC) framework that incorporates pretrained text encoders into text clustering tasks. This model, which is based on sequence representations, breaks the dependency on supervision. The experimental results show that our model outperforms classic text clustering algorithms on almost all the considered datasets. In addition, the explanation of the clustering results is significant for understanding the principles of the deep learning approach. Our proposed clustering framework includes an explanation module that can help users understand the meaning and quality of the clustering results. Our code is available at https://github.com/KEAML-JLU/DeepTextClustering.}
}


@inproceedings{DBLP:conf/icde/PengR0N23,
	author = {Bo Peng and
                  Zhiyun Ren and
                  Srinivasan Parthasarathy and
                  Xia Ning},
	title = {{HAM:} Hybrid Associations Models for Sequential Recommendation (Extended
                  abstract)},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3873--3874},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00363},
	doi = {10.1109/ICDE55515.2023.00363},
	timestamp = {Wed, 10 Jan 2024 22:27:39 +0100},
	biburl = {https://dblp.org/rec/conf/icde/PengR0N23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Sequential recommendation aims to identify and recommend the next few items of users’ interest. It becomes an effective tool to help users select their favorite items from a variety of options. A key challenge in sequential recommendation is to learn the patterns and dynamics, which are most pertinent to inform future interactions of users. With the prosperity of deep learning, many deep models, particularly based on recurrent neural networks [1] and with attention mechanisms [2] , [3] , have been developed for sequential recommendation purposes. However, our analysis demonstrates that, these deep models, particularly those with attention mechanisms, may not always learn meaningful attention weights from the extremely sparse recommendation data, and thus, could degrade the recommendation performance. Therefore, in this study, instead of deep models, we develop novel, effective and efficient hybrid associations models (HAM) to better learn from the sparse and limited recommendation data. This study has been published in IEEE Transactions on Knowledge and Data Engineering. Please refer to the full manuscript [4] for more details.}
}


@inproceedings{DBLP:conf/icde/CuiAM0H23,
	author = {Laizhong Cui and
                  Sudipta Acharya and
                  Sumit Mishra and
                  Yi Pan and
                  Joshua Zhexue Huang},
	title = {MMCo-Clus - An Evolutionary Co-clustering Algorithm for Gene Selection
                  (Extended abstract)},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3875--3876},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00364},
	doi = {10.1109/ICDE55515.2023.00364},
	timestamp = {Tue, 07 May 2024 20:05:37 +0200},
	biburl = {https://dblp.org/rec/conf/icde/CuiAM0H23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Dimensionality reduction through feature selection becomes inevitable to overcome the problem of the Curse of dimensionality. In this article, we propose a feature (gene) selection method for high dimensional gene expression (GE) data through a Multi-objective optimization-based Multi-view Co-Clustering algorithm (named MMCo-Clus). A thorough comparative analysis with existing feature selection algorithms using external/internal evaluation metrics supports our proposed method’s potency.}
}


@inproceedings{DBLP:conf/icde/LiangDLX0KW23,
	author = {Meiyu Liang and
                  Junping Du and
                  Linghui Li and
                  Zhe Xue and
                  Xiaoxiao Wang and
                  Feifei Kou and
                  Xu Wang},
	title = {Video Super-Resolution Reconstruction Based on Deep Learning and Spatio-Temporal
                  Feature Self-similarity (Extended abstract)},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3877--3878},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00365},
	doi = {10.1109/ICDE55515.2023.00365},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LiangDLX0KW23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Video super-resolution (SR) reconstruction technology aims at obtaining high quality reconstruction of high-resolution (HR) video sequences by inferring the lost detailed information from their low-resolution (LR) counterparts. However, this technology is an ill-posed problem because significant detailed information is lost in the process of video degrading. The existing learning-based SR reconstruction methods can be adapted to a larger super-resolution factor, but it cannot be guaranteed that any low-resolution image block can find its corresponding high-resolution block matching in a limited-scale training set. Some noise and over smooth phenomenon usually exist while dealing with some unique features that rarely appear in a given training data set. The self-similarity based SR methods do not rely on accurate sub-pixel motion estimation and thus can be adapted to complex motion patterns. However, under conditions of insufficient internal similar blocks, some visual flaws are usually produced due to the mismatched internal instances.}
}


@inproceedings{DBLP:conf/icde/ChrpaBVV23,
	author = {Luk{\'{a}}s Chrpa and
                  Roman Bart{\'{a}}k and
                  Jindrich Vodr{\'{a}}zka and
                  Marta Vomlelov{\'{a}}},
	title = {Attributed Transition-Based Domain Control Knowledge for Domain-Independent
                  Planning (Extended Abstract)},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3879--3880},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00366},
	doi = {10.1109/ICDE55515.2023.00366},
	timestamp = {Sun, 06 Oct 2024 21:04:56 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ChrpaBVV23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This extended abstract from the area of automated planning discusses work on Attributed Transition-Based Domain Control Knowledge (ATB-DCK). ATB-DCK, roughly speaking, represents the "grammar" of solution plans that guides the search. ATB-DCK is expressed by a finite state automaton with attributed states, referring to specific states of objects, connected by transitions imposing constraints on action applicability. This representation stays on side of the planning domain model, but it can be compiled into a classical planning task and thus it complements domain-independent planning techniques. Results on several benchmark domains from the International Planning Competitions show that the use of ATB-DCK often considerably improves efficiency of existing state-of-the-art planning engines.}
}


@inproceedings{DBLP:conf/icde/YuW23,
	author = {Yun William Yu and
                  Griffin M. Weber},
	title = {HyperMinHash: MinHash in LogLog Space (Extended Abstract)},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3881--3882},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00367},
	doi = {10.1109/ICDE55515.2023.00367},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/YuW23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this extended abstract, we describe and analyze a lossy compression of MinHash from buckets of size O(log n) to buckets of size O(log log n) by encoding using floating-point notation. This new compressed sketch, which we call HyperMinHash, as we build off a HyperLogLog scaffold, can be used as a drop-in replacement of MinHash. Unlike comparable Jaccard index fingerprinting algorithms in sub-logarithmic space (such as b-bit MinHash), HyperMinHash retains MinHash’s features of streaming updates, unions, and cardinality estimation. For an additive approximation error ϵ on a Jaccard index t, given a random oracle, HyperMinHash needs\nO(\n∈\n−2\n(loglogn+log\n1\n∈\n))\nspace. HyperMinHash allows estimating Jaccard indices of 0.01 for set cardinalities on the order of 10 19 with relative error of around 10% using 2MiB of memory; MinHash can only estimate Jaccard indices for cardinalities of 10 10 with the same memory consumption.}
}


@inproceedings{DBLP:conf/icde/SongGZ023,
	author = {Yang Song and
                  Yu Gu and
                  Rui Zhang and
                  Ge Yu},
	title = {BrePartition: Optimized High-Dimensional kNN Search with Bregman Distances
                  (Extended Abstract)},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3883--3884},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00368},
	doi = {10.1109/ICDE55515.2023.00368},
	timestamp = {Tue, 15 Aug 2023 12:13:06 +0200},
	biburl = {https://dblp.org/rec/conf/icde/SongGZ023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Bregman distances (also known as Bregman divergences) are widely used in machine learning, speech recognition and signal processing, and kNN searches with Bregman distances have become increasingly important with the rapid advances of multimedia applications. Data in multimedia applications such as images and videos are commonly transformed into space of hundreds of dimensions. Such high-dimensional space has posed significant challenges for existing kNN search algorithms with Bregman distances, which could only handle data of medium dimensionality (typically less than 100). This paper addresses the urgent problem of high-dimensional kNN search with Bregman distances. We propose a novel partition-filter-refinement framework. Specifically, we propose an optimized dimensionality partitioning scheme to solve several non-trivial issues. First, an effective bound from each partitioned subspace to obtain exact kNN results is derived. Second, we conduct an in-depth analysis of the optimized number of partitions and devise an effective strategy for partitioning. Third, we design an efficient integrated index structure for all the subspaces together to accelerate the search processing. Moreover, we extend our exact solution to an approximate version by a trade-off between the accuracy and efficiency. Experimental results on four real-world datasets and two synthetic datasets show the clear advantage of our method in comparison to state-of-the-art algorithms.}
}


@inproceedings{DBLP:conf/icde/HanCT0W23,
	author = {Chao Han and
                  Jian Chen and
                  Mingkui Tan and
                  Michael K. Ng and
                  Qingyao Wu},
	title = {A Tensor-based Markov Chain Model for Heterogeneous Information Network
                  Collective Classification : Extended abstract},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3885--3886},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00369},
	doi = {10.1109/ICDE55515.2023.00369},
	timestamp = {Wed, 28 Aug 2024 21:53:50 +0200},
	biburl = {https://dblp.org/rec/conf/icde/HanCT0W23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Heterogeneous Information Network(HIN) collective classification aims to classify one type of node, which is associated with multiple types of nodes through multiple types of relations. Previous studies have revealed that exploiting the relative importance of relation types is quite useful for improving node classification performance. We propose a Tensor-based Markov chain (T-Mark) model to improve the nodes classification accuracy by predicting the labels for unlabeled nodes and the importance ranking of relationship types automatically and simultaneously. Specifically, we build two tensor equations according to the HIN structure and content similarities among nodes of both labeled and unlabeled data. Consequently, We solve the semi-supervised T-Mark model by using an iterative process until obtaining two stationary distributions for labels and relation types. Experimental results on several real-world datasets demonstrate the effectiveness of T-Mark.}
}


@inproceedings{DBLP:conf/icde/MrabahBK23,
	author = {Nairouz Mrabah and
                  Mohamed Bouguessa and
                  Riadh Ksantini},
	title = {Adversarial Deep Embedded Clustering: On a better trade-off between
                  Feature Randomness and Feature Drift (Extended abstract)},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3887--3888},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00370},
	doi = {10.1109/ICDE55515.2023.00370},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/MrabahBK23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Deep clustering models are trained based on self-supervision and pseudo-supervision. However, applying these techniques can cause Feature Randomness and Feature Drift. On one hand, Feature Randomness takes place when a considerable portion of the pseudo-labels do not match the true ones. On the other hand, Feature Drift takes place when there is a strong con-flict between the self-supervision and pseudo-supervision tasks. We propose ADEC (Adversarial Deep Embedded Clustering) a novel autoencoder-based clustering model, which relies on a discriminator network to reduce random features while avoiding the drifting effect. Experimental results validate that our model alleviates these problems and outperforms existing methods.}
}


@inproceedings{DBLP:conf/icde/LiH23,
	author = {Lusi Li and
                  Haibo He},
	title = {Bipartite Graph based Multi-view Clustering (Extended Abstract)},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3889--3890},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00371},
	doi = {10.1109/ICDE55515.2023.00371},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LiH23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In existing graph-based multi-view clustering algorithms, consensus cluster structures are explored by constructing similarity graphs of multiple views and then fusing them into a unified superior graph. However, they overlook consensus information when learning each graph independently, resulting in the undesirable unified graph with biases. To this end, we proposed a framework named bipartite graph based multi-view clustering (BIGMC) in [1] to tackle this challenge. To summarize, the key idea of BIGMC is to employ a small number of uniform anchors to represent the consensus information across views. In this way, BIGMC creates a bipartite graph between data points and anchors for each view, which are then fused to generate a unified bipartite graph. The unified graph would in turn improve each view bipartite graph and the anchor set. Finally, the clusters are formed directly using the unified graph. In this extended abstract, we also summarize the effectiveness of BIGMC as shown in experimental results originally presented in [1].}
}


@inproceedings{DBLP:conf/icde/MrabahBTK23,
	author = {Nairouz Mrabah and
                  Mohamed Bouguessa and
                  Mohamed Fawzi Touati and
                  Riadh Ksantini},
	title = {Rethinking Graph Auto-Encoder Models for Attributed Graph Clustering
                  (Extended abstract)},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3891--3892},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00372},
	doi = {10.1109/ICDE55515.2023.00372},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/MrabahBTK23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recent graph clustering methods have resorted to Graph Auto-Encoders (GAEs). However, two important issues have been overlooked. First, the accumulative error, inflicted by learning from noisy clustering assignments, degrades the model’s effectiveness. This problem is called Feature Randomness (FR). Second, reconstructing the adjacency matrix sets the model to learn irrelevant similarities for the clustering task. This problem is called Feature Drift (FD). To address these issues, we first propose a sampling operator that triggers a protection mechanism against FR. second, we propose an operator Υ that triggers a correction mechanism against FD by transforming the reconstructed graph. Experimental results validate that our operators alleviate these problems and bring significant clustering improvement.}
}


@inproceedings{DBLP:conf/icde/Shan0Z23,
	author = {Zhangqing Shan and
                  Weiwei Sun and
                  Baihua Zheng},
	title = {Extract Human Mobility Patterns Powered by City Semantic Diagram :
                  Extended Abstract},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3893--3894},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00373},
	doi = {10.1109/ICDE55515.2023.00373},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Shan0Z23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With widespread deployment of GPS devices, massive spatiotemporal trajectories became more accessible. This booming trend paved the solid data ground for researchers to discover the regularities or patterns of human mobility. However, there are still three challenges in semantic pattern extraction including semantic absence, semantic bias and semantic complexity. We invent and apply a novel data structure namely City Semantic Diagram to overcome above three challenges. First, our approach resolves semantic absence by exactly identifying semantic behaviours from raw trajectories. Second, the design of semantic purification helps us to detect semantic complexity from human mobility. Third, we avoid semantic bias using objective data source such as ubiquitous GPS trajectories.}
}


@inproceedings{DBLP:conf/icde/NosratiC23,
	author = {Masoud Nosrati and
                  Ying Cai},
	title = {Verifying the Correctness of Analytic Query Results (Extended Abstract)},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3895--3896},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00374},
	doi = {10.1109/ICDE55515.2023.00374},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/NosratiC23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This research studies the problem of enabling users to verify that the results of analytical queries such as top k they receive from a potentially untrustworthy cloud are indeed correct. Existing work shows that it is possible for a data owner to create an authentication data structure (ADS) by which a cloud can build a verification object (VO) to prove the correctness of a query result. The current technique, however, has largely ignored the computation cost in VO construction and query result verification. In this paper, we extend and integrate Intersection tree (I-tree) and Merkle hash-tree (MH-tree) to develop a new ADS called Intersection Function Merkle Hash-tree (IFMH-tree). We propose two versions of the IFMH-tree, one-signature and multi-signature, and study their performance in supporting three representative types of analytic queries, including top-k, range, and KNN queries. Our results show that the new technique outperforms the existing solution to a large extent.}
}


@inproceedings{DBLP:conf/icde/0001CQHMS23,
	author = {Jens Dietrich and
                  Lijun Chang and
                  Long Qian and
                  Lyndon M. Henry and
                  Catherine McCartin and
                  Bernhard Scholz},
	title = {Efficient Sink-Reachability Analysis via Graph Reduction (Extended
                  Abstract)},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3897--3898},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00375},
	doi = {10.1109/ICDE55515.2023.00375},
	timestamp = {Sat, 30 Sep 2023 09:44:49 +0200},
	biburl = {https://dblp.org/rec/conf/icde/0001CQHMS23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We study a variation of the elementary graph reachability problem, called the sink-reachability problem, which can be found in many applications such as static program analysis, social network analysis, large scale web graph analysis, XML document link path analysis, and the study of gene regulation relationships. To scale sink-reachablity analysis to large graphs, we develop a highly scalable sink-reachability preserving graph reduction strategy for input sink graphs, by using a composition framework. That is, individual sink-reachability preserving condensation operators, each running in linear time, are pipelined together to produce graph reduction algorithms that result in close to maximum reduction, while keeping the computation efficient. Experiments on large real-world sink graphs demonstrate that our compositional approach achieves a reduction rate of up to 99.74% for vertices and a rate of up to 99.46% for edges.}
}


@inproceedings{DBLP:conf/icde/PuL0Q23,
	author = {Cunlai Pu and
                  Jie Li and
                  Jian Wang and
                  Tony Q. S. Quek},
	title = {The Node-Similarity Distribution of Complex Networks and Its Applications
                  in Link Prediction (Extended Abstract)},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3899--3900},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00376},
	doi = {10.1109/ICDE55515.2023.00376},
	timestamp = {Mon, 05 Feb 2024 20:31:11 +0100},
	biburl = {https://dblp.org/rec/conf/icde/PuL0Q23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Node-similarity distributions not only characterize different types of complex networks, but also offer insights in the structural predictability of complex networks, and even facilitate prediction tasks in complex networks. By means of the generating function, we propose a framework to calculate the common neighbor based similarity (CNS) distributions, offering theoretical results of similarity distributions of various complex networks. Furthermore, we apply node-similarity distributions to link prediction, a key task in network analysis. Specifically, by deriving analytical solutions for two metrics: i) precision and ii) area under the receiver operating characteristic curve (AUC), we give theoretical evaluation of link prediction. Also, by analyzing i) the expected prediction accuracy of similarity scores and ii) optimal prediction priority of unconnected node pairs, we optimize link prediction with similarity distributions. Simulation results confirm our findings and also validate the proposed methods for evaluating and optimizing link prediction.}
}


@inproceedings{DBLP:conf/icde/ZhouCLS23,
	author = {Xuanhe Zhou and
                  Chengliang Chai and
                  Guoliang Li and
                  Ji Sun},
	title = {Database Meets Artificial Intelligence: {A} Survey (Extended Abstract)},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3901--3902},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00377},
	doi = {10.1109/ICDE55515.2023.00377},
	timestamp = {Wed, 28 Feb 2024 00:16:39 +0100},
	biburl = {https://dblp.org/rec/conf/icde/ZhouCLS23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Database and Artificial Intelligence (AI) can benefit from each other. On one hand, AI can make database more intelligent (AI4DB). It is challenging for empirical database optimization techniques (e.g., configuration tuning, query optimization) to meet the high-performance requirement for large-scale database instances, various applications, diversified users. Learning-based techniques can alleviate this problem by exploring high-quality optimization strategies and reusing the historical data/models. On the other hand, database techniques can optimize AI models (DB4AI). AI is hard to deploy in real applications, because it requires developers to write complex codes and train complicated models. Database techniques can be used to reduce the complexity of using AI models, accelerate AI algorithms and provide AI capability inside databases. Thus, both DB4AI and AI4DB have been extensively studied recently.}
}


@inproceedings{DBLP:conf/icde/Lee23,
	author = {Youjin Lee},
	title = {Data Additive Residual Learning based Yield Prediction for Semiconductor
                  Manufacturing},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3903--3907},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00378},
	doi = {10.1109/ICDE55515.2023.00378},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Lee23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In semiconductor manufacturing, yield prediction and yield-related factor detection are critical. Various process data are analyzed to predict the yield and discover the causes of yield lowering and enhancement. Based on the growing field of artificial intelligence, studies have been carried out to improve the efficiency and accuracy of yield analysis by applying machine learning. In empirical eases, engineers continue to add suitable data for the problem, so we suggest modeling that can add the appropriate data sequentially. Based on the ideas of the boosting algorithm, the added data is used to estimate the residual in the existing model. The proposed method is applied to actual industrial data to demonstrate the practical application and improvements in yield prediction. Various optimization procedures are conducted in the modeling process, including those for the base model, the shrink rate, the number of iterations, and the order of dataset addition. The best model of three rounds with a shrink rate of 0.9 showed the minimum mean absolute error value of 0.497. The proposed approach improves prediction accuracy and various attempts for optimization will be the cornerstone of data additive residual learning.}
}


@inproceedings{DBLP:conf/icde/Liang23,
	author = {Shuang Liang},
	title = {Knowledge Graph Embedding Based on Graph Neural Network},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3908--3912},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00379},
	doi = {10.1109/ICDE55515.2023.00379},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Liang23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The representation of semantic information pertaining to the real world has been active research for some time now. Among the available methods, knowledge graphs have emerged as a widely accepted approach. Meanwhile, graph neural networks (GNNs) have demonstrated excellent performance in embedding graph-based information. Given the natural graph structure of knowledge graphs, employing GNNs to embed them is expected to yield a more interpretable and trustworthy representation of the learned knowledge. In this paper, we propose three customized GNNs for different scenarios of knowledge graph representation, including traditional, multimodal, and uncertain knowledge graphs. In the traditional knowledge graph scenario, we present a graph self-supervised learning method, named deep relation graph infomax (DRGI), which incorporates both the complete graph structure information and semantic information. In the multimodal knowledge graph scenario, we introduce a novel network, named hyper-node relational graph attention network (HRGAT), which combines different modal information with graph structure information for a more precise representation of multimodal knowledge graphs. In the uncertain knowledge graph scenario, we define a novel message-passing paradigm with box embedding, named box graph neural network (BGNN). BGNN leverages both the graph structure information of uncertain knowledge graphs and the probabilistic semantics of box embedding. To validate the effectiveness of our proposed methods, we conduct a series of experiments and report the results. We also discuss possible future work in GNN-based knowledge graph embedding.}
}


@inproceedings{DBLP:conf/icde/Lassig23,
	author = {Nico L{\"{a}}ssig},
	title = {Towards an AutoML System for Fair Classifications\({}^{\mbox{{\({_\ast}\)}}}\)},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3913--3917},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00380},
	doi = {10.1109/ICDE55515.2023.00380},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Lassig23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Machine learning (ML) models are frequently used for decision support. Typically, ML approaches are able to give decisions in an efficient way. They are mainly used to optimize prediction accuracy. However, from a legal and ethical standpoint, performing fair predictions should also be aimed for in a variety of applications. Unfair training datasets are a main reason that causes discrimination in supervised learning. If models are trained on unfair datasets, while ignoring underlying discrimination, they will learn to discriminate towards people of specific gender or ethnicity. In recent years, many different notions of fairness, algorithms, and systems have emerged to tackle the issue for different types of decision support problems, like classification, regression, or ranking.This paper presents ongoing and planned research to further advance this research field. First, we introduce a novel fairness definition called local fairness. It unifies ideas of both (global) group and individual fairness. Next, we summarize our initial FALCES system framework that aims at improving local fairness in classification problems without compromising accuracy. To cover realistic practical applications, improvements on both efficiency and effectiveness have been introduced, resulting in the FALCC system framework. This framework also paves the way towards a simplified configuration of the overall system. In the future, we plan to investigate how to make the system auto-configurable, leveraging AutoML techniques.}
}


@inproceedings{DBLP:conf/icde/Lenzi23,
	author = {Emilia Lenzi},
	title = {{INTERPRET:} An INtegrated and adapTive framEwoRk to support Policy-makers
                  in the urban EnvironmenT},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3918--3922},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00381},
	doi = {10.1109/ICDE55515.2023.00381},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Lenzi23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The city, as a hub of human activity, represents a crucial investigation field for data-driven decision making. The main goal of my PhD project is to formalize a methodology to guide and describe the entire analysis of the built environment from a sustainability perspective, achieving a better integration of the available data with respect to already existing smart city models. Using an interdisciplinary approach, we aim to: automatize data collection and cleaning; create a conceptual model to represent data characterizing the city structure and performance; use this model to enable integration and analysis of the collected data using data exploration and mining techniques.}
}


@inproceedings{DBLP:conf/icde/Nikookar23,
	author = {Sepideh Nikookar},
	title = {Human-AI Complex Task Planning},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3923--3927},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.00382},
	doi = {10.1109/ICDE55515.2023.00382},
	timestamp = {Thu, 27 Jul 2023 17:17:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Nikookar23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The process of complex task planning is ubiquitous and arises in a variety of compelling applications. A few leading examples include designing a personalized course plan or trip plan, designing music playlists/work sessions in web applications, or even planning routes of naval assets to collaboratively discover an unknown destination. For all of these aforementioned applications, creating a plan requires satisfying a basic construct, i.e., composing a sequence of sub-tasks (or items) that optimizes several criteria and satisfies constraints. For instance, in course planning, sub-tasks or items are core and elective courses, and degree requirements capture their complex dependencies as constraints. In trip planning, sub-tasks are points of interests (POIs) and constraints represent time and monetary budget, or user-specified requirements. Needless to say, task plans are to be individualized and designed considering uncertainty. When done manually, the process is human-intensive and tedious, and unlikely to scale. The goal of my research is to present computational frameworks that synthesize the capabilities of human and AI algorithms to enable task planning at scale while satisfying multiple objectives and complex constraints.I present a set of computational frameworks for automated task planning as a sequence generation problem that requires minimal inputs from the end users and produces personalized task plans in an uncertain environment while satisfying multiple objectives and complex constraints. At the core, I propose a set of multi-objective optimization problems with constraints, solving which will generate task plans as a sequence of sub-tasks that are highly dependent and optimize the underlying problems. From the algorithmic standpoint, I design novel algorithms by adapting Reinforcement Learning (RL) and discrete optimization-based techniques with theoretical guarantees. I also study data engineering and data management opportunities to design scalable algorithms. Finally, I provide large-scale synthetic and real-world experiments, as well as deployment challenges in the real-world environment.}
}


@inproceedings{DBLP:conf/icde/XuZXXLCD23,
	author = {Derong Xu and
                  Jingbo Zhou and
                  Tong Xu and
                  Yuan Xia and
                  Ji Liu and
                  Enhong Chen and
                  Dejing Dou},
	title = {Multimodal Biological Knowledge Graph Completion via Triple Co-Attention
                  Mechanism},
	booktitle = {39th {IEEE} International Conference on Data Engineering, {ICDE} 2023,
                  Anaheim, CA, USA, April 3-7, 2023},
	pages = {3928--3941},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/ICDE55515.2023.10231041},
	doi = {10.1109/ICDE55515.2023.10231041},
	timestamp = {Wed, 27 Dec 2023 10:43:34 +0100},
	biburl = {https://dblp.org/rec/conf/icde/XuZXXLCD23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Biological Knowledge Graphs (BKGs) can help to model complex biological systems in a structural way to support various tasks. Nevertheless, the incompleteness problem may limit the performance of existing BKGs, which still deserves new methods to reveal the missing relations. Though great efforts have been made to knowledge graph completion, existing methods are not easy to be adapted to the multimodal biological information such as molecular structures and textual descriptions. To this end, we propose a novel co-attention-based multimodal embedding framework, named CamE, for the multimodal BKG completion task. Specifically, we design a Triple Co-Attention (TCA) operator to capture and highlight the same semantic features among different modalities. Based on TCA, we further propose two components to handle multimodal fusion and multimodal entity-relation interaction, respectively. One is the multimodal TCA fusion module to achieve a multimodal joint representation for each entity in the BKG. It aims to project different modal information into a common space by capturing the same semantic features and overcoming the modality gap. The other is the relation-aware interactive TCA module to learn interactive representation by modelling the deep interaction between multimodal entities and relations. Extensive experiments on two real-world multimodal BKG datasets demonstrate that our method significantly outperforms several state-of-the-art baselines, including 10.3% and 16.2% improvement w.r.t MRR and Hits@1 metrics over its best competitors on public DRKG-MM dataset.}
}
