@inproceedings{DBLP:conf/icde/GantiO024,
	author = {Manasi Ganti and
                  Laurel J. Orr and
                  Sen Wu},
	title = {Evaluating Text-to-SQL Model Failures on Real-World Data},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {1},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00456},
	doi = {10.1109/ICDE60146.2024.00456},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/GantiO024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Text-to-SQL generation models, capable of converting natural language prompts into SQL queries, offer significant potential for streamlining data analytics tasks. Despite state-of-the-art performance on popular academic benchmarks such as Spider [1], recent large language models, such as GPT-4, exhibit a considerable performance degradation on real-world applications with longer, more convoluted schemas [2]. This disparity raises questions about what factors contribute to this drop and whether existing academic benchmarks are effective for representing real-world challenges. To determine these factors, we first examine Text-to-SQL model failures on customer logs. We find that accuracy on customer logs was on average 30% lower than accuracy on Spider. We identify three main challenges in real-world Text-to-SQL applications: long context length, unclear question formulation, and greater query complexity. With these insights, we create a new benchmark built from manually labeled customer logs and evaluate existing open source and private LLMs to demonstrate the impact of each factor on model performance. The benchmark incorporates 20 non-join queries and 30 join queries, each accompanied by three additional question phrasing variations, resulting in 200 queries total. To capture the effects of large schemas, we vary schema size from 5 to over 300 columns while retaining the minimum columns required to answer all questions. We assess the performance of prominent Text-to-SQL models, including GPT-4, GPT-3.5, BigCode's Starcoder [3], and NSQL Llama-2 [4] on both our benchmark and the Spider benchmark for comparative analysis. We use Spider execution accuracy to measure model performance. The evaluation results reveal a) A consistent decline in execution accuracy for longer schemas, dropping about 0.5 percentage points for every additional 10 columns, indicating that existing Text-to-SQL models struggle with progressively larger tables and schema lengths that are characteristic of real-world datasets, b) A decrease in execution accuracy of 12.3 points on average on questions that emulate real-world phrasing compared to questions phrased unambiguously based on academic benchmarks and c) An accuracy drop of an average of 36 and up to 52 points when models must reason over nested or complex queries compared to simple SELECT statements, with models commonly making errors interpreting column schemas correctly. Overall, accuracy drops when the complexity of queries or schemas increases from that of academic benchmarks. Our benchmark highlights this model performance disparity between enterprise and academic settings, emphasizing the need for improvements in handling long context tasks, generating complex queries, and increasing robustness against question ambiguity. We hope to encourage development of enterprise inspired benchmarks to better capture LLM performance in real-world scenarios.}
}


@inproceedings{DBLP:conf/icde/WangLXBDD24,
	author = {Sha Wang and
                  Yuchen Li and
                  Hanhua Xiao and
                  Zhifeng Bao and
                  Lambert Deng and
                  Yanfei Dong},
	title = {Enabling Roll-Up and Drill-Down Operations in News Exploration with
                  Knowledge Graphs for Due Diligence and Risk Management},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {1--7},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00400},
	doi = {10.1109/ICDE60146.2024.00400},
	timestamp = {Tue, 30 Jul 2024 08:18:19 +0200},
	biburl = {https://dblp.org/rec/conf/icde/WangLXBDD24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Efficient news exploration is crucial in real-world applications, particularly within the financial sector, where numerous control and risk assessment tasks rely on the analysis of public news reports. The current processes in this domain predominantly rely on manual efforts, often involving keyword-based searches and the compilation of extensive keyword lists. In this paper, we introduce NCEXPLORER, a framework designed with OLAP-like operations to enhance the news exploration experience. NCEXPLORER empowers users to use roll-up operations for a broader content overview and drill-down operations for detailed insights. These operations are achieved through integration with external knowledge graphs (KGs), encompassing both fact-based and ontology-based structures. This integration significantly augments exploration capabilities, offering a more comprehensive and efficient approach to unveiling the underlying structures and nuances embedded in news content. Extensive empirical studies through master-qualified evaluators on Amazon Mechanical Turk demonstrate NCEXPLORER'S superiority over existing state-of-the-art news search methodologies across an array of topic domains, using real-world news datasets.}
}


@inproceedings{DBLP:conf/icde/WangW0Z24,
	author = {Hanchen Wang and
                  Kai Wang and
                  Wenjie Zhang and
                  Ying Zhang},
	title = {Bipartite Graph Analytics: Current Techniques and Future Trends},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {1--7},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00405},
	doi = {10.1109/ICDE60146.2024.00405},
	timestamp = {Tue, 30 Jul 2024 08:18:21 +0200},
	biburl = {https://dblp.org/rec/conf/icde/WangW0Z24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As the field of data science continues to evolve, bipartite graphs have emerged as a fundamental structure in numerous applications, drawing significant interest from both academic and industrial communities. Bipartite graphs are a specific type of graph consisting of two distinct sets of vertices, where connections only occur between vertices of different sets. Examples include e-commerce networks and biological networks. Analytics of bipartite graphs has become an important research topic in the era of big data. This tutorial aims to shed light on analysis methods for bipartite graphs, categorizing them into three areas: classical models, learning-based models, and application-driven models. We start by outlining the importance of bipartite graph analytics, and the unique challenges that need to be addressed. Then, we conduct a thorough review of existing works on bipartite graph analytics. We also compare and analyze the models and solutions in these works. Finally, we point out new research directions.}
}


@inproceedings{DBLP:conf/icde/ZhouC024,
	author = {Lixi Zhou and
                  K. Sel{\c{c}}uk Candan and
                  Jia Zou},
	title = {DeepMapping: Learned Data Mapping for Lossless Compression and Efficient
                  Lookup},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {1--14},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00008},
	doi = {10.1109/ICDE60146.2024.00008},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhouC024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Storing tabular data to balance storage and query efficiency is a long-standing research question in the database community. In this work, we argue and show that a novel DeepMapping abstraction, which relies on the impressive memorization capabilities of deep neural networks, can provide better storage cost, better latency, and better run-time memory footprint, all at the same time. Such unique properties may benefit a broad class of use cases in capacity-limited devices. Our proposed DeepMapping abstraction transforms a dataset into multiple key-value mappings and constructs a multi-tasking neural network model that outputs the corresponding values for a given input key. To deal with memorization errors, DeepMapping couples the learned neural network with a lightweight auxiliary data structure capable of correcting mistakes. The auxiliary structure design further enables DeepMapping to efficiently deal with insertions, deletions, and updates even without retraining the mapping. We propose a multi-task search strategy for selecting the hybrid DeepMapping structures (including model architecture and auxiliary structure) with a desirable trade-off among memorization capacity, size, and efficiency. Extensive experiments with a real-world dataset, synthetic and benchmark datasets, including TPC-H and TPC-DS, demonstrated that the DeepMapping approach can better balance the retrieving speed and compression ratio against several cutting-edge competitors.}
}


@inproceedings{DBLP:conf/icde/RenFHHDHJZYW24,
	author = {Tonghui Ren and
                  Yuankai Fan and
                  Zhenying He and
                  Ren Huang and
                  Jiaqi Dai and
                  Can Huang and
                  Yinan Jing and
                  Kai Zhang and
                  Yifan Yang and
                  X. Sean Wang},
	title = {{PURPLE:} Making a Large Language Model a Better {SQL} Writer},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {15--28},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00009},
	doi = {10.1109/ICDE60146.2024.00009},
	timestamp = {Wed, 14 Aug 2024 08:20:47 +0200},
	biburl = {https://dblp.org/rec/conf/icde/RenFHHDHJZYW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Large Language Model (LLM) techniques play an increasingly important role in Natural Language to SQL (NL2SQL) translation. LLMs trained by extensive corpora have strong natural language understanding and basic SQL generation abilities without additional tuning specific to NL2SQL tasks. Existing LLMs-based NL2SQL approaches try to improve the translation by enhancing the LLMs with an emphasis on user intention understanding. However, LLMs sometimes fail to generate appropriate SQL due to their lack of knowledge in organizing complex logical operator composition. A promising method is to input the LLMs with demonstrations, which include known NL2SQL translations from various databases. LLMs can learn to organize operator compositions from the input demonstrations for the given task. In this paper, we propose PURPLE (Pre-trained models Utilized to Retrieve Prompts for Logical Enhancement), which improves accuracy by retrieving demonstrations containing the requisite logical operator composition for the NL2SQL task on hand, thereby guiding LLMs to produce better SQL translation. PURPLE achieves a new state-of-the-art performance of 80.5% exact-set match accuracy and 87.8% execution match accuracy on the validation set of the popular NL2SQL benchmark Spider. PURPLE maintains high accuracy across diverse benchmarks, budgetary constraints, and various LLMs, showing robustness and cost-effectiveness.}
}


@inproceedings{DBLP:conf/icde/0003YWLCMQ24,
	author = {Yi Wang and
                  Jianan Yuan and
                  Shangyu Wu and
                  Huan Liu and
                  Jiaxian Chen and
                  Chenlin Ma and
                  Jianbin Qin},
	title = {LeaderKV: Improving Read Performance of {KV} Stores via Learned Index
                  and Decoupled {KV} Table},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {29--41},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00010},
	doi = {10.1109/ICDE60146.2024.00010},
	timestamp = {Sun, 06 Oct 2024 21:04:56 +0200},
	biburl = {https://dblp.org/rec/conf/icde/0003YWLCMQ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Log-structured merge-tree (LSM-tree) is a storage architecture widely used in key-value (KV) stores. To enhance the read efficiency of LSM-tree, recent works utilize the learned index to learn the mapping between keys and locations. However, in existing learned-index-aided KV stores, inefficient design of the learned index and disk access significantly impact the read performance. How to design a learned KV store to improve index efficiency and minimize disk access remains a critical problem. This paper presents LeaderKV, a read-optimized LSM-tree-based KV store. LeaderKV employs decoupled KV tables (DK-Table) and efficient learned indexes for data retrieval. DKTables are storage files in Leader Kvbecause they avoid reading irrelevant data in collaboration with learned indexes during queries. A learned index called Leader is proposed to accelerate data retrieval within DKTable. Leader is composed of precise models and approximate models. A redirect mechanism is designed to reduce the cost of mispredictions in Leader. We integrate DKTable and Leader into LeaderKV and demonstrate its effectiveness using a variety of datasets and workloads. Experimental results show that LeaderKV significantly improves the read performance compared to representative schemes.}
}


@inproceedings{DBLP:conf/icde/Zhou0Z0W24,
	author = {Wei Zhou and
                  Chen Lin and
                  Xuanhe Zhou and
                  Guoliang Li and
                  Tianqing Wang},
	title = {{TRAP:} Tailored Robustness Assessment for Index Advisors via Adversarial
                  Perturbation},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {42--55},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00011},
	doi = {10.1109/ICDE60146.2024.00011},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Zhou0Z0W24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Many index advisors have recently been proposed to build indexes automatically to improve query performance. However, they mainly consider performance improvement in static scenarios. Their robustness, i.e., stable performance in dynamic scenarios (e.g., with minor workload changes), has not been well investigated. This paper addresses the challenges of assessing the index advisor's robustness from the following aspects. First, we introduce perturbation-based workloads for robustness assessment and identify three typical perturbation constraints that occur in real scenarios. Second, with the perturbation constraints, we formulate the generation of perturbed queries as a sequence-to-sequence problem and propose TRAP (Tailored Robustness assessment via Adversarial Perturbation) to pinpoint the performance loopholes of index advisors. Third, to generalize to various index advisors, we place TRAP in an opaque-box setting (i.e., with little knowledge of the index advisors' internal design), and we propose a two-phase training paradigm to efficiently train TRAP without elaborately annotated data. Fourth, we conduct comprehensive robustness assessments on standard benchmarks and real workloads for ten existing index advisors. Our findings reveal that these index advisors are vulnerable to the workloads generated by TRAP. Finally, based on the assessment results, we shed light on insights to enhance the robustness of different index advisors. For example, learning-based index advisors can benefit from adopting a fine-grained state representation and a candidate pruning strategy.}
}


@inproceedings{DBLP:conf/icde/ZhangWLLSYY24,
	author = {Kaixin Zhang and
                  Hongzhi Wang and
                  Yabin Lu and
                  Ziqi Li and
                  Chang Shu and
                  Yu Yan and
                  Donghua Yang},
	title = {Duet: Efficient and Scalable Hybrid Neural Relation Understanding},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {56--69},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00012},
	doi = {10.1109/ICDE60146.2024.00012},
	timestamp = {Mon, 02 Dec 2024 08:28:08 +0100},
	biburl = {https://dblp.org/rec/conf/icde/ZhangWLLSYY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Learned cardinality estimation methods have achieved high precision compared to traditional methods. Among learned methods, query-driven approaches have faced the work-load drift problem for a long time. Although both data-driven and hybrid methods are proposed to avoid this problem, most of them suffer from high training and estimation costs, limited scalability, instability, and long-tail distribution problems on high-dimensional tables, which seriously affects the practical application of learned cardinality estimators. In this paper, we prove that most of these problems are directly caused by the widely used progressive sampling. We solve this problem by introducing predicate information into the autoregressive model and propose Duet, a stable, efficient, and scalable hybrid method to estimate cardinality directly without sampling or any non-differentiable process, which can not only reduce the inference complexity from O(n)\nto O(1)\ncompared to Naru and UAE but also achieve higher accuracy on high cardinality and high-dimensional tables. Experimental results show that Duet can achieve all the design goals above and be much more practical. Besides, Duet even has a lower inference cost on CPU than that of most learned methods on GPU.}
}


@inproceedings{DBLP:conf/icde/ZhengLYLX24,
	author = {Juncheng Zheng and
                  Meiyu Liang and
                  Yang Yu and
                  Yawen Li and
                  Zhe Xue},
	title = {Knowledge Graph Enhanced Multimodal Transformer for Image-Text Retrieval},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {70--82},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00013},
	doi = {10.1109/ICDE60146.2024.00013},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhengLYLX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Image-text retrieval is a fundamental cross-modal task that aims to align the representation spaces between the image and text modalities. Existing cross-modal image-text retrieval methods independently generate embeddings for images and text, introduce interaction-based networks for cross-modal inference, and then achieve retrieval by using matching metrics. However, they overlook the semantic relationship between the coarse-grained and fine-grained representations within each modality, failing to capture the consistency of representations across different modalities, which affects the semantic learning of cross-modal representations, and makes it difficult to align modalities in semantic space. Consequently, these previous works inevitably suffer from low retrieval accuracy or high computational costs. In this paper, instead of directly fusing two cross-modal het-erogeneous spaces, we propose an multimodal knowledge enhanced multimodal transformer network framework to combine coarse-grained and fine-grained representation learning into a unified framework, capturing alignment information between targets, constructing a global semantic graph, and ultimately align multimodal representations in the semantic space. In our approach, images generate semantic and spatial graphs to represent visual information, while sentences generate text graphs based on semantic relationships between words, and they are used for intra-modal graph network inference. Subsequently, the generated global and local embeddings are fused into an enhanced multimodal transformer framework, effectively imple-menting cross-modal interaction processes by leveraging prior implicit semantic information from the multimodal knowledge graph. Furthermore, compared to simply matching words with image regions, our method proposes a bidirectional fine-grained matching method to filter the salient regions and words of images and texts, remove the interfering noise information, and realize bidirectional fine-grained pairing, which captures fine-grained bi-directional representational information, thus enable the model to generate more discriminative representations Finally, equipped with a coarse-to-fine inference method based on hybrid global and local cross-modal similarities, we demonstrate that the proposed method is able to significantly outperform existing state-of-the-art algorithms by evaluating our method using two widely-used datasets.}
}


@inproceedings{DBLP:conf/icde/YuePC0HZXY24,
	author = {Zhongwei Yue and
                  Shujian Peng and
                  Peng Cai and
                  Xuan Zhou and
                  Huiqi Hu and
                  Rong Zhang and
                  Quanqing Xu and
                  Chuanhui Yang},
	title = {Functionality-Aware Database Tuning via Multi-Task Learning},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {83--95},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00014},
	doi = {10.1109/ICDE60146.2024.00014},
	timestamp = {Thu, 08 Aug 2024 08:08:00 +0200},
	biburl = {https://dblp.org/rec/conf/icde/YuePC0HZXY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Functionalities of a database system are co-designed and jointly maintain the database performance. Each function-ality usually has its own metrics to evaluate its state. Previous knobs tuning methods regard the database system as a black box and aim to automatically find the optimal configurations by collecting and observing the overall performance data (e.g., transaction throughput per second) under various configuration knobs. However, if a functionality is not running in the tuning phase, its knobs irrelevant to performance changes can also be tuned by existing tools and potential risks would be introduced. To resolve this problem, we design a database knob tuning framework to support functionality-aware knobs tuning. It uses multitask learning to take the database overall performance as the objective of main learning task, and each function module as a separate learning task. This framework enhances the tuning results through learning the relationships between different tasks, and avoids adjusting irrelevant knobs by perceiving the status of functionalities. We validate its generalizability on OceanBase and PostgreSQL. Experimental results show that better performances were achieved on the overall performance and the metrics of various functionalities.}
}


@inproceedings{DBLP:conf/icde/HeinrichBKL24,
	author = {Roman Heinrich and
                  Carsten Binnig and
                  Harald Kornmayer and
                  Manisha Luthra},
	title = {Costream: Learned Cost Models for Operator Placement in Edge-Cloud
                  Environments},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {96--109},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00015},
	doi = {10.1109/ICDE60146.2024.00015},
	timestamp = {Sun, 06 Oct 2024 21:04:57 +0200},
	biburl = {https://dblp.org/rec/conf/icde/HeinrichBKL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this work, we present Costream, a novel learned cost model for Distributed Stream Processing Systems that provides accurate predictions of the execution costs of a streaming query in an edge-cloud environment. The cost model can be used to find an initial placement of operators across heterogeneous hardware, which is particularly important in these environments. In our evaluation, we demonstrate that Costream can produce highly accurate cost estimates for the initial operator placement and even generalize to unseen placements, queries, and hardware. When using Costream to optimize the placements of streaming operators, a median speedup of around 21 × can be achieved compared to baselines.}
}


@inproceedings{DBLP:conf/icde/ShankarB0C24,
	author = {Aditya Shankar and
                  Hans Brouwer and
                  Rihan Hai and
                  Lydia Y. Chen},
	title = {S i 1 o {F} use: Cross-silo Synthetic Data Generation with Latent
                  Tabular Diffusion Models},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {110--123},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00016},
	doi = {10.1109/ICDE60146.2024.00016},
	timestamp = {Sun, 06 Oct 2024 21:04:58 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ShankarB0C24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Synthetic tabular data is crucial for sharing and augmenting data across silos, especially for enterprises with proprietary data. However, existing synthesizers are designed for centrally stored data. Hence, they struggle with real-world scenarios where features are distributed across multiple silos, necessitating on-premise data storage. We introduce SiloFuse, a novel generative framework for high-quality synthesis from cross-silo tabular data. To ensure privacy, SiloFuse utilizes a distributed latent tabular diffusion architecture. Through autoencoders, latent representations are learned for each client's features, masking their actual values. We employ stacked dis-tributed training to improve communication efficiency, reducing the number of rounds to a single step. Under SiloFuse, we prove the impossibility of data reconstruction for vertically partitioned synthesis and quantify privacy risks through three attacks using our benchmark framework. Experimental results on nine datasets showcase SiloFuse's competence against centralized diffusion-based synthesizers. Notably, SiloFuse achieves 43.8 and 29.8 higher percentage points over GANs in resemblance and utility. Experiments on communication show stacked training's fixed cost compared to the growing costs of end-to-end training as the number of training iterations increases. Additionally, SiloFuse proves robust to feature permutations and varying numbers of clients.}
}


@inproceedings{DBLP:conf/icde/ShaoWZMZ24,
	author = {Xinyue Shao and
                  Hongzhi Wang and
                  Xiao Zhu and
                  Tianyu Mu and
                  Yan Zhang},
	title = {Explainable Database Management System Configuration Tuning through
                  Counterfactuals},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {124--137},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00017},
	doi = {10.1109/ICDE60146.2024.00017},
	timestamp = {Mon, 02 Dec 2024 08:28:09 +0100},
	biburl = {https://dblp.org/rec/conf/icde/ShaoWZMZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Data management system configuration optimization has been the focus of database-related research. It can improve the adaptability of DBMS to various business scenarios by selecting the right parameter combination. However, this has been a daunting task because of the vast number of configuration “knobs” involved, and the information about the effects of each knob usually comes from valuable experience, which is very labor-intensive. While machine learning techniques show promise in certain database tasks, they encounter challenges when applied to configuration optimization. Traditional machine learning models excel in prediction tasks through data fitting, but they lack direct applicability in configuration tuning. Moreover, the lack of explainability in machine learning poses a significant obstacle in quantifying the impact of individual knobs on the database performance. Affected by the above factors, this paper proposes CFTune, a method that can accurately evaluate the performance of a DBMS under each configuration using experience and achieve automatic DBMS configuration tuning with counterfactual techniques. Based on various optimization requirements, the approach can offer configuration tuning advice with minimal modification knobs for DBMS that perform badly under specified workloads. Furthermore, to address model shifts resulting from training data, we offer additional strategies to enhance the robustness of the tuning advice. The experimental results demonstrate that the CFTune effectively optimizes the configuration and enhances the performance.}
}


@inproceedings{DBLP:conf/icde/DuYW0L24,
	author = {Xingyu Du and
                  Gongsheng Yuan and
                  Sai Wu and
                  Gang Chen and
                  Peng Lu},
	title = {In Situ Neural Relational Schema Matcher},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {138--150},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00018},
	doi = {10.1109/ICDE60146.2024.00018},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/DuYW0L24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The scarcity of training data restricts a neural network from capturing schema diversity and intricacies, hindering schema-matching models' generalization capabilities. In this paper, we propose ISResMat, a framework specifically designed to match the schemas of relational tables by fine-tuning a pre-trained language model. We first offer a training data construction method, Pairwise Sampling, which could generate the training dataset with table data. Next, we design two loss functions (i.e., Meta-Matching Loss and Agent-Delegating Loss) to learn representations of table columns. With those representations, we could calculate matching scores between different table columns for deducing the matching candidates, which provides a novel approach to schema matching. Finally, we present two optimizations (i.e., Matching Rectification Loss and Distribution-Aware Fingerprint) to handle the problems of matching cardinality constraints and numerical columns, respectively. ISResMat is a flexible framework supporting instance-based, schema-based, and hybrid matching without significant modification. Experiments on 500+ fabricated and human-curated relation pairs spanning diverse domains and matching scenarios showcase that our approach outperforms existing state-of-the-art methods.}
}


@inproceedings{DBLP:conf/icde/FengL024,
	author = {Jieming Feng and
                  Zhanhuai Li and
                  Qun Chen},
	title = {Towards Exploratory Query Optimization for Template-Based {SQL} Workloads},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {151--164},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00019},
	doi = {10.1109/ICDE60146.2024.00019},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/FengL024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {SQL query optimization aims to choose an optimal Query Execution Plan (QEP) for a query. The existing optimizers usually choose the plan with the minimal execution cost. However, in some real scenarios (e.g., cloud OLAP), it is a business imperative to minimize the cost of an entire workload. Unfortunately, the greedy optimizers are prone to generating execution plans that are only suboptimal from the workload perspective. In this paper, we propose a novel QEP optimization approach for template-based SQL that aims to minimize the execution cost of an entire workload instead of individual queries. While choosing an execution plan for a query, the proposed approach considers a plan's impact on future query execution as well as its own execution cost. We first define an exploratory metric, Plan Exploration Value (PEV), to measure a plan's potential benefit to future query execution. Then, we model exploratory plan selection as an optimization problem with cost constraints, and present an efficient algorithm based on dynamic programming for its solution. Finally, we evaluate the performance of the proposed approach by a comparative study on benchmark workloads. Our extensive experiments have shown that it generates more efficient workload execution plans than the existing alternatives.}
}


@inproceedings{DBLP:conf/icde/LeeZYH0HL24,
	author = {Cheryl Lee and
                  Zhouruixin Zhu and
                  Tianyi Yang and
                  Yintong Huo and
                  Yuxin Su and
                  Pinjia He and
                  Michael R. Lyu},
	title = {{SPES:} Towards Optimizing Performance-Resource Trade-Off for Serverless
                  Functions},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {165--178},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00020},
	doi = {10.1109/ICDE60146.2024.00020},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LeeZYH0HL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As an emerging cloud computing deployment paradigm, serverless computing is gaining traction due to its efficiency and ability to harness on-demand cloud resources. However, a significant hurdle remains in the form of the cold start problem, causing latency when launching new function instances from scratch. Existing solutions tend to use over-simplistic strategies for function pre-loading/unloading without full invocation pattern exploitation, rendering unsatisfactory optimization of the trade-off between cold start latency and resource waste. To bridge this gap, we propose SPES, the first differentiated scheduler for runtime cold start mitigation by optimizing serverless function provision. Our insight is that the common architecture of serverless systems prompts the concentration of certain invocation patterns, leading to predictable invocation behaviors. This allows us to categorize functions and pre-load/unload proper function instances with finer-grained strategies based on accurate invocation prediction. Experiments demonstrate the success of SPES in optimizing serverless function provision on both sides: reducing the 75 th -percentile cold start rates by 49.77% and the wasted memory time by 56.43%, compared to the state-of-the-art. By mitigating the cold start issue, SPES is a promising advancement in facilitating cloud services deployed on serverless architectures.}
}


@inproceedings{DBLP:conf/icde/HelaliMVCHCAH024,
	author = {Mossad Helali and
                  Niki Monjazeb and
                  Shubham Vashisth and
                  Philippe Carrier and
                  Ahmed Helal and
                  Antonio Cavalcante and
                  Khaled Ammar and
                  Katja Hose and
                  Essam Mansour},
	title = {KGLiDS: {A} Platform for Semantic Abstraction, Linking, and Automation
                  of Data Science},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {179--192},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00021},
	doi = {10.1109/ICDE60146.2024.00021},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/HelaliMVCHCAH024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent years, we have witnessed the growing interest from academia and industry in applying data science technologies to analyze large amounts of data. In this process, a myriad of artifacts (datasets, pipeline scripts, etc.) are created. However, there has been no systematic attempt to holistically collect and exploit all the knowledge and experiences that are implicitly contained in those artifacts. Instead, data scientists recover information and expertise from colleagues or learn via trial and error. Hence, this paper presents a scalable platform, KGLiDS, that employs machine learning and knowledge graph technologies to abstract and capture the semantics of data science artifacts and their connections. Based on this information, KGLiDS enables various downstream applications, such as data discovery and pipeline automation. Our comprehensive evaluation covers use cases in data discovery, data cleaning, transformation, and AutoML. It shows that KGLiDS is significantly faster with a lower memory footprint than the state-of-the-art systems while achieving comparable or better accuracy.}
}


@inproceedings{DBLP:conf/icde/SantosKF24,
	author = {A{\'{e}}cio S. R. Santos and
                  Flip Korn and
                  Juliana Freire},
	title = {Efficiently Estimating Mutual Information Between Attributes Across
                  Tables},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {193--206},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00022},
	doi = {10.1109/ICDE60146.2024.00022},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/SantosKF24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Relational data augmentation is a powerful technique for enhancing data analytics and improving machine learning models by incorporating columns from external datasets. However, it is challenging to efficiently discover relevant external tables to join with a given input table. Existing approaches rely on data discovery systems to identify “joinable” tables from external sources, typically based on overlap or containment. However, the sheer number of tables obtained from these systems results in irrelevant joins that need to be performed; this can be computationally expensive or even infeasible in practice. We address this limitation by proposing the use of efficient mutual information (MI) estimation for finding relevant joinable tables. We introduce a new sketching method that enables efficient evaluation of relationship discovery queries by estimating MI without materializing the joins and returning a smaller set of tables that are more likely to be relevant. We also demonstrate the effectiveness of our approach at approximating MI in extensive experiments using synthetic and real-world datasets.}
}


@inproceedings{DBLP:conf/icde/ZhangYYSGW24,
	author = {Qifan Zhang and
                  Junjie Yao and
                  Yuquan Yang and
                  Yizhou Shi and
                  Wei Gao and
                  Xiaoling Wang},
	title = {Effective Entry-Wise Flow for Molecule Generation},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {207--220},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00023},
	doi = {10.1109/ICDE60146.2024.00023},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhangYYSGW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Molecule generation is a critical process in the fields of drug discovery and materials science. Recently, generative models based on normalizing flows have demonstrated significant potential in this domain. These models are particularly suited for handling the symmetrical and complex chemical structures often encountered in molecular datasets. Despite their promising nature, normalizing flow-based models for molecule generation face considerable challenges. The complexity of molecule representation, the rigorous demands of optimization, and the scarcity of training labels in molecular datasets contribute to these difficulties. Additionally, adequately and comprehensively learning the distribution of molecular datasets remains a formidable task. In this paper, we delve into the intricate entry-wise modules in vanilla flows, introducing an effective variation of flow-based models. Our proposed approach innovatively encapsulates affine coupling transformations within normalizing flows. Furthermore, we deconstruct existing invertible flow models, integrating them with newly developed entry-wise transformations. Our experimental studies demonstrate that these proposed entry-wise modules, when incorporated into standard flow-based models, surpass other generative models in performance on various representative datasets and generation tasks. Notably, in the context of low-resourced molecular graph generation, our model achieves remarkable performance compared to its counterparts.}
}


@inproceedings{DBLP:conf/icde/KontaxakisSSAN24,
	author = {Antonios Kontaxakis and
                  Dimitris Sacharidis and
                  Alkis Simitsis and
                  Alberto Abell{\'{o}} and
                  Sergi Nadal},
	title = {{HYPPO:} Using Equivalences to Optimize Pipelines in Exploratory Machine
                  Learning},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {221--234},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00024},
	doi = {10.1109/ICDE60146.2024.00024},
	timestamp = {Sun, 06 Oct 2024 21:04:57 +0200},
	biburl = {https://dblp.org/rec/conf/icde/KontaxakisSSAN24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We present HYPPO, a novel system to optimize pipelines encountered in exploratory machine learning. HYPPO exploits alternative computational paths of artifacts from past executions to derive better execution plans while reusing materialized artifacts. Adding alternative computations introduces new challenges for exploratory machine learning regarding workload representation, system architecture, and optimal execution plan generation. To this end, we present a novel workload representation based on directed hypergraphs, and we formulate the problem of discovering the optimal execution plan as a search problem over directed hypergraphs and that of selecting artifacts to materialize as an optimization problem. A thorough experimental evaluation shows that HYPPO results in plans that are typically one order (up to two orders) of magnitude faster and cheaper than the non-optimized pipeline and considerably (up to one order of magnitude) faster and cheaper than plans generated by the state of the art when materializing artifacts is possible. Lastly, our evaluation reveals that HYPPO reduces the cost by 3–4× even when materialization cannot be exploited.}
}


@inproceedings{DBLP:conf/icde/ChenM0G24,
	author = {Zixuan Chen and
                  Subhodeep Mitra and
                  R. Ravi and
                  Wolfgang Gatterbauer},
	title = {HITSnDIFFs: From Truth Discovery to Ability Discovery by Recovering
                  Matrices with the Consecutive Ones Property},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {235--248},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00025},
	doi = {10.1109/ICDE60146.2024.00025},
	timestamp = {Fri, 02 Aug 2024 21:41:46 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ChenM0G24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We analyze a general problem in a crowd-sourced setting where one user asks a question (also called item) and other users return answers (also called labels) for this question. Different from existing crowd sourcing work which focuses on finding the most appropriate label for the question (the “truth”), our problem is to determine a ranking of the users based on their ability to answer questions. We call this problem “ability discovery” to emphasize the connection to and duality with the more well-studied problem of “truth discovery”. To model items and their labels in a principled way, we draw upon Item Response Theory (IRT) which is the widely accepted theory behind standardized tests such as SAT and GRE. We start from an idealized setting where the relative performance of users is consistent across items and better users choose better fitting labels for each item. We posit that a principled algorithmic solution to our more general problem should solve this ideal setting correctly and observe that the response matrices in this setting obey the Consecutive Ones Property (C1P). While C1P is well understood algorithmically with various discrete algorithms, we devise a novel variant of the HITS algorithm which we call “HITSnDIFFs” (or HnD), and prove that it can recover the ideal C1P-permutation in case it exists. Unlike fast combinatorial algorithms for finding the consecutive ones permutation (if it exists), HnD also returns an ordering when such a permutation does not exist. Thus it provides a principled heuristic for our problem that is guaranteed to return the correct answer in the ideal setting. Our experiments show that HnD produces user rankings with robustly high accuracy compared to state-of-the-art truth discovery methods. We also show that our novel variant of HITS scales better in the number of users than ABH, the only prior spectral C1P reconstruction algorithm.}
}


@inproceedings{DBLP:conf/icde/SunWCZ0024,
	author = {Yushi Sun and
                  Jiachuan Wang and
                  Peng Cheng and
                  Libin Zheng and
                  Lei Chen and
                  Jian Yin},
	title = {Cross-Domain-Aware Worker Selection with Training for Crowdsourced
                  Annotation},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {249--262},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00026},
	doi = {10.1109/ICDE60146.2024.00026},
	timestamp = {Sun, 06 Oct 2024 21:04:59 +0200},
	biburl = {https://dblp.org/rec/conf/icde/SunWCZ0024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Annotation through crowdsourcing draws incremental attention, which relies on an effective selection scheme given a pool of workers. Existing methods propose to select workers based on their performance on tasks with ground truth, while two important points are missed. 1) The historical performances of workers in other tasks. In real-world scenarios, workers need to solve a new task whose correlation with previous tasks is not well-known before the training, which is called cross-domain. 2) The dynamic worker performance as workers will learn from the ground truth. In this paper, we consider both factors in designing an allocation scheme named cross-domain-aware worker selection with training approach. Our approach proposes two estimation modules to both statistically analyze the cross-domain correlation and simulate the learning gain of workers dynamically. A framework with a theoretical analysis of the worker elimination process is given. To validate the effectiveness of our methods, we collect two novel real-world datasets and generate synthetic datasets. The experiment results show that our method outperforms the baselines on both real-world and synthetic datasets.}
}


@inproceedings{DBLP:conf/icde/Liu0TLCYZGYH24,
	author = {Hao Liu and
                  Jiacheng Liu and
                  Feilong Tang and
                  Peng Li and
                  Long Chen and
                  Jiadi Yu and
                  Yanmin Zhu and
                  Min Gao and
                  Yanqin Yang and
                  Xiaofeng Hou},
	title = {Graph Contrastive Learning for Truth Inference},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {263--275},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00027},
	doi = {10.1109/ICDE60146.2024.00027},
	timestamp = {Sun, 06 Oct 2024 21:04:58 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Liu0TLCYZGYH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Crowdsourcing has become a popular paradigm for collecting large-scale labeled datasets by leveraging numerous annotators. However, these annotators often provide noisy labels due to varying expertise. Truth inference aims to infer accurate consensus labels from noisy crowdsourced annotations. Existing approaches rely heavily on hand-engineered assumptions or ground truth data, limiting their applicability. To address this, we propose GOVERN, a graph contrastive learning framework for truth inference without such external supervision. GOVERN employs a novel graph data augmentation strategy to generate views capturing worker coordination patterns. A contrastive objective then encourages invariant representations across views, enabling the discovery of features related to the hidden consensus. Further, a label correction method based on k-nearest neighbors refines noisy pseudo-labels to supervise model training. Comprehensive experiments on 9 real-world datasets demonstrate that GOVERN outperforms state-of-the-art truth inference techniques.}
}


@inproceedings{DBLP:conf/icde/0001ZCXCZ24,
	author = {Liwei Deng and
                  Yan Zhao and
                  Yue Cui and
                  Yuyang Xia and
                  Jin Chen and
                  Kai Zheng},
	title = {Task Recommendation in Spatial Crowdsourcing: {A} Trade-Off Between
                  Diversity and Coverage},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {276--288},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00028},
	doi = {10.1109/ICDE60146.2024.00028},
	timestamp = {Tue, 30 Jul 2024 08:18:21 +0200},
	biburl = {https://dblp.org/rec/conf/icde/0001ZCXCZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The popularity of mobile devices has led to the increased attention of Spatial Crowdsourcing (SC), a framework that assigns location-sensitive tasks to mobile workers. Task recommendation is crucial in helping workers discover attractive tasks. Existing studies have focused on modeling workers' preferences from past task-performing patterns, but their performance is sub-optimal due to the strong coupling of sequentiality, spatiality, and temporality. Moreover, achieving the highest preference-based utility of workers in most of the existing task recommendation studies is inferior to the benefits of the SC platform and the satisfaction of workers in a long range, due to the lower task coverage rate and the poor diversity in a worker's recommended list. To address these problems, we propose a Diversity-Coverage Balanced Task Recommendation (DCBTaskRec) framework. Specifically, we first introduce a decoupled worker preference learning model that adopts self-attention networks as the backbone and decouples the modeling of multiple factors in attention scores. Additionally, we provide an optimal diveristy-aware approach to maximize the recommendation diversity while keeping high preference-based utility of workers to satisfy the multiple tastes of workers. From the side of the SC platform, we also provide two approaches (i.e., greedy coverage-aware approach and diversity-coverage balanced approach) to achieve high coverage and provide a trade-off between diversity and coverage, respectively. Extensive experiments offer insight into the effectiveness of the proposed framework.}
}


@inproceedings{DBLP:conf/icde/00380ZWLCYXWQ024,
	author = {Yu Chen and
                  Sheng Zhang and
                  Ziying Zhou and
                  Xiaokun Wang and
                  Yu Liang and
                  Ning Chen and
                  Yuting Yan and
                  Mingjun Xiao and
                  Jie Wu and
                  Zhuzhong Qian and
                  Harry Xu},
	title = {{MACRO:} Incentivizing Multi-Leader Game-Based Pareto-Efficient Crowdsourcing
                  for Video Analytics},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {289--302},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00029},
	doi = {10.1109/ICDE60146.2024.00029},
	timestamp = {Tue, 30 Jul 2024 08:18:17 +0200},
	biburl = {https://dblp.org/rec/conf/icde/00380ZWLCYXWQ024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent years, many crowdsourcing platforms have emerged, using the resources of recruited workers to perform diverse outsourcing tasks, where the video analytics attracts much attention due to its practical implications. For maximum profits, platforms carefully choose the workers and determine the video analytics configurations to ensure accuracy; meanwhile, workers possess the flexibility to tailor the configurations for their indivi-dual gains, which makes it hard for platforms to optimize their profits considering the platform-worker conflicts. In this paper, we design an incentive mechanism for Multi-leader game-based video Analytics upon CROwdsourcing, named MACRO, to over-come the above situation. Under that mechanism, we first formu-late the utility optimization problems for platforms and workers, respectively. We then propose a dual ascent-based method to op-timally determine the video analytics configurations for a multi-platform game, ensuring Pareto efficiency. Moreover, in the context of a multi-leader game involving platform-worker conflicts, we design an incentive function with its incentive factor update strategy and propose an ADMM-based approach for maximizing incentives that motivate workers to contribute to the platforms' profits. Rigorous proofs demonstrate the linear convergence of the MACRO to the multi-leader Stackelberg equilibrium. Trace-driven experiments show that MACRO improves the Pareto efficiency by 26.3%, outperforming other approaches.}
}


@inproceedings{DBLP:conf/icde/CuiCZ0W24,
	author = {Xiaoxi Cui and
                  Yurong Cheng and
                  Siyi Zhang and
                  Ye Yuan and
                  Guoren Wang},
	title = {Cooperative Global Path Planning for Multiple Platforms},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {303--316},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00030},
	doi = {10.1109/ICDE60146.2024.00030},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/CuiCZ0W24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the development of AI, big data, and mobile communication, intelligent transportation has become popular in recent years. Path planning is a typical topic of intelligent transportation, attracting significant attention from researchers. However, existing studies only focus on the path planning of a single platform, which may lead to unexpected traffic congestion. This is because multiple platforms can provide route planning services, the optimal planning calculated by one single platform may be not good in practice, since multiple platforms may lead the users to the same roads, which causes unexpected traffic congestion. Although in the view of each platform, the planning is optimal. Fortunately, with the rise of data sharing and cross-platform cooperation, the data silos between different platforms are gradually being broken. Based on this, we propose Cooperative Global Path Planning (CG PP) framework to over-come the above shortcoming. CGPP allows the path planning request target platform to send some queries to cooperative platforms to optimize its path planning results. Such queries should be “easy” enough to answer, and the query frequency should be small. Based on the above principle, we design a query decision model based on multi-agent reinforcement learning in CGPP framework to decide the query range and query frequency. We design action and reward specifically for the CGPP problem. Furthermore, we propose the Self-adjusting Query Area algorithm to enhance the precision of query results and the Query Reuse Optimization algorithm to further minimize the number of queries. Extensive experiments on real and synthetic datasets confirm the effectiveness and efficiency of our algorithms.}
}


@inproceedings{DBLP:conf/icde/LiuXZQG024,
	author = {Zhao Liu and
                  Guoqing Xiao and
                  Xu Zhou and
                  Yunchuan Qin and
                  Yunjun Gao and
                  Kenli Li},
	title = {Cross Online Assignment of Hybrid Task in Spatial Crowdsourcing},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {317--329},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00031},
	doi = {10.1109/ICDE60146.2024.00031},
	timestamp = {Tue, 30 Jul 2024 08:18:17 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LiuXZQG024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Task assignment is a fundamental problem in spatial crowdsourcing. In many spatial crowdsourcing platforms, such as Didi, AMAP, and Uber, there are hybrid tasks, including real-time and reservation-type tasks, which are with different constraints and unevenly distributed in spatial and temporal. For these hybrid tasks, most existing studies suffer from low task completion rate and low profit for two reasons: firstly, they focus on homogeneous tasks with uniform constraints, and assign hybrid tasks separately; secondly, they cannot effectively address the uneven distribution of hybrid tasks. Inspired by this, we delve into the problem of online hybrid task assignment (HyTAO) with the goal of maximizing total revenue by simultaneously assigning both real-time and reservation-type tasks online for the first time. We prove the NP-hardness of the offline version of the HyTAO problem. To solve HyTAO effectively, we utilize a cross-platform cooperation model to tackle the challenge of non-uniform distribution. Following this, we design a binary tree-based search algorithm, namely BTS, which is capable of uniformly processing various types of tasks and quickly searching for available workers. Additionally, we discuss the parallel optimization strategies of BTS. To further enhance performance, we develop TBTS, which identifies tasks with high increased revenue based on a threshold. Finally, we conduct a comprehensive analysis of the complexity and competitive ratio of both BTS and TBTS. Extensive experiments are performed to demonstrate the efficiency of our approaches.}
}


@inproceedings{DBLP:conf/icde/ChaiQ0L24,
	author = {Lei Chai and
                  Lu Qi and
                  Hailong Sun and
                  Jingzheng Li},
	title = {RA\({}^{\mbox{3}}\): {A} Human-in-the-loop Framework for Interpreting
                  and Improving Image Captioning with Relation-Aware Attribution Analysis},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {330--341},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00032},
	doi = {10.1109/ICDE60146.2024.00032},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ChaiQ0L24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Interpreting model behavior is crucial for model evaluation and optimization. Recent research demonstrates that incorporating human intelligence into the learning process effectively improve the interpretability and performance of the machine learning models, especially for simple classification tasks. However, the image captioning task has not received much attention. Such complex sequential tasks generally contain semantic relationships between different concepts, which pose challenges for interpreting model behavior and developing optimization methods. In this paper, we present RA 3 (Relation-Aware Attribution Analysis), a human-in-the-loop framework, for improving the interpretability, and further boosting the performance of the image captioning model. Specifically, we first engage human participants in two types of annotation tasks to identify what the model actually focuses on (model attribution) and what it should focus on (human rationale) at the conceptual level, supported by machine learning interpretability methods. Then, we identify and filter hard instances based on relation-aware model attribution for both validating the quality of the explanation and eliminating low-quality captions (this process is also considered as a kind of data debugging). We subsequently designed an explanation loss that penalizes the difference between model attribution and human rationale to optimize the model's behavior for improving caption quality. Through extensive experiments on crowdsourced annotations and MSCOCO, the experiment results indicate that the explanations produced by RA 3 can accurately describe the model's behavior, effectively identify difficult instances, and significantly improve the caption quality.}
}


@inproceedings{DBLP:conf/icde/ZhaoG0B24,
	author = {Zhuowei Zhao and
                  Junhao Gan and
                  Jianzhong Qi and
                  Zhifeng Bao},
	title = {Efficient Example-Guided Interactive Graph Search},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {342--354},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00033},
	doi = {10.1109/ICDE60146.2024.00033},
	timestamp = {Sun, 06 Oct 2024 21:04:59 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhaoG0B24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We study the problem of interactive graph search (IGS). Given a query entity\nφ\n, the goal is to identify the target concept in a directed acyclic graph (DAG) concept hierarchy\nH\n, which best describes\nφ\n, through interactions with an oracle. In each interaction, a question in the form of “Does\nφ\nbelong to concept\nu?\n” is asked and the oracle can only answer either YES or NO. The efficiency of an IGS algorithm is measured by the number of questions asked, to identify the target concept, which is referred to as query cost. In theory aspect, we propose the Target-Sensitive IGS (TS-IGS) algorithm that achieves a query cost complexity of\nO(logn.log\nL\nlogn\n+d⋅\nlog\nd\nn)\n, where\nL\nis the length of the path from the root of\nH\nto the target concept. When\nL∈O(logn)\n, our TS-IGS matches the known lower bound [1]. In practice aspect, we propose an algorithm called Example-Guided IGS (EG-IGS) that exploits the knowledge of entities and asks promising questions guided by examples similar to\nφ\n. We prove that EG-IGS achieves a finer-grained query cost bound than that of TS-IGS, and is extremely efficient in practice. Extensive experiments on six real-world datasets (including images, texts, and gene sequences) show that our EG-IGS outperforms all the existing competitors by up to two orders of magnitude in terms of query cost, and is robust in various settings. To further demonstrate the real feasibility of our EG-IGS technique, we develop a fully-automatic Amazon product categorization demo system with GPT-3.5 serving as the oracle.}
}


@inproceedings{DBLP:conf/icde/ZhongJCNZC024,
	author = {Xiaoyao Zhong and
                  Jiabao Jin and
                  Peng Cheng and
                  Wangze Ni and
                  Libin Zheng and
                  Lei Chen and
                  Xuemin Lin},
	title = {Wait to be Faster: {A} Smart Pooling Framework for Dynamic Ridesharing},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {355--367},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00034},
	doi = {10.1109/ICDE60146.2024.00034},
	timestamp = {Tue, 20 Aug 2024 08:24:11 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhongJCNZC024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Ridesharing services, such as Uber or Didi, have attracted considerable attention in recent years due to their positive impact on environmental protection and the economy. Existing studies require quick responses to orders, which lack the flexibility to accommodate longer wait times for better grouping opportunities. In this paper, we address a NP-hard ridesharing problem, called Minimal Extra Time RideSharing (METRS), which balances waiting time and group quality (i.e., detour time) to improve riders' satisfaction. To tackle this problem, we propose a novel approach called WATTER (WAit To be fasTER), which leverages an order pooling management algorithm allowing orders to wait until they can be matched with suitable groups. The key challenge is to customize the extra time threshold for each order by reducing the original optimization objective into a convex function of threshold, thus offering a theoretical guarantee to be optimized efficiently. We model the dispatch process using a Markov Decision Process (MDP) with a carefully designed value function to learn the threshold. Through extensive experiments on three real datasets, we demonstrate the efficiency and effectiveness of our proposed approaches.}
}


@inproceedings{DBLP:conf/icde/HerlihyMAO24,
	author = {Anna Herlihy and
                  Guillaume Martres and
                  Anastasia Ailamaki and
                  Martin Odersky},
	title = {Adaptive Recursive Query Optimization},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {368--381},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00035},
	doi = {10.1109/ICDE60146.2024.00035},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/HerlihyMAO24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Performance-critical industrial applications, including large-scale program, network, and distributed system analyses, are increasingly reliant on recursive queries for data analysis. Yet traditional relational algebra-based query optimization techniques do not scale well to recursive query processing due to the iterative nature of query evaluation, where relation cardinalities can change unpredictably during the course of a single query execution. To avoid error-prone cardinality estimation, adaptive query processing techniques use runtime information to inform query optimization, but these systems are not optimized for the specific needs of recursive query processing. In this paper, we introduce Adaptive Metaprogramming, an innovative technique that shifts recursive query optimization and code generation from compile-time to runtime using principled metaprogramming, enabling dynamic optimization and re-optimization before and after query execution has begun. We present a custom join-ordering optimization applicable at multiple stages during query compilation and execution. Through Carac, a custom Datalog engine, we evaluate the optimization potential of Adaptive Metaprogramming and show unoptimized recursive query execution time can be improved by three orders of magnitude and hand-optimized queries by 6x.}
}


@inproceedings{DBLP:conf/icde/0005DZJLML24,
	author = {Ping Lu and
                  Ting Deng and
                  Haoyuan Zhang and
                  Yufeng Jin and
                  Feiyi Liu and
                  Tiancheng Mao and
                  Lexiao Liu},
	title = {Ontology-Mediated Query Answering Using Graph Patterns with Conditions},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {382--395},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00036},
	doi = {10.1109/ICDE60146.2024.00036},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/0005DZJLML24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper proposes an extension of graph patterns, referred to as ontological graph patterns (OGPs), to accelerate ontology-mediated query answering. OGPs employ graph patterns to support topological queries, attach conditions to both vertices and edges to specify additional restrictions, and support conditional partial matching semantics. Hence, OG Ps can express conjunctive queries (CQs) under ontological constraints. We develop a PTIME algorithm to generate an equivalent OGP from a CQ over the ontology specified by description logic DL-Lite_{\\mathcal{R}}\n, and design a matching algorithm to match OGPs in graphs. Using real-life and synthetic data, we experimentally verify that the proposed approach outperforms the state-of-the-art algorithms for ontology-mediated query answering by 2–3 orders of magnitude.}
}


@inproceedings{DBLP:conf/icde/QiuJ00Z024,
	author = {Tao Qiu and
                  Shenwang Jiang and
                  Xiaochun Yang and
                  Bin Wang and
                  Chuanyu Zong and
                  Rui Zhu},
	title = {An Efficient Algorithm for Continuous Complex Event Matching Using
                  Bit-Parallelism},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {396--408},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00037},
	doi = {10.1109/ICDE60146.2024.00037},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/QiuJ00Z024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Complex event matching has gained a lot of at-tention for evaluating complex queries over event streams. The events composing a complex event occur within a user-specified time window and can be nonconsecutive on the stream. Existing methods widely utilize the state automaton to match complex events. However, the state automaton is typically used for matching consecutive items satisfying a pattern, e.g., the regular expression. To support nonconsecutive event matching, it has to maintain a large number of partial matches and skip irrelevant events, which results in a huge overhead. To avoid this problem, we employ the bit parallelism technique to match complex events continuously in this paper. We utilize a set of bit sequences to represent the events, where each bit is associated with a time slice, and an event is mapped to a 1-bit of the sequence if its timestamp belongs to the time slice. Then, bit-parallel operations are designed to process the constraints defined on the complex event, e.g., the time window limitation, and sequential order of the events, etc. We further propose the bit-parallel algorithms to support continuous complex event matching using these bit operations. Our experiments on real and synthetic datasets demonstrate that our method outperforms the existing methods by up to an order of magnitude in Query efficiency.}
}


@inproceedings{DBLP:conf/icde/ZhuLL0ML24,
	author = {Zulun Zhu and
                  Siqiang Luo and
                  Wenqing Lin and
                  Sibo Wang and
                  Dingheng Mo and
                  Chunbo Li},
	title = {Personalized PageRanks over Dynamic Graphs - The Case for Optimizing
                  Quality of Service},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {409--422},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00038},
	doi = {10.1109/ICDE60146.2024.00038},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhuLL0ML24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We study the problem of Quality-of-Service (QoS)-Aware Personalized PageRank (PPR) computation. Existing studies mostly focus on improving the PPR query processing time. However, the query processing time alone may not reflect the service quality in real-world PPR-based systems. The query response time can be a more service-relevant measure in many applications such as the online game service of Tencent and the related-pin recommendation module of Pinterest. We make the first attempt at studying QoS-Aware PPR computation and present Quota, a system that adapts the state-of-the-art PPR algorithms to a given environment for minimizing query response time. Equipped with mathematical tools including queuing theory, algorithmic complexity analysis, and constrained optimization, Quota is designed to adapt itself to a wide spectrum of workloads. We conduct extensive experiments on real datasets and show that Quota can reduce the query response time compared with state-of-the-art PPR algorithms, often by a significant margin.}
}


@inproceedings{DBLP:conf/icde/ShahrokhiKGS24,
	author = {Hesam Shahrokhi and
                  Amirali Kaboli and
                  Mahdi Ghorbani and
                  Amir Shaikhha},
	title = {PyTond: Efficient Python Data Science on the Shoulders of Databases},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {423--435},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00039},
	doi = {10.1109/ICDE60146.2024.00039},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ShahrokhiKGS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Python data science libraries such as Pandas and NumPy have recently gained immense popularity. Although these libraries are feature-rich and easy to use, their scalability limitations require more robust computational resources. In this paper, we present PyTond, an efficient approach to push the processing of data science workloads down into the database engines that are already known for their big data handling capabilities. Compared to the previous work, by introducing TondIR, our approach can capture a more comprehensive set of workloads and data layouts. Moreover, by doing IR-level optimizations, we generate better SQL code that improves the query processing by the underlying database engine. Our evaluation results show promising performance improvement compared to Python and other alternatives for diverse data science workloads.}
}


@inproceedings{DBLP:conf/icde/WangA24,
	author = {Ziheng Wang and
                  Alex Aiken},
	title = {Efficient Fault Tolerance for Pipelined Query Engines via Write-ahead
                  Lineage},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {436--448},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00040},
	doi = {10.1109/ICDE60146.2024.00040},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/WangA24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Modern distributed pipelined query engines either do not support intra-query fault tolerance or employ high-overhead approaches such as persisting intermediate outputs or checkpointing state. In this work, we present write-ahead lineage, a novel fault recovery technique that combines Spark's lineage-based replay and write-ahead logging. Unlike Spark, where the lineage is determined before query execution, write-ahead lineage persistently logs lineage at runtime to support dynamic task dependencies in pipelined query engines. Since only KB-sized lineages are persisted instead of MB-sized intermediate outputs, the normal execution overhead is minimal compared to spooling or checkpointing based approaches. To ensure fast fault recovery times, tasks only consume intermediate outputs with persisted lineage, preventing global rollbacks upon failure. In addition, lost tasks from different stages can be recovered in a pipelined parallel manner. We implement write-ahead lineage in a distributed pipelined query engine called Quokka. We show that Quokka is around 2x faster than SparkSQL on the TPC-H benchmark with similar fault recovery performance.}
}


@inproceedings{DBLP:conf/icde/Amagata24,
	author = {Daichi Amagata},
	title = {Independent Range Sampling on Interval Data},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {449--461},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00041},
	doi = {10.1109/ICDE60146.2024.00041},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Amagata24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Many applications require efficient management of large sets of intervals because many objects are associated with intervals (e.g., time and price intervals). In such interval management systems, range search is a primitive operator for retrieving and analysis tasks. As dataset sizes are growing nowadays, range search results are also becoming larger, which may overwhelm users and incur long computation time. Because applications are usually satisfied with a subset of the result set, it is desirable to efficiently obtain only small samples from the result set. We therefore address the problem of independent range sampling on interval data, which outputs\ns\nrandom samples that overlap a given query interval and are independent of the samples of all previous queries. To efficiently solve this problem theoretically and practically, we propose a variant of an interval tree, namely the augmented interval tree (or AIT), and we show that there exists an exact algorithm that needs\nO(nlogn)\nspace and\nO(\nlog\n2\nn+s)\ntime, where\nn\nis the dataset size. The simple structure of an AIT provides flexible extensions: (i) its time and space complexities respectively become\nO(\nlog\n2\nn+s)\nexpected and\nO(n)\nby bucketing intervals and (ii) it can deal with weighted intervals and outputs\ns\nweighted random samples in\nO(\nlog\n2\nn+slogn)\ntime. We conduct extensive experiments on real datasets, and the results demonstrate that our algorithms significantly outperform competitors.}
}


@inproceedings{DBLP:conf/icde/Wagner0BL24,
	author = {Benjamin Wagner and
                  Andr{\'{e}} Kohn and
                  Peter A. Boncz and
                  Viktor Leis},
	title = {Incremental Fusion: Unifying Compiled and Vectorized Query Execution},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {462--474},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00042},
	doi = {10.1109/ICDE60146.2024.00042},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Wagner0BL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Modern high-performance analytical query engines follow one of two execution paradigms. Vectorized engines implement an interpreter for relational algebra operators that operates on batches of tuples to maximize performance. Compiling engines, on the other hand, generate optimized and specialized code for every query. This paper unifies these two approaches. We present Incremental Fusion, a novel execution paradigm for modern, high-performance query engines. An Incremental Fusion engine performs operator-fusing code generation - with a twist: The compiling engine generates its own vectorized interpreter. The engine uses a finite set of building blocks below relational algebra for code generation. It can enumerate each building block and generate a vectorized primitive for it. The vectorized interpreter becomes a free byproduct of carefully choosing the right abstraction for code generation. This allows an Incremental Fusion engine to dynamically switch between vectorized interpretation and operator-fusing code generation. We demonstrate Incremental Fusion in our open-source prototype engine InkFuse. We measure InkFuse against the state-of-the-art vectorized and compiling engines DuckDB and Umbra. InkFuse is able to achieve competitive performance both for low-latency processing, and compute-intensive long-running queries.}
}


@inproceedings{DBLP:conf/icde/Lall24,
	author = {Ashwin Lall},
	title = {The Indistinguishability Query},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {475--487},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00043},
	doi = {10.1109/ICDE60146.2024.00043},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Lall24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We propose the indistinguishability query for iden-tifying all of a user's near-optimal tuples. This query returns all the tuples that are at most a small fraction away from the optimal of the user's unknown utility function. This is motivated by the idea that users can have a hard time distinguishing very similar tuples and in fact even tuples that are slightly inferior in the identified criteria may have additional characteristics that make them more attractive to the user. In order to perform this query without knowledge of the user's utility function, we use a simple interactive framework that asks the user to perform a modest number of comparisons to narrow down their utility function. We show that the indistinguishability query cannot be approximated solely with real tuples in the database and thus our algorithms with provable bounds must present the user with artificial tuples. We also give heuristic algorithms that show the user only real tuples from the database. Since the user may make errors while performing comparisons, we generalize our algorithms to account for user error as well. Experiments on synthetic and real data sets show that the indistinguishability query can be performed accurately while asking the user to compare a small number of tuples.}
}


@inproceedings{DBLP:conf/icde/WangJLC24,
	author = {Xiaoliang Wang and
                  Peiquan Jin and
                  Yongping Luo and
                  Zhaole Chu},
	title = {Range Cache: An Efficient Cache Component for Accelerating Range Queries
                  on {LSM} - Based Key-Value Stores},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {488--500},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00044},
	doi = {10.1109/ICDE60146.2024.00044},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/WangJLC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {LSM-tree has been widely used in key-value stores to offer high write throughputs. However, LSM-tree suffers from the block-cache invalidation problem caused by periodical compaction operations, which lowers the efficiency of the block cache and leads to poor read performance, especially for range queries. To address this problem, we propose a novel cache component named Range Cache to accelerate range queries on LSM-based key-value stores. The differences between Range Cache and the traditional block cache lie in two aspects. First, Range Cache caches the query results, i.e., key-value pairs, rather than data blocks. Second, in contrast to the traditional block cache that utilizes a hash table to index data, Range Cache incorporates an ordered index, which is more efficient for range queries. Further, we integrate Range Cache into LSM-based key-value stores without disturbing other components. With Range Cache, we can eliminate the impact of compaction operations on the block cache, avoiding the block-cache invalidation problem and reducing disk I/Os for point/range queries. We implement Range Cache on top of RocksDB and conduct system-to-system comparisons to compare Range Cache with LevelDB, RocksDB, LSbM-tree, and RemixDB under various settings. The experimental results show that Range Cache can significantly improve the cache efficiency and increase the throughput, especially for range queries.}
}


@inproceedings{DBLP:conf/icde/SancaCA24,
	author = {Viktor Sanca and
                  Manos Chatzakis and
                  Anastasia Ailamaki},
	title = {Optimizing Context-Enhanced Relational Joins},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {501--515},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00045},
	doi = {10.1109/ICDE60146.2024.00045},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/SancaCA24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Collecting data, extracting value, and combining insights from relational and context-rich sources of many modalities in data processing pipelines presents a challenge for traditional relational DBMS. While relational operators enable declarative and optimizable query specification, they are limited to unsuitable data transformations for capturing or analyzing context. On the other hand, representation learning models can map context-rich data into embeddings, enabling machine-automated context processing but requiring imperative data transformation integration with the analytical query. We present a context-enhanced relational join operator to bridge this dichotomy and introduce an embedding operator composable with relational operators. This approach enables hybrid relational and context-rich vector data processing, with algebraic equivalences compatible with relational algebra and corresponding logical and physical optimizations. We investigate model-operator interaction with vector data processing and study the characteristics of the join operator. We demonstrate the hybrid context-enhanced relational join operators with vector embeddings and evaluate it against a vector database approach. We show step-by-step the impact of logical and physical optimizations, which result in orders of magnitude execution time improvement resulting in tensor join formulation. We also outline the performance tradeoffs and cases of using scan-based processing against vector indexes.}
}


@inproceedings{DBLP:conf/icde/ZhongZCZHP024,
	author = {Chen Zhong and
                  Qingqing Zhou and
                  Yuxing Chen and
                  Xingsheng Zhao and
                  Kuang He and
                  Anqun Pan and
                  Song Jiang},
	title = {IndeXY: {A} Framework for Constructing Indexes Larger than Memory},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {516--529},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00046},
	doi = {10.1109/ICDE60146.2024.00046},
	timestamp = {Sun, 06 Oct 2024 21:05:00 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhongZCZHP024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Indexes in a database system can consume a large amount of memory. When they grow too large to be entirely held in the memory, selected portions of the indexes have to be unloaded to the secondary storage. There are a number of challenges in the design of an extensible index spanning memory and disk. First, the designs of in-memory portion and on-disk portion of the index must be decoupled so that the best choice for each device can be independently made. Second, selective unloading of in-memory portion to the disk must be carefully designed to maximize chance of memory access and to produce the most disk-friendly I/O access. Third, the strategy for index reloading from the disk and retaining in the memory must be optimized for the highest memory efficiency. In this paper, we proposed a memory-disk-spanning index design, named IndeXY, to effectively address the challenges. IndeXY distinguishes itself by being a framework that allows separate adoption of an in-memory index design and an on-disk data organization and access scheme that are deemed most efficient to its workloads. Instead of being just another one-size-fit-all index across memory and disk, the framework provides well-designed mechanisms and policies to integrate a selected in-memory index (Index X) and an on-disk index (Index Y) into one extensible index (IndeXY). We have implemented IndeXY with alternative in-memory indexes (ART tree or B+ tree) and alternative disk indexes (LSM tree or B+ tree). As an anecdotal example, experiments show that integrating the ART tree and an LSM tree in the framework can lead to a throughput improvement by as high as an 8.6X on a TPC-C workload over LeanStore that uses B+-tree indexes in the memory and disk, and can improve performance for almost all YCSB workloads.}
}


@inproceedings{DBLP:conf/icde/Zhang0Z024,
	author = {Lingzi Zhang and
                  Xin Zhou and
                  Zhiwei Zeng and
                  Zhiqi Shen},
	title = {Are {ID} Embeddings Necessary? Whitening Pre-trained Text Embeddings
                  for Effective Sequential Recommendation},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {530--543},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00063},
	doi = {10.1109/ICDE60146.2024.00063},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Zhang0Z024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recent sequential recommendation models have combined pre-trained text embeddings of items with item ID embeddings to achieve superior recommendation performance. Despite their effectiveness, the expressive power of text features in these models remains largely unexplored. While most existing models emphasize the importance of ID embeddings in recommendations, our study takes a step further by studying sequential recommendation models that only rely on text features and do not necessitate ID embeddings. Upon examining pre- trained text embeddings experimentally, we discover that they reside in an anisotropic semantic space, with an average cosine similarity of over 0.8 between items. We also demonstrate that this anisotropic nature hinders recommendation models from effectively differentiating between item representations and leads to degenerated performance. To address this issue, we propose to employ a pre-processing step known as whitening transformation, which transforms the anisotropic text feature distribution into an isotropic Gaussian distribution. Our experiments show that whitening pre-trained text embeddings in the sequential model can significantly improve recommendation performance. However, the full whitening operation might break the potential manifold of items with similar text semantics. To preserve the original semantics while benefiting from the isotropy of the whitened text features, we introduce WhitenRec+, an ensemble approach that leverages both fully whitened and relaxed whitened item representations for effective recommendations. We further discuss and analyze the benefits of our design through experiments and proofs. Experimental results on three public benchmark datasets demonstrate that WhitenRec+ outperforms state-of-the-art methods for sequential recommendation.}
}


@inproceedings{DBLP:conf/icde/LiYHH024,
	author = {Anchen Li and
                  Bo Yang and
                  Huan Huo and
                  Farookh Khadeer Hussain and
                  Guandong Xu},
	title = {Structure- and Logic-Aware Heterogeneous Graph Learning for Recommendation},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {544--556},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00048},
	doi = {10.1109/ICDE60146.2024.00048},
	timestamp = {Tue, 30 Jul 2024 09:00:32 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LiYHH024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recently, there has been a surge in recommendations based on heterogeneous information networks (HINs), attributed to their ability to integrate complex and rich semantics. Despite this advancement, most HIN-based recommenders overlook two critical aspects. First, they often fail to consider HIN's heterophily nature, hindering the capture of non-local structures in HINs. Second, most methods lack the capability for logical reasoning. In this paper, we propose a novel structure- and logic-aware heterogeneous graph learning framework for recommender systems (SLHRec). Our SLHRec contains a structure-aware module and a logic-aware module. The former uses network geometry to construct non-local neighborhoods for nodes in HINs, and then introduces a graph neural network to integrate constructed neighbors for modeling the heterophily of HINs. The logic-aware module uses the Markov logic network (MLN) to infuse logic rules into heterogeneous graph learning, thereby boosting logic reasoning in recommendations. Furthermore, we utilize contrastive learning to model cooperative signals between modules, enabling them to complement each other. In the prediction stage, both modules contribute to generating recommendations. Compared with several strong recommender baselines, our SLHRec achieves superior performance on four real-world datasets.}
}


@inproceedings{DBLP:conf/icde/ZhangXCY0J24,
	author = {Qianru Zhang and
                  Lianghao Xia and
                  Xuheng Cai and
                  Siu{-}Ming Yiu and
                  Chao Huang and
                  Christian S. Jensen},
	title = {Graph Augmentation for Recommendation},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {557--569},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00049},
	doi = {10.1109/ICDE60146.2024.00049},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhangXCY0J24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graph augmentation with contrastive learning has gained significant attention in the field of recommendation systems due to its ability to learn expressive user representations, even when labeled data is limited. However, directly applying existing GCL models to real-world recommendation environments poses challenges. There are two primary issues to address. Firstly, the lack of consideration for data noise in contrastive learning can result in noisy self-supervised signals, leading to degraded performance. Secondly, many existing GCL approaches rely on graph neural network (GNN) architectures, which can suffer from over-smoothing problems due to non-adaptive message passing. To address these challenges, we propose a principled framework called GraphAug. This framework introduces a robust data augmentor that generates denoised self-supervised signals, enhancing recommender systems. The GraphAug framework incorporates a graph information bottleneck (GIB)-regularized augmentation paradigm, which automatically distills informative self-supervision information and adaptively adjusts contrastive view generation. Through rigorous experimentation on real-world datasets, we thoroughly assessed the performance of our novel GraphAug model. The outcomes consistently unveil its superiority over existing baseline methods. The source code for our model is publicly available at: https://github.com/HKUDS/GraphAug.}
}


@inproceedings{DBLP:conf/icde/HaoC0DMW024,
	author = {Xinli Hao and
                  Yile Chen and
                  Chen Yang and
                  Zhihui Du and
                  Chaohong Ma and
                  Chao Wu and
                  Xiaofeng Meng},
	title = {From Chaos to Clarity: Time Series Anomaly Detection in Astronomical
                  Observations},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {570--583},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00050},
	doi = {10.1109/ICDE60146.2024.00050},
	timestamp = {Tue, 06 Aug 2024 09:17:50 +0200},
	biburl = {https://dblp.org/rec/conf/icde/HaoC0DMW024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the development of astronomical facilities, large-scale time series data observed by these facilities is being collected. Analyzing anomalies in these astronomical observations is crucial for uncovering potential celestial events and physical phenomena, thus advancing the scientific research process. However, existing time series anomaly detection methods fall short in tackling the unique characteristics of astronomical observations where each star is inherently independent but interfered by random concurrent noise, resulting in a high rate of false alarms. To overcome the challenges, we propose AERO, a novel two-stage framework tailored for unsupervised anomaly detection in astronomical observations. In the first stage, we employ a Transformer-based encoder-decoder architecture to learn the normal temporal patterns on each variate (i.e., star) in alignment with the characteristic of variate independence. In the second stage, we enhance the graph neural network with a window-wise graph structure learning to tackle the occurrence of concurrent noise characterized by spatial and temporal randomness. In this way, AERO is not only capable of distinguishing normal temporal patterns from potential anomalies but also effectively differentiating concurrent noise, thus decreasing the number of false alarms. We conducted extensive experiments on three synthetic datasets and three real-world datasets. The results demonstrate that AERO outperforms the compared baselines. Notably, compared to the state-of-the-art model, AERO improves the F1-score by up to 8.76% and 2.63% on synthetic and real-world datasets respectively.}
}


@inproceedings{DBLP:conf/icde/GaoLLWCMY24,
	author = {Xin Gao and
                  Yang Lin and
                  Ruiqing Li and
                  Yasha Wang and
                  Xu Chu and
                  Xinyu Ma and
                  Hailong Yu},
	title = {Enhancing Topic Interpretability for Neural Topic Modeling Through
                  Topic-Wise Contrastive Learning},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {584--597},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00051},
	doi = {10.1109/ICDE60146.2024.00051},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/GaoLLWCMY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Data mining and knowledge discovery are essential aspects of extracting valuable insights from vast datasets. Neural topic models (NTMs) have emerged as a valuable unsupervised tool in this field. However, the predominant objective in NTMs, which aims to discover topics maximizing data likelihood, often lacks alignment with the central goals of data mining and knowledge discovery which is to reveal interpretable insights from large data repositories. Overemphasizing likelihood maximization without incorporating topic regularization can lead to an overly expansive latent space for topic modeling. In this paper, we present an innovative approach to NTMs that addresses this misalignment by introducing contrastive learning measures to assess topic interpretability. We propose a novel NTM framework, named ContraTopic, that integrates a differentiable regularizer capable of evaluating multiple facets of topic interpretability throughout the training process. Our regularizer adopts a unique topic-wise contrastive methodology, fostering both internal coherence within topics and clear external distinctions among them. Comprehensive experiments conducted on three diverse datasets demonstrate that our approach consistently produces topics with superior interpretability compared to state-of-the-art NTMs.}
}


@inproceedings{DBLP:conf/icde/AiCWSTL24,
	author = {Meng Ai and
                  Zhuo Chen and
                  Jibin Wang and
                  Jing Shang and
                  Tao Tao and
                  Zhen Li},
	title = {Improve {ROI} with Causal Learning and Conformal Prediction},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {598--610},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00052},
	doi = {10.1109/ICDE60146.2024.00052},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/AiCWSTL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the commercial sphere, such as operations and maintenance, advertising, and marketing recommendations, intelligent decision-making utilizing data mining and neural network technologies is crucial, especially in resource allocation to optimize ROI. This study delves into the Cost-aware Binary Treatment Assignment Problem (C-BTAP) across different industries, with a focus on the state-of-the-art Direct ROI Prediction (DRP) method. However, the DRP model confronts issues like covariate shift and insufficient training data, hindering its real-world effectiveness. Addressing these challenges is essential for ensuring dependable and robust predictions in varied operational contexts. This paper presents a robust Direct ROI Prediction (rDRP) method, designed to address challenges in real-world deployment of neural network-based uplift models, particularly under conditions of covariate shift and insufficient training data. The rDRP method, enhancing the standard DRP model, does not alter the model's structure or require retraining. It utilizes conformal prediction and Monte Carlo dropout for interval estimation, adapting to model uncertainty and data distribution shifts. A heuristic calibration method, inspired by a Kaggle competition, combines point and interval estimates. The effectiveness of these approaches is validated through offline tests and online A/B tests in various settings, demonstrating significant improvements in target rewards compared to the state-of-the-art method.}
}


@inproceedings{DBLP:conf/icde/YuanYQNLY24,
	author = {Wei Yuan and
                  Chaoqun Yang and
                  Liang Qu and
                  Quoc Viet Hung Nguyen and
                  Jianxin Li and
                  Hongzhi Yin},
	title = {Hide Your Model: {A} Parameter Transmission-free Federated Recommender
                  System},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {611--624},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00053},
	doi = {10.1109/ICDE60146.2024.00053},
	timestamp = {Sun, 06 Oct 2024 21:04:59 +0200},
	biburl = {https://dblp.org/rec/conf/icde/YuanYQNLY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the growing concerns regarding user data privacy, Federated Recommender System (FedRec) has garnered significant attention recently due to its privacy-preserving capabilities. Existing FedRecs generally adhere to a learning protocol in which a central server shares a global recommendation model with clients, and participants achieve collaborative learning by frequently communicating the model's public parameters. Nevertheless, this learning framework has two drawbacks that limit its practical usability: (1) It necessitates a global-sharing recommendation model; however, in real-world scenarios, information related to the recommendation model, including its algorithm and parameters, constitutes the platforms' intellectual property. Hence, service providers are unlikely to release such information actively. (2) The communication costs of model parameter transmission are expensive since the model parameters are usually high-dimensional matrices. With the model size increasing, the communication burden will be the bottleneck for such traditional FedRecs. Given the above limitations, this paper introduces a novel parameter transmission-free federated recommendation framework that balances the protection between users' data privacy and platforms' model privacy, namely PTF-FedRec. Unlike traditional FedRecs, participants in PTF-FedRec collaboratively exchange knowledge by sharing their predictions within a privacy-preserving mechanism. Through this approach, the central server can learn a recommender model without disclosing its model parameters or accessing clients' raw data, preserving both the server's model privacy and users' data privacy. Besides, since clients and the central server only need to communicate prediction scores which are just a few real numbers, the communication overhead is significantly reduced compared to traditional FedRecs. Extensive experiments conducted on three commonly used recommendation datasets with three recommendation models demonstrate the effectiveness, efficiency, and generalization of our proposed federated recommendation framework.}
}


@inproceedings{DBLP:conf/icde/ChangCWPC24,
	author = {Ching Chang and
                  Chiao{-}Tung Chan and
                  Wei{-}Yao Wang and
                  Wen{-}Chih Peng and
                  Tien{-}Fu Chen},
	title = {TimeDRL: Disentangled Representation Learning for Multivariate Time-Series},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {625--638},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00054},
	doi = {10.1109/ICDE60146.2024.00054},
	timestamp = {Mon, 30 Sep 2024 16:40:40 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ChangCWPC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Multivariate time-series data in numerous real-world applications (e.g., healthcare and industry) are informative but challenging due to the lack of labels and high dimensionality. Recent studies in self-supervised learning have shown their potential in learning rich representations without relying on labels, yet they fall short in learning disentangled embeddings and addressing issues of inductive bias (e.g., transformation-invariance). To tackle these challenges, we propose TimeDRL, a generic multivariate time-series representation learning frame-work with disentangled dual-level embeddings. TimeDRL is characterized by three novel features: (i) disentangled derivation of timestamp-level and instance-level embeddings from patched time-series data using a [CLS] token strategy; (ii) utilization of timestamp-predictive and instance-contrastive tasks for disentangled representation learning, with the former optimizing timestamp-level embeddings with predictive loss, and the latter optimizing instance-level embeddings with contrastive loss; and (iii) avoidance of augmentation methods to eliminate inductive biases, such as transformation-invariance from cropping and masking. Comprehensive experiments on 6 time-series forecasting datasets and 5 time-series classification datasets have shown that TimeDRL consistently surpasses existing representation learning approaches, achieving an average improvement of forecasting by 58.02% in MSE and classification by 1.48% in accuracy. Further-more, extensive ablation studies confirmed the relative contribution of each component in TimeDRL's architecture, and semi-supervised learning evaluations demonstrated its effectiveness in real-world scenarios, even with limited labeled data. The code is available at https://github.com/blacksnail789521/TimeDRL.}
}


@inproceedings{DBLP:conf/icde/WangJHT24,
	author = {Xi Wang and
                  Ruochun Jin and
                  Wanrong Huang and
                  Yuhua Tang},
	title = {Boosting Meaningful Dependency Mining with Clustering and Covariance
                  Analysis},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {639--652},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00055},
	doi = {10.1109/ICDE60146.2024.00055},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/WangJHT24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Functional dependencies (FDs) form a valuable ingredient for various data management tasks. However, existing methods can hardly discover practical and interpretable FDs, especially in large noisy real-life datasets. This paper studies the problem of discovering meaningful functional dependencies (FDms) that utilize support and error parameters to capture interesting dependencies in such datasets and proposes an efficient discovery algorithm called FDMε. In order to scale with large datasets, FDM ε employs an efficient sampling method with accuracy guarantees to capture the differences between tuple pairs and to quantify the connection between support/error of dependencies on samples and those on the entire dataset. Moreover, it adopts a clustering-based correlated attributes extraction to divide the exponentially large search space into multiple small sub-spaces and proposes an easy-first traversal strategy with covariance-based guidance that quickly detects candidate dependencies and validates them. Additionally, we prove a covariance lower bound as an additional pruning criterion to reduce the search space. Extensive experiments on real-life and synthetic datasets demonstrate that FDM ε is 14 times faster than existing discovery algorithms on average, up to 31 times, and scales to larger datasets with the least memory cost.}
}


@inproceedings{DBLP:conf/icde/ZhangWLZCLL024,
	author = {Honglei Zhang and
                  Shuyi Wang and
                  Haoxuan Li and
                  Chunyuan Zheng and
                  Xu Chen and
                  Li Liu and
                  Shanshan Luo and
                  Peng Wu},
	title = {Uncovering the Propensity Identification Problem in Debiased Recommendations},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {653--666},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00056},
	doi = {10.1109/ICDE60146.2024.00056},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhangWLZCLL024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In database of recommender systems, users' ratings for most items are usually missing, resulting in selection bias when users selectively choose items to rate. To address this problem, propensity-based methods, e.g., inverse propensity scoring and doubly robust, have been widely studied and applied to missing rating prediction and post-click conversion rate prediction tasks. However, have we completely eliminated the selection bias? Under what missing data mechanism can previous studies completely eliminate the selection bias and lead to unbiased learning? In this paper, following the previous literature on statistics, we first formally define three missing data mechanisms, i.e., missing completely at random (MCAR), missing at random (MAR), and missing not at random (MNAR), and discuss the widespread prevalence of MNAR in recommender systems. Next, we theoretically reveal that the unbiasedness of previous propensity-based debiasing methods is valid only when data are MCAR or MAR, while it leads to biased predictions when data are MNAR. To tackle this research gap, we propose to disentangle user and item embeddings into the primary latent vector for rating prediction and the auxiliary latent vector for missing mechanism modeling. We prove the identifiablility results, and show that the proposed method can achieve unbiased learning under MNAR with imposed constraints. Extensive experiments are conducted on a semi-synthetic dataset and three real-world datasets, validating the effectiveness of our proposed method.}
}


@inproceedings{DBLP:conf/icde/ZhaZLZ0XC24,
	author = {Rui Zha and
                  Le Zhang and
                  Shuangli Li and
                  Jingbo Zhou and
                  Tong Xu and
                  Hui Xiong and
                  Enhong Chen},
	title = {Scaling Up Multivariate Time Series Pre-Training with Decoupled Spatial-Temporal
                  Representations},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {667--678},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00057},
	doi = {10.1109/ICDE60146.2024.00057},
	timestamp = {Tue, 30 Jul 2024 08:18:21 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhaZLZ0XC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Data scale has been acknowledged as a crucial factor for enhancing the generalization and effectiveness of pre-training models. While existing methods of multivariate time series pre-training are primarily limited to a single specific dataset, scaling to a larger scenario that includes multiple diverse datasets (e.g., multi-region data) remains a substantial challenge. In this paper, we present a novel Decoupled Spatial-Temporal Representation Learning (DeSTR) framework to serve as the backbone network for investigating the data scaling capability of multivariate time series pre-training architectures. Specifically, DeSTR utilizes two separate encoders to capture both the temporal dynamics within each time series and the spatial correlations among multiple variables. The obtained representations of distinct modalities are then fed into a Spatial-Guided Temporal Transformer to equip the temporal features with spatial discriminative information. Moreover, we employ masked autoencoding as the foundational pre-training framework and introduce spacetime-agnostic augmentation to improve robustness and facilitate implicit spatiotemporal modeling. Finally, we successfully pre-train a unified time series representation learning framework on real-world datasets from three different cities. Extensive experiments are carried out on various downstream tasks to validate the performance of DeSTR, compared with three categories of state-of-the-art baselines: deep sequential models, spatial-temporal graph neural networks, and time series representation learning methods. The results clearly demonstrate the advantages of scaling multivariate time series pre-training to multiple datasets, highlighting the effectiveness of DeSTR as a general spatiotemporal learner.}
}


@inproceedings{DBLP:conf/icde/HaoZQ00ZS024,
	author = {Yongjing Hao and
                  Pengpeng Zhao and
                  Jianfeng Qu and
                  Lei Zhao and
                  Guanfeng Liu and
                  Fuzhen Zhuang and
                  Victor S. Sheng and
                  Xiaofang Zhou},
	title = {Meta-optimized Structural and Semantic Contrastive Learning for Graph
                  Collaborative Filtering},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {679--691},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00058},
	doi = {10.1109/ICDE60146.2024.00058},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/HaoZQ00ZS024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graph Collaborative Filtering (GCF) is designed to leverage high-order connectivity in user-item graphs, thereby significantly enhancing recommendation performance. Recent advancements have seen the integration of contrastive learning into GCF as a strategy to mitigate the challenges of data sparsity. This approach involves creating contrastive views through augmentations, followed by the generation of self-supervised signals. These signals are produced by maximizing the mutual information between the contrastive views. While this method has proven effective, we argue that current CL-based GCF models are still limited to current augmentation techniques. Existing data augmentation or noise perturbation may destroy the structural and semantic features of the original data and node attribute information is not considered. To tackle the above limitations, we propose a Meta-optimized Structure and Semantic Contrastive Learning for Graph Collaborative Filtering, named Meta-SSCL, which utilizes graph structure information and semantic information contrastive learning for recommendation. Specifically, we first model the structural and node semantic information representations with LightGCN and vanilla attention mechanism, respectively. Then consider the structural and semantic information as two contrastive views for recommendation. Next, the meta-optimized two-step training strategy generates adaptive contrastive views. Finally, we fuse structural and semantic representations for recommendation. Extensive experiments on real-world datasets demonstrate that Meta-SSCL consistently outperforms state-of-the-art sequential recommendation methods. The code is available1.}
}


@inproceedings{DBLP:conf/icde/LiLTY024,
	author = {Yihan Li and
                  Ruifeng Li and
                  Zijing Tan and
                  Weidong Yang and
                  Shuai Ma},
	title = {Efficient Set-Based Order Dependency Discovery with a Level-Wise Hybrid
                  Strategy},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {692--704},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00059},
	doi = {10.1109/ICDE60146.2024.00059},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LiLTY024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Order dependencies (ODs) state ordering specifications between attributes, and have been proven effective in query optimization for sorting operations. In this paper we investigate the problem of set-based OD discovery, for automatically finding hidden ODs from data. We tackle the problem with a novel level-wise hybrid strategy. With a given relational instance r, we discover ODs from a sample (subset) of r, validate the discovered ODs on r and refine the sample by leveraging the validation, in a level-by-level manner according to the lattice of set-based ODs. This process continues until the discovery result on the sample converges to that on r. We prove that a dynamic sample whose size keeps growing can be used in the process without affecting the correctness and completeness of the discovery result, and present techniques to incrementally refine the sample on demand. We also enhance our method with multi-threaded parallelism. On a host of datasets, our method is faster than the state-of-the-art method up to orders of magnitude even when the parallelism of our approach is disabled, and achieves up to a 4.5x self-relative parallel speedup with 6 threads.}
}


@inproceedings{DBLP:conf/icde/HaoZFQ0ZS024,
	author = {Yongjing Hao and
                  Pengpeng Zhao and
                  Junhua Fang and
                  Jianfeng Qu and
                  Guanfeng Liu and
                  Fuzhen Zhuang and
                  Victor S. Sheng and
                  Xiaofang Zhou},
	title = {Meta-Optimized Joint Generative and Contrastive Learning for Sequential
                  Recommendation},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {705--718},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00060},
	doi = {10.1109/ICDE60146.2024.00060},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/HaoZFQ0ZS024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Sequential Recommendation (SR) has received increasing attention due to its ability to capture user dynamic preferences. Recently, Contrastive Learning (CL) provides an effective approach for sequential recommendation by learning invariance from different views of an input. However, most existing data or model augmentation methods may destroy semantic sequential interaction characteristics and often rely on the hand-crafted property of their contrastive view-generation strategies. In this paper, we propose a Meta-optimized Seq2Seq Generator and Contrastive Learning (Meta-SGCL) for sequential recommendation, which applies the meta-optimized two-step training strategy to adaptive generate contrastive views. Specifically, Meta-SGCL first introduces a simple yet effective augmentation method called Sequence-to-Sequence (Seq2Seq) generator, which treats the Variational AutoEncoders (VAE) as the view generator and can constitute contrastive views while preserving the original sequence's semantics. Next, the model employs a meta-optimized two-step training strategy, which aims to adaptively generate contrastive views without relying on manually designed view-generation techniques. Finally, we evaluate our proposed method Meta-SGCL using three public real-world datasets. Compared with the state-of-the-art methods, our experimental results demonstrate the effectiveness of our model and the code is available. 1 1 https.//anonymous.4open.science/status/Meta-SGCL-05B5}
}


@inproceedings{DBLP:conf/icde/Wei0ZZQZ24,
	author = {Yuyang Wei and
                  Wei Chen and
                  Xiaofang Zhang and
                  Pengpeng Zhao and
                  Jianfeng Qu and
                  Lei Zhao},
	title = {Multi-Modal Siamese Network for Few-Shot Knowledge Graph Completion},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {719--732},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00061},
	doi = {10.1109/ICDE60146.2024.00061},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Wei0ZZQZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Multi-modal data have recently been utilized to improve the performance of knowledge graph completion (KGC), attracting widespread research interest. However, they have been ignored in few-shot knowledge graph completion (FKGC), which aims to discover potential facts involving unseen relations that only appear in few-shot triples. The most relevant FKGC study simply concatenates various modal features, but the performance is still limited due to the following problems: (1) lack of exploiting significant multi-modal features in neighborhoods, and (2) ineffectively modeling inter-modal interactions in a few-shot setting. To tackle these problems, we propose a novel relational learning model entitled MMSN (Multi-Modal Siamese Network) for few-shot knowledge graph completion, which is composed of the following two primary modules: the Siamese multi-modal neighbor encoder (SMNE) and the meta-learning multi-modal knowledge representation decoder (MKRD). The module SMNE is developed to encode diverse modalities of neighbors by a Siamese attention network, fuse multi-modal information through a gating fusion network, and learn effective relational embeddings using an aggregator. The module MKRD is introduced to handle inter-modal interactions between multiple modalities and train the proposed model in a few-shot scenario. Extensive experiments demonstrate that our proposed model MMSN outperforms the state-of-the-art FKGC models, including uni-modal and multi-modal models, on two real-world few-shot multi-modal datasets.}
}


@inproceedings{DBLP:conf/icde/ChenWWZCLL24,
	author = {Wei Chen and
                  Huaiyu Wan and
                  Yuting Wu and
                  Shuyuan Zhao and
                  Jiayaqi Cheng and
                  Yuxin Li and
                  Youfang Lin},
	title = {Local-Global History-Aware Contrastive Learning for Temporal Knowledge
                  Graph Reasoning},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {733--746},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00062},
	doi = {10.1109/ICDE60146.2024.00062},
	timestamp = {Tue, 30 Jul 2024 08:18:20 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ChenWWZCLL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Temporal knowledge graphs (TKGs) have been identified as a promising approach to represent the dynamics of facts along the timeline. The extrapolation of TKG is to predict unknowable facts happening in the future, holding significant practical value across diverse fields. Most extrapolation studies in TKGs focus on modeling global historical fact repeating and cyclic patterns, as well as local historical adjacent fact evolution patterns, showing promising performance in predicting future un-known facts. Yet, existing methods still face two major challenges: (1) They usually neglect the importance of historical information in KG snapshots related to the queries when encoding the local and global historical information; (2) They exhibit weak anti-noise capabilities, which hinders their performance when the inputs are contaminated with noise. To this end, we propose a novel Local-global history-aware Contrastive Learning model (LogCL) for TKG reasoning, which adopts contrastive learning to better guide the fusion of local and global historical information and enhance the ability to resist interference. Specifically, for the first challenge, LogCL proposes an entity-aware attention mechanism applied to the local and global historical facts encoder, which captures the key historical information related to queries. For the latter issue, LogCL designs a local-global query contrast module, effectively improving the robustness of the model. The experimental results on four benchmark datasets demonstrate that LogCL delivers better and more robust performance than the state-of-the-art baselines. The code of LogCL is available at https://eithub.com/WeiChen3690/LoeCL.}
}


@inproceedings{DBLP:conf/icde/ChenZQFJLWD24,
	author = {Feiyi Chen and
                  Yingying Zhang and
                  Zhen Qin and
                  Lunting Fan and
                  Renhe Jiang and
                  Yuxuan Liang and
                  Qingsong Wen and
                  Shuiguang Deng},
	title = {Learning Multi-Pattern Normalities in the Frequency Domain for Efficient
                  Time Series Anomaly Detection},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {747--760},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00047},
	doi = {10.1109/ICDE60146.2024.00047},
	timestamp = {Sun, 06 Oct 2024 21:04:56 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ChenZQFJLWD24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Anomaly detection significantly enhances the robustness of cloud systems. While neural network-based methods have recently demonstrated strong advantages, they encounter practical challenges in cloud environments: the contradiction between the impracticality of maintaining a unique model for each service and the limited ability to deal with diverse normal patterns by a unified model, as well as issues with handling heavy traffic in real time and short-term anomaly detection sensitivity. Thus, we propose MACE, a multi-normal-pattern accommodated and efficient anomaly detection method in the frequency domain for time series anomaly detection. There are three novel characteristics of it: (i) a pattern extraction mechanism excelling at handling diverse normal patterns with a unified model, which enables the model to identify anomalies by examining the correlation between the data sample and its service normal pattern, instead of solely focusing on the data sample itself; (ii) a dualistic convolution mechanism that amplifies short-term anomalies in the time domain and hinders the reconstruction of anomalies in the frequency domain, which enlarges the reconstruction error disparity between anomaly and normality and facilitates anomaly detection; (iii) leveraging the sparsity and parallelism of frequency domain to enhance model efficiency. We theoretically and experimentally prove that using a strategically selected subset of Fourier bases can not only reduce computational overhead but is also profitable to distinguish anomalies, compared to using the complete spectrum. Moreover, extensive experiments demonstrate MACE's effectiveness in handling diverse normal patterns with a unified model and it achieves state-of-the-art performance with high efficiency.}
}


@inproceedings{DBLP:conf/icde/DaiSZZDXDW24,
	author = {Sunhao Dai and
                  Ninglu Shao and
                  Jieming Zhu and
                  Xiao Zhang and
                  Zhenhua Dong and
                  Jun Xu and
                  Quanyu Dai and
                  Ji{-}Rong Wen},
	title = {Modeling User Attention in Music Recommendation},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {761--774},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00064},
	doi = {10.1109/ICDE60146.2024.00064},
	timestamp = {Tue, 30 Jul 2024 08:18:19 +0200},
	biburl = {https://dblp.org/rec/conf/icde/DaiSZZDXDW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the popularity of online music services, personalized music recommendation has garnered much research interest. Recommendation models are typically trained on datasets constructed from user feedback, which includes both the active feedback (e.g., clicking the Like or Skip buttons) and passive feedback (e.g., auto-play), with passive feedback comprising the majority. Due to the unavailability of user attention, the massive amount of passive feedback is unreliable, significantly compromising the quality of the training data. How to estimate the user's attention on the target music has become a critical problem in music recommendation. Heuristic methods such as exponential decay and negative sampling have been proposed. However, they either neglect the sequential dependencies between feedback actions or utilize only a small fraction of passive samples, leading to inaccurate and biased attention estimation. In this paper, we naturally propose modeling user attention prediction as a positive-unlabeled (PU) learning problem, where active feedback is treated as positive samples and passive feedback is treated as unlabeled samples, as we can only ensure that the user's attention is focused when she provides active feedback. Then we propose an extended PU-learning model with sequential dependencies, called UAE, which contains an unbiased user attention estimator and an unbiased propensity estimator. Subsequently, a joint learning algorithm is developed in which the attention and propensity estimators are optimized in alternating fashion. Theoretical analysis shows the unbiasedness and variance of the attention estimator and the propensity estimator. Extensive experiments on two large-scale datasets demonstrate the proposed UAE's effectiveness and generality in enhancing downstream music recommendation. One week online A/B testing on Huawei Music App manifests that UAE can significantly increase the users' play count and time over 2%, further demonstrating the effectiveness of UAE in real-world music recommendation products.}
}


@inproceedings{DBLP:conf/icde/LuZPZJ24,
	author = {Guanyu Lu and
                  Fang Zhou and
                  Martin Pavlovski and
                  Chenyi Zhou and
                  Cheqing Jin},
	title = {A Robust Prioritized Anomaly Detection when Not All Anomalies are
                  of Primary Interest},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {775--788},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00065},
	doi = {10.1109/ICDE60146.2024.00065},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LuZPZJ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Anomaly detection has emerged as a prominent research area with extensive exploration across various applications. Existing methods predominantly focus on detecting all anomalies exhibiting unusual patterns, however, they overlook the critical need to prioritize the detection of target anomaly categories (anomalies of primary interest) that could pose significant threats to various systems. This oversight results in the excessive involvement of valuable human labor and resources in dealing with non-target anomalies (that are of lower interest). This work is focused on target-class anomaly detection, which entails overcoming several challenges: (1) deficient prior information regarding non-target anomalies and (2) an elevated false positive rate caused by the presence of non-target anomalies. Thus, we introduce a novel semi-supervised model, called TargAD, which leverages a few labeled target anomalies, along with potential non-target anomaly candidates and normal candidates selected from unlabeled data. By introducing a novel loss function, TargAD effectively maximizes the distributional differences among normal candidates, target anomalies, and non-target anomaly candidates, leading to a significant improvement in detecting target anomalies. Furthermore, when confronted with novel non-target anomaly scenarios, TargAD maintains its accuracy in detecting target anomalies. We conducted extensive experiments, the results of which demonstrate that TargAD outperforms eleven state-of-the-art baselines on a real-world dataset and three publicly available datasets, with average AUPRC improvements of 5.9%-24.8%, 9.2%-57.8%, 2.7%-71.3%, and 2.0%-70.3%, respectively.}
}


@inproceedings{DBLP:conf/icde/HuangHLJXC24,
	author = {Yuncheng Huang and
                  Qianyu He and
                  Jiaqing Liang and
                  Sihang Jiang and
                  Yanghua Xiao and
                  Yunwen Chen},
	title = {Enhancing Quantitative Reasoning Skills of Large Language Models through
                  Dimension Perception},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {789--802},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00066},
	doi = {10.1109/ICDE60146.2024.00066},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/HuangHLJXC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Quantities are distinct and critical components of texts that characterize the magnitude properties of entities, providing a precise perspective for the understanding of natural language, especially for reasoning tasks. In recent years, there has been a flurry of research on reasoning tasks based on large language models (LLMs), most of which solely focus on numerical values, neglecting the dimensional concept of quantities with units despite its importance. We argue that the concept of dimension is essential for precisely understanding quantities and of great significance for LLMs to perform quantitative reasoning. However, the lack of dimension knowledge and quantity-related benchmarks has resulted in low performance of LLMs. Hence, we present a framework to enhance the quantitative reasoning ability of language models based on dimension perception. We first construct a dimensional unit knowledge base (DimUnitKB) to address the knowledge gap in this area. We propose a benchmark DimEval consisting of seven tasks of three categories to probe and enhance the dimension perception skills of LLMs. To evaluate the effectiveness of our methods, we propose a quantitative reasoning task and conduct experiments. The experimental results show that our dimension perception method dramatically improves accuracy (43.55%→50.67%) on quantitative reasoning tasks compared to GPT-4.}
}


@inproceedings{DBLP:conf/icde/ZhangH00TS24,
	author = {Chi Zhang and
                  Qilong Han and
                  Rui Chen and
                  Xiangyu Zhao and
                  Peng Tang and
                  Hongtao Song},
	title = {SSDRec: Self-Augmented Sequence Denoising for Sequential Recommendation},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {803--815},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00067},
	doi = {10.1109/ICDE60146.2024.00067},
	timestamp = {Sun, 06 Oct 2024 21:04:59 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhangH00TS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Traditional sequential recommendation methods assume that users' sequence data is clean enough to learn accurate sequence representations to reflect user preferences. In practice, users' sequences inevitably contain noise (e.g., accidental interactions), leading to incorrect reflections of user preferences. Consequently, some pioneer studies have explored modeling sequentiality and correlations in sequences to implicitly or explicitly reduce noise's influence. However, relying on only available intra-sequence information (i.e., sequentiality and correlations in a sequence) is insufficient and may result in over-denoising and under-denoising problems (OUPs), especially for short sequences. To improve reliability, we propose to augment sequences by inserting items before denoising. However, due to the data sparsity issue and computational costs, it is challenging to select proper items from the entire item universe to insert into proper positions in a target sequence. Motivated by the above observation, we propose a novel framework-Self-augmented Sequence Denoising for sequential Recommendation (SSDRec) with a three-stage learning paradigm to solve the above challenges. In the first stage, we empower SSDRec by a global relation encoder to learn multi-faceted inter-sequence relations in a data-driven manner. These relations serve as prior knowledge to guide subsequent stages. In the second stage, we devise a self-augmentation module to augment sequences to alleviate OUPs. Finally, we employ a hierarchical denoising module in the third stage to reduce the risk of false augmentations and pinpoint all noise in raw sequences. Extensive experiments on five real-world datasets demonstrate the superiority of SSDRec over state-of-the-art denoising methods and its flexible applications to mainstream sequential recommendation models. The source code is available online at https://github.com/zc-97/SSDRec.}
}


@inproceedings{DBLP:conf/icde/Wu0WSZW24,
	author = {Junkang Wu and
                  Jiawei Chen and
                  Jiancan Wu and
                  Wentao Shi and
                  Jizhi Zhang and
                  Xiang Wang},
	title = {{BSL:} Understanding and Improving Softmax Loss for Recommendation},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {816--830},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00068},
	doi = {10.1109/ICDE60146.2024.00068},
	timestamp = {Thu, 08 Aug 2024 08:05:57 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Wu0WSZW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Loss functions steer the optimization direction of recommendation models and are critical to model performance, but have received relatively little attention in recent recommendation research. Among various losses, we find Softmax loss (SL) stands out for not only achieving remarkable accuracy but also better robustness and fairness. Nevertheless, the current literature lacks a comprehensive explanation for the efficacy of SL. Toward addressing this research gap, we conduct theoretical analyses on SL and uncover three insights: 1) Optimizing SL is equivalent to performing Distributionally Robust Optimization (DRO) on the negative data, thereby learning against perturbations on the negative distribution and yielding robustness to noisy negatives. 2) Comparing with other loss functions, SL implicitly penalizes the prediction variance, resulting in a smaller gap between predicted values and and thus producing fairer results. Building on these insights, we further propose a novel loss function Bilateral SoftMax Loss (BSL) that extends the advantage of SL to both positive and negative sides. BSL augments SL by applying the same Log-Expectation-Exp structure to positive examples as is used for negatives, making the model robust to the noisy positives as well. Remarkably, BSL is simple and easy-to-implement - requiring just one additional line of code compared to SL. Experiments on four real-world datasets and three representative backbones demonstrate the effectiveness of our proposal. The code is available at https://github.com/junkangwu/BSL.}
}


@inproceedings{DBLP:conf/icde/0001YSLZC0024,
	author = {Yuhan Wu and
                  Aomufei Yuan and
                  Zhouran Shi and
                  Yuanpeng Li and
                  Yikai Zhao and
                  Peiqing Chen and
                  Tong Yang and
                  Bin Cui},
	title = {Online Detection of Outstanding Quantiles with QuantileFilter},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {831--844},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00069},
	doi = {10.1109/ICDE60146.2024.00069},
	timestamp = {Mon, 26 Aug 2024 16:11:59 +0200},
	biburl = {https://dblp.org/rec/conf/icde/0001YSLZC0024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In quantile estimation within a stream of key-value pairs, recent work has made significant progress in query flexibility, supporting quantile estimation for any key using a unified statistical structure. However, despite this flexibility, their query speed falls behind, unable to match the high speed of online data insertion. This “offline query + online insertion” model is not ideal for online quantile estimation. Our goal is to online detect keys whose quantiles exceed a user-queried threshold in real-time, such as identifying the user whose 95 % latency exceeds 200ms in network data. These keys, termed “Quantile-Outstanding Keys,” are vital for anomaly detection in streaming data. In this paper, we propose QuantileFilter, the first approximate algorithm specifically designed for detecting quantile-outstanding keys. QuantileFilter overcomes existing limitations by 1) enabling fast online computation, capable of handling streaming data in real-time with a constant processing time for each data item, accelerating the state-of-the-art (SOTA) by 10 ~ 100 times, and 2) maintaining high space efficiency, saving 50 ~ 500 times storage space compared to the SOTA while maintaining the same accuracy. All associated code is available on GitHub.}
}


@inproceedings{DBLP:conf/icde/WuCY024,
	author = {Binquan Wu and
                  Yu Cheng and
                  Haitao Yuan and
                  Qianli Ma},
	title = {When Multi-Behavior Meets Multi-Interest: Multi-Behavior Sequential
                  Recommendation with Multi-Interest Self-Supervised Learning},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {845--858},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00070},
	doi = {10.1109/ICDE60146.2024.00070},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/WuCY024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Sequential Recommendation utilizes interaction history to uncover users' dynamic interest changes and recommend the most relevant items for their next interaction. In recent years, multi-behavior modeling and multi-interest modeling have been hot research topics. Although multi-behavior and multi-interest methods have strengths in their respective domains, both have limitations. Multi-behavior methods focus excessively on target behavior recommendation (i.e., purchase) without sufficiently leveraging auxiliary behavior interactions (i.e., click) to discern users' multi-faced interests, leading to suboptimal recommendation quality. Meanwhile, existing multi-interest methods overlook the distinct user interests behind multi-behavior when extracting interests, resulting in inaccurate interest modeling. Combining the two can not only facilitate sophisticated modeling of complex user interests but also deepen understanding of multi-behavior interactions, achieving synergistic effects. In this paper, we propose a novel approach called Multi-Interest Self-Supervised Learning (MISSL) that precisely unifies multi-behavior and multi-interest modeling to obtain more comprehensive and accurate user profiles. MISSL utilizes a hypergraph transformer network to extract behavior-specific and shared interests followed by multi-interest self-supervised learning to refine item and interest representations. Additionally, a behavior-aware training task is incorporated to enhance model stability during training. Extensive experiments on benchmark datasets demonstrate that MISSL outperforms baseline methods. The source code for MISSL is available at: https://github.com/qianlima-Iab/MISSL.}
}


@inproceedings{DBLP:conf/icde/LiDCZ24,
	author = {Haoyang Li and
                  Shimin Di and
                  Lei Chen and
                  Xiaofang Zhou},
	title = {E\({}^{\mbox{2}}\)GCL: Efficient and Expressive Contrastive Learning
                  on Graph Neural Networks},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {859--873},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00071},
	doi = {10.1109/ICDE60146.2024.00071},
	timestamp = {Sun, 06 Oct 2024 21:04:58 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LiDCZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recently, graph contrastive learning proposes to learn node representations from the unlabeled graph to alleviate the heavy reliance on node labels in graph neural networks (GNNs). The core idea is to generate diverse positive views and negative views according to local subgraphs. Then, GNNs take these views as supervised signals and train the model by maximizing the similarity between positive view pairs of each node and minimizing the similarity between positive and negative views. Regardless of the fruitful progress, existing graph contrastive learning approaches still suffer from low-efficiency, insufficient-expressivity, and unpreserved-locality issues. First, they train GNNs by all nodes, reducing the efficiency due to similar and redundant nodes. Second, they only use limited operations (e.g., edge deletion and feature masking) to generate positive views, thereby restricting their expressivity. Third, they uniformly delete edges and mask node features and may modify important edges and features, thereby damaging the important locality information of nodes. In this paper, we propose an efficient and expressive contrastive learning framework for GNNs, namely E 2 GCL. Specifically, given a limited node budget, we select a set of representative nodes instead of all nodes to accelerate the GNNs training. Besides, we use three general operations (edge deletion, edge addition, and feature perturbation) to generate expressive and locality-preserved positive views based on edge and feature importance. Extensive experiments on various real-world datasets demonstrate the superior effectiveness and efficiency of our proposed E 2 GCL.}
}


@inproceedings{DBLP:conf/icde/ShenW24,
	author = {Wei Shen and
                  Haixu Went},
	title = {Ambiguous Entity Oriented Targeted Document Detection},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {874--886},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00072},
	doi = {10.1109/ICDE60146.2024.00072},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ShenW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The documents mentioning a target entity are essential prerequisites of various applications, such as market intelligence analysis, knowledge base enrichment, fact checking and retrieval augmented generation. A simple solution to acquire these documents is to exploit search engines via querying the name of the target entity. However, the name of the target entity appearing in a returned document does not necessarily mean it really refers to the target entity due to the name ambiguity, as it may refer to another entity sharing the same name as the target entity. Thus, in this paper, we explore a new task of targeted document detection, which aims to detect those targeted documents (i.e., documents really mentioning the target entity) from the given candidate documents each of which contains an ambiguous name of the target entity. We propose GADE, a novel Graph-based framework to solve the task of tArgeted Document dEtection by leveraging both the local relevance information and the global cross-document interactions jointly. We develop a local relevance model to capture the local relevance information between the target entity and the candidate document based on a pre-trained language model. Additionally, we derive a global interaction model to unify the two categories of global cross-document interactions (i.e., similarity interaction and dissimilarity interaction) among candidate documents. Specifically, a document interaction graph is constructed based on all the candidate documents of a target entity, and a graph neural network is applied over the graph to model the global cross-document interactions via message passing mechanism. We construct four labeled datasets for this task based on Wikipedia and Web documents respectively, and a thorough experimental study shows that our framework GADE significantly outperforms all the baseline methods in terms of F1-score.}
}


@inproceedings{DBLP:conf/icde/MaHLL24,
	author = {Xiangkai Ma and
                  Xiaobin Hong and
                  Sanglu Lu and
                  Wenzhong Li},
	title = {TS3Net: Triple Decomposition with Spectrum Gradient for Long-Term
                  Time Series Analysis},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {887--900},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00073},
	doi = {10.1109/ICDE60146.2024.00073},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/MaHLL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Time series analysis has a wide range of applications in the fields of weather forecasting, traffic management, fault detection, intelligent operation, etc. In the real world, time series typically consist of dynamic fluctuations and mixtures of periodicities, which bring challenges on modeling and analyzing their patterns. To overcome the complexities, a common approach is to decompose long-term time series into sub-components for easier analysis. Unlike conventional time series decomposition that decouples a series into the trend and seasonal parts, we proposed a novel triple decomposition method to decouple a long-term series into three components: trend-part, regular-part, and fluctuant-part. Notably, the third part is a particular component that represents the dynamic spectral fluctuation in time series with the formulation of spectrum gradient. Based on triple decomposition, we propose a novel task-general deep learning model called TS3Net for long-term series analysis. It introduces a temporal-frequency block (TF-Block) with a multi-branch structure to expand the time series into a 2D temporal-frequency distribution. Subsequently, deep representation can be learned by a vision architecture that captures the dynamic variations from the complex multi-periodic series. The decomposed components are processed by TS3Net individually, and their results are integrated to form the final result for time series analysis. We conduct extensive experiment based on six open datasets to evaluate the proposed method in comparison with 10 baselines. Numerical results show that TS3Net significantly outperforms the state-of-the-art methods on both time series forecasting and imputation tasks. The source codes of TS3Net are publicly available on https://github.com/Xiang-Kai/TS3Net.}
}


@inproceedings{DBLP:conf/icde/XieDXZ0024,
	author = {Jiang Xie and
                  Minggao Dai and
                  Shuyin Xia and
                  Jinajinz Zhang and
                  Guoyin Wang and
                  Xinbo Gao},
	title = {An Efficient Fuzzy Stream Clustering Method Based on Granular-Ball
                  Structure},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {901--913},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00074},
	doi = {10.1109/ICDE60146.2024.00074},
	timestamp = {Tue, 30 Jul 2024 09:46:05 +0200},
	biburl = {https://dblp.org/rec/conf/icde/XieDXZ0024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Current data stream clustering algorithms face low efficiency in both the online and offline phases, and struggle to address the problem of cluster boundary overlap caused by concept drift. Specifically, in the online phase, the majority of existing data stream clustering algorithms require each newly arriving sample to be scanned and inserted into the appropriate micro-clusters. In offline clustering, algorithms typically require all sample points as input. Moreover, most data stream clustering algorithms struggle to effectively deal with the problem of cluster boundary overlap caused by the concept drift. To tackle these challenges, we use a granular-ball structure for the coarse-grained representation of data stream. This structure eliminates the need for computations on all data points in both the online and offline phases. Additionally, we introduce fuzziness into the granular-ball structure to resolve the issue of cluster boundary overlap caused by the concept drift. Experimental results on both synthetic and real-world datasets demonstrate that our approach achieves efficient and accurate clustering performance when compared to existing data stream clustering algorithms. Our source code is publicly available at https://github.com/xjnine/GBFuzzyStream.}
}


@inproceedings{DBLP:conf/icde/0002HXC0024,
	author = {Jiang Xie and
                  Chunfeng Hua and
                  Shuyin Xia and
                  Yuxin Cheng and
                  Guoyin Wang and
                  Xinbo Gao},
	title = {{W-GBC:} An Adaptive Weighted Clustering Method Based on Granular-Ball
                  Structure},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {914--925},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00075},
	doi = {10.1109/ICDE60146.2024.00075},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/0002HXC0024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Existing weighted clustering algorithms often heavily rely on specific parameters. Specifically, in addition to the number of clusters (k), several other parameters need to be manually tuned, which greatly limits their practical applicability. The fundamental issue lies in the fact that most weighted clustering methods derive feature weights through global iterations. To address this challenge, this paper introduces a novel weighted granular-ball structure, continually optimizing weights during the ball splitting process and restricting the calculation of local data point weights to the corresponding weighted granular-ball. We employ local iterations within this structure as an approximation to global weight calculations. This method eliminates the need for parameter tuning during the weight calculation process and incidentally addresses the “curse of dimensionality” in traditional granular-ball computing model. When applied to complex real-world datasets, this method accurately represents high-dimensional data, thereby improving clustering precision and extending the adaptability of the granular-ball computing model in high-dimensional spaces. Comprehensive experimental analysis demonstrates that our W-GBC algorithm performs well in terms of clustering results and competes strongly with baseline algorithms. The code has been released and is now available at https://github.com/xjnine/W-GBC.}
}


@inproceedings{DBLP:conf/icde/ZhouLSLGL24,
	author = {Ting Zhou and
                  Ning Liu and
                  Bo Song and
                  Hongtao Lv and
                  Deke Guo and
                  Lei Liu},
	title = {RobFL: Robust Federated Learning via Feature Center Separation and
                  Malicious Center Detection},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {926--938},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00076},
	doi = {10.1109/ICDE60146.2024.00076},
	timestamp = {Thu, 08 Aug 2024 08:05:58 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhouLSLGL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent years, the integration of federated learning and deep learning technologies has become increasingly prevalent in privacy-preserved scenarios, such as smart health applications and automatic financial support. However, the inherent robustness issue in deep learning poses potential risks to federated learning systems when subjected to various attack methods. These attacks can inflict damage during the training and testing phases, perturbing models and inputs. To enhance the robustness of existing federated learning systems, we propose a novel framework called RobFL. This framework incorporates a unique feature learning module - feature center separation learning - that is specifically designed to increase the margins between different classes in the feature space, thereby augmenting the difficulty of attacks employing imperceptible perturbations on inputs. Furthermore, we design a malicious center detection method to detect malicious clients and mitigate their adverse impact. Extensive experiments substantiate the robustness of our proposed framework, RobFL, demonstrating its resilience against both evasion attacks and poisoning attacks.}
}


@inproceedings{DBLP:conf/icde/ChaiLTYF024,
	author = {Heyan Chai and
                  Zeyu Liu and
                  Yongxin Tong and
                  Ziyi Yao and
                  Binxing Fang and
                  Qing Liao},
	title = {Towards Task-Conflicts Momentum-Calibrated Approach for Multi-task
                  Learning},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {939--952},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00077},
	doi = {10.1109/ICDE60146.2024.00077},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ChaiLTYF024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Multi-task learning (MTL) has succeeded in various industrial applications by utilizing common knowledge among joint training tasks to enhance the generalization of MTL models, resulting in improved performance across all training tasks simultaneously. Unfortunately, training all tasks simultaneously often causes performance degradation compared to single-task models since different tasks might conflict with each other. Despite existing MTL methods that aim to mitigate task conflicts by manipulating task gradients at each iteration, they ignore the potential influence of noisy data from different batches on task gradients. Consequently, the current iteration's task gradient may not accurately reflect the task itself, leading to inadequate alleviation of the dilemma of task conflicts. Moreover, existing works seldom explore the potential source of task conflicts and merely pose an assumption. In this paper, we conduct an in-depth empirical investigation into the potential sources of performance degradation of MTL and find that task gradient conflict is one of the primary reasons for the performance degradation of tasks. Then, to address the task conflicts problem, we propose a novel gradient manipulation approach, namely MoCoGrad, which manipulates task gradients by leveraging the momentum information of the task to calibrate the gradients of conflicting tasks. In addition, we derive theoretical guarantees for the con-vergence of our proposed MoCoGrad and theoretically analyze the convergence rate of MoCoGrad. Finally, to evaluate the effectiveness of MoCoGrad, extensive experiments are conducted on six real-world datasets from different domains. Our approach yields the best performance across all tasks in all six MTL benchmarks, demonstrating the effectiveness and superiority of our method.}
}


@inproceedings{DBLP:conf/icde/Ding0Q24,
	author = {Guangyao Ding and
                  Chen Xu and
                  Weining Qian},
	title = {Hybrid Evaluation for Occlusion-based Explanations on {CNN} Inference
                  Queries},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {953--966},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00078},
	doi = {10.1109/ICDE60146.2024.00078},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Ding0Q24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Deep CNNs are increasingly prevalent in various application domains such as image processing. To explain a CNN prediction, it is popular to employ occlusion-based explanations (OBE). OBE helps users understand which parts of an image are important to a CNN prediction. Existing systems have explored incremental evaluation to accelerate CNN inference in OBE. However, they are oblivious that incremental evaluation does not always outperform full evaluation for certain layers. To address this issue, we propose a hybrid evaluation to efficiently interleave full and incremental evaluations during the CNN inference. Ad-ditionally, it employs a cost model to compare the overhead costs of two types of evaluations and a heuristic method to determine the efficient plan combination for common CNNs. More impor-tantly, hybrid evaluation adopts a dynamic programming-based method for attention-based CNNs. In particular, the dynamic programming-based method significantly reduces the overhead of searching for the efficient plan combination on the complex DAG structure. To demonstrate the efficiency of our techniques, we implement HyInJ, a hybrid CNN inf erence system based on PyTorch. Our experiments show that HyInf reduces execution time by up to 22% on GPU and 55% on CPU in comparison to the state-of-the-art incremental evaluation.}
}


@inproceedings{DBLP:conf/icde/ChenWCH24,
	author = {Yile Chen and
                  Zeyi Wen and
                  Jian Chen and
                  Jin Huang},
	title = {Enhancing the Performance of Bandit-based Hyperparameter Optimization},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {967--980},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00079},
	doi = {10.1109/ICDE60146.2024.00079},
	timestamp = {Tue, 06 Aug 2024 09:17:50 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ChenWCH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Bandit-based methods are commonly used for hyperparameter optimization (HPO), which is significant in data analytics. When confronted with numerous configurations and high-dimensional large problems, existing bandit-based methods face challenges of high evaluation cost and poor optimization performance. To address these challenges, we introduce an improved bandit-based approach that exhibits enhanced evaluation ability and is suitable for situations with limited resources. Specifically, our method first effectively utilizes the feature and label information to conduct representative groups for further evaluation. After that, two kinds of folds (i.e., general folds and special folds) are constructed to facilitate better evaluation of the configuration in the cross-validation process. Additionally, we incorporate variance and subset size into the evaluation metric to comprehensively evaluate the configuration. We integrate our proposed method into three commonly used bandit-based methods, and experimental results on multiple datasets show that our method has advantages in stability with accuracy improvement of 1 % to 15 % on the datasets tested. In addition, since our method can avoid configurations that are low-quality but time-consuming to evaluate, it is always more efficient than the existing bandit-based methods, and can even reduce the execution time by half in some datasets. Sometimes it takes a little more time, but the improvement in accuracy can be significant.}
}


@inproceedings{DBLP:conf/icde/SunPY0HY24,
	author = {Yuting Sun and
                  Guansong Pang and
                  Guanhua Ye and
                  Tong Chen and
                  Xia Hu and
                  Hongzhi Yin},
	title = {Unraveling the 'Anomaly' in Time Series Anomaly Detection: {A} Self-supervised
                  Tri-domain Solution},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {981--994},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00080},
	doi = {10.1109/ICDE60146.2024.00080},
	timestamp = {Sun, 06 Oct 2024 21:04:59 +0200},
	biburl = {https://dblp.org/rec/conf/icde/SunPY0HY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The ongoing challenges in time series anomaly detection (TSAD), including the scarcity of anomaly labels and the variability in anomaly lengths and shapes, have led to the need for a more robust and efficient solution. As limited anomaly labels hinder traditional supervised models in anomaly detection, various state-of-the-art (SOTA) deep learning (DL) techniques (e.g., self-supervised learning) are introduced to tackle this issue. However, they encounter difficulties handling variations in anomaly lengths and shapes, limiting their adaptability to diverse anomalies. Additionally, many benchmark datasets suffer from the problem of having explicit anomalies that even random functions can detect. This problem is exacerbated by an ill-posed evaluation metric, known as point adjustment (PA), which results in inflated model performance. In this context, we propose a novel self-supervised learning based Tri-domain Anomaly Detector (TriAD), which addresses these challenges by modeling features across three aspects - temporal, frequency, and residual domains - without relying on anomaly labels. Unlike traditional contrastive learning methods, TriAD employs both inter-domain and intra-domain contrastive loss to learn common attributes among normal data and differentiate them from anomalies. Additionally, our approach can detect anomalies of varying lengths by integrating with a discord discovery algorithm. It is worth noting that this study is the first to reevaluate the DL potential in TSAD, utilizing both rigorously designed datasets and evaluation metrics. Experimental results demonstrate that TriAD achieves a consistent and significant performance increase over both DL and non-DL SOTA baselines. Moreover, in comparison to SOTA discord discovery algorithms, TriAD improves anomaly detection accuracy by 50 % while cutting the inference time down to just one-tenth. Illuminating the significance of rigorous datasets and evaluation metrics, this paper offers a new direction for addressing the multifaceted challenges of TSAD. The source code is publicly available at https://github.com/pseudo-Skye/TriAD.}
}


@inproceedings{DBLP:conf/icde/Ouyang0WX024,
	author = {Yudian Ouyang and
                  Kun Xie and
                  Jigang Wen and
                  Gaogang Xie and
                  Kenli Li},
	title = {A Robust Low-Rank Tensor Decomposition and Quantization based Compression
                  Method},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {995--1008},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00081},
	doi = {10.1109/ICDE60146.2024.00081},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Ouyang0WX024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Tensor data is widely used in fields such as smart grids, cloud systems, and deep learning. As the scale of this data increases, storage and transmission costs rise significantly. Many tensor data exhibit low-rank structures, offering the potential for data compression through low-rank decomposition techniques. Tucker decomposition, a typical low-rank decomposition technique, achieves data compression and interpretability by capturing complex data correlations and representing the original tensor with a compact core tensor and factor matrices. However, the compression ratio provided by Tucker decomposition is often insufficient, particularly for large-scale tensors. To tackle this issue, we propose a robust low-rank tensor compression method that leverages Tucker decomposition with quantization and coding. Initially, we establish a robust Tucker decomposition framework that decomposes the low-rank tensor into a core tensor and factor matrices using well-designed Tucker rank-setting rules. This framework effectively handles noise and missing values. Subsequently, we conduct an in-depth analysis of the numerical characteristics of the core tensor and factor matrices within the Tucker decomposition framework. Based on their distinct characteristics, we design tailored quantization and coding schemes to compress the core tensor and factor matrices, respectively, thereby significantly improving the compression ratio of Tucker decomposition while maintaining high accu-racy. Through extensive experiments on four publicly available datasets (which can form 3 or 4 order tensors), we demonstrate that our approach can achieve compression ratios\n4×−10×\nhigher than the best competitor, with recovery errors improved by 8% - 42%.}
}


@inproceedings{DBLP:conf/icde/ZhangWQL0Z0024,
	author = {Mingchen Zhang and
                  Jiaan Wang and
                  Jianfeng Qu and
                  Zhixu Li and
                  An Liu and
                  Lei Zhao and
                  Zhigang Chen and
                  Xiaofang Zhou},
	title = {A Coarse-to-Fine Framework for Entity-Relation Joint Extraction},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {1009--1022},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00082},
	doi = {10.1109/ICDE60146.2024.00082},
	timestamp = {Tue, 30 Jul 2024 08:18:21 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhangWQL0Z0024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Extracting entities and relations from text is a significant task of information extraction. Existing extraction models often straightforwardly produce their confident prediction results without any reconsideration or double-checking, resulting in avoidable mistakes and sub-optimal performance. In this paper, we propose a novel coarse-to-fine extraction framework, which first extracts high-potential relations as well as entities via knowledge distillation, and then rechecks the predictions via handcrafted natural language inference (NLI) task in a fine-grained manner. Specifically, based on the knowledge distillation mechanism, we train multiple teacher models iteratively through an adaptive loss function for making one teacher concentrate more on the data that others are incompetent for. Then, these complementary teacher models are utilized to provide valuable soft-label information for training a considerate student model, enabling it to generate reliable preliminary predictions. Further, these generated potential relations and entities are formulated as hypotheses, together with the original sentences as premises, serving as the input for an NLI model. Considering the linguistic diversity of relational expression, we automatically generate various semantic templates for hypotheses through an\nN\n-gram mining strategy. Moreover, due to the existence of multi-fact sentences, a relation-guided Gaussian attention is designed to reduce the gap between the single-relation hypothesis and the multi-relation premise. To implement efficient training, we also develop several ways to generate high-quality negative samples, which help the NLI model learn to identify errors. Experimental results show that the proposed method is effective and outperforms other strong baselines on public benchmarks.}
}


@inproceedings{DBLP:conf/icde/WangXC24,
	author = {Yubo Wang and
                  Hao Xin and
                  Lei Chen},
	title = {KGLink: {A} Column Type Annotation Method that Combines Knowledge
                  Graph and Pre-Trained Language Model},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {1023--1035},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00083},
	doi = {10.1109/ICDE60146.2024.00083},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/WangXC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The semantic annotation of tabular data plays a crucial role in various downstream tasks. Previous research has proposed knowledge graph (KG)-based and deep learning-based methods, each with its inherent limitations. KG-based methods encounter difficulties annotating columns when there is no match for column cells in the KG. Moreover, KG-based methods can provide multiple predictions for one column, making it challenging to determine the semantic type with the most suitable granularity for the dataset. This type granularity issue limits their scalability. On the other hand, deep learning-based methods face challenges related to the valuable context missing issue. This occurs when the information within the table is insufficient for determining the correct column type. This paper presents KGLink, a method that combines Wiki-Data KG information with a pre-trained deep learning language model for table column annotation, effectively addressing both type granularity and valuable context missing issues. Through comprehensive experiments on widely used tabular datasets encompassing numeric and string columns with varying type granularity, we showcase the effectiveness and efficiency of KGLink. By leveraging the strengths of KGLink, we successfully surmount challenges related to type granularity and valuable context issues, establishing it as a robust solution for the semantic annotation of tabular data.}
}


@inproceedings{DBLP:conf/icde/LiuWX24,
	author = {Yuli Liu and
                  Christian Walder and
                  Lexing Xie},
	title = {Learning k-Determinantal Point Processes for Personalized Ranking},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {1036--1049},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00084},
	doi = {10.1109/ICDE60146.2024.00084},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LiuWX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The key to personalized recommendation is to predict a personalized ranking on a catalog of items by modeling the user's preferences. There are many personalized ranking approaches for item recommendation from implicit feedback like Bayesian Personalized Ranking (BPR) and listwise ranking. Despite these methods have shown performance benefits, there are still limitations affecting recommendation performance. First, none of them directly optimize ranking of sets, causing inadequate exploitation of correlations among multiple items. Second, the diversity aspect of recommendations is insufficiently addressed compared to relevance. In this work, we present a new optimization criterion LkP based on set probability comparison for personalized ranking that moves beyond traditional ranking-based methods. It for-malizes set-level relevance and diversity ranking comparisons through a Determinantal Point Process (DPP) kernel decom-position. To confer ranking interpretability to the DPP set probabilities and prioritize the practicality of LkP, we condition the standard DPP on the cardinality\nk\nof the DPP-distributed set, known as k-DPP, a less-explored extension of DPP. The generic stochastic gradient descent based technique can be directly applied to optimizing models that employ LkP. We implement LkP in the context of both Matrix Factorization (MF) and neural networks approaches, on three real-world datasets, obtaining improved relevance and diversity performances. LkP is broadly applicable, and when applied to existing recommendation models it also yields strong performance improvements, suggesting that LkP holds significant value to the field of recommender systems.}
}


@inproceedings{DBLP:conf/icde/00010GY0HXJ24,
	author = {Hao Miao and
                  Yan Zhao and
                  Chenjuan Guo and
                  Bin Yang and
                  Kai Zheng and
                  Feiteng Huang and
                  Jiandong Xie and
                  Christian S. Jensen},
	title = {A Unified Replay-Based Continuous Learning Framework for Spatio-Temporal
                  Prediction on Streaming Data},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {1050--1062},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00085},
	doi = {10.1109/ICDE60146.2024.00085},
	timestamp = {Tue, 30 Jul 2024 08:18:19 +0200},
	biburl = {https://dblp.org/rec/conf/icde/00010GY0HXJ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The widespread deployment of wireless and mobile devices results in a proliferation of spatio-temporal data that is used in applications, e.g., traffic prediction, human mobility mining, and air quality prediction, where spatio-temporal prediction is often essential to enable safety, predictability, or reliability. Many recent proposals that target deep learning for spatio-temporal prediction suffer from so-called catastrophic forgetting, where previously learned knowledge is entirely forgotten when new data arrives. Such proposals may experience deteriorating prediction performance when applied in settings where data streams into the system. To enable spatio-temporal prediction on streaming data, we propose a unified replay- based continuous learning framework. The framework includes a replay buffer of previously learned samples that are fused with training data using a spatio-temporal mixup mechanism in order to preserve historical knowledge effectively, thus avoiding catastrophic forgetting. To enable holistic representation preservation, the framework also integrates a general spatio-temporal autoencoder with a carefully designed spatio-temporal simple siamese (STSimSiam) network that aims to ensure prediction accuracy and avoid holistic feature loss by means of mutual information maximization. The framework further encompasses five spatio-temporal data augmentation methods to enhance the performance of STSimSiam. Extensive experiments on real data offer insight into the effectiveness of the proposed framework.}
}


@inproceedings{DBLP:conf/icde/DuanZZTW24,
	author = {Tao Duan and
                  Junzhou Zhao and
                  Shuo Zhang and
                  Jing Tao and
                  Pinghui Wang},
	title = {Representation Learning of Tangled Key-Value Sequence Data for Early
                  Classification},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {1063--1075},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00086},
	doi = {10.1109/ICDE60146.2024.00086},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/DuanZZTW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Key-value sequence data has become ubiquitous and naturally appears in a variety of real-world applications, ranging from the user-product purchasing sequences in e-commerce, to network packet sequences forwarded by routers in networking. Classifying these key-value sequences is important in many scenarios such as user profiling and malicious applications identification. In many time-sensitive scenarios, besides the requirement of classifying a key-value sequence accurately, it is also desired to classify a key-value sequence early, in order to respond fast. However, these two goals are conflicting in nature, and it is challenging to achieve them simultaneously. In this work, we formulate a novel tangled key-value sequence early classification problem, where a tangled key-value sequence is a mixture of several concurrent key-value sequences with different keys. The goal is to classify each individual key-value sequence sharing a same key both accurately and early. To address this problem, we propose a novel method, i.e., Key-Value sequence Early Co-classification (KVEC), which leverages both inner- and inter-correlations of items in a tangled key-value sequence through key correlation and value correlation to learn a better sequence representation. Meanwhile, a time-aware halting policy decides when to stop the ongoing key-value sequence and classify it based on current sequence representation. Experiments on both real-world and synthetic datasets demonstrate that our method outperforms the state-of-the-art baselines significantly. KVEC improves the prediction accuracy by up to 4.7 -17.5% under the same prediction earliness condition, and improves the harmonic mean of accuracy and earliness by up to 3.7 -14.0%.}
}


@inproceedings{DBLP:conf/icde/CuiST0024,
	author = {Jianwei Cui and
                  Wenhang Shi and
                  Honglin Tao and
                  Wei Lu and
                  Xiaoyong Du},
	title = {A Two-Phase Recall-and-Select Framework for Fast Model Selection},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {1076--1089},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00087},
	doi = {10.1109/ICDE60146.2024.00087},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/CuiST0024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As the ubiquity of deep learning in various machine learning applications has amplified, a proliferation of neural network models has been trained and shared on public model repositories. In the context of a targeted machine learning assignment, utilizing an apt source model as a starting point typically outperforms the strategy of training from scratch, particularly with limited training data. Despite the investigation and development of numerous model selection strategies in prior work, the process remains time-consuming, especially given the ever-increasing scale of model repositories. In this paper, we propose a two-phase (coarse-recall and fine-selection) model selection framework, aiming to enhance the efficiency of selecting a robust model by leveraging the models' training performances on benchmark datasets. Specifically, the coarse-recall phase clusters models showcasing similar training performances on benchmark datasets in an offline manner. A light-weight proxy score is subsequently computed between this model cluster and the target dataset, which serves to recall a significantly smaller subset of potential candidate models in a swift manner. In the following fine-selection phase, the final model is chosen by fine-tuning the recalled models on the target dataset with successive halving. To accelerate the process, the final fine-tuning performance of each potential model is predicted by mining the model's convergence trend on the benchmark datasets, which aids in filtering lower performance models more earlier during fine-tuning. Through extensive experimentation on tasks covering natural language processing and computer vision, it has been demonstrated that the proposed methodology facilitates the selection of a high-performing model at a rate about 3x times faster than conventional baseline methods. Our code is available at https://github.com/plasware/two-phase-selection.}
}


@inproceedings{DBLP:conf/icde/KimHP24,
	author = {Chaeeun Kim and
                  Changhun Han and
                  Ha{-}Myung Park},
	title = {{BTS:} Load-Balanced Distributed Union-Find for Finding Connected
                  Components with Balanced Tree Structures},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {1090--1102},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00089},
	doi = {10.1109/ICDE60146.2024.00089},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/KimHP24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {How can we efficiently find connected components with Union-Find in a distributed system? Union-Find is the most efficient sequential algorithm for finding connected components with low memory usage and high speed. Several studies have adapted Union-Find to distributed memory systems to process large graphs quickly; however, they all suffer from load balancing problems. We notice that the leading cause of the load balancing problems is the nature of Union-Find, which gathers more and more edges to a small number of vertices as it proceeds. In this paper, we propose BTS, a new fast and scalable distributed Union-Find algorithm for finding connected components in large graphs. BTS resolves the load balancing problems by proposing Balanced Union-Find, which allocates vertices to each processor and makes edges link to vertices in the same processor as much as possible. We further optimize BTS with edge refinement to minimize network traffic and memory usage. Experimental results show that BTS efficiently resolves the load balancing problems, processing 16–1024 times larger graphs with 3.1-261.9 times faster speeds than existing algorithms.}
}


@inproceedings{DBLP:conf/icde/CuiYJZWZ24,
	author = {Jiajun Cui and
                  Minghe Yu and
                  Bo Jiang and
                  Aimin Zhou and
                  Jianyong Wang and
                  Wei Zhang},
	title = {Interpretable Knowledge Tracing via Response Influence-based Counterfactual
                  Reasoning},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {1103--1116},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00090},
	doi = {10.1109/ICDE60146.2024.00090},
	timestamp = {Mon, 07 Oct 2024 08:29:24 +0200},
	biburl = {https://dblp.org/rec/conf/icde/CuiYJZWZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Knowledge tracing (KT) plays a crucial role in computer-aided education and intelligent tutoring systems, aiming to assess students' knowledge proficiency by predicting their future performance on new questions based on their past response records. While existing deep learning knowledge tracing (DLKT) methods have significantly improved prediction accuracy and achieved state-of-the-art results, they often suffer from a lack of interpretability. To address this limitation, current approaches have explored incorporating psychological influences to achieve more explainable predictions, but they tend to overlook the potential influences of historical responses. In fact, understanding how models make predictions based on response influences can enhance the transparency and trustworthiness of the knowledge tracing process, presenting an opportunity for a new paradigm of interpretable KT. However, measuring unobservable response influences is challenging. In this paper, we resort to counterfactual reasoning that intervenes in each response to answer what if a student had answered a question incorrectly that he/she actually answered correctly, and vice versa. Based on this, we propose RCKT, a novel response influence-based counterfactual knowledge tracing framework. RCKT generates response influences by comparing prediction outcomes from factual sequences and constructed counterfactual sequences after interventions. Additionally, we introduce maximization and inference techniques to leverage accumulated influences from different past responses, further improving the model's performance and credibility. Extensive experimental results demonstrate that our RCKT method outperforms state-of-the-art knowledge tracing methods on four datasets against six baselines, and provides credible interpretations of response influences. The source code is available at https://github.com/JJCui96IRCKT.}
}


@inproceedings{DBLP:conf/icde/ZhangWKDSW24,
	author = {Yuling Zhang and
                  Anpeng Wu and
                  Kun Kuang and
                  Liang Du and
                  Zixun Sun and
                  Zhi Wang},
	title = {Stable Heterogeneous Treatment Effect Estimation across Out-of-Distribution
                  Populations},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {1117--1130},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00091},
	doi = {10.1109/ICDE60146.2024.00091},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhangWKDSW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Heterogeneous treatment effect (HTE) estimation is vital for understanding the change of treatment effect across individuals or subgroups. Most existing HTE estimation methods focus on addressing selection bias induced by imbalanced distributions of confounders between treated and control units, but ignore distribution shifts across populations. Thereby, their applicability has been limited to the in-distribution (ID) population, which shares a similar distribution with the training dataset. In real-world applications, where population distributions are subject to continuous changes, there is an urgent need for stable HTE estimation across out-of-distribution (OOD) populations, which, however, remains an open problem. As pioneers in resolving this problem, we propose a novel Stable Balanced Representation Learning with Hierarchical-Attention Paradigm (SBRL-HAP) framework, which consists of 1) Balancing Regularizer for eliminating selection bias, 2) Independence Regularizer for addressing the distribution shift issue, 3) Hierarchical-Attention Paradigm for coordination between balance and independence. In this way, SBRL- HAP regresses counterfactual outcomes using ID data, while ensuring the resulting HTE estimation can be successfully generalized to out-of-distribution scenarios, thereby enhancing the model's applicability in real-world settings. Extensive experiments conducted on synthetic and real-world datasets demonstrate the effectiveness of our SBRL-HAP in achieving stable HTE estimation across OOD populations, with an average 10% reduction in the error metric PEHE and 11% decrease in the ATE bias, compared to the SOTA methods.}
}


@inproceedings{DBLP:conf/icde/CarvalhoPZCY24,
	author = {Marcus de Carvalho and
                  Mahardhika Pratama and
                  Jie Zhang and
                  Haoyan Chua and
                  Edward Kien Yee Yapp},
	title = {Towards Cross-Domain Continual Learning},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {1131--1142},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00092},
	doi = {10.1109/ICDE60146.2024.00092},
	timestamp = {Sun, 06 Oct 2024 21:04:56 +0200},
	biburl = {https://dblp.org/rec/conf/icde/CarvalhoPZCY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Continual learning is a process that involves training learning agents to sequentially master a stream of tasks or classes without revisiting past data. The challenge lies in leveraging previously acquired knowledge to learn new tasks efficiently, while avoiding catastrophic forgetting. Existing methods primarily focus on single domains, restricting their applicability to specific problems. In this work, we introduce a novel approach called Cross-Domain Continual Learning (CDCL) that addresses the limitations of being limited to single supervised domains. Our method combines inter- and intra-task cross-attention mechanisms within a compact convolutional network. This integration enables the model to maintain alignment with features from previous tasks, thereby delaying the data drift that may occur between tasks, while performing unsupervised cross-domain (UDA) between related domains. By leveraging an intra-task-specific pseudo-labeling method, we ensure accurate input pairs for both labeled and unlabeled samples, enhancing the learning process. To validate our approach, we conduct extensive experiments on public UDA datasets, showcasing its positive performance on cross-domain continual learning challenges. Additionally, our work introduces incremental ideas that contribute to the advancement of this field. We make our code and models available to encourage further exploration and reproduction of our results: https://github.com/IvsucramlCDCL}
}


@inproceedings{DBLP:conf/icde/0001PMDA24,
	author = {Anna Beer and
                  Oliv{\'{e}}r Palot{\'{a}}s and
                  Andrea Maldonado and
                  Andrew Draganov and
                  Ira Assent},
	title = {{DROPP:} Structure-Aware {PCA} for Ordered Data: {A} General Method
                  and its Applications in Climate Research and Molecular Dynamics},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {1143--1156},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00093},
	doi = {10.1109/ICDE60146.2024.00093},
	timestamp = {Mon, 05 Aug 2024 15:14:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/0001PMDA24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Ordered data arises in many areas, e.g., in molec-ular dynamics and other spatial-temporal trajectories. While data points that are close in this order are related, common dimensionality reduction techniques cannot capture this relation or order. Thus, the information is lost in the low-dimensional representations. We introduce DROPP, which incorporates order into dimensionality reduction by adapting a Gaussian kernel function across the ordered covariances between data points. We find underlying principal components that are characteristic of the process that generated the data. In extensive experiments, we show DROPP's advantages over other dimensionality re-duction techniques on synthetic as well as real-world data sets from molecular dynamics and climate research: The principal components of different data sets that were generated by the same underlying mechanism are very similar to each other. They can, thus, be used for dimensionality reduction with low reconstruction errors along a set of data sets, allowing an explainable visual comparison of different data sets as well as good compression even for unseen data.}
}


@inproceedings{DBLP:conf/icde/WuWJPZYCY024,
	author = {Yuhan Wu and
                  Hanbo Wu and
                  Chengjun Jia and
                  Bo Peng and
                  Ziyun Zhang and
                  Tong Yang and
                  Peiqing Chen and
                  Kaicheng Yang and
                  Bin Cui},
	title = {Scalable Overspeed Item Detection in Streams},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {1157--1170},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00094},
	doi = {10.1109/ICDE60146.2024.00094},
	timestamp = {Tue, 30 Jul 2024 08:18:18 +0200},
	biburl = {https://dblp.org/rec/conf/icde/WuWJPZYCY024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In data stream mining, monitoring high-speed users and segregating their excessive use, known as “Overspeed items,” is crucial for preventing system overload and maintaining fairness in messaging and network systems. Current approaches, however, face scalability challenges with large user bases, primarily due to increasing memory requirements proportional to user numbers. We have pinpointed the inefficiency in allocating memory for all users, recognizing that only a small fraction exhibit overspeed behavior at any given time. Addressing this, we employed the sketching technique, a type of approximate algorithm, and designed the first sketch algorithm for finding Overspeed items, named SpeedSketch: (1) Scalability. SpeedSketch can scale user numbers (saving memory space) to a factor of 6430 while maintaining a low average error rate of 0.1% in real-world datasets. (2) Accuracy. In theory, SpeedSketch stands out as the only sketch algorithm offering a per-user relative error bound. (3) Speed. SpeedSketch is implemented on a high-speed programmable switch with a throughput capacity of 4.8 billion items per second. All codes are available on GitHub for reference.}
}


@inproceedings{DBLP:conf/icde/GuoWXS24,
	author = {Yang Guo and
                  Zhiqi Wang and
                  Jin Xue and
                  Zili Shao},
	title = {A Spatio-Temporal Series Data Model with Efficient Indexing and Layout
                  for Cloud-Based Trajectory Data Management},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {1171--1184},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00313},
	doi = {10.1109/ICDE60146.2024.00313},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/GuoWXS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Massive trajectory data are continuously generated with the rapid development of location-acquisition devices such as vehicles and smartphones. To provide services for applications such as mobility pattern discovery, how to manage such gigantic trajectory data to support queries in an efficient and cost-effective way becomes vitally important. Due to its low cost, large storage capacity, and reliability, cloud storage such as S3 becomes a new paradigm for storing gigantic data and is used in some general-purpose data management systems to strike a balance between performance and monetary costs. However, few systems exploit the inherent features of cloud storage for trajectory data. In this paper, we propose a novel cloud-based trajectory data management technique, called Springbok, to bridge the gap between massive trajectory data and cloud storage. Springbok is designed to address several key issues related to cloud-based trajectory data management. First, Springbok treats trajectories as first-class citizens using a new spatio-temporal series data model that can benefit insertion, query processing, and storage management in the cloud. Second, a holistic indexing scheme that considers features of trajectory data and cloud storage is designed to facilitate efficient queries. Third, based on performance features and billing models of cloud storage, we design effective data layouts for trajectory data and corresponding data flushing and access policies in a tiered cloud storage architecture for performance improvement and cost reduction. We have implemented a fully functional prototype of Springbok and conducted evaluations using both real-world and synthetic datasets, demonstrating its ability to achieve a good tradeoff between performance and monetary costs. Springbok has been open-sourced for public access.}
}


@inproceedings{DBLP:conf/icde/LiD0024,
	author = {Ran Li and
                  Shimin Di and
                  Lei Chen and
                  Xiaofang Zhou},
	title = {GradGCL: Gradient Graph Contrastive Learning},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {1171--1184},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00095},
	doi = {10.1109/ICDE60146.2024.00095},
	timestamp = {Sun, 06 Oct 2024 21:04:58 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LiD0024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graph self-supervised learning aiming to learn the graph representation without much label information is an important tasks in data mining and machine learning since labeled graph data is scarce and expensive to obtain in the real world. Contrastive learning emerges as a promising solution. However, we show existing graph contrastive learning (GCL) models have a significant issue: they generate representations that collapse into a low-dimensional subspace, resulting in a loss of information and diversity. We believe this issue arises from the strong assumption in current GCL methods that all positive samples should be close and all negative samples should be far in the representation space. From a data engineering view, this assumption fails to deeply mine the graph data and oversimplifies the complexity and heterogeneity of graph data, leading to clustered and redundant representations. To address this issue, we propose GradGCL, a novel method that leverages intrinsic gradient information as an additional input signal to regularize GCL training. The gradient information reflects the optimization process of the representations with respect to the contrastive loss, providing a complementary perspective to the representations. Furthermore, we have designed a soft separation strategy that relaxes the hard separation strategy between positive and negative samples, allowing for more flexibility and diversity in the representation space. We have conducted extensive experiments on various graph-related tasks, using different types of contrastive losses, datasets, and model architectures. We demonstrate that gradients alone can learn graph information and achieve competitive results with representation-based GCL methods. We also show that GradGCL can enhance existing GCL models and prevent the issue of dimensional collapse.}
}


@inproceedings{DBLP:conf/icde/Li0LYZZ24,
	author = {Shuhao Li and
                  Yue Cui and
                  Libin Li and
                  Weidong Yang and
                  Fan Zhang and
                  Xiaofang Zhou},
	title = {{ST-ABC:} Spatio-Temporal Attention-Based Convolutional Network for
                  Multi-Scale Lane-Level Traffic Prediction},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {1185--1198},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00096},
	doi = {10.1109/ICDE60146.2024.00096},
	timestamp = {Wed, 13 Nov 2024 17:13:07 +0100},
	biburl = {https://dblp.org/rec/conf/icde/Li0LYZZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the widespread application of intelligent transportation systems and navigation software, traffic prediction should be modeled in finer granularity to facilitate lane-changing guidance and congestion mitigation. However, existing studies divide the road network into continuous segments which assumes different lanes share the same spatio-temporal patterns. This paper proposes a novel lightweight, attention-based, fully convolutional model, named the Spatio-Temporal Attention- Based Convolutional network (ST-ABC), where lane segments are treated as graph nodes and dynamically models the adjacent spatial dependencies using local attention graph convolution. The attention-based dilated convolutions can process longer sequence periods in parallel, and a global attention layer allows individual nodes to be associated with the global context. By setting a target window, it can further reduce unnecessary computations and improve the prediction effect for the targeted area. Further-more, the ST-ABC model facilitates the simultaneous integration of spatio-temporal information and relational distance metrics among lane segments, enriching the granularity of multi-scaled spatial prediction. Empirical evaluations conducted on two real-world datasets substantiate the augmented efficacy of the STABC model in comparison to established models, with a marked prominence in long-term prediction scenarios.}
}


@inproceedings{DBLP:conf/icde/BeiX0CWZLB24,
	author = {Yuanchen Bei and
                  Hao Xu and
                  Sheng Zhou and
                  Huixuan Chi and
                  Haishuai Wang and
                  Mengdi Zhang and
                  Zhao Li and
                  Jiajun Bu},
	title = {{CPDG:} {A} Contrastive Pre-Training Method for Dynamic Graph Neural
                  Networks},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {1199--1212},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00097},
	doi = {10.1109/ICDE60146.2024.00097},
	timestamp = {Tue, 30 Jul 2024 08:18:21 +0200},
	biburl = {https://dblp.org/rec/conf/icde/BeiX0CWZLB24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Dynamic graph data mining has gained popularity in recent years due to the rich information contained in dynamic graphs and their widespread use in the real world. Despite the advances in dynamic graph neural networks (DGNNs), the rich information and diverse downstream tasks have posed significant difficulties for the practical application of DGNNs in industrial scenarios. To this end, in this paper, we propose to address them by pre-training and present the Contrastive Pre-Training Method for Dynamic Graph Neural Networks (CPDG). CPDG tackles the challenges of pre-training for DGNNs, including generalization capability and long-short term modeling capability, through a flexible structural-temporal subgraph sampler along with structural-temporal contrastive pre-training schemes. Extensive experiments conducted on both large-scale research and industrial dynamic graph datasets show that CPDG outperforms existing methods in dynamic graph pre-training for various downstream tasks under three transfer settings.}
}


@inproceedings{DBLP:conf/icde/AiZZLML024,
	author = {Xing Ai and
                  Jialong Zhou and
                  Yulin Zhu and
                  Gaolei Li and
                  Tomasz P. Michalak and
                  Xiapu Luo and
                  Kai Zhou},
	title = {Graph Anomaly Detection at Group Level: {A} Topology Pattern Enhanced
                  Unsupervised Approach},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {1213--1227},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00098},
	doi = {10.1109/ICDE60146.2024.00098},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/AiZZLML024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graph anomaly detection (GAD) has achieved success and has been widely applied in various domains, such as fraud detection, cybersecurity, finance security, and biochemistry. However, existing graph anomaly detection algorithms focus on distinguishing individual entities (nodes or graphs) and overlook the possibility of anomalous groups within the graph. To address this limitation, this paper introduces a novel unsupervised framework for a new task called Group-level Graph Anomaly Detection (Gr-GAD). The proposed framework first employs a variant of Graph AutoEncoder (GAE) to locate anchor nodes that belong to potential anomaly groups by capturing long-range inconsistencies. Subsequently, group sampling is employed to sample candidate groups, which are then fed into the proposed Topology Pattern-based Graph Contrastive Learning (TPGCL) method. TPGCL utilizes the topology patterns of groups as clues to generate embeddings for each candidate group and thus distinct anomaly groups. The experimental results on both real-world and synthetic datasets demonstrate that the proposed framework shows superior performance in identifying and localizing anomaly groups, highlighting it as a promising solution for Gr-GAD. Datasets and codes of the proposed framework are at the github repository https://github.com/STiL-Team/Topology-Pattern-Enhanced-Unsupervised-Group-level-Graph-Anomaly-Detection.git.}
}


@inproceedings{DBLP:conf/icde/FangXZ0G024,
	author = {Yuchen Fang and
                  Jiandong Xie and
                  Yan Zhao and
                  Lu Chen and
                  Yunjun Gao and
                  Kai Zheng},
	title = {Temporal-Frequency Masked Autoencoders for Time Series Anomaly Detection},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {1228--1241},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00099},
	doi = {10.1109/ICDE60146.2024.00099},
	timestamp = {Mon, 12 Aug 2024 18:35:46 +0200},
	biburl = {https://dblp.org/rec/conf/icde/FangXZ0G024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the era of observability, massive amounts of time series data have been collected to monitor the running status of the target system, where anomaly detection serves to identify observations that differ significantly from the remaining ones and is of utmost importance to enable value extraction from such data. While existing reconstruction-based methods have demonstrated favorable detection capabilities in the absence of labeled data, they still encounter issues of training bias on abnormal times and distribution shifts within time series. To address these issues, we propose a simple yet effective Temporal-Frequency Masked AutoEncoder (TFMAE) to detect anomalies in time series through a contrastive criterion. Specifically, TFMAE uses two Transformer-based autoencoders that respectively incorporate a window-based temporal masking strategy and an amplitude-based frequency masking strategy to learn knowledge without abnormal bias and reconstruct anomalies by the extracted normal information. Moreover, the dual autoencoder undergoes training through a contrastive objective function, which minimizes the discrepancy of representations from temporal-frequency masked autoencoders to highlight anomalies, as it helps alleviate the negative impact of distribution shifts. Finally, to prevent over-fitting, TFMAE adopts adversarial training during the training phase. Extensive experiments conducted on seven datasets provide evidence that our model is able to surpass the state-of-the-art in terms of anomaly detection accuracy.}
}


@inproceedings{DBLP:conf/icde/XiaoHSH0024,
	author = {Jinzhao Xiao and
                  Wendi He and
                  Shaoxu Song and
                  Xiangdong Huang and
                  Chen Wang and
                  Jianmin Wang},
	title = {{REGER:} Reordering Time Series Data for Regression Encoding},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {1242--1254},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00100},
	doi = {10.1109/ICDE60146.2024.00100},
	timestamp = {Mon, 09 Sep 2024 19:07:30 +0200},
	biburl = {https://dblp.org/rec/conf/icde/XiaoHSH0024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Regression models are employed in lossless compression of time series data, by storing the residual of each point, known as regression encoding. Owing to value fluctuation, the regression residuals could be large and thus occupy huge space. It is worth noting that compared to the fluctuating values, time intervals are often regular and easy to compress, especially in the IoT scenarios where sensor data are collected in a preset frequency. In this sense, there is a trade-off between storing the regular timestamps and fluctuating values. Intuitively, rather than in time order, we may exchange the data points in the series such that the nearby ones have both smoother timestamps and values, leading to lower residuals. In this paper, we propose to reorder the time series data for better regression encoding. Rather than recomputing from scratch, efficient updates of residuals after moving some points are devised. The experimental comparison over various real-world datasets, either public or collected by our industrial partners, illustrates the superiority of the proposal in compression ratio. The method, REGression Encoding with Reordering (REGER), has now become an encoding method in an open-source time series database, Apache IoTDB.}
}


@inproceedings{DBLP:conf/icde/JiangLCLKLC24,
	author = {Yue Jiang and
                  Xiucheng Li and
                  Yile Chen and
                  Shuai Liu and
                  Weilong Kong and
                  Antonis F. Lentzakis and
                  Gao Cong},
	title = {{SAGDFN:} {A} Scalable Adaptive Graph Diffusion Forecasting Network
                  for Multivariate Time Series Forecasting},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {1255--1268},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00101},
	doi = {10.1109/ICDE60146.2024.00101},
	timestamp = {Tue, 06 Aug 2024 09:17:50 +0200},
	biburl = {https://dblp.org/rec/conf/icde/JiangLCLKLC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Time series forecasting is essential for our daily activities and precise modeling of the complex correlations and shared patterns among multiple time series is essential for improving forecasting performance. Spatial-Temporal Graph Neural Networks (STGNNs) are widely used in multivariate time series forecasting tasks and have achieved promising performance on multiple real-world datasets for their ability to model the underlying complex spatial and temporal dependencies. However, existing studies have mainly focused on datasets comprising only a few hundred sensors due to the heavy computational cost and memory cost of spatial-temporal GNNs. When applied to larger datasets, these methods fail to capture the underlying complex spatial dependencies and exhibit limited scalability and performance. To this end, we present a Scalable Adaptive Graph Diffusion Forecasting Network (SAGDFN) to capture complex spatial-temporal correlation for large-scale multivariate time series and thereby, leading to exceptional performance in multivariate time series forecasting tasks. The proposed SAGDFN is scalable to datasets of thousands of nodes without the need of prior knowledge of spatial correlation. Extensive experiments demonstrate that SAGDFN achieves comparable performance with state-of-the-art baselines on one real-world dataset of 207 nodes and outperforms all state-of-the-art baselines by a significant margin on three real-world datasets of 2000 nodes.}
}


@inproceedings{DBLP:conf/icde/LiuYZC24,
	author = {Guangyi Liu and
                  Quanming Yao and
                  Yongqi Zhang and
                  Lei Chen},
	title = {Knowledge-Enhanced Recommendation with User-Centric Subgraph Network},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {1269--1281},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00102},
	doi = {10.1109/ICDE60146.2024.00102},
	timestamp = {Tue, 30 Jul 2024 08:18:21 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LiuYZC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recommendation systems, as widely implemented nowadays on various platforms, recommend relevant items to users based on their preferences. The classical methods which rely on user-item interaction matrices has limitations, especially in scenarios where there is a lack of interaction data for new items. Knowledge graph (KG)-based recommendation systems have emerged as a promising solution. However, most KG-based methods adopt node embeddings, which do not provide personal-ized recommendations for different users and cannot generalize well to the new items. To address these limitations, we propose Knowledge-enhanced User-Centric subgraph Network (KUCNet), a subgraph learning approach with graph neural network (GNN) for effective recommendation. KUCN et constructs a U-I subgraph for each user-item pair that captures both the historical information of user-item interactions and the side information provided in KG. An attention-based GNN is designed to encode the U-I subgraphs for recommendation. Considering efficiency, the pruned user-centric computation graph is further introduced such that multiple U-I subgraphs can be simultaneously computed and that the size can be pruned by Personalized PageRank. Our proposed method achieves accurate, efficient, and interpretable recommendations especially for new items. Experimental results demonstrate the superiority of KUCNet over state-of-the-art KG-based and collaborative filtering (CF)-based methods. Our code and data is available in https://github.com/leolouis14/KUCNet. 1}
}


@inproceedings{DBLP:conf/icde/Qin0TCD0F024,
	author = {Jianyang Qin and
                  Yan Jia and
                  Yongxin Tong and
                  Heyan Chai and
                  Ye Ding and
                  Xuan Wang and
                  Binxing Fang and
                  Qing Liao},
	title = {MUSE-Net: Disentangling Multi-Periodicity for Traffic Flow Forecasting},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {1282--1295},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00103},
	doi = {10.1109/ICDE60146.2024.00103},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Qin0TCD0F024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Accurate forecasting of traffic flow plays a crucial role in building smart cities in the new era. Previous work has achieved success in learning inherent spatial and temporal patterns of traffic flow. However, existing works investigated the multiple periodicities (e.g., hourly, daily, and weekly) of traffic via entanglement learning, which has not yet dealt with distribution shift and interaction shift problems in traffic flow. In this paper, we propose a novel disentanglement learning network, called MUSE-Net, to tackle the limitations of entanglement learning by simultaneously factorizing the exclusiveness and interaction of multi-periodic patterns in traffic flow. Grounded in the theory of mutual information, we first learn and dis-entangle exclusive and interactive representations of traffics from multi-periodic patterns. Then, we utilize semantic-pushing and semantic-pulling regularizations to encourage the learned representations to be independent and informative. Moreover, we derive a lower bound estimator to tractably optimize the disentanglement problem with multiple variables and propose a joint training model for traffic forecasting. Extensive experimental results on several real-world traffic datasets demonstrate the effectiveness of the proposed framework. The code is available at: https://github.com/JianyangQin/MUSE-Net.}
}


@inproceedings{DBLP:conf/icde/LiWZKB024,
	author = {Ziyu Li and
                  Hilco van der Wilk and
                  Danning Zhan and
                  Megha Khosla and
                  Alessandro Bozzon and
                  Rihan Hai},
	title = {Model Selection with Model Zoo via Graph Learning},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {1296--1309},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00088},
	doi = {10.1109/ICDE60146.2024.00088},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LiWZKB024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Pre-trained deep learning (DL) models are increasingly accessible in public repositories, i.e., model zoos. Given a new prediction task, finding the best model to fine-tune can be computationally intensive and costly, especially when the number of pre-trained models is large. Selecting the right pre-trained models is crucial, yet complicated by the diversity of models from various model families (like ResNet, Vit, Swin) and the hidden relationships between models and datasets. Existing methods, which utilize basic information from models and datasets to compute scores indicating model performance on target datasets, overlook the intrinsic relationships, limiting their effectiveness in model selection. In this study, we introduce TransferGraph, a novel framework that reformulates model selection as a graph learning problem. TransferGraph constructs a graph using extensive metadata extracted from models and datasets, while capturing their inherent relationships. Through comprehensive experiments across 16 real datasets, both images and texts, we demonstrate TransferGraph's effectiveness in capturing essential model-dataset relationships, yielding up to a 32% improvement in correlation between predicted performance and the actual fine-tuning results compared to the state-of-the-art methods.}
}


@inproceedings{DBLP:conf/icde/Tan0ZGX00W024,
	author = {Yanchao Tan and
                  Hang Lv and
                  Zihao Zhou and
                  Wenzhong Guo and
                  Bo Xiong and
                  Weiming Liu and
                  Chaochao Chen and
                  Shiping Wang and
                  Carl Yang},
	title = {Logical Relation Modeling and Mining in Hyperbolic Space for Recommendation},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {1310--1323},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00108},
	doi = {10.1109/ICDE60146.2024.00108},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Tan0ZGX00W024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The sparse interactions between users and items have aggravated the difficulty of their representations in recommender systems. Existing methods leverage tags to alleviate the sparsity problem but ignore prevalent logical relations among items and tags (e.g., membership, hierarchy, and exclusion), which can be leveraged to enhance the accuracy of modeling user preferences and conducting recommendations. To this end, we propose to extract logical relations among item tags from existing tag taxonomies and exploit the individual strengths of the Poincaré and the Lorentz models in hyperbolic space for logical relation modeling towards enhanced recommendations. Moreover, we find that the logical relations directly extracted from existing tag taxonomies can be inaccurate and coarse. Therefore, we further devise innovative consistency-based and granularity- based weighting mechanisms based on user behavior patterns for data-driven logical relation mining that can be jointly optimized along with recommendations in an end-to-end fashion. Extensive experiments on four real-world benchmark datasets show drastic performance gains brought by our proposed framework, which constantly achieves an average of 8.25% improvement over state-of-the-art competitors regarding both Recall and NDCG metrics. Insightful case studies further demonstrate that our automatically refined logical relations are highly accurate and interpretable.}
}


@inproceedings{DBLP:conf/icde/YuanQCT0Y24,
	author = {Wei Yuan and
                  Liang Qu and
                  Lizhen Cui and
                  Yongxin Tong and
                  Xiaofang Zhou and
                  Hongzhi Yin},
	title = {HeteFedRec: Federated Recommender Systems with Model Heterogeneity},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {1324--1337},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00109},
	doi = {10.1109/ICDE60146.2024.00109},
	timestamp = {Sun, 06 Oct 2024 21:04:59 +0200},
	biburl = {https://dblp.org/rec/conf/icde/YuanQCT0Y24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Owing to the nature of privacy protection, feder-ated recommender systems (FedRecs) have garnered increasing interest in the realm of on-device recommender systems. However, most existing FedRecs only allow participating clients to collaboratively train a recommendation model of the same public parameter size. Training a model of the same size for all clients can lead to suboptimal performance since clients possess varying resources. For example, clients with limited training data may prefer to train a smaller recommendation model to avoid excessive data consumption, while clients with sufficient data would benefit from a larger model to achieve higher recommendation accuracy. To address the above challenge, this paper introduces HeteFedRec, a novel FedRec framework that enables the assignment of personalized model sizes to partici-pants. Specifically, we present a heterogeneous recommendation model aggregation strategy, including a unified dual-task learning mechanism and a dimensional decorrelation regularization, to allow knowledge aggregation among recommender models of different sizes. Additionally, a relation-based ensemble knowledge distillation method is proposed to effectively distil knowledge from heterogeneous item embeddings. Extensive experiments conducted on three real-world recommendation datasets demonstrate the effectiveness and efficiency of HeteFedRec in training federated recommender systems under heterogeneous settings.}
}


@inproceedings{DBLP:conf/icde/0004WLZFWG24,
	author = {Peng Jia and
                  Pinghui Wang and
                  Rundong Li and
                  Junzhou Zhao and
                  Junlan Feng and
                  Xidian Wang and
                  Xiaohong Guan},
	title = {A Compact and Accurate Sketch for Estimating a Large Range of Set
                  Difference Cardinalities},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {1338--1351},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00110},
	doi = {10.1109/ICDE60146.2024.00110},
	timestamp = {Sun, 06 Oct 2024 21:04:56 +0200},
	biburl = {https://dblp.org/rec/conf/icde/0004WLZFWG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Computing set difference cardinalities is a critical task in database optimization, network management, and anomaly detection. Due to the limited computational and mem-ory resources, exactly calculating set difference cardinalities becomes impractical in real-world applications. To solve this issue, sketch methods such as Odd sketch, Tug-of-War sketch, and HyperLogLog sketch can be extended to provide approximate estimations of set difference cardinalities. They use a family of hash functions to compress all elements in a set into a compact data structure. Unfortunately, Odd sketch suffers from limited estimation range, while Tug-of-War sketch and HyperLogLog sketch unavoidably face the problems of large estimation errors and high computational costs. In this paper, we design a novel data structure of bit array GXBits to fast and accurately estimate set difference cardinalities in a large range. In GXBits, the prob-ability of each bit recording its corresponding elements follows a variant of geometric distributions and varies across different bits. We conduct extensive experiments on synthetic datasets and real-world datasets. Experimental results demonstrate that our method GXBits is more computationally and memory efficient, and significantly increases the estimation accuracy of existing methods by up to 221.3 times.}
}


@inproceedings{DBLP:conf/icde/ChenFLCW24,
	author = {Liyue Chen and
                  Jiangyi Fang and
                  Tengfei Liu and
                  Shaosheng Cao and
                  Leye Wang},
	title = {A Unified Model for Spatio-Temporal Prediction Queries with Arbitrary
                  Modifiable Areal Units},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {1352--1365},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00111},
	doi = {10.1109/ICDE60146.2024.00111},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ChenFLCW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Temporal (ST) prediction is crucial for making informed decisions in urban location-based applications like ride-sharing. However, existing ST models often require region partition as a prerequisite, resulting in two main pitfalls. Firstly, location-based services necessitate ad-hoc regions for various purposes, requiring multiple ST models with varying scales and zones, which can be costly to support. Secondly, different ST models may produce conflicting outputs, resulting in confusing predictions. In this paper, we propose One4All-ST, a framework that can conduct ST prediction for arbitrary modifiable areal units using only one model. To reduce the cost of getting multi-scale predictions, we design an ST network with hierarchical spatial modeling and scale normalization modules to efficiently and equally learn multi-scale representations. To address prediction inconsistencies across scales, we propose a dynamic programming scheme to solve the formulated optimal combination problem, minimizing predicted error through theoretical analysis. Besides, we suggest using an extended quad-tree to index the optimal combinations for quick response to arbitrary modifiable areal units in practical online scenarios. Extensive experiments on two real-world datasets verify the efficiency and effectiveness of One4All-ST in ST prediction for arbitrary modifiable areal units. The source codes and data of this work are available at https://github.com/uctb/One4All-ST.}
}


@inproceedings{DBLP:conf/icde/WenQ0YQX024,
	author = {Zhenyu Wen and
                  Jiaxu Qian and
                  Bin Qian and
                  Qin Yuan and
                  Jianbin Qin and
                  Qi Xuan and
                  Ye Yuan},
	title = {Across Images and Graphs for Question Answering},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {1366--1379},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00112},
	doi = {10.1109/ICDE60146.2024.00112},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/WenQ0YQX024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cross-source query serves as a proxy for scene understanding to support many web applications such as rec-ommendation systems, e-commerce, and e-learning applications. In this paper, we propose SVQA that semantically combines the knowledge from available images and graphs to answer the complex question. To this end, we design a graph-based method to unify various data sources into one representation. We then develop a complex question parse method that utilizes the structure of languages to transform the query into a query graph. A graph query engine that performs the query graph over the unified data source while optimizing the query process. To evaluate the proposed system, we build a vanilla dataset called MVQA and show that the state-of-the-art (SOTA) VQA models fail to perform our task. The comprehensive evaluations show that the proposed SVQA is able to reason implicit relationships over multiple images and external knowledge to correctly answer a complex query. We hope that our first attempt provides researchers with a fresh taste of multimodal data analysis.}
}


@inproceedings{DBLP:conf/icde/00040WTZCYDWG24,
	author = {Haoyu Wang and
                  Ruirui Li and
                  Zhengyang Wang and
                  Xianfeng Tang and
                  Danqing Zhang and
                  Monica Xiao Cheng and
                  Bing Yin and
                  Jasha Droppo and
                  Suhang Wang and
                  Jing Gao},
	title = {LightLT: {A} Lightweight Representation Quantization Framework for
                  Long-Tail Data},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {1380--1393},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00114},
	doi = {10.1109/ICDE60146.2024.00114},
	timestamp = {Tue, 30 Jul 2024 08:18:20 +0200},
	biburl = {https://dblp.org/rec/conf/icde/00040WTZCYDWG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Search tasks require finding items similar to a given query, making it a crucial aspect of various applications. However, storing and computing similarity for millions or billions of item representations can be computationally expensive. To address this, quantization-based hash methods present memory and inference-efficient solutions by converting continuous representations into non-negative integer codes. Despite their advantages, these methods often encounter difficulties in handling long-tail datasets due to imbalanced class distributions. To address this, we propose LightLT, a lightweight representation quantization framework tailored for long-tail datasets. LightLT produces compact codebooks and discrete IDs, enabling efficient inference by computing distances between query and codewords. Our framework includes innovative designs: 1) Quantization Step: We select the most similar codeword for continuous inputs using the differentiable argmax operation. 2) Double Skip Quantization Connection Module: This module promotes codebook diversity and stability during training. 3) Training Loss: Our comprehensive loss includes class-weighted cross-entropy, center loss, and ranking loss. 4) Model Ensemble: We incorporate a model ensemble step to improve generalization. Theoretical analysis confirms LightLT's low space and inference complexity. Experimental results demonstrate superior performance compared to state-of-the-art baselines in terms of search accuracy, efficiency, and memory usage.}
}


@inproceedings{DBLP:conf/icde/YaoJC0GW24,
	author = {Yuanyuan Yao and
                  Hailiang Jie and
                  Lu Chen and
                  Tianyi Li and
                  Yunjun Gao and
                  Shiting Wen},
	title = {TSec: An Efficient and Effective Framework for Time Series Classification},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {1394--1406},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00115},
	doi = {10.1109/ICDE60146.2024.00115},
	timestamp = {Tue, 30 Jul 2024 08:18:21 +0200},
	biburl = {https://dblp.org/rec/conf/icde/YaoJC0GW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Time series classification assigns predefined labels or classes to sequences of data points ordered chronologically, which is a fundamental task for time series analysis. Existing time series classification methods mainly focus on a specific type of time series (i.e., univariate time series or multivariate time series), while failing to support both of them efficiently and effectively. In addition, most of existing multivariate time series classification methods model all variables collectively, resulting in protracted computational times and suboptimal accuracy. In this paper, we introduce TSec, an innovative time series classification framework that exhibits high training efficiency and classification accuracy for both univariate time series and multivariate time series. During online classification, TSec first involves sequence segmentation and de-duplication, and then employs pre-trained models to perform classifications. To opti-mize the classification performance, TSec (i) utilizes correlation analysis to reveal closely interconnected groups of variables within multivariate time series data; (ii) incorporates time series alignment and different sliding windows to generate potential shapelets; (iii) applies PAA and SAX techniques to eliminate duplicates, thereby enhancing the quality of shapelets; (iv) adopts Bi-GRU and GCN-GRU models to effectively capture the characteristics of the two types of time series. Extensive experiments on 112 public univariate time series datasets and 26 public multivariate time series datasets show that TSec can achieve both high efficiency and accuracy compared with the state-of-the-art 19 toolkits.}
}


@inproceedings{DBLP:conf/icde/VincesCF24,
	author = {Braulio Valentin Sanchez Vinces and
                  Robson L. F. Cordeiro and
                  Christos Faloutsos},
	title = {Mccatch: Scalable Microcluster Detection in Dimensional and Nondimensional
                  Datasets},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {1407--1420},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00116},
	doi = {10.1109/ICDE60146.2024.00116},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/VincesCF24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {How could we have an outlier detector that works even with nondimensional data, and ranks together both singleton microclusters (‘one-off’ outliers) and nonsingleton microclusters by their anomaly scores? How to obtain scores that are prin-cipled in one scalable and ‘hands-off’ manner? Microclusters of outliers indicate coalition or repetition in fraud activities, etc.; their identification is thus highly desirable. This paper presents Mccatch: a new algorithm that detects microclusters by leveraging our proposed ‘Oracle’ plot (1NN Distance versus Group 1NN Distance). We study 31 real and synthetic datasets with up to 1M data elements to show that McCatchi's the only method that answers both of the questions above; and, it outperforms 11 other methods, especially when the data has non-singleton microclusters or is nondimensional. We also showcase McCATCH'S ability to detect meaningful microclusters in graphs, fingerprints, logs of network connections, text data, and satellite imagery. For example, it found a 30-elements microcluster of confirmed ‘Denial of Service’ attacks in the network logs, taking only ~3 minutes for 222K data elements on a stock desktop.}
}


@inproceedings{DBLP:conf/icde/SYW24,
	author = {Vinay M. S. and
                  Shuhan Yuan and
                  Xintao Wu},
	title = {Contrastive Learning for Fraud Detection from Noisy Labels},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {1421--1434},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00117},
	doi = {10.1109/ICDE60146.2024.00117},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/SYW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Detecting frauds in computing platforms involves identifying malicious user activity sessions. Recently, deep learning models have been employed to design fraud detection approaches. Effective training of these deep learning models requires a large amount of well-annotated sessions. However, due to the cost of expert annotation, many organizations rely on heuristics to perform automated annotation, which leads to the noisy label learning problem. It is well known that the performance of deep learning models can easily degrade because of noisy or inaccurate labels. To tackle this challenge, we propose a supervised Contrastive Learning based Fraud Detection (CLFD) framework, which is designed to operate in the noisy label setting. CLFD employs an effective label corrector for correcting noisy labels and which is specifically designed for the fraud detection task. Then, by employing the corrected labels, it trains a fraud detector through supervised contrastive learning, and derives separable representations. We empirically evaluate our CLFD framework and other state-of-the-art baselines on benchmark datasets. Our CLFD framework demonstrates superior performance over state-of-the-art baselines.}
}


@inproceedings{DBLP:conf/icde/ZhengHLCZCW24,
	author = {Bowen Zheng and
                  Yupeng Hou and
                  Hongyu Lu and
                  Yu Chen and
                  Wayne Xin Zhao and
                  Ming Chen and
                  Ji{-}Rong Wen},
	title = {Adapting Large Language Models by Integrating Collaborative Semantics
                  for Recommendation},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {1435--1448},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00118},
	doi = {10.1109/ICDE60146.2024.00118},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhengHLCZCW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recently, large language models (LLMs) have shown great potential in recommender systems, either improving existing recommendation models or serving as the backbone. However, there exists a large semantic gap between LLMs and recommender systems, since items to be recommended are often indexed by discrete identifiers (item ID) out of the LLM's vocabulary. In essence, LLMs capture language semantics while recommender systems imply collaborative semantics, making it difficult to sufficiently leverage the model capacity of LLMs for recommendation. To address this challenge, in this paper, we propose a new LLM-based recommendation model called LC-Rec, which can better integrate language and collaborative semantics for recommender systems. Our approach can directly generate items from the entire item set for recommendation, without relying on candidate items. Specifically, we make two major contributions in our approach. For item indexing, we design a learning-based vector quantization method with uniform semantic mapping, which can assign meaningful and non-conflicting IDs (called item indices) for items. For alignment tuning, we propose a series of specially designed tuning tasks to enhance the integration of collaborative semantics in LLMs. Our fine-tuning tasks enforce LLMs to deeply integrate language and collaborative semantics (characterized by the learned item indices), so as to achieve an effective adaptation to recommender systems. Extensive experiments demonstrate the effectiveness of our method, showing that our approach can outperform a number of competitive baselines including traditional recommenders and existing LLM-based recommenders. Our code is available at https://github.com/RUCAIBox/LC-Rec/.}
}


@inproceedings{DBLP:conf/icde/LiuDLLCZ24,
	author = {Hanmo Liu and
                  Shimin Di and
                  Haoyang Li and
                  Shuangyin Li and
                  Lei Chen and
                  Xiaofang Zhou},
	title = {Effective Data Selection and Replay for Unsupervised Continual Learning},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {1449--1463},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00119},
	doi = {10.1109/ICDE60146.2024.00119},
	timestamp = {Sun, 06 Oct 2024 21:04:58 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LiuDLLCZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recently, continual learning (CL) has attracted much attention due to its widespread applications in the real world. Given a set of data sets sequentially, continual learning aims to achieve good performance on the new data sets while avoiding deterioration in performance on the old data sets. Despite the success, most CL models follow the supervised setting, which limits their potential in data scarcity cases. Thus, some pioneering works study unsupervised CL (UCL) to discuss what CL tricks suit the unsupervised setting. However, their advancements lack in-depth analysis of the characteristics of UCL, especially the lack of attention to the use of old data. We identify that using old data sets is essential for improving the UCL model performance while existing works ignore them. Unfortunately, given a limited data storage budget, it is a nontrivial task to select representative data and effectively replay them without label assistance. To further improve the UCL performance, we present a new method in this paper, named Effective Data Selection and Replay (EDSR) for UCL. Specifi-cally, we analyze that entropy can be an effective data selection metric, where representative data usually exhibit the highest entropy in the representation space. Then, to balance the model stability for old data and the plasticity for new data, we adopt a strategy of replaying those stored representative data with a noise-enhanced knowledge distillation process. The empirical study demonstrates the outstanding performance of EDSR on benchmark computer vision data sets. Especially, EDSR shows strong resistance to forgetting old data knowledge while maintaining high accuracy. The implementation is publicly available at https://github.com/LeeJarvis996/edsr_project/tree/main/EDSR.}
}


@inproceedings{DBLP:conf/icde/HeXCLC24,
	author = {Tianlang He and
                  Zhiqiu Xia and
                  Jierun Chen and
                  Haoliang Li and
                  S.{-}H. Gary Chan},
	title = {Target-agnostic Source-free Domain Adaptation for Regression Tasks},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {1464--1477},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00121},
	doi = {10.1109/ICDE60146.2024.00121},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/HeXCLC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Unsupervised domain adaptation (UDA) seeks to bridge the domain gap between the target and source using unlabeled target data. Source-free UDA removes the requirement for labeled source data at the target to preserve data privacy and storage. However, previous works on source-free UDA assume knowledge of domain gap, and hence is limited to either target-aware or classification task. To overcome it, we propose TASFAR, a novel target-agnostic source-free domain adaptation approach for regression tasks. Using prediction confidence, TASFAR estimates a label density map as the target label distribution, which is then used to calibrate the source model on the target domain. We have conducted extensive experiments on four regression tasks with various domain gaps, namely, pedestrian dead reckoning for different users, image-based people counting in different scenes, housing-price prediction at different districts, and taxi-trip duration prediction from different departure points. TASFAR demonstrates significant superiority over state-of-the-art source-free UDA approaches, achieving an average error reduction of 22 % across the four tasks and comparable accuracy to source-based UDA, all without relying on source data.}
}


@inproceedings{DBLP:conf/icde/ZhaoLZDL0024,
	author = {Jianjun Zhao and
                  Haikun Liu and
                  Shuhao Zhang and
                  Zhuohui Duan and
                  Xiaofei Liao and
                  Hai Jin and
                  Yu Zhang},
	title = {Fast Parallel Recovery for Transactional Stream Processing on Multicores},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {1478--1491},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00122},
	doi = {10.1109/ICDE60146.2024.00122},
	timestamp = {Sun, 06 Oct 2024 21:04:59 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhaoLZDL0024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Transactional stream processing engines (TSPEs) have gained increasing attention due to their capability of processing real-time stream applications with transactional semantics. However, TSPEs remain susceptible to system failures and power outages. Existing TSPEs mainly focus on performance improvement, but still face a significant challenge to guarantee fault tolerance while offering high-performance services. We revisit commonly-used fault tolerance approaches in stream processing and database systems, and find that these approaches do not work well on TSPEs due to complex data dependencies. In this paper, we propose a novel TSPE called MorphStreamR to achieve fast failure recovery while guaranteeing low performance overhead at runtime. The key idea of MorphStreamR is to record intermediate results of resolved dependencies at runtime, and thus eliminate data dependencies to improve task parallelism during failure recovery. MorphStreamR further mitigates the runtime overhead by selectively tracking data dependencies and incorporating workload-aware log commitment. Experimental results show that MorphStreamR can significantly reduce the recovery time by up to 3.1 x while experiencing much less performance slowdown at runtime, compared with other applicable fault tolerance approaches.}
}


@inproceedings{DBLP:conf/icde/Liu0CWW0L24,
	author = {Qingxiu Liu and
                  Qun Huang and
                  Xiang Chen and
                  Sa Wang and
                  Wenhao Wang and
                  Shujie Han and
                  Patrick P. C. Lee},
	title = {PP-Stream: Toward High-Performance Privacy-Preserving Neural Network
                  Inference via Distributed Stream Processing},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {1492--1505},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00123},
	doi = {10.1109/ICDE60146.2024.00123},
	timestamp = {Mon, 16 Sep 2024 10:28:05 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Liu0CWW0L24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Privacy preservation is critical for neural network inference, which often involves collaborative execution of different parties to make predictions on sensitive data based on sensitive neural network models. However, the expensive cryptographic operations of privacy preservation also pose performance chal-lenges to neural network inference. We address this performance-security tension by designing PP-Stream, a distributed stream processing system for high-performance privacy-preserving neural network inference. PP-Stream adopts hybrid privacy-preserving mechanisms for linear and non-linear operations of neural network inference. It treats inference data as real-time data streams, and parallelizes the inference operations across multiple pipelined stages that are executed by multiple servers and threads. It also solves the load-balanced resource allocation across servers and threads as an optimization problem. We prototype PP-Stream and show via testbed experiments that it achieves low inference latencies on various neural network models.}
}


@inproceedings{DBLP:conf/icde/LiuPE24,
	author = {Chunwei Liu and
                  John Paparrizos and
                  Aaron J. Elmore},
	title = {AdaEdge: {A} Dynamic Compression Selection Framework for Resource
                  Constrained Devices},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {1506--1519},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00124},
	doi = {10.1109/ICDE60146.2024.00124},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LiuPE24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the Internet of Things (IoT), a vast number of connected devices generate significant data, necessitating efficient compression techniques to manage storage costs and enhance query performance. However, “one-size-fits-all” approach to data compression is ineffective due to diverse applications, which vary in data characteristics, workloads, and hardware limitations. This paper introduces AdaEdge, a dynamic, hardware-conscious compression selection framework tailored for resource-constrained devices. AdaEdge is a best-effort compression selection frame- work designed to preserve application-critical information as much as possible within system constraints. It enhances the use of limited system resources through a dynamic data compression policy that considers the staleness and the significance of the data. AdaEdge applies a multi-armed bandit algorithm to assist compression selection, optimizing workload targets such as compression ratio, compression throughput, workload accuracy, or their weighted combinations. It supports both lossy and lossless compression selection, adapting to hardware constraints. It operates in both online and offline modes, addressing network constraints for edge nodes and evolving data policies to preserve workload-specific information. AdaEdge improves machine learning task accuracy by up to 30% over baseline within the same storage budget and by up to 20% in scenarios where lossless methods fall short due to low compression ratios. AdaEdge also shows robustness against data shifts and hardware variability.}
}


@inproceedings{DBLP:conf/icde/GerenSTM24,
	author = {Hasan Geren and
                  Nasrin Sohrabi and
                  Zahir Tari and
                  Nour Moustafa},
	title = {A Predictive Profiling and Performance Modeling Approach for Distributed
                  Stream Processing in Edge},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {1520--1532},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00125},
	doi = {10.1109/ICDE60146.2024.00125},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/GerenSTM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The advent of edge computing has allowed the continuously generated data to be processed closer to their sources instead of being sent to the cloud for processing. Given the heterogeneous and limited computational resources and dynamic nature of edge computing, stream processing systems need an accurate and easily accessible performance modeling/measurement to perform efficiently in edge environments. This paper proposes a predictive profiling model to enable measuring the performance of a system by predicting the operators' processing time on heterogeneous devices without having to carry out the testing on individual devices. This profiling model comprises a quadratic function to generate CPU clock speed/processing time curves for each operator. By using these curves, the model predicts the processing times of operators without requiring any extra profiling runs. Moreover, a performance model is proposed to deal with (performance) degradation of stream processing applications by modeling their topologies as systems comprising M/M/1 queues. The model uses the performance expectations of queueing models to define the data transfer rates inside topologies and uses Integer Linear Programming to specify the maximum input rate and an operator placement plan that can process that input rate. Experimental results showed that the profiling approach predicts the processing times of 17 operators with an average error rate of 5%. The performance model finds the maximum input rate accurately, while the operator placement plan achieves up to 84% higher throughput and 70% less latency in AWS EC2 instances and 257% higher throughput and 66% less latency in real hardware compared to the default resource-aware scheduler of Apache Storm.}
}


@inproceedings{DBLP:conf/icde/XuZXWLZ24,
	author = {Yin Xu and
                  Xichong Zhang and
                  Mingjun Xiao and
                  Jie Wu and
                  An Liu and
                  Sheng Zhang},
	title = {Joint Mobile Edge Caching and Pricing: {A} Mean-Field Game Approach},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {1533--1546},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00126},
	doi = {10.1109/ICDE60146.2024.00126},
	timestamp = {Wed, 21 Aug 2024 07:35:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/XuZXWLZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we investigate the competitive content placement problem in Mobile Edge Caching (MEC) systems, where Edge Data Providers (EDPs) cache appropriate contents and trade them with requesters at a suitable price. Most of the existing works ignore the complicated strategic and economic interplay between content caching, pricing, and content sharing. Therefore, we propose a joint Mean-Field Game framework for mobile edge Caching and Pricing (MFG-CP) in large-scale dynamic MEC systems, which can facilitate distributed optimal decision-making based on the mean-field game theory. Specifi-cally, we first formulate the competitive content placement issue among EDPs as a non-cooperative stochastic differential game. To significantly reduce the communication and computation complexity, we further devise a mean-field model to approximate the collective impact of all EDPs on caching, trading, and sharing, by which each EDP can quickly estimate some unknown information without considerable interactions. Then, we develop a distributed best response scheme based on iterative learning, enabling each EDP to solely customize its optimal caching strategy and pricing policy. Besides, we theoretically prove the existence of a unique MFG equilibrium. Finally, trace-driven simulations demonstrate the effectiveness of MFG-CP compared with some baselines.}
}


@inproceedings{DBLP:conf/icde/LiTZZZHC24,
	author = {Guopeng Li and
                  Haisheng Tan and
                  Xuan Zhang and
                  Chi Zhang and
                  Ruiting Zhou and
                  Zhenhua Han and
                  Guoliang Chen},
	title = {Online Container Caching with Late-Warm for IoT Data Processing},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {1547--1560},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00127},
	doi = {10.1109/ICDE60146.2024.00127},
	timestamp = {Tue, 30 Jul 2024 08:18:21 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LiTZZZHC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Serverless edge computing is an efficient way to execute event-driven, short-duration, and bursty IoT data processing tasks on resource-limited edge servers, using on-demand resource allocation and dynamic auto-scaling. In this paradigm, function requests are handled in virtualized environments, e.g., containers. When a function request arrives online, if there is no container in memory to execute it, the serverless platform will initialize such a container with non-negligible latency, known as cold start. Otherwise, it results in a warm start with no latency in previous studies. However, based on our experiments, we find there is a remarkable third case called Late-Warm, i.e., when a request arrives during the container initializing, its latency is less than a cold start but not zero. In this paper, we study online container caching in serverless edge computing to minimize the total latency with Late-Warm and other practical issues considered. We propose OnCoLa, a novel\nO(\nT\n3\nc\n/2K)\n-competitive algorithm supporting request relaying on multiple edge servers. Here, Tc and\nK\nare the maximum container cold start latency and the memory size, respectively. Experiments on Raspberry Pi and Jetson Nano with OpenFaaS and faasd using common IoT data processing tasks show that OnCoLa reduces latency by up to 21.38% compared with representative lightweight policies. Extensive simulations on two real-world traces demonstrate that OnCoLa consistently outperforms the state-of-the-art container caching algorithms and reduces the latency by 27.8%.}
}


@inproceedings{DBLP:conf/icde/BaoZXC24,
	author = {Hao Bao and
                  Zhi Zhou and
                  Fei Xu and
                  Xu Chen},
	title = {{COUPLE:} Orchestrating Video Analytics on Heterogeneous Mobile Processors},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {1561--1574},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00128},
	doi = {10.1109/ICDE60146.2024.00128},
	timestamp = {Fri, 18 Oct 2024 08:29:19 +0200},
	biburl = {https://dblp.org/rec/conf/icde/BaoZXC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Video analytics is considered the killer application of edge computing and has been successfully deployed across diverse domains. Yet, executing video analytics on mobile devices presents notable challenges owing to the considerable computational demands and frame rate requirements of DNN models. Current mobile inference frameworks often concentrate on enhancing model inference performance on the CPU or GPU, overlooking the potential of the Digital Signal Processor (DSP) – an emerging heterogeneous processor increasingly integrated into modern mobile processors. In this paper, we introduce COUPLE, an orchestration framework for video analytics on heterogeneous mobile processors, with the goal of optimizing real-time video analysis through the collaboration of CPU, GPU and DSP. To tackle the accuracy loss of DSP inference, we introduce the Anchor Frame Calibration mechanism, utilizing high-precision GPU inference results and frame similarities to mitigate accuracy loss on the DSP. Additionally, we design a lightweight progressive scheduler to distribute video frames to GPU and DSP, maximizing inference Average Precision (AP) under performance (i.e., frame rate) and power constraints. COUPLE has been implemented on the Qualcomm's Snapdragon 888 mobile SoC, extensive evaluation results demonstrate its efficacy in imnroving the inference performance and accuracy.}
}


@inproceedings{DBLP:conf/icde/0003JYZ0Z24,
	author = {Rui Zhu and
                  Yujin Jia and
                  Xiaochun Yang and
                  Baihua Zheng and
                  Bin Wang and
                  Chuanyu Zong},
	title = {Multiple Continuous Top-K Queries Over Data Stream},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {1575--1588},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00129},
	doi = {10.1109/ICDE60146.2024.00129},
	timestamp = {Sun, 06 Oct 2024 21:04:56 +0200},
	biburl = {https://dblp.org/rec/conf/icde/0003JYZ0Z24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Continuous top- k\nquery over sliding window is a fundamental challenge in the domain of streaming data management. Specifically, a continuous top-k query q\nmonitors the window W\n, returning the k\nobjects with the highest scores to the system with each slide of the window. This paper delves into one of its important variants, referred to as multiple continuous top. k\nqueries over data stream, which holds significant applications. While various efforts have been made to support continuous top-k query, few have addressed the complexities of multiple continuous top-k queries. The prevailing approach involves selecting a minimal number of objects in the window as candidates, incrementally maintaining them, and using them to support query processing as efficiently as possible. However, these endeavors exhibit sensitivity to the query workload scale or query parameters such as k\n, the window length n\n, and others. Consequently, they incur high running/space cost in updating the candidate set. In this paper, we propose a novel index PH-Tree (Partition and Heap-based Binary Tree), designed to facilitate multiple continuous top-k queries. We partition the query window into a group of disjoint partitions and use PH-Tree to organize these partitions. Additionally, the PH-Tree allows for flexible candidate selection based on the size of each partition, parameter distribution of queries and score distribution of objects. We further develop a group of efficient algorithms to support candidate set incremental maintenance and query processing. The effectiveness and efficiency of the proposed algorithms are validated through extensive theoretical analysis and exneriments detailed in this paper.}
}


@inproceedings{DBLP:conf/icde/ChenH00024,
	author = {Qizhi Chen and
                  Yisen Hong and
                  Yuhan Wu and
                  Tong Yang and
                  Bin Cui},
	title = {CodingSketch: {A} Hierarchical Sketch with Efficient Encoding and
                  Recursive Decoding},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {1592--1605},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00130},
	doi = {10.1109/ICDE60146.2024.00130},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ChenH00024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Sketch is a probabilistic data structure widely used in various fields due to its high accuracy under small memory. Designing hierarchical data structures for real-world datasets with high skewness is one of the main optimization directions of Sketch. However, there is still a big accuracy gap between the existing sketches and the optimum. To fill the gap, we propose a new sketch called Coding Sketch. For the first time, we used both hierarchical structure and nearly-lossless encoding-and-decoding to compress frequent items, which significantly improves the accuracy of frequent items. Besides, we propose flagless pruning to remove the additional flag bits in traditional hierarchical structure. Thus Coding Sketch can optimize the frequency estimation of both frequent and infrequent items. Our evaluation shows that our algorithm is 10 times more accurate than the state-of-the-art under the same memory cost. All related codes are open-sourced. 2 2 https://github.com/CodingSketch/Coding-Sketc}
}


@inproceedings{DBLP:conf/icde/RathSS24,
	author = {Timo R{\"{a}}th and
                  Marius Schlegel and
                  Kai{-}Uwe Sattler},
	title = {Everything Everyway All at Once - Time Traveling Debugging for Stream
                  Processing Applications},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {1606--1618},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00131},
	doi = {10.1109/ICDE60146.2024.00131},
	timestamp = {Sun, 04 Aug 2024 19:37:46 +0200},
	biburl = {https://dblp.org/rec/conf/icde/RathSS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Debugging, evaluating, and optimizing stream processing applications is challenging due to continuous streams of input data and typically distributed and parallel execution environments. To address these issues, we present an approach for explorative debugging of stream processing pipelines that allows in-depth investigation of a pipeline's execution behavior and evolution. The time traveling debugger enables traveling back in time within the pipeline's execution history and thoroughly analyzing and retracing each fine-grained step. Any changes made to the pipeline's structure or parameters are captured based on provenance information and can be reviewed, compared, and analyzed with the provenance inspector to understand the impact of each alteration on the quality of the pipeline.}
}


@inproceedings{DBLP:conf/icde/Sun0HDW0Y24,
	author = {Xinyue Sun and
                  Qingqing Ye and
                  Haibo Hu and
                  Jiawei Duan and
                  Tianyu Wo and
                  Jie Xu and
                  Renyu Yang},
	title = {LDPRecover: Recovering Frequencies from Poisoning Attacks Against
                  Local Differential Privacy},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {1619--1631},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00132},
	doi = {10.1109/ICDE60146.2024.00132},
	timestamp = {Tue, 30 Jul 2024 08:18:20 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Sun0HDW0Y24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Local differential privacy (LDP), which enables an untrusted server to collect aggregated statistics from distributed users while protecting the privacy of those users, has been widely deployed in practice. However, LDP protocols for frequency estimation are vulnerable to poisoning attacks, in which an attacker can poison the aggregated frequencies by manipulating the data sent from malicious users. Therefore, it is an open challenge to recover the accurate aggregated frequencies from poisoned ones. In this work, we propose LDPRecover, a method that can recover accurate aggregated frequencies from poisoning attacks, even if the server does not learn the details of the attacks. In LDPRecover, we establish a genuine frequency estimator that theoretically guides the server to recover the frequencies aggregated from genuine users' data by eliminating the impact of malicious users' data in poisoned frequencies. Since the server has no idea of the attacks, we propose an adaptive attack to unify existing attacks and learn the statistics of the malicious data within this adaptive attack by exploiting the properties of LDP protocols. By taking the estimator and the learning statistics as constraints, we formulate the problem of recovering aggregated frequencies to approach the genuine ones as a constraint inference (CI) problem. Consequently, the server can obtain accurate aggregated frequencies by solving this problem optimally. Moreover, LDPRecover can serve as a frequency recovery paradigm that recovers more accurate aggregated frequencies by integrating attack details as new constraints in the CI problem. Our evaluation on two real-world datasets, three LDP protocols, and untargeted and targeted poisoning attacks shows that LDPRecover is both accurate and widely applicable against various poisoning attacks.}
}


@inproceedings{DBLP:conf/icde/Ran00HXF24,
	author = {Xun Ran and
                  Qingqing Ye and
                  Haibo Hu and
                  Xin Huang and
                  Jianliang Xu and
                  Jie Fu},
	title = {Differentially Private Graph Neural Networks for Link Prediction},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {1632--1644},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00133},
	doi = {10.1109/ICDE60146.2024.00133},
	timestamp = {Mon, 30 Sep 2024 07:54:40 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Ran00HXF24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graph Neural Networks (GNNs) have proven to be highly effective in addressing the link prediction problem. However, the need for large amounts of user data to learn representations of user interactions raises concerns about data privacy. While differential privacy (DP) techniques have been widely used for node-level tasks in graphs, incorporating DP into GNNs for link prediction is challenging due to data dependency. To this end, in this work we propose a differentially private link prediction (DPLP) framework, building upon subgraph-based GNNs. DPLP includes a DP-compliant subgraph extraction module as its core component. We first propose a neighborhood subgraph extraction method, and carefully analyze its data dependency level. To reduce this dependency, we optimize DPLP by integrating a novel path subgraph extraction method, which alleviates the utility loss in GNNs by reducing the noise sensitivity. Theoretical analysis demonstrates that our approaches achieve a good balance between privacy protection and prediction accuracy, even when using GNNs with few layers. We extensively evaluate our approaches on benchmark datasets and show that they can learn accurate privacy-preserving GNNs and outperforms the existing methods for link prediction.}
}


@inproceedings{DBLP:conf/icde/CaoLBL024,
	author = {Xinle Cao and
                  Yuhan Li and
                  Dmytro Bogatov and
                  Jian Liu and
                  Kui Ren},
	title = {Secure and Practical Functional Dependency Discovery in Outsourced
                  Databases},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {1645--1658},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00134},
	doi = {10.1109/ICDE60146.2024.00134},
	timestamp = {Tue, 30 Jul 2024 08:18:18 +0200},
	biburl = {https://dblp.org/rec/conf/icde/CaoLBL024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The popularity of cloud computing has made outsourced databases prevalent in real-world applications. To protect data security, numerous encrypted outsourced databases have been proposed for this paradigm. However, the maintenance of encrypted databases (EDBs) has scarcely been addressed. In this paper, we focus on a typical maintenance task - functional dependency (FD) discovery. We develop novel FD protocols in EDBs while guaranteeing minimal leakages: nothing is revealed besides the database size and the actual discovered FDs. As far as we know, we are the first to formally define secure FD discovery with minimal leakage. We present two oblivious FD discovery protocols and prove them secure in the presence of the persistent adversary (monitoring processes on the server). The first protocol leverages oblivious RAM (ORAM) and is suitable for dynamic databases. The second protocol relies on oblivious sorting and is more practical in static databases due to high parallelism. We present a thorough experimental evaluation of the proposed methods.}
}


@inproceedings{DBLP:conf/icde/BaiWG0CBJ24,
	author = {Zhao Bai and
                  Mingyue Wang and
                  Fangda Guo and
                  Yu Guo and
                  Chengjun Cai and
                  Rongfang Bie and
                  Xiaohua Jia},
	title = {SecMdp: Towards Privacy-Preserving Multimodal Deep Learning in End-Edge-Cloud},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {1659--1670},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00135},
	doi = {10.1109/ICDE60146.2024.00135},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/BaiWG0CBJ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Multimodal deep learning technologies have advanced significantly, which brings extensive applications in diverse fields. The substantial computational demands of training and prediction in multimodal deep learning have made the End-Edge-Cloud (EEC) framework popular. It is essential to protect multimodal data and model privacy in such a framework. However, traditional cryptographic methods, though secure for data and models at edge nodes, cause efficiency limitations. In this paper, we propose SecMdp, an SGX-assisted secure computational framework for multimodal data in the EEC architecture. Edge nodes are equipped with the trusted execution environment (e.g., Intel SGX) to run multimodal algorithms. Additionally, to address the side-channel attacks of SGX, we present an enhanced PathORAM algorithm, MM_PathORAM, for the multimodal training and prediction processes, which are tailored for multimodal deep learning scenarios. It accelerates multimodal data access while protecting data privacy and model security. Experimental evaluation supports the effectiveness of our design in preserving edge computing efficiency. It demonstrates negligible impact on the speed of multimodal data loading, the configuration of model parameters during training, or the accuracy of predictions.}
}


@inproceedings{DBLP:conf/icde/Liu0MLY24,
	author = {Shang Liu and
                  Yang Cao and
                  Takao Murakami and
                  Jinfei Liu and
                  Masatoshi Yoshikawa},
	title = {{CARGO:} Crypto-Assisted Differentially Private Triangle Counting
                  Without Trusted Servers},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {1671--1684},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00136},
	doi = {10.1109/ICDE60146.2024.00136},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Liu0MLY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Differentially private triangle counting in graphs is essential for analyzing connection patterns and calculating clustering coefficients while protecting sensitive individual information. Previous works have relied on either central or local models to enforce differential privacy. However, a significant utility gap exists between the central and local models of differentially private triangle counting, depending on whether or not a trusted server is needed. In particular, the central model provides a high accuracy but necessitates a trusted server. The local model does not require a trusted server but suffers from limited accuracy. Our paper introduces a crypto-assisted differentially private triangle counting system, named CARGO, leveraging cryptographic building blocks to improve the effectiveness of differentially private triangle counting without assumption of trusted servers. It achieves high utility similar to the central model but without the need for a trusted server like the local model. CARGO consists of three main components. First, we introduce a similarity-based projection method that reduces the global sensitivity while preserving more triangles via triangle homogeneity. Second, we present a triangle counting scheme based on the additive secret sharing that securely and accurately computes the triangles while protecting sensitive information. Third, we design a distributed perturbation algorithm that perturbs the triangle count with minimal but sufficient noise. We also provide a comprehensive theoretical and empirical analysis of our proposed methods. Extensive experiments demonstrate that our CARGO significantly outperforms the local model in terms of utility and achieves high-utility triangle counting comparable to the central model.}
}


@inproceedings{DBLP:conf/icde/Hu00F00G24,
	author = {Yujia Hu and
                  Yuntao Du and
                  Zhikun Zhang and
                  Ziquan Fang and
                  Lu Chen and
                  Kai Zheng and
                  Yunjun Gao},
	title = {Real-Time Trajectory Synthesis with Local Differential Privacy},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {1685--1698},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00137},
	doi = {10.1109/ICDE60146.2024.00137},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Hu00F00G24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Trajectory streams are being generated from location-aware devices, such as smartphones and in-vehicle navigation systems. Due to the sensitive nature of the location data, directly sharing user trajectories suffers from privacy leakage issues. Local differential privacy (LDP), which perturbs sensitive data on the user side before it is shared or analyzed, emerges as a promising solution for private trajectory stream collection and analysis. Unfortunately, existing stream release approaches often neglect the rich spatial-temporal context information within trajectory streams, resulting in suboptimal utility and limited types of downstream applications. To this end, we propose RetraSyn, a novel real-time trajectory synthesis framework, which is able to perform on-the-f1y trajectory synthesis based on the mobility patterns privately extracted from users' trajectory streams. Thus, the downstream trajectory analysis can be performed on the high-utility synthesized data with privacy protection. We also take the genuine behaviors of real-world mobile travelers into consideration, ensuring authenticity and practicality. The key components of RetraSyn include the global mobility model, dynamic mobility update mechanism, real-time synthesis, and adaptive allocation strategy. We conduct extensive experiments on multiple real-world and synthetic trajectory datasets under various location-based utility metrics, encompassing both streaming and historical scenarios. The empirical results demonstrate the superiority and versatility of our proposed framework.}
}


@inproceedings{DBLP:conf/icde/ZhuZZCMC0024,
	author = {Xiaoting Zhu and
                  Libin Zheng and
                  Chen Jason Zhang and
                  Peng Cheng and
                  Rui Meng and
                  Lei Chen and
                  Xuemin Lin and
                  Jian Yin},
	title = {Privacy-Preserving Traffic Flow Release with Consistency Constraints},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {1699--1711},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00138},
	doi = {10.1109/ICDE60146.2024.00138},
	timestamp = {Tue, 13 Aug 2024 08:04:50 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhuZZCMC0024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Urban traffic flow data is useful in transport ap-plications, playing an important role in various tasks such as road planning, site selection, ad services, etc. However, traffic flow data is the composition of personal driving trajectories, which can reveal sensitive information such as home and work locations, leading to privacy issues. Thus publishing traffic flow data while not disclosing private information remains a challenge for urban managers. To address this challenge, we study the noisy publication of traffic flow data in this paper. The noise is added to the data with respect to the differential privacy paradigm, which ensures data safety but deteriorates its utility. On the other hand, we find that the inherent relations of the flow data inherited from the road network structure can be used to correct data without hurting the privacy property. Hence, we propose post-processing techniques, which exploit the data's inherent relations for corrections over the global and local differentially private traffic flow data, respectively. Extensive experiments on real data show that the proposed post-processing techniques improve the data utility by 29.7%-41.1% and 17.3%-48.6% subjecting to the global and local differential privacy paradigm, respectively.}
}


@inproceedings{DBLP:conf/icde/0012YP24,
	author = {He Zhang and
                  Xingliang Yuan and
                  Shirui Pan},
	title = {Unraveling Privacy Risks of Individual Fairness in Graph Neural Networks},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {1712--1725},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00139},
	doi = {10.1109/ICDE60146.2024.00139},
	timestamp = {Sun, 06 Oct 2024 21:04:56 +0200},
	biburl = {https://dblp.org/rec/conf/icde/0012YP24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graph neural networks (GNNs) have gained significant attraction due to their expansive real-world applications. To build trustworthy GNNs, two aspects - fairness and privacy - have emerged as critical considerations. Previous studies have separately examined the fairness and privacy aspects of GNNs, revealing their tradeoff with GNN performance. Yet, the inter-play between these two aspects remains unexplored. In this paper, we pioneer the exploration of the interaction between the privacy risks of edge leakage and the individual fairness of a GNN. Our theoretical analysis unravels that edge privacy risks unfortunately escalate when the nodes' individual fairness improves. Such an issue hinders the accomplishment of privacy and fairness of GNNs at the same time. To balance fairness and privacy, we carefully introduce fairness-aware loss reweighting based on in-fluence function and privacy-aware graph structure perturbation modules within a fine-tuning mechanism. Experimental results underscore the effectiveness of our approach in achieving GNN fairness with limited performance compromise and controlled privacy risks. This work contributes to the comprehensively developing trustworthy GNNs by simultaneously addressing both fairness and privacy aspects.}
}


@inproceedings{DBLP:conf/icde/ZhangLY24,
	author = {Meifan Zhang and
                  Xin Liu and
                  Lihua Yin},
	title = {Sketches-Based Join Size Estimation Under Local Differential Privacy},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {1726--1738},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00140},
	doi = {10.1109/ICDE60146.2024.00140},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhangLY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Join size estimation on sensitive data poses a risk of privacy leakage. Local differential privacy (LDP) is a solution to preserve privacy while collecting sensitive data, but it introduces significant noise when dealing with sensitive join attributes that have large domains. Employing probabilistic structures such as sketches is a way to handle large domains, but it leads to hash-collision errors. To achieve accurate estimations, it is necessary to reduce both the noise error and hash-collision error. To tackle the noise error caused by protecting sensitive join values with large domains, we introduce a novel algorithm called LDPJoinSketch for sketch-based join size estimation under LDP. Additionally, to address the inherent hash-collision errors in sketches under LDP, we propose an enhanced method called LDPJoinSketch+. It utilizes a frequency-aware perturbation mechanism that effectively separates high-frequency and low-frequency items without compromising privacy. The proposed methods satisfy LDP, and the estimation error is bounded. Experimental results show that our method outperforms existing methods, effectively enhancing the accuracy of join size estimation under LDP.}
}


@inproceedings{DBLP:conf/icde/Mao00WH24,
	author = {Yulian Mao and
                  Qingqing Ye and
                  Haibo Hu and
                  Qi Wang and
                  Kai Huang},
	title = {PrivShape: Extracting Shapes in Time Series Under User-Level Local
                  Differential Privacy},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {1739--1751},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00141},
	doi = {10.1109/ICDE60146.2024.00141},
	timestamp = {Thu, 07 Nov 2024 07:50:09 +0100},
	biburl = {https://dblp.org/rec/conf/icde/Mao00WH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Time series have numerous applications in finance, healthcare, IoT, and smart city. In many of these applications, time series typically contain personal data, so privacy infringement may occur if they are released directly to the public. Recently, local differential privacy (LDP) has emerged as the state-of-the-art approach to protecting data privacy. However, existing works on LDP-based collections cannot preserve the shape of time series. A recent work, PatternLDP, attempts to address this problem, but it can only protect a finite group of elements in a time series due to ω-event level privacy guarantee. In this paper, we propose PrivShape, a trie-based mechanism under user-level LDP to protect all elements. PrivShape first transforms a time series to reduce its length, and then adopts trie-expansion and two-level refinement to improve utility. By extensive experiments on real-world datasets, we demonstrate that PrivShape outperforms PatternLDP when adapted for offline use, and can effectively extract frequent shapes.}
}


@inproceedings{DBLP:conf/icde/ZhaoYMLCG24,
	author = {Minjun Zhao and
                  Yichen Yin and
                  Yuren Mao and
                  Qing Liu and
                  Lu Chen and
                  Yunjun Gao},
	title = {SparDL: Distributed Deep Learning Training with Efficient Sparse Communication},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {1752--1764},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00142},
	doi = {10.1109/ICDE60146.2024.00142},
	timestamp = {Tue, 30 Jul 2024 08:18:18 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhaoYMLCG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Top-k sparsification has recently been widely used to reduce the communication volume in distributed deep learning. However, due to the Sparse Gradient Accumulation (SGA) dilemma, the performance of top-k sparsification still has limitations. Recently, a few methods have been put forward to handle the SGA dilemma. Regrettably, even the state-of-the-art method suffers from several drawbacks, e.g., it relies on an inefficient communication algorithm and requires extra transmission steps. Motivated by the limitations of existing methods, we propose a novel efficient sparse communication framework, called SparDL. Specifically, SparDL uses the Spar-Reduce-Scatter algorithm, which is based on an efficient Reduce-Scatter model, to handle the SGA dilemma without additional communication operations. Besides, to further reduce the latency cost and improve the efficiency of SparDL, we propose the Spar-All-Gather algorithm. Moreover, we propose the global residual collection algorithm to ensure fast convergence of model training. Finally, extensive experiments are conducted to validate the superiority of SparDL.}
}


@inproceedings{DBLP:conf/icde/FanHRHJZW24,
	author = {Yuankai Fan and
                  Zhenying He and
                  Tonghui Ren and
                  Can Huang and
                  Yinan Jing and
                  Kai Zhang and
                  X. Sean Wang},
	title = {Metasql: {A} Generate-Then-Rank Framework for Natural Language to
                  {SQL} Translation},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {1765--1778},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00143},
	doi = {10.1109/ICDE60146.2024.00143},
	timestamp = {Wed, 07 Aug 2024 07:59:36 +0200},
	biburl = {https://dblp.org/rec/conf/icde/FanHRHJZW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Natural Language Interface to Databases (NLIDB) empowers non-technical users with database access through intuitive natural language (NL) interactions. Advanced approaches, utilizing neural sequence-to-sequence models or large-scale language models, typically employ auto-regressive decoding to generate unique SQL queries sequentially. While these translation models have greatly improved the overall translation accuracy, surpassing 70% on NLIDB benchmarks, the use of auto-regressive decoding to generate single SQL queries may result in sub-optimal outputs, potentially leading to erroneous translations. In this paper, we propose Metasql, a unified generate-then-rank framework that can be flexibly incorporated with existing NLIDBs to consistently improve their translation accuracy. Metasql introduces query metadata to control the generation of better SQL query candidates and uses learning-to-rank algorithms to retrieve globally optimized queries. Specifically, Metasql first breaks down the meaning of the given NL query into a set of possible query metadata, representing the basic concepts of the semantics. These metadata are then used as language constraints to steer the underlying translation model toward generating a set of candidate SQL queries. Finally, Metasql ranks the candidates to identify the best matching one for the given NL query. Extensive experiments are performed to study Metasql on two public NLIDB benchmarks. The results show that the performance of the translation models can be effectively improved using Metasql. In particular, applying Metasql to the published Lgesql model obtains a translation accuracy of 77.4 % on the validation set and 72.3 % on the test set of the Spider benchmark, outperforming the baseline by 2.3% and 0.3%, respectively. Moreover, applying Metasql to GpT-4 achieves translation accuracies of 68.6%, 42.0%, and 17.6 % on the three real-world complex scientific databases of Sciencebenchmark, respectively. The code for Metasql is available at https://github.com/Kaimary/MetaSQL.}
}


@inproceedings{DBLP:conf/icde/QiaoZBZYW24,
	author = {Pengpeng Qiao and
                  Kangfei Zhao and
                  Bei Bi and
                  Zhiwei Zhang and
                  Ye Yuan and
                  Guoren Wang},
	title = {Feed: Towards Personalization-Effective Federated Learning},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {1779--1791},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00144},
	doi = {10.1109/ICDE60146.2024.00144},
	timestamp = {Tue, 30 Jul 2024 08:18:20 +0200},
	biburl = {https://dblp.org/rec/conf/icde/QiaoZBZYW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated learning (FL) has become an emerging paradigm via cooperative training models among distributed clients without leaking data privacy. The performance degradation of F1 on heterogeneous data has driven the development of personalized FL (PFL) solutions, where different models are built for individual clients. However, existing PFL approaches often have limited personalization in terms of modeling capability and training strategy. In this paper, we propose a novel PFL solution, Feed, that employs an enhanced shared-private model architecture and equips with a hybrid federated training strategy. Specifically, to model heterogeneous data for different clients, we design an ensemble-based shared encoder that generates an ensemble of embeddings, and a private decoder that adaptively aggregates these embeddings for personalized prediction. In addition, we propose a server-side hybrid federated aggregation strategy to enable effective training of the heterogeneous shared-private model. To prevent personalization degradation in local model updates, we further optimize the personalized local training on the client-side by smoothing the historical encoders. Extensive experiments on MNIST/FEMNIST, CIFARIO/CIFARIOO, and YELP datasets demonstrate that Feed consistently outperforms state-of-the-art approaches.}
}


@inproceedings{DBLP:conf/icde/MadhyasthaBBVB24,
	author = {Meghana Madhyastha and
                  Tamas Budavari and
                  Vladimir Braverman and
                  Joshua T. Vogelstein and
                  Randal C. Burns},
	title = {T-Rex (Tree-Rectangles): Reformulating Decision Tree Traversal as
                  Hyperrectangle Enclosure},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {1792--1804},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00145},
	doi = {10.1109/ICDE60146.2024.00145},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/MadhyasthaBBVB24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Tree ensembles, random forests and gradient boosted trees, are useful in resource-limited machine learning deployments. However, traversing tree data structures is not cache friendly, which results in high latency during inference or regression. Tree traversal incurs random I/Os making inference memory bound. We present a system that trades many random I/Os for few sequential I/O by remapping a forest of trees into a single spatial index. It builds on the observation that each leaf in the forest encodes a hyperrectangle in the feature space. We make queries I/O efficient through pruning and space-filling curves. We then optimize computation through quantization of hyperrectangle boundaries and vectorization of enclosure queries. Our evaluation on a diverse set of benchmark datasets shows that the system reduces inference latency by 2 times in memory and 10 times for external memory with no detectable loss of accuracy.}
}


@inproceedings{DBLP:conf/icde/QiZ024,
	author = {Danrui Qi and
                  Weiling Zheng and
                  Jiannan Wang},
	title = {FeatAug: Automatic Feature Augmentation From One-to-Many Relationship
                  Tables},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {1805--1818},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00146},
	doi = {10.1109/ICDE60146.2024.00146},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/QiZ024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Feature augmentation from one-to-many relationship tables is a critical but challenging problem in ML model development. To augment good features, data scientists need to come up with SQL queries manually, which is time-consuming. Featuretools [1] is a widely used tool by the data science community to automatically augment the training data by extracting new features from relevant tables. It represents each feature as a group-by aggregation SQL query on relevant tables and can automatically generate these SQL queries. However, it does not include predicates in these queries, which significantly limits its application in many real-world scenarios. To overcome this limitation, we propose FEATAuG, a new feature augmentation framework that automatically extracts predicate-aware SQL queries from one-to-many relationship tables. This extension is not trivial because considering predicates will exponentially increase the number of candidate queries. As a result, the original Featuretools framework, which materializes all candidate queries, will not work and needs to be redesigned. We formally define the problem and model it as a hyperparameter optimization problem. We discuss how the Bayesian Optimization can be applied here and propose a novel warm-up strategy to optimize it. To make our algorithm more practical, we also study how to identify promising attribute combinations for predicates. We show that how the beam search idea can partially solve the problem and propose several techniques to further optimize it. Our experiments on four real-world datasets demonstrate that FeatAug extracts more effective features compared to Featuretools and other baselines. The code is open-sourced at https://github.com/sfu-db/FeatAug.}
}


@inproceedings{DBLP:conf/icde/Wang0S24,
	author = {Chunnan Wang and
                  Hongzhi Wang and
                  Xiangyu Shi},
	title = {AutoMC: Automated Model Compression Based on Domain Knowledge and
                  Progressive Search},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {1819--1832},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00147},
	doi = {10.1109/ICDE60146.2024.00147},
	timestamp = {Sun, 06 Oct 2024 21:04:59 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Wang0S24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Model compression methods can reduce model complexity on the premise of maintaining acceptable performance, and thus promote the application of deep neural networks under resource constrained environments. Despite their great success, the selection of suitable compression methods and design of details of the compression scheme are difficult, requiring lots of domain knowledge as support, which is not friendly to non-expert users. To make more users easily access to the model compression scheme that best meet their needs, in this paper, we propose AutoMC, an effective and efficient automatic tool for model compression. In order to improve the search efficiency and quality, in AutoMC, we build the domain knowledge on model compression to deeply understand the characteristics and advantages of each compression method under different settings. This method can provide AutoMC with the more reasonable guidance and thus reduce useless evaluation. In addition, we present a progressive search strategy to efficiently explore pareto optimal compression scheme according to the learned prior knowledge combined with the historical evaluation information. This strategy can help AutoMC selectively and gradually explore more valuable search space, and thus reduce the search difficulty and improve the search efficiency. Extensive experimental results show that AutoMC can provide users with better compression schemes within short time compared to the existing compression methods and AutoML algorithms, which demonstrates the effectiveness and significance of our proposed algorithm.}
}


@inproceedings{DBLP:conf/icde/AbdallahAK024,
	author = {Hussein Abdallah and
                  Waleed Afandi and
                  Panos Kalnis and
                  Essam Mansour},
	title = {Task-Oriented GNNs Training on Large Knowledge Graphs for Accurate
                  and Efficient Modeling},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {1833--1846},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00148},
	doi = {10.1109/ICDE60146.2024.00148},
	timestamp = {Sun, 06 Oct 2024 21:04:56 +0200},
	biburl = {https://dblp.org/rec/conf/icde/AbdallahAK024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A Knowledge Graph (KG) is a heterogeneous graph encompassing a diverse range of node and edge types. Heterogeneous Graph Neural Networks (HGNNs) are popular for training machine learning tasks like node classification and link prediction on KGs. However, HGNN methods exhibit excessive complexity influenced by the KG's size, density, and the number of node and edge types. AI practitioners handcraft a subgraph of a KG\nG\nrelevant to a specific task. We refer to this subgraph as a task-oriented subgraph (TOSG), which contains a subset of task-related node and edge types in\nG\n. Training the task using TOSG instead of\nG\nalleviates the excessive computation required for a large KG. Crafting the TOSG demands a deep understanding of the KG's structure and the task's objectives. Hence, it is challenging and time-consuming. This paper proposes KG-TOSA, an approach to automate the TOSG extraction for task-oriented HGNN training on a large KG. In KG-TOSA, we define a generic graph pattern that captures the KG's local and global structure relevant to a specific task. We explore different techniques to extract subgraphs matching our graph pattern: namely (i) two techniques sampling around targeted nodes using biased random walk or influence scores, and (ii) a SPARQL-based extraction method leveraging RDF engines' built-in indices. Hence, it achieves negligible preprocessing overhead compared to the sampling techniques. We develop a benchmark of real KGs of large sizes and various tasks for node classification and link prediction. Our experiments show that KG-TOSA helps state-of-the-art HGNN methods reduce training time and memory usage by up to 70% while improving the model performance, e.g., accuracy and inference time.}
}


@inproceedings{DBLP:conf/icde/Jiang0XWQ24,
	author = {Zhida Jiang and
                  Yang Xu and
                  Hongli Xu and
                  Zhiyuan Wang and
                  Chunming Qiao},
	title = {Clients Help Clients: Alternating Collaboration for Semi-Supervised
                  Federated Learning},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {1847--1860},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00149},
	doi = {10.1109/ICDE60146.2024.00149},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Jiang0XWQ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated learning (FL) provides a distributed framework for multiple clients to collaboratively train models without exposing raw data. Most FL research assumes that all clients have fully labeled data, which is impractical for many real-world applications. To this end, we focus on semi-supervised FL (SSFL), where data samples of each client are partially labeled. However, existing SSFL methods ignore two inherent characteristics of FL: limited communication resources and heterogeneous data distribution, which severely hinder convergence stability and efficiency. This paper proposes a novel SSFL mechanism, called FedAC, to address the above two challenges by alternating client-to-client (C2C) collaboration. Specifically, we group all clients using different clustering strategies at two different training stages. During each global round, FedAC first performs similarity clustering based on local data distribution, which gathers the knowledge from similar clients to generate high-quality pseudo-labels for unlabeled data. Then the clients are re-grouped using dissimilarity clustering strategy to approximate the IID setting at the cluster level, thereby alleviating the bias induced by Non-IID data. FedAC adopts a reinforcement learning algorithm to achieve a balance between labeling assistance from similar clients and unbiased optimization from dissimilar clients. Extensive evaluations demonstrate that FedAC can improve model accuracy and save up to 59.65% of communication costs compared with existing benchmarks.}
}


@inproceedings{DBLP:conf/icde/IonescuVB0K24,
	author = {Andra Ionescu and
                  Kiril Vasilev and
                  Florena Buse and
                  Rihan Hai and
                  Asterios Katsifodimos},
	title = {AutoFeat: Transitive Feature Discovery over Join Paths},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {1861--1873},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00150},
	doi = {10.1109/ICDE60146.2024.00150},
	timestamp = {Mon, 19 Aug 2024 20:24:08 +0200},
	biburl = {https://dblp.org/rec/conf/icde/IonescuVB0K24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Can we automatically discover machine learning (ML) features in a large data lake in order to increase the accuracy of a given ML model? Existing solutions either focus on simple star schemata, failing to discover features in more complex real-world schemata or consider only PK-FK relationships in clean, curated databases. However, real-world data lakes can contain long join paths of uncurated joinability relationships resulting from automated dataset discovery methods. This paper proposes a novel ranking-based feature discovery method called AutoFeat. Given a base table with a target label, AutoFeat explores multi-hop, transitive join paths to find relevant features in order to augment the base table with additional features, ultimately leading to increased accuracy of an ML model. AutoFeat is general: it evaluates the predictive power of features without the need to train an ML model, ranking join paths using the concepts of relevance and redundancy. Our experiments on real-world open data show that AutoFeat is efficient: it can find features of high predictive power on data lakes with an increased number of dataset joinability relationships 5x-44x faster than baseline approaches. In addition, AutoFeat is effective, improving accuracy by 16% on average compared to the baseline approaches, even in noisy, uncurated data lakes.}
}


@inproceedings{DBLP:conf/icde/ZhuZCC24,
	author = {Xinyi Zhu and
                  Yongqi Zhang and
                  Lei Chen and
                  Kai Chen},
	title = {Triple-D: Denoising Distant Supervision for High-Quality Data Creation},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {1874--1887},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00151},
	doi = {10.1109/ICDE60146.2024.00151},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhuZCC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Distant supervision is a technique that aims to create large amounts of training data at a low cost. This approach benefits various downstream systems, particularly in natural language processing and relation extraction tasks. However, due to its strong assumption that any sentence containing entities expresses the specific relation between them found in existing knowledge bases (KBs), distant supervision introduces considerable noise. Existing works attempt to denoise distant supervision data by either using the original text or replacing entities in the text with patterns representing the entity types as inputs. However, replacing a frequently repeating pattern will result in loss of context due to the excessively general semantics of the pattern. Furthermore, due to the lack of ground truth, denoising module often relies on parametric models that still learn distribution from noisy data, which further limits model performance. In this paper, we propose Triple-d, a technique for high-quality data creation through adaptive pattern replacement and a scalable non-parametric model. Specifically, we formulate the adaptive pattern replacement task as a maximum-profit bipartite graph problem and propose an approximation algorithm as a solution. Additionally, we design a non-parametric model with scalable instance normalization to efficiently estimate and eliminate the influence of each dimension in neighbors. Extensive experiments in the denoising task and a downstream relation extraction task on real-world datasets demonstrate the superior effectiveness and efficiency of Triple-d, highlighting its potential to improve the performance for high-quality data creation. 1 1 Corresponding author: Yongqi Zhang.}
}


@inproceedings{DBLP:conf/icde/ZhaoZWY0WX24,
	author = {Shuai Zhao and
                  Zhiwei Zhang and
                  Junkai Wang and
                  Ye Yuan and
                  Meihui Zhang and
                  Guoren Wang and
                  Jiang Xiao},
	title = {Efficient Partial Order Based Transaction Processing for Permissioned
                  Blockchains},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {1888--1901},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00152},
	doi = {10.1109/ICDE60146.2024.00152},
	timestamp = {Tue, 30 Jul 2024 08:18:20 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhaoZWY0WX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the development of permissioned blockchains, transaction processing plays an increasingly crucial role in improving performance. The execution and consensus phases in existing transaction processing methods are based on total order. The consensus phase constructs a total order representing the execution order and submission order of different transactions. Then, in the execution phase, transactions are executed or validated sequentially based on this total order. However, while the total order guarantees consistency across nodes, it also restricts the execution order of any two transactions, even if there is no conflict between them. Additionally, existing methods process transactions based on block snapshots before the consensus phase, but these snapshots are only updated after reaching consensus. The stale data between these phases results in high transaction abort rates due to delays in updated visibility. Therefore, we propose a novel blockchain called Partial Order-Based Ledger (POBL). POBL constructs a partial order of transaction executions in the execution phase and then, in the consensus phase, builds a consistent submission order based on this execution partial order. Notably, POBL allows the visibility of transaction processing results in the execution phase even before committing its block. To ensure the correct execution, the consensus and execution phases need to consider the consistency of data and the dependencies between transactions. Therefore, we use a graph, PGraph, to capture the concurrent partial order in the execution phase. In the consensus phase, we propose a consensus algorithm to conduct the maximal common subgraph, CPGraph, based on the PGraphs of different nodes. We propose to validate blocks and transactions in parallel based on CPGraph, without being restricted by the order between blocks. We perform extensive experiments compared to state-of-the-art architectural systems, and our method significantly outperforms existing work.}
}


@inproceedings{DBLP:conf/icde/TongYZJZ24,
	author = {Xing Tong and
                  Zheming Ye and
                  Zhao Zhang and
                  Cheqing Jin and
                  Aoying Zhou},
	title = {{TELL:} Efficient Transaction Execution Protocol Towards Leaderless
                  Consensus},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {1902--1915},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00154},
	doi = {10.1109/ICDE60146.2024.00154},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/TongYZJZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Permissioned blockchain, as a multi-replica system, has its performance significantly affected by both the consensus protocol and the transaction execution protocol. Currently, there are many works optimizing the consensus or transaction execution of permissioned blockchain. However, existing works mainly focus on optimizing either consensus or transaction execution independently, lacking a holistic perspective. Based on this observation, we consider optimizing the permissioned blockchain from the holistic optimization perspective. Specifically, we heuristically design a transaction execution protocol TELL towards leaderless consensus to achieve collaborative optimization of consensus and transaction execution. Leaderless consensus is essentially a parallel running of multiple leader-based consensus instances, based on this characteristic, TELL pertinently designs intra-instance execution and inter-instances merging protocols. Additionally, we devise a novel State Hash Table (SHT) to record transactions' accessed states, so as to improve conflict serialization efficiency. Besides, we propose Dynamic Commitment Epoch (DCE) to adapt to instances' running status and decrease blocks' committing latency. Experimental results shows that compared with existing works, TELL further improves the performance of permissioned blockchain.}
}


@inproceedings{DBLP:conf/icde/KangRHS24,
	author = {Dakai Kang and
                  Sajjad Rahnama and
                  Jelle Hellings and
                  Mohammad Sadoghi},
	title = {SpotLess: Concurrent Rotational Consensus Made Practical Through Rapid
                  View Synchronization},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {1916--1929},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00157},
	doi = {10.1109/ICDE60146.2024.00157},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/KangRHS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The emergence of blockchain technology has renewed the interest in consensus-based data management systems that are resilient to failures. To maximize the throughput of these systems, we have recently seen several prototype consensus solutions that optimize for throughput at the expense of overall implementation complexity, high costs, and reliability. Due to this, it remains unclear how these prototypes will perform in real-world environments. In this paper, we present SpotLess, a novel concurrent rotational consensus protocol made practical. Central to SpotLess is the combination of (1) a chained rotational consensus design for replicating requests with a reduced message cost and low-cost failure recovery that eliminates the traditional complex, error-prone view-change protocol; (2) the novel Rapid View Synchronization protocol that enables SpotLess to work in more general network assumptions, without a need for a Global Synchronization Time to synchronize view, and recover valid earlier views with the aid of non-faulty replicas without the need to rely on the primary; (3) a high-performance concurrent consensus architecture in which independent instances of the chained consensus operate concurrently to process requests with high throughput, thereby avoiding the bottlenecks seen in other rotational protocols. Due to the concurrent consensus architecture, SpotLess greatly outperforms traditional primary-backup consensus protocols such as Pbft (by up to 430%), Narwhal-HS (by up to 137%), and HotStuff (by up to 3803%). Due to its reduced message cost, SpotLess is even able to outperform RCC, a state-of-the-art high-throughput concurrent consensus protocol, by up to 23%. Furthermore, SpotLess is able to maintain a stable and low latency and consistently high throughput even during failures.}
}


@inproceedings{DBLP:conf/icde/ZhangPTJ24,
	author = {Gengrui Zhang and
                  Fei Pan and
                  Sofia Tijanic and
                  Hans{-}Arno Jacobsen},
	title = {PrestigeBFT: Revolutionizing View Changes in {BFT} Consensus Algorithms
                  with Reputation Mechanisms},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {1930--1943},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00156},
	doi = {10.1109/ICDE60146.2024.00156},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhangPTJ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Passive view-change protocols are widely employed in BFT algorithms; however, they present the risks of selecting unavailable or slow servers as leaders. To tackle these challenges, we propose PrestigeBFT, a novel BFT consensus algorithm that incorporates an active view-change protocol with reputation mechanisms. PrestigeBFT evaluates a server's reputation based on its past behavior and elects more reputable servers as leaders. Our reputation mechanism incentivizes protocol-abiding behavior while penalizing faulty servers by imposing computational work. PrestigeBFT significantly enhances system availability and efficiency by avoiding unavailable or slow servers being assigned as leaders. Under normal operation, PrestigeBFT achieves\n5×\nhigher throughput than the baseline that uses passive view-change protocols. In addition, PrestigeBFT's throughput remains unaffected under benign faults and witnesses only a 24% drop under a variety of Byzantine faults, whereas the baseline throughput drops by 62% and 69%, respectively. In the long run, while the baseline's availability struggles at 37%, PrestigeBFT progressively improves its availability to over 90%.}
}


@inproceedings{DBLP:conf/icde/ChenXCDZHLZ24,
	author = {Wuhui Chen and
                  Ding Xia and
                  Zhongteng Cai and
                  Hong{-}Ning Dai and
                  Jianting Zhang and
                  Zicong Hong and
                  Junyuan Liang and
                  Zibin Zheng},
	title = {Porygon: Scaling Blockchain via 3D Parallelism},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {1944--1957},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00153},
	doi = {10.1109/ICDE60146.2024.00153},
	timestamp = {Sun, 06 Oct 2024 21:04:56 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ChenXCDZHLZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recently, stateless blockchains have been proposed to alleviate the storage overhead for nodes. A stateless blockchain achieves storage-consensus parallelism, where storage workloads are offloaded from on-chain consensus, enabling more resource-constraint nodes to participate in the consensus. However, existing stateless blockchains still suffer from limited throughput. In this paper, we present Porygon, a novel stateless blockchain with three-dimensional (3D) parallelism. First, Porygon separates the storage and consensus of transactions as the stateless blockchain, achieving the storage-consensus parallelism. This first-dimensional parallelism divides the processing of transactions into several stages and scales the network by supporting more nodes in the system. Based on such a design, we then propose a pipeline mechanism to achieve second-dimensional inter-block parallelism, where relevant stages of processing transactions are pipelined efficiently, thereby reducing transaction latency. Finally, Porygon presents a sharding mechanism to achieve third-dimensional inner-block parallelism. By sharding the executions of transactions of a block and adopting a lightweight cross-shard coordination mechanism, Porygon can effectively execute both intra-shard and cross-shard transactions, consequently achieving outstanding transaction throughput. We evaluate the performance of Porygon by extensive experiments on an implemented prototype and large-scale simulations. Compared with existing blockchains, Porygon boosts throughput by up to 20x, reduces network usage by more than 50%, and simultaneously requires only 5MB of storage consumption per node.}
}


@inproceedings{DBLP:conf/icde/LiZX0YW24,
	author = {Siyu Li and
                  Zhiwei Zhang and
                  Jiang Xiao and
                  Meihui Zhang and
                  Ye Yuan and
                  Guoren Wang},
	title = {Authenticated Keyword Search on Large-Scale Graphs in Hybrid-Storage
                  Blockchains},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {1958--1971},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00155},
	doi = {10.1109/ICDE60146.2024.00155},
	timestamp = {Tue, 30 Jul 2024 08:18:18 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LiZX0YW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The widespread availability of Internet access and online services has led to the generation of numerous large-scale graphs in various real-world applications, such as online social networks and knowledge graphs. Keyword search stands out as a crucial task in the analysis and mining of these graphs. However, graph data owners tend to outsource storage and computation tasks to the cloud due to limited computing and storage resources. In this case, it is critical to ensure the integrity of the query results, as the cloud may have an incentive to return tampered results to serve its own interests. Currently, blockchain systems can store data efficiently and securely, creating a decentralized, tamper-proof digital platform. This functionality positions blockchain as a crucial complement and enhancement to traditional cloud storage solutions. Mainstream blockchains use a hybrid storage system to improve scalability, storing small meta-data on-chain and outsourcing raw data off-chain. While cryptographic proofs protect data integrity for queries, current schemes only support key-value data. This paper pioneers the study of authenticated keyword searches on graphs in hybrid-storage blockchains. The key challenge is to design an authenticated data structure (ADS) based on the graph data that can efficiently deal with keyword search queries. We propose Merkle Path DAG (MP-DAG), a novel ADS that aggregates the unqualified paths that will not appear in the result trees to efficiently handle authenticated keyword search queries on graphs. Furthermore, to reduce the ADS storage cost, we design an optimization scheme MP-DAG* by combining the similar subgraphs of MP-DAG. Experimental results demonstrate the performance of the proposed ADS and optimization measure.}
}


@inproceedings{DBLP:conf/icde/QianWDVRCZWCH24,
	author = {Peng Qian and
                  Hanjie Wu and
                  Zeren Du and
                  Turan Vural and
                  Dazhong Rong and
                  Zheng Cao and
                  Lun Zhang and
                  Yanbin Wang and
                  Jianhai Chen and
                  Qinming He},
	title = {MuFuzz: Sequence-Aware Mutation and Seed Mask Guidance for Blockchain
                  Smart Contract Fuzzing},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {1972--1985},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00158},
	doi = {10.1109/ICDE60146.2024.00158},
	timestamp = {Sun, 06 Oct 2024 21:04:58 +0200},
	biburl = {https://dblp.org/rec/conf/icde/QianWDVRCZWCH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As blockchain smart contracts become more widespread and carry more valuable digital assets, they become an increasingly attractive target for attackers. Over the past few years, smart contracts have been subject to a plethora of devastating attacks, resulting in billions of dollars in financial losses. There has been a notable surge of research interest in identifying defects in smart contracts. However, existing smart contract fuzzing tools are still unsatisfactory. They struggle to screen out meaningful transaction sequences and specify critical inputs for each transaction. As a result, they can only trigger a limited range of contract states, making it difficult to unveil complicated vulnerabilities hidden in the deep state space. In this paper, we shed light on smart contract fuzzing by employing a sequence-aware mutation and seed mask guidance strategy. In particular, we first utilize data-flow-based feedback to determine transaction orders in a meaningful way and further introduce a sequence-aware mutation technique to explore deeper states. Thereafter, we design a mask-guided seed mutation strategy that biases the generated transaction inputs to hit target branches. In addition, we develop a dynamic-adaptive energy adjustment paradigm that balances the fuzzing resource allocation during a fuzzing campaign. We implement our designs into a new smart contract fuzzer named MuFuzz, and extensively evaluate it on three benchmarks. Empirical results demonstrate that MuFuzz outperforms existing tools in terms of both branch coverage and bug finding. Overall, MuFuzz achieves higher branch coverage than state-of-the-art fuzzers (up to 25%) and detects 30 % more bugs than existing bug detectors.}
}


@inproceedings{DBLP:conf/icde/LiZZYW24,
	author = {Siyu Li and
                  Zhiwei Zhang and
                  Meihui Zhang and
                  Ye Yuan and
                  Guoren Wang},
	title = {Authenticated Subgraph Matching in Hybrid-Storage Blockchains},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {1986--1998},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00159},
	doi = {10.1109/ICDE60146.2024.00159},
	timestamp = {Tue, 30 Jul 2024 08:18:20 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LiZZYW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graphs serve as an essential data structure to model complex relationships in a variety of applications, such as social networks, web graphs, and chemical informatics. Due to the high cost of maintaining large-scale graph data and executing graph queries, data owners often outsource their graph data to a third-party service provider for graph processing. In this scenario, it is crucial to ensure the integrity of query results, as the provider may have the incentive to return only partial or tampered results to save computing resources or serve their own interests. Blockchain, as a promising solution for secure data storage and retrieval, opens up new opportunities for data management in such scenarios. To scale the blockchain, many works have been conducted using off-chain storage while ensuring the integrity of query results for key-value data in hybrid-storage blockchain architectures. To our knowledge, there is no work to enable the blockchain to support subgraph matching queries. In this paper, we present a novel approach to support authenticated subgraph matching queries for large graphs kept off-chain. We first design the authenticated data structure as MELTree and keep the digests of the roots on-chain. We propose the verification object (VO) construction algorithm AMatching for queries to ensure the completeness and soundness of the results. To further reduce the cost, we propose AMatching* based on a bidirectional search including forward search and reverse search. Moreover, we further optimize the on-chain storage cost by proposing MVPTree, which organizes the structures for vertices and only needs to keep one root digest on-chain for verification. Experimental results show that the proposed algorithms and the optimizations improve the performance significantly.}
}


@inproceedings{DBLP:conf/icde/00010C00T0X24,
	author = {Haixin Wang and
                  Cheng Xu and
                  Xiaojie Chen and
                  Ce Zhang and
                  Haibo Hu and
                  Shikun Tian and
                  Ying Yan and
                  Jianliang Xu},
	title = {{V2FS} : {A} Verifiable Virtual Filesystem for Multi-Chain Query Authentication},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {1999--2011},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00160},
	doi = {10.1109/ICDE60146.2024.00160},
	timestamp = {Sun, 06 Oct 2024 21:04:56 +0200},
	biburl = {https://dblp.org/rec/conf/icde/00010C00T0X24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The rise of decentralized finance (DeFi), Web 3.0, and other blockchain-based applications has led to an increased demand for on-chain data analysis across multiple blockchains. Conducting advanced queries, such as data aggregation and correlation analysis, is essential for gaining valuable insights in this context. However, multi-chain queries pose several challenges for the querying system, including compatibility with existing blockchains, supporting diverse query types, and ensuring the integrity of query results. To tackle these challenges, we propose a novel paradigm called verifiable virtual filesystem (V 2 FS). V 2 FS extends the POSIX I/O interface, shifting the focus from verifying computation to verifying data. This innovative approach empowers query clients to leverage an off-the-shelf database engine to evaluate queries using verifiable data retrieved from an indexing service provider (ISP). Our solution ensures strong integrity guarantees and can be smoothly integrated with existing database engines to support various query types. To achieve blockchain compatibility, we utilize the DCert framework to certify blocks from different blockchains, making our system applicable to various blockchain systems. Furthermore, we propose cache-based algorithms and a bloom filter-integrated algorithm to optimize query performance and minimize network communication costs. Security analysis and empirical study validate the effectiveness and efficiency of the proposed system.}
}


@inproceedings{DBLP:conf/icde/ZhengZLYCPD24,
	author = {Qiushi Zheng and
                  Zhanhao Zhao and
                  Wei Lu and
                  Chang Yao and
                  Yuxing Chen and
                  Anqun Pan and
                  Xiaoyong Du},
	title = {Lion: Minimizing Distributed Transactions Through Adaptive Replica
                  Provision},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {2012--2025},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00161},
	doi = {10.1109/ICDE60146.2024.00161},
	timestamp = {Sun, 06 Oct 2024 21:05:00 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhengZLYCPD24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Distributed transaction processing often involves multiple rounds of cross-node communications, and therefore, tends to be slow. To improve performance, existing approaches convert distributed transactions into single-node transactions by either migrating co-accessed partitions onto the same nodes or establishing a super node housing replicas of the entire database. However, migration-based methods might cause transactions to be blocked due to waiting for data migration, while the super node can become a bottleneck. In this paper, we present Lion, a novel transaction processing protocol that utilizes partition-based replication to reduce the occurrence of distributed transactions. Inspired by the fact that modern distributed databases horizontally partition data, with each partition having multiple replicas, Lion aims to assign a node with one replica from each partition involved in a given transaction's read or write operations. To ensure such a node is available, we propose an adaptive replica provision mechanism, enhanced with an LSTM-based workload prediction algorithm, to determine the appropriate node for locating replicas of co-accessed partitions. The adaptation of replica placement is conducted preemptively and asynchronously, thereby minimizing its impact on performance. By employing this adaptive replica placement strategy, we ensure that the majority of transactions can be efficiently processed on a single node without additional overhead. Only a small fraction of transactions will need to be treated as regular distributed transactions when such a node is unavailable. Consequently, Lion effectively minimizes distributed transactions, while avoiding any disruption caused by data migration or the creation of a super node. We conduct extensive experiments to compare Lion against various transaction processing protocols. The results show that Lion achieves up to 2.7x higher throughput and 76.4% better scalability against these state-of-the-art approaches.}
}


@inproceedings{DBLP:conf/icde/PanT0ZC0O24,
	author = {Hexiang Pan and
                  Quang{-}Trung Ta and
                  Meihui Zhang and
                  Zhanhao Zhao and
                  Yeow Meng Chee and
                  Gang Chen and
                  Beng Chin Ooi},
	title = {{FC:} Adaptive Atomic Commit via Failure Detection},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {2026--2039},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00162},
	doi = {10.1109/ICDE60146.2024.00162},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/PanT0ZC0O24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Atomic commit protocols (ACPs) are crucial for ensuring transaction atomicity in distributed transaction processing. However, existing ACPs, designed specifically for fixed failure conditions, cannot work efficiently in modern environments, where failures such as node crashes and connection delays can happen anytime due to the use of commodity nodes and networks. In this paper, we propose FC, a novel and practical ACP that can adapt to changes in failure conditions. In essence, FC includes three dedicated protocols, which are specifically designed for three different failure conditions: (i) failure-free: no failure occurs, (ii) crash-failure: nodes might crash but there is no delayed connection, or (iii) network-failure: both crashed nodes and delayed connection can occur. During its operation, FC can monitor if any failure occurs and dynamically switch to the most suitable protocol, using a protocol selector, whose parameters are fine-tuned by reinforcement learning. Consequently, FC improves transaction performance and robustly ensures fault tolerance when crash failures and network failures occur. We conduct extensive experiments to evaluate FC with both YCSB and TPC-C benchmarks. The experimental results show that FC achieves up to 2.88x higher throughput and 3.76x lower latency than state-of-the-art ACPs, and its sustainable performance when integrated with two popular databases, namely MongoDB and PostgreSQL.}
}


@inproceedings{DBLP:conf/icde/AgnihotriKSHBL24,
	author = {Pratyush Agnihotri and
                  Boris Koldehofe and
                  Paul Stiegele and
                  Roman Heinrich and
                  Carsten Binnig and
                  Manisha Luthra},
	title = {ZERoTuNE: Learned Zero-Shot Cost Models for Parallelism Tuning in
                  Stream Processing},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {2040--2053},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00163},
	doi = {10.1109/ICDE60146.2024.00163},
	timestamp = {Sun, 06 Oct 2024 21:04:56 +0200},
	biburl = {https://dblp.org/rec/conf/icde/AgnihotriKSHBL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper introduces ZEROTuNE, a novel cost model for parallel and distributed stream processing that can be used to effectively set initial parallelism degrees of streaming queries. Unlike existing models, which rely majorly on online learning statistics that are non-transferable, context-specific, and require extensive training, ZEROTuNE proposes data-efficient zero-shot learning techniques that enable very accurate cost predictions without having observed any query deployment. To overcome these challenges, we propose ZEROTuNE, a graph neural network architecture that can learn from the structural complexity of parallel distributed stream processing systems, enabling them to adapt to unseen workloads and hardware configurations. In our experiments, we show when integrating ZEROTuNE in a distributed streaming system such as Apache Flink, we can accurately set the degree of parallelism, showing an average speed-up of around 5× in comparison to existing approaches.}
}


@inproceedings{DBLP:conf/icde/LiaoXXWYQ24,
	author = {Yunming Liao and
                  Yang Xu and
                  Hongli Xu and
                  Lun Wang and
                  Zhiwei Yao and
                  Chunming Qiao},
	title = {MergeSFL: Split Federated Learning with Feature Merging and Batch
                  Size Regulation},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {2054--2067},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00164},
	doi = {10.1109/ICDE60146.2024.00164},
	timestamp = {Tue, 30 Jul 2024 09:18:50 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LiaoXXWYQ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recently, federated learning (FL) has emerged as a popular technique for edge AI to mine valuable knowledge in edge computing (EC) systems. To boost the performance of AI applications, large-scale models have received increasing attention due to their excellent generalized abilities. However, training and transmitting large-scale models will incur significant computing and communication burden on the resource-constrained workers, and the exchange of entire models may violate model privacy. To relax the burden of workers and protect model privacy, split federated learning (SFL) has been released by integrating both data and model parallelism. Despite resource limitations, SFL also faces two other critical challenges in EC systems, i.e., statistical heterogeneity and system heterogeneity. In order to address these challenges, we propose a novel SFL framework, termed MergeSFL, by incorporating feature merging and batch size regulation in SFL. Concretely, feature merging aims to merge the features from workers into a mixed feature sequence, which is approximately equivalent to the features derived from IID data and is employed to promote model accuracy. While batch size regulation aims to assign diverse and suitable batch sizes for heterogeneous workers to improve training efficiency. Moreover, MergeSFL explores to jointly optimize these two strategies upon their coupled relationship to better enhance the performance of SFL. Extensive experiments are conducted on a physical platform with 80 NVIDIA Jetson edge devices, and the experimental results show that MergeSFL can improve the final model accuracy by 5.82% to 26.22%, with a speedup by about 1.39x to 4.14x, compared to the baselines.}
}


@inproceedings{DBLP:conf/icde/ChengXLZZ0L024,
	author = {Feng Cheng and
                  Jiang Xiao and
                  Cunyang Liu and
                  Shijie Zhang and
                  Yifan Zhou and
                  Bo Li and
                  Baochun Li and
                  Hai Jin},
	title = {SharDAG: Scaling DAG-Based Blockchains Via Adaptive Sharding},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {2068--2081},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00165},
	doi = {10.1109/ICDE60146.2024.00165},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ChengXLZZ0L024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Directed Acyclic Graph (DAG)-based blockchain (a.k.a distributed ledger) has become prevalent for supporting highly concurrent applications. Its inherent parallel data structure accelerates block generation significantly, shifting the bottleneck from performance to storage scalability. An intuitive solution is to apply state sharding that divides the entire ledger (i.e., transactions and states) into multiple shards. While each node only stores proportional transactions, it suffers from the challenges of storing and ensuring the processing consistency of cross-shard transactions. In this paper, we propose SharDAG, a new mechanism that leverages adaptive sharding for DAG-based blockchains to achieve high performance and strong consistency. The key idea of SharDAG is to exploit unique characteristics - silent assets - and design a lightweight processing mechanism based on avatar account caching. Furthermore, we design a Byzantine resilient cross-shard verification mechanism with a theoretically optimal number of participating nodes, which guarantees the consistency and security of avatar account aggregation. Our comprehensive evaluations on real-world workloads demonstrate that SharDAG presents up to 3.8 x throughput improvement compared to the state-of-the-art and reduces the storage overhead of cross-shard transactions.}
}


@inproceedings{DBLP:conf/icde/0003HSDCMZ024,
	author = {Yi Wang and
                  Jiajian He and
                  Kaoyi Sun and
                  Yunhao Dong and
                  Jiaxian Chen and
                  Chenlin Ma and
                  Amelie Chi Zhou and
                  Rui Mao},
	title = {Boosting Write Performance of {KV} Stores: An {NVM} - Enabled Storage
                  Collaboration Approach},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {2082--2095},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00166},
	doi = {10.1109/ICDE60146.2024.00166},
	timestamp = {Sun, 06 Oct 2024 21:04:56 +0200},
	biburl = {https://dblp.org/rec/conf/icde/0003HSDCMZ024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As the most common data structure for key-value stores, LogStructured Merge Tree (LSM-tree) can eliminate random write operations and keep acceptable read performance. However, write stall and write amplification introduced by the leveled compaction of LSM-tree significantly degrade the system performance. The emerging non-volatile memory (NVM) provides byte-addressable access and low-latency data persistence. Integrating DIMM-interface NVM in the design of the LSM-tree can potentially alleviate the write stall and write amplification issue, as the access speed of NVM is several orders of magnitude faster than hard disk drives or flash memory-based solid-state drives. This hybrid storage should be carefully designed, requiring new architectural and key-value structural support. This paper presents ZigZagDB, an NVM-enabled data man-agement scheme for LSM-tree-based key-value stores. ZigZagDB adds additional layers of key-value stores and uses non-volatile memory as the storage media to hold these additional layers of data. The newly designed key-value stores alternately access the data from either SSD or NVM. This ‘ZigZag’ shape of storage collaboration and synchronization can benefit write efficiency and space utilization. By utilizing the NVM with very limited capacity, the redesigned organization of LSM-tree can effectively solve the write stall and write amplification issue. We demonstrate the viability of the proposed ZigZagDB using a set of extensive experiments. Experimental results show that ZigZagDB can significantly reduce the write amplification and boost the throughput in comparison with representative schemes.}
}


@inproceedings{DBLP:conf/icde/ZhuYCWZCQ24,
	author = {Jun{-}Peng Zhu and
                  Zhiwei Ye and
                  Peng Cai and
                  Donghui Wang and
                  Fengyan Zhang and
                  Dunbo Cai and
                  Ling Qian},
	title = {Log Replaying for Real-Time {HTAP:} An Adaptive Epoch-Based Two-Stage
                  Framework},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {2096--2108},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00167},
	doi = {10.1109/ICDE60146.2024.00167},
	timestamp = {Sun, 06 Oct 2024 21:05:00 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhuYCWZCQ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As real-time analytics become increasingly important, more organizations are deploying Hybrid Transactional/An-alytical Processing (HTAP) systems. The HTAP systems, based on a primary/backup replication architecture, usually support real-time read-only queries on backup nodes for the data recently generated by OLTP applications on the primary node. This work is based on the observation that real-time analytical applications often require access to only a fraction of the latest modifications from OLTP applications. However, the state-of-the-art parallel log replay approaches treat all replicated transaction logs equally and replay the entire transaction logs with the same priority which does not take consideration into the OLAP query access pattern. This design can result in increased response latency for real-time applications. This paper presents AETS, an Adaptive Epoch-based Two-Stage log replay framework that implements epoch-based log replay and table group transaction commit. Simultaneously, AETS also takes full account of the table access priority in real-time HTAP workload log replay. It aims to make the data required by analytical queries visible more quickly. Furthermore, AETS includes a two-phase parallel log replay algorithm called TPLR, which achieves lower overhead compared to state-of-the-art algorithms through careful design. We also offer an adaptive fine-grained thread resource allocation method that considers changes in table access patterns over time under thread resource constraints. Our experimental results show that AETS significantly reduces visibility delay for real-time queries. And the results also show that AETS achieves significant replay throughput improvement.}
}


@inproceedings{DBLP:conf/icde/OakleyF24,
	author = {Joe Oakley and
                  Hakan Ferhatosmanoglu},
	title = {FSD-Inference: Fully Serverless Distributed Inference with Scalable
                  Cloud Communication},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {2109--2122},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00168},
	doi = {10.1109/ICDE60146.2024.00168},
	timestamp = {Tue, 24 Sep 2024 21:55:22 +0200},
	biburl = {https://dblp.org/rec/conf/icde/OakleyF24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Serverless computing offers attractive scalability, elasticity and cost-effectiveness. However, constraints on memory, CPU and function runtime have hindered its adoption for dataintensive applications and machine learning (ML) workloads. Traditional ‘server-ful’ platforms enable distributed computation via fast networks and well-established inter-process communication (IPC) mechanisms such as MPI and shared memory. In the absence of such solutions in the serverless domain, parallel computation with significant IPC requirements is challenging. We present FSD-Inference, the first fully serverless and highly scalable system for distributed ML inference. We explore poten-tial communication channels, in conjunction with Function-as-a-Service (FaaS) compute, to design a state-of-the-art solution for distributed ML within the context of serverless data-intensive computing. We introduce novel fully serverless communication schemes for ML inference workloads, leveraging both cloud-based publish-subscribe/queueing and object storage offerings. We demonstrate how publish-subscribe/queueing services can be adapted for FaaS IPC with comparable performance to object storage, while offering significantly reduced cost at high parallelism levels. We conduct in-depth experiments on benchmark DNNs of various sizes. The results show that when compared to server-based alternatives, FSD-Inference is significantly more cost-effective and scalable, and can even achieve competitive performance against optimized HPC solutions. Experiments also confirm that our serverless solution can handle large distributed workloads and leverage high degrees of FaaS parallelism.}
}


@inproceedings{DBLP:conf/icde/Xu0X24,
	author = {Ruiqi Xu and
                  Yue Wang and
                  Xiaokui Xiao},
	title = {Graph Computation with Adaptive Granularity},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {2123--2136},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00169},
	doi = {10.1109/ICDE60146.2024.00169},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Xu0X24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Despite the development of various distributed graph systems, little attention has been paid to the granularity of computation and communication, which can significantly impact overall efficiency. Moreover, users often struggle to write and optimize new parallel algorithms to fit different programming abstractions, which can be a daunting task. To address these challenges, this paper introduces Argan, a parallel graph system that offers efficient adaptive-grained executions and a user-friendly abstraction. Argan utilizes the adaptive-Grained Asynchronous Parallel (GAP) model, which enables runtime adjustments of granularity to enhance performance. Additionally, its programming model allows users to directly derive parallel programs from existing batch sequential algorithms. Our experiments using real-life and synthetic graphs demonstrate that for a variety of graph applications, GAP effectively improves the performance of Argan, which outperforms Grap +, PowerSwitch, and Maiter.}
}


@inproceedings{DBLP:conf/icde/0003ZYL0LLLC24,
	author = {Ming Hu and
                  Peiheng Zhou and
                  Zhihao Yue and
                  Zhiwei Ling and
                  Yihao Huang and
                  Anran Li and
                  Yang Liu and
                  Xiang Lian and
                  Mingsong Chen},
	title = {FedCross: Towards Accurate Federated Learning via Multi-Model Cross-Aggregation},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {2137--2150},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00170},
	doi = {10.1109/ICDE60146.2024.00170},
	timestamp = {Mon, 09 Dec 2024 07:47:49 +0100},
	biburl = {https://dblp.org/rec/conf/icde/0003ZYL0LLLC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As a promising distributed machine learning paradigm, Federated Learning (FL) has attracted increasing attention to deal with data silo problems without compromising user privacy. By adopting the classic one-to-multi training scheme (i.e., FedAvg), where the cloud server dispatches one single global model to multiple involved clients, conventional FL methods can achieve collaborative model training without data sharing. However, since only one global model cannot always accommodate all the incompatible convergence directions of local models, existing FL approaches greatly suffer from inferior classification accuracy. To address this issue, we present an efficient FL framework named FedCross, which uses a novel multi-to-multi FL training scheme based on our proposed multi-model cross-aggregation approach. Unlike traditional FL methods, in each round of FL training, FedCross uses multiple middleware models to conduct weighted fusion individually. Since the middleware models used by FedCross can quickly converge into the same flat valley in terms of loss landscapes, the generated global model can achieve a well-generalization. Experimental results on various well-known datasets show that, compared with state-of-the-art FL methods, Fed Cross can significantly improve FL accuracy within both IID and non-IID scenarios without causing additional communication overhead.}
}


@inproceedings{DBLP:conf/icde/LinGJ24,
	author = {Yin Lin and
                  Samika Gupta and
                  H. V. Jagadish},
	title = {Mitigating Subgroup Unfairness in Machine Learning Classifiers: {A}
                  Data-Driven Approach},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {2151--2163},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00171},
	doi = {10.1109/ICDE60146.2024.00171},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LinGJ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Fairness in machine learning, particularly in classifiers, is receiving increasing attention. However, most studies on this topic focus on fairness metrics for a limited number of predefined groups and do not address fairness across intersectional subgroups. In this paper, we investigate ways to improve subgroup fairness where subgroups are defined by the intersection of protected attributes. Specifically, our paper reveals the correlation between the representation bias of training data and model fairness. We demonstrate that biased sample collection due to historical biases and a lack of control over data collection can lead to unfairness in learned models. We introduce the concept of an “Implicit Biased Set (IBS)”, which refers to regions in the intersectional attribute space where positive and negative examples are not proportionately represented. For example, if our training data set has a disproportionate representation of black male recidivists, then criminal risk assessment tools are more likely to discriminate against black males, even if they are innocent. We propose an efficient pre-processing approach that initially identifies IBS and then employs techniques to remedy the data collection within IBS. Our evaluation shows that our method effectively mitigates various subgroup biases regardless of the downstream machine learning models used.}
}


@inproceedings{DBLP:conf/icde/0003M24,
	author = {Ke Yang and
                  Alexandra Meliou},
	title = {Non-Invasive Fairness in Learning Through the Lens of Data Drift},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {2164--2178},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00172},
	doi = {10.1109/ICDE60146.2024.00172},
	timestamp = {Sun, 06 Oct 2024 21:04:56 +0200},
	biburl = {https://dblp.org/rec/conf/icde/0003M24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Machine Learning models are widely employed to drive many modern data systems. While they are undeniably powerful tools, ML models often demonstrate imbalanced performance and unfair behaviors. The root of this problem often lies in the fact that different subpopulations commonly display divergent trends: as a learning algorithm tries to identify trends in the data, it naturally favors the trends of the majority groups, leading to a model that performs poorly and unfairly for minority populations. Our goal is to improve the fairness and trustworthiness of ML models by applying only non-invasive interventions, which don't alter the data or the learning algorithm. We use a simple but key insight: the divergence of trends between different popu-lations, and, consecutively, between a learned model and minority populations, is analogous to data drift, which indicates poor conformance between parts of the data and the trained model. We explore two strategies (model-splitting and reweighing) to resolve this drift, aiming to improve the overall conformance of models to the underlying data. Both our methods introduce novel ways to employ the recently-proposed data profiling primitive of Conformance Constraints. Our splitting approach is based on a simple data drift strategy: training separate models for different populations. Our DifFair algorithm enhances this simple strategy by employing conformance constraints, learned over the data partitions, to select the appropriate model to use for predictions on each serving tuple. However, the performance of such a multi-model strategy can degrade severely under poor representation of some groups in the data. We thus propose a single-model, reweighing strategy, ConFair, to overcome this limitation. ConFair employs conformance constraints in a novel way to derive weights for training data, which are then used to build a single model. Our experimental evaluation over 7 real-world datasets shows that both DifFair and ConFair improve the fairness of ML models. We demonstrate scenarios where DifFair has an edge, though ConFair has the greatest practical impact and outperforms other baselines. Moreover, as a model-agnostic technique, ConFairstays robust when used against different models than the ones on which the weights have been learned, which is not the case for other states of the art.}
}


@inproceedings{DBLP:conf/icde/Zhang0RZ0S24,
	author = {Jun Zhang and
                  Huan Li and
                  Dazhong Rong and
                  Yan Zhao and
                  Ke Chen and
                  Lidan Shou},
	title = {Preventing the Popular Item Embedding Based Attack in Federated Recommendations},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {2179--2191},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00173},
	doi = {10.1109/ICDE60146.2024.00173},
	timestamp = {Sun, 06 Oct 2024 21:04:59 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Zhang0RZ0S24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Privacy concerns have led to the rise of federated recommender systems (FRS), which can create personalized models across distributed clients. However, FRS is vulnerable to poisoning attacks, where malicious users manipulate gradients to promote their target items intentionally. Existing attacks against FRS have limitations, as they depend on specific models and prior knowledge, restricting their real-world applicability. In our exploration of practical FRS vulnerabilities, we devise a model-agnostic and prior-knowledge-free attack, named PIECK (Popular Item Embedding based Attack). The core module of PIECK is popular item mining, which leverages embedding changes during FRS training to effectively identify the popular items. Built upon the core module, PIECK branches into two diverse solutions: The PIECKIPE solution employs an item popularity enhancement module, which aligns the embeddings of targeted items with the mined popular items to increase item exposure. The PIECKUEA further enhances the robustness of the attack by using a user embedding approximation module, which approximates private user embeddings using mined popular items. Upon identifying PIECK, we evaluate existing federated defense methods and find them ineffective against PIECK, as poisonous gradients inevitably overwhelm the cold target items. We then propose a novel defense method by introducing two regularization terms during user training, which constrain item popularity enhancement and user embedding approximation while preserving FRS performance. We evaluate PIECK and its defense across two base models, three real datasets, four top-tier attacks, and six general defense methods, affirming the efficacy of both PIECK and its defense.}
}


@inproceedings{DBLP:conf/icde/GaleM24,
	author = {Abraham Gale and
                  Am{\'{e}}lie Marian},
	title = {Explainable Disparity Compensation for Efficient Fair Ranking},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {2192--2204},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00174},
	doi = {10.1109/ICDE60146.2024.00174},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/GaleM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Ranking functions that are used in decision systems often produce disparate results for different populations because of bias in the underlying data. Addressing, and compensating for, these disparate outcomes is a critical problem for fair decision-making. Recent compensatory measures have mostly focused on opaque transformations of the ranking functions to satisfy fairness guarantees or on the use of quotas or set-asides to guarantee a minimum number of positive outcomes to members of underrepresented groups. In this paper we propose easily explainable data-driven compensatory measures for ranking functions. Our measures rely on the generation of bonus points given to members of underrepresented groups to address disparity in the ranking function. The bonus points can be set in advance, and can be combined, allowing for considering the intersections of representations and giving better transparency to stakeholders. We propose efficient sampling-based algorithms to calculate the number of bonus points to minimize disparity. We validate our algorithms using real-world school admissions and recidivism datasets, and compare our results with that of existing fair ranking algorithms.}
}


@inproceedings{DBLP:conf/icde/TianS024,
	author = {Xiaobin Tian and
                  Zequn Sun and
                  Wei Hu},
	title = {Generating Explanations to Understand and Repair Embedding-Based Entity
                  Alignment},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {2205--2217},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00175},
	doi = {10.1109/ICDE60146.2024.00175},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/TianS024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Entity alignment (EA) seeks identical entities in different knowledge graphs, which is a long-standing task in the database research. Recent work leverages deep learning to embed entities in vector space and align them via nearest neighbor search. Although embedding-based EA has gained marked success in recent years, it lacks explanations for alignment decisions. In this paper, we present the first framework that can generate explanations for understanding and repairing embedding-based EA results. Given an EA pair produced by an embedding model, we first compare its neighbor entities and relations to build a matching subgraph as a local explanation. We then construct an alignment dependency graph to understand the pair from an abstract perspective. Finally, we repair the pair by resolving three types of alignment conflicts based on dependency graphs. Experiments on a variety of EA datasets demonstrate the effectiveness, generalization, and robustness of our framework in explaining and repairing embedding-based EA results.}
}


@inproceedings{DBLP:conf/icde/LiuW0D0W024,
	author = {Wei Liu and
                  Haozhao Wang and
                  Jun Wang and
                  Zhiying Deng and
                  Yuankai Zhang and
                  Cheng Wang and
                  Ruixuan Li},
	title = {Enhancing the Rationale-Input Alignment for Self-explaining Rationalization},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {2218--2230},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00176},
	doi = {10.1109/ICDE60146.2024.00176},
	timestamp = {Tue, 30 Jul 2024 08:18:21 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LiuW0D0W024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Rationalization empowers deep learning models with self-explaining capabilities through a cooperative game, where a generator selects a semantically consistent subset of the input as a rationale, and a subsequent predictor makes predictions based on the selected rationale. In this paper, we discover that rationalization is prone to a problem named rationale shift, which arises from the algorithmic bias of the cooperative game. Rationale shift refers to a situation where the semantics of the selected rationale may deviate from the original input, but the predictor still produces accurate predictions based on the deviation, resulting in a compromised generator with misleading feedback. To address this issue, we first demonstrate the importance of the alignment between the rationale and the full input through both empirical observations and theoretical analysis. Subsequently, we introduce a novel approach called DAR (Discriminatively Aligned Rationalization), which utilizes an auxiliary module pretrained on the full input to discriminatively align the selected rationale and the original input. We theoretically illustrate how DAR accomplishes the desired alignment, thereby overcoming the rationale shift problem. The experiments on two widely used real-world benchmarks show that the proposed method significantly improves the explanation quality (measured by the overlap between the model-selected explanation and the human-annotated rationale) as compared to state-of-the-art techniques. Additionally, results on two synthetic settings further validate the effectiveness of DAR in addressing the rationale shift problem.}
}


@inproceedings{DBLP:conf/icde/ChenCYJ00ZHGF024,
	author = {Qian Chen and
                  Yiqiang Chen and
                  Bingjie Yan and
                  Xinlong Jiang and
                  Xiaojin Zhang and
                  Yan Kang and
                  Teng Zhang and
                  Wuliang Huang and
                  Chenlong Gao and
                  Lixin Fan and
                  Qiang Yang},
	title = {Model Trip: Enhancing Privacy and Fairness in Model Fusion Across
                  Multi-Federations for Trustworthy Global Healthcare},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {2231--2244},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00177},
	doi = {10.1109/ICDE60146.2024.00177},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ChenCYJ00ZHGF024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated Learning has emerged as a revolutionary innovation in the evolving landscape of global healthcare, fostering collaboration among institutions and facilitating collaborative data analysis. As practical applications continue to proliferate, numerous federations have formed in different regions. The optimization and sustainable development of federation-pretrained models have emerged as new challenges. These challenges primarily encompass privacy, population shift and data dependency, which may lead to severe consequences such as the leakage of sensitive information within models and training samples, unfair model performance and resource burdens. To tackle these issues, we propose FairFusion, a cross-federation model fusion approach that enhances privacy and fairness. FairFusion operates across federations within a Model Trip paradigm, integrating knowledge from diverse federations to continually enhance model performance. Through federated model fusion, multi-objective quantification and optimization, FairFusion obtains trustworthy solutions that excel in utility, privacy and fairness. We conduct comprehensive experiments on three public real-world healthcare datasets. The results demonstrate that FairFusion achieves outstanding model fusion performance in terms of utility and fairness across various model structures and subgroups with sensitive attributes while guaranteeing model privacy.}
}


@inproceedings{DBLP:conf/icde/AttolouTSK24,
	author = {Herv{\'{e}}{-}Madelein Attolou and
                  Katerina Tzompanaki and
                  Kostas Stefanidis and
                  Dimitris Kotzinos},
	title = {Why-Not Explainable Graph Recommender},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {2245--2257},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00178},
	doi = {10.1109/ICDE60146.2024.00178},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/AttolouTSK24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Explainable Recommendation Systems (RS) enhance the user experience on online platforms by recommending personalized content, as well as explanations for the given recommendations to add transparency and build up trust in the platforms. Extending the notion of explainable RS, in this paper we define Why-Not explanations for recommendations that were expected but not returned, and propose and implement a technique for computing Why-Not explanations in a post-hoc manner for a graph-based RS. Our approach builds on the notion of counterfactual explanations in the means of a set of user-rooted edges to add or remove in the graph, in order to place the missing recommendation to the top of the recommendation list, and provides in this way actionable insights on the source data and their interrelations. Our experimental evaluation on a real-world data set demonstrates the feasibility of our proposal and reveals interesting directions for future work.}
}


@inproceedings{DBLP:conf/icde/SaqibFCW24,
	author = {Mohd Saqib and
                  Benjamin C. M. Fung and
                  Philippe Charland and
                  Andrew Walenstein},
	title = {{GAGE:} Genetic Algorithm-Based Graph Explainer for Malware Analysis},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {2258--2270},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00179},
	doi = {10.1109/ICDE60146.2024.00179},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/SaqibFCW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Malware analysts often prefer reverse engineering using Call Graphs, Control Flow Graphs (CFGs), and Data Flow Graphs (DFGs), which involves the utilization of black-box Deep Learning (DL) models. The proposed research introduces a structured pipeline for reverse engineering-based analysis, offering promising results compared to state-of-the-art methods and providing high-level interpretability for malicious code blocks in subgraphs. We propose the Canonical Executable Graph (CEG) as a new representation of Portable Executable (PE) files, uniquely incorporating syntactical and semantic information into its node embeddings. At the same time, edge features capture structural aspects of PE files. This is the first work to present a PE file representation encompassing syntactical, semantic, and structural characteristics, whereas previous efforts typically focused solely on syntactic or structural properties. Furthermore, recognizing the limitations of existing graph explanation methods within Explainable Artificial Intelligence (XAI) for malware analysis, primarily due to the specificity of malicious files, we introduce Genetic Algorithm-based Graph Explainer (GAGE). GAGE operates on the CEG, striving to identify a precise subgraph relevant to predicted malware families. Through experiments and comparisons, our proposed pipeline exhibits substantial improvements in model robustness scores and discriminative power compared to the previous benchmarks. Furthermore, we have successfully used GAGE in practical applications on real-world data, producing meaningful insights and interpretability. This research offers a robust solution to enhance cybersecurity by delivering a transparent and accurate understanding of malware behaviour. Moreover, the proposed algorithm is specialized in handling graph-based data, effectively dissecting complex content and isolating influential nodes.}
}


@inproceedings{DBLP:conf/icde/XieCJXPC24,
	author = {Ruitao Xie and
                  Jingbang Chen and
                  Limai Jiang and
                  Rui Xiao and
                  Yi Pan and
                  Yunpeng Cai},
	title = {Accurate Explanation Model for Image Classifiers using Class Association
                  Embedding},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {2271--2284},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00180},
	doi = {10.1109/ICDE60146.2024.00180},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/XieCJXPC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Image classification is a primary task in data analy-sis where explainable models are crucially demanded in various applications. Although amounts of methods have been proposed to obtain explainable knowledge from the black-box classifiers, these approaches lack the efficiency of extracting global knowl-edge regarding the classification task, thus is vulnerable to local traps and often leads to poor accuracy. In this study, we propose a generative explanation model that combines the advantages of global and local knowledge for explaining image classifiers. We develop a representation learning method called class association embedding (CAE), which encodes each sample into a pair of separated class-associated and individual codes. Recombining the individual code of a given sample with altered class-associated code leads to a synthetic real-looking sample with preserved individual characters but modified class-associated features and possibly flipped class assignments. A building-block coherency feature extraction algorithm is proposed that efficiently separates class-associated features from individual ones. The extracted feature space forms a low-dimensional manifold that visualizes the classification decision patterns. Explanation on each individual sample can be then achieved in a counter-factual generation manner which continuously modifies the sample in one direction, by shifting its class-associated code along a guided path, until its classification outcome is changed. We compare our method with state-of-the-art ones on explaining image classification tasks in the form of saliency maps, demonstrating that our method achieves higher accuracies. The class-associated manifold not only helps with skipping local traps and achieving accurate explanation, but also provides insights to the data distribution patterns that potentially aids knowledge discovery. The code is available at https://github.com/xrtll/xAI-CODE.}
}


@inproceedings{DBLP:conf/icde/Zheng0TXZH24,
	author = {Lecheng Zheng and
                  Dawei Zhou and
                  Hanghang Tong and
                  Jiejun Xu and
                  Yada Zhu and
                  Jingrui He},
	title = {Fairgen: Towards Fair Graph Generation},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {2285--2297},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00181},
	doi = {10.1109/ICDE60146.2024.00181},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Zheng0TXZH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {There have been tremendous efforts over the past decades dedicated to the generation of realistic graphs in a variety of domains, ranging from social networks to computer networks, from gene regulatory networks to online transaction networks. Despite the remarkable success, the vast majority of these works are unsupervised in nature and are typically trained to minimize the expected graph reconstruction loss, which would result in the representation disparity issue in the generated graphs, i.e., the protected groups (often minorities) contribute less to the objective and thus suffer from systematically higher errors. In this paper, we aim to tailor graph generation to downstream mining tasks by leveraging label information and user-preferred parity constraints. In particular, we start from the investigation of representation disparity in the context of graph generative models. To mitigate the disparity, we propose a fairness-aware graph generative model named Fairgen. Our model jointly trains a label-informed graph generation module and a fair representation learning module by progressively learning the behaviors of the protected and unprotected groups, from the ‘easy’ concepts to the ‘hard’ ones. In addition, we propose a generic context sampling strategy for graph generative models, which is proven to be capable of fairly capturing the contextual information of each group with a high probability. Experimental results on seven real-world data sets demonstrate that Fairgen (1) obtains performance on par with state-of-the-art graph generative models across nine network properties, (2) mitigates the representation disparity issues in the generated graphs, and (3) substantially boosts the model performance by up to 17% in downstream tasks via data augmentation.}
}


@inproceedings{DBLP:conf/icde/WangLLLGW24,
	author = {Yong Wang and
                  Kaiyu Li and
                  Yuyu Luo and
                  Guoliang Li and
                  Yunyan Guo and
                  Zhuo Wang},
	title = {Fast, Robust and Interpretable Participant Contribution Estimation
                  for Federated Learning},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {2298--2311},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00182},
	doi = {10.1109/ICDE60146.2024.00182},
	timestamp = {Wed, 07 Aug 2024 07:59:36 +0200},
	biburl = {https://dblp.org/rec/conf/icde/WangLLLGW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we introduce CTFL, a fair, robust, and interpretable framework designed to estimate clients' contributions to federated learning, aiming to incentivize high-quality data providers to participate in the federation. Firstly, CTFL can precisely allocate contribution credits in a single pass of model training and inference, ensuring computational efficiency. This is accomplished by tracking the test performance gain brought by each participant through exploiting classification rules. Secondly, CTFL adheres to essential theoretical properties of an ideal contribution estimation algorithm, including symmetry, zero-element, and additivity, ensuring fair and rational estimations. Thirdly, CTFL demonstrates resilience against strategic and malicious behaviors due to carefully crafted micro and macro contribution estimation schemes. Fourthly, CTFL offers insights into participants' roles within the federation by interpreting their contribution scores through respective high-frequently activated rules. Finally, CTFL integrates logical neural networks and model binarization techniques to ensure effectiveness and efficiency while preserving data privacy. Extensive experiments validate that CTFL accurately estimates contributions, significantly reducing computation time by 2–3 orders of magnitude compared to state-of-the-art methods while maintaining robustness.}
}


@inproceedings{DBLP:conf/icde/ZongD00ZQ024,
	author = {Chuanyu Zong and
                  Zefang Dong and
                  Xiaochun Yang and
                  Bin Wang and
                  Huaijie Zhu and
                  Tao Qiu and
                  Rui Zhu},
	title = {Exploring Optimal Parameters for Expected Results on Radius-Bounded
                  k-Core Queries},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {2312--2324},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00183},
	doi = {10.1109/ICDE60146.2024.00183},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZongD00ZQ024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Radius-bounded $k$ -core queries (RB- $k$ -core queries) in geo-social networks aim to find all $k$ -cores containing a given query vertex $q$ while all vertices in each $k$ -core fall into a circle under a given query radius $r$ , which is widely used in many applications, such as team formulation and event organization. However, the query parameters $k$ and $r$ are hard to specify by the users without any background knowledge, which means the query results often do not meet the users' requirements, i.e., some expected vertices are missed in the query results. To tackle this issue, we investigate the problem of exploring optimal refined parameters (EOP) for expected results on RB\xad $k$ -core queries, which aims to explore the optimal parameters that make the expected vertex $\\omega$ and query vertex $q$ appear in the same RB- $k$ -core. To address the EOP problem, we first propose two baseline algorithms, namely PriorityR and HybridR, which refine the parameters $k$ and $r$ simultaneously based on the effective bounds of the refined $r^{\\prime}$ • To enhance the efficiency of exploring optimal parameters, we develop two efficient al-gorithms. The first algorithm, Priority K, simultaneously refines both parameters based on the effective bound of the refined $k$ • The second algorithm, HybridK, explores the optimal parameters using the continuous convergence bounds of the refined $k^{\\prime}$ and $r$ • Furthermore, to enhance exploration efficiency, we develop a novel index, called HCR-Tree, based on the hierarchical coreness of vertices and R- Tree. This index accelerates the verification of whether the coreness of a vertex in any sub graph exceeds $k$ in the above algorithms. Finally, we conduct extensive experiments using five real geo-social network datasets, which show that the optimal parameters can be explored effectively by the algorithms, and HybridK is the most effective. Meanwhile, the HCR- Tree performs better than the R- Tree for the EOP problem.}
}


@inproceedings{DBLP:conf/icde/Benassi0PT24,
	author = {Riccardo Benassi and
                  Francesco Guerra and
                  Matteo Paganelli and
                  Donato Tiano},
	title = {Explaining Entity Matching with Clusters of Words},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {2325--2337},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00184},
	doi = {10.1109/ICDE60146.2024.00184},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Benassi0PT24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Deep learning models achieve state-of-the-art per-formance in solving the task of Entity Matching, which aims to identify records that refer to the same real-world entity. However, they act as black-box models for the user, who has limited insights into the rationales behind their decisions. Several explainers (e.g., LIME, Mojito, Landmark, LEMON, and CERTA) have been proposed in the literature to address this issue. Their main focus is to generate explanations that are faithful to the model without considering their comprehensibility to the user. For example, verbose explanations could be very complex to analyze, hindering the model's understanding. In this paper, we propose CREW, an explanation system for Entity Matching models that combines the comprehensibility of the explanations and fidelity to the model. To achieve this, CREW creates explanations as clusters of words. The clusters are created by exploiting three different forms of knowledge: the semantic similarity of the words, their arrangement into the dataset attributes, and their importance in explaining the model. Experiments show that CREW generates explanations that are more interpretable for the user and more faithful to the model than those generated by competing explanation techniques.}
}


@inproceedings{DBLP:conf/icde/LiuWZX024,
	author = {Hao Liu and
                  Raymond Chi{-}Wing Wong and
                  Zheng Zhang and
                  Min Xie and
                  Bo Tang},
	title = {Fair Top-k Query on Alpha-Fairness},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {2338--2350},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00185},
	doi = {10.1109/ICDE60146.2024.00185},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LiuWZX024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The traditional top-k query was proposed to obtain a small subset from the database according to the user preference, which is explicitly expressed as a ranking scheme (i.e., utility function). However, a poorly-designed utility function may create discrimination, which in turn may cause harm to minority groups, e.g., women and ethnic minorities, and thus, fairness is becoming increasingly important in many situations, e.g., hiring and admission decisions. Motivated by this, we study fair ranking to alleviate discrimination. We design a fairness model, called α-fairness, to quantify the fairness of utility functions. We propose an efficient exact framework with a basic implementation and an improved implementation to find the fairest utility function with the minimum modification penalty. We conducted extensive experiments on both real and synthetic datasets to demonstrate our effectiveness and efficiency compared with the prior studies.}
}


@inproceedings{DBLP:conf/icde/HeW0LNZ24,
	author = {Yizhang He and
                  Kai Wang and
                  Wenjie Zhang and
                  Xuemin Lin and
                  Wei Ni and
                  Ying Zhang},
	title = {Butterfly Counting over Bipartite Graphs with Local Differential Privacy},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {2351--2364},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00186},
	doi = {10.1109/ICDE60146.2024.00186},
	timestamp = {Fri, 18 Oct 2024 08:29:21 +0200},
	biburl = {https://dblp.org/rec/conf/icde/HeW0LNZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Butterfly counting on bipartite graphs has gained increasing attention in past decades. Inevitably, butterfly counts can reveal the presence of certain edges, posing a privacy risk in real applications. Edge local differential privacy (edge LDP), which requires each vertex to perturb its neighbors locally, has been applied to protect edge privacy in graphs. This paper, for the first time, investigates butterfly counting on bipartite graphs with edge LDP. Although a straightforward approach that allows each vertex to perturb its incident edges locally to construct a noisy graph and perform butterfly counting preserves edge LDP, it often results in severe over-counting and significant bias since the resulting noisy graph is generally much denser than the input graph. To obtain unbiased butterfly counts, we propose a multiple-round interaction algorithm to allow the vertices to download the noisy graph and compute local motif counts. Moreover, to avoid adding substantial noise to satisfy edge LDP, we further propose the Download-free Butterfly. Estimation (DBE) algorithm, which captures motif transformation probabilities and relies on motif counts from the noisy graph to yield unbiased butterfly estimates. DBE significantly enhances accuracy via reduced communication between vertices and the data curator. Extensive experiments on 14 datasets validate the effectiveness and efficiency of our proposed techniques.}
}


@inproceedings{DBLP:conf/icde/ZhengWWLFY24,
	author = {Shuwen Zheng and
                  Chaokun Wang and
                  Cheng Wu and
                  Yunkai Lou and
                  Hao Feng and
                  Xuran Yang},
	title = {Temporal Graph Generation Featuring Time-Bound Communities},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {2365--2378},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00187},
	doi = {10.1109/ICDE60146.2024.00187},
	timestamp = {Tue, 30 Jul 2024 08:18:20 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhengWWLFY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Synthetic graph datasets are crucial for the assessment of network analysis algorithms, providing a measure of their effectiveness and efficiency. However, most existing generation techniques typically focus on community formation, neglecting the fact that real-world communities not only emerge but may also dissipate over time. This lifecycle occurs within a finite timeframe, adding complexity to the community dynamics. In this paper, firstly we introduce the concept of time-bound community to characterize communities that are destined to disintegrate. Secondly, we devise GTB, a temporal graph Generation method featuring Time-Bound communities, leveraging newly identified patterns within real datasets that we have collected. Additionally, we propose the advanced Temporal Edge Distribution (TED) model, a key component of G TB, designed for the swift generation of temporal edges within distribution limits and offering a constant time complexity to generate each edge. The TED model not only accommodates diverse distribution configurations but also facilitates its seamless transfer between time-bound communities to enhance time and space efficiency. Finally, extensive experimental results demonstrate that our method outperforms baseline methods by delivering generated content of superior Quality with notably competitive time and space consumption.}
}


@inproceedings{DBLP:conf/icde/SunLWSLW24,
	author = {Henan Sun and
                  Xunkai Li and
                  Zhengyu Wu and
                  Daohan Su and
                  Rong{-}Hua Li and
                  Guoren Wang},
	title = {Breaking the Entanglement of Homophily and Heterophily in Semi-supervised
                  Node Classification},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {2379--2392},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00188},
	doi = {10.1109/ICDE60146.2024.00188},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/SunLWSLW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recently, graph neural networks (GNNs) have shown prominent performance in semi-supervised node classification by leveraging knowledge from the graph database. However, most existing GNNs follow the homophily assumption, where connected nodes are more likely to exhibit similar feature distributions and the same labels, and such an assumption has proven to be vulnerable in a growing number of practical applications. As a supplement, heterophily reflects dissimilarity in connected nodes, which has gained significant attention in graph learning. To this end, data engineers aim to develop a powerful GNN model that can ensure performance under both homophily and heterophily. Despite numerous attempts, most existing GNNs struggle to achieve optimal node representations due to the constraints of undirected graphs. The neglect of directed edges results in sub-optimal graph representations, thereby hindering the capacity of GNNs. To address this issue, we introduce AMUD, which quantifies the relationship between node profiles and topology from a statistical perspective, offering valuable insights for Adaptively Modeling the natural directed graphs as the Undirected or Directed graph to maximize the benefits from subsequent graph learning. Furthermore, we propose Adaptive Directed Pattern Aggregation (ADPA) as a new directed graph learning paradigm for AMUD. Empirical studies have demonstrated that AMUD guides efficient graph learning. Meanwhile, extensive experiments on 16 benchmark datasets substantiate the impressive performance of ADPA, outperforming baselines by significant margins of 3.96%.}
}


@inproceedings{DBLP:conf/icde/Guo0F24,
	author = {Yucan Guo and
                  Chenhao Ma and
                  Yixiang Fang},
	title = {Efficient Core Decomposition Over Large Heterogeneous Information
                  Networks},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {2393--2406},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00189},
	doi = {10.1109/ICDE60146.2024.00189},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Guo0F24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Core decomposition is a critical metric for evaluating the vertex importance and analyzing graph structure. Given a graph\nG\n, a k-core is the largest subgraph of\nG\nwhere each vertex has at least\nk\nneighbors. Most existing works mainly focus on homogeneous graphs in which edges are of the same type and cannot be applied to heterogeneous information networks (HINs) directly. However, most real-world networks are HINs which consist of different vertex types and edge types. To reveal the cohesive subgraphs with hierarchical relations on HINs, we adopt the well-known\n(k,P)\n-core model to compute coreness over HINs, where\nP\nis a meta-path, i.e., a sequence of relations defined between different types of vertices. Hence, the\n(k,P)\n-core is a subgraph where each vertex is connected to at least\nk\nother vertices via instances of\nP\n. Based on two kinds of sparse matrix products, we propose two kinds of algebraic core decomposition algorithms, which are suitable for general HINs and locally dense HINs, respectively. We have performed extensive empirical evaluations of our algorithms on six large real-world HINs. The results show that the proposed solutions are highly efficient for core decomposition and achieve up to\n258.84×\nspeedup than the state-of-the-art parallel algorithm on 20 cores. Moreover, other HIN tasks that involve homogeneous graph construction can also benefit from our algorithms.}
}


@inproceedings{DBLP:conf/icde/ChenY24,
	author = {YuAng Chen and
                  Jeffrey Xu Yu},
	title = {Accelerating SpMV for Scale-Free Graphs with Optimized Bins},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {2407--2420},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00190},
	doi = {10.1109/ICDE60146.2024.00190},
	timestamp = {Thu, 15 Aug 2024 14:08:00 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ChenY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Sparse matrix-vector multiplication (\nSpMV\n) is a fundamental operation in numerous scientific applications, particularly in the context of graph analytics. As graph-based computations become increasingly complex, there is a growing demand for the development of more efficient Sp MV. In this paper, we present a novel approach called Binn to enhance SpMV performance for scale-free graphs on modern multicore processors. Binn incorporates three key optimizations to accelerate SpMV. Firstly, it employs an adaptive cache blocking strategy, which partitions the adjacency matrix of a graph into 2D blocks of varying sizes. This promotes balanced workloads and cache efficiency. Secondly, Binn reorders the nonzero elements of the adjacency matrix, enabling regularized access patterns within each block. Lastly, Binn identifies and eliminates redundant message passing during the execution of SpMV, resulting in reduced memory costs. Through these optimizations, Binn aims to accelerate\nSpMV\nby facilitating efficient data movement across the memory-cache hierarchy and achieving workload balance among threads. Experimental evaluation on diverse graph datasets demonstrates the effectiveness of Binn, outperforming state-of-the-art Sp MV implementations and graph systems such as Intel's MKL by\n3.78×\nand Galios by\n1.47×\n.}
}


@inproceedings{DBLP:conf/icde/HuangLHSWC24,
	author = {Xing Huang and
                  Dandan Lin and
                  Weiyi Huang and
                  Shijie Sun and
                  Jie Wen and
                  Chuan Chen},
	title = {PlatoD2GL: An Efficient Dynamic Deep Graph Learning System for Graph
                  Neural Network Training on Billion-Scale Graphs},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {2421--2434},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00191},
	doi = {10.1109/ICDE60146.2024.00191},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/HuangLHSWC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recently, huge interests in both academic and in-dustry have been posed to Graph Neural Network due to its power on revealing the topological information inside the data. To support the real-world applications, most of (if not all) which contain large-scale graphs with billions of edges, a number of graph-based deep learning systems have been proposed and implemented. However, all of them fail to efficiently process the dynamic graphs in terms of both memory and time cost. The state-of-the-art suffers from two issues: (1) expensive memory consumption due to the huge indexing overhead of numerous key-value pairs in traditional key-value topology storage and (2) inefficient dynamic updating due to the heavy updates on indexing structures for weighted neighbor sampling. In this paper, we proposed a Dynamic Graph-based Learning System PiatoD2GL to address above two issues. Specifically, we design a novel and effective non-key-value data structure, termed samtree, for dynamic topology storage, which largely reduces the memory cost. In addition, we propose an efficient sampling indexing structure FSTable by utilizing Fenwick tree, guaranteeing the efficiency of both dynamic updates and weighted sampling. Comprehensive experiments have demonstrated that, for dynamic updating the graph topology, the efficiency of our system by up to 79.8% and by up to 6.3 times in terms of memory and time cost, respectively. Now, our system serves the major traffic in WeChat Platform for training various GNN models.}
}


@inproceedings{DBLP:conf/icde/LiCZ24,
	author = {Xiaofan Li and
                  Gao Cong and
                  Rui Zhou},
	title = {Quantum Algorithms for the Maximum K-Plex Problem},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {2435--2448},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00192},
	doi = {10.1109/ICDE60146.2024.00192},
	timestamp = {Thu, 01 Aug 2024 07:45:44 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LiCZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The k-plex model, which allows each vertex to miss connections with up to\nk\nneighbors, serves as a relaxation of the clique model. Its adaptability makes it more suitable for analyzing graphs from real-world applications, where noise and imperfect data are common and the stringent clique model is often impractical. The challenge of identifying maximum k-plex (MKP, an NP-hard problem) is gaining attention in fields such as social network analysis, community detection, terrorist network identification, and graph clustering. Recent research efforts have focused on optimizing the time complexity of MKP algorithms. The state-of-the-art has reduced the complexity from a trivial\nO\n∗\n(\n2\nn\n)\nto\nO\n∗\n(\nc\nn\nk\n)\n, with\nc\nk\n>1.94\nfor\nk\n> 3, where\nn\ndenotes the number of vertices. In this paper, we demonstrate that MKP can be solved in\nO\n∗\n(\n1.42\nn\n)\nand propose the first two quantum algorithms, qTKP and qMKP, to achieve this complexity. qTKP employs quantum search integrated with graph encoding, degree count, degree comparison, and size determination to find a k-plex of a given size; qMKP uses a binary search to progressively identify the maximum solution. To validate the practical performance and effectiveness of our algorithms, proof-of-principle experiments were conducted using the latest IBM quantum simulator currently available. This work holds potential to be applied to a wide range of clique relaxations, e.g., n-clan and n-club.}
}


@inproceedings{DBLP:conf/icde/ZhouGYCYLZ0Y24,
	author = {Yijie Zhou and
                  Shufeng Gong and
                  Feng Yao and
                  Hanzhang Chen and
                  Song Yu and
                  Pengxi Liu and
                  Yanfeng Zhang and
                  Ge Yu and
                  Jeffrey Xu Yu},
	title = {Fast Iterative Graph Computing with Updated Neighbor States},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {2449--2462},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00193},
	doi = {10.1109/ICDE60146.2024.00193},
	timestamp = {Thu, 24 Oct 2024 11:33:42 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhouGYCYLZ0Y24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Enhancing the efficiency of iterative computation on graphs has garnered considerable attention in both industry and academia. Nonetheless, the majority of efforts focus on expediting iterative computation by minimizing the running time per iteration step, ignoring the optimization of the number of iteration rounds, which is a crucial aspect of iterative compu-tation. We experimentally verified the correlation between the vertex processing order and the number of iterative rounds, thus making it possible to reduce the number of execution rounds for iterative computation. In this paper, we propose a graph reordering method, GoGraph, which can construct a well-formed vertex processing order effectively reducing the number of iteration rounds and, consequently, accelerating iterative computation. Before delving into GoGraph, a metric function is introduced to quantify the efficiency of vertex processing order in accelerating iterative computation. This metric reflects the quality of the processing order by counting the number of edges whose source precedes the destination. GoGraph employs a divide-and-conquer mindset to establish the vertex processing order by maximizing the value of the metric function. Our experimental results show that GoGraph outperforms current state-of-the-art reordering algorithms by 1.83 x on average (up to 3.34 x) in runtime. Compared with traditional synchronous computation, our method improves the iterative computations up to 6.30 x in runtime.}
}


@inproceedings{DBLP:conf/icde/YangLWWQ24,
	author = {Mingyu Yang and
                  Wentao Li and
                  Wei Wang and
                  Dong Wen and
                  Lu Qin},
	title = {Querying Numeric-Constrained Shortest Distances on Road Networks},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {2463--2475},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00194},
	doi = {10.1109/ICDE60146.2024.00194},
	timestamp = {Mon, 05 Aug 2024 15:14:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/YangLWWQ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In real-world road networks, edges possess additional numeric attributes, such as width and toll, in addition to length. Incorporating these additional attributes enhances the functionality of shortest-distance services. To this end, current research on shortest-distance computation requires that the numeric attributes of edges on a path exceed a lower bound\nl\n(within the interval [l,oo]). However, it often overlooks the benefits of setting an upper bound\nr\n(within the interval [l, r]). To bridge this gap, we introduce the numeric-constrained shortest-distance query problem, which enforces interval constraints [l, r] on the numeric attributes of edges on a path. There are two intuitive solutions: the Online-Search method, which excludes edges that violate the constraints during the search, leading to inefficient query responses, and the Full-Index method, which creates an index for each necessary interval constraint [l, r], resulting in excessive space consumption due to numerous potential intervals. Our novel index-based method, which uses the tree decomposition technique and exploits interval-distance relationships, aims to mitigate these issues. As confirmed by our experimental results, our method greatly improves query speed - over 20 times faster than Online-Search- and consumes less space than Full-Index.}
}


@inproceedings{DBLP:conf/icde/ZengQLWW024,
	author = {Yue Zeng and
                  Hongchao Qin and
                  Rong{-}Hua Li and
                  Kai Wang and
                  Guoren Wang and
                  Xuemin Lin},
	title = {Mining Quasi-Periodic Communities in Temporal Network},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {2476--2488},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00195},
	doi = {10.1109/ICDE60146.2024.00195},
	timestamp = {Mon, 26 Aug 2024 18:09:59 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZengQLWW024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Periodic group behaviors often exist in temporal interaction networks, such as monthly group meetings, quarterly animal migrations, and yearly birthday parties. In real life, these events are usually quasi-periodic, meaning that the time intervals between two adjacent events are nearly constant but not exactly constant. Most existing studies mainly focus on identifying exact periodic group behaviors, which may result in an incomplete detection of periodic patterns in temporal networks. To fill this gap, we focus on a quasi-periodic community mining problem, which aims to find the most representative cohesive sub graphs, including the quasi-periodic\nk\n-core and quasi-periodic k-clique. The number of quasi-periodic communities is much larger than that of periodic communities, since the number of quasi-periodic sub-sequences is larger than that of periodic sub-sequences in a given time sequence. To efficiently compute the quasi-periodic communities, we propose a novel two-stage framework. In the first stage, the framework checks whether the time sequence of each vertex contains quasi-periodic sub-sequences. To this end, we develop a new structure, the DAG oracle, which comprises a set of concise DAGs that enables rapid extraction of all quasi-periodic sub-sequences. Based on the DAG oracle, we can easily compute all quasi-periodic sub-sequences for every vertex. In the second stage, the framework computes local quasi-periodic subgraphs that contain the vertex, which allows for the application of existing community mining algorithms. Given the large number of these subgraphs, we propose several carefully -designed pruning rules to further reduce redundant computations. Extensive experiments on 5 real-life datasets demonstrate the efficiency and effectiveness of our proposed solutions.}
}


@inproceedings{DBLP:conf/icde/000200BP0L0P24,
	author = {Tianhao Peng and
                  Wenjun Wu and
                  Haitao Yuan and
                  Zhifeng Bao and
                  Zhao Pengrui and
                  Xin Yu and
                  Xuetao Lin and
                  Yu Liang and
                  Yanjun Pu},
	title = {GraphRARE: Reinforcement Learning Enhanced Graph Neural Network with
                  Relative Entropy},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {2489--2502},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00196},
	doi = {10.1109/ICDE60146.2024.00196},
	timestamp = {Sun, 06 Oct 2024 21:04:56 +0200},
	biburl = {https://dblp.org/rec/conf/icde/000200BP0L0P24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graph neural networks (GNNs) have shown ad-vantages in graph-based analysis tasks. However, most existing methods have the homogeneity assumption and show poor performance on heterophilic graphs, where the linked nodes have dissimilar features and different class labels, and the semantically related nodes might be multi-hop away. To address this limitation, this paper presents GraphRARE, a general framework built upon node relative entropy and deep reinforcement learning, to strengthen the expressive capability of GNNs. An innovative node relative entropy, which considers node features and structural similarity, is used to measure mutual information between node pairs. In addition, to avoid the sub-optimal solutions caused by mixing useful information and noises of remote nodes, a deep reinforcement learning-based algorithm is developed to optimize the graph topology. This algorithm selects informative nodes and discards noisy nodes based on the defined node relative en-tropy. Extensive experiments are conducted on seven real-world datasets. The experimental results demonstrate the superiority of GraphRARE in node classification and its capability to optimize the original graph topology.}
}


@inproceedings{DBLP:conf/icde/LiW0ZHY24,
	author = {Shunyang Li and
                  Kai Wang and
                  Xuemin Lin and
                  Wenjie Zhang and
                  Yizhang He and
                  Long Yuan},
	title = {Querying Historical Cohesive Subgraphs Over Temporal Bipartite Graphs},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {2503--2516},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00197},
	doi = {10.1109/ICDE60146.2024.00197},
	timestamp = {Wed, 14 Aug 2024 10:20:09 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LiW0ZHY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In many real-world scenarios, relationships between two different entities can be naturally represented as bipartite graphs, such as author-paper, user-item, and people-location. Cohesive subgraph search, which aims to find densely connected subgraphs, is a popular research topic on bipartite graphs. While various cohesive subgraph models are proposed on bipartite graphs, none of them consider the temporal dimension, which expresses dynamic changes occurring in cohesive subgraphs over time. In this paper, we propose the first cohesive subgraph model $(\\alpha,\\ \\beta,\\ \\mathcal{T})$ -core on temporal bipartite graphs. Given degree constraints $\\alpha$ and $\\beta$ , as well as a time window $\\mathcal{T}=[t_{s},t_{e}],(\\alpha,\\beta,\\ \\mathcal{T})$ -core guarantees that each vertex in the upper or lower layer has at least $\\alpha$ or $\\beta$ neighbors, respectively, within the snapshot over the time window $\\mathcal{T}$ . An intuitive solution to compute the $(\\alpha,\\ \\beta,\\ \\mathcal{T})$ -core is to iteratively remove the vertices that do not satisfy the degree constraints in the snapshot, which suffers from inefficiency and is impractical on large temporal bipartite graphs. Therefore, we turn to index-based methods to enhance query performance. To support efficient arbitrary $(\\alpha,\\ \\beta,\\ \\mathcal{T})$ -core queries, we propose a vertex-partitioning historical index called VH-Index and a time-partitioning historical index called TH-Index. Note that these two indexes need to store $(\\alpha,\\ \\beta,\\ \\mathcal{T})$ -core for each possible combination of $\\alpha, \\beta$ , and $a\\mathcal{T}$ and incur large construction costs. Therefore, we further propose a temporal intersection index called TH*-Index to strike a balance between the efficiency of query processing and the space cost of the index. We develop both sequential and parallel algorithms for efficiently constructing the temporal-intersection index. Extensive experiments are conducted on 10 real-world temporal bipartite graphs to validate the effectiveness of the $(\\alpha,\\ \\beta,\\ \\mathcal{T})$ -core model and the efficiency of our proposed algorithms.}
}


@inproceedings{DBLP:conf/icde/LiWZSLW24,
	author = {Xunkai Li and
                  Zhengyu Wu and
                  Wentao Zhang and
                  Henan Sun and
                  Rong{-}Hua Li and
                  Guoren Wang},
	title = {AdaFGL: {A} New Paradigm for Federated Node Classification with Topology
                  Heterogeneity},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {2517--2530},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00198},
	doi = {10.1109/ICDE60146.2024.00198},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LiWZSLW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recently, Federated Graph Learning (FGL) has attracted significant attention as a distributed framework based on graph neural networks, primarily due to its capability to break data silos. Existing FGL studies employ community split on the homophilous global graph by default to simulate federated semisupervised node classification settings. Such a strategy assumes the consistency of topology between the multi-client subgraphs and the global graph, where connected nodes are highly likely to possess similar feature distributions and the same label. However, in real-world implementations, the varying perspectives of local data engineering result in various subgraph topologies, posing unique heterogeneity challenges in FGL. Unlike the well-known label Non-independent identical distribution (Non-iid) problems in federated learning, FGL heterogeneity essentially reveals the topological divergence among multiple clients, namely homophily or heterophily. To simulate and handle this unique challenge, we introduce the concept of structure Non-iid split and then present a new paradigm called Adaptive Federated Graph Learning (AdaFGL), a decoupled two-step personalized approach. To begin with, AdaFGL employs standard multi-client federated collaborative training to acquire the federated knowledge extractor by aggregating uploaded models in the final round at the server. Then, each client conducts personalized training based on the local subgraph and the federated knowledge extractor. Extensive experiments on the 12 graph benchmark datasets validate the superior performance of AdaFGL over state-of-the-art baselines. Specifically, in terms of test accuracy, our proposed AdaFGL outperforms baselines by significant margins of 3.24 % and 5.57 % on community split and structure Non-iid split, respectively.}
}


@inproceedings{DBLP:conf/icde/0001WCO24,
	author = {Alexander Zhou and
                  Yue Wang and
                  Lei Chen and
                  M. Tamer {\"{O}}zsu},
	title = {Positive Communities on Signed Graphs That Are Not Echo Chambers:
                  {A} Clique-Based Approach},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {2531--2543},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00199},
	doi = {10.1109/ICDE60146.2024.00199},
	timestamp = {Sun, 06 Oct 2024 21:04:56 +0200},
	biburl = {https://dblp.org/rec/conf/icde/0001WCO24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {An area of research on communities in signed networks aims to find structures in which each user in the graph is connected to other members in their community by more positive edges than negative edges, indicating a positive experience for the user. However, some of these communities are ‘echo chambers', a rising area of concern in modern discourse regarding social media, which contain almost exclusively positive edges indicating all users trust each other with little or no push-back. Here exists an interesting contradiction, when finding a ‘positive’ community often times the resulting structure may be the negative ‘echo chamber’. In this work we propose a signed graph community substructure named the\n(ϵ, ϕ)\n-Clique which is the best of both worlds, where each user is happy to be in their community (indicated by have a proportion of positive edges\n≥ϵ\nfor each node) as well as there existing a level of disagreement in the system (indicated by the community having a proportion of negative edges\n≥ϕ\n). From this definition, we design algorithms to exactly find the Maximum\n(ϵ, ϕ)\n-Clique containing a query user, utilising heuristics to combat the NP-Hard and NP-Hard to approximate nature of the problem. We perform experiments to examine the improvements in efficiency of our algorithms to the proposed baseline as well as examine example community outputs to show the effectiveness of our structure.}
}


@inproceedings{DBLP:conf/icde/ChenWLQ0W24,
	author = {Jiujian Chen and
                  Kai Wang and
                  Ronghua Li and
                  Hongchao Qin and
                  Xuemin Lin and
                  Guoren Wang},
	title = {Maximal Biclique Enumeration: {A} Prefix Tree Based Approach},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {2544--2556},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00200},
	doi = {10.1109/ICDE60146.2024.00200},
	timestamp = {Sun, 04 Aug 2024 16:27:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ChenWLQ0W24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Bipartite graphs are commonly used to model relationships between two distinct types of entities, such as customer-product relationships in e-commerce platforms and protein-protein interactions in bioinformatics. Enumerating all maximal bicliques from a bipartite graph is a fundamental graph mining problem that has been widely used in many real-world applications including community search and spam detection. Existing algorithms for maximal biclique enumeration can struggle to scale to large graphs with a vast number of maximal bicliques. In this paper, we propose a novel and highly-efficient algorithm for maximal biclique enumeration in bipartite graphs using prefix trees. Specifically, a prefix tree is a data structure that stores lists of elements as paths in the tree, and we observe that a maximal biclique can be represented uniquely by the vertices in one of its vertex layers and stored compactly in prefix trees. The process of our algorithm is divided into two steps. First, we find the lower layer vertices of all maximal bicliques and organize them in a prefix tree (i.e., the result tree). During this step, we transform the original time-consuming operations of checking maximality and filtering candidates for vertex sets into determining uniqueness and performing extraction from a prefix tree at each level of the recursion. Second, we use the result tree to obtain the upper layer vertices of the maximal bicliques by computing the common neighbors of vertices in the tree. In this step, we further optimize the computation for intersections of vertex sets by compressing the neighbors of each vertex and memoization. In addition, we also propose a pre-processing method based on the order of traversal on the prefix tree to reduce memory usage. We conduct extensive experiments on 10 real-world datasets, and the results demonstrate that the proposed algorithm outperforms existing solutions by up to one order of magnitude.}
}


@inproceedings{DBLP:conf/icde/YuanH0024,
	author = {Long Yuan and
                  Kongzhang Hao and
                  Xuemin Lin and
                  Wenjie Zhang},
	title = {Batch Hop-Constrained s-t Simple Path Query Processing in Large Graphs},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {2557--2569},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00201},
	doi = {10.1109/ICDE60146.2024.00201},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/YuanH0024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Hop-constrained s-t simple path (HC-s-t path) enu-meration is a fundamental problem in graph analysis. Existing solutions for this problem focus on optimizing the processing performance of a single query. However, in practice, it is more often that multiple H C-s-t path queries are issued simultaneously and processed as a batch. Therefore, we study the problem of batch H C-s-t path query processing in this paper and aim to compute the results of all queries concurrently and efficiently as a batch. To achieve this goal, we first propose the concept of H C-s path query which can precisely characterize the common computation among different queries. We then devise a two-phase H C-s path query detection algorithm to identify the common H C-5 path queries for the given H C-s-t path queries. Based on the detected HC-s path queries, we further devise an efficient HC-s-t path enumeration algorithm in which the common computation represented by H C-s path queries are effectively shared. We conduct extensive experiments on real-world graphs and the experimental results demonstrate that our proposed algorithm is efficient and scalable regarding processing multiple HC-s-t path queries in large graphs at billion-scale.}
}


@inproceedings{DBLP:conf/icde/GaoYLLQ24,
	author = {Shuohao Gao and
                  Kaiqiang Yu and
                  Shengxin Liu and
                  Cheng Long and
                  Zelong Qiu},
	title = {On Searching Maximum Directed (k, {\unicode{120001}})-Plex},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {2570--2583},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00202},
	doi = {10.1109/ICDE60146.2024.00202},
	timestamp = {Tue, 22 Oct 2024 20:38:20 +0200},
	biburl = {https://dblp.org/rec/conf/icde/GaoYLLQ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Finding cohesive subgraphs from a directed graph is a fundamental approach to analyze directed graph data. We consider a new model called directed\n(k,ℓ)\n-plex for a cohesive directed subgraph, which is generalized from the concept of\nk\n-plex that is only applicable to undirected graphs. Directed\n(k,ℓ)\n-plex has the connection requirements on both inbound and outbound directions of each vertex inside, i.e., each vertex disconnects at most\nK\nvertices and is meanwhile not pointed to by at most\nℓ\nvertices. In this paper, we study the maximum directed\n(k,ℓ)\n-plex search problem which finds a directed\n(k,ℓ)\n-plex with the most vertices. We formally prove the NP-hardness of the problem. We then design a heuristic algorithm called DPHeuris, which finds a directed\n(k,ℓ)\n-plex with the size close to the maximum one and runs practically fast in polynomial time. Furthermore, we propose a branch-and-bound algorithm called DPBB to find the exact maximum directed\n(k,ℓ)\n-plex and develop effective graph reduction strategies for boosting the empirical performance. Finally, we conduct extensive experiments on real directed graphs. The experimental results show that (1) our heuristic method can quickly find a near-optimal solution and (2) our branch-and-bound method runs up to six orders of magnitude faster than other baselines.}
}


@inproceedings{DBLP:conf/icde/LuoLSWWW24,
	author = {Yanchen Luo and
                  Sihang Li and
                  Yongduo Sui and
                  Junkang Wu and
                  Jiancan Wu and
                  Xiang Wang},
	title = {Masked Graph Modeling with Multi- View Contrast},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {2584--2597},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00203},
	doi = {10.1109/ICDE60146.2024.00203},
	timestamp = {Wed, 14 Aug 2024 08:24:56 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LuoLSWWW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Masked modeling has recently achieved remarkable success in specific fields of vision and language, sparking a surge of interest in graph-related research. However, Masked Graph Modeling (MGM), which captures fine-grained local information by masking low-level elements such as nodes, edges, and features, limits itself to a sub-optimal position, particularly on tasks requiring high-quality graph-level representations. Such a local perspective disregards the graph's global information and structure. To address these limitations, we propose a novel graph pre-training framework called Graph Contrastive Masked Autoencoder (GCMAE). GCMAE leverages the strengths of both MGM and Graph Contrastive Learning (GCL) to provide a more comprehensive perspective of both local and global. Our frame-work uses instance discrimination to learn global representations of graphs and reconstructs the graph using masked low-level elements. We augment the framework with a novel multi-view augmentation module to further enhance the pre-trained model's robustness and generalization ability. We evaluate GCMAE on real-world biochemistry and social network datasets, conducting extensive experiments on both node and graph classification tasks and transfer learning on downstream graph classification tasks. Our experimental results demonstrate that GCMAE's comprehensive perspective of both local and global benefits model pre-training. Moreover, GCMAE outperforms existing MGM and GCL baselines, proving its effectiveness on downstream tasks. Our code is available at https://github.com/lyc0930/GCMAE.}
}


@inproceedings{DBLP:conf/icde/TangLYLZ024,
	author = {Yuhao Tang and
                  Junyu Luo and
                  Ling Yang and
                  Xiao Luo and
                  Wentao Zhang and
                  Bin Cui},
	title = {Multi- View Teacher with Curriculum Data Fusion for Robust Unsupervised
                  Domain Adaptation},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {2598--2611},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00204},
	doi = {10.1109/ICDE60146.2024.00204},
	timestamp = {Tue, 06 Aug 2024 08:17:52 +0200},
	biburl = {https://dblp.org/rec/conf/icde/TangLYLZ024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graph Neural Networks (GNNs) have emerged as an effective tool for graph classification, yet their reliance on extensive labeled data poses a significant challenge, especially when such labels are scarce. To address this challenge, this paper presents a novel framework, denoted as Multi-View Teacher with Curriculum Data Fusion (MTDF). MTDF achieves robust unsupervised domain adaptation in both the model and data perspectives. On the one hand, MTDF utilizes a multi-teacher framework with diverse update strategies for robust adaptation. Moreover, it employs a complementary perspective consistency model from local implicit representation and global explicit graph structure. On the other hand, MTDF generates source-mimicry data at the target domain to serve as a bridge to overcome the challenge of domain shift. MTDF achieves stable unsupervised domain adaptation through bi-directional processes from the perspective of both the model and the data. We have conducted comprehensive experimental evaluations across multiple real-world datasets with a range of baseline methods to demonstrate the superior performance of our proposed method.}
}


@inproceedings{DBLP:conf/icde/0014YWWW24,
	author = {Chen Chen and
                  Ye Yuan and
                  Zhenyu Wen and
                  Yu{-}Ping Wang and
                  Guoren Wang},
	title = {GShop: Towards Flexible Pricing for Graph Statistics},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {2612--2624},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00205},
	doi = {10.1109/ICDE60146.2024.00205},
	timestamp = {Tue, 30 Jul 2024 08:18:18 +0200},
	biburl = {https://dblp.org/rec/conf/icde/0014YWWW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The prevalence of online query services in human life has attracted significant interest from the fields of economics and databases in determining appropriate pricing for such services. Simultaneously, the utilization of graph analytics across various domains has resulted in substantial social and economic benefits in recent years. As the adoption of graph analytics continues to expand, there is a corresponding need to establish fair pricing models for the information contributed by each participant in the data ecosystem. However, current query-based pricing frameworks cannot be applied to price graph statistics, as they fail to consider buyers' affordability and prevent arbitrage trading. To address this gap, in this paper, we propose a novel framework GSHOP for pricing graph statistic queries. Instead of pricing a precise answer for a query, our framework offers the flexibility to price a set of answers injected with noise. Based on the framework, data owners initially create and publish extended local views (ELVs) to represent their graph data. Additionally, it allows buyers to tolerate a certain degree of noise added to the answer to reduce their payments. The framework accurately quantifies the relationship between noise and price to ensure that payment and compensation are reasonable for the buyer and owners, respectively. We also propose algorithms specifically designed for fundamental graph statistics, including node degrees and subgraph counts such as k-stars and k-cliques. Furthermore, we formally prove that the pricing framework is arbitrage-free. Extensive experimental results on real-life graph data validate the good performance of the proposed framework and algorithms.}
}


@inproceedings{DBLP:conf/icde/HouZT24,
	author = {Wenzhe Hou and
                  Xiang Zhao and
                  Bo Tang},
	title = {LearnSC: An Efficient and Unified Learning-Based Framework for Subgraph
                  Counting Problem},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {2625--2638},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00206},
	doi = {10.1109/ICDE60146.2024.00206},
	timestamp = {Mon, 11 Nov 2024 09:02:56 +0100},
	biburl = {https://dblp.org/rec/conf/icde/HouZT24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graphs are valuable data structures used to represent complex relationships between entities in a wide range of applications, such as social networks and chemical reactions. Subgraph counting problem is a well-known hard problem, as its core subroutine, the subgraph matching, is NP-complete. In this work, we propose an efficient and unified deep learning-based solution framework LearnSC, which solves the subgraph counting problem approximately. This framework offers two key advantages: (i) it is a generic solution that is orthogonal to the existing techniques of learning-based solutions; and (ii) it is equipped with a suite of optimizations to significantly improve the accuracy of the estimated results. Our experimental results on 7 datasets demonstrate that our proposal is highly accurate, robust, and scalable, making it an excellent solution for subgraph counting problem among all statistics-based and learning-based competitors.}
}


@inproceedings{DBLP:conf/icde/ChenYY24,
	author = {Bing{-}Jyue Chen and
                  Ho Chiok Yew and
                  De{-}Nian Yang},
	title = {{AFTER:} Adaptive Friend Discovery for Temporal-Spatial and Social-Aware
                  {XR}},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {2639--2652},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00207},
	doi = {10.1109/ICDE60146.2024.00207},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ChenYY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recent advancements in the field of extended reality (XR) have garnered significant interest in XR socialization. However, traditional social XR experiences often fall short of satisfying users' social expectations due to the negligence of the emerging opportunities in XR. In this paper, we propose a novel scenario of socializing in social XR, which has the potential to substantially enhance traditional social media through i) the recommendation of appropriate surrounding users that cater to users' individual preferences, ii) the adaptive avoidance of view occlusions to facilitate users in locating their friends, iii) the consideration of users' social presence, and iv) the development of cross-platform solutions to provide hybrid participation. To this end, we formulate Adaptive Friend Discovery for Temporal-spatial and Social-aware XR, a new NP-hard social recommendation problem aiming at satisfying social XR users. The proposed model, POSHGNN, is a deep temporal graph learning framework designed to provide efficient social recommendations for target users. Experimental results obtained from real-world social XR datasets and a user study that supports multiple XR interfaces demonstrate that the proposed method outperforms baseline approaches with an improvement of 18.5 % in solution quality.}
}


@inproceedings{DBLP:conf/icde/LiuKG24,
	author = {Qu Liu and
                  Adam King and
                  Tingjian Ge},
	title = {Reducing Resource Usage for Continuous Model Updating and Predictive
                  Query Answering in Graph Streams},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {2653--2666},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00208},
	doi = {10.1109/ICDE60146.2024.00208},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LiuKG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We observe the need for continuous, online training of dynamic graph neural network (DGNN) models while at the same time using them to answer continuous predictive queries as data streams in. This implies significant training-time and memory costs. Along with the DGNN model learning, we simultaneously learn a weight/priority distribution over the nodes via a randomized online algorithm. In turn, the DGNN is continuously trained/learned by sampling nodes from the learned distribution and performing the chosen nodes' partitions of training work. We also devise a novel graph Kernel Density Estimation technique to smooth the distribution and improve the learning quality. Our experiments show that continuous online learning is much needed for graph streams and our approach significantly improves the standard DGNN models-to achieve the same accuracy, the training time ranges from several times to two orders of magnitude shorter, and the maximum memory consumption is several times to 20 times smaller.}
}


@inproceedings{DBLP:conf/icde/Li024,
	author = {Xujia Li and
                  Lei Chen},
	title = {Graph Anomaly Detection with Domain-Agnostic Pre-Training and Few-Shot
                  Adaptation},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {2667--2680},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00209},
	doi = {10.1109/ICDE60146.2024.00209},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Li024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graph anomaly detection attracts considerable interest across a variety of application domains, including fraud detection within social networks, identifying money laundering activities in transaction graphs, etc. The advent of Graph Neural Networks (GNNs) has enhanced existing deep learning methods to capture the anomaly patterns in the latent space and achieve satisfactory results. However, the performance deficiency of current GNNs is primarily caused by the scarce labeled anomalies in a specific real-world application. Unlike the total neglect of valuable labeled anomalies in unsupervised approaches or the potential overfitting in supervised approaches, we proposed a few-shot-oriented framework GUDI in this paper. GUDI is the first work to incorporate a self-supervised pre-training approach to capture general graph patterns across domains and design a classifier with few-shot learning to model the labeled data within a specific domain. The proposed guided diffusion mechanism synthesizes the outcomes of the pre-trained model and the domain-specific classifier in the inference phase, which negates the need for fine-tuning the large pre-trained model, thereby facilitating efficient domain adaptation. GUDI retains the ability to uncover unknown anomalies through unsupervised pre-training while also possessing the ability to identify known anomaly natterns from few-shot labels.}
}


@inproceedings{DBLP:conf/icde/ZhangWYLC0024,
	author = {Wentao Zhang and
                  Yexin Wang and
                  Zhenbang You and
                  Yang Li and
                  Gang Cao and
                  Zhi Yang and
                  Bin Cui},
	title = {{NC-ALG:} Graph-Based Active Learning Under Noisy Crowd},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {2681--2694},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00210},
	doi = {10.1109/ICDE60146.2024.00210},
	timestamp = {Tue, 30 Jul 2024 08:18:18 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhangWYLC0024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graph Neural Networks (GNNs) have achieved great success in various data mining tasks but they heavily rely on a large number of annotated nodes, requiring considerable human efforts. Despite the effectiveness of existing GNN-based Active Learning (AL) methods, they assume that the annotated labels are always correct, which is contradictory to the error-prone labeling process in a practical crowdsourcing environment. Besides, due to this impractical assumption, existing works only focus on optimizing the node selection in AL but neglect optimizing the labeling process. Therefore, we present NC-ALG, the first GNN-based AL framework that optimizes both the node selection and node labeling process under a noisy crowd. For node selection, NC-ALG introduces a new measurement to model influence reliability and an effective influence maximization objective to select nodes. For node labeling, NC-ALG significantly reduces the labeling cost by considering the model-predicted labels and the labels of mirror nodes. To the best of our knowledge, this is the first attempt to consider GNN-based AL under the practical noisy crowd. Empirical studies on public datasets demonstrate that NC-ALG significantly outperforms existing methods in terms labeling efficiency. Notably, it only takes NC-ALG one-third of the labeling budget that the competitive baseline GRAIN needs to achieve an accuracy of 70.7 % on PubMed.}
}


@inproceedings{DBLP:conf/icde/LiuWZ024,
	author = {Dandan Liu and
                  Run{-}An Wang and
                  Zhaonian Zou and
                  Xin Huang},
	title = {Fast Multilayer Core Decomposition and Indexing},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {2695--2708},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00211},
	doi = {10.1109/ICDE60146.2024.00211},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LiuWZ024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The multilayer (ML) graph model provides a robust representation of multi-sourced relationships among real-world entities, laying a solid foundation for reliable knowledge discovery. ML core decomposition is a fundamental analytical tool for ML graphs. It offers valuable insights into the dense structures in ML graphs and forms the basis for many complex analysis tasks. However, existing ML core decomposition algorithms face performance issues due to unavoidably unnecessary computations and are inherently serial, unable to fully leverage the multi-core processors. In this paper, we reformulate the search space of this problem with a tree-shaped structure called MLC-tree. Based on it, we present an efficient serial ML core decomposition algorithm that achieves improved time complexity over existing solutions and the first parallel framework for this problem by exploiting the path-decomposition of the MLC-tree. Two practical optimizations are introduced to further boost the parallel efficiency. To facilitate applications built upon ML cores, we construct a compact storage and index structure for ML cores based on the MLC-tree. The usefulness of this index is showcased through two applications: ML core search and a novel weighted densest sub graph discovery problem. Extensive experiments on 9 real-world ML graphs show that our MLC-tree-based ML core decomposition algorithm achieves a speedup of up to\n128×\nover existing baselines and the parallel approach attains an additional speedup of up to\n30.6×\nusing 40 cores. Moreover, the MLC-tree index can efficiently support the studied applications.}
}


@inproceedings{DBLP:conf/icde/JiaoLW024,
	author = {Pengfei Jiao and
                  Yuanqi Liu and
                  Yinghui Wang and
                  Ge Zhang},
	title = {{CINA:} Curvature-Based Integrated Network Alignment with Hypergraph},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {2709--2722},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00212},
	doi = {10.1109/ICDE60146.2024.00212},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/JiaoLW024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Network alignment involves identifying corresponding nodes across multiple networks. The majority of existing methods adhere to the assumption of consistency. However, due to distinct graph generation mechanisms, anchor nodes in real-world datasets often exhibit more intricate structural patterns, such as having multiple different neighbors and higher-order associations. Relying solely on consistency while disregarding the intricate patterns of anchor links may potentially inflict substantial detriment upon both the accuracy of network alignment and the generality of the model. In this paper, we introduce the disparity and diversity based on distinct structural patterns of ubiquitous anchor links. We propose a comprehensive framework that employs first-order proximity, lower-order discriminability, and higher-order correlation to model consistency, disparity, and diversity. We also incorporate a post-fusion mechanism for effectively integrating alignment matrices. Furthermore, we innovatively introduce hyperbolic space as an embedding space to further minimize embedding distortion. Extensive experiments have shown that our approach achieves state-of-the-art alignment results and yields notable improvements in the overall versatility of the model.}
}


@inproceedings{DBLP:conf/icde/Wang0ZLDL0Y24,
	author = {Yanling Wang and
                  Jing Zhang and
                  Lingxi Zhang and
                  Lixin Liu and
                  Yuxiao Dong and
                  Cuiping Li and
                  Hong Chen and
                  Hongzhi Yin},
	title = {Open-World Semi-Supervised Learning for Node Classification},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {2723--2736},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00213},
	doi = {10.1109/ICDE60146.2024.00213},
	timestamp = {Sun, 06 Oct 2024 21:04:59 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Wang0ZLDL0Y24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Open-world semi-supervised learning (Open-world SSL) for node classification, that classifies unlabeled nodes into seen classes or multiple novel classes, is a practical but under-explored problem in the graph community. As only seen classes have human labels, they are usually better learned than novel classes, and thus exhibit smaller intra-class variances within the embedding space (named as imbalance of intra-class variances between seen and novel classes). Based on empirical and theoretical analysis, we find the variance imbalance can negatively impact the model performance. Pre-trained feature encoders can alleviate this issue via producing compact representations for novel classes. However, creating general pre-trained encoders for various types of graph data has been proven to be challenging. As such, there is a demand for an effective method that does not rely on pre-trained graph encoders. In this paper, we propose an IMbalance-A ware method named OpenIMA for Open-world semi-supervised node classification, which trains the node classification model from scratch via contrastive learning with bias-reduced pseudo labels. Extensive experiments on seven popular graph benchmarks demonstrate the effectiveness of OpenIMA, and the source code has been available on GitHub 1 1 https://github.com/RUCKBReasoning/OpenIMA.}
}


@inproceedings{DBLP:conf/icde/0001YXGZK024,
	author = {Yuxiang Wang and
                  Shuzhan Ye and
                  Xiaoliang Xu and
                  Yuxia Geng and
                  Zhenghe Zhao and
                  Xiangyu Ke and
                  Tianxing Wu},
	title = {Scalable Community Search with Accuracy Guarantee on Attributed Graphs},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {2737--2750},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00214},
	doi = {10.1109/ICDE60146.2024.00214},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/0001YXGZK024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Given an attributed graph G\nand a query node q\n, Community Search over Attributed Graphs (CS-AG) aims to find a structure- and attribute-cohesive subgraph from G\nthat contains q\n. Although CS-AG has been widely studied, they still face three challenges. (1) Exact methods based on graph traversal are time-consuming, especially for large graphs. Some tailored indices can improve efficiency, but introduce nonnegligible storage and maintenance overhead. (2) Approximate methods with a loose approximation ratio only provide a coarse-grained evaluation of a community's quality, rather than a reliable evaluation with an accuracy guarantee in runtime. (3) Attribute cohesiveness metrics often ignores the important correlation with the query node q\n. We formally define our CS-AG problem atop a q- \\mathbf{centric}\nattribute cohesiveness metric considering both textual and numerical attributes, for k-\\mathbf{core}\nmodel on homogeneous graphs. We show the problem is NP-hard. To solve it, we first propose an exact baseline with three pruning strategies. Then, we propose an index-free sampling-estimation-based method to quickly return an approximate community with an accuracy guarantee, in the form of a confidence interval. Once a good result satisfying a user-desired error bound is reached, we terminate it early. We extend it to heterogeneous graphs, k-\\mathbf{truss}\nmodel, and size-bounded CS. Comprehensive experimental studies on ten real-world datasets show its superiority, e.g., at least 1.54\\times (41.1\\times\non average) faster in response time and a reliable relative error (within a user-specific error bound) of attribute cohesiveness is achieved.}
}


@inproceedings{DBLP:conf/icde/WangCLCC24,
	author = {Qihao Wang and
                  Hongtai Cao and
                  Xiaodong Li and
                  Kevin Chen{-}Chuan Chang and
                  Reynold Cheng},
	title = {From Motif to Path: Connectivity and Homophily},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {2751--2764},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00227},
	doi = {10.1109/ICDE60146.2024.00227},
	timestamp = {Thu, 01 Aug 2024 08:00:47 +0200},
	biburl = {https://dblp.org/rec/conf/icde/WangCLCC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {While motif has been widely employed in graph analytics, a fundamental question remains open: How should overlapping motif edges connect into a path? Existing works address this question with simple but inconsistent generalizations from standard graphs. This paper studies this issue by proposing the concept of connectivity degree (CD), i.e. the number of overlapping nodes needed for motif edges to be adjacent, as the requirement for path connection. We further study three research questions. First, is CD significant? We study how CD impacts motif analytics, more specifically, three motif-based methods. Second, how to estimate the right CD? We develop a minimax estimator based on minimizing the worst-case risk. Finally, how to detect the connected components with connectivity degree, an important task by itself and necessary for our estimator. As the traditional BFS or DFS approaches are not valid anymore, we develop a disjoint set algorithm instead. Our experiments validate that our CD can improve the performance of motif analytics. Also, our estimator is effective and our connected component detection algorithm is efficient.}
}


@inproceedings{DBLP:conf/icde/0008CZSWYW24,
	author = {Yuan Li and
                  Xiuxu Chen and
                  Yuhai Zhao and
                  Wen Shan and
                  Zhengkui Wang and
                  Guoli Yang and
                  Guoren Wang},
	title = {Self-Training GNN-based Community Search in Large Attributed Heterogeneous
                  Information Networks},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {2765--2778},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00216},
	doi = {10.1109/ICDE60146.2024.00216},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/0008CZSWYW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Attributed Heterogeneous Information Networks (AHINs) amalgamate the advantages of attributed graphs (AGs) and heterogeneous information networks (HINs) to model intri-cate systems. Within this context, community search-aiming to identify the most probable community containing the queried ver-tex-has been extensively explored in AGs and HINs. However, existing methodologies fall short in simultaneously accommodating heterogeneous attributes and multiple meta-paths in AHINs, posing a substantial challenge in investigating community search within expansive AHINs. Recent studies highlight the efficacy of machine learning-based community search, offering enhanced flexibility and higher-quality communities in comparison to traditional structural-based methods. Yet, semi-supervised learning methods demand substantial labeled data and incur considerable memory and time costs when applied to large AHINs. To tackle these challenges, we propose a MK (Most-likely; K-sized) community search approach. This approach involves defining an MK community and leveraging Graph Neural Networks (GNNs) to amalgamate structures and attributes into a unified goodness metric. Our methodology involves training on local subgraphs sampled via guided random walks based on multiple meta-paths, circumventing the need for training on the entire graph. Moreover, attention-based GNNs adeptly learn meta-path weights to guide weighted walks in subsequent iterations. Additionally, self-training is employed to alleviate the labeling burden. We also demonstrate that pinpointing the location for the MK community is NP-hard and present a heuristic local search strategy that expedites the resolution process through rewriting. Ultimately, the convergence of iterations yields the solution. Extensive experiments conducted on four real-world datasets underscore that the MK framework significantly enhances both effectiveness and efficiency in community search within AHINs. Our code is publicly available at https://github.com/uucxuu/CSAH.}
}


@inproceedings{DBLP:conf/icde/LiangZSYJT024,
	author = {Yuxuan Liang and
                  Wentao Zhang and
                  Zeang Sheng and
                  Ling Yang and
                  Jiawei Jiang and
                  Yunhai Tong and
                  Bin Cui},
	title = {{HGAMLP:} Heterogeneous Graph Attention {MLP} with De-Redundancy Mechanism},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {2779--2791},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00217},
	doi = {10.1109/ICDE60146.2024.00217},
	timestamp = {Tue, 27 Aug 2024 17:30:57 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LiangZSYJT024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Heterogeneous graphs contain rich semantic information that can be exploited by heterogeneous graph neural networks (HGNNs). However, scaling HGNNs to large graphs is challenging due to the high computational cost. Existing non-parametric HGNNs use general subgraphs construction method and mean aggregator before training to reduce the complexity. Despite their success, they ignore two key characteristics of heterogeneous graphs, leading to low predictive performance. First, they adopt fixed local and global knowledge extractor for the feature aggregation and the semantic fusion. Besides, they bury the graph structure information of the higher-order meta-paths and fail to explore deeper graph structure information. In this paper, we address these two limitations and propose a new non-parametric HGNN framework called Heterogeneous Graph Attention Multi-Layer Perceptron (HGAMLP). Our framework employs the local multi-knowledge extractor to enhance the node representation, and leverages the de-redundancy mechanism to extract the pure graph structure information from higher-order meta-paths. Besides, it adopts a node-adaptive weight adjustment mechanism as an efficiency training model to fuse global knowledge and local knowledge. We evaluate our framework on ten commonly used heterogeneous graph datasets and show that it outperforms the state-of-the-art baselines in both accuracy and speed. Notably, our framework achieves the best performance on the large public heterogeneous graph dataset (i.e., Ogbn-mag) of Open Graph Benchmark 1 1 https://ogb.stanford.edu/docs/leader_nodeprop.}
}


@inproceedings{DBLP:conf/icde/WangLZ24,
	author = {Run{-}An Wang and
                  Dandan Liu and
                  Zhaonian Zou},
	title = {FocusCore Decomposition of Multilayer Graphs},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {2792--2804},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00218},
	doi = {10.1109/ICDE60146.2024.00218},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/WangLZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Mining dense subgraphs on multilayer graphs offers the opportunity for more in-depth discoveries than classical dense subgraph mining on single-layer graphs. However, the existing approaches fail to ensure the denseness of a discovered subgraph on layers of users' interest and simultaneously gain partial supports on the denseness from other layers. In this paper, we introduce a novel dense subgraph model called FocusCore (FoCore) for multilayer graphs, which can pay more attention to layers focused on by users. The FoCore decomposition problem, i.e., identifying all nonempty FoCores in a multilayer graph, can be addressed by executing the peeling process with respect to all possible configurations of focus and background layers. By utilizing the nice properties of FoCores, we devise an interleaved peeling algorithm and a vertex-centric algorithm towards efficient FoCore decomposition. As an application, we propose a FoCore-decomposition-based algorithm to approximate the densest subgraph in a multilayer graph with a provable approximation guarantee. The extensive experiments on real-world datasets verify the effectiveness of the FoCore model and the efficiency of the proposed algorithms.}
}


@inproceedings{DBLP:conf/icde/WangDC024,
	author = {Zhili Wang and
                  Shimin Di and
                  Lei Chen and
                  Xiaofang Zhou},
	title = {Search to Fine-Tune Pre-Trained Graph Neural Networks for Graph-Level
                  Tasks},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {2805--2819},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00219},
	doi = {10.1109/ICDE60146.2024.00219},
	timestamp = {Sun, 06 Oct 2024 21:04:59 +0200},
	biburl = {https://dblp.org/rec/conf/icde/WangDC024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recently, graph neural networks (GNNs) have shown its unprecedented success in many graph-related tasks. However, GNNs face the label scarcity issue as other neural networks do. Thus, recent efforts try to pre-train GNNs on a large-scale unlabeled graph and adapt the knowledge from the unlabeled graph to the target downstream task. The adaptation is generally achieved by fine-tuning the pre-trained GNNs with a limited number of labeled data. However, current GNNs pre-training works focus more on how to better pre-train a GNN, but ignore the importance of fine-tuning to better leverage the transferred knowledge. Only a few works start to investigate a better fine-tuning strategy for pre-trained GNNs. But their designs either have strong assumptions or overlook the data-aware issue behind various downstream domains. To further boost pre-trained GNNs, we propose to search to fine-tune pre-trained GNNs for graph-level tasks (S2PGNN), which can adaptively design a suitable fine-tuning framework for the given pre-trained GNN and downstream data. Unfortunately, it is a non-trivial task to achieve this goal due to two technical challenges. First is the hardness of fine-tuning space design since there lack a systematic and unified exploration in existing literature. Second is the enormous computational overhead required for discovering suitable fine-tuning strategies from the discrete space. To tackle these challenges, S2PGNN first carefully summarizes a search space of fine-tuning strategies that is suitable for GNNs, which is expressive enough to enable powerful strategies to be searched. Then, S2PGNN integrates an efficient search algorithm to solve the computationally expensive search problem from a discrete and large space. The empirical studies show that S2PGNN can be implemented on the top of 10 famous pre-trained GNNs and consistently improve their performance by 9 % to 17 %. Our code is publicly available at https://github.com/zwangeo/icde2024.}
}


@inproceedings{DBLP:conf/icde/LiuHSS0Y24,
	author = {Jie Liu and
                  Mengting He and
                  Xuequn Shang and
                  Jieming Shi and
                  Bin Cui and
                  Hongzhi Yin},
	title = {{BOURNE:} Bootstrapped Self-Supervised Learning Framework for Unified
                  Graph Anomaly Detection},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {2820--2833},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00220},
	doi = {10.1109/ICDE60146.2024.00220},
	timestamp = {Sun, 06 Oct 2024 21:04:58 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LiuHSS0Y24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graph anomaly detection (GAD) has gained increasing attention in recent years due to its critical application in a wide range of domains, such as social networks, financial risk management, and traffic analysis. Existing GAD methods can be categorized into node and edge anomaly detection models based on the type of graph objects being detected. However, these methods typically treat node and edge anomalies as separate tasks, overlooking their associations and frequent co-occurrences in real-world graphs. As a result, they fail to leverage the complementary information provided by node and edge anomalies for mutual detection. Additionally, state-of-the-art GAD methods, such as CoLA and SL-GAD, heavily rely on negative pair sampling in contrastive learning, which incurs high computational costs, hindering their scalability to large graphs. To address these limitations, we propose a novel unified graph anomaly detection framework based on bootstrapped self-supervised learning (named BOURNE). We extract a subgraph (graph view) centered on each target node as node context and transform it into a dual hypergraph (hypergraph view) as edge context. These views are encoded using graph and hypergraph neural networks to capture the representations of nodes, edges, and their associated contexts. By swapping the context embeddings between nodes and edges and measuring the agreement in the embedding space, we enable the mutual detection of node and edge anomalies. Furthermore, BOURNE can eliminate the need for negative sampling, thereby enhancing its efficiency in handling large graphs. Extensive experiments conducted on six benchmark datasets demonstrate the superior effectiveness and efficiency of BOURNE in detecting both node and edge anomalies.}
}


@inproceedings{DBLP:conf/icde/Niu0K0L24,
	author = {Yudong Niu and
                  Yuchen Li and
                  Panagiotis Karras and
                  Yanhao Wang and
                  Zhao Li},
	title = {Discovering Personalized Characteristic Communities in Attributed
                  Graphs},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {2834--2847},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00221},
	doi = {10.1109/ICDE60146.2024.00221},
	timestamp = {Sun, 06 Oct 2024 21:04:58 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Niu0K0L24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {What is the widest community in which a person exercises a strong impact? Although extensive attention has been devoted to searching communities containing given individuals, the problem of finding their unique communities of influence has barely been examined. In this paper, we study the novel problem of Characteristic cOmmunity Discovery (COD) in attributed graphs. Our goal is to identify the largest community, taking into account the query attribute, in which the query node has a significant impact. The key challenge of the COD problem is that it requires evaluating the influence of the query node over a large number of hierarchically structured communities. We first propose a novel compressed COD evaluation approach to accelerate the influence estimation by eliminating redundant computations for overlapping communities. Then, we further devise a local hierarchical reclustering method to alleviate the skewness of hierarchical communities generated by global clustering for a specific query attribute. Extensive experiments confirm the effectiveness and efficiency of our solutions to COD: they find characteristic communities better than existing community search methods by several quality measures and achieve up to 25 x speedups against well-crafted baselines.}
}


@inproceedings{DBLP:conf/icde/LiuL0TC24,
	author = {Jie Liu and
                  Jiamou Liu and
                  Kaiqi Zhao and
                  Yanni Tang and
                  Wu Chen},
	title = {{TP-GNN:} Continuous Dynamic Graph Neural Network for Graph Classification},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {2848--2861},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00215},
	doi = {10.1109/ICDE60146.2024.00215},
	timestamp = {Mon, 16 Sep 2024 20:39:37 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LiuL0TC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Dynamic networks are data structures that represent the interactions among various entities in real-world systems, with their topology and node properties evolving over time. However, prevailing approaches typically derive node embeddings through aggregating temporal neighbor nodes of adjacent several hops, thus failing to capture the long temporal dependencies in dynamic networks. Furthermore, existing research on dynamic networks focuses on node- and edge-level tasks, lacking the support of graph-level tasks. To address the limitations of current approaches, this paper proposes TP-GNN, a novel continuous dynamic graph neural network model intended for graph classification in dynamic networks, which offers two primary advantages: (1) TP-GNN captures the long temporal dependencies via a novel message-passing method based on the information flow among the nodes, and (2) it learns the network evolution process from edge order for accurate dynamic network analytics. We evaluate the performance of TP-GNN in five datasets, including a new dataset we created from a Java software project. The results show that our method outperforms state-of-the-art approaches in graph classification with an average improvement of 4.91% in terms of\nF\n1\nScore 1 1 Codes and dataset are available at https://github.com/Jie-0828/TP-GNN..}
}


@inproceedings{DBLP:conf/icde/FengWLLLZBY24,
	author = {Hao Feng and
                  Chaokun Wang and
                  Ziyang Liu and
                  Yunkai Lou and
                  Zhenyu Liu and
                  Xiaokun Zhu and
                  Yongjun Bao and
                  Weipeng Yan},
	title = {GraphHI: Boosting Graph Neural Networks for Large-Scale Graphs},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {2862--2875},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00222},
	doi = {10.1109/ICDE60146.2024.00222},
	timestamp = {Tue, 30 Jul 2024 08:18:19 +0200},
	biburl = {https://dblp.org/rec/conf/icde/FengWLLLZBY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {To analyze and process graph data, researchers have proposed Graph Neural Network (GNN) models. In this paper, we focus on methods for boosting the performance of existing GNN models and propose GraphHI, a GNN framework that integrates Hidden Insights to enhance the performance of a given GNN model. We propose to utilize both inter-model and intra-model hidden insights. The inter-model hidden insights encompass the embedding vectors and logit vectors derived from other pretrained models using the same graph data. The intra-model hidden insights incorporate the embedding vectors of other nodes from the same GNN model. To optimize the suitability of hidden insights for GNN model training, we conduct a theoretical analysis of the influence of various forms of the transformed logits and the parameter T\nin the data transformation function. Based on this analysis, a method for setting dynamic personalized parameters in the data transformation is proposed, which is tailored to the current state of each node in the GNN model. To integrate multiple sources of hidden insights, we propose ALC, an algorithm that dynamically sets appropriate combination coefficients for various loss terms. The experimental results show that GraphHI can boost the performance of GNN models using different pretrained models in four different tasks.}
}


@inproceedings{DBLP:conf/icde/XiaC0GZYL24,
	author = {Jun Xia and
                  Shaorong Chen and
                  Yue Liu and
                  Zhangyang Gao and
                  Jiangbin Zheng and
                  Xihong Yang and
                  Stan Z. Li},
	title = {DiscoGNN: {A} Sample-Efficient Framework for Self-Supervised Graph
                  Representation Learning},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {2876--2888},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00223},
	doi = {10.1109/ICDE60146.2024.00223},
	timestamp = {Tue, 29 Oct 2024 16:54:59 +0100},
	biburl = {https://dblp.org/rec/conf/icde/XiaC0GZYL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Self-supervised graph representation learning has received increasing research interest recently, with generative and contrastive modeling being two dominant ways. Typically, generative learning first masks parts of each graph and then recovers the masked parts based on the encoding results of the corrupted graph. However, these methods only mask fixed parts of each graph and fail to train on all the nodes and edges, which hinders them from getting the most out of each graph. As a remedy, we propose a novel self-supervised strategy, dubbed DetCor, where we first randomly replace some nodes and edges with alternative ones and then pre-train GNNs to detect and correct the replaced ones from all the nodes and edges. Additionally, for graph-level learning, the vanilla contrastive framework cannot reflect the distinction between the in-batch negatives. To alleviate this issue, we propose RankGCL, which enables the contrastive framework to capture the similarity ranking information between graphs and shows special superiority in graph similarity-based practical tasks. DetCor and RankGCL together constitute a unified self-supervised framework, DiscoGNN, which matches or outperforms state-of-the-art strategies on multiple datasets from various domains. Also, DiscoGNN is a sample-efficient framework that can achieve better performance than competitive methods with much less pre-training data. We release the codes at: https://github.com/junxia97/DiscoGNN-ICDE.}
}


@inproceedings{DBLP:conf/icde/LiuWYLFWZS24,
	author = {Ziyang Liu and
                  Chaokun Wang and
                  Liqun Yang and
                  Yunkai Lou and
                  Hao Feng and
                  Cheng Wu and
                  Kai Zheng and
                  Yang Song},
	title = {Incorporating Dynamic Temperature Estimation into Contrastive Learning
                  on Graphs},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {2889--2903},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00224},
	doi = {10.1109/ICDE60146.2024.00224},
	timestamp = {Tue, 01 Oct 2024 08:25:47 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LiuWYLFWZS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Contrastive learning, a powerful self-supervised learning paradigm, has shown its efficacy in learning embed dings from independent and identically distributed (IID) as well as non-IID data without relying on label information. Since high-quality discriminative embeddings form a rich embedding space, which benefits model performance on downstream tasks, it is necessary to study how to improve the quality of contrastive node embeddings in graph contrastive learning. However, there has been limited research on this area. In this paper, we investigate how to generate high-quality contrastive node embeddings based on an in-depth analysis of graph contrastive losses. Firstly, we propose a novel and effective method, GLATE, for estimating the temperatures in three mainstream graph contrastive losses during the training phase. Secondly, we conduct the derivation of GLATE, and the derivation results reveal the specific relationship between the quality of contrastive node embeddings and tem-peratures. Finally, the extensive experiments on 16 benchmark datasets demonstrate that GLATE consistently outperforms the state-of-the-art graph contrastive learning models in terms of both model performance and training efficiency.}
}


@inproceedings{DBLP:conf/icde/ChenWL00024,
	author = {Qizhi Chen and
                  Ke Wang and
                  Aoran Li and
                  Yuhan Wu and
                  Tong Yang and
                  Bin Cui},
	title = {Newton Sketches: Estimating Node Intimacy in Dynamic Graphs Using
                  Newton's Law of Cooling},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {2904--2916},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00225},
	doi = {10.1109/ICDE60146.2024.00225},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ChenWL00024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Dynamic graphs are gaining importance in many real-world applications based on different graph queries. Due to the large volume and high dynamicity, people resort to compute approximations to answer graph queries. However, previous work primarily evaluates the relationship between nodes based on frequency, which is not sufficient in many cases. We observe that this relationship varying process is highly similar to the water cooling process in nature. Based on the observation, we formulate a new concept Intimacy with Newton's law of cooling, to illustrate the relationship between nodes. Currently, there is no prior algorithm tailored for Intimacy estimation. Because Intimacy varies in every time unit, the main challenge lies in how to record and update the Intimacy efficiently. In this paper, we propose a novel technique named Newton-Observe to address this challenge. The key idea of Newton-Observe is that we only decay the Intimacy when we observe/query it. Based on Newton-Observe, we develop a series of Newton sketches to answer three fundamental tasks of Intimacy in dynamic graphs. We theoretically prove that the Newton sketch can estimate the Intimacy within an additive constant error to the real Intimacy. Our experiments on real-world datasets and synthetic datasets show that Newton-Observe outperform the strawman solution by up to\n570×\nsmaller ARE and improve the throughput by up to\n1.62×\n. All source codes are open sourced at Github anonymously.}
}


@inproceedings{DBLP:conf/icde/PapadiasKPQM24,
	author = {Serafeim Papadias and
                  Zoi Kaoudi and
                  Varun Pandey and
                  Jorge{-}Arnulfo Quian{\'{e}}{-}Ruiz and
                  Volker Markl},
	title = {Counting Butterflies in Fully Dynamic Bipartite Graph Streams},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {2917--2930},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00226},
	doi = {10.1109/ICDE60146.2024.00226},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/PapadiasKPQM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A bipartite graph extensively models relationships between real-world entities of two different types, such as user-product data in e-commerce. Such graph data are inherently becoming more and more streaming, entailing continuous insertions and deletions of edges. A butterfly (i.e., 2 x 2 bi-clique) is the smallest non-trivial cohesive structure that plays a crucial role. Counting such butterfly patterns in streaming bipartite graphs is a core problem in applications such as dense subgraph discovery and anomaly detection. Yet, existing approximate solutions consider insert-only streams and, thus, achieve very low accuracy in fully dynamic bipartite graph streams that involve both insertions and deletions of edges. Adapting them to consider deletions is not trivial either, because different sampling schemes and new accuracy analyses are required. We propose Abacus, a novel approximate algorithm that counts butterflies in the presence of both insertions and deletions by utilizing sampling. We prove that Abacus always delivers unbiased estimates of low variance. Furthermore, we extend Abacus and devise a parallel mini-batch variant, namely, ParAbacus, which counts butterflies in parallel. ParAbacus counts butterflies in a load-balanced manner using versioned samples, which results in significant speedup and is thus ideal for critical applications in the streaming environment. We evaluate ABACUS/PARABACUS using a diverse set of real bipartite graphs and assess its performance in terms of accuracy, throughput, and speedup. The results indicate that our proposal is the first capable of efficiently providing accurate butterfly counts in the most generic setting, i.e., a fully dynamic graph streaming environment that entails both insertions and deletions. It does so without sacrificing throughput, and even improves it with the parallel version.}
}


@inproceedings{DBLP:conf/icde/ZhangG0CHSY024,
	author = {Wentao Zhang and
                  Xinyi Gao and
                  Ling Yang and
                  Meng Cao and
                  Ping Huang and
                  Jiulong Shan and
                  Hongzhi Yin and
                  Bin Cui},
	title = {{BIM:} Improving Graph Neural Networks with Balanced Influence Maximization},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {2931--2944},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00228},
	doi = {10.1109/ICDE60146.2024.00228},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhangG0CHSY024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The imbalanced data classification problem has aroused lots of concerns from both academia and industry since data imbalance is a widespread phenomenon in many real-world scenarios. Although this problem has been well researched from the view of imbalanced class samples, we further argue that graph neural networks (GNNs) expose a unique source of imbalance from the influenced nodes of different classes of labeled nodes, i.e., labeled nodes are imbalanced in terms of the number of nodes they influenced during the influence propagation in GNNs. To tackle this previously unexplored influence-imbalance issue, we connect social influence maximization with the imbalanced node classification problem and propose balanced influence maximization (BIM). Specifically, BIM greedily assigns the pseudo label to the node which can maximize the number of influenced nodes in GNN training while making the influence of each class more balance. Experimental results on five public datasets demonstrate the effectiveness of our method in relieving the influence-imbalance issue. For example, when training a GCN with an imbalance ratio of 0.1, BIM significantly outperforms the most competitive baseline by 0.6% -9.8% in five public datasets in terms of the F1 score.}
}


@inproceedings{DBLP:conf/icde/0002LWJZM24,
	author = {Zhenhua Huang and
                  Kunhao Li and
                  Shaojie Wang and
                  Zhaohong Jia and
                  Wentao Zhu and
                  Sharad Mehrotra},
	title = {{SES:} Bridging the Gap Between Explainability and Prediction of Graph
                  Neural Networks},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {2945--2958},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00229},
	doi = {10.1109/ICDE60146.2024.00229},
	timestamp = {Sun, 06 Oct 2024 21:04:56 +0200},
	biburl = {https://dblp.org/rec/conf/icde/0002LWJZM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Despite the Graph Neural Networks' (GNNs) pro-ficiency in analyzing graph data, achieving high-accuracy and interpretable predictions remains challenging. Existing GNN interpreters typically provide post-hoc explanations disjointed from GNNs' predictions, resulting in misrepresentations. Self-explainable GNNs offer built-in explanations during the training process. However, they cannot exploit the explanatory outcomes to augment prediction performance, and they fail to provide high-quality explanations of node features and require additional processes to generate explainable subgraphs, which is costly. To address the aforementioned limitations, we propose a self-explained and self-supervised graph neural network (SES) to bridge the gap between explainability and prediction. SES comprises two processes: explainable training and enhanced predictive learning. During explainable training, SES employs a global mask generator co-trained with a graph encoder and directly produces crucial structure and feature masks, reducing time consumption and providing node feature and subgraph explanations. In the enhanced predictive learning phase, mask-based positive-negative pairs are constructed utilizing the ex-planations to compute a triplet loss and enhance the node representations by contrastive learning. Extensive experiments demonstrate the superiority of SES on multiple datasets and tasks. SES outperforms baselines on real-world node classification datasets by notable margins of up to 2.59% and achieves state-of-the-art (SOTA) performance in explanation tasks on synthetic datasets with improvements of up to 3.0%. Moreover, SES delivers more coherent explanations on real-world datasets, has a fourfold increase in Fidelity+ score for explanation quality, and demonstrates faster training and expla-nation generating times. To our knowledge, SES is a pioneering GNN to achieve SOTA performance on both explanation and prediction tasks.}
}


@inproceedings{DBLP:conf/icde/SunHWX24,
	author = {Longxu Sun and
                  Xin Huang and
                  Zheng Wu and
                  Jianliang Xu},
	title = {Efficient Cross-layer Community Search in Large Multilayer Graphs},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {2959--2971},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00230},
	doi = {10.1109/ICDE60146.2024.00230},
	timestamp = {Thu, 08 Aug 2024 08:10:24 +0200},
	biburl = {https://dblp.org/rec/conf/icde/SunHWX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Community search is a query-dependent graph task to find communities containing a given set of query vertices, which is useful for personalized search and recommendation. Recently, community search over multilayer networks has gained attention thanks to its strong ability to capture cross-layer relationships among diverse entities from multiple domains. This brings significant advantages against the classical studies of community search over only single-layer graphs. However, most existing multilayer community models suffer from two major limitations: 1) failure to identify informative communities with the most layers when a multilayer graph is associated with a large number of layers; 2) missing to distinguish the degree of connections in internal layers and cross-layers. To tackle the above limitations, this paper proposes a novel multilayer subgraph model called $(k, d)$ -core. A $(k,d)$ -core based community requires that every two layers have enough $k$ internal layer connections and $d$ cross-layer connections for each vertex in this community. We formulate the problem of multilayer community search (MCS-problem), which finds a $(k,d)$ -core connected subgraph $H$ containing query vertices to achieve the largest number of cross-layers. For cross-layer connectivity, we consider two-fold definitions of full-layer and path-layer connectivities. First, we consider a strong definition of full-layer connectivity, which constrains that every two layers are connected in $H$ . We show that the MCS-problem under full-layer connectivity is NP-hard. We propose two methods of exact exploration and heuristic search for finding M CS answers. Second, to improve the efficiency of community search, we further study a relaxation of path-layer connectivity, allowing two layers to be connected via a path of immediate layers. Then, we develop a fast search algorithm to identify path-layer-based communities and then refine them to full-layer answers. Furthermore, we develop a novel $(k,d){-}$ core index that effectively captures essential $(k,d)$ -core structure, including the neighborhood information, the layer connectivities, and the internal/cross-layer corenesses. Extensive experiments on nine real-world multilayer graphs demonstrate the effectiveness and efficiency of our M CS model and algorithms.}
}


@inproceedings{DBLP:conf/icde/CaoWLNCC24,
	author = {Hongtai Cao and
                  Qihao Wang and
                  Xiaodong Li and
                  Matin Najafi and
                  Kevin Chen{-}Chuan Chang and
                  Reynold Cheng},
	title = {Large Subgraph Matching: {A} Comprehensive and Efficient Approach
                  for Heterogeneous Graphs},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {2972--2985},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00231},
	doi = {10.1109/ICDE60146.2024.00231},
	timestamp = {Tue, 30 Jul 2024 08:18:21 +0200},
	biburl = {https://dblp.org/rec/conf/icde/CaoWLNCC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The subgraph matching problem is crucial in graph analysis, involving identifying all instances of a given pattern\nP\nwithin a graph\nG\n. Advances in this field aim to uncover larger patterns across diverse graph types and subgraph matching tasks. However, existing methods often prove inefficient for such tasks. To address this gap, we propose CSCE, which generates efficient plans for various problem settings. CSCE utilizes clustered compressed sparse rows for heterogeneous graphs and sequential candidate equivalence to reduce redundant computations. Moreover, our approach seamlessly supports different subgraph matching variants, such as edge-induced, vertex-induced, and homomorphic scenarios. Experiments show that our work is up to two orders of magnitude faster than the state of the art on graphs of millions scale.}
}


@inproceedings{DBLP:conf/icde/XuLWZZZ24,
	author = {Rongwei Xu and
                  Guanfeng Liu and
                  Yan Wang and
                  Xuyun Zhang and
                  Kai Zheng and
                  Xiaofang Zhou},
	title = {Adaptive Hypergraph Network for Trust Prediction},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {2986--2999},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00232},
	doi = {10.1109/ICDE60146.2024.00232},
	timestamp = {Tue, 13 Aug 2024 08:03:52 +0200},
	biburl = {https://dblp.org/rec/conf/icde/XuLWZZZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Trust plays an essential role in an individual's decision-making. Traditional trust prediction models rely on pairwise correlations to infer potential relationships between users. However, in the real world, interactions between users are usually complicated rather than pairwise only. Hypergraphs offer a flexible approach to modeling these complex high-order correlations (not just pairwise connections), since hypergraphs can leverage hyperedeges to link more than two nodes. However, most hypergraph-based methods are generic and cannot be well applied to the trust prediction task. In this paper, we propose an Adaptive Hypergraph Network for Trust Prediction (AHNTP), a novel approach that improves trust prediction accuracy by using higher-order correlations. AHNTP utilizes Motif-based PageRank to capture high-order social influence information. In addition, it constructs hypergroups from both node-level and structure-level attributes to incorporate complex correlation information. Furthermore, AHNTP leverages adaptive hypergraph Graph Convolutional Network (GCN) layers and multilayer perceptrons (MLPs) to generate comprehensive user embeddings, facilitating trust relationship prediction. To enhance model generalization and robustness, we introduce a novel supervised contrastive learning loss for optimization. Extensive experiments demonstrate the superiority of our model over the state-of-the-art approaches in terms of trust prediction accuracy.}
}


@inproceedings{DBLP:conf/icde/LiuWX024,
	author = {Haoyu Liu and
                  Yongcai Wang and
                  Xiaojia Xu and
                  Deying Li},
	title = {Bottom-up k-Vertex Connected Component Enumeration by Multiple Expansion},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {3000--3012},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00233},
	doi = {10.1109/ICDE60146.2024.00233},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LiuWX024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Bottom-up k-vertex connected component (k- VCC) enumeration methods, referred to as VCCE-BU, have exhib-ited better efficiency compared to the exact top-down k- VCC enumeration method (VCCE-TD). However, VCCE-BU has been found to have surprisingly low detection accuracy, that it may detect fewer k- VCC vertices than VCCE-TD. This raises the question of what causes VCCE-BU to have a low k-VCC enumeration quality. This paper investigates the reason and proposes that the local expansion should be reformulated as a Multiple vertex collaborative Expansion problem instead of the traditional Unitary Expansion (UE). A Multiple Expansion (ME) approach, which allows to expand multiple neighboring vertices jointly and collaboratively is proposed, which is proven exact in local expansion. However, the exact ME-based local expansion needs to explore large neighborhoods in each step, which is time-consuming. To address the efficiency issue, a Ring-based Multiple Expansion (RME) is proposed to conduct ME within one-hop neighbors. A maximum flow-based merging algorithm FBM is proposed for effective merging. A maximal clique and breath-first-search-based quick seeding algorithm QkVCS is proposed to generate k-VCC seeds efficiently. As a result, RIPPLE which integrates QkVCS+FBM+RME is presented as a new accurate and efficient bottom-up approach. Extensive verifications in real large-scale graph datasets demonstrate that even the single-thread RIPPLE is much more accurate and a magnitude faster than the state-of-the-art VCCE-BU method. We also demonstrate the effective speeding up to run RIPPLE in parallel.}
}


@inproceedings{DBLP:conf/icde/JiangZLLJZ0C24,
	author = {Guanxian Jiang and
                  Yunjian Zhao and
                  Yichao Li and
                  Zhi Liu and
                  Tatiana Jin and
                  Wanying Zheng and
                  Boyang Li and
                  James Cheng},
	title = {Wings: Efficient Online Multiple Graph Pattern Matching},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {3013--3027},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00260},
	doi = {10.1109/ICDE60146.2024.00260},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/JiangZLLJZ0C24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Finding query patterns in a graph is fundamental for graph data analytics. Existing works mostly focus on either finding a single query pattern or finding patterns in a static graph. However, many applications today need to match multiple query patterns against a dynamically changing graph, i.e., online multiple graph pattern matching (online multi-GPM). Online multi-GPM is challenging as it requires quick responses for timely business decision-making. This paper proposes Wings — a distributed system for online multi-GPM. The key to efficient multi-GPM is a query planner that optimizes query plans by maximizing computation sharing among multiple queries and minimizing intermediate matching results. In addition, we also design an efficient query executor for Wings with memory footprint control and runtime redundant processing elimination. Our experimental results verified that Wings' designs are efficient for online multi-GPM.}
}


@inproceedings{DBLP:conf/icde/CuiCYDF024,
	author = {Jinhao Cui and
                  Heyan Chai and
                  Xu Yang and
                  Ye Ding and
                  Binxing Fang and
                  Qing Liao},
	title = {{SGCL:} Semantic-aware Graph Contrastive Learning with Lipschitz Graph
                  Augmentation},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {3028--3041},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00235},
	doi = {10.1109/ICDE60146.2024.00235},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/CuiCYDF024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graph contrastive learning (GCL) has gained increasing interest as a solution for graph representation learning. In GCL, graph augmentation is essential to generate contrastive samples used for contrastive learning. Recently, most existing methods employ learnable graph view generators to augment graphs based on the node probability distribution adaptively. However, these methods cannot ensure that semantic-related nodes are preserved during graph augmentation, leading to performance degradation. To tackle this issue, we propose a novel approach called Semantic-aware Graph Contrastive Learning (SGCL), which can generate high-quality contrastive samples by only augmenting semantic-unrelated nodes so as to facilitate the performance of GCL on downstream tasks. Specifically, we first design a Lipschitz constant generator to compute the Lipschitz constants that measure the semantic relevance of each node. Then, we propose the Lipschitz graph augmentation to augment graphs while only dropping these semantic-unrelated nodes with small Lipschitz constants. Furthermore, we propose semanticaware contrastive learning to obtain more refined representations by contrasting the graph-level representation of anchor graphs and high-quality generated samples. Experimental results on unsupervised learning and transfer learning demonstrate the effectiveness of SGCL compared to state-of-the-art methods.}
}


@inproceedings{DBLP:conf/icde/GaoZYSN0Y24,
	author = {Xinyi Gao and
                  Wentao Zhang and
                  Junliang Yu and
                  Yingxia Shao and
                  Quoc Viet Hung Nguyen and
                  Bin Cui and
                  Hongzhi Yin},
	title = {Accelerating Scalable Graph Neural Network Inference with Node-Adaptive
                  Propagation},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {3042--3055},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00236},
	doi = {10.1109/ICDE60146.2024.00236},
	timestamp = {Sun, 06 Oct 2024 21:04:57 +0200},
	biburl = {https://dblp.org/rec/conf/icde/GaoZYSN0Y24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graph neural networks (GNNs) have exhibited exceptional efficacy in a diverse array of applications. However, the sheer size of large-scale graphs presents a significant challenge to real-time inference with GNNs. Although existing Scalable GNNs leverage linear propagation to preprocess the features and accelerate the training and inference procedure, these methods still suffer from scalability issues when making inferences on unseen nodes, as the feature preprocessing requires the graph to be known and fixed. To further accelerate Scalable GNNs inference in this inductive setting, we propose an online propagation framework and two novel node-adaptive propagation methods that can customize the optimal propagation depth for each node based on its topological information and thereby avoid redundant feature propagation. The trade-off between accuracy and latency can be flexibly managed through simple hyper-parameters to accommodate various latency constraints. Moreover, to compensate for the inference accuracy loss caused by the potential early termination of propagation, we further propose Inception Distillation to exploit the multi-scale receptive field information within graphs. The rigorous and comprehensive experimental study on public datasets with varying scales and characteristics demonstrates that the proposed inference acceleration framework outperforms existing state-of-the-art graph inference acceleration methods in terms of accuracy and efficiency. Particularly, the superiority of our approach is notable on datasets with larger scales, yielding a 75\\times\ninference speedup on the largest Ogbn-products dataset.}
}


@inproceedings{DBLP:conf/icde/Gao0ZZN0Y24,
	author = {Xinyi Gao and
                  Tong Chen and
                  Yilong Zang and
                  Wentao Zhang and
                  Quoc Viet Hung Nguyen and
                  Kai Zheng and
                  Hongzhi Yin},
	title = {Graph Condensation for Inductive Node Representation Learning},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {3056--3069},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00237},
	doi = {10.1109/ICDE60146.2024.00237},
	timestamp = {Sun, 06 Oct 2024 21:04:57 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Gao0ZZN0Y24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graph neural networks (GNNs) encounter significant computational challenges when handling large-scale graphs, which severely restricts their efficacy across diverse applications. To address this limitation, graph condensation has emerged as a promising technique, which constructs a small synthetic graph for efficiently training GNNs while retaining performance. However, due to the topology structure among nodes, graph condensation is limited to condensing only the observed training nodes and their corresponding structure, thus lacking the ability to effectively handle the unseen data. Consequently, the original large graph is still required in the inference stage to perform message passing to inductive nodes, resulting in substantial computational demands. To overcome this issue, we propose mapping-aware graph condensation (MCond), explicitly learning the one-to-many node mapping from original nodes to synthetic nodes to seamlessly integrate new nodes into the synthetic graph for inductive representation learning. This enables direct information propagation on the synthetic graph, which is much more efficient than on the original large graph. Specifically, MCond employs an alternating optimization scheme with innovative loss terms from transductive and inductive perspectives, facilitating the mutual promotion between graph condensation and node mapping learning. Extensive experiments demonstrate the efficacy of our approach in inductive inference. On the Reddit dataset, MCond achieves up to 121.5× inference speedup and 55.9× reduction in storage requirements compared with counterparts based on the original graph.}
}


@inproceedings{DBLP:conf/icde/Galvizo024,
	author = {Glenn Galvizo and
                  Michael J. Carey},
	title = {Graphix: "One User's {JSON} is Another User's Graph"},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {3070--3083},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00238},
	doi = {10.1109/ICDE60146.2024.00238},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Galvizo024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The increasing prevalence of large graph data has produced a variety of research and applications tailored toward graph data management. Users aiming to perform graph analytics will typically start by importing existing data into a separate graph-purposed storage engine. The cost of maintaining a separate system (e.g., the data copy, the associated queries, etc …) just for graph analytics may be prohibitive for users with Big Data. In this paper, we introduce Graphix and show how it enables property graph views of existing document data in AsterixDB, a Big Data management system boasting a partitioned-parallel query execution engine. We explain a) the graph view user model of Graphix, b)\ngSQL\n++\n, a novel query language extension for synergistic document-based navigational pattern matching, and c) how edge hops are evaluated in a parallel fashion. We then compare queries authored in\ngSQL\n++\nagainst versions in other leading query languages. Finally, we evaluate our approach against a leading native graph database, Neo4j, and show that Graphix is appropriate for operational and analytical workloads, especially at scale.}
}


@inproceedings{DBLP:conf/icde/GaoLYZ24,
	author = {Chuchu Gao and
                  Youhuan Li and
                  Zhibang Yang and
                  Xu Zhou},
	title = {CSM-TopK: Continuous Subgraph Matching with TopK Density Constraints},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {3084--3097},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00239},
	doi = {10.1109/ICDE60146.2024.00239},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/GaoLYZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Continuous subgraph matching (CSM) is an important problem of graph analysis over dynamic graphs. Given a query graph, existing CSM efforts return numerous matches, which may overwhelm analysts. In addition, they do not consider weighted graphs that are ubiquitous in many real-world applications, such as payment networks where each edge has a weight to represent a transaction amount. Over these weighted graphs, matches of the given query graph have diverse priorities for analysis if they own different densities. In this paper, we propose a new problem of CSM-TopK to compute\nk\nmatches of a given query graph with the highest densities over a dynamic weighted graph and prove it to be NP-hard. To compute the CSM-TopK effectively, we first define a star-structured subquery, based on which we design two lightweight indexes, called global and local MWstar, respectively. In particular, the global MWstar maintains the maximum weights of all partial matches of each specific star-structured subquery. Differently, the local MW star is designed based on the corresponding maximum weight distribution for each specific data vertex. Additionally, a query-dependent graph compacted technique is introduced to further improve the performance on both time and space. Extensive experiments over real-world datasets show that our MW star- based approaches surpass the comparative ones by at least two orders of magnitude.}
}


@inproceedings{DBLP:conf/icde/WuSWZ00024,
	author = {Yanping Wu and
                  Renjie Sun and
                  Xiaoyang Wang and
                  Ying Zhang and
                  Lu Qin and
                  Wenjie Zhang and
                  Xuemin Lin},
	title = {Efficient Maximal Temporal Plex Enumeration},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {3098--3110},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00240},
	doi = {10.1109/ICDE60146.2024.00240},
	timestamp = {Tue, 30 Jul 2024 08:18:20 +0200},
	biburl = {https://dblp.org/rec/conf/icde/WuSWZ00024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Maximal k-plex enumeration is an important problem in graph analysis and can find many real-world applications. A k-plex is a subgraph in which every vertex can miss edges to at most\nk\nvertices (including itself). Previous studies mainly focus on static graphs. However, in reality, relationships between two entities often occur at some specific timestamps, which can be modeled as temporal graphs. Directly extending the k-plex model may fail to find some critical groups in temporal graphs, which exhibit certain frequent occurring phenomenon. To fill the gap, in this paper, we propose a novel model called\n(k, l)\n-plex, which is a vertex set that exists in no less than\nI\ntimestamps, at each of which the subgraph induced is a\nk\n-plex. To identify practical results, we introduce the concept of large maximal\n(k, l)\n-plex (MalKLP), i.e., maximal\n(k, l)\n-plex with size no less than a given threshold. In this paper, we conduct the first attempt to propose and investigate the MalKLP enumeration problem, which is proved to be NP-hard. A reasonable baseline method called KLPE-BK is developed by extending the Bron-Kerbosch framework. To overcome the three limitations in KLPE-BK and scale for larger graphs, novel optimized strategies are proposed, including graph reduction, search branch pruning and maximality checking approaches. Finally, we present our optimized algorithm KLPE+ by integrating the techniques proposed. Comprehensive experiments on 8 real-world datasets are conducted to validate the efficiency and scalability of the proposed techniques. Compared with the baseline method, KLPE + can achieve up to two orders of magnitude speedup. A case study is conducted to verify the effectiveness of our model.}
}


@inproceedings{DBLP:conf/icde/ChenCLFLW24,
	author = {Yonghao Chen and
                  Ruibing Chen and
                  Qiaoyun Li and
                  Xiaozhao Fang and
                  Jiaxing Li and
                  Wai Keung Wong},
	title = {Denoising High-Order Graph Clustering},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {3111--3124},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00241},
	doi = {10.1109/ICDE60146.2024.00241},
	timestamp = {Sun, 06 Oct 2024 21:04:56 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ChenCLFLW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {High-Order Graph (HOG) clustering has received much attention for its advantage of exploiting the rich intrinsic structure of data. However, the construction of HOG involves the generation of a large number of redundant walks, which dilutes the useful walks and thus leads to untrustworthy high-order similarity and, consequently, suboptimal clustering results may be obtained. We formalize this issue as the Weight Explosion (WE) problem. Furthermore, current works rarely focus on exploiting the correlation between multi-order graphs that can capture high-order relations at various levels. In this paper, we first analyze the pattern of redundant walks, also termed as noise, and subsequently propose a novel\nh\n-length Simple Path Search (\nh\n-SPS) algorithm to solve the WE problem.\nh\n-SPS aims to find valid walks to denoise HOG and thus avoids enumerating walks to report the similarity. Regarding the second problem, we propose a multi-order graphs fusion method, which adaptively integrates graphs of varying orders by solving a convex problem. This allows us to capture information across different order levels effectively. Extensive experiments on benchmark datasets demonstrate that our method 1 1 https://github.com/YonghaoChen511/DenoHOG can effectively solve the proposed WE problem, while also well exploiting the correlation of multi-order graphs.}
}


@inproceedings{DBLP:conf/icde/WangZCZ24,
	author = {Pinghui Wang and
                  Yuanming Zhang and
                  Kuankuan Cheng and
                  Junzhou Zhao},
	title = {A Revisit to Graph Neighborhood Cardinality Estimation},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {3125--3137},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00242},
	doi = {10.1109/ICDE60146.2024.00242},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/WangZCZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graph data are ubiquitous in real-world systems such as social networks and protein-protein interaction networks. In many applications, nodes usually are associated with real-value attributes, e.g., age, income, and wealth. Recently, industry and research communities have attracted attention to mining and learning attribute graphs. In this paper, we study the problem of calculating the general neighborhood cardinality of each node\nv\nin the graph, i.e., the sum of non-negative attribute values of the nodes in the\nk\n-hop neighborhood of a node\nv\n. The naive solution is to run a\nk\n-step breadth-first-search (BFS) algorithm starting from each node and storing all visited nodes' attributes. Clearly, the time complexity of this solution is\nO(|V|\nd\nk\nmax\n)\n, where\n|V|\nis the number of nodes and\nd\nmax\nis the maximum node degree in the graph. In real-world networks such as Twitter,\nd\nmax\nis over\n3×1\n0\n6\n. Therefore, it is infeasible to compute the neighborhood cardinality of nodes exactly in such massive networks even if we set\nk=2\n. To solve this problem, we propose efficient methods to compute the neighborhood cardinality of graphs with non-negative node attributes and binary node attributes, respectively. Extensive experiments on large real-world networks show the efficiency and effectiveness of our methods.}
}


@inproceedings{DBLP:conf/icde/WuYLMZ24,
	author = {Anbiao Wu and
                  Ye Yuan and
                  Changsheng Li and
                  Yuliang Ma and
                  Hao Zhang},
	title = {Attributed Network Embedding in Streaming Style},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {3138--3150},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00243},
	doi = {10.1109/ICDE60146.2024.00243},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/WuYLMZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Attributed network embedding (ANE) can learn low-dimensional embeddings for nodes in attributed graphs, which can facilitate several data analysis tasks. However, the existing ANE methods fail to tackle scenarios involving the continuous generation of attributes. The ongoing generation of attributes accumulates numerous attributes, incurring high storage costs in existing methods. Furthermore, due to storage limitations, old attributes will be discarded as new ones are generated, existing methods struggle to integrate the new attribute information into embeddings generated from old attributes. Therefore, we propose a novel ANE framework named SANE (Streaming-style ANE), featuring a “memory” capability - that is, when updating the embeddings for new attributes, old attribute information can be partly preserved. In SANE, we first define forward and backward affinity between nodes and attributes by reviewing a node as source or target node. The definition guides quick computation of affinity vectors that integrate both topological and attribute information. Meanwhile, we propose an augmentation strategy to enrich node attribute information for enhance the quality of node embeddings. Leveraging the augmented attributes, we iteratively generate forward and backward affinity vectors, providing quantification of node-attribute affinity in two directions. Subsequently, we achieve a streaming-style update of node embeddings by employing matrix sketching technology on these iteratively generated vectors. Furthermore, capitalizing on the mergeability of matrix sketching, we efficiently integrate information of new generated attributes into node embeddings. Extensive experiments on 5 real datasets demonstrate that SANE surpasses the state-of-the-art algorithms in node classification and link prediction. SANE's ability to incorporate new attribute information into embeddings in a fast manner is validated through adequate simulation experiments.}
}


@inproceedings{DBLP:conf/icde/Yuan0HA0024,
	author = {Lyuheng Yuan and
                  Da Yan and
                  Jiao Han and
                  Akhlaque Ahmad and
                  Yang Zhou and
                  Zhe Jiang},
	title = {Faster Depth-First Subgraph Matching on GPUs},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {3151--3163},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00244},
	doi = {10.1109/ICDE60146.2024.00244},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Yuan0HA0024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Subgraph search problems such as maximal clique enumeration and subgraph matching generate a search-space tree which is traversed in depth-first manner by serial backtracking algorithms that are recursive. Since Jenkins et al. reported the backtracking paradigm to be sub-optimal for GPU acceleration, breadth-first traversal of the search-space tree is widely adopted by GPU algorithms. However, they produce a lot of intermediate subgraphs that exhaust the GPU device memory. Recent works revive the depth-first backtracking paradigm for GPU acceleration, where each warp is a basic processing unit with its own stack in device memory for subgraph backtracking. However, they adopt complicated methods for load balancing that incur a lot of overheads. They also use hardcoded fixed space for stacks that is determined ad-hoc and may lead to inaccuracy when the allocated space is insufficient. In this paper, we use subgraph matching as a case study to propose novel depth-first GPU solutions to address the above problems. Our approach, called T-DFS, decomposes computation into independent tasks that process search-space subtrees, which are managed by an efficient lock-free circular task queue. Tasks are distributed to different warps for parallel processing, and a novel timeout mechanism is used to eliminate straggler tasks to ensure load balancing. We also support flexible and fine-grained dynamic memory allocation for stack spaces to avoid the stack space allocation pitfalls of existing works. Extensive experiments on real graphs show that T-DFS significantly outperforms existing depth-first GPU solutions for the subgraph matching application.}
}


@inproceedings{DBLP:conf/icde/YuanA0HAY024,
	author = {Lyuheng Yuan and
                  Akhlaque Ahmad and
                  Da Yan and
                  Jiao Han and
                  Saugat Adhikari and
                  Xiaodong Yu and
                  Yang Zhou},
	title = {G\({}^{\mbox{2}}\)-AIMD: {A} Memory-Efficient Subgraph-Centric Framework
                  for Efficient Subgraph Finding on GPUs},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {3164--3177},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00245},
	doi = {10.1109/ICDE60146.2024.00245},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/YuanA0HAY024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Finding all those subgraphs of a big graph that satisfy certain conditions (aka. subgraph finding) is useful in many applications such as community detection and subgraph matching. These problems often generate a search-space tree with size exponential to the size of the input graph. GPUs with thousands of cores are a natural choice to speed up subgraph finding, but existing GPU solutions either conduct BFS on the search-space tree which leads to memory overflow due to intermediate subgraph-size explosion, or they conduct DFS on the search-space tree which is memory-efficient but can be 2 orders of magnitude slower than a BFS solution. In this paper, we present\nG\n2\n-AIMD, a subgraph-centric framework for efficient subgraph Search on GPUs, which enjoys the efficiency of BFS on the search-space tree, while avoids intermediate subgraph-size explosion with novel system designs such as adaptive chunk-size adjustment and host-memory subgraph buffering, inspired by the additive-increase/multiplicative-decrease (AIMD) algorithm in TCP congestion control.\nG\n2\n-AIMD provides a convenient subgraph-centric programming interface to facilitate the implementation of subgraph finding algorithms on top, so as to enjoy the above performance merits.\nG\n2\n−\nAIMD also supports multi-GPU execution where each GPU only needs to load a fraction of the input graph. To demonstrate the efficiency and scalability of\nG\n2\n-AIMD, two algorithms were implemented on top with additional optimization techniques, and they significantly outperform the existing GPU solutions.}
}


@inproceedings{DBLP:conf/icde/00130X24,
	author = {Dong Chen and
                  Xiang Zhao and
                  Weidong Xiao},
	title = {Fine-Grained Anomaly Detection on Dynamic Graphs via Attention Alignment},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {3178--3190},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00246},
	doi = {10.1109/ICDE60146.2024.00246},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/00130X24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Dynamic graphs are ubiquitous in our lives, yet they are also susceptible to the risks imposed by malicious activities. However, identifying anomalies in these dynamic graphs presents a challenging task due to the complex graph structures. Existing methods for dynamic anomaly detection primarily focus on learning representations for each timestamp and using sequence modeling techniques to capture and model the temporal information. Despite extensive research, dynamic anomaly detection still faces two key challenges. First, existing methods are limited in effectively using fine-grained temporal information. Second, they have limited generalization capabilities under unsupervised settings. Overcoming these challenges is crucial for advances in dynamic anomaly detection. In this paper, we propose a novel unsupervised anomaly detection method for dynamic graphs. Our approach leverages complex temporal information through fine-grained sampling and embedding modules. Additionally, we introduce an attention alignment strategy to minimize discrepancies in contextual attention between source and target nodes. Through a comprehensive evaluation, we demonstrate that our strategy effectively mitigates overfitting and improves generalization. Experiments on ten dynamic graph datasets validate the effectiveness of our proposed method in detecting anomalies.}
}


@inproceedings{DBLP:conf/icde/QiuLKCG24,
	author = {Linshan Qiu and
                  Zhonggen Li and
                  Xiangyu Ke and
                  Lu Chen and
                  Yunjun Gao},
	title = {Accelerating Biclique Counting on {GPU}},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {3191--3203},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00247},
	doi = {10.1109/ICDE60146.2024.00247},
	timestamp = {Tue, 30 Jul 2024 08:18:21 +0200},
	biburl = {https://dblp.org/rec/conf/icde/QiuLKCG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Counting (\np\n, q)-bicliques in bipartite graphs poses a foundational challenge with broad applications, from densest sub-graph discovery in algorithmic research to personalized content recommendation in practical scenarios. Despite its significance, current leading (\np\n, q)-biclique counting algorithms fall short, particularly when faced with larger graph sizes and clique scales. Fortunately, the problem's inherent structure, allowing for the independent counting of each biclique starting from every vertex, combined with a substantial set intersections, makes it highly amenable to parallelization. Recent successes in GPU-accelerated algorithms across various domains motivate our exploration into harnessing the parallelism power of GPUs to efficiently address the (\np\n, q)-biclique counting challenge. We introduce GBC (GPU-based Biclique Counting), a novel approach designed to enable efficient and scalable (\np\n, q)-biclique counting on GPUs. To address major bottleneck arising from redundant comparisons in set intersections (occupying an average of 90% of the runtime), we introduce a novel data structure that hashes adjacency lists into truncated bitmaps to enable efficient set intersection on GPUs via bit-wise AND operations. Our in-novative hybrid DFS-BFS exploration strategy further enhances thread utilization and effectively manages memory constraints. A composite load balancing strategy, integrating pre-runtime and runtime workload allocation, ensures equitable distribution among threads. Additionally, we employ vertex reordering and graph partitioning strategies for improved compactness and scalability. Experimental evaluations on eight real-life and two synthetic datasets demonstrate that GBC outperforms state-of-the-art algorithms by a substantial margin. In particular, GBC achieves an average speedup of\n497.8×\n, with the largest instance achieving a remarkable\n1217.7×\nspeedup when\np=q=8\n.}
}


@inproceedings{DBLP:conf/icde/QiuCJKGLZ24,
	author = {Linshan Qiu and
                  Lu Chen and
                  Hailiang Jie and
                  Xiangyu Ke and
                  Yunjun Gao and
                  Yang Liu and
                  Zetao Zhang},
	title = {GPU-Accelerated Batch-Dynamic Subgraph Matching},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {3204--3216},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00248},
	doi = {10.1109/ICDE60146.2024.00248},
	timestamp = {Tue, 30 Jul 2024 08:18:20 +0200},
	biburl = {https://dblp.org/rec/conf/icde/QiuCJKGLZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Subgraph matching has garnered increasing attention for its diverse real-world applications. Given the dynamic nature of real-world graphs, addressing evolving scenarios with-out incurring prohibitive overheads has been a focus of research. However, existing approaches for dynamic subgraph matching often proceed serially, retrieving incremental matches for each updated edge individually. This approach falls short when handling batch data updates, leading to a decrease in system throughput. Leveraging the parallel processing power of GPUs, which can execute a massive number of cores simultaneously, has been widely recognized for performance acceleration in various domains. Surprisingly, systematic exploration of subgraph matching in the context of batch-dynamic graphs, particularly on a GPU platform, remains untouched. In this paper, we bridge this gap by introducing an efficient framework, GAMMA (GPU-Accelerated Batch-Dynamic Subgraph Matching). Our approach features a DFS-based warp-centric batch-dynamic subgraph matching algorithm. To ensure load balance in the DFS-based search, we propose warp-level work stealing via shared memory. Additionally, we introduce coalesced search to reduce redundant computations. Comprehensive experiments demonstrate the superior performance of GAMMA. Compared to state-of-the-art algorithms, GAMMA showcases a performance improvement up to hundreds of times.}
}


@inproceedings{DBLP:conf/icde/JiangZLDW24,
	author = {Jiaqi Jiang and
                  Qi Zhang and
                  Rong{-}Hua Li and
                  Qiangqiang Dai and
                  Guoren Wang},
	title = {{I/O} Efficient Max-Truss Computation in Large Static and Dynamic
                  Graphs},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {3217--3229},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00249},
	doi = {10.1109/ICDE60146.2024.00249},
	timestamp = {Tue, 30 Jul 2024 08:18:19 +0200},
	biburl = {https://dblp.org/rec/conf/icde/JiangZLDW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cohesive sub graph mining has received much at-tention in the area of graph analysis. A k- truss, defined as a sub graph where each edge is associated with at least\nk−2\ntriangles, serves as a fundamental graph analysis tool. Among all k-trusses, the\nk\nmax\n-truss with the maximum\nk\nvalue holds significant importance in various practical applications such as community search and keyword retrieval. Furthermore, it is also closely related to many graph analysis problems, particularly those computational complexity problems parameterized by\nk\n. However, real-world graphs often exhibit large-scale characteris-tics, making it impractical to fully load them into main memory. In this paper, we investigate the problem of finding the\nk\nmax\n-truss in external memory settings. To address this problem, we propose an 110 efficient algorithm following a semi-external model, which only allows node information to be loaded into main memory. Our approach leverages greedy strategies and a binary search framework to efficiently find the\nk\nmax\n- truss. Subsequently, an elegant data structure is proposed to significantly reduce 110 costs. Furthermore, to address dynamic graph updates, we develop an 110 efficient\nk\nmax\n- truss maintenance algorithm based on the local-first update technique. To evaluate the performance of our algorithms, we conduct extensive experiments. The results demonstrate the high efficiency and scalability of our algorithms, which are at least two orders of magnitude faster in runtime and at least one order of magnitude lower in terms of 110 costs compared to the state-of-the-art solutions.}
}


@inproceedings{DBLP:conf/icde/MaYZ0WY0024,
	author = {Ziyi Ma and
                  Jianye Yang and
                  Xu Zhou and
                  Guoqing Xiao and
                  Jianhua Wang and
                  Liang Yang and
                  Kenli Li and
                  Xuemin Lin},
	title = {Efficient Multi-Query Oriented Continuous Subgraph Matching},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {3230--3243},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00250},
	doi = {10.1109/ICDE60146.2024.00250},
	timestamp = {Tue, 30 Jul 2024 08:18:18 +0200},
	biburl = {https://dblp.org/rec/conf/icde/MaYZ0WY0024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Continuous subgraph matching (CSM) is a critical task for analyzing dynamic graphs and has a wide range of applications, such as merchant fraud detection, cyber-attack hunting, and rumor detection. Although many efficient CSM algorithms have been recently proposed, they are mainly designed to process a single query. However, in some application scenarios, multi-query oriented continuous subgraph matching (MQCSM) may be of more interest. To our knowledge, the two existing solutions to MQCSM are outdated due to unsatisfactory performance. In this paper, we propose MQ-Match, an efficient approach to MQCSM. First, we design a compact yet effective index structure CCG, which maintains the local matching result of vertices in the data graph using a directed graph. The directed edges in CCG can be utilized as an effective pruning rule for the subsequent incremental matching algorithm when expanding a partial match. Then, we develop a computation sharing incremental matching algorithm. In specific, a set of matching trees is constructed based on the depth-first search trees of the query graphs. By utilizing CCG, we conduct subgraph matching for the matching tree to collect the incremental matches for the query graphs, where the common structures of query graphs are matched only once. Extensive experiments show that MQ-Match can achieve 3.1x-7071.4x speedup over the competitors, and consumes much less memory under the majority of the experiment settings.}
}


@inproceedings{DBLP:conf/icde/0001C0GJZ24,
	author = {Yishu Wang and
                  Jinlong Chu and
                  Ye Yuan and
                  Yu Gu and
                  Hangxu Ji and
                  Hao Zhang},
	title = {Label Constrained Reachability Queries on Time Dependent Graphs},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {3244--3256},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00251},
	doi = {10.1109/ICDE60146.2024.00251},
	timestamp = {Wed, 25 Sep 2024 16:58:42 +0200},
	biburl = {https://dblp.org/rec/conf/icde/0001C0GJZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Label-constrained reachability (LCR) has been ex-tensively studied. However, these studies have neglected two aspects: the label sequence and time-dependent properties. When processing reachability queries, not only label presence but also label sequence and time-dependent properties should be considered. Various real-world scenarios, including vehicular networks, computing networks, and biological networks, require such queries. In this paper, we present a formal definition of time-dependent label-constrained reachability (TDLCR) queries based on LCR. These queries require both label sequence and time-dependent constraints to be considered, thus introducing a higher level of complexity. To address this challenge, we propose two indexing algorithms that are optimized for the label constraint: OneL and TD2H. OneL builds a single-label index for each vertex and provides a baseline for solving the TDLCR problem. TD2H is based on classical 2-hop index with excellent query efficiency, while innovative pruning rules and vertex order strategies are proposed to reduce indexing overhead. To further balance indexing overhead and query efficiency and to optimize the time-dependent constraint, we introduce a BII algorithm. It effectively improves index construction efficiency by building only a local index instead of a global one. Finally, experiments on many real datasets demonstrate that although the BII has a slightly inferior query time to TD2H, it has a significant advantage in the index construction.}
}


@inproceedings{DBLP:conf/icde/MinJPGIH24,
	author = {Seunghwan Min and
                  Jihoon Jang and
                  Kunsoo Park and
                  Dora Giammarresi and
                  Giuseppe F. Italiano and
                  Wook{-}Shin Han},
	title = {Time-Constrained Continuous Subgraph Matching Using Temporal Information
                  for Filtering and Backtracking},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {3257--3269},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00252},
	doi = {10.1109/ICDE60146.2024.00252},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/MinJPGIH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Real-time analysis of graphs containing temporal information, such as social media streams, Q&A networks, and cyber data sources, plays an important role in various applications. Among them, detecting patterns is one of the fundamental graph analysis problems. In this paper, we study time-constrained continuous subgraph matching, which detects a pattern with a strict partial order on the edge set in real-time whenever a temporal data graph changes over time. We propose a new algorithm based on two novel techniques. First, we introduce a filtering technique called time-constrained matchable edge that uses temporal information for filtering with polynomial space. Second, we develop time-constrained pruning techniques that reduce the search space by pruning some of the parallel edges in backtracking, utilizing temporal information. Extensive experiments on real and synthetic datasets show that our approach outperforms the state-of-the-art algorithm by up to two orders of magnitude in terms of query processing time.}
}


@inproceedings{DBLP:conf/icde/SunHPLX24,
	author = {Zitan Sun and
                  Xin Huang and
                  Chengzhi Piao and
                  Cheng Long and
                  Jianliang Xu},
	title = {Adaptive Truss Maximization on Large Graphs: {A} Minimum Cut Approach},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {3270--3282},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00253},
	doi = {10.1109/ICDE60146.2024.00253},
	timestamp = {Tue, 22 Oct 2024 20:38:20 +0200},
	biburl = {https://dblp.org/rec/conf/icde/SunHPLX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A cohesive subgraph of k-truss requires that each edge has at least $(k-2)$ triangles, which has wide applications of modeling social communities and complex network visualization. Recently, the study of truss maximization has gained attention, which aims to enlarge $k$ -truss most by inserting $b$ new edges into a graph $G$ . However, existing maximization methods suffer from a stiff strategy of complete truss conversion, that is either converting the whole $(k-1)$ -truss component to k-truss or converting no edge to k-truss without using any budget. To tackle this bottleneck, we develop a novel partial conversion strategy to explore more insertion plans. Based on partial conversion strategy, we revisit the problem of truss maximization in this paper and propose adaptive solutions by achieving more new k-truss edges. Specifically, we first decompose all $(k-1)$ -truss into a series of disjoint components via the triangle connectivity, where each component's conversion is independent to each other. Then, for each $(k-1)$ -truss component, we explore possible insertion plans of partial conversions. An intuitive method is to randomly insert a budget no more than $b$ new edges and check the expected profit of new $k$ -truss edges. Obviously, this method is inefficient due to a large search space of edge insertions and many times of expensive $k$ -truss verification. To improve it, we propose a new minimum-cut based approach, which converts a subgraph of $(k-1)$ -truss component into a flow graph with weighted edges and finds a key of maximum-flow answer corresponding to a k-truss conversion plan with the minimum budget consumption. Next, we develop a new dynamic programming framework to find the best way to allocate the budget $b$ to all components. We design two fast dynamic programming algorithms and analyze the complexities theoretically. In addition, we explore the case of a large given budget $b$ and extend our techniques to handle the conversion of $(k-h)$ -truss into $k$ -truss for $2\\leq h\\leq k-2$ . Extensive experiment results demonstrate the superiority of our algorithms against the state-of-the-art methods.}
}


@inproceedings{DBLP:conf/icde/LiuGXBSC24,
	author = {Yanghao Liu and
                  Fangda Guo and
                  Bingbing Xu and
                  Peng Bao and
                  Huawei Shen and
                  Xueqi Cheng},
	title = {{SACH:} Significant-Attributed Community Search in Heterogeneous Information
                  Networks},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {3283--3296},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00254},
	doi = {10.1109/ICDE60146.2024.00254},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LiuGXBSC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Community search is a personalized community discovery problem aimed at finding densely-connected subgraphs containing the query vertex. In particular, the search for com-munities with high-importance vertices has recently received a great deal of attention. However, existing works mainly focus on conventional homogeneous networks where vertices are of the same type, but are not applicable to heterogeneous information networks (HINs) composed of multi-typed vertices and different semantic relations, such as bibliographic networks. In this paper, we study the problem of high-importance community search in HINs. A novel community model is introduced, named heterogeneous significant community (HSC), to unravel the closely connected vertices of the same type with high attribute values through multiple semantic relationships. An HSC not only maximizes the exploration of indirect relationships across entities of the anchor-type but incorporates their significance. To search the HSCs, we first develop online algorithms by exploiting both segmented-based meta-path expansion and significance incrernent. Specially, a solution space reuse strategy based on structural nesting is designed to boost the efficiency. In addition, we further devise a two-level index to support searching HSCs in optimal time, based on which a space-efficient compact index is proposed. Extensive experiments on real-world large-scale HINs demonstrate that our solutions are effective and efficient for searching HSCs, and the index-based algorithms are 2–4 orders of magnitude faster than online algorithms.}
}


@inproceedings{DBLP:conf/icde/000200O024,
	author = {Yuanyuan Xu and
                  Wenjie Zhang and
                  Ying Zhang and
                  Maria E. Orlowska and
                  Xuemin Lin},
	title = {TimeSGN: Scalable and Effective Temporal Graph Neural Network},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {3297--3310},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00255},
	doi = {10.1109/ICDE60146.2024.00255},
	timestamp = {Sun, 06 Oct 2024 21:04:56 +0200},
	biburl = {https://dblp.org/rec/conf/icde/000200O024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Temporal graph neural networks (T-GNNs) have emerged as leading approaches for representation learning over dynamic graphs. However, existing solutions typically suffer from exponential time complexity with model depth and excessive GPU memory usage due to acceleration techniques, and cannot handle large dynamic graphs. Furthermore, the core component of T-G NNs, temporal message passing, still predominantly derives from static GNNs. This neglects the distinct characteristics of two types of features, timestamps and edge features, and results in sub-optimal embedding quality. Consequently, existing T-GNNs fail to scale to large dynamic graphs and generalize well in unseen or complex scenarios, limiting their applicability. To bridge the gap, this paper first proposes a simple yet effective temporal message passing paradigm for T-GNNs, called the divided temporal message passing (DT-MP) paradigm, which enables effective feature learning for each feature type. We theoretically demonstrate that the DT-MP paradigm can reduce GPU memory usage compared to existing T-GNNs. Building on this foundation, we propose TimeSGN, a scalable and effective temporal graph neural network, which can handle billion-scale dynamic graphs. Specifically, we design a linear state updater to effectively capture node dynamic evolution and instantiate the DT-MP paradigm using two 1-layer self-attention mechanisms for temporal message passing to generate temporal embeddings. As a result, TimeSGN fundamentally avoids exponential time complexity and significantly reduces GPU memory usage. Extensive experiments demonstrate that TimeSGN achieves an average 10.56% improvement in accuracy, up to 42.48% reduction in training GPU memory, and up to 5 x speedup in per-epoch training time compared to the state-of-the-art baselines, while being one order of magnitude faster than vanilla T-GNNs.}
}


@inproceedings{DBLP:conf/icde/Li0H0024,
	author = {Mingdao Li and
                  Peng Peng and
                  Zheyuan Hu and
                  Lei Zou and
                  Zheng Qin},
	title = {Variable-Length Path Query Evaluation Based on Worst-Case Optimal
                  Joins},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {3311--3323},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00256},
	doi = {10.1109/ICDE60146.2024.00256},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Li0H0024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Variable-length path queries are essential for finding paths in a graph that adhere to a specified length constraint, utilizing only edges with labels from a restricted subset of the edge labels. These queries play a crucial role in graph analytics and are supported by practical graph query languages like Cypher in property graph systems and SPARQL 1.1 in RDF graph systems. In this paper, we present a novel solution for efficient evaluation of variable-length path queries, based on worst-case optimal joins. Our solution's core relies on a jumping-like worst-case optimal join technique, allowing us to select a query vertex order that differs completely from existing graph systems based on worst-case optimal joins. Furthermore, we introduce a cost-based dynamic programming optimizer that combines traditional and jumping-like worst-case optimal join techniques. We also propose an optimization technique to leverage intra-query parallelism during query evaluation. Through extensive experiments conducted on numerous synthetic and real RDF and property graphs, we demonstrate that the proposed technique achieves excellent performance.}
}


@inproceedings{DBLP:conf/icde/LiLCZLY024,
	author = {Ziming Li and
                  Youhuan Li and
                  Xinhuan Chen and
                  Lei Zou and
                  Yang Li and
                  Xiaofeng Yang and
                  Hongbo Jiang},
	title = {NewSP: {A} New Search Process for Continuous Subgraph Matching over
                  Dynamic Graphs},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {3324--3337},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00257},
	doi = {10.1109/ICDE60146.2024.00257},
	timestamp = {Wed, 14 Aug 2024 07:37:54 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LiLCZLY024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this study, we address the problem of unnecessary computations in traditional continuous subgraph matching (CSM) frameworks due to premature expansions of the search space in dynamic graphs. Traditional CSM frameworks expand small partial matches according to a specific matching order until the final results are obtained. This extension involves two sequential steps: computing candidate vertices for an unmapped query vertex and expanding the search space using these candidate data. However, this long-established search model has a potential flaw, as premature expansions of the search space can lead to unnecessary computations. To address this issue, we introduce a novel search process, NewSP. Unlike traditional methods, NewSP emphasizes operations rather than extensions, incorporating a unique feature of postponing expansion at the operation level. This approach prevents premature expansions without compromising the initial pruning power of the selected matching order. Furthermore, NewSP allows for multiple consecutive expansions, paving the way for a multi-expansion strategy for further optimization. Our model also enables the implementation of cache strategies for candidate set reuse, as it does not necessitate immediate expansion of a candidate set once identified. To improve performance, we propose an adaptive index filtering strategy independent of the specific index used. Comprehensive experiments demonstrate that our method improves by up to two to three orders of magnitude compared to traditional algorithms. A case study showed that NewSP can accelerate the majority of subgraph matching algorithms.}
}


@inproceedings{DBLP:conf/icde/Hu0ZQ0CLY24,
	author = {Chuhan Hu and
                  Ming Zhong and
                  Yuanyuan Zhu and
                  Tieyun Qian and
                  Ting Yu and
                  Hongyang Chen and
                  Mengchi Liu and
                  Jeffrey Xu Yu},
	title = {Querying Cohesive Subgraph Regarding Span-Constrained Triangles on
                  Temporal Graphs},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {3338--3350},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00258},
	doi = {10.1109/ICDE60146.2024.00258},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Hu0ZQ0CLY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The recent prosperity of temporal graph research redefines many traditional concepts on static graphs, such as triangle, motif, k\n-core, etc. Inspired by that, we propose a novel (k, \\delta)\n-truss on temporal graphs, which requires its triangles to exist in short enough time windows ever. The (k,\\delta)\n-truss satisfies both static and temporal cohesion, while the original k\n-truss is its special case when \\delta=\\infty\n. In order to address the (k, \\delta)\n-truss query, we propose both index-free and index-based approaches. By leveraging the dual containment relation on (k, \\delta)\n-trusses, our indexes can compress all (k, \\delta)\n-trusses losslessly into map or tree structures with dramatically less space, so that a specific (k,\\ \\delta)\n-truss can be retrieved from indexes in the optimal time. To enable our index to scale to large temporal graphs, we develop two index construction algorithms that can reduce redundant computation significantly, based on truss decomposition and truss maintenance respectively. The experimental results demonstrate that index-based approaches process queries in interactive time and outperform the index-free approach by 2~4 orders of magnitude, while indexes achieve compression ratios up to 10- 4 .}
}


@inproceedings{DBLP:conf/icde/QiuW0W24,
	author = {Dazhuo Qiu and
                  Mengying Wang and
                  Arijit Khan and
                  Yinghui Wu},
	title = {Generating Robust Counterfactual Witnesses for Graph Neural Networks},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {3351--3363},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00259},
	doi = {10.1109/ICDE60146.2024.00259},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/QiuW0W24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper introduces a new class of explanation structures, called robust counterfactual witnesses (RCWs), to provide robust, both counterfactual and factual explanations for graph neural networks. Given a graph neural network\nM\n, a robust counterfactual witness refers to the fraction of a graph\nG\nthat are counterfactual and factual explanation of the results of\nM\nover\nG\n, but also remains so for any “disturbed”\nG\nby flipping up to\nk\nof its node pairs. We establish the hardness results, from tractable results to co-NP-hardness, for verifying and generating robust counterfactual witnesses. We study such structures for GNN-based node classification, and present efficient algorithms to verify and generate RCWs. We also provide a parallel algorithm to verify and generate RCWs for large graphs with scalability guarantees. We experimentally verify our explanation generation process for benchmark datasets, and showcase their applications.}
}


@inproceedings{DBLP:conf/icde/WangYHXYFZWDJ24,
	author = {Yuxiang Wang and
                  Xiao Yan and
                  Chuang Hu and
                  Quanqing Xu and
                  Chuanhui Yang and
                  Fangcheng Fu and
                  Wentao Zhang and
                  Hao Wang and
                  Bo Du and
                  Jiawei Jiang},
	title = {Generative and Contrastive Paradigms Are Complementary for Graph Self-Supervised
                  Learning},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {3364--3378},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00234},
	doi = {10.1109/ICDE60146.2024.00234},
	timestamp = {Tue, 12 Nov 2024 07:57:55 +0100},
	biburl = {https://dblp.org/rec/conf/icde/WangYHXYFZWDJ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {For graph self-supervised learning (GSSL), masked autoencoder (MAE) follows the generative paradigm and learns to reconstruct masked graph edges or node features while contrastive learning (CL) maximizes the similarity between augmented views of the same graph. Existing works utilize MAE and CL separately but we observe that the MAE and CL paradigms are complementary and propose the graph contrastive masked autoencoder (GCMAE) framework to unify them. Specifically, by focusing on local edges or node features, MAE cannot capture global information of the graph and is sensitive to particular edges and features. On the contrary, CL excels in extracting global information because it considers the relation between graphs. As such, we equip GCMAE with an MAE branch and a CL branch, and the two branches share a common encoder, which allows the MAE branch to exploit the global information extracted by the CL branch. To force GCMAE to capture global graph structures, we train it to reconstruct the entire adjacency matrix instead of only the masked edges as in existing works. Moreover, a discrimination loss is proposed for feature reconstruction, which improves the disparity between node embeddings rather than reducing the reconstruction error to tackle the feature smoothing problem of MAE. We evaluate GCMAE on four popular graph tasks (i.e., node classification, node clustering, link prediction, and graph classification) and compare it with 14 state-of-the-art baselines. The results show that GCMAE consistently provides good accuracy across these tasks, and the maximum accuracy improvement is up to 3.2% compared with the best-performing baseline.}
}


@inproceedings{DBLP:conf/icde/00020WCHX24,
	author = {Yihang Cheng and
                  Lan Zhang and
                  Junyang Wang and
                  Xiaokai Chu and
                  Dongbo Huang and
                  Lan Xu},
	title = {FedMix: Boosting with Data Mixture for Vertical Federated Learning},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {3379--3392},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00261},
	doi = {10.1109/ICDE60146.2024.00261},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/00020WCHX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The need to safeguard data privacy and adhere to regulations such as GDPR creates data silos and has prompted the emergence and widespread adoption of techniques for distributed databases. To effectively explore the value of data across multiple organizations, techniques for data management, data analysis and data functionality from distributed databases have been proposed. Recently, Vertical Federated Learning (VFL) has become a solution with growing interests, which enables collaborative model training when data features are partitioned into multiple parts and are held by different parties. However, typical VFL methods heavily rely on private set intersection (PSI) to align data before training and only utilize aligned data for training. In this work, we provide a theoretical analysis to show that unaligned data actually contains valuable and rich features, and a thoughtful design that harnesses the potential of unaligned samples to significantly improve the performance of VFL models. Regrettably, many existing methods simply discard unaligned data, resulting in an irrecoverable loss of performance. To address this data sacrifice problem, we introduce the concept of data mixture, which enables the utilization of both aligned and unaligned data during training. Building upon the data mixture idea, we present FedMix, the first on-the-fly and distribution-agnostic framework designed to boost the performance of VFL models by leveraging unaligned data. A data seasoning approach is also designed to utilize auxiliary data lacking label information. Evaluations on diverse datasets under different settings demonstrate the effectiveness of the proposed FedMix compared with various SOTA approaches. FedMix achieves up to 15% model performance improvement and 30.5 hours time cost reduction.}
}


@inproceedings{DBLP:conf/icde/ShiWZLC024,
	author = {Jiyun Shi and
                  Yuqiao Wang and
                  Chi Zhang and
                  Zhaojing Luo and
                  Chengliang Chai and
                  Meihui Zhang},
	title = {DMRNet: Effective Network for Accurate Discharge Medication Recommendation},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {3393--3406},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00262},
	doi = {10.1109/ICDE60146.2024.00262},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ShiWZLC024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Electronic Health Records, which contain abundant structured data information of the patients, can help clinicians and data scientists address complex medical issues, particularly medication recommendation. The recommendation of medications is crucial for accurate and timely prescriptions. It is a nuanced task that entails analyzing various sources of healthcare data. Traditional medication recommendation is performed manually, which is labor-intensive and error-prone. The development of Electronic Health Records enables automatic medication recommendation. There are mainly two categories of methods for automatic medication recommendation. The first category uses the patients' current visit information and the drug-drug interactions (DDI). For these methods, both the comprehensive patient's medical history and the significant medication-diagnosis knowledge are not exploited appropriately. The second category utilizes longitudinal patient data, but different history visits are incorporated indiscriminately. Furthermore, in clinical practice, the associations between historical medications and future prescriptions are highlighted. However, they are less emphasized in current methods. Nevertheless, this is less emphasized by current automatic medication recommendation methods. To tackle the above challenges, we propose a three-module Discharge Medication Recommendation Network, called DMRNet, for accurate discharge medication recommendations. Specifically, the Information Integration Module combines information from the current visit and significant external knowledge e.g., the Diagnosis-Medication Co-occurrence (DMC) relationship. The Medication Retention Module is specially designed to capture the associations between the historical medications and the recommended medications. The History Retrieval Module differentiates the significance of different historical visits and incorporates them based on different significance values. Experimental evaluations on benchmark datasets, i.e., MIMIC-III and MIMIC-IV, confirm DMRNet's superiority over state-of-the-art baseline methods in terms of Jaccard Similarity, F1-score, Precision and Recall.}
}


@inproceedings{DBLP:conf/icde/QinHWZZM0O024,
	author = {Jianbin Qin and
                  Sifan Huang and
                  Yaoshu Wang and
                  Jing Zhu and
                  Yifan Zhang and
                  Yukai Miao and
                  Rui Mao and
                  Makoto Onizuka and
                  Chuan Xiao},
	title = {BClean: {A} Bayesian Data Cleaning System},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {3407--3420},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00263},
	doi = {10.1109/ICDE60146.2024.00263},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/QinHWZZM0O024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {There is a considerable body of work on data cleaning which employs various principles to rectify erroneous data and transform a dirty dataset into a cleaner one. One of prevalent approaches is probabilistic methods, including Bayesian methods. However, existing probabilistic methods often assume a simplistic distribution (e.g., Gaussian distribution), which is frequently under-fitted in practice, or they necessitate experts to provide a complex prior distribution (e.g., via a programming language). This requirement is both labor-intensive and costly, rendering these methods less suitable for real-world applications. In this paper, we propose BClean, a Bayesian Cleaning system that features automatic Bayesian network construction and user interaction. We recast the data cleaning problem as a Bayesian inference that fully exploits the relationships between attributes in the observed dataset and any prior information provided by users. To this end, we present an automatic Bayesian network construction method that extends a structure learning-based functional dependency discovery method with similarity functions to capture the relationships between attributes. Furthermore, our system allows users to modify the generated Bayesian network in order to specify prior information or correct inaccuracies identified by the automatic generation process. We also design an effective scoring model (called the compensative scoring model) necessary for the Bayesian inference. To enhance the efficiency of data cleaning, we propose several approximation strategies for the Bayesian inference, including graph partitioning, domain pruning, and pre-detection. By evaluating on both real-world and synthetic datasets, we demonstrate that BClean is capable of achieving an F-measure of up to 0.9 in data cleaning, outperforming existing Bayesian methods by 2% and other data cleaning methods by 15%.}
}


@inproceedings{DBLP:conf/icde/ZengWMCLG24,
	author = {Xiaocan Zeng and
                  Pengfei Wang and
                  Yuren Mao and
                  Lu Chen and
                  Xiaoze Liu and
                  Yunjun Gao},
	title = {MultiEM: Efficient and Effective Unsupervised Multi-Table Entity Matching},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {3421--3434},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00264},
	doi = {10.1109/ICDE60146.2024.00264},
	timestamp = {Sun, 06 Oct 2024 21:04:59 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZengWMCLG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Entity Matching (EM), which aims to identify all pairs of records referring to the same real-world entity from relational tables, is one of the most important tasks in real-world data management systems. Due to the labeling process of EM being extremely labor-intensive, unsupervised EM is more applicable than supervised EM in practical scenarios. Traditional unsupervised EM assumes that all entities come from two tables; however, it is more common to match entities from multiple tables in practical applications, that is, multi-table entity matching (multi-table EM). Unfortunately, effective and efficient unsupervised multi-table EM remains under-explored. To fill this gap, this paper formally studies the problem of unsupervised multi-table entity matching and proposes an effective and efficient solution, termed as MultiEM. MultiEM is a parallelable pipeline of enhanced entity representation, table-wise hierarchical merging, and density-based pruning. Extensive experimental results on six real-world benchmark datasets demonstrate the superiority of MultiEM in terms of effectiveness and efficiency.}
}


@inproceedings{DBLP:conf/icde/0001KCP24,
	author = {George Papadakis and
                  Nishadi Kirielle and
                  Peter Christen and
                  Themis Palpanas},
	title = {A Critical Re-evaluation of Record Linkage Benchmarks for Learning-Based
                  Matching Algorithms},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {3435--3448},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00265},
	doi = {10.1109/ICDE60146.2024.00265},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/0001KCP24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Entity resolution (ER) is the process of identifying records that refer to the same entities within one or across multiple databases. Numerous techniques have been developed to tackle ER challenges over the years, with recent emphasis placed on machine and deep learning methods for the matching phase. However, the quality of the benchmark datasets typically used in the experimental evaluations of learning-based matching algorithms has not been examined in the literature. To cover this gap, we propose four complementary approaches to assessing the difficulty and appropriateness of 13 commonly used datasets: two theoretical ones, which involve new measures of linearity and existing measures of complexity, and two practical ones - the difference between the best non-linear and linear matchers, as well as the difference between the best learning-based matcher and the perfect oracle. Our analysis demonstrates that most existing benchmark datasets pose rather easy classification tasks. As a result, they are not suitable for properly evaluating learning-based matching algorithms. To address this issue, we propose a new methodology for yielding benchmark datasets. We put it into practice by creating four new matching tasks, and we verify that these new benchmarks are more challenging and therefore more suitable for further advancements in the field.}
}


@inproceedings{DBLP:conf/icde/FuMPNDY24,
	author = {Yicheng Fu and
                  Xiaoye Miao and
                  Huanhuan Peng and
                  Chongning Na and
                  Shuiguang Deng and
                  Jianwei Yin},
	title = {Online Query-Based Data Pricing with Time-Discounting Valuations},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {3449--3461},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00266},
	doi = {10.1109/ICDE60146.2024.00266},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/FuMPNDY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Online data marketplaces emerge in diverse data-driven applications, where dynamically arriving consumers pur-chase the data at posted prices. The data value decays over time in many tasks, such as machine learning predictions and realtime systems. Existing query pricing methods do not consider the time-discounting data value. In this paper, we study the query feature-based data pricing problem with unknown time-discounting data valuation. We propose an effective online data pricing mechanism Pride to maximize the cumulative sales revenue. It leverages the powerful property of the ellipsoid method to efficiently solve online optimization via exploration and exploitation. Based on Thompson sampling, we present a novel non-stationary MAB algorithm Biased-TS to determine a suitable discount factor and attain the dynamic posted price. It is theoretically proved that, the regret upper bound order of Pride is dominated by the discretization error\nO(\nT\nk\n)\n, where\nK\nand\nT\nare the numbers of discount candidates and total trading rounds, respectively. Biased-TS gets a sub-linear regret upper bound\nO(\nK\n3\nTlnT\n−\n−\n−\n−\n−\n√\n+Kexp{4\nlnT\n−\n−\n−\n√\n})\n. Extensive experiments using both synthetic and real datasets demonstrate that Pride yields around 90% of the optimal cumulative revenue, and it substantially outperforms the state-of-the-art methods.}
}


@inproceedings{DBLP:conf/icde/Huang0ZCF24,
	author = {Peng Huang and
                  Meihui Zhang and
                  Ziyue Zhong and
                  Chengliang Chai and
                  Ju Fan},
	title = {Representation Learning for Entity Alignment in Knowledge Graph: {A}
                  Design Space Exploration},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {3462--3475},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00267},
	doi = {10.1109/ICDE60146.2024.00267},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Huang0ZCF24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Entity alignment (EA) is a critical task in knowledge fusion, focusing on identifying equivalent entities in different knowledge graphs (KGs). As representation learning techniques have advanced, EA methods have achieved notable improvements on current EA datasets, and several benchmark studies have been conducted. However, we have identified two limitations with respect to existing benchmarks. (1) They perform coarse-grained evaluation, which analyzes each EA approach as a whole. However, a typical EA framework consists of multiple modules, each of which has different strategies. The combinations of these strategies may provide more optimization opportunities, which are unexplored in current studies. (2) Current EA datasets tested in existing studies always contain dense information. However, real-world applications are often with noisy and missing data, which introduces complexities for EA tasks. To address this, we propose a new benchmark that explores the design space of EA framework, which consists of the embedding, relation, attribute and alignment module. Each module has multiple strategies. We also synthesize multiple datasets based on real-world datasets to cover different complex scenarios. Based on the design space and various datasets, we aim to provide a general guideline that recommends the most effective strategy for EA under practical settings. We conduct extensive experiments via comparing 13 baseline methods over 4 real datasets and 12 synthesized datasets. Based on the experimental observations, we also propose a new EA method that outperforms existing baselines.}
}


@inproceedings{DBLP:conf/icde/ShahbaziWMB24,
	author = {Nima Shahbazi and
                  Jin Wang and
                  Zhengjie Miao and
                  Nikita Bhutani},
	title = {Fairness-Aware Data Preparation for Entity Matching},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {3476--3489},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00268},
	doi = {10.1109/ICDE60146.2024.00268},
	timestamp = {Thu, 08 Aug 2024 08:25:49 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ShahbaziWMB24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Entity matching is a crucial task in many real applications. Despite the substantial body of research that focuses on improving the effectiveness of entity matching, enhancing its fairness has received scant attention. To fill this gap, this paper introduces a new problem of preparing fairness-aware datasets for entity matching. We formally outline the problem, drawing upon the principles of group fairness and statistical parity. We devise three highly efficient algorithms to accelerate the process of identifying an unbiased dataset from the vast search space. Our experiments on four real-world datasets show that our proposed algorithms can significantly improve fairness in the results while achieving comparable effectiveness to existing fairness-agnostic methods. Furthermore, we conduct case studies to demonstrate that our proposed techniques can be seamlessly integrated into end-to-end entity matching pipelines to support fairness requirements in real-world applications.}
}


@inproceedings{DBLP:conf/icde/RahmanN0S24,
	author = {Md. Ataur Rahman and
                  Sergi Nadal and
                  Oscar Romero and
                  Dimitris Sacharidis},
	title = {Mitigating Data Sparsity in Integrated Data through Text Conceptualization},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {3490--3504},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00269},
	doi = {10.1109/ICDE60146.2024.00269},
	timestamp = {Thu, 14 Nov 2024 07:43:17 +0100},
	biburl = {https://dblp.org/rec/conf/icde/RahmanN0S24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We study the data sparsity problem for data generated from an integration system. We approach the problem from a textual information extraction perspective and propose to conceptualize external documents using the concepts in the integrated schema. We present THOR, a novel system that, unlike related approaches, neither relies on complex rules nor models trained with large annotated corpus, but on the integrated data and its schema without the need for human annotations. An extensive evaluation on the text conceptualization task demonstrates the superiority of our approach in terms of F1-score, effort and use of resources over the state-of-the-art language models.}
}


@inproceedings{DBLP:conf/icde/ParciakWHNPV24,
	author = {Marcel Parciak and
                  Sebastiaan Weytjens and
                  Niel Hens and
                  Frank Neven and
                  Liesbet M. Peeters and
                  Stijn Vansummeren},
	title = {Measuring Approximate Functional Dependencies: {A} Comparative Study},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {3505--3518},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00270},
	doi = {10.1109/ICDE60146.2024.00270},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ParciakWHNPV24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Approximate functional dependencies (AFDs) are functional dependencies (FDs) that “almost” hold in a relation. While various measures have been proposed to quantify the level to which an FD holds approximately, they are difficult to compare and it is unclear which measure is preferable when one needs to discover FDs in real-world data, i.e., data that only approximately satisfies the FD. In response, this paper formally and qualitatively compares AFD measures. We obtain a formal comparison through a novel presentation of measures in terms of Shannon and logical entropy. Qualitatively, we perform a sensitivity analysis w.r.t. structural properties of input relations and quantitatively study the effectiveness of AFD measures for ranking AFDs on real world data. Based on this analysis, we give clear recommendations for the AFD measures to use in practice.}
}


@inproceedings{DBLP:conf/icde/DingLWWSYW24,
	author = {Xiaoou Ding and
                  Yida Liu and
                  Hongzhi Wang and
                  Chen Wang and
                  Yichen Song and
                  Donghua Yang and
                  Jianmin Wang},
	title = {Efficient Relaxed Functional Dependency Discovery with Minimal Set
                  Cover},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {3519--3531},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00271},
	doi = {10.1109/ICDE60146.2024.00271},
	timestamp = {Mon, 02 Dec 2024 08:28:11 +0100},
	biburl = {https://dblp.org/rec/conf/icde/DingLWWSYW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Assessing data quality through Functional Depen-dencies (FDs) is a crucial aspect of data governance. However, with the diverse range of data sources and the exponential growth in data volume, exact FDs can sometimes be impractical for real-world applications. In contrast, relaxed functional dependencies (RFDs), which allows for some flexibility in attribute value comparisons, demonstrates greater adaptability and flexibility for big data scenarios. To address the efficient discovery of RFDs, this paper proposes a novel mining method to supplement the current research gaps. By establishing a difference table for tuples, we transform the problem into a specialized minimal set covering problem. Additionally, we introduce two optimization strategies: reducing the time complexity of enumerating the left-hand side of the base RFDs to 0 (1) and decreasing the search complexity for feasible LHS attributes and threshold candidates from O(2 m-l ) to O(1.5 m-1 ). We rigorously proof that our mining approach guarantees the identification of validity and minimal RFDs. Experiments on nine real-world datasets reveal that our method significantly improves efficiency compared to existing techniques. Furthermore, it uncovers more concise and higher-quality RFDs. Importantly, the RFDs extracted through our methodology exhibit better performance in downstream cleaning tasks.}
}


@inproceedings{DBLP:conf/icde/FanSM24,
	author = {Grace Fan and
                  Roee Shraga and
                  Ren{\'{e}}e J. Miller},
	title = {Gen-T: Table Reclamation in Data Lakes},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {3532--3545},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00272},
	doi = {10.1109/ICDE60146.2024.00272},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/FanSM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We introduce the problem of Table Reclamation. Given a Source Table and a large table repository, reclamation finds a set of tables that, when integrated, reproduce the source table as closely as possible. Unlike query discovery problems like Query-by-Example or by-Target, Table Reclamation focuses on reclaiming the data in the Source Table as fully as possible using real tables that may be incomplete or inconsistent. To do this, we define a new measure of table similarity, called error-aware instance similarity, to measure how close a reclaimed table is to a Source Table, a measure grounded in instance similarity used in data exchange. Our search covers not only Select-project-join queries, but integration queries with unions, outerjoins, and the unary operators subsumption and complementation that have been shown to be important in data integration and fusion. Using reclamation, a data scientist can understand if any tables in a repository can be used to exactly reclaim a tuple in the Source. If not, one can understand if this is due to differences in values or to incompleteness in the data. Our solution, Gen-T, performs table discovery to retrieve a set of candidate tables from the table repository, filters these down to a set of originating tables, then integrates these tables to reclaim the Source as closely as possible. We show that our solution, while approximate, is accurate, efficient and scalable in the size of the table repository with experiments on real data lakes containing up to 15K tables, where the average number of tuples varies from small (web tables) to extremely large (open data tables) up to 1M tuples.}
}


@inproceedings{DBLP:conf/icde/Pena0N24,
	author = {Eduardo H. M. Pena and
                  F{\'{a}}bio Porto and
                  Felix Naumann},
	title = {Discovering Denial Constraints in Dynamic Datasets},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {3546--3558},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00273},
	doi = {10.1109/ICDE60146.2024.00273},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Pena0N24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Denial constraints (DCs) are data dependencies with high expressive power, offering great flexibility for modeling data quality rules. Specifying DCs manually is problematic, as the required domain expertise is expensive and scarce. Moreover, database updates can invalidate DCs thought to hold and simultaneously uncover new DCs. This fact leads to burdensome scenarios where experts must often revisit DC specifications. Several algorithms have been devised to discover DCs from data, among which only one considers DC discovery on data updates. However, that solution underperforms in many scenarios due to long runtime and excessive memory use. Also, it targets database inserts only, so no previous solution covers deletions. This paper proposes an efficient and flexible algorithm that covers the earlier limitations regarding performance and scope. The algorithm maintains small-footprint intermediate structures during database updates and a method that exploits the changes in this intermediate to update the DCs incrementally. The results of our extensive experimental evaluation show that our algorithm is orders of magnitude faster than the existing one, with much better scalability in the size of the data updates.}
}


@inproceedings{DBLP:conf/icde/Wang0W000SL24,
	author = {Yuanyi Wang and
                  Haifeng Sun and
                  Jiabo Wang and
                  Jingyu Wang and
                  Wei Tang and
                  Qi Qi and
                  Shaoling Sun and
                  Jianxin Liao},
	title = {Towards Semantic Consistency: Dirichlet Energy Driven Robust Multi-Modal
                  Entity Alignment},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {3559--3572},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00274},
	doi = {10.1109/ICDE60146.2024.00274},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Wang0W000SL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Multi-Modal Entity Alignment (MMEA) is a pivotal task in Multi-Modal Knowledge Graphs (MMKGs), seeking to identify identical entities by leveraging associated modal attributes. However, real-world MMKGs confront the challenges of semantic inconsistency arising from diverse and incomplete data sources. This inconsistency is predominantly caused by the absence of specific modal attributes, manifesting in two distinct forms: disparities in attribute counts or the absence of certain modalities. Current methods address these issues through attribute interpolation, but their reliance on predefined distributions introduces modality noise, compromising original semantic information. Furthermore, the absence of a generalizable theoretical principle hampers progress towards achieving semantic consistency. In this work, we propose a generalizable theoretical principle by examining semantic consistency from the perspective of Dirichlet energy. Our research reveals that, in the presence of semantic inconsistency, models tend to overfit to modality noise, leading to over-smoothing and performance oscillations or declines, particularly in scenarios with a high rate of missing modality. To overcome these challenges, we propose DESAlign, a robust method addressing the over-smoothing caused by semantic inconsistency and interpolating missing semantics using existing modalities. Specifically, we devise a training strategy for multi-modal knowledge graph learning based on our proposed principle. Then, we introduce a propagation strategy that utilizes existing features to provide interpolation solutions for missing semantic features. DESAlign outperforms existing approaches across 60 benchmark splits, encompassing both monolingual and bilingual scenarios, achieving state-of-the-art performance. Experiments on splits with high missing modal attributes demonstrate its effectiveness, providing a robust MMEA solution to semantic inconsistency in real-world MMKGs.}
}


@inproceedings{DBLP:conf/icde/BiLZZ0024,
	author = {Yuran Bi and
                  Jinfei Liu and
                  Chen Zhao and
                  Junyi Zhao and
                  Kui Ren and
                  Li Xiong},
	title = {Share: Stackelberg-Nash based Data Markets},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {3573--3586},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00275},
	doi = {10.1109/ICDE60146.2024.00275},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/BiLZZ0024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the prevalence of data-driven intelligence, data markets with various data products are gaining considerable interest as a promising paradigm for commoditizing data and facilitating data flow. In this paper, we present Stackelberg-Nash based Data Markets (Share) to first realize a demand-driven incentivized data market with absolute pricing. We propose a three-stage Stackelberg-Nash game to model trading dynamics which not only optimizes the profits of all selfish participants but also adapts to the common buyer-broker-sellers market flow and solves the seller selection problem based on sellers' inner competition. We define Stackelberg-Nash Equilibrium and use backward induction to solve the equilibrium. For inner Nash equilibrium, we apply the conventional direct derivation approach and propose a novel mean-field based method along with provable approximation guarantees for complicated cases where direct derivation fails. Experiments on real datasets verify the effectiveness and efficiency of Share.}
}


@inproceedings{DBLP:conf/icde/Fu0D024,
	author = {Yue Fu and
                  Qingqing Ye and
                  Rong Du and
                  Haibo Hu},
	title = {Interactive Trimming Against Evasive Online Data Manipulation Attacks:
                  {A} Game-Theoretic Approach},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {3587--3599},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00276},
	doi = {10.1109/ICDE60146.2024.00276},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Fu0D024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the exponential growth of data and its crucial impact on our lives and decision-making, the integrity of data has become a significant concern. Malicious data poisoning attacks, where false values are injected into the data, can disrupt machine learning processes and lead to severe consequences. To mitigate these attacks, distance-based defenses, such as trimming, have been proposed, but they can be easily evaded by white-box attackers. The evasiveness and effectiveness of poisoning attack strategies are two sides of the same coin, making game theory a promising approach. However, existing game-theoretical models often overlook the complexities of online data poisoning attacks, where strategies must adapt to the dynamic process of data collection. In this paper, we present an interactive game-theoretical model to defend online data manipulation attacks using the trimming strategy. Our model accommodates a complete strategy space, making it applicable to strong evasive and colluding adversaries. Leveraging the principle of least action and the Euler-Lagrange equation from theoretical physics, we derive an analytical model for the game-theoretic process. To demonstrate its practical usage, we present a case study in a privacy-preserving data collection system under local differential privacy where a non-deterministic utility function is adopted. Two strategies are devised from this analytical model, namely, Tit-for-tat and Elastic. We conduct extensive experiments on real-world datasets, which showcase the effectiveness and accuracy of these two strategies.}
}


@inproceedings{DBLP:conf/icde/WangJGGBJ24,
	author = {Haodi Wang and
                  Tangyu Jiang and
                  Yu Guo and
                  Fangda Guo and
                  Rongfang Bie and
                  Xiaohua Jia},
	title = {Label Noise Correction for Federated Learning: {A} Secure, Efficient
                  and Reliable Realization},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {3600--3612},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00277},
	doi = {10.1109/ICDE60146.2024.00277},
	timestamp = {Thu, 08 Aug 2024 08:11:04 +0200},
	biburl = {https://dblp.org/rec/conf/icde/WangJGGBJ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated learning has emerged as a promising paradigm for large-scale collaborative training tasks, harnessing diverse local datasets from different clients to jointly train global models. In real-world implementations, client data could have label noise, causing the quality of the global model to be influenced. Existing label-correction solutions assume all the clients are discreet and fail to consider detecting the malicious clients, thus are not practical or privacy-preserving. In this paper, we present zkCor, an efficient and reliable label noise correction scheme with zero-knowledge confidentiality. Our method is designed upon FedCorr [1], but with more relaxed security assumptions. zkCor is established from the ingenious synergy of the label noise correction protocol and the zero-knowledge proof (ZKP), requiring each client to provide a computation integrity proof to the aggregator in each iteration. Thus, clients are forced to jointly guarantee label-correction reliability. We further devise a batch ZKP that is efficient and more suitable for federated learning settings. We rigorously illustrate the building blocks of zkCor and complete the prototype implementation. The extensive experiments demonstrate that zkCor can gain at least 2 to 30 times better performance than the baseline approach on verification workloads with nearly no extra proof time cost from clients.}
}


@inproceedings{DBLP:conf/icde/ChaiJ0FQWLYW24,
	author = {Chengliang Chai and
                  Kaisen Jin and
                  Nan Tang and
                  Ju Fan and
                  Lianpeng Qiao and
                  Yuping Wang and
                  Yuyu Luo and
                  Ye Yuan and
                  Guoren Wang},
	title = {Mitigating Data Scarcity in Supervised Machine Learning Through Reinforcement
                  Learning Guided Data Generation},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {3613--3626},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00278},
	doi = {10.1109/ICDE60146.2024.00278},
	timestamp = {Tue, 30 Jul 2024 08:18:19 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ChaiJ0FQWLYW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {One primary problem for supervised ML is data scarcity, which refers to the inadequacy of well-labeled training data. Recently, deep generative models have shown the capability of generating data objects that closely resemble real data for datasets in different modalities, including images, natural language, and tabular data. Naturally, a promising approach for tackling data scarcity involves training a generative model to produce a collection of data objects, and then employing machine-labeling solutions (e.g., weak supervision or semi-supervised learning) to incorporate these generated data objects for supervised ML. However, it is important to note that because the provided training data may exhibit a different data distribution compared to the validation (or unseen testing) data, the generative model learned from these seen training data cannot guarantee the generation of high-quality data relative to this ML task. To address this challenge, we introduce an iterative approach that gradually calibrates the generative model by interacting with an environment that tells whether generated tuples are good or bad, by using a validation dataset that is not exposed to the generative model. In each iteration, we first use a pre-trained generative model to create unlabeled data objects, label them, and integrate this freshly generated data into the learning process. Afterwards, the model will be tested in the environment to assess the quality of the generated data. The iterative framework can be naturally controlled using reinforcement learning (RL), where an agent generates and labels tuples, an environment tests the generated tuples and sends reward back to the agent to progressively enhance the generative model for a specific supervised ML task. Experimental results over 8 datasets and multiple baselines demonstrate that our RL guided data synthesis, together with off-the-shelf semi-automatic labeling solutions, can significantly improve the performance of supervised ML models.}
}


@inproceedings{DBLP:conf/icde/LiFG024,
	author = {Jiayang Li and
                  Xuan Feng and
                  Tianlong Gu and
                  Liang Chang},
	title = {Dual-Teacher De-Biasing Distillation Framework for Multi-Domain Fake
                  News Detection},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {3627--3639},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00279},
	doi = {10.1109/ICDE60146.2024.00279},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LiFG024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Multi-domain fake news detection aims to identify whether various news from different domains is real or fake and has become urgent and important. However, existing methods are dedicated to improving the overall performance of fake news detection, ignoring the fact that unbalanced data leads to disparate treatment for different domains, i.e., the domain bias problem. To solve this problem, we propose the Dual-Teacher De-biasing Distillation framework (DTDBD) to mitigate bias across different domains. Following the knowledge distillation methods, DTDBD adopts a teacher-student structure, where pre-trained large teachers instruct a student model. In particular, the DTDBD consists of an unbiased teacher and a clean teacher that jointly guide the student model in mitigating domain bias and maintaining performance. For the unbiased teacher, we introduce an adversarial de-biasing distillation loss to instruct the student model in learning unbiased domain knowledge. For the clean teacher, we design domain knowledge distillation loss, which effectively incentivizes the student model to focus on representing domain features while maintaining performance. Moreover, we present a momentum-based dynamic adjustment algorithm to trade off the effects of two teachers. Extensive experiments on Chinese and English datasets show that the proposed method substantially outperforms the state-of-the-art baseline methods in terms of bias metrics while guaranteeing competitive performance 1 1 Our codes are available at https://github.com/ningljy/DTDBD.}
}


@inproceedings{DBLP:conf/icde/ZhangLW24,
	author = {Yunan Zhang and
                  Shige Liu and
                  Jianguo Wang},
	title = {Are There Fundamental Limitations in Supporting Vector Data Management
                  in Relational Databases? {A} Case Study of PostgreSQL},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {3640--3653},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00280},
	doi = {10.1109/ICDE60146.2024.00280},
	timestamp = {Wed, 31 Jul 2024 08:30:59 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhangLW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {High-dimensional vector data is gaining increasing importance in data science applications. Consequently, various database systems have recently been developed to manage vector data. These systems can be broadly categorized into two types: specialized and generalized vector databases. Specialized vector databases are explicitly designed and optimized for storing and querying vector data, while generalized vector databases support vector data management within a relational database like PostgreSQL. It is expected (and confirmed by our experiments) that generalized vector databases exhibit slower performance. However, it is not clear whether there are fundamental limitations (or just implementation issues) for relational databases to support vector data management. This paper aims to answer this question. We chose PostgreSQL as a representative relational database due to its popularity. We focused on PASE, as it is a high-performance and open-sourced PostgreSQL-based vector database. We analyzed the source code of PASE and compared its performance with Faiss, a high-performance and open-sourced specialized vector database, to identify the underlying root causes of the performance gap and analyze how to bridge the gap. Based on our results, we provide insights and directions for building a future generalized vector database that can achieve comparable performance to a high-performance specialized vector database.}
}


@inproceedings{DBLP:conf/icde/ZhaoK24,
	author = {Jinjin Zhao and
                  Sanjay Krishnan},
	title = {Compression and In-Situ Query Processing for Fine-Grained Array Lineage},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {3654--3667},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00281},
	doi = {10.1109/ICDE60146.2024.00281},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhaoK24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Tracking data lineage is important for data integrity, reproducibility, and debugging data science workflows. However, fine-grained lineage (i.e., at a cell level) is challenging to store, even for the smallest datasets. This paper introduces DSLog, a storage system that efficiently stores, indexes, and queries array data lineage, agnostic to capture methodology. A main contribution is our new compression algorithm, named ProvRC, that compresses captured lineage relationships. Using ProvRC for lineage compression result in a significant storage reduction over functions with simple spatial regularity, beating alternative columnar-store baselines by up to 2000x. We also show that ProvRC facilitates in-situ query processing that allows forward and backward lineage queries without decompression - in the optimal case, surpassing baselines by 20x in query latency on random numpy pipelines.}
}


@inproceedings{DBLP:conf/icde/DingLWWLW24,
	author = {Xiaoou Ding and
                  Yingze Li and
                  Hongzhi Wang and
                  Chen Wang and
                  Yida Liu and
                  Jianmin Wang},
	title = {{TSDDISCOVER:} Discovering Data Dependency for Time Series Data},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {3668--3681},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00282},
	doi = {10.1109/ICDE60146.2024.00282},
	timestamp = {Mon, 02 Dec 2024 08:28:13 +0100},
	biburl = {https://dblp.org/rec/conf/icde/DingLWWLW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Intelligent devices often produce time series data that suffer from significant data quality issues. While the utilization of data dependency in error detection and data repair has been somewhat beneficial, it remains inadequate in accurately representing the data quality of time series datasets. In recognition of the obvious characteristics inherent in time series data, we introduce a novel data dependency, termed TSDD. It effectively captures the contextual relationships embedded within multivariate time series, thereby enhancing the semantic richness of data quality representations. We analyze the complexity of both implication and consistency problems for TSDD reasoning, and develop TSDD discovery algorithm TSDDISCOVER, which consists of functional structure discovery, allowable error bound determination, and validation of TSDD patterns. Experimental results on real-life datasets verify TSDDISCOVER efficiently discovers high-quality TSDD patterns. In comparing the performance of TSDD-based error detection with several leading data quality constraints, our findings reveal that the former achieves an average improvement of 12% in accuracy and 30% in the F1 score over other dependency-based detection methods.}
}


@inproceedings{DBLP:conf/icde/DingLWWS24,
	author = {Xiaoou Ding and
                  Genglong Li and
                  Hongzhi Wang and
                  Chen Wang and
                  Yichen Song},
	title = {Time Series Data Cleaning Under Expressive Constraints on Both Rows
                  and Columns},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {3682--3695},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00283},
	doi = {10.1109/ICDE60146.2024.00283},
	timestamp = {Mon, 02 Dec 2024 08:28:14 +0100},
	biburl = {https://dblp.org/rec/conf/icde/DingLWWS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Time series data generated by thousands of sensors are suffering data quality problems. Traditional constraint-based techniques have greatly contributed to data cleaning applications. However, cleaning methods that support expressive constraints on time series data remain insufficient. Given the notable characteristics of time series data, existing cleaning approaches are challenged to provide good repair solutions. To address the challenges, we propose a novel data cleaning method for time series which incorporates expressive constraints that support arithmetic operations between attributes and time context. In the violation detection phase, we introduce specialized violation degree quantification functions and design a violation cell discovery algorithm to identify errors hidden in time series data. In the data repairing phase, we formalize the cleaning task as a constrained optimization problem and develop a novel repair objective function that considers both modification costs and conformance degrees of constraints. We effectively reduce the repair search space through the evaluation of time-context constraints and propose a bidirectional repairing algorithm. We also provide theoretical analysis of the proposed repairing method. Experimental results on three real-world IoT datasets across five metrics demonstrate that our proposed method outperforms seven state-of-the-art cleaning techniques specialized for time series data. Specifically, we achieve a 60% improvement in repairing effectiveness and a 70% reduction in time costs with our designed cleaning strategy.}
}


@inproceedings{DBLP:conf/icde/FanHFC00024,
	author = {Meihao Fan and
                  Xiaoyue Han and
                  Ju Fan and
                  Chengliang Chai and
                  Nan Tang and
                  Guoliang Li and
                  Xiaoyong Du},
	title = {Cost-Effective In-Context Learning for Entity Resolution: {A} Design
                  Space Exploration},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {3696--3709},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00284},
	doi = {10.1109/ICDE60146.2024.00284},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/FanHFC00024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Entity resolution (ER) is an important data integration task with a wide spectrum of applications. The state-of-the-art solutions on ER rely on pre-trained language models (PLMs), which require fine-tuning on a lot of labeled matching/non-matching entity pairs. Recently, large languages models (LLMs), such as GPT-4, have shown the ability to perform many tasks without tuning model parameters, which is known as in-context learning (ICL) that facilitates effective learning from a few labeled input context demonstrations. However, existing ICL approaches to ER typically necessitate providing a task description and a set of demonstrations for each entity pair and thus have limitations on the monetary cost of interfacing LLMs. To address the problem, in this paper, we provide a comprehensive study to investigate how to develop a cost-effective batch prompting approach to ER. We introduce a framework BATCHER consisting of demonstration selection and question batching and explore different design choices that support batch prompting for ER. We also devise a covering-based demonstration selection strategy that achieves an effective balance between matching accuracy and monetary cost. We conduct a thorough evaluation to explore the design space and evaluate our proposed strategies. Through extensive experiments, we find that batch prompting is very cost-effective for ER, compared with not only PLM-based methods fine-tuned with extensive labeled data but also LLM-based methods with manually designed prompting. We also provide guidance for selecting appropriate design choices for batch prompting.}
}


@inproceedings{DBLP:conf/icde/YangZFLY24,
	author = {Xu Yang and
                  Meihui Zhang and
                  Ju Fan and
                  Zeyu Luo and
                  Yuxin Yang},
	title = {A Multi-Task Learning Framework for Reading Comprehension of Scientific
                  Tabular Data},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {3710--3724},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00285},
	doi = {10.1109/ICDE60146.2024.00285},
	timestamp = {Tue, 30 Jul 2024 08:18:19 +0200},
	biburl = {https://dblp.org/rec/conf/icde/YangZFLY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Tabular data in scientific papers provides valuable structured information for knowledge discovery and validation. Although the language models such as BERT and ChatGPT have significantly advanced the research on general domain tables, challenges remain in scientific tables. Specifically, such models have limitations in understanding scientific entities, as well as lacks numerical representation and computation capabilities. Previous studies have focused on scientific tables, but they are limited to individual modules or tasks and lack a comprehensive framework. To address these issues, we introduce a reading comprehension framework for scientific tables, named NRTR, which uses a multi-task learning approach that shares a common encoder, achieves reasoning across various tasks, including question answering, cloze testing, and fact verification. It has the following characteristics: (1) utilizing entity linking and named entity recognition to extract key information from papers, which enhances the models' understanding of scientific entities; (2) injecting numerical representation capabilities into language models and promoting the model's understanding of the relative magnitude of numbers to better reason about maximum and difference values. Notably, the existing scientific corpus lacks tabular contexts or does not integrate computational reasoning, which hinders the evaluation of reasoning models in scientific tables. To this end, we release SciTab, a multi-task dataset that merges high-quality scientific tables with contextual information to provide a benchmark for future research. Our experimental results show that NRTR outperforms existing models on SciTab.}
}


@inproceedings{DBLP:conf/icde/Fang0NZHC024,
	author = {Xiaokun Fang and
                  Feng Zhang and
                  Junxiang Nong and
                  Mingxing Zhang and
                  Puyun Hu and
                  Yunpeng Chai and
                  Xiaoyong Du},
	title = {Enabling Efficient NVM-Based Text Analytics without Decompression},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {3725--3738},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00286},
	doi = {10.1109/ICDE60146.2024.00286},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Fang0NZHC024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Text analytics directly on compression (TADOC) is a promising technology designed for handling big data analytics. However, a substantial amount of DRAM is required for high performance, which limits its usage in many important scenarios where the capacity of DRAM is limited, such as memory-constrained systems. Non-volatile memory (NVM) is a novel storage technology that combines the advantage of reading per-formance and byte addressability of DRAM with the durability of traditional storage devices like SSD and HDD. Unfortunately, no research demonstrates how to use NVM to reduce DRAM utilization in compressed data analytics. In this paper, we propose N-TADOC, which substitutes DRAM with NVM while maintaining TADOC's analytics performance and space savings. Utilizing an NVM block device to reduce DRAM utilization presents two challenges, including poor data locality in traversing datasets and auxiliary data structure reconstruction on NVM. We develop novel designs to solve these challenges, including a pruning method with NVM pool management, bottom-up upper bound estimation, correspondent data structures, and persistence strategy at different levels of cost. Experimental results show that on four real-world datasets, N-TADOC achieves 2.04× performance speedup compared to the processing directly on the uncompressed data and 70.7% DRAM space saving compared to the original TADOC.}
}


@inproceedings{DBLP:conf/icde/ZhouZLHLZD24,
	author = {Yanliang Zhou and
                  Feng Zhang and
                  Tuo Lin and
                  Yuanjie Huang and
                  Saiqin Long and
                  Jidong Zhai and
                  Xiaoyong Du},
	title = {{F-TADOC:} FPGA-Based Text Analytics Directly on Compression with
                  {HLS}},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {3739--3752},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00287},
	doi = {10.1109/ICDE60146.2024.00287},
	timestamp = {Tue, 30 Jul 2024 08:18:17 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhouZLHLZD24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the development of loT and edge computing, data analytics on edge has become popular, and text analytics directly on compression (TADOC) has been proven to be a promising technology for edge data analytics. At the same time, Field Programmable Gate Array (FPGA) also has broad application prospects in data analytics systems. Unfortunately, there is no work to date showing how to support TADOC using FPGAs. We propose FPGA-based text analytics directly on compression with HLS, namely F - TADOC, which is the first framework using HLS to provide FPGA-based text analytics directly on compressed data. It effectively supports efficient text analytics on FPGA without decompressing input data. F-TADOC addresses three major challenges. First, TADOC involves a large number of dependencies with unbalanced workload of rules, which causes extremely low pipeline efficiency on FPG As. To solve it, we use layer-wise approach to traverse the DAG composed of rules and allocate different pipeline processing strategies for rules of different sizes. Second, the data volume required can be large that beyond the on-chip memory capacity of FPGAs. We develop a memory pool supporting hash structure and on-chip caches on FPGA to deal with this challenge. Third, when traversing the DAG, there are massive indirect addressing with a large number of random accesses. This leads to redundant time overhead caused by the latency in accessing the High Bandwidth Memory (HBM) during the pipeline. We optimize the F - TADOC algorithm by using dataflow to expand the nested loop, thus eliminate indirect addressing. With four widely used datasets, experiments show that F - TADOC achieves 4.63 x and 1.49 x performance speedup over TADOC and G- TADOC.}
}


@inproceedings{DBLP:conf/icde/KuiperBM24,
	author = {Laurens Kuiper and
                  Peter A. Boncz and
                  Hannes M{\"{u}}hleisen},
	title = {Robust External Hash Aggregation in the Solid State Age},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {3753--3766},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00288},
	doi = {10.1109/ICDE60146.2024.00288},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/KuiperBM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Analytical database systems offer high-performance in-memory aggregation. If there are many unique groups, temporary query intermediates may not fit RAM, requiring the use of external storage. However, switching from an in-memory to an external algorithm can degrade performance sharply. We revisit external hash aggregation on modern hardware, aiming instead for robust performance that avoids a “performance cliff” when memory runs out. To achieve this, we introduce two techniques for handling temporary query intermediates. First, we propose unifying the memory management of temporary and persistent data. Second, we propose using a page layout that can be spilled to disk despite being optimized for main memory performance. These two techniques allow operator implementations to process larger-than-memory query intermediates with only minor modifications. We integrate these into DuckDB's parallel hash aggregation. Experimental results show that our implementation gracefully degrades performance as query intermediates exceed the available memory limit, while main memory performance is competitive with other analytical database systems.}
}


@inproceedings{DBLP:conf/icde/HuangFYW24,
	author = {Yuchen Huang and
                  Xiaopeng Fan and
                  Song Yan and
                  Chuliang Weng},
	title = {Neos: {A} NVMe-GPUs Direct Vector Service Buffer in User Space},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {3767--3781},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00289},
	doi = {10.1109/ICDE60146.2024.00289},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/HuangFYW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the development of AI generated content and LLM (Large Language Model), demands of vector management have brought prosperity to vector databases. However, the status that vectors cannot be retrieved before being indexed, harms timeliness of vector databases. Updating indexes immediately when adding new vectors, reduces throughput of storage. Due to this contradiction, when facing streaming data, using vector database solely in vector services cannot have it both ways: real-time searches and high-throughput storage. This paper proposes a vector buffer engine, Neos. It is designed for real-time unindexed-vector searches on streaming input and buffering vectors with high throughput before loading them into vector databases. On one hand, we build a lightweight storage on raw NVMe device and liberate throughput from indexes, to maximize storage performance. On the other hand, we realize direct NVMe-GPUs 110 stack and a CPU-GPU heterogeneous task architecture for low-latency unindexed-vector searches on streaming data. Experiments show that our approach performs with 1.5x to 3.4x bandwidth, as low as 20% latency compared to existing 110 stacks, and up to orders-of-magnitude higher vector storage throughput under concurrent RIW workloads. Further, N eos can handle real-time unindexed - vector searches with millisecond-level latency on streaming input, a capability that current vector systems lack.}
}


@inproceedings{DBLP:conf/icde/FanYHW24,
	author = {Xiaopeng Fan and
                  Song Yan and
                  Yuchen Huang and
                  Chuliang Weng},
	title = {TEngine: {A} Native Distributed Table Storage Engine},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {3782--3795},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00290},
	doi = {10.1109/ICDE60146.2024.00290},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/FanYHW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the rapid development of storage and network technology, emerging high-performance hardware is being widely applied to the distributed storage cluster. However, existing distributed storage systems employing multi-layer abstractions to provide table data services result in leaving high-speed hardware under-exploited. In this paper, we propose TEngine, a native distributed table storage engine designed for NVMe SSD and RDMA. The key is that TEngine removes the file abstraction to construct table structures on the device directly. For metadata service, TEngine designs a decoupled single metadata server, reducing distributed coordination, easing the burden on the metadata node, and enabling localized data node access. For data service, TEngine optimizes the parallel processing capability of NVMe devices by integrating upper-level multi-thread parallel operations with lower-level NVMe devices' parallel I/O processing. Moreover, TEngine introduces a periodic pull-based data synchronization approach to transform data pushing into periodic data pulling, which offloads the synchronization burden from the leader to the followers. The experimental results show that TEngine outperforms state-of-the-art distributed storage systems using the same hardware environment.}
}


@inproceedings{DBLP:conf/icde/ZhangCZW24,
	author = {Jie Zhang and
                  Xuzheng Chen and
                  Yin Zhang and
                  Zeke Wang},
	title = {DmRPC: Disaggregated Memory-aware Datacenter {RPC} for Data-intensive
                  Applications},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {3796--3809},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00291},
	doi = {10.1109/ICDE60146.2024.00291},
	timestamp = {Tue, 06 Aug 2024 08:17:23 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhangCZW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Modern datacenter applications are increasingly being built using a microservices architecture. These microservices communicate with each other using datacenter RPCs. RPC's pass by value semantics incur redundant data movement along the network, especially for data-intensive applications. Naively introducing a shared global address space to datacenter RPC does not work as it would couple microservices and require microservices to handle data consistency, significantly complicating the development and deployment of applications. Fortunately, the modern datacenter is embracing disaggregated memory (DM). In a DM-enabled datacenter, servers running the microservices can be all connected to one global disaggregated memory pool, thus the pass by value semantics can be replaced by pass by reference. However, prior work on DM requires complicated synchronization primitives to share data across physical machines, so naively adopting them to datacenter RPC would harm microservices' agility and modularity. To this end, we present DmRPC, a DM-aware datacenter RPC for data-intensive datacenter applications to our knowledge. First, DmRPC introduces a DM-aware shared global address space to provide the semantics of pass by reference to datacenter RPC, thus alleviating the redundant data movement issue. Second, DmRPC adopts a copy-on-write mechanism to avoid complicating application logic to handle data consistency while guaranteeing high performance. We have applied DmRPC to two different implementations of DM, one is network-based (DmRPC-net) while the other is CXL-based (DmRPC-CXL). Our evaluations on synthetic 7-tier microservices workloads show that DmRPC-net (or DmRPC-CXL) achieves 4.2× (or 8.3×) higher throughput and achieves 1.1 × (or 1.7 ×) lower average latency than that of the baseline, respectively. On a widely used microservice benchmark DeathStarBench, DmRPC-net can achieve 3.1 × higher throughput and 2.5 × lower average latency than the baseline.}
}


@inproceedings{DBLP:conf/icde/ChengS024,
	author = {Yiran Cheng and
                  Xibo Sun and
                  Qiong Luo},
	title = {RapidGKC: GPU-Accelerated K-Mer Counting},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {3810--3822},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00292},
	doi = {10.1109/ICDE60146.2024.00292},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ChengS024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Many bioinformatics applications, e.g., genome assembly, genome profiling, and sequence alignment, break biological sequences into k-mers, or length-k substrings, for sub-sequent processing. In these applications, counting the number of occurrences of distinct k-mers is a common but expensive step due to the data and computation intensity. As such, prior work proposed to parallelize this task and utilize GPUs for further acceleration. However, these solutions under-utilize the GPU parallelism because the encoding format of intermediate data forces sequential decoding. To address this problem, we design a new encoding scheme for variable-length genomic data to support parallel encoding and decoding. Furthermore, we propose a novel rule to select common substrings among k-mers for partitioning, reducing the space cost as well as facilitating efficient parallel processing. Finally, we parallelize the entire workflow of partitioning and counting through pipelining, CPU-GPU co-processing, and work stealing. As a result, RapidGKC, our end-to-end GPU-accelerated k-mer counting system, outperforms state-of-the-art CPU-based and GPU-accelerated methods on real-world datasets.}
}


@inproceedings{DBLP:conf/icde/ZhangHWW00024,
	author = {Meng Zhang and
                  Qinghao Hu and
                  Cheng Wan and
                  Haozhao Wang and
                  Peng Sun and
                  Yonggang Wen and
                  Tianwei Zhang},
	title = {Sylvie: 3D-Adaptive and Universal System for Large-Scale Graph Neural
                  Network Training},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {3823--3836},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00293},
	doi = {10.1109/ICDE60146.2024.00293},
	timestamp = {Mon, 19 Aug 2024 15:02:12 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhangHWW00024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Distributed full-graph training of Graph Neural Networks (GNNs) has been widely adopted to learn large-scale graphs. While recent system advancements can improve the training throughput of GNNs, their practical adoption is limited by the potential accuracy decline. This concern is particularly prominent in deeper and more intricate GNN architectures, where noticeable performance degradation becomes apparent. Moreover, existing works fail to comprehensively consider diverse opportunities for acceleration. Motivated by these deficiencies, we propose Sylvie,a full-graph training system that not only improves the training throughput substantially but also maintains the model quality for universal GNNs. By harnessing the inherent information embedded in the graph data and model structure, Sylvie intelligently optimizes GNN training across three key dimensions: data, time, and execution. It identifies performance-relevant features of the input graph offline as subsequent optimization guidance. Subsequently, Sylvie devises an online convergence-maintenance strategy that adaptively integrates and aligns GNN-specific quantization and inter-epoch asynchronous training with the real-time training characteristics. Extensive experiments demonstrate that Sylvie surpasses existing GNN training systems by up to 17.2× speedup for both shallow and deep GNNs, without compromising the model accuracy.}
}


@inproceedings{DBLP:conf/icde/LiXYLZ24,
	author = {Xin Li and
                  Mengbai Xiao and
                  Dongxiao Yu and
                  Rubao Lee and
                  Xiaodong Zhang},
	title = {UltraPrecise: {A} GPU-Based Framework for Arbitrary-Precision Arithmetic
                  in Database Systems},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {3837--3850},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00294},
	doi = {10.1109/ICDE60146.2024.00294},
	timestamp = {Mon, 18 Nov 2024 08:02:15 +0100},
	biburl = {https://dblp.org/rec/conf/icde/LiXYLZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Fixed-point decimal operations in databases with arbitrary-precision arithmetic refer to the ability to store and operate decimal fraction numbers with an arbitrary length of digits. This type of operation has become a requirement for many applications, including scientific databases, financial data processing, geometric data processing, and cryptography. However, the state-of-the-art fixed-point decimal technology either provides high performance for low-precision operations or supports arbitrary-precision arithmetic operations at low performance. In this paper, we present a design and implementation of a framework called UltraPrecise which supports arbitrary-precision arithmetic for databases on GPU, aiming to gain high performance for arbitrary-precision arithmetic operations. We build our framework based on the just-in-time compilation technique and optimize its performance via data representation design, PTX acceleration, and expression scheduling. UltraPrecise achieves comparable performance to other high-performance databases for low-precision arithmetic operations. For high-precision, we show that UltraPrecise consistently outperforms existing databases by two orders of magnitude, including workloads of RSA encryption and trigonometric function approximation.}
}


@inproceedings{DBLP:conf/icde/ZhangZNQH024,
	author = {Bowen Zhang and
                  Shengan Zheng and
                  Liangxu Nie and
                  Zhenlin Qi and
                  Linpeng Huang and
                  Hong Mei},
	title = {Exploiting Persistent {CPU} Cache for Scalable Persistent Hash Index},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {3851--3864},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00295},
	doi = {10.1109/ICDE60146.2024.00295},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhangZNQH024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Byte-addressable persistent memory (PM) has been widely studied in the past few years. Recently, the emerging eADR technology further incorporates CPU cache into the persistence domain. The persistent CPU cache is promising to optimize the write performance of PM-based storage systems and facilitate the design of concurrent crash-consistent data structures. In this paper, we propose Spash, a highly scalable persistent hash index for PM systems with persistent CPU cache. Spash fully exploits the benefits of persistent CPU cache to implement a durable linearizable index with low PM access overhead and high concurrency. Spash employs a fine-grained extendible hash architecture and a metadata-free segment design to minimize the number of PM accesses. Moreover, Spash adopts adaptive in-place updates and compacted-flush insertions, which dramatically conserve scarce PM write bandwidth by absorbing a large amount of PM write in the persistent CPU cache. Furthermore, Spash proposes a two-phase concurrency protocol and a collaborative staged doubling mechanism, which leverage the persistent CPU cache and hardware transactional memory to achieve lock-free concurrency and durable linearizability. Spash outperforms the other state-of-the-art persistent hash indexes in YCSB workloads by up to 19.6×.}
}


@inproceedings{DBLP:conf/icde/Wei0L0LZJ024,
	author = {Jianpeng Wei and
                  Yu Gu and
                  Tianyi Li and
                  Jianzhong Qi and
                  Chuanwen Li and
                  Yanfeng Zhang and
                  Christian S. Jensen and
                  Ge Yu},
	title = {{LTPG:} Large-Batch Transaction Processing on GPUs with Deterministic
                  Concurrency Control},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {3865--3877},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00296},
	doi = {10.1109/ICDE60146.2024.00296},
	timestamp = {Sun, 06 Oct 2024 21:04:59 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Wei0L0LZJ024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {GPUs are being applied widely to batch workloads that benefit from the parallel processing capabilities of GPUs. To enable the processing of concurrent batch-based transactions on GPUs, existing systems build dependency graphs during a pre-execution phase to manage read and write operations. However, as dependency-graph maintenance introduces a sub-stantial overhead, there is a need for more efficient transaction support to exploit the power of GPUs more fully for transaction processing. This paper proposes LTPG, a novel GPU-enabled database system that offers increased versatility and efficiency by eliminating the need for predefined read/write-sets. LTPG employs deterministic optimistic concurrency control to ensure correct transaction execution, thus avoiding the maintenance of dependency graphs. The proposed concurrency control simpli-fies transaction processing workflows and avoids the overhead associated with managing dependency graphs, thus resulting in improved efficiency. LTPG divides a workflow into three stages: execution, conflict detection, and write-back, leveraging the parallelism of GPUs. Moreover, several additional optimization strategies are adopted to improve system performance. Experiments with real-world workloads from two benchmarks verify LTPG can achieve effective improvement in the throughput and latency compared to the leading baselines.}
}


@inproceedings{DBLP:conf/icde/NguyenL24,
	author = {Lam{-}Duy Nguyen and
                  Viktor Leis},
	title = {Why Files If You Have a DBMS?},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {3878--3892},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00297},
	doi = {10.1109/ICDE60146.2024.00297},
	timestamp = {Sun, 06 Oct 2024 21:04:58 +0200},
	biburl = {https://dblp.org/rec/conf/icde/NguyenL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Most Database Management Systems (DBMSs) sup-port arbitrary-sized objects through the Binary Large OBjects (BLOBs) data type. Nevertheless, application developers usually store large objects in file systems and only manage the metadata and file paths through the DBMS. This combined approach has major downsides, including a lack of transactional and indexing capabilities. Two factors contribute to the rare use of database BLOBs: the inefficiency of DBMSs in such workloads and the interoperability difficulties when interacting with external programs that expect files. To address the former, we present a new BLOB allocation and logging design that exhibits lower write amplification, reduces WAL checkpointing frequency, and consumes less storage than the conventional strategies. Our approach flushes each BLOB only once and features only a single indirection layer. Moreover, using the Filesystem in Userspace framework, BLOBs can be exposed as read-only files, allowing unmodified applications to directly access database BLOBs. The experimental results show that our design outperforms both file systems and DBMSs in handling large objects.}
}


@inproceedings{DBLP:conf/icde/TangWMYKX24,
	author = {Dongdong Tang and
                  Weilan Wang and
                  Yu Mao and
                  Jinghuan Yu and
                  Tei{-}Wei Kuo and
                  Chun Jason Xue},
	title = {{STEM:} Streaming-Based {FPGA} Acceleration for Large-Scale Compactions
                  in {LSM} {KV}},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {3893--3905},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00298},
	doi = {10.1109/ICDE60146.2024.00298},
	timestamp = {Sun, 06 Oct 2024 21:04:59 +0200},
	biburl = {https://dblp.org/rec/conf/icde/TangWMYKX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Log-Structured-Merge-tree (LSM-tree) has been extensively adopted because of its exceptional write efficiency and high space utilization. Compaction is invoked periodically in LSM-tree based key-value(LSM KV) systems to maintain good system performance. As the size of LSM-KV grows, large-scale compaction is now frequently seen. Compaction throughput significantly degrades with larger inputs, leading to frequent write stalls and decrement in overall write throughput. This paper proposes STEM, a stream-based compaction framework with FPGA to address this issue. A clean-cut algorithm is introduced to enable streaming-based compaction for large-scale data. With a multi-unit pipeline and dynamic pipeline schedule, STEM can handle large-scale compaction tasks efficiently. Based on the experiment result, the compaction throughput of STEM can achieve\n27×\non average and up to\n35×\nimprovement compared with the current RocksDB compaction,\n2.09×\nto\n2.27×\nimprovement compared with the state-of-the-art FPGA accelerator.}
}


@inproceedings{DBLP:conf/icde/YanZ24,
	author = {Wei Yan and
                  Xingjun Zhang},
	title = {Improving the Relationship Between B\({}^{\mbox{+}}\)-Tree and Memory
                  Allocator for Persistent Memory},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {3906--3919},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00299},
	doi = {10.1109/ICDE60146.2024.00299},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/YanZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the traditional volatile DRAM, the B + -Tree inter-acts with the memory allocator by specifying space requirements for scaling. However, the emergence of persistent memory (PM) as a potential substitute for DRAM heap implementation presents new challenges, including crash-consistent issues and limited performance. Prevalent solutions in both the allocators and B + - Trees are confronted with similar dilemmas between runtime performance and recovery efficiency. In this paper, we propose a novel crash-consistent protocol called ST-protocol (share and talk protocol) to address these dilemmas. The core idea of ST-protocol is overlapping the post-crash garbage collection of the allocator with the recovery of the B + -Tree, according to the shared node status. This overlapped process can be performed by multiple threads, according to the shared space layout. Consequently, both the allocator and index can achieve high runtime performance from the volatile components in DRAM without much compromising the recovery efficiency. We further propose a B + -Tree model and a new PM allocator as two interacting characters in ST-protocol, and the experimental results demonstrate that our design outperforms existing solutions by a large margin in both runtime performance and recovery efficiency.}
}


@inproceedings{DBLP:conf/icde/JibrilAS24,
	author = {Muhammad Attahir Jibril and
                  Hani Al{-}Sayeh and
                  Kai{-}Uwe Sattler},
	title = {Accelerating Aggregation Using a Real Processing-in-Memory System},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {3920--3932},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00300},
	doi = {10.1109/ICDE60146.2024.00300},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/JibrilAS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Processing-in-Memory (PIM) is a new computing paradigm aimed at minimizing data movement, which is a bottleneck in modern and emerging applications. PIM upgrades the otherwise passive memory subsystem to an active computation role along with the processor. PIM achieves this by moving processing cores to where the data resides, thereby reducing memory access latency, increasing overall memory bandwidth and decreasing energy consumption. In this paper, we leverage the commercially available real UPMEM PIM system to accelerate the execution of the aggregation operator, which is data-intensive and involves large amounts of data movements. We tailor the operator to PIM, propose various performance optimizations with regards to the architectural peculiarities of the UPMEM PIM system and conduct evaluations in comparison with a CPU baseline implementation. Our PIM-based aggregation outperforms the CPU baseline by up to a speedup of 2.41 x.}
}


@inproceedings{DBLP:conf/icde/ZhangERA24,
	author = {Liang Zhang and
                  Mohamed Y. Eltabakh and
                  Elke A. Rundensteiner and
                  Khalid Alnuaim},
	title = {{CLIMBER:} Pivot-Based Approximate Similarity Search Over Big Data
                  Series},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {3933--3946},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00301},
	doi = {10.1109/ICDE60146.2024.00301},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhangERA24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The terabyte-scale of data series has motivated recent efforts to design fully distributed techniques for supporting operations such as approximate kNN similarity search, which is a building block operation in most analytics services on data series. Unfortunately, these techniques are heavily geared towards achieving scalability at the cost of sacrificing the results' accuracy. State-of-the-art systems DPiSAX and TARDIS report accuracy below 10% and 40%, respectively, which is not practical for many real-world applications. In this paper, we investigate the root problems in these existing techniques that limit their ability to achieve better a trade-off between scalability and accuracy. Then, we propose a framework, called CLIMBER, that encompasses a novel feature extraction mechanism, indexing scheme, and query processing algorithms for supporting approximate similarity search in big data series. For CLIMBER, we propose a new loss-resistant dual representation composed of rank-sensitive and ranking-insensitive signatures capturing data series objects. Based on this representation, we devise a distributed two-level index structure supported by an efficient data partitioning scheme. Our similarity metrics tailored for this dual representation enables meaningful comparison and distance evaluation between the rank-sensitive and ranking-insensitive signatures. Finally, we propose two efficient query processing algorithms, CLIMBER-kNN and CLIMBER-kNN-Adaptive, for answering approximate kNN similarity queries. Our experimental study on real-world and benchmark datasets demonstrates that CLIMBER, unlike existing techniques, features results' accuracy above 80% while retaining the desired scalability to terabytes of data.}
}


@inproceedings{DBLP:conf/icde/LiHLZQ24,
	author = {Yunfan Li and
                  Huiqi Hu and
                  Chaojing Lei and
                  Xuan Zhou and
                  Weining Qian},
	title = {Hill-Cache: Adaptive Integration of Recency and Frequency in Caching
                  with Hill-Climbing},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {3947--3960},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00302},
	doi = {10.1109/ICDE60146.2024.00302},
	timestamp = {Tue, 06 Aug 2024 08:18:22 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LiHLZQ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cache replacement policies are essential for maximizing application performance. Policies such as LRFU, which incorporate both recency and frequency, have shown efficacy in improving hit rates in many studies. In this paper, we theoretically investigated how parameters impact hit rates in LRFU and discovered two distinct features named unimodality and correlation. Drawing on our understanding, we formulated Hill-Cache. Hill-Cache provides a holistic approach to cache. It incorporates recency and frequency and employs a hill-climbing algorithm for adaptability. Additionally, it improves churn resistance through quick demotion, the approach that the most recent research suggests. By overcoming the limitations of LRFU, including high maintenance overhead and dependency on parameters, Hill-Cache distinguishes itself as a new cache method. Hill-Cache is well-suited for situations where there is an efficiency gap between performance devices and capacity devices, including data caching applications and database systems. Our evaluations, employing 36 real-world traces and various sophisticated policies across diverse cache sizes, demonstrated the superior performance of Hill-Cache. It reduces the average miss rate by 11.97% compared to LRU and outperforms other advanced cache policies such as ARC, LIRS, DLIRS, CACHEUS, and S3FIFO. We incorporated Hill-Cache into Memcached and RocksDB, significantly improving performance metrics such as throughput and latency.}
}


@inproceedings{DBLP:conf/icde/0006CHZZ024,
	author = {Xi Zhao and
                  Zhonghan Chen and
                  Kai Huang and
                  Ruiyuan Zhang and
                  Bolong Zheng and
                  Xiaofang Zhou},
	title = {Efficient Approximate Maximum Inner Product Search Over Sparse Vectors},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {3961--3974},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00303},
	doi = {10.1109/ICDE60146.2024.00303},
	timestamp = {Thu, 07 Nov 2024 07:52:34 +0100},
	biburl = {https://dblp.org/rec/conf/icde/0006CHZZ024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The maximum inner product search (MIPS) problem in high-dimensional vector spaces has various applications, primarily driven by the success of deep neural network-based embedding models. Existing MIPS methods designed for dense vectors using approximate techniques like locality-sensitive hashing (LSH) have been well studied, but they are not efficient and effective for searching sparse vectors due to the near-orthogonality among the sparse vectors. The solutions to MIPS over sparse vectors rely heavily on inverted lists, resulting in poor query efficiency, particularly when dealing with large-scale sparse datasets. In this paper, we introduce SOSIA, a novel framework specifically tailored to address these limitations. To handle sparsity, we propose the SOS transformation, which converts sparse vectors into a binary space while providing an unbiased estimator of the inner product between any two vectors. Additionally, we develop a minHash-based index to enhance query efficiency. We provide a theoretical analysis on the query quality of SOSIA and present extensive experiments on real-world sparse datasets to validate its effectiveness. The experimental results demonstrate its superior performance in terms of query efficiency and accuracy compared to existing methods.}
}


@inproceedings{DBLP:conf/icde/0002EFK24,
	author = {Rui Liu and
                  Aaron J. Elmore and
                  Michael J. Franklin and
                  Sanjay Krishnan},
	title = {Riveter: Adaptive Query Suspension and Resumption Framework for Cloud
                  Native Databases},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {3975--3988},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00304},
	doi = {10.1109/ICDE60146.2024.00304},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/0002EFK24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In modern cloud environments, ephemeral resources with intermittent availability and fluctuating monetary costs are becoming common. This dynamic nature presents a new challenge when deploying cloud-native databases: adaptive query execution, which can suspend queries when the resources are scarce or costs unexpectedly soar, and then resume them when the resources become available or cost-effective. Addressing this challenge requires the design and implementation of query suspension and resumption with a mechanism that can adaptively determine when, if, and how to suspend queries. In this paper, we propose Riveter, a query suspension and resumption framework that can adaptively pause ongoing queries using various strategies, including (1) a redo strategy that terminates queries and subsequently re-runs them, (2) a pipeline-level strategy that suspends a query once one of its pipelines has completed to reduce the storage requirements for intermediate data, (3) and a process-level strategy that enables the suspension of query execution processes at any given moment but generates a substantial volume of intermediate data for query resumption. We also devise a cost model to estimate query latency using various strategies and an algorithm to select the one that causes minimum latency. To demonstrate the effectiveness of Riveter, we conduct evaluations based on the TPC-H benchmark to investigate intermediate data persistence, strategy selection, and cost model-based estimation. Our results not only present the difference among the strategies of Riveter in terms of the size of persisted intermediate data and the time of triggering the suspension but also confirm the adaptive and efficient query suspension and resumption delivered by Riveter.}
}


@inproceedings{DBLP:conf/icde/WangLHZYCZZ24,
	author = {Qingshuai Wang and
                  Hao Li and
                  Zirui Hu and
                  Rong Zhang and
                  Chengcheng Yang and
                  Peng Cai and
                  Xuan Zhou and
                  Aoying Zhou},
	title = {Mirage: Generating Enormous Databases for Complex Workloads},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {3989--4001},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00306},
	doi = {10.1109/ICDE60146.2024.00306},
	timestamp = {Tue, 06 Aug 2024 08:18:20 +0200},
	biburl = {https://dblp.org/rec/conf/icde/WangLHZYCZZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {To optimize query parallelism techniques, substantial workloads are required with specific query plans and customized output size for each operator (denoted as cardinality constraint). To this end, a rich body of query-aware database generators (QAG) are proposed. However, the complex data dependencies hidden behind queries make previous QAGs suffer from deficiencies in supporting complex operators and controlling the generation errors. In this paper, we design a new generator Mirage supporting well for complex operators with low error bounds for cardinality constraints. First, Mirage leverages Query Rewriting and Set Transforming Rules to decouple dependencies between key and non-key columns, which could help generate each of them individually. Then, for the non-key columns, Mirage abstracts cardinality constraints of operators as placement requirements within each column's domain, and further models the generation problem as a classic bin packing problem. Finally, for the key columns, Mirage proposes a uniform representation of join cardinality constraints for all types of PK-FK joins and partitions the data according to the matching status between PK and F K columns. Then, it formulates the key population as a Constraint Programming problem, which can be solved by an existing CP Solver. The experiments show that Mirage conquers all previous work in either operator support or generation error.}
}


@inproceedings{DBLP:conf/icde/HuangLYZS24,
	author = {Kecheng Huang and
                  Xijun Li and
                  Mingxuan Yuan and
                  Ji Zhang and
                  Zili Shao},
	title = {Joint Directory, File and {IO} Trace Feature Extraction and Feature-based
                  Trace Regeneration for Enterprise Storage Systems},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {4002--4015},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00307},
	doi = {10.1109/ICDE60146.2024.00307},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/HuangLYZS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {For enterprise storage systems, users' directory/file and IO access traces are critical for fine-tuning and new designs. However, once these systems are deployed, only trace features with small sizes are allowed to be sent back to vendors. Therefore, it is crucial to develop effective techniques for highly compressed feature extraction and feature-based high-fidelity trace regeneration. Existing works primarily focus on I/O trace modeling and regeneration without considering the directory/file access information. In this paper, we propose a new technique, called Sketcher, that can sketch massive traces into highly compressed “joint features” with both directory/file and I/O characteristics, and then based on these features regenerate high-fidelity traces with a learning-based approach. For trace feature extraction, one key idea is to divide traces into multiple distance-associated segments, where each segment contains all files and IO accesses operating under the same directory and the differences between segments are represented as displacement of segment inside the directory tree. A dynamic weight scaling technique is proposed to further compress features considering feature criticality and the size quota, thereby achieving high compression ratios with critical characteristics (e.g., abnormal IO access patterns). For trace regeneration, a new learning-based RNN model is proposed to regenerate high-fidelity traces from extracted features based on sampling directory trees. We have implemented a fully functional prototype based on typical enterprise storage systems and evaluated Sketcher with real applications and benchmarks on Huawei OceanStor Dorado storage server. Results show that Sketcher can effectively extract features with marginal runtime overheads while achieving compression ratios up to 15.2K and regenerating high-fidelity traces.}
}


@inproceedings{DBLP:conf/icde/HangTSB0W24,
	author = {Haitian Hang and
                  Xiu Tang and
                  Jianling Sun and
                  Lingfeng Bao and
                  David Lo and
                  Haoye Wang},
	title = {Robust Auto-Scaling with Probabilistic Workload Forecasting for Cloud
                  Databases},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {4016--4029},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00308},
	doi = {10.1109/ICDE60146.2024.00308},
	timestamp = {Sun, 06 Oct 2024 21:04:57 +0200},
	biburl = {https://dblp.org/rec/conf/icde/HangTSB0W24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Auto-scaling is crucial for achieving elasticity in cloud databases as well as other cloud systems. Predictive auto-scaling, which leverages forecasting techniques to adjust resources based on predicted workload, has been widely adopted. However, the inherent inaccuracy of forecasting presents a significant challenge, potentially causing resource under-provisioning. To address this challenge, we propose robust predictive auto-scaling that considers the uncertainty in forecasts. Unlike previous predictive approaches that rely on single-valued forecasts, we leverage probabilistic forecasting techniques to generate quan-tile forecasts, providing a more comprehensive understanding of the potential future workloads. By formulating the auto-scaling problem as a robust optimization problem, we enable the implementation of auto-scaling strategies with customizable levels of robustness, which can be determined by considering various quantile levels of forecasts. Moreover, we enhance the adaptability of our strategy by incorporating different quantile levels through-out the entire decision horizon, allowing for dynamic adjustments in the conservatism of our auto-scaling decisions. This enables us to strike a balance between resource efficiency and system robustness. Through extensive experiments, we demonstrate the effectiveness of our approach in achieving robust auto-scaling in cloud databases, while maintaining reasonable resource efficiency.}
}


@inproceedings{DBLP:conf/icde/SiachamisPFDCK24,
	author = {George Siachamis and
                  Kyriakos Psarakis and
                  Marios Fragkoulis and
                  Arie van Deursen and
                  Paris Carbone and
                  Asterios Katsifodimos},
	title = {CheckMate: Evaluating Checkpointing Protocols for Streaming Dataflows},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {4030--4043},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00309},
	doi = {10.1109/ICDE60146.2024.00309},
	timestamp = {Sun, 06 Oct 2024 21:04:59 +0200},
	biburl = {https://dblp.org/rec/conf/icde/SiachamisPFDCK24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Stream processing in the last decade has seen broad adoption in both commercial and research settings. One key element for this success is the ability of modern stream processors to handle failures while ensuring exactly-once processing guarantees. At the moment of writing, virtually all stream processors that guarantee exactly-once processing implement a variant of Apache Flink's coordinated checkpoints - an extension of the original Chandy-Lamport checkpoints from 1985. However, the reasons behind this prevalence of the coordinated approach remain anecdotal, as reported by practitioners of the stream processing community. At the same time, common checkpointing approaches, such as the uncoordinated and the communication-induced ones, remain largely unexplored. This paper is the first to address this gap by i) shedding light on why practitioners have favored the coordinated approach and ii) investigating whether there are viable alternatives. To this end, we implement three checkpointing approaches that we surveyed and adapted for the distinct needs of streaming dataflows. Our analysis shows that the coordinated approach outperforms the uncoordinated and communication-induced protocols under uniformly distributed workloads. To our surprise, however, the uncoordinated approach is not only competitive to the coordinated one in uniformly distributed workloads, but it also outperforms the coordinated approach in skewed workloads. We conclude that rather than blindly employing coordinated checkpointing, research should focus on optimizing the very promising uncoordinated approach, as it can address issues with skew and support prevalent cyclic queries. We believe that our findings can trigger further research into checkpointing mechanisms.}
}


@inproceedings{DBLP:conf/icde/HuangWRHZHXZZJ24,
	author = {Qiang Huang and
                  Xin Wang and
                  Susie Xi Rao and
                  Zhichao Han and
                  Zitao Zhang and
                  Yongjun He and
                  Quanqing Xu and
                  Yang Zhao and
                  Zhigao Zheng and
                  Jiawei Jiang},
	title = {Benchtemp: {A} General Benchmark for Evaluating Temporal Graph Neural
                  Networks},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {4044--4057},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00310},
	doi = {10.1109/ICDE60146.2024.00310},
	timestamp = {Fri, 11 Oct 2024 08:02:00 +0200},
	biburl = {https://dblp.org/rec/conf/icde/HuangWRHZHXZZJ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {To handle graphs in which features or connections are evolving over time, a series of temporal graph neural networks (TGNNs) have been proposed. Despite the success of these TGNNs, the previous TGNN evaluations reveal several limitations regarding four critical issues: 1) inconsistent datasets, 2) inconsistent evaluation pipelines, 3) lacking workload diversity, and 4) lacking efficient comparison. Overall, there lacks an empirical study that puts TGNN models onto the same ground and compares them comprehensively. To this end, we propose Benchtemp, a general benchmark for evaluating TGNN models on various workloads. Benchtemp provides a set of benchmark datasets so that different TGNN models can be fairly compared. Further, Benchtemp engineers a standard pipeline that unifies the TGNN evaluation. With Benchtemp, we extensively compare the representative TGNN models on different tasks (e.g., link prediction and node classification) and settings (transductive and inductive), w.r.t. both effectiveness and efficiency metrics. We have made Benchtemp publicly available at https://github.com/qianghuangwhu/benchtemp and datasets at https://zenodo.org/record/8267846.}
}


@inproceedings{DBLP:conf/icde/WangSCWSW24,
	author = {Zeyu Wang and
                  Qihao Shi and
                  Jiawei Chen and
                  Can Wang and
                  Mingli Song and
                  Xinyu Wang},
	title = {Fast Query Answering by Labeling Index on Uncertain Graphs},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {4058--4071},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00311},
	doi = {10.1109/ICDE60146.2024.00311},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/WangSCWSW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Given the ubiquity of Uncertain Graphs (UGs), the field of UG mining has garnered increasing attention. Among various mining tasks, query processing stands out as the most fundamental and crucial. Current methods for query answering on UGs primarily rely on Monte-Carlo sampling and heuristic approaches. However, these techniques either struggle with a significant efficiency-accuracy trade-off or lack generalization over different graphs and queries. To circumvent these limitations, this work proposes a novel index-based method for query answering on UGs. We construct a labeling index framework, which can answer queries by pre-computed and stored operators. To the best of our knowledge, this is the first index frame-work that can deal with reliability, expected reliable distance and distance-constrained reliability queries, providing lower or upper bounded query answer results. By transferring the time consuming sampling process into the offline index operator computation, the query answering only needs to traverse a limited number of operators, which accelerates the response time of query answering with several orders of magnitude. We further utilize the vertex cover and its h-hop extension to prune the index structure, thereby reducing the space complexity. Experimental results on five real-world datasets demonstrate that the proposed index framework is both effective and efficient.}
}


@inproceedings{DBLP:conf/icde/ZhangWQWOHLF024,
	author = {Jianshun Zhang and
                  Fang Wang and
                  Sheng Qiu and
                  Yi Wang and
                  Jiaxin Ou and
                  Junxun Huang and
                  Baoquan Li and
                  Peng Fang and
                  Dan Feng},
	title = {Scavenger: Better Space-Time Trade-Offs for Key-Value Separated LSM-trees},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {4072--4085},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00312},
	doi = {10.1109/ICDE60146.2024.00312},
	timestamp = {Sun, 06 Oct 2024 21:04:59 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhangWQWOHLF024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Key- Value Stores (KVS) implemented with log- structured merge-tree (LSM-tree) have gained widespread ac-ceptance in storage systems. Nonetheless, a significant challenge arises in the form of high write amplification due to the compaction process. While KV-separated LSM-trees successfully tackle this issue, they also bring about substantial space am-plification problems, a concern that cannot be overlooked in cost-sensitive scenarios. Garbage collection (GC) holds significant promise for space amplification reduction, yet existing GC strategies often fall short in optimization performance, lacking thorough consideration of workload characteristics. Additionally, current KV-separated LSM-trees also ignore the adverse effect of the space amplification in the index LSM-tree. In this paper, we systematically analyze the sources of space amplification of KV- separated LSM-trees and introduce Scavenger, which achieves a better trade-off between performance and space amplification. Scavenger initially proposes an I/O-efficient garbage collection scheme to reduce I/O overhead and incorporates a space-aware compaction strategy based on compensated size to minimize the space amplification of index LSM-trees. Extensive experiments show that Scavenger significantly improves write performance and achieves lower space amplification than other KV-separated LSM-trees (including BlobDB, Titan, and TerarkDB).}
}


@inproceedings{DBLP:conf/icde/WangWJX24,
	author = {Weicheng Wang and
                  Raymond Chi{-}Wing Wong and
                  H. V. Jagadish and
                  Min Xie},
	title = {Reverse Regret Query},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {4100--4112},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00314},
	doi = {10.1109/ICDE60146.2024.00314},
	timestamp = {Mon, 12 Aug 2024 18:35:46 +0200},
	biburl = {https://dblp.org/rec/conf/icde/WangWJX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Reverse operators have lately gained much attention within the realm of multi-criteria decision-making. While forward operators, such as skyline, seek to identify products that may interest a customer, reverse operators identify prospective customers who are likely to be attracted to a particular product. Specifically, for each customer, they assign scores to all products w.r.t. the customer's preference and then rank the products based on these scores. If the particular product ranks high, the customer is considered a prospective customer for that product. However, relying purely on rankings might cause misleading results, as rankings emphasize the products' relative positions without accounting for their score differences. In a competitive market, a comparatively low-ranked product may have a score that is nearly indistinguishable from that of the top-tier product(s), and thus, may still be interesting to the customer. In this paper, we directly utilize scores to evaluate products, enabling more accurate identification of prospective customers. We refer to our problem as the reverse regret query (RRQ) and make several contributions. First, for the special case in which each product is described by two attributes, we propose an algorithm Sweeping that only takes linear time. Second, for the general case in which each product can be described by multiple attributes, we present two algorithms: an exact algorithm E-PT and a faster approximate algorithm A-PC. We conducted experiments on synthetic and real datasets. The results confirm that evaluating products via scores provides a sound and insightful way of identifying prospective customers. Under typical settings, our proposed algorithms execute faster than existing ones by 1–3 orders of magnitude.}
}


@inproceedings{DBLP:conf/icde/LuZZZ24,
	author = {Zenan Lu and
                  Xiaotian Zhou and
                  Ahad N. Zehmakan and
                  Zhongzhi Zhang},
	title = {Resistance Eccentricity in Graphs: Distribution, Computation and Optimization},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {4113--4126},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00315},
	doi = {10.1109/ICDE60146.2024.00315},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LuZZZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We study resistance eccentricity, a fundamental metric in network science for measuring the structural significance of a node. For a node in a graph, the resistance eccentricity is its maximum resistance distance to all other nodes. Fast computation of resistance eccentricity for a given subset of nodes is essential for a wide range of applications. However, a naive computation, requiring the pseudoinverse of the graph Laplacian, takes cubic time and is thus infeasible for huge networks with millions of nodes. In this paper, we devise a near-linear time algorithm to approximate the resistance eccentricity for one or multiple given nodes, accompanied by a theoretically guaranteed error bound. Furthermore, we investigate the problem of minimizing the resistance eccentricity for a given node by adding\nk\nmissing edges to the graph, for a budget\nk\n. We show that while the objective function is monotone, it does not possess the submodularity property, ruling out the classical hill-climbing algorithm with theoretical guarantees. Instead, we propose two fast heuristic algorithms to approximately solve this problem. Then, we conduct extensive experiments on different networks with sizes up to several million nodes, demonstrating the superiority of our algorithms in terms of efficiency and effectiveness.}
}


@inproceedings{DBLP:conf/icde/WangSCZ24,
	author = {Zhenghao Wang and
                  Lidan Shou and
                  Ke Chen and
                  Xuan Zhou},
	title = {BushStore: Efficient B+Tree Group Indexing for LSM-Tree in Non-Volatile
                  Memory},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {4127--4139},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00316},
	doi = {10.1109/ICDE60146.2024.00316},
	timestamp = {Wed, 07 Aug 2024 07:51:02 +0200},
	biburl = {https://dblp.org/rec/conf/icde/WangSCZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Non- Volatile Memory (NVM) offers low-latency, non-volatility, and byte-addressability, positioning it as a highly promising device for database performance enhancement. Cur-rent research primarily focuses on utilizing LSM-Tree in con-junction with NVM to reduce write amplification and alleviate write stall issues. However, the comprehensive potential of NVM in simultaneously augmenting both read and write performances remains underexplored. And the previous NVM-enhanced LSM-Tree also ignores the sensitivity of NVM to small-grained random reads and writes, which we believe is the key to further improving read and write performance. To address these issues, we propose BushStore, an innovative LSM-Tree variant specifically optimized for NVM. BushStore is designed with a three-level architecture, where the higher levels of BushStore contain a group of immutable, non-clustered B+Trees, replacing traditional SSTables. By storing the non-leaf nodes in the DRAM and the leaf nodes in NVM, and separating the data pages from the indexes, these B+Trees are able to exhibit high performance for diverse read and write operations. Our approach encompasses four key techniques to significantly boost system efficiency: First, we develop novel data structures that localize read/write operations to confined NVM areas, enhancing access speed. Second, we optimize the key-value data handling during flushing and compaction phases, leveraging the superior scanning and sequantial writing capabilities of B+Trees to ex-pedite write and compaction processes. Third, we dynamically adjust the B+Tree sizes, enabling a balanced and optimized flushing and compaction process, thereby improving overall write performance. Fourth, we implement a lazy-delete Cuckoo filtering and lazy-persistent allocation strategy to accelerate query and compaction processes. Evaluations show that BushStore exhibits high performance and scalability under synthetic and real work-loads, and achieves an average performance improvement of 3.3x in random write throughput and 4.3x in random read throughput compared to the state-of-the-art MioDB system.}
}


@inproceedings{DBLP:conf/icde/ChengLHYZYW24,
	author = {Yurong Cheng and
                  Zhaohe Liao and
                  Xiaosong Huang and
                  Yi Yang and
                  Xiangmin Zhou and
                  Ye Yuan and
                  Guoren Wang},
	title = {Cross Online Ride-Sharing for Multiple-Platform Cooperations in Spatial
                  Crowdsourcing},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {4140--4152},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00317},
	doi = {10.1109/ICDE60146.2024.00317},
	timestamp = {Tue, 30 Jul 2024 08:18:21 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ChengLHYZYW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The last few years have seen the wide applications of ride-sharing, a transportation service that allows users to share their travel routes. A typical problem for ride-sharing is to find an optimal route for each worker to serve the dynamically arriving requests with different objectives. Previous studies focus on the route planning on a single platform. However, a single platform may have an uneven distribution of supply and demand, which causes the platform to lose requests from lack of available workers. Luckily, some ride-sharing platforms provide the same service, which enables their collaborations. The inter-platform collaborations on ride-sharing can ease the worker shortages and greatly improve the service quality, but have not been studied yet. In this paper, we propose a Cross Online Ride-sharing (CORS) problem, which allows a platform to borrow the available workers from other platforms to serve its own requests. We first design two algorithms to select the optimal available worker from other platforms, ROWS and DOWS. ROWS randomly picks an available worker, while DOWS selects the optimal worker with the minimum additional travel distance calculated based on his/er predicted destination direction. Then, we design an efficient CORS framework that embeds the proposed optimal worker selection algorithms for the CORS problem. Extensive experiments on real and synthetic datasets demonstrate the effectiveness and efficiency of our algorithms.}
}


@inproceedings{DBLP:conf/icde/GaoWZSZHP24,
	author = {Junhui Gao and
                  Qianru Wang and
                  Xin Zhang and
                  Juan Shi and
                  Xiang Zhao and
                  Qingye Han and
                  Yan Pan},
	title = {Cooperative Air-Ground Instant Delivery by UAVs and Crowdsourced Taxis},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {4153--4166},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00120},
	doi = {10.1109/ICDE60146.2024.00120},
	timestamp = {Wed, 14 Aug 2024 08:23:26 +0200},
	biburl = {https://dblp.org/rec/conf/icde/GaoWZSZHP24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Instant delivery has become a fundamental service in people's daily lives. Different from the traditional express service, the instant delivery has a strict shipping time constraint after being ordered. However, the labor shortage makes it challenging to realize efficient instant delivery. To tackle the problem, researchers have studied to introduce vehicles (i.e., taxis) or Unmanned Aerial Vehicles (UAVs or drones) into instant delivery tasks. Unfortunately, the delivery detour of taxis and the limited battery of UAVs make it hard to meet the rapidly increasing instant delivery demands. Under this circumstance, this paper proposes an air-ground cooperative instant delivery paradigm to maximize the delivery performance and meanwhile minimize the negative effects on the taxi passengers. Specifically, a data-driven delivery potential-demands-aware cooperative strategy is designed to improve the overall delivery performance of both UAVs and taxis as well as the taxi passengers' experience. The experimental results show that the proposed method improves the delivery number by 30.1% and 114.5% compared to the taxi-based and UAV-based instant delivery respectively, and shortens the delivery time by 35.7% compared to the taxi-based instant delivery.}
}


@inproceedings{DBLP:conf/icde/WangTRLLLYB024,
	author = {Shuliang Wang and
                  Song Tang and
                  Sijie Ruan and
                  Cheng Long and
                  Yuxuan Liang and
                  Qi Li and
                  Ziqiang Yuan and
                  Jie Bao and
                  Yu Zheng},
	title = {Urban Sensing for Multi-Destination Workers via Deep Reinforcement
                  Learning},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {4167--4179},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00318},
	doi = {10.1109/ICDE60146.2024.00318},
	timestamp = {Tue, 22 Oct 2024 20:38:20 +0200},
	biburl = {https://dblp.org/rec/conf/icde/WangTRLLLYB024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Urban sensing aims to sense the status of the city, e.g., air quality, noise level, concentration of viruses, which can be completed by spatial crowdsourcing. Multi-destination people, who have many intermediate locations to visit before the final destination, e.g., couriers and tourists, are ideal recruitment candidates to conduct sensing tasks since they spend more time outside and have a wide spatio-temporal distribution. However, existing spatial crowdsourcing methods are only designed for workers who have single destinations, e.g., commuters, which are not applicable to recruit the multiple-destination people. Therefore, in this paper, we generalize the urban crowdsensing problem to the multi-destination scenario, namely, Urban Sensing for Multi-Destination Workers (USMDW). We prove its NP-hardness, and propose a framework Urban Sensing for Multi-destination Workers via Deep REinforcement learning, i.e., SMORE, to solve it effectively and efficiently. SMORE is composed of two steps: 1) candidate assignment initialization, which initializes all feasible sensing task-worker assignment pairs by a pre-trained reinforcement learning-based working route planning solver; and 2) reinforcement learning-based iterative selection, which iteratively selects a sensing task-worker pair to the current assignment via a novel policy network, i.e., Two-stage Assignment Selection Network (TASNet). Extensive experiments on three real-world datasets show SMORE outperforms the best baseline in data coverage by 5.2% on average with high efficiency.}
}


@inproceedings{DBLP:conf/icde/KangYLWLD24,
	author = {Xiangping Kang and
                  Guoxian Yu and
                  Qingzhong Li and
                  Jun Wang and
                  Hui Li and
                  Carlotta Domeniconi},
	title = {Semi-Asynchronous Online Federated Crowdsourcing},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {4180--4193},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00319},
	doi = {10.1109/ICDE60146.2024.00319},
	timestamp = {Tue, 30 Jul 2024 08:18:18 +0200},
	biburl = {https://dblp.org/rec/conf/icde/KangYLWLD24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Crowdsourcing is a promising human-in-the-loop paradigm for processing computer hard tasks by harnessing crowd intelligence. However, canonical crowdsourcing systems mostly need to aggregate/transmit worker data and may lead to privacy-leakage. To tackle this problem, we propose a novel approach, called FedCS (Federated CrowdSourcing), to achieve privacy protection while ensuring quality. FedCS aggregates model parameters from clients to build a shared server model while keeping the training data locally on worker devices to protect data privacy. To mitigate the staleness of stragglers and boost efficiency, we introduce a semi-asynchronous federated crowdsourcing mechanism, where the parameter server performs global aggregation periodically. Moreover, due to the different frequencies of workers participating in asynchronous update, FedCS uses a staleness-aware grouping and weighted aggregation heuristic to balance the training process. To speed up the convergence rate and improve the training accuracy, FedCS deploys adaptive learning step size for worker devices by their participation frequency. We further present a task assignment algorithm to help workers choose worthy and suitable tasks for annotations and to save the budget. Extensive experiments on benchmark datasets and a real-world crowdsourcing project show that FedCS can complete secure crowdsourcing projects with high quality and low budget.}
}


@inproceedings{DBLP:conf/icde/SevimEC0T24,
	author = {Akil Sevim and
                  Ahmed Eldawy and
                  E. Preston Carman and
                  Michael J. Carey and
                  Vassilis J. Tsotras},
	title = {{FUDJ:} Flexible User-Defined Distributed Joins},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {4194--4207},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00320},
	doi = {10.1109/ICDE60146.2024.00320},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/SevimEC0T24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Join operations are crucial in data analysis, but can suffer inefficiency with large datasets and complex non-equality-based conditions. Optimized join algorithms have gained traction in database research to address these challenges. One popular choice for implementing join algorithms is distributed data processing frameworks, e.g., Hadoop and Spark, but each implementation is highly tailored for specific query types. As a result, they do not address join queries that involve diverse and complex conditions since they are not integrated into a holistic query optimization engine like in DBMSs. On the other hand, implementing new join algorithms on a DBMS from scratch requires substantial effort and expertise. This paper introduces FUDJ, Flexible User-defined Distributed Joins, a framework for complex distributed join algorithms. The key idea of FUDJ is to allow developers to realize new distributed join algorithms into the database without delving into the database internals. As shown, an algorithm implemented in FUDJ is up to an order of magnitude faster than existing user-defined implementations with an order of magnitude fewer lines of code.}
}


@inproceedings{DBLP:conf/icde/JiangZHYY24,
	author = {Zite Jiang and
                  Shuai Zhang and
                  Xingzhong Hou and
                  Mengting Yuan and
                  Haihang You},
	title = {{IVE:} Accelerating Enumeration-Based Subgraph Matching via Exploring
                  Isolated Vertices},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {4208--4221},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00321},
	doi = {10.1109/ICDE60146.2024.00321},
	timestamp = {Tue, 17 Sep 2024 16:24:48 +0200},
	biburl = {https://dblp.org/rec/conf/icde/JiangZHYY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The performance of the enumeration-based sub-graph matching, which searches all isomorphic subgraphs in the data graph, is crucial to various applications. The upper bound of the complexity for the enumeration-based method is exponential to the number of query graph vertices, denoted as\nn\n. We propose a novel subgraph matching algorithm called the Isolated Vertices Exploration (IVE). The IVE leverages isolated vertices during the reordering and enumeration phases, thereby significantly accelerating the subgraph matching process. During the enumeration, the isolated vertices can be matched by using a quick bipartite graph matching algorithm. Consequently, the complexity of matching the remaining non-isolated vertices is exponential to the number of non-isolated vertices, denoted as\nn\n′\n. For the reordering, we designed the Maximum Deleted Edges (MDE) to minimize\nn\n′\n. MDE iteratively selects the query vertex with the maximum edges. According to the experimental results,\nn\n′\nis less than\n0.8n\nfor 99.8% of arbitrary graphs. Moreover, IVE outperforms the state-of-the-art algorithms in various scenarios with different sizes, sparsities and fields, achieving a performance speedup of up to 80.3x.}
}


@inproceedings{DBLP:conf/icde/LiuL0H024,
	author = {Ziyi Liu and
                  Lei Li and
                  Mengxuan Zhang and
                  Wen Hua and
                  Xiaofang Zhou},
	title = {Approximate Skyline Index for Constrained Shortest Pathfinding with
                  Theoretical Guarantee},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {4222--4235},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00322},
	doi = {10.1109/ICDE60146.2024.00322},
	timestamp = {Fri, 18 Oct 2024 15:26:38 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LiuL0H024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Constrained Shortest Path (CSP) problem seeks to identify the shortest path between two vertices in a road network while adhering to a specific constraint on another criterion. Solving the CSP problem frequently entails navigating the two-criteria skyline path problem, which incurs a substantial computational expense in large road networks. The primary challenge lies in handling a vast quantity of partial skyline paths, which often hinders index-based solutions from accurately determining the skyline paths. This paper introduces a-FHL, a practical approximation method designed to circumvent the costly skyline path search and hasten computation on skyline path indexing. a-FHL uses tree decomposition to hierarchically assign approximation ratios, thereby facilitating effective pruning within the labelling index. Moreover, we devise various strategies to allocate approximation ratios and an efficient approximation concatenation method to respond to the approximate CSP queries via the a-FHL index. Our method culminates in swift index construction and efficient query response. Comprehensive exper-iments conducted on real-world road networks substantiate the superiority of our approach over contemporary solutions}
}


@inproceedings{DBLP:conf/icde/OotomoNNWFW24,
	author = {Hiroyuki Ootomo and
                  Akira Naruse and
                  Corey Nolet and
                  Ray Wang and
                  Tamas Feher and
                  Yong Wang},
	title = {{CAGRA:} Highly Parallel Graph Construction and Approximate Nearest
                  Neighbor Search for GPUs},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {4236--4247},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00323},
	doi = {10.1109/ICDE60146.2024.00323},
	timestamp = {Fri, 02 Aug 2024 21:41:46 +0200},
	biburl = {https://dblp.org/rec/conf/icde/OotomoNNWFW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Approximate Nearest Neighbor Search (ANNS) plays a critical role in various disciplines spanning data mining and artificial intelligence, from information retrieval and computer vision to natural language processing and recommender systems. Data volumes have soared in recent years and the computational cost of an exhaustive exact nearest neighbor search is often prohibitive, necessitating the adoption of approximate techniques. The balanced performance and recall of graph-based approaches have more recently garnered significant attention in ANNS algorithms, however, only a few studies have explored harnessing the power of GPUs and multi-core processors despite the widespread use of massively parallel and general-purpose computing. To bridge this gap, we introduce a novel parallel computing hardware-based proximity graph and search algorithm. By leveraging the high-performance capabilities of modern hardware, our approach achieves remarkable efficiency gains. In particular, our method surpasses existing CPU and GPU-based methods in constructing the proximity graph, demonstrating higher throughput in both large- and small-batch searches while maintaining compatible accuracy. In graph construction time, our method, CAGRA, is 2.2-27x faster than HNSW, which is one of the CPU SOTA implementations. In large-batch query throughput in the 90 % to 95 % recall range, our method is 33–77 x faster than HNSW, and is 3.8-8.8 x faster than the SOTA implementations for GPU. For a single query, our method is 3.4-53x faster than HNSW at 95% recall.}
}


@inproceedings{DBLP:conf/icde/0001WZFX0024,
	author = {Yuhan Wu and
                  Feiyu Wang and
                  Yifan Zhu and
                  Zhuochen Fan and
                  Zhiting Xiong and
                  Tong Yang and
                  Bin Cui},
	title = {VisionEmbedder: Bit-Level-Compact Key-Value Storage with Constant
                  Lookup, Rapid Updates, and Rare Failure},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {4248--4261},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00324},
	doi = {10.1109/ICDE60146.2024.00324},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/0001WZFX0024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In key-value storage scenarios where storage space is at a premium, our focus is on a class of solutions that only store the value, which is highly space-efficient. While these solutions have proven their worth in distributed storage, networking, and bioinformatics, they still face two significant issues: one is that their space cost could be further reduced; the other is their are vulnerable to update failures, which can necessitate a complete table reconstruction. To address these issues, we introduce VisionEmbedder, a compact key-value embedder with constant-time lookup, fast dynamic updates, and a near-zero risk of reconstruction. VisionEmbedder cuts down the storage requirement from 2.2L bits to just 1.6L bits per key-value pair with an L-bit value, and it significantly reduces the chance of update failures by a factor of n, where\nn\nis the number of keys (for instance, 1 million or more). The compromise with VisionEmbedder comes with a minor reduction in query throughput on certain data sizes. The enhancements offered by VisionEmbedder have been theoretically validated and are effective across any dataset. Additionally, we have implemented VisionEmbedder on both FPGA and CPU platforms, with all codes made available as open-source.}
}


@inproceedings{DBLP:conf/icde/SongW0CXL24,
	author = {Yitong Song and
                  Kai Wang and
                  Bin Yao and
                  Zhida Chen and
                  Jiong Xie and
                  Feifei Li},
	title = {Efficient Reverse k Approximate Nearest Neighbor Search Over High-Dimensional
                  Vectors},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {4262--4274},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00325},
	doi = {10.1109/ICDE60146.2024.00325},
	timestamp = {Thu, 15 Aug 2024 07:54:17 +0200},
	biburl = {https://dblp.org/rec/conf/icde/SongW0CXL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Reverse\nk\nnearest neighbor search\n(RkNNS)\nplays an important role in various data processing and analysis tasks, seeking to pinpoint data considering the query data\nq\namong their\nk\nnearest neighbors. As large models gain popularity, processing high-dimensional vectors has become more and more widespread. However, existing\nRkNNS\nsolutions face inefficiency when handling large-scale high-dimensional vectors due to their sensitivity to data dimensions and sizes during index construction or the verification of numerous candidate results in the query phase. Motivated by these challenges and the inherent intricacies of high-dimensional data processing, in this paper, we study an approximate version of the\nRkNNS\nproblem\n(RkANNS)\nfor high-dimensional vectors, aiming to offer efficient and practical solutions. To this end, we propose a new proximity-graph-based index called HAMG, which enables finding the query results within\nk\nhops from\nq\n. We also present a user-friendly query algorithm on HAMG that can adaptively adjust the search scope based on the desired query recall of users. To further enhance the query process, two pruning strategies are proposed to reduce the number of candidates requiring verification. Extensive experiments validate that HAMG scales well for data dimensions and sizes, and our query algorithm improves query efficiency by up to two orders of magnitude while maintaining comparable query accuracy against existing approaches.}
}


@inproceedings{DBLP:conf/icde/ZhuCGMZZ24,
	author = {Yifan Zhu and
                  Lu Chen and
                  Yunjun Gao and
                  Ruiyao Ma and
                  Baihua Zheng and
                  Jingwen Zhao},
	title = {{HJG:} An Effective Hierarchical Joint Graph for {ANNS} in Multi-Metric
                  Spaces},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {4275--4287},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00326},
	doi = {10.1109/ICDE60146.2024.00326},
	timestamp = {Sun, 06 Oct 2024 21:05:00 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhuCGMZZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Owing to the widespread deployment of smartphones and networked devices, massive amount of data in different types are generated every day, including numeric data, locations, text data, images, etc. Nearest neighbour search in multi-metric spaces has attracted much attention, as it can accommodate any type of data and support search on flexible combinations of multiple metrics. However, most existing methods focus on single metric queries, failing to answer multi-metric queries efficiently due to the complex metric combinations. In this paper, for the first time, we study the approximate nearest neighbour search (ANNS) in multi-metric spaces, and propose HJG, a hierarchical joint graph, to solve the multi-metric query efficiently and effectively. HJG constructs hierarchical graphs for modeling objects of various types, and applies our presented balancing techniques to improve the graph distribution. To support efficient and accurate nearest neighbour search, we join individual graphs dynamically with high efficiency, and develop filtering techniques with efficient search strategy for HJG. Extensive experiments on four datasets demonstrate the superior effectiveness and scalability of our proposed HJG.}
}


@inproceedings{DBLP:conf/icde/00010SC24,
	author = {Kexin Rong and
                  Paul Liu and
                  Sarah Ashok Sonje and
                  Moses Charikar},
	title = {Dynamic Data Layout Optimization with Worst-Case Guarantees},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {4288--4301},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00327},
	doi = {10.1109/ICDE60146.2024.00327},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/00010SC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Many data analytics systems store and process large datasets in partitions containing millions of rows. By mapping rows to partitions in an optimized way, it is possible to improve query performance by skipping over large numbers of irrelevant partitions during query processing. This mapping is referred to as a data layout. Recent works have shown that customizing the data layout to the anticipated query workload greatly improves query performance, but the performance benefits may disappear if the workload changes. Reorganizing data layouts to accommodate workload drift can resolve this issue, but reorganization costs could exceed query savings if not done carefully. In this paper, we present an algorithmic framework OReO that makes online reorganization decisions to balance the benefits of improved query performance with the costs of reorganization. Our framework extends results from Metrical Task Systems to provide a tight bound on the worst-case performance guarantee for online reorganization, without prior knowledge of the query workload. Through evaluation on real-world datasets and query workloads, our experiments demonstrate that online reorganization with OReO can lead to an up to 32% improvement in combined query and reorganization time compared to using a single, optimized data layout for the entire workload.}
}


@inproceedings{DBLP:conf/icde/YanWHZYZYW24,
	author = {Yu Yan and
                  Hongzhi Wang and
                  Junfang Huang and
                  Dake Zhong and
                  Tao Yu and
                  Kaixin Zhang and
                  Man Yang and
                  Tianqing Wang},
	title = {{QCFE:} An Efficient Feature Engineering for Query Cost Estimation},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {4302--4315},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00328},
	doi = {10.1109/ICDE60146.2024.00328},
	timestamp = {Mon, 02 Dec 2024 08:28:16 +0100},
	biburl = {https://dblp.org/rec/conf/icde/YanWHZYZYW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Query cost estimation is a classical task for database management. Recently, researchers have applied AI-driven methods to implement query cost estimation for achieving high accuracy. However, two defects of the feature design lead to poor time-accuracy efficiency in the query cost estimation task. On the one hand, existing works only encode the query plan and data statistics while ignoring some important variables, like storage structure, hardware, database knobs, etc. These variables also have a significant impact on the query cost. On the other hand, existing works suffer the heavy model training and model inference due to inefficient features, such as the index encoding of write-only workloads. To address the above two problems, we first propose an efficient feature engineering for query cost estimation, called QCFE, consisting of the feature snapshot and feature reduction algorithm. (1) We design a novel concept called feature snapshot to efficiently integrate the influences of the missing variables. (2) We propose a difference-propagation feature reduction method for query cost estimation to filter the ineffective features. Compared to state-of-the-art methods, QCFE demonstrates significant improvements in various aspects with well-known benchmarks. QCFE saves up to 50% time consumption for model training, resulting in more efficient and faster training processes. QCFE also optimizes the mean q-error by 19.8% in TPCH, leading to more precise query cost estimation. QCFE offers up to an impressive 8 times inference speedup in query inference throughput.}
}


@inproceedings{DBLP:conf/icde/GuoWSG0LXY24,
	author = {Na Guo and
                  Yaqi Wang and
                  Wenli Sun and
                  Yu Gu and
                  Jianzhong Qi and
                  Zhenghao Liu and
                  Xiufeng Xia and
                  Ge Yu},
	title = {Chameleon: Towards Update-Efficient Learned Indexing for Locally Skewed
                  Data},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {4316--4328},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00329},
	doi = {10.1109/ICDE60146.2024.00329},
	timestamp = {Sun, 06 Oct 2024 21:04:57 +0200},
	biburl = {https://dblp.org/rec/conf/icde/GuoWSG0LXY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recently, learned indexes are assisting and are being adopted to replace traditional indexes for their low memory usage and high query performance. However, existing learned indexes suffer in query efficiency when dealing with locally skewed data distributions which may be caused or exacerbated by ubiquitous updates. Frequent model retraining and reconstruction is required under this circumstance. To address this issue, we present Chameleon, an adaptive learned index for locally skewed data especially in the context of frequent updates. We propose a metric for measuring local skewness, based on which we employ Multi-Agent Reinforcement Learning to assist in locating locally skewed regions and optimizing index structures. Additionally, to reduce the blocking time caused by index model retraining, we propose a lightweight lock named the Interval Lock to achieve a non-blocking retraining. Extensive experiments demonstrate that, without costing more memory, Chameleon outperforms the state-of-the-art learned indexes by up to 3.75 x and 4.37 x in lookup times for read-only and mixed workloads, respectively, and it accelerates update processing by up to 2.92 x.}
}


@inproceedings{DBLP:conf/icde/ZhongSJ0024,
	author = {Kai Zhong and
                  Luming Sun and
                  Tao Ji and
                  Cuiping Li and
                  Hong Chen},
	title = {{FOSS:} {A} Self-Learned Doctor for Query Optimizer},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {4329--4342},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00330},
	doi = {10.1109/ICDE60146.2024.00330},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhongSJ0024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Various works have utilized deep learning to address the query optimization problem in database system. They either learn to construct plans from scratch in a bottom-up manner or steer the plan generation behavior of traditional optimizer using hints. While these methods have achieved some success, they face challenges in either low training efficiency or limited plan search space. To address these challenges, we introduce FOSS, a novel framework for query optimization based on deep reinforcement learning. FOSS initiates optimization from the original plan generated by a traditional optimizer and incrementally refines suboptimal nodes of the plan through a sequence of actions. Additionally, we devise an asymmetric advantage model to evaluate the advantage between two plans. We integrate it with a traditional optimizer to form a simulated environment. Leveraging this simulated environment, FOSS can bootstrap itself to rapidly generate a large amount of high-quality simulated experiences. FOSS then learns from these experiences to improve its optimization capability. We evaluate the performance of FOSS on Join Order Benchmark, TPC-DS, and Stack Overflow. The experimental results demonstrate that FOSS outperforms the state-of-the-art methods in terms of latency performance. Compared to PostgreSQL, FOSS achieves speedup ranging from 1.15x to 8.33x in total latency across different benchmarks.}
}


@inproceedings{DBLP:conf/icde/ChangZLMQ024,
	author = {Zhuo Chang and
                  Xinyi Zhang and
                  Yang Li and
                  Xupeng Miao and
                  Yanzhao Qin and
                  Bin Cui},
	title = {{MFIX:} An Efficient and Reliable Index Advisor via Multi-Fidelity
                  Bayesian Optimization},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {4343--4356},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00331},
	doi = {10.1109/ICDE60146.2024.00331},
	timestamp = {Tue, 30 Jul 2024 08:30:22 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ChangZLMQ024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Indexes play a pivotal role in enhancing database performance. However, index selection remains one of the most challenging problems in relational database management systems, as it demands a careful equilibrium: the search procedure needs to efficiently navigate through a multitude of potential configu-rations, while the evaluation method needs to precisely assess the performance impact of index configurations. Specifically, prohibitively high costs can arise from frequent index creation and workload execution for evaluation, whereas over-reliance on cost estimations can yield suboptimal performance due to potential inaccuracies. In this paper, we present a multi-fidelity index advisor, MFIX, designed to reconcile search efficiency and solution quality. To balance evaluation accuracy and efficiency, MFIX coordinates a range of low-fidelity cost estimates as cheap-to-evaluate ap-proximations, with a select few precise high-fidelity workload executions for refinement. To optimize search efficiency, MFIX employs a data-efficient Bayesian optimization method, paired with a condensed tree-structured index space that eliminates redundant configurations. Furthermore, MFIX incorporates his-torical tasks as auxiliary information with variable fidelity, using an adaptive weighting mechanism that considers task similarity to expedite the search process. Extensive experiments with diverse analytical workloads show that MFIX consistently out-performs state-of-the-art single-fidelity methods, achieving up to a 10.2% increase in performance improvement in actual execution cost over the leading estimation-based approach. Furthermore, through its multi-fidelity Bayesian optimization over conditional space, MFIX significantly enhances the search efficiency and ensures a sustainable search cost.}
}


@inproceedings{DBLP:conf/icde/YangHPLL0024,
	author = {Tiannuo Yang and
                  Wen Hu and
                  Wangqi Peng and
                  Yusen Li and
                  Jianguo Li and
                  Gang Wang and
                  Xiaoguang Liu},
	title = {VDTuner: Automated Performance Tuning for Vector Data Management Systems},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {4357--4369},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00332},
	doi = {10.1109/ICDE60146.2024.00332},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/YangHPLL0024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Vector data management systems (VDMSs) have become an indispensable cornerstone in large-scale information retrieval and machine learning systems like large language models. To enhance the efficiency and flexibility of similarity search, VDMS exposes many tunable index parameters and system parameters for users to specify. However, due to the inherent characteristics of VDMS, automatic performance tuning for VDMS faces several critical challenges, which cannot be well addressed by the existing auto-tuning methods. In this paper, we introduce VDTuner, a learning-based automatic performance tuning framework for VDMS, leveraging multi-objective Bayesian optimization. VDTuner overcomes the challenges associated with VDMS by efficiently exploring a complex multi-dimensional parameter space without requiring any prior knowledge. Moreover, it is able to achieve a good balance between search speed and recall rate, delivering an optimal configuration. Extensive evaluations demonstrate that VDTuner can markedly improve VDMS performance (14.12% in search speed and 186.38 % in recall rate) compared with default setting, and is more efficient compared with state-of-the-art baselines (up to 3.57 x faster in terms of tuning time). In addition, VDTuner is scalable to specific user preference and cost-aware optimization objective. VDTuner is available online at https://github.com/tiannuo-yanWVDTuner.}
}


@inproceedings{DBLP:conf/icde/ZhanW0Z0Z0024,
	author = {Jiexi Zhan and
                  Han Wu and
                  Peng Cheng and
                  Libin Zheng and
                  Lei Chen and
                  Chen Jason Zhang and
                  Xuemin Lin and
                  Wenjie Zhang},
	title = {TrendSharing: {A} Framework to Discover and Follow the Trends for
                  Shared Mobility Services},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {4370--4382},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00333},
	doi = {10.1109/ICDE60146.2024.00333},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhanW0Z0Z0024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the development of ubiquitous smart devices, shared mobility services, such as food delivery, ridesharing and crowdsourced parcel delivery, and the related problems, such as task assignment and route planning have drawn much attention from academia and industry. Specifically, shared mobility services enable one worker to deliver more than one package/passenger together such that their routes can share some common sub-routes. Tardiness (the exceeded time) can harm users' experience and reduce the revenue of workers and platforms, which is not well handled in the existing studies. In this paper, we propose a framework, TrendSharing, to minimize the total tardiness when serving all tasks. In TrendSharing, we first build a flow tree to group tasks together. Then, we propose a concept of trend, which represents a group of tasks with high sharability in the flow tree. Furthermore, we devise a decision factor \\epsilon\n-score to properly select the trend from the flow tree. In addition, we devise an indicator k-regret to quantify the likelihood of tardiness for each task and devise a greedy algorithm to conduct task assignment. We observe that the insertion operation that is widely used by existing works has little effect on the objective of minimizing total tardiness. Thus, we adopt a simple yet effective strategy, which will continuously append newly planned routes to the workers' existing routes. Moreover, we design an algorithm to plan a route for the trend with an approximation ratio of 2.5. Through extensive experiments, we demonstrate the efficiency and effectiveness of our proposed approaches on real datasets.}
}


@inproceedings{DBLP:conf/icde/WangLCJ24,
	author = {Zheng Wang and
                  Cheng Long and
                  Gao Cong and
                  Christian S. Jensen},
	title = {Collectively Simplifying Trajectories in a Database: {A} Query Accuracy
                  Driven Approach},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {4383--4395},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00334},
	doi = {10.1109/ICDE60146.2024.00334},
	timestamp = {Wed, 23 Oct 2024 08:55:27 +0200},
	biburl = {https://dblp.org/rec/conf/icde/WangLCJ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Increasing and massive volumes of trajectory data are being accumulated that may serve a variety of applications, such as mining popular routes or identifying ridesharing candidates. As storing and querying massive trajectory data is costly, trajectory simplification techniques have been introduced that intuitively aim to reduce the sizes of trajectories, thus reducing storage and speeding up querying, while preserving as much information as possible. Existing techniques rely mainly on hand-crafted error measures when deciding which point to drop when simplifying a trajectory. While the hope may be that such simplification affects the subsequent usability of the data only minimally, the usability of the simplified data remains largely unexplored. Instead of using error measures that indirectly may to some extent yield simplified trajectories with high usability, we adopt a direct approach to simplification and present the first study of query accuracy driven trajectory simplification, where the direct objective is to achieve a simplified trajectory database that preserves the query accuracy of the original database as much as possible. Specifically, we propose a multi-agent reinforcement learning based solution with two agents working cooperatively to collectively simplify trajectories in a database while optimizing query usability. Extensive experiments on four real-world trajectory datasets show that the solution is capable of consistently outperforming baseline solutions over various query types and dynamics.}
}


@inproceedings{DBLP:conf/icde/WangYJ0Y024,
	author = {Kunming Wang and
                  Shiyu Yang and
                  Jiabao Jin and
                  Peng Cheng and
                  Jianye Yang and
                  Xuemin Lin},
	title = {Efficient Learning-based Top-k Representative Similar Subtrajectory
                  Query},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {4396--4408},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00335},
	doi = {10.1109/ICDE60146.2024.00335},
	timestamp = {Mon, 05 Aug 2024 15:14:25 +0200},
	biburl = {https://dblp.org/rec/conf/icde/WangYJ0Y024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The advancement in location technology and the increase in trajectory data have made trajectory data mining a focal point in the field of spatiotemporal data analysis. Unlike the extensive research focused on the similarity of entire trajectories, this paper delves into subtrajectory similarity within collections containing a large number of trajectories, under a specified trajectory similarity metric. We propose the Top-k Representative Similar Subtrajectory Query problem, with the objective of identifying the top-k representative subtrajectories which are most similar to the query trajectory within a large trajectory set. To ensure diversity in the results, we adopt the concept of representative similarity, where only the subtrajectory with the highest similarity score to the query trajectory is reported, thus avoiding the redundancy in the top- k\nresults. To address the challenge of high computational costs, we propose a learning-based framework, leveraging a deep learning model called Representative Similarity Score Estimation (RSSE) to approximate subtrajectory similarity scores efficiently and reduce the candidate set significantly. Empirical evaluations conducted on various real-world datasets substantiate the effectiveness and efficiency of our proposed method.}
}


@inproceedings{DBLP:conf/icde/Sun0CFKT24,
	author = {Fengze Sun and
                  Jianzhong Qi and
                  Yanchuan Chang and
                  Xiaoliang Fan and
                  Shanika Karunasekera and
                  Egemen Tanin},
	title = {Urban Region Representation Learning with Attentive Fusion},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {4409--4421},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00336},
	doi = {10.1109/ICDE60146.2024.00336},
	timestamp = {Sun, 06 Oct 2024 21:04:59 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Sun0CFKT24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {An increasing number of related urban data sources have brought forth novel opportunities for learning urban region representations, i.e., embeddings. The embeddings describe latent features of urban regions and enable discovering similar regions for urban planning applications. Existing methods learn an embedding for a region using every different type of region feature data, and subsequently fuse all learned embeddings of a region to generate a unified region embedding. However, these studies often overlook the significance of the fusion process. The typical fusion methods rely on simple aggregation, such as summation and concatenation, thereby disregarding correlations within the fused region embeddings. To address this limitation, we propose a novel model named HAFusion. Our model is powered by a dual-feature attentive fusion module named DAFusion, which fuses embeddings from different region features to learn higher-order correlations be-tween the regions as well as between the different types of region features. DAFusion is generic - it can be integrated into existing models to enhance their fusion process. Further, motivated by the effective fusion capability of an attentive module, we propose a hybrid attentive feature learning module named HALearning to enhance the embedding learning from each individual type of region features. Extensive experiments on three real-world datasets demonstrate that our model HAFusion outperforms state-of-the-art models across three different prediction tasks. Using our learned region embeddings leads to consistent and up to 31 % improvements in the prediction accuracy.}
}


@inproceedings{DBLP:conf/icde/Liu00L0024,
	author = {Ziqiao Liu and
                  Hao Miao and
                  Yan Zhao and
                  Chenxi Liu and
                  Kai Zheng and
                  Huan Li},
	title = {LightTR: {A} Lightweight Framework for Federated Trajectory Recovery},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {4422--4434},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00337},
	doi = {10.1109/ICDE60146.2024.00337},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Liu00L0024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the proliferation of GPS-equipped edge devices, huge trajectory data is generated and accumulated in various domains, motivating a variety of urban applications. Due to the limited acquisition capabilities of edge devices, a lot of trajectories are recorded at a low sampling rate, which may lead to the effectiveness drop of urban applications. We aim to recover a high-sampled trajectory based on the low-sampled trajectory in free space, i.e., without road network information, to enhance the usability of trajectory data and support urban applications more effectively. Recent proposals targeting trajectory recovery often assume that trajectories are available at a central location, which fail to handle the decentralized trajectories and hurt privacy. To bridge the gap between decentralized training and trajectory recovery, we propose a lightweight framework, LightTR, for federated trajectory recovery based on a client-server architecture, while keeping the data decentralized and private in each client/platform center (e.g., each data center of a company). Specifically, considering the limited processing capabilities of edge devices, LightTR encompasses a light local trajectory embedding module that offers improved computational efficiency without compromising its feature extraction capabilities. LightTR also features a meta-knowledge enhanced local-global training scheme to reduce communication costs between the server and clients and thus further offer efficiency improvement. Extensive experiments demonstrate the effectiveness and efficiency of the proposed framework.}
}


@inproceedings{DBLP:conf/icde/MaHJ00X024,
	author = {Minbo Ma and
                  Jilin Hu and
                  Christian S. Jensen and
                  Fei Teng and
                  Peng Han and
                  Zhiqiang Xu and
                  Tianrui Li},
	title = {Learning Time-Aware Graph Structures for Spatially Correlated Time
                  Series Forecasting},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {4435--4448},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00338},
	doi = {10.1109/ICDE60146.2024.00338},
	timestamp = {Tue, 13 Aug 2024 07:51:47 +0200},
	biburl = {https://dblp.org/rec/conf/icde/MaHJ00X024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Spatio-temporal forecasting of future values of spatially correlated time series is important across many cyber-physical systems (CPS). Recent studies offer evidence that the use of graph neural networks to capture latent correlations between time series holds a potential for enhanced forecasting. However, most existing methods rely on predefined or self-learning graphs, which are either static or unintentionally dynamic, and thus cannot model the time-varying correlations that exhibit trends and periodicities caused by the regularity of the underlying processes in CPS. To tackle such limitation, we propose Time-aware Graph Structure Learning (TagSL), which extracts time-aware correlations among time series by measuring the interaction of node and time representations in high-dimensional spaces. Notably, we introduce time discrepancy learning that utilizes contrastive learning with distance-based regularization terms to constrain learned spatial correlations to a trend sequence. Additionally, we propose a periodic discriminant function to enable the capture of periodic changes from the state of nodes. Next, we present a Graph Convolution-based Gated Recurrent Unit (GCGRU) that jointly captures spatial and temporal dependencies while learning time-aware and node-specific patterns. Finally, we introduce a unified framework named Time-aware Graph Convolutional Recurrent Network (TGCRN), combining TagSL, and GCGRU in an encoder-decoder architecture for multi-step spatiotemporal forecasting. We report on experiments with TGCRN and popular existing approaches on five real-world datasets, thus providing evidence that TGCRN is capable of advancing the state-of-the-art. We also cover a detailed ablation study and visualization analysis, offering detailed insight into the effectiveness of time-aware structure learning.}
}


@inproceedings{DBLP:conf/icde/0001WCGHB24,
	author = {Di Yao and
                  Jin Wang and
                  Wenjie Chen and
                  Fangda Guo and
                  Peng Han and
                  Jingping Bi},
	title = {Deep Dirichlet Process Mixture Model for Non-parametric Trajectory
                  Clustering},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {4449--4462},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00339},
	doi = {10.1109/ICDE60146.2024.00339},
	timestamp = {Tue, 30 Jul 2024 08:18:17 +0200},
	biburl = {https://dblp.org/rec/conf/icde/0001WCGHB24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Trajectory clustering is an essential task in spatial data mining. To address this problem, many previous studies either extended traditional clustering algorithms with spatial features of trajectories or employed deep learning models for representation learning. However, one common drawback of existing solutions is that the final number of clusters needs to be specified as part of the input. In this paper, we proposed Tra-jDPM, an end-to-end framework for non-parametric trajectory clustering. We come up with two novel loss functions to pretrain a trajectory encoder so as to generate discriminative trajectory representation. Moreover, we employed the neural Dirichlet process mixture model to perform non-parametric clustering based on trajectory embeddings. In this process, the trajectory encoder can also be jointly optimized to improve the performance by a contrastive learning based strategy. We conduct an extensive set of evaluations on several public datasets. Experimental results show that our proposed framework can outperform state-of-the-art methods by a significant margin.}
}


@inproceedings{DBLP:conf/icde/Xia0Y0ZS024,
	author = {Yuyang Xia and
                  Shuncheng Liu and
                  Quanlin Yu and
                  Liwei Deng and
                  You Zhang and
                  Han Su and
                  Kai Zheng},
	title = {Parameterized Decision-Making with Multi-Modality Perception for Autonomous
                  Driving},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {4463--4476},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00340},
	doi = {10.1109/ICDE60146.2024.00340},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Xia0Y0ZS024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Autonomous driving is an emerging technology that has advanced rapidly over the last decade. Modern transportation is expected to benefit greatly from a wise decision-making framework of autonomous vehicles, including the improvement of mobility and the minimization of risks and travel time. However, existing methods either ignore the complexity of environments only fitting straight roads, or ignore the impact on surrounding vehicles during optimization phases, leading to weak environmental adaptability and incomplete optimization objectives. To address these limitations, we propose a pArameterized decision-making framework with mU lti-modality percepTiOn based on deep reinforcement learning, called AUTO. We conduct a comprehensive perception to capture the state features of various traffic participants around the autonomous vehicle, based on which we design a graph-based model to learn a state representation of the multi-modal semantic features. To distinguish between lane-following and lane-changing, we decompose an action of the autonomous vehicle into a parameterized action structure that first decides whether to change lanes and then computes an exact action to execute. A hybrid reward function takes into account aspects of safety, traffic efficiency, passenger comfort, and impact to guide the framework to generate optimal actions. In addition, we design a regularization term and a multi-worker paradigm to enhance the training. Extensive experiments offer evidence that AUTO can advance state-of-the-art in terms of both macroscopic and microscopic effectiveness.}
}


@inproceedings{DBLP:conf/icde/Li0GCJZZFB24,
	author = {Wenbin Li and
                  Di Yao and
                  Chang Gong and
                  Xiaokai Chu and
                  Quanliang Jing and
                  Xiaolei Zhou and
                  Yuxuan Zhang and
                  Yunxia Fan and
                  Jingping Bi},
	title = {CausalTAD: Causal Implicit Generative Model for Debiased Online Trajectory
                  Anomaly Detection},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {4477--4490},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00341},
	doi = {10.1109/ICDE60146.2024.00341},
	timestamp = {Sun, 06 Oct 2024 21:04:58 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Li0GCJZZFB24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Trajectory anomaly detection, aiming to estimate the anomaly risk of trajectories given the Source-Destination (SD) pairs, has become a critical problem for many real-world applications. Existing solutions directly train a generative model for observed trajectories and calculate the conditional generative probability\nP(T|C)\nas the anomaly risk, where\nT\nand\nC\nrepresent the trajectory and SD pair respectively. However, we argue that the observed trajectories are confounded by road network preference which is a common cause of both SD distribution and trajectories. Existing methods ignore this issue limiting their generalization ability on out-of-distribution trajectories. In this paper, we define the debiased trajectory anomaly detection problem and propose a causal implicit generative model, namely CausalTAD, to solve it. CausalTAD adopts do-calculus to eliminate the confounding bias of road network preference and estimates\nP(T|do(C))\nas the anomaly criterion. Extensive experiments show that CausalTadcan not only achieve superior performance on trained trajectories but also generally improve the performance of out-of-distribution data, with improvements of 2.1% ~ 5.7% and 10.6% ~ 32.7% respectively.}
}


@inproceedings{DBLP:conf/icde/0001ZC0X024,
	author = {Liwei Deng and
                  Yan Zhao and
                  Jin Chen and
                  Shuncheng Liu and
                  Yuyang Xia and
                  Kai Zheng},
	title = {Learning to Hash for Trajectory Similarity Computation and Search},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {4491--4503},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00342},
	doi = {10.1109/ICDE60146.2024.00342},
	timestamp = {Tue, 30 Jul 2024 08:18:18 +0200},
	biburl = {https://dblp.org/rec/conf/icde/0001ZC0X024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Searching for similar trajectories from a database is an important way for extracting human-understandable knowledge. However, due to the huge volume of trajectories and high computation complexity of distance between trajectories, it is difficult to search for exact results, which motivates the research of approximating approaches. In this study, we propose a learning to hash method for trajectory similarity computation and search, called Traj2Hash, which consists of a two-channel trajectory encoder and a hash layer to encode trajectories into Euclidean and Hamming space, respectively. The embeddings of trajectories obtained from the encoder are capable of preserving the reverse symmetric property and more representative due to the reverse augmentation and the lower-bound induced read-out layer. Moreover, we design a decomposed grid representation in the encoder to make the model lighter and better. In the model training phase, we combine a weighted mean squared error loss and a ranking-based hashing loss to enable the model similarity-aware and representations self-structured, respectively, in which a fast trajectory triplet generation method is leveraged to enrich the training corpus. Extensive experiments conducted on real data offer evidence of the effectiveness and efficiency of the proposed model.}
}


@inproceedings{DBLP:conf/icde/FengFXCZ0024,
	author = {Chunhui Feng and
                  Junhua Fang and
                  Yue Xia and
                  Pingfu Chao and
                  Pengpeng Zhao and
                  Jiajie Xu and
                  Xiaofang Zhou},
	title = {Ocean: Online Clustering and Evolution Analysis for Dynamic Streaming
                  Data},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {4504--4517},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00343},
	doi = {10.1109/ICDE60146.2024.00343},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/FengFXCZ0024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the popularization of mobile applications and the timely acquisition of fresh data, real-time clustering and its evolution analysis have become the primary operations for data processing and knowledge discovery. Such continuous queries on massive objects are computation-intensive tasks in dynamic scenarios. However, existing clustering techniques are incompetent to achieve decent performance when computation-intensive operations frequently occur in streaming scenarios, which is caused by two challenges: (i) uncertainty of the clustering frequency; (ii) unpredictable distribution evolution. Hence, it is critical to find a lightweight model that can cluster the high-speed dynamic instances while exploiting the evolution amid different clustering results. This paper focuses on the problem of real-time clustering on streaming data in computation-intensive and high-dynamics tasks, through a framework Ocean, consisting of the Online clustering algorithm and evolution analysis. Particularly, the framework conceives a flexible composite window to augment the knowledge mining, achieving a proper real-time response in various scenarios. The evolution analysis supports full life-cycle detection, improving the adaptability to dynamic concept drifts and multiple patterns. Inspired by the grid partition strategy, this framework adopts grid feature vectors to capture the significant changes in streaming data. Furthermore, we propose an optimization that removes sparse grids timely and performs the online clustering adaptively for space and time efficiency. It is proven to be effective both theoretically and experimentally. This strategy enables real-time clustering for dynamic streaming data without degrading the clustering quality or increasing the computation cost. Experiments on real datasets and synthetic datasets verify the accuracy and effectiveness of Ocean compared to the state-of-the-art approaches, as well as the superior ability to perform clustering in a real-time manner.}
}


@inproceedings{DBLP:conf/icde/WangYLWWXJ24,
	author = {Chenxu Wang and
                  Xin Yang and
                  Tianyi Li and
                  Jiaxing Wei and
                  Pinghui Wang and
                  Hongzhen Xiang and
                  Christian S. Jensen},
	title = {{SWISP:} Distributed Convoy Mining via Sliding Window-based Indexing
                  and Sub-track Partitioning},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {4518--4531},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00344},
	doi = {10.1109/ICDE60146.2024.00344},
	timestamp = {Tue, 06 Aug 2024 08:21:19 +0200},
	biburl = {https://dblp.org/rec/conf/icde/WangYLWWXJ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the widespread deployment of location-aware mobile devices, a mass of trajectory data is being generated and collected. Mining co-movement patterns of people and vehicles from streaming and massive trajectory data has attracted much attention due to its wide applications in various fields. As a typical co-movement pattern, convoys describe objects moving together in consecutive timestamps. There are two challenges for efficient distributed convoy mining: object clustering and workload balancing. Clustering objects in each time snapshot is a time-consuming operation. In addition, on the basis of practical application scenarios, load balancing is an important consideration for distributed algorithms. To tackle the above challenges, we propose a novel method for distributed convoy mining via sliding window-based indexing and sub-track partitioning, abbreviated SWISP. We offer three major advancements. First, we develop a grid-based DBSCAN clustering algorithm named Grid-DBSCAN for distributed scenarios. It avoids the exhaustive calculation of pairwise distances for neighborhood search and thus improves computational efficiency in the clustering stage. Second, we propose a sliding window-based indexing scheme to filter out sub-tracks with less than\nk\nconsecutive time snapshots, significantly reducing the number of candidate sub-tracks for convoy mining. Third, we develop a distributed convoy mining algorithm based on sub-track partitioning. It exploits both temporal and spatial information of sub-tracks for data partitioning and solves the data skewness problem caused by uneven data distributions. We conduct extensive experiments on four real-world datasets. The experimental results show that our distributed algorithm can handle large-scale trajectory data and is more efficient than state-of-the-art approaches.}
}


@inproceedings{DBLP:conf/icde/GongZC24,
	author = {Zengyang Gong and
                  Yuxiang Zeng and
                  Lei Chen},
	title = {Querying Shortest Path on Large Time-Dependent Road Networks with
                  Shortcuts},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {4532--4544},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00345},
	doi = {10.1109/ICDE60146.2024.00345},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/GongZC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Querying the shortest path between two locations is a fundamental task in many applications, and has been extensively studied for static road networks. However, in reality, the travel costs of road segments evolve over time, and hence the road network can be modeled as a time-dependent graph. In this paper, we study the shortest path query over large-scale time-dependent road networks. We first present a tree decomposition method to model the time-dependent road network as a tree structure that preserves travel costs. To further improve query efficiency, a set of shortcuts is selected and built on the constructed tree structure. Specifically, we formally define a shortcut selection problem over the tree decomposition of the time-dependent road network. This problem, which is proven to be NP-hard, aims to select and build the most effective shortcut set. We first devise a dynamic programming method with exact results to solve the selection problem. To obtain the optimal shortcut set quickly, we design an approximation algorithm that guarantees a 0.5-approximation ratio. Based on the novel tree structure, we devise a shortcut-based algorithm to answer the shortest path query over time-dependent road networks. Finally, we conduct extensive performance studies using large-scale real-world road networks. The results demonstrate that our method can achieve better efficiency and scalability than the state-of-the-art method.}
}


@inproceedings{DBLP:conf/icde/HuangL0TZC0024,
	author = {Kai Huang and
                  Yunqi Li and
                  Qingqing Ye and
                  Yao Tian and
                  Xi Zhao and
                  Yue Cui and
                  Haibo Hu and
                  Xiaofang Zhou},
	title = {{FRESH:} Towards Efficient Graph Queries in an Outsourced Graph},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {4545--4557},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00346},
	doi = {10.1109/ICDE60146.2024.00346},
	timestamp = {Thu, 07 Nov 2024 07:50:11 +0100},
	biburl = {https://dblp.org/rec/conf/icde/HuangL0TZC0024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The constantly increasing scale of graphs leads to higher costs in terms of data storage and computation. Consequently, there is a growing trend of outsourcing and analyzing graphs in clouds. As there is a concern that cloud servers may extract sensitive information from these graphs, the graphs being outsourced must be pre-anonymized, leading to increased space consumption and degraded graph query processing efficiency. Previous work has attempted to address this issue by outsourcing a compacted anonymized graph to the cloud. However, the solution typically focuses on a specific type of query, such as a subgraph query, and cannot adequately accommodate real-life scenarios where multiple applications often work concurrently on the same graph. In this paper, we propose a generic framework called FRESH to handle various graph queries efficiently within a single outsourced graph. To reduce the size of the outsourced graph, we developed a novel graph contraction scheme that transforms a big graph into a compact one while preserving graph privacy. To showcase the adaptability of classical graph query algorithms (e.g., subgraph query, triangle counting, and shortest distance query), we demonstrate their successful execution on the same compact graph created through our contraction scheme. We further extend our framework by incorporating optimizations that significantly improve query processing efficiency. Extensive experimental results demonstrate the superiority of FRESH over traditional techniques.}
}


@inproceedings{DBLP:conf/icde/XuL0XZ24,
	author = {Zizhuo Xu and
                  Lei Li and
                  Mengxuan Zhang and
                  Yehong Xu and
                  Xiaofang Zhou},
	title = {Managing the Future: Route Planning Influence Evaluation in Transportation
                  Systems},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {4558--4572},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00347},
	doi = {10.1109/ICDE60146.2024.00347},
	timestamp = {Sun, 06 Oct 2024 21:04:59 +0200},
	biburl = {https://dblp.org/rec/conf/icde/XuL0XZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Route planning and navigation systems have played an increasingly important role in our society and have a growing impact on transportation systems. The current system takes the traffic prediction as input and optimizes the routes individually. However, such a paradigm could generate congestion and deteriorate traffic conditions because the routing algorithms are not aware of their results' influence on the traffic flow. Therefore, in this paper, we identify this flaw in the current paradigm and propose a route data management system to evaluate the influence of the routing results and help improve future downstream tasks. Specifically, we first formulate traffic evaluation as a clear traffic-aware network time calibration problem and propose a simulation-based method to evaluate hundreds of thousands of routes efficiently. To support route updates on the evaluation results, we propose an RR-Index to support high throughput of route insertion, deletion, and temporal update. After that, we propose several techniques like influence terminate condition, propagation merge and ordering, and parallel processing to make it efficient enough to work in real life. Evaluations on real-world road networks verify the necessity, effectiveness, and efficiency of our methods.}
}


@inproceedings{DBLP:conf/icde/ZhouZLZ24,
	author = {Xinjie Zhou and
                  Mengxuan Zhang and
                  Lei Li and
                  Xiaofang Zhou},
	title = {Scalable Distance Labeling Maintenance and Construction for Dynamic
                  Small-World Networks},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {4573--4585},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00348},
	doi = {10.1109/ICDE60146.2024.00348},
	timestamp = {Fri, 11 Oct 2024 21:56:05 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhouZLZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Shortest path computation is a fundamental operation of many applications in small-world networks, and shortest path index has been extensively studied to achieve high query efficiency. However, small-world networks evolve continuously in real life, and their graph size expands rapidly, necessitating the investigation of efficient shortest path index maintenance and construction for large dynamic graphs. In this paper, we adopt the Core-Tree index, which has exceptional scalability while preserving high query efficiency, as the underlying shortest path index, and put forward efficient algorithms to maintain and construct it for large dynamic small-world networks. Specifically, we first propose update propagation mechanisms for our Dynamic Core-Tree (DCT) algorithm, based on which the global tree index strategy is designed for efficient query processing. Moreover, for the core index, we propose a Propagation-based Dynamic PLL incorporating coarse update and refined update phases to ensure correct and efficient index maintenance. To enhance update efficiency and scalability for the core index, we also propose novel Parallel Canonical 2-hop Labeling (PCL) and Batch PCL (BPCL) to efficiently generate minimal canonical labels and pruning point records. Experimental studies on large real-world datasets demonstrate the superiority of our methods over the state-of-the-art in terms of indexing, updating, and scalability.}
}


@inproceedings{DBLP:conf/icde/WangWJ24,
	author = {Libin Wang and
                  Raymond Chi{-}Wing Wong and
                  Christian S. Jensen},
	title = {Congestion-Mitigating Spatiotemporal Routing in Road Networks},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {4586--4599},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00349},
	doi = {10.1109/ICDE60146.2024.00349},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/WangWJ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Vehicular traffic congestion is a recurring and widespread societal phenomenon. Since drivers increasingly rely on routing services, we consider how to enhance such services to provide routes that mitigate congestion. Specifically, we propose the Congestion-mitigating Spatiotemporal Routing (CSR) problem that considers the congestion caused by vehicles following the routes provided. This problem is challenging because vehicles that follow recommended routes appear on different road segments at different times. We propose two solutions, Spatiotemporal Oblivious Routing (SOR) and Spatiotemporal Routing with History (SRH), which return routes based on the current and anticipated future traffic statuses, respectively, while offering theoretical guarantees. We also propose an update procedure for handling traffic dynamics. Extensive evaluations on real data provide insight into the properties of the solutions, indicating that SRH can reduce the number of vehicles on the most congested road segments by nearly 33 % and can process a query in less than 10 ms.}
}


@inproceedings{DBLP:conf/icde/ZhaoLZLZZ24,
	author = {Jing Zhao and
                  Lei Li and
                  Mengxuan Zhang and
                  Zihan Luo and
                  Xi Zhao and
                  Xiaofang Zhou},
	title = {A Just-In-Time Framework for Continuous Routing},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {4600--4613},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00350},
	doi = {10.1109/ICDE60146.2024.00350},
	timestamp = {Fri, 11 Oct 2024 21:56:05 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhaoLZLZZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we revisit the problem of the current routing system in terms of prediction scalability and routing result optimality. Specifically, the current traffic prediction models are not suitable for large urban networks due to the incomplete information of traffic conditions. Besides, existing routing systems can only plan the routes based on the past traffic conditions and struggle to update the optimal route for vehicles in real-time. As a result, the actual route taken by vehicles is different from the ground-truth optimal path. Therefore, we propose a Just-In-Time Predictive Route Planning framework to tackle these two problems. Firstly, we propose a Travel Time Constrained Top-\nk\nn\nShortest Path algorithm which pre-computes a set of candidate paths with several switch points. This empowers vehicles to continuously have the opportunity to switch to better paths taking into account real-time traffic condition changes. Moreover, we present a query-driven prediction paradigm with ellipse-based searching space estimation, along with an efficient multi-queries handling mechanism. This not only allows for targeted traffic prediction by prioritizing regions with valuable yet outdated traffic information, but also provides optimal results for multiple queries based on real-time traffic evolution. Evaluations on two real-life road networks demonstrate the effectiveness and efficiency of our framework and methods.}
}


@inproceedings{DBLP:conf/icde/Bian0ZY024,
	author = {Zheng Bian and
                  Xiao Yan and
                  Jiahao Zhang and
                  Man Lung Yiu and
                  Bo Tang},
	title = {{QSRP:} Efficient Reverse k-Ranks Query Processing on High-Dimensional
                  Embeddings},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {4614--4627},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00351},
	doi = {10.1109/ICDE60146.2024.00351},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Bian0ZY024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Embedding models represent users and products as high-dimensional embedding vectors and are widely used for recommendation. In this paper, we study the reverse k-\\mathbf{ranks}\nquery, which finds the users that are the most interested in a product and has many applications including product promotion, targeted advertising, and market analysis. As reverse k-\\mathbf{ranks}\nsolutions for low dimensionality (e.g., trees) fail for the high-dimensional embeddings generated by embedding models, we propose the QSRP framework. QSRP precomputes the score table between all user and product embeddings to facilitate pruning and refinement at query time. As the score table is usually large, QSRP samples some of its columns as the index to fit in memory. To tackle the problem that naive uniform sampling results in poor pruning effect, we propose query-aware sampling, which conducts sampling by explicitly maximizing the pruning effect for a set of sample queries. Moreover, we introduce regression-based pruning, which fits cheap linear functions to predict the bounds used for pruning. We also design techniques to build the index with limited memory, reduce index building time, and handle updates. We evaluate QSRP under various configurations and compare with state-of-the-art baselines. The results show that QSRP achieves shorter query time than the baselines in all cases, and the speedup is usually over 100x.}
}


@inproceedings{DBLP:conf/icde/ZengFCGZC24,
	author = {Zhihao Zeng and
                  Ziquan Fang and
                  Lu Chen and
                  Yunjun Gao and
                  Kai Zheng and
                  Gang Chen},
	title = {FedCTQ: {A} Federated-Based Framework for Accurate and Efficient Contact
                  Tracing Query},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {4628--4642},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00352},
	doi = {10.1109/ICDE60146.2024.00352},
	timestamp = {Tue, 30 Jul 2024 08:18:19 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZengFCGZC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Contact tracing query (CTQ) plays a crucial role in the prevention of epidemic diseases. In real-world applications, user trajectory, encompassing a wealth of sensitive information, is typically dispersed across various devices or organizations. Consequently, safeguarding user privacy becomes imperative in the context of CTQ. Simultaneously, for effective epidemic control, it is essential to identify contacts efficiently and accurately, enabling prompt implementation of necessary measures. However, existing CTQ studies face limitations as they struggle to concurrently meet the demands of privacy, accuracy and efficiency. This constraint impedes their practical application in real-world scenarios. To this end, we define the Federated Contact Tracing Query (F-CTQ) problem and propose the FedCTQ framework based on hierarchical federation. To the best of our knowledge, this is the first solution grounded in federation, offering a simultaneous fulfillment of privacy, accuracy and efficiency requirements. Specifically, to ensure the privacy of F-CTQ, we introduce a meticulously designed binary-based secret-sharing (BSS) scheme, which delivers an effective privacy guarantee for user data while preserving the accuracy of the query results. Concurrently, to enhance the efficiency of F-CTQ, we propose a binary-based distance tree (DistTree) index that maximizes computational resources for parallel queries. Based on DistTree, FedCTQ enables nearly the real-time and accurate execution of F-CTQ. Extensive experiments on four datasets demonstrate the superiority of FedCTQ, showcasing a remarkable performance improvement ranging from\n4.7×\nto\n14.8×\nover state-of-the-art approaches.}
}


@inproceedings{DBLP:conf/icde/LiYKWLX24,
	author = {Tieying Li and
                  Xiaochun Yang and
                  Yiping Ke and
                  Bin Wang and
                  Yinan Liu and
                  Jiaxing Xu},
	title = {Alleviating the Inconsistency of Multimodal Data in Cross-Modal Retrieval},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {4643--4656},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00353},
	doi = {10.1109/ICDE60146.2024.00353},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LiYKWLX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the explosive growth of multimodal Internet data, cross-modal hashing retrieval has become crucial for semantically searching instances across different modalities. However, existing cross-modal retrieval methods rely on assumptions of perfect consistency between modalities and between modalities and labels, which often do not hold in real-world data. We introduce two types of inconsistency: Modality-Modality (M-M) and Modality-Label (M-L) inconsistencies. We further validate the prevalent existence of inconsistent data in multimodal datasets and highlight it will reduce the accuracy of existing Cross-Modal retrieval methods. In this paper, we propose a novel framework called Inconsistency Alleviated Cross-Modal Retrieval (IA-CMR), addressing challenges posed by these inconsistencies. We first utilize two forms of contrastive learning loss and a mutual exclusion constraint to effectively disentangle modal information into modality-common hash codes and modality-unique hash codes. Our dedicated design in modality disentanglement is capable of alleviating the M-M inconsistency. Subsequently, we refine common labels through a label refinement loss and employ a Cross-modal Common Semantic Alignment module for effective alignment. The label refinement process and the CCSA module collectively handle the M-L inconsistency issue. IA-CMR outperforms 9 comparison baselines on two benchmark multimodal datasets, achieving an improvement in retrieval accuracy of up to 25.13%. The results confirm the effectiveness of IA-CMR in alleviating inconsistency and enhancing cross-modal retrieval performance.}
}


@inproceedings{DBLP:conf/icde/HeHPSS24,
	author = {Hulingxiao He and
                  Xiangteng He and
                  Yuxin Peng and
                  Zifei Shan and
                  Xin Su},
	title = {Firzen: Firing Strict Cold-Start Items with Frozen Heterogeneous and
                  Homogeneous Graphs for Recommendation},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {4657--4670},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00354},
	doi = {10.1109/ICDE60146.2024.00354},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/HeHPSS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recommendation models utilizing unique identities (IDs) to represent distinct users and items have dominated the recommender systems literature for over a decade. Since multi-modal content of items (e.g., texts and images) and knowledge graphs (KGs) may reflect the interaction-related users' preferences and items' characteristics, they have been utilized as useful side information to further improve the recommendation quality. However, the success of such methods often limits to either warm-start or strict cold-start item recommendation in which some items neither appear in the training data nor have any interactions in the test stage: (1) Some fail to learn the embedding of a strict cold-start item since side information is only utilized to enhance the warm-start ID representations; (2) The others deteriorate the performance of warm-start recommendation since unrelated multi-modal content or entities in KGs may blur the final representations. In this paper, we propose a unified framework incorporating multi-modal content of items and KGs to effectively solve both strict cold-start and warm-start recommendation termed Firzen, which extracts the user-item collaborative information over frozen heterogeneous graph (collaborative knowledge graph), and exploits the item-item semantic structures and user-user behavioral association over frozen homogeneous graphs (item-item relation graph and user-user co-occurrence graph). Furthermore, we build four unified strict cold-start evaluation benchmarks based on publicly available Amazon datasets and a real-world industrial dataset from Weixin Channels via rearranging the interaction data and constructing KGs. Extensive empirical results demonstrate that our model yields significant improvements for strict cold-start recommendation and outperforms or matches the state-of-the-art performance in the warm-start scenario. The code is available at https://github.com/PKU-ICST-MIPL/Firzen_ICDE2024.}
}


@inproceedings{DBLP:conf/icde/Ma0Z24,
	author = {Hengzhao Ma and
                  Jianzhong Li and
                  Yong Zhang},
	title = {Reconsidering Tree based Methods for k-Maximum Inner-Product Search:
                  The LRUS-CoverTree},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {4671--4684},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00355},
	doi = {10.1109/ICDE60146.2024.00355},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Ma0Z24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Existing literature on k-Maximum Inner-Product Search has made it a common belief that tree based methods are less effective in terms of index construction time and query performance compared to locality sensitive hashing based, similarity graph based and quantization based methods. However, in this paper we partially roll over the existing assessments about tree based k- Maximum Inner-Product Search methods by our newly proposed tree structure named LRUS-CoverTree. The experimental results show that the new k- Maximum Inner-Product Search algorithm based on LRUS-CoverTree outperforms the state-of-the-art locality sensitive hashing based methods, and achieves comparable performance with similarity graph based and quantization based methods in terms of query time and accuracy. What's more important, the desirable query performance is attained with significantly lower index construction time compared to all the other methods. Besides the experimental evaluations, substantial theoretical results about the LRUS-CoverTree and the new k-Maximum Inner-Product Search algorithm are provided, including construction time and search time complexity, size and height of the tree, and so on. Furthermore, several new effective upper bounds on the inner-product value are provided to support the efficient branch-and-bound algorithm on LRUS-CoverTree. In summary, our novel tree structure and new algorithm significantly improve upon existing tree based methods, and it is hoped that this contribution can lead to a reconsideration of tree based k-Maximum Inner-Product Search methods.}
}


@inproceedings{DBLP:conf/icde/Zheng0DZS024,
	author = {Zetao Zheng and
                  Jie Shao and
                  Shilong Deng and
                  Anjie Zhu and
                  Heng Tao Shen and
                  Xiaofang Zhou},
	title = {Cross-Insight Trader: {A} Trading Approach Integrating Policies with
                  Diverse Investment Horizons for Portfolio Management},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {4685--4698},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00356},
	doi = {10.1109/ICDE60146.2024.00356},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Zheng0DZS024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Deep reinforcement learning (RL) has emerged as a promising approach for portfolio management due to its ability to make sequential decisions. However, applying RL techniques to this domain is still challenging due to the non-stationary nature of financial markets. Existing RL-based solutions fail to consider the intrinsic causes behind this non-stationary, which primarily stem from the involvement of diverse traders with distinct investment horizons and their varied investment strategies. In this paper, we tackle the non-stationary problem by examining its intrinsic causes and propose cross-insight trader, a novel two-step RL-based approach that integrates multiple trading policies with different investment horizons to adapt to the changing market conditions. In the first step, we learn multiple horizon-specific policies by providing each policy with tailored information specific to its investment horizon. This allows each policy to recognize dynamic patterns within its respective horizon and make insightful pre-decisions. In the second step, we learn a cross-insight policy to make the final trade decision by considering the investment pre-decisions made by multiple horizon-specific policies in the first step. To enable effective learning of two types of policies, our approach employs a centralized critic to evaluate the actions performed by both horizon-specific and cross-insight policies. By incorporating multiple insights from different investment horizons into the decision-making process, our approach enhances its adaptability to changing market conditions. Experimental results conducted on three stock markets demonstrate the superiority of our framework.}
}


@inproceedings{DBLP:conf/icde/YuLYLDX24,
	author = {Yang Yu and
                  Meiyu Liang and
                  Mengran Yin and
                  Kangkang Lu and
                  Junping Du and
                  Zhe Xue},
	title = {Unsupervised Multimodal Graph Contrastive Semantic Anchor Space Dynamic
                  Knowledge Distillation Network for Cross-Media Hash Retrieval},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {4699--4708},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00357},
	doi = {10.1109/ICDE60146.2024.00357},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/YuLYLDX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cross-media hash retrieval are efficient and effective techniques for retrieval on multi-media database. The success of the Multimodal Large Models (MLM) provides a valuable direction to enhance the accuracy of multimodal hash retrieval, which achieves decent retrieval accuracy with finetuning the pretrained multimodal large models, but their massive model parameters significantly reduce retrieval efficiency. Knowledge Distillation (KD) methods enable small models to learn from the knowledge of larger models, achieving a reduction in model parameter count while ensuring a certain level of accuracy. However, current KD methods face challenges when applied in the multimodal domain, as it requires preserving the multimodal semantic information while minimizing accuracy degradation. To address these challenges, we propose a novel unsupervised multimodal graph contrastive semantic anchor space dynamic knowledge distillation network for cross-media hash retrieval (GASKN). Firstly, to obtain a multimodal semantic anchor space, we construct a large multimodal fusion teacher model using the BEiT-3 model as the backbone. This teacher model is capable of encoding data from different modalities, such as images and text, using the same multimodal encoder to acquire multimodal hash codes that contain rich information from both modalities simultaneously. Secondly, to ensure efficient retrieval capabilities for the student model, we utilize the ALBERT text encoding model and the BiFormer image encoding model as the compact student model's backbones. This allows us to build a lightweight student model with only a twentieth of the parameter count of the teacher model. We propose a dynamic knowledge distillation technique to transfer the multimodal semantic anchor space knowledge embedded in the multimodal large teacher model to the lightweight student model as much as possible. Thirdly, to further distill the structural knowledge of the semantic anchor space from the teacher model to the student model, we propose a graph attention contrastive learning mechanism, which enables structural semantic space learning, thereby mining implicit fine-grained cross-media semantic information. By evaluating our method using three widely-used datasets, we demonstrate that GASKN is able to significantly outperform existing state-of-the-art hashing algorithms.}
}


@inproceedings{DBLP:conf/icde/Zheng00ZDS24,
	author = {Zetao Zheng and
                  Jie Shao and
                  Feiyu Chen and
                  Anjie Zhu and
                  Shilong Deng and
                  Heng Tao Shen},
	title = {{HIT:} Solving Partial Index Tracking via Hierarchical Reinforcement
                  Learning},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {4709--4721},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00358},
	doi = {10.1109/ICDE60146.2024.00358},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Zheng00ZDS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Partial index tracking (PIT) is a popular passive investment strategy aiming at replicating the performance of a market index (e.g., S&P 500). Existing PIT methods typically treat it as a regression problem and divide it into two tasks: (i) asset selection (determining which assets to choose from the index constituents) and (ii) asset allocation (deciding how to allocate capital among the selected assets). However, these methods either optimize these two tasks jointly, which has been proven to be NP-hard and inefficient when tracking large-scale constituent indices (e.g., Russell 2000), or attempt an independent optimization, lacking a connection to ensure collaborative optimization. In this paper, we present a hierarchical model for partial index tracking (HIT), which formulates PIT as a hierarchical Markov decision process (MDP) and is optimized via hierarchical reinforcement learning (HRL). HIT consists of (1) a high-level policy learns to select assets from constituents to handle task (i) and (2) a low-level policy learns to allocate capital weights among the selected assets to handle task (ii). We further propose a novel cost-sensitive reward function that serves as a connection to collaboratively optimize the two policies, aiming to replicate the index closely while considering transaction cost. Compared with existing jointly optimized approaches, our model simplifies the problem by learning separate policies for the two tasks, and the reward function serves as a connection to ensure collaborative optimization between them, avoiding challenges faced by joint optimization methods in existing literature. Remarkable performance across 6 benchmarks, ranging from small to large-scale constituents demonstrate the superiority of HIT. Moreover, the experiments conducted on a real-world market dataset spanning over 10 years show its effectiveness and practicality.}
}


@inproceedings{DBLP:conf/icde/0002W0ET24,
	author = {Jing Xie and
                  James B. Wendt and
                  Yichao Zhou and
                  Seth Ebner and
                  Sandeep Tata},
	title = {FieldSwap: Data Augmentation for Effective Form-Like Document Extraction},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {4722--4732},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00359},
	doi = {10.1109/ICDE60146.2024.00359},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/0002W0ET24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Extracting structured data from visually rich documents like invoices, receipts, financial statements, and tax forms is key to automating many business workflows. However, building extraction models in this domain often demands a large collection of high-quality training examples. To address this challenge, we introduce FieldSwap, a novel data augmentation technique specifically designed for such extraction problems. FieldSwap generates synthetic training examples by replacing key phrases indicative of one field with those corresponding to another. Our experiments on five diverse datasets demonstrate that incorporating FieldSwap-augmented data into the training process can enhance model performance by 1–11 F1 points, particularly when dealing with limited training data (10–100 documents). Additionally, we propose algorithms for automatically inferring key phrases from the training data. Our findings indicate that FieldSwap is effective regardless of whether key phrases are manually provided by human experts or inferred automatically.}
}


@inproceedings{DBLP:conf/icde/ChuHWYZZL24,
	author = {Xiaokai Chu and
                  Changying Hao and
                  Shuaiqiang Wang and
                  Dawei Yin and
                  Jiashu Zhao and
                  Lixin Zou and
                  Chenliang Li},
	title = {LT\({}^{\mbox{2}}\)R: Learning to Online Learning to Rank for Web
                  Search},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {4733--4746},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00360},
	doi = {10.1109/ICDE60146.2024.00360},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ChuHWYZZL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Online learning to rank (OLTR), which directly optimizes the ranker with interactive user feedback, has gained considerable attention in both academia and industry. However, most current approaches suffer from the inefficiency of heuristic exploration strategies, which can seriously hurt users' experience. Furthermore, the existing OLTR solutions fail to learn from the cost-effective logged data, blocking their usage in the real industrial system. To handle the above issues, we in this paper introduce a new OLTR framework LT 2 R, namely Learning To online Learning to Rank. LT 2 R aims to study an efficient parameterized exploration strategy, by which a ranker could converge to the optimal ranking with as few exploration steps as possible. Specifically, we formulate the OLTR task as a typical Markov Decision Process and introduce an online reinforcement learning algorithm with a multi-round cumulative reward to guarantee fast convergence. Moreover, we contribute an offline learning algorithm for LT 2 R to exploit the knowledge from the historical searching logs, which can provide a fair warm-up model for its industrial deployment. Extensive experiments on both benchmark datasets and Baidu search engine have demonstrated its superiority over state-of-the-art methods.}
}


@inproceedings{DBLP:conf/icde/WangKXCGHZ24,
	author = {Mengzhao Wang and
                  Xiangyu Ke and
                  Xiaoliang Xu and
                  Lu Chen and
                  Yunjun Gao and
                  Pinpin Huang and
                  Runkai Zhu},
	title = {{MUST:} An Effective and Scalable Framework for Multimodal Search
                  of Target Modality},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {4747--4759},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00361},
	doi = {10.1109/ICDE60146.2024.00361},
	timestamp = {Tue, 30 Jul 2024 08:18:20 +0200},
	biburl = {https://dblp.org/rec/conf/icde/WangKXCGHZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We investigate the problem of multimodal search of target modality, where the task involves enhancing a query in a specific target modality by integrating information from auxiliary modalities. The goal is to retrieve relevant objects whose contents in the target modality match the specified multimodal query. The paper first introduces two baseline approaches that integrate techniques from the Database, Information Retrieval, and Computer Vision communities. These baselines either merge the results of separate vector searches for each modality or perform a single-channel vector search by fusing all modalities. However, both baselines have limitations in terms of efficiency and accuracy as they fail to adequately consider the varying importance of fusing information across modalities. To overcome these limitations, the paper proposes a novel framework, Multimodal Search of Target Modality, called MUST. Our framework employs a hybrid fusion mechanism, combining different modalities at multiple stages. Notably, we leverage vector weight learning to determine the importance of each modality, thereby enhancing the accuracy of joint similarity measurement. Additionally, the proposed framework utilizes a fused proximity graph index, enabling efficient joint search for multimodal queries. MUST offers several other advantageous properties, including a plug-gable design to integrate any advanced embedding techniques, user flexibility to customize weight preferences, and modularized index construction. Extensive experiments on real-world datasets demonstrate the superiority of MUST over the baselines in terms of both search accuracy and efficiency. Our framework achieves over 10× faster search times while attaining an average of 93% higher accuracy. Furthermore, MUST exhibits scalability to datasets containing more than 10 million data elements.}
}


@inproceedings{DBLP:conf/icde/HeZ0G0Y24,
	author = {Chengkun He and
                  Xiangmin Zhou and
                  Chen Wang and
                  Iqbal Gondal and
                  Jie Shao and
                  Xun Yi},
	title = {Online Anomaly Detection over Live Social Video Streaming},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {4760--4772},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00362},
	doi = {10.1109/ICDE60146.2024.00362},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/HeZ0G0Y24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Social video anomaly is an observation in video streams that does not conform to a common pattern of dataset's behaviour. Social video anomaly detection plays a critical role in applications from e-commerce to e-Iearning. Traditionally, anomaly detection techniques are applied to find anomalies in video broadcasting. However, they neglect the live social video streams which contain interactive talk, speech, or lecture with audience. In this paper, we propose a generic framework for effectively online detecting Anomalies Over social Video LI ve Streaming (AOVLIS). Specifically, we propose a novel deep neural network model called Coupling Long Short-Term Memory (CLSTM) that adaptively captures the history behaviours of the presenters and audience, and their mutual interactions to predict their behaviour at next time point over streams. Then we well integrate the CLSTM with a decoder layer, and propose a new reconstruction error-based scoring function REI A to calculate the anomaly score of each video segment for anomaly detection. After that, we propose a novel model update scheme that incrementally maintains CLSTM and decoder. Moreover, we design a novel upper bound and ADaptive Optimisation Strategy (ADOS) for improving the efficiency of our solution. Extensive experiments are conducted to prove the superiority of AOVLIS.}
}


@inproceedings{DBLP:conf/icde/GaoLM24,
	author = {Xiangyu Gao and
                  Jianzhong Li and
                  Dongjing Miao},
	title = {Computing All Restricted Skyline Probabilities on Uncertain Datasets},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {4773--4786},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00363},
	doi = {10.1109/ICDE60146.2024.00363},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/GaoLM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Restricted skyline (rskyline) query is widely used in multi-criteria decision making. It generalizes the skyline query by additionally considering a set of personalized scoring functions\nF\n. Since uncertainty is inherent in datasets for multi-criteria decision making, we study rskyline queries on uncertain datasets from both complexity and algorithm perspective. We formalize the problem of computing rskyline probabilities of all data items and show that no algorithm can solve this problem in truly subquadratic-time, unless the orthogonal vectors conjecture fails. Considering that linear scoring functions are widely used in practical applications, we propose two efficient algorithms for the case where\nF\nis a set of linear scoring functions whose weights are described by linear constraints, one with near-optimal time complexity and the other with better expected time complexity. For special linear constraints involving a series of weight ratios, we further devise an algorithm with sublinear query time and polynomial preprocessing time. Extensive experiments demonstrate the effectiveness, efficiency, scalability, and usefulness of our proposed algorithms.}
}


@inproceedings{DBLP:conf/icde/DongFB0XC024,
	author = {Siyuan Dong and
                  Zhuochen Fan and
                  Tianyu Bai and
                  Tong Yang and
                  Hanyu Xue and
                  Peiqing Chen and
                  Yuhan Wu},
	title = {{M4:} {A} Framework for Per-Flow Quantile Estimation},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {4787--4800},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00364},
	doi = {10.1109/ICDE60146.2024.00364},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/DongFB0XC024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The field of quantile estimation has grown in importance due to its myriad practical applications. Recent research trends have evolved from estimating the quantile for a single data stream to developing data structures that can concurrently estimate quantiles for multiple sub-streams, also known as flows. This paper introduces a novel framework, M4, designed to estimate per-flow quantiles in data streams accurately. M4 is a versatile framework that can be integrated with a wide array of single-flow quantile estimation algorithms, thereby enabling them to perform per-flow estimation. The framework employs a sketch-based approach to provide a space-efficient method for recording and extracting distribution information. M4 incorporates two techniques: MINIMUM and SUM. The MINIMUM technique minimizes the noise on a flow from other flows caused by hash collisions, while the SUM technique efficiently categorizes flows based on their sizes and customizes treatment strategies accordingly. We demonstrate the application of M4 on three single-flow quantile estimation algorithms (DDSketch, t-digest, and ReqSketch), detailing the specific implementation of the MINIMUM and SUM techniques. We provide theoretical proof that M4 delivers high accuracy while utilizing limited memory. Additionally, we conduct extensive experiments to evaluate the performance of M4 regarding accuracy and speed. The experimental results indicate that across all three example algorithms, M4 significantly outperforms two comparison frameworks in terms of accuracy for per-flow quantile estimation while maintaining comparable speed.}
}


@inproceedings{DBLP:conf/icde/LiuBWDC24,
	author = {Jiaqian Liu and
                  Ran Ben Basat and
                  Louis De Wardt and
                  Haipeng Dai and
                  Guihai Chen},
	title = {{DISCO:} {A} Dynamically Configurable Sketch Framework in Skewed Data
                  Streams},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {4801--4814},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00365},
	doi = {10.1109/ICDE60146.2024.00365},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LiuBWDC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Sketches have gained popularity as effective methods for estimating frequency in data streams, and optimizing their accuracy is critical in many applications. However, while sketches are backed by a standard guarantee under the worst-case analysis, their actual errors can vary significantly with real-world skewed data streams. Therefore, it is challenging to configure sketches to optimize accuracy without prior knowledge of the input. Moreover, even with a new configuration, it is unclear when to apply it. This paper presents a novel sketch framework that can be dy-namically configured to optimize the accuracy given a processed data stream. Specifically, we provide a precise guarantee and derive an optimal number of hash functions under the Zipfian distribution, which is an appropriate way to model skewed data streams in practice. We then propose a dynamically configurable sketch framework, namely DISCO, that can estimate the distri-bution parameter and adjust the number of hash functions on the fly to optimize accuracy. We provide rigorous mathematical analysis and apply DISCO to three classical solutions, including the Count-min, Conservative Update, and Count sketches. Experimental results, using synthetic and real datasets, show that DISCO can achieve the optimal configuration for the metric (i.e., FP) related to the sketch guarantee, while achieving near-optimal accuracy for other common metrics (e.g., ARE) compared with state-of-the-art methods.}
}


@inproceedings{DBLP:conf/icde/ShiJLLYJXZY24,
	author = {Qilong Shi and
                  Chengjun Jia and
                  Wenjun Li and
                  Zaoxing Liu and
                  Tong Yang and
                  Jianan Ji and
                  Gaogang Xie and
                  Weizhe Zhang and
                  Minlan Yu},
	title = {BitMatcher: Bit-level Counter Adjustment for Sketches},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {4815--4827},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00366},
	doi = {10.1109/ICDE60146.2024.00366},
	timestamp = {Sun, 04 Aug 2024 19:37:46 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ShiJLLYJXZY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Sketch has been widely used in the field of large-scale data stream processing. However, common fixed-counter algorithms such as Count-Min Sketch have to allocate larger counters, which wastes a lot of memory due to the high skewness of real-world data streams. To reduce memory usage, we propose to dynamically adjust the counter size that matches the distribution of the data stream. We introduce BitMatcher, a fast global-adjusting algorithm that automatically adjusts the counter to the appropriate size to match the data stream. During stream processing, BitMatcher identifies items hashed into a bucket based on isolated fingerprints. If it overflows, BitMatcher changes the flag bits in the bucket and dynamically increases or shrinks the size of some counters in a fine-grained manner. BitMatcher can also relocate a cold item in the bucket with the idea of cuckoo hashing to preserve the potential hot item while achieving global load balancing. Through the above way of dealing with overflow caused by skewed data, BitMatcher precisely manipulates allocated bits and maximizes memory utilization. The experiments show that BitMatcher has high throughput and can outperform SOTA by up to 4 orders of magnitude in terms of accuracy. We also deployed BitMatcher on several platforms, showing its software and hardware scalability.}
}


@inproceedings{DBLP:conf/icde/Gabory0LPZ24,
	author = {Est{\'{e}}ban Gabory and
                  Chang Liu and
                  Grigorios Loukides and
                  Solon P. Pissis and
                  Wiktor Zuba},
	title = {Space-Efficient Indexes for Uncertain Strings},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {4828--4842},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00367},
	doi = {10.1109/ICDE60146.2024.00367},
	timestamp = {Sun, 06 Oct 2024 21:04:57 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Gabory0LPZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Strings in the real world are often encoded with some level of uncertainty, for example, due to: unreliable data measurements; flexible sequence modeling; or noise introduced for privacy protection. In the character-level uncertainty model, an uncertain string X of length $n$ on an alphabetΣ is a sequence of $n$ probability distributions over Σ. Given an uncertain string $X$ and a weight threshold $\\frac {1}{z}\\in(0,1)$ , we say that pattern $P$ occurs in $X$ at position $i$ , if the product of probabilities of the letters of $P$ at positions $i,\\ldots, i+ \\vert P\\vert-1$ is at least $\\frac {1}{z}$ . While indexing standard strings for online pattern searches can be performed in linear time and space, indexing uncertain strings is much more challenging. Specifically, the state-of-the-art index for uncertain strings has $O(nz)$ size, requires $O(nz)$ time and $O(nz)$ space to be constructed, and answers pattern matching queries in the optimal $O(m+ [Occl)$ time, where $m$ is the length of $P$ and $\\vert Occ\\vert$ is the total number of occurrences of $P$ in $X$ . For large $n$ and (moderate) $z$ values, this index is completely impractical to construct, which outweighs the benefit of the supported optimal pattern matching queries. We were thus motivated to design a space-efficient index at the expense of slower yet competitive pattern matching queries. We show that when we have at hand a lower bound ℓ on the length of the supported pattern queries, as is often the case in real-world applications, we can slash the index size and the construction space roughly by ℓ. In particular, we propose an index of $Q (n/ \\log z)$ expected size, which can be constructed using $Q (n/ \\log z)$ expected space, and supports very fast pattern matching queries in expectation, for patterns of length m ≥ ℓ. We have implemented and evaluated several versions of our index. The best-performing version of our index is up to two orders of magnitude smaller than the state of the art in terms of both index size and construction space, while offering faster or very competitive query and construction times.}
}


@inproceedings{DBLP:conf/icde/ChenGTX24,
	author = {Tianyi Chen and
                  Jun Gao and
                  Yaofeng Tu and
                  Mo Xu},
	title = {{GLO:} Towards Generalized Learned Query Optimization},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {4843--4855},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00368},
	doi = {10.1109/ICDE60146.2024.00368},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ChenGTX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent years, there has been a growing interest in the application of deep reinforcement learning (DRL) techniques on query execution plan generation. Although current DRL-based query optimizers achieve competitive performance against traditional methods on specific query workloads, these methods encounter issues when generalizing to workloads unseen during training. Thus, we propose GLO to address the limitations and step towards generalized learned query optimization. First, rather than using ungeneralizable table-specific one-hot labels in almost all existing work, GLO relies on statistical information of the well-established underlying DBMS along with table patterns extracted via a clustering algorithm, enabling GLO to enhance generalization in different scenarios. Second, GLO improves the information capture of plans by integrating Transformer layers into the DRL value model, empowering the model's capability to handle diverse queries with deeper networks and more parameters in plan generation. In addition, GLO allows the injection of cost estimations from the DBMS as external knowledge for better generalization. Third, GLO recognizes and replaces disastrously poor plans by making comparisons between generated plans and those produced by the DBMS. We establish our experiments on composite workloads that combine various query sets including JOB, Extended JOB, TPC-DS, and Stack. The results demonstrate that GLO outperforms previous state-of-the-art learned optimizers, with a speed 1.4x faster than LOGER and 2.1x faster than Balsa on TPC-DS when TPC-DS queries are completely unknown during training. To the best of our knowledge, GLO is the first learned optimizer that directly generates plans while possessing the preliminary generalization ability across different query workloads.}
}


@inproceedings{DBLP:conf/icde/LanBCBD24,
	author = {Hai Lan and
                  Zhifeng Bao and
                  J. Shane Culpepper and
                  Renata Borovica{-}Gajic and
                  Yu Dong},
	title = {A Fully On-Disk Updatable Learned Index},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {4856--4869},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00369},
	doi = {10.1109/ICDE60146.2024.00369},
	timestamp = {Sun, 06 Oct 2024 21:04:57 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LanBCBD24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {While in-memory learned indexes have shown promising performance as compared to B+-tree, most widely used databases in real applications still rely on disk-based operations. From our experiments, we observe that directly applying the ex-isting in-memory learned indexes into on-disk setting suffers from several drawbacks and cannot outperform a standard B+-tree in most cases. Therefore, we make the first attempt to show how the idea of learned index can benefit the on-disk index by proposing AULID, a fully on-disk updatable learned index that can achieve state-of-the-art performance across multiple workload types. The AULID approach combines the benefits from both traditional indexing techniques and the learned indexes to reduce the I/O cost - the main overhead under disk setting. Specifically, three aspects are taken into consideration in reducing I/O costs: (1) reduce the overhead in updating the index structure; (2) induce shorter paths from root to leaf node; (3) achieve better locality to minimize the number of block reads required to complete a scan. Five principles are proposed to guide the design of AULID which shows remarkable performance gains and meanwhile is easy to implement. Our evaluation shows that AULI D has comparable storage costs to a B+-tree and is much smaller than other learned indexes, and AULID is up to 2.11x, 8.63x, 1.72x, 5.51x, and 8.02x more efficient than FITing-tree, PGM, B+-tree, ALEX, and LIPP.}
}


@inproceedings{DBLP:conf/icde/YueX0TL24,
	author = {Qiang Yue and
                  Xiaoliang Xu and
                  Yuxiang Wang and
                  Yikun Tao and
                  Xuliyuan Luo},
	title = {Routing-Guided Learned Product Quantization for Graph-Based Approximate
                  Nearest Neighbor Search},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {4870--4883},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00370},
	doi = {10.1109/ICDE60146.2024.00370},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/YueX0TL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Given a vector dataset\nX\n, a query vector\nx\n⃗ \nq\n, graph-based Approximate Nearest Neighbor Search (ANNS) aims to build a proximity graph (PG) as an index of\nX\nand approximately return vectors with minimum distances to\nx\n⃗ \nq\nby searching over the PG index. It has been widely recognized that graph-based ANNS is effective and efficient, however, it suffers from the large-scale\nX\nbecause of the entire PG is too large to fit into the memory. To solve this, Product Quantization (PQ) integrated graph-based ANNS is proposed to reduce the memory usage, by replacing a large PG with original vectors by the one with smaller compact codes of quantized vectors. Existing PQ methods do not consider the important routing features of PG, thus resulting in low-quality quantized vectors that significantly affect the ANNS's effectiveness. In this paper, we present an end-to-end Routing-guided learned Product Quantization (RPQ) for graph-based ANNS, which easily can be adaptive to existing popular PGs. Specifically, RPQ consists of (1) a differentiable quantizer used to make the standard discrete PQ differentiable to suit for back-propagation of end-to-end learning, (2) a sampling-based feature extractor used to extract neighborhood and routing features of a PG by using the quantized vectors, and (3) a multi-feature joint training module with two types of feature-aware losses to continuously optimize the differentiable quantizer. As a result, the inherent features of a specific PG would be embedded into the learned PQ, thus generating high-quality quantized vectors that facilitate the graph-based ANNS's effectiveness and efficiency. Moreover, we integrate our RPQ with the state-of-the-art DiskANN and existing PGs to improve their performance. Comprehensive experimental studies on real-world large-scale datasets (scale from 1M to 1B) demonstrate RPQ's superiority.}
}


@inproceedings{DBLP:conf/icde/MandamadiotisKA24,
	author = {Antonis Mandamadiotis and
                  Georgia Koutrika and
                  Sihem Amer{-}Yahia},
	title = {Guided SQL-Based Data Exploration with User Feedback},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {4884--4896},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00372},
	doi = {10.1109/ICDE60146.2024.00372},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/MandamadiotisKA24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The exploration of large, real-world databases poses major challenges to users due to their volume and complexity. SQL is the preferred language for data exploration. However, the process of iteratively refining SQL queries is tedious and time consuming. We formulate the automation of personalized SQL-based data exploration as the problem of suggesting the most relevant query and accounting for user feedback at each step. We develop an end-to-end solution and a system to assist users in exploring different components of a complex database. We instantiate our solution using Multi-Armed Bandits, a category of algorithms that are suitable for interactive online learning by balancing exploration with exploitation. We design a lightweight algorithm to personalize stepwise SQL recommendations that efficiently discovers the current user preferences in coordination with that user's feedback and what other users prefer. We run extensive experiments that demonstrate the utility of our approach for large-scale data exploration.}
}


@inproceedings{DBLP:conf/icde/Mu0TS24,
	author = {Tianyu Mu and
                  Hongzhi Wang and
                  Haoyun Tang and
                  Xinyue Shao},
	title = {ShrinkHPO: Towards Explainable Parallel Hyperparameter Optimization},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {4897--4910},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00371},
	doi = {10.1109/ICDE60146.2024.00371},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Mu0TS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this era of exploding data volumes, more and more complex data analysis tasks are now accomplished by machine learning (ML) or deep learning (DL). Despite the powerful and flexible task processing capability, it also brings challenges such as how to reasonably design the optimal hyperparameters configuration and the huge consumption of time for a single validation. Existing Hyperrarameter Optimization (HPO) methods are gradually facing performance bottlenecks. However, in an era where progressively data-centric big data analytics methods are prevalent, such efficiency issues need to be urgently addressed in the design of intelligent DBMS. In this paper, we propose ShrinkHPO, an efficient and explainable-designed HPO approach with a major focus on (\na\n) efficient hyperparameter configuration search strategy, (b) asynchronous executing intervention, and (c) XAI (eXplainable AI) design. ShrinkHPO employs a hyperparameter weight estimation strategy named Shrink-search together with an asynchronous execution design to improve HPO efficiency. To the best of our knowledge, ShrinkHPO is the first HPO method that introduces explainable analysis and verification to ensure the judgment of “high significance” hyperparameters. We also conduct a series of experiments on data analysis tasks in the database domain (classification, regression, time series classification, CASH [1], etc.), collecting HPO results on the usual ML or DL models in each task. Compared to SOTA asynchronous and sequential HPO baselines, ShrinkHPO achieves top performance on both accuracy (RMSE for regression tasks) and time cost, accelerating from 20% to a maximum of 2.2 x.}
}


@inproceedings{DBLP:conf/icde/JiXW024,
	author = {Zhaoxuan Ji and
                  Zhongle Xie and
                  Yuncheng Wu and
                  Meihui Zhang},
	title = {{LBSC:} {A} Cost-Aware Caching Framework for Cloud Databases},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {4911--4924},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00373},
	doi = {10.1109/ICDE60146.2024.00373},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/JiXW024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Caching is a crucial solution to alleviate the high latency and low bandwidth of cloud databases. However, existing caching algorithms are not suitable for cloud databases as 1) they cannot ensure the adaptability to changing workloads; 2) they are not designed with awareness of data fetching costs. Combining learning-based models with cost-aware caching algorithms is natural for better performance. However, it is challenging due to the absence of the oracle algorithm for guiding the learning model. Moreover, current learning models incur significant computation overheads, potentially worsening the performance of cloud databases. In this paper, we propose a learning-based cost-aware caching framework called LBSC for cloud databases, ensuring faster query execution and robust performance in dynamic workloads. We first introduce an approximately optimal oracle algorithm called BeladySizeCost, which retains data items with high cost per byte that are likely to be accessed in near future. Then, we present a lightweight supervised learning-based model that learns from BeladySizeCost to predict the eviction probability of the cached data. Moreover, we design effective optimizations to reduce the computation overheads of the learning-based algorithm. Extensive experiments in both simulations and real-world cloud databases demonstrate that the proposed framework significantly outperforms the state-of-the-art baselines.}
}


@inproceedings{DBLP:conf/icde/LiangCXYCX024,
	author = {Zibo Liang and
                  Xu Chen and
                  Yuyang Xia and
                  Runfan Ye and
                  Haitian Chen and
                  Jiandong Xie and
                  Kai Zheng},
	title = {{DACE:} {A} Database-Agnostic Cost Estimator},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {4925--4937},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00374},
	doi = {10.1109/ICDE60146.2024.00374},
	timestamp = {Tue, 30 Jul 2024 08:18:18 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LiangCXYCX024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cost estimation is of great importance in query optimization. However, traditional optimizers compute the cost based on heuristics, sacrificing accuracy for efficiency. In recent years, learning-based cost estimation models have achieved high accuracy. However, their poor robustness and inefficiency lead to their failure to meet the needs of practical scenarios. We propose a lightweight and Database-Agnostic Cost Estimation model (DACE) to address the above limitations. To further improve the effectiveness of DACE, we design a tree-structure-based loss adjustment strategy to learn sub-plan information and solve the information redundancy problem. As a pretrained estimator, DACE can efficiently make accurate predictions on unseen databases. For more complex scenarios, we fine-tune DACE with LoRA. The excellent efficiency allows DACE to adapt to challenging scenarios with minimal effort. As a pretrained encoder, DACE can improve the accuracy and robustness of other cost estimation models through knowledge integration and solve the notorious cold start problem. Extensive experiments have shown that DACE's accuracy, efficiency, and robustness are much better than existing methods.}
}


@inproceedings{DBLP:conf/icde/LiR0L24,
	author = {Jinhong Li and
                  Yanjing Ren and
                  Shujie Han and
                  Patrick P. C. Lee},
	title = {Enhancing LSM-Tree Key-Value Stores for Read-Modify-Writes via Key-Delta
                  Separation},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {4938--4950},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00375},
	doi = {10.1109/ICDE60146.2024.00375},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LiR0L24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Read-modify-writes (RMWs) are increasingly observed in practical key-value (KV) storage workloads to support fine-grained updates. To make RMWs efficient, one approach is to write deltas (i.e., changes to current values) to the log-structured merge-tree (LSM-tree), yet it increases the read overhead caused by retrieving and combining a chain of deltas. We propose a notion called key-delta (KD) separation to support efficient reads and RMWs in LSM-tree KV stores under RMW-intensive workloads. KD separation aims to store deltas in separate storage areas and group deltas into storage units called buckets, such that all deltas of a key are kept in the same bucket and can be all together accessed in subsequent reads. To this end, we build KDSep, a middleware layer that realizes KD separation and integrates KDSep into state-of-the-art LSM-tree KV stores (e.g., RocksDB and BlobDB). We show that KDSep achieves significant I/O throughput gains and read latency reduction under RMW-intensive workloads while preserving the efficiency in general workloads.}
}


@inproceedings{DBLP:conf/icde/HeXL00024,
	author = {Huajun He and
                  Zihang Xu and
                  Ruiyuan Li and
                  Jie Bao and
                  Tianrui Li and
                  Yu Zheng},
	title = {TMan: {A} High-Performance Trajectory Data Management System Based
                  on Key-Value Stores},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {4951--4964},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00376},
	doi = {10.1109/ICDE60146.2024.00376},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/HeXL00024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The effective management of trajectory data heavily relies on the utilization of fundamental spatio-temporal queries. The surge in trajectory data, with its dynamic spatio-temporal properties, poses notable management challenges. Existing systems are inadequate in providing fine-grained trajectory representations and efficient architecture for processing queries, leading to significant computational overhead. This paper introduces TMan to address these challenges. First, TMan presents two innovative index structures that precisely capture the spatio-temporal characteristics of trajectory data. Compared to the state-of-the-art indexes, our indexes for temporal range and spatial range queries can reduce the number of retrievals by up to 77% and 83%, respectively. Next, TMan devises concise and effective encoding methods for these indexes. Leveraging these indexes, TMan provides a distributed storage structure and an index caching mechanism for efficiently managing trajectories in key-value data stores. Moreover, TMan introduces a parallel query processing approach incorporating a push-down strategy to enhance the efficiency of fundamental queries. Extensive experimental results demonstrate that TMan's index structures and architecture outperform the baselines.}
}


@inproceedings{DBLP:conf/icde/ModiTMKGD24,
	author = {Aniket Modi and
                  Rohan Tikmany and
                  Tanu Malik and
                  Raghavan Komondoor and
                  Ashish Gehani and
                  Deepak D'Souza},
	title = {Kondo: Efficient Provenance-Driven Data Debloating},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {4965--4978},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00377},
	doi = {10.1109/ICDE60146.2024.00377},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ModiTMKGD24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Isolation increases upfront costs of provisioning containers. This is due to unnecessary software and data in container images. While several static and dynamic analysis methods for pruning unnecessary software are known, less attention has been paid to pruning unnecessary data. In this paper, we address the problem of determining and reducing unused data within a containerized application. Current data lineage methods can be used to detect data files that are never accessed in any of the observed runs, but this leads to a pessimistic amount of debloating. It is our observation that while an application may access a data file, it often accesses only a small portion of it over all its runs. Based on this observation, we present an approach and a tool Kondo, which aims to identify the set of all possible offsets that could be accessed within the data files over all executions of the application. Kondo works by fuzzing the parameter inputs to the application, and running it on the fuzzed inputs, with vastly fewer runs than brute force execution over all possible parameter valuations. Our evaluation on realistic benchmarks shows that Kondo is able to achieve 63% reduction in data file sizes and 98% recall against the set of all required offsets, on average.}
}


@inproceedings{DBLP:conf/icde/XiaDCJ0LW0024,
	author = {Mingze Xia and
                  Sheng Di and
                  Franck Cappello and
                  Pu Jiao and
                  Kai Zhao and
                  Jinyang Liu and
                  Xuan Wu and
                  Xin Liang and
                  Hanqi Guo},
	title = {Preserving Topological Feature with Sign-of-Determinant Predicates
                  in Lossy Compression: {A} Case Study of Vector Field Critical Points},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {4979--4992},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00378},
	doi = {10.1109/ICDE60146.2024.00378},
	timestamp = {Tue, 12 Nov 2024 16:50:49 +0100},
	biburl = {https://dblp.org/rec/conf/icde/XiaDCJ0LW0024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Lossy compression has been employed to reduce the unprecedented amount of data produced by today's large-scale scientific simulations and high-resolution instruments. To avoid loss of critical information, state-of-the-art scientific lossy compressors provide error controls on relatively simple metrics such as absolute error bound. However, preserving these metrics does not translate to the preservation of topological features, such as critical points in vector fields. To address this problem, we investigate how to effectively preserve the sign of determinant in error-controlled lossy compression, as it is an important quantity of interest used for the robust detection of many topological features. Our contribution is three-fold. (1) We develop a generic theory to derive the allowable perturbation for one row of a matrix while preserving its sign of the determinant. As a practical use-case, we apply this theory to preserve critical points in vector fields because critical point detection can be reduced to the result of the point-in-simplex test that purely relies on the sign of determinants. (2) We optimize this algorithm with a speculative compression scheme to allow for high compression ratios and efficiently parallelize it in distributed environments. (3) We perform solid experiments with real-world datasets, demonstrating that our method achieves up to 440% improvements in compression ratios over state-of-the-art lossy compressors when all critical points need to be preserved. Using the parallelization strategies, our method delivers up to 1.25 x and 4.38 x performance speedup in data writing and reading compared with the vanilla approach without compression.}
}


@inproceedings{DBLP:conf/icde/IslerCGKL24,
	author = {Devri\c{s} \.{I}\c{s}ler and
                  Elisa Cabana and
                  {\'{A}}lvaro Garc{\'{\i}}a{-}Recuero and
                  Georgia Koutrika and
                  Nikolaos Laoutaris},
	title = {FreqyWM: Frequency Watermarking for the New Data Economy},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {4993--5007},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00379},
	doi = {10.1109/ICDE60146.2024.00379},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/IslerCGKL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We present a novel technique for modulating the appearance frequency of a few tokens within a dataset for encoding an invisible watermark that can be used to protect ownership rights upon data. We develop optimal as well as fast heuristic algorithms for creating and verifying such watermarks. We also demonstrate the robustness of our technique against various attacks and derive analytical bounds for the false positive probability of erroneously “detecting” a watermark on a dataset that does not carry it. Our technique is applicable to both single dimensional and multidimensional datasets, is independent of token type, allows for a fine control of the introduced distortion, and can be used in a variety of use cases that involve buying and selling data in contemporary data marketplaces.}
}


@inproceedings{DBLP:conf/icde/LiDNZGY024,
	author = {Youhua Li and
                  Hanwen Du and
                  Yongxin Ni and
                  Pengpeng Zhao and
                  Qi Guo and
                  Fajie Yuan and
                  Xiaofang Zhou},
	title = {Multi-Modality is All You Need for Transferable Recommender Systems},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5008--5021},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00380},
	doi = {10.1109/ICDE60146.2024.00380},
	timestamp = {Sun, 04 Aug 2024 19:37:46 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LiDNZGY024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {ID-based Recommender Systems (RecSys), where each item is assigned a unique identifier and subsequently converted into an embedding vector, have dominated the de-signing of RecSys. Though prevalent, such ID-based paradigm is not suitable for developing transferable RecSys and is also susceptible to the cold -start issue. In this paper, we unleash the boundaries of the ID- based paradigm and propose a Pure Multi-Modality based Recommender system (PMMRec), which relies solely on the multi-modal contents of the items (e.g., texts and images) and learns transition patterns general enough to transfer across domains and platforms. Specifically, we design a plug-and-play framework architecture consisting of multi-modal item encoders, a fusion module, and a user encoder. To align the cross-modal item representations, we propose a novel next-item enhanced cross-modal contrastive learning objective, which is equipped with both inter- and intra-modality negative samples and explicitly incorporates the transition patterns of user behaviors into the item encoders. To ensure the robustness of user representations, we propose a novel noised item detection objective and a robustness-aware contrastive learning objective, which work together to denoise user sequences in a self-supervised manner. PMMRec is designed to be loosely coupled, so after being pre-trained on the source data, each component can be transferred alone, or in conjunction with other components, allowing PMMRec to achieve versatility under both multi-modality and single-modality transfer learning settings. Extensive experiments on 4 sources and 10 target datasets demonstrate that PMMRec surpasses the state-of-the-art recommenders in both recommendation performance and transferability. Our code and dataset is available at: https://github.com/ICDE24IPMMRec.}
}


@inproceedings{DBLP:conf/icde/YangX00LZL24,
	author = {Wen Yang and
                  Jiajie Xu and
                  Rui Zhou and
                  Lu Chen and
                  Jianxin Li and
                  Pengpeng Zhao and
                  Chengfei Liu},
	title = {Multi-view Attentive Variational Learning for Group Recommendation},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5022--5034},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00381},
	doi = {10.1109/ICDE60146.2024.00381},
	timestamp = {Tue, 30 Jul 2024 08:18:20 +0200},
	biburl = {https://dblp.org/rec/conf/icde/YangX00LZL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Group recommendation aims to recommend desired items for a group of users. Due to the sparsity of group-item interactions, existing methods mainly model group preferences by aggregating member-level preference. However, they not only ignore possible user interest drift in specific groups, but also adopt deterministic models to represent group preferences using fixed-points, which are weak in characterizing uncertain group preferences. To this end, following the paradigm of variational learning, this paper proposes a multi-view attentive variational preference aggregation network called GroupAV for group rec-ommendation, so as to conduct user/group preference modeling and aggregation in a density-based manner. Specifically, we first adopt Variational AutoEncoder (VAE) to capture member-level preferences by variational vectors as density. To address user interest drift in groups, a variational preference adapter module is designed to learn group-contextualized preferences via rational transformation in variational space. Next, attentive variational aggregation networks are carefully designed for group-level preference aggregation in two different views (i.e., group-interactions and member-consensus views). Besides, we apply contrastive learning and gating fusion to optimize the multi-view learning process for the final group preference modeling of Mixture-of-Gaussian distribution. Finally, we conduct experiments on real-world datasets and demonstrate GroupAV's significant performance improvements compared to state-of-the-art group recommendation methods.}
}


@inproceedings{DBLP:conf/icde/HuLWS0C24,
	author = {Yongyi Hu and
                  Xueyan Li and
                  Xikai Wei and
                  Yangguang Shi and
                  Xiaofeng Gao and
                  Guihai Chen},
	title = {Corruption Robust Dynamic Pricing in Liner Shipping under Capacity
                  Constraint},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5035--5047},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00382},
	doi = {10.1109/ICDE60146.2024.00382},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/HuLWS0C24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The shipping industry has irreplaceable importance in international trade and commerce. How to dynamically price different containers has long been a hot topic due to its direct connection to the final revenue. Two critical observations have been made after a comprehensive survey within a top liner company, China Ocean Shipping Company (COSCO). (1) Each type of container carried on a liner ship has its maximum capacity. (2) The sales volume is occasionally subject to huge fluctuations due to rare uncontrollable factors, such as COVID. Based on the above two points and the liner routine's periodic nature, we model the dynamic pricing problem as an episodic MDP model integrating with both capacity constraints and adversarial corruption, named C3-MDP. To maximize the cumulative revenue in the C3-MDP setting, we propose a programming framework, Bonus-Exploration based Episodic Programming (BEEP). This framework can directly accommodate the linear programming algorithm to form the algorithm BEEP-LP, which provides the episode-wise greedy optimal strategy. Furthermore, a detailed regret analysis is provided, showing that BEEP-LP has a regret that is sublinear in the number of episodes. Combining deep techniques, we also present an approximation algorithm BEEP-DQN in the case of large state-action space to strike a balance between the running time and the performance. Abundant experiments based on real container sales data exhibit the rationality of C3-MDP and the effectiveness of BEEP.}
}


@inproceedings{DBLP:conf/icde/QianCCX024,
	author = {Tangwen Qian and
                  Yile Chen and
                  Gao Cong and
                  Yongjun Xu and
                  Fei Wang},
	title = {AdapTraj: {A} Multi-Source Domain Generalization Framework for Multi-Agent
                  Trajectory Prediction},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5048--5060},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00113},
	doi = {10.1109/ICDE60146.2024.00113},
	timestamp = {Tue, 06 Aug 2024 09:17:50 +0200},
	biburl = {https://dblp.org/rec/conf/icde/QianCCX024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Multi-agent trajectory prediction, as a critical task in modeling complex interactions of objects in dynamic systems, has attracted significant research attention in recent years. Despite the promising advances, existing studies all follow the assumption that data distribution observed during model learning matches that encountered in real-world deployments. However, this assumption often does not hold in practice, as inherent distribution shifts might exist in the mobility patterns for deploy-ment environments, thus leading to poor domain generalization and performance degradation. Consequently, it is appealing to leverage trajectories from multiple source domains to mitigate such discrepancies for multi-agent trajectory prediction task. However, the development of multi-source domain generalization in this task presents two notable issues: (1) negative transfer; (2) inadequate modeling for external factors. To address these issues, we propose a new causal formulation to explicitly model four types of features: domain-invariant and domain-specific features for both the focal agent and neighboring agents. Building upon the new formulation, we propose AdapTraj, a multi-source domain generalization framework specifically tailored for multi-agent trajectory prediction. AdapTraj serves as a plug-and-play module that is adaptable to a variety of models. Extensive experiments on four datasets with different domains demonstrate that AdapTraj consistently outperforms other baselines by a substantial margin.}
}


@inproceedings{DBLP:conf/icde/JiangYSCW24,
	author = {Nan Jiang and
                  Haitao Yuan and
                  Jianing Si and
                  Minxiao Chen and
                  Shangguang Wang},
	title = {Towards Effective Next {POI} Prediction: Spatial and Semantic Augmentation
                  with Remote Sensing Data},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5061--5074},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00104},
	doi = {10.1109/ICDE60146.2024.00104},
	timestamp = {Tue, 30 Jul 2024 08:18:19 +0200},
	biburl = {https://dblp.org/rec/conf/icde/JiangYSCW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The next point-of-interest (POI) prediction is a significant task in location-based services, yet its complexity arises from the consolidation of spatial and semantic intent. This fusion is subject to the influences of historical preferences, prevailing location, and environmental factors, thereby posing significant challenges. In addition, the uneven POI distribution further complicates the next POI prediction procedure. To address these challenges, we enrich input features and propose an effective deep-learning method within a two-step prediction framework. Our method first incorporates remote sensing data, capturing pivotal environmental context to enhance input features regarding both location and semantics. Subsequently, we employ a region quad-tree structure to integrate urban remote sensing, road network, and POI distribution spaces, aiming to devise a more coherent graph representation method for urban spatial. Leveraging this method, we construct the QR-P graph for the user's historical trajectories to encapsulate historical travel knowledge, thereby augmenting input features with comprehensive spatial and semantic insights. We devise distinct embedding modules to encode these features and employ an attention mechanism to fuse diverse encodings. In the two-step prediction procedure, we initially identify potential spatial zones by predicting user-preferred tiles, followed by pinpointing specific POls of a designated type within the projected tiles. Empirical findings from four real-world location-based social network datasets underscore the remarkable superiority of our proposed approach over competitive baseline methods.}
}


@inproceedings{DBLP:conf/icde/XinC24,
	author = {Hao Xin and
                  Lei Chen},
	title = {KartGPS: Knowledge Base Update with Temporal Graph Pattern-based Semantic
                  Rules},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5075--5087},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00105},
	doi = {10.1109/ICDE60146.2024.00105},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/XinC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The rapidly changing nature of information world-wide often leads to incomplete and obsolete knowledge facts stored in knowledge bases (KBs). Therefore, reasoning over the dynamic KB sequences, which targets at knowledge inference from evolving facts, is of great importance to maintain KB completeness as well as freshness. Existing approaches for KB updating mainly either focus on knowledge representation learning methods, which suffer from lack of interpretability, or attempt to mine path-based logical rules, which are limited in capturing structural semantics of KB. In this work, we present KartGPS, a system for KB updating taking advantage of temporal graph pattern-based semantic (tGPS) rules. Specifically, the tGPS rules are learned from KB sequences and thus are capable of capturing both temporal and topological regularities of KBs along the evolving of time. Due to the huge amount and imperfect quality of tGPS rules, directly generating and applying all generated rules in a brute-force manner for knowledge updating over large-scale KB sequences would be highly time-consuming and error-prone. Therefore, we investigate the problem of Knowledge Update Rule Discovery (KURD), which aims at deriving an optimal subset of tGPS rules for performing knowledge updating, considering the rule quality and coverage. We show that the KURD problem is NP-hard and design two effective approximation algorithms with greedy and pruning strategies. We demonstrate the effectiveness and efficiency of proposed approaches by extensive experiments on real-world KB datasets.}
}


@inproceedings{DBLP:conf/icde/MeiMW24,
	author = {Lang Mei and
                  Jiaxin Mao and
                  Ji{-}Rong Wen},
	title = {Optimizing Probabilistic Box Embeddings with Distance Measures},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5088--5100},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00106},
	doi = {10.1109/ICDE60146.2024.00106},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/MeiMW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recently, geometric-inspired embedding methods draw research interests for their superior ability in representing transitive and asymmetric relations. A typical example, box embeddings, in which objects are parameterized as axis-aligned hyper-rectangles (i.e. boxes), can effectively model the partial orders and similarities between objects with the inclusion and overlapping relations of the boxes. However, the hard edges of the boxes present difficulties for gradient-based optimization. In this paper, we first identify two problems that may hinder the optimization of box embeddings, namely the zero-gradient problem and the vanishing gradient problem in high dimensional settings. Then, we propose a simple yet effective framework (Box++) to tackle these problems. For the first problem, Box++ combines the overlapping volumes and distance measures in optimizing box embeddings. The distance measures can naturally measure the “degree of disjointedness” for disjoint boxes and provide reasonable gradients for optimization. For the second problem, we theoretically prove that under certain conditions, the gradient would vanish exponentially, and therefore, make the optimization converges to suboptimal solutions. We further design a gradient normalization strategy for the Box++ models to alleviate this problem by rescaling the vanishing gradient. Extensive experiments on real-world datasets demonstrate the effectiveness of the proposed framework.}
}


@inproceedings{DBLP:conf/icde/LuYWN24,
	author = {Minkuan Lu and
                  Jianhua Yin and
                  Kaijun Wang and
                  Liqiang Nie},
	title = {A Multi-View Clustering Algorithm for Short Text},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5101--5110},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00107},
	doi = {10.1109/ICDE60146.2024.00107},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LuYWN24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The objective of the short text clustering task is to group semantically similar short texts into one class and segregate semantically different short texts. Despite the commendable performance achieved by existing topic model based short text clustering algorithms and deep clustering models, a fundamental limitation persists. Both of them are based on one view of the text, which inevitably constrains their clustering performance. Specifically, the topic model based short text clustering algorithms represent short texts as bag-of-words, while the deep clustering models represent short texts as document embeddings. To address these issues, we propose a Multi-View Clustering (MVC) model that considers both views of the text. We modeled the bag-of-words view using the Dirichlet Multinomial Mixture (DMM) model and the document embedding view using the Gaussian Mixture Model (GMM). A Bernoulli random variable is used to control these two models, enabling our proposed model to utilize the semantic information of short text embeddings while obtaining the bag-of-words information. Extensive experiments on four datasets demonstrate MVC's effectiveness. The code for MVC is available at https://github.com/jhyin12/MVC.}
}


@inproceedings{DBLP:conf/icde/MemarziaZHGW24,
	author = {Puya Memarzia and
                  Huaxin Zhang and
                  Kelvin Ho and
                  Ronen Grosman and
                  Jiang Wang},
	title = {GaussDB-Global: {A} Geographically Distributed Database System},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5111--5118},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00383},
	doi = {10.1109/ICDE60146.2024.00383},
	timestamp = {Sun, 06 Oct 2024 21:04:58 +0200},
	biburl = {https://dblp.org/rec/conf/icde/MemarziaZHGW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Geographically distributed database systems use remote replication to protect against regional failures. These systems are sensitive to severe latency penalties caused by centralized transaction management, remote access to sharded data, and log shipping over long distances. To tackle these issues, we present GaussDB-Global, a sharded geographically distributed database system with asynchronous replication, for OLTP applications. To tackle the transaction management bottleneck, we take a decentralized approach using synchronized clocks. Our system can seamlessly transition between centralized and decentralized transaction management, providing efficient fault tolerance and streamlining deployment. To alleviate the remote read and log shipping issues, we support reads on asynchronous replicas with strong consistency, tunable freshness guarantees, and dynamic load balancing. Our experimental results on a geographically distributed cluster show that our approach provides up to 14× higher read throughput, and 50% more TPC-C throughput compared to our baseline.}
}


@inproceedings{DBLP:conf/icde/ZhangYCLXZWZ24,
	author = {Yingqiang Zhang and
                  Xinjun Yang and
                  Hao Chen and
                  Feifei Li and
                  Jiawei Xu and
                  Jie Zhou and
                  Xudong Wu and
                  Qiang Zhang},
	title = {Towards a Shared-Storage-Based Serverless Database Achieving Seamless
                  Scale-Up and Read Scale-Out},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5119--5131},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00384},
	doi = {10.1109/ICDE60146.2024.00384},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhangYCLXZWZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The serverless database has recently attracted increasing attention both in industry and academia due to its high elasticity and the “pay-as-you-go” model. This paper delivers a thorough review of current shared-storage-based commercial serverless databases, pinpointing two major challenges: (1) they either experience difficulties with instance migration during scaling up or restrict the resource usage within a single physical host to avoid potential migration. (2) they lack the ability to scale out secondary nodes due to the absence of strong consistency support in secondary nodes. Based on our experience in building serverless databases, this paper proposes two fundamental requirements to address these two issues: seamless and instant migration and read scale-out. The former allows for instance migration when there are insufficient resources on the resident host during scaling up without application disruption, whereas the latter necessitates strong consistency on secondary nodes to process read requests. To fulfill these fundamental requirements, we propose PolarDB Serverless, a shared-storage-based serverless database achieving seamless scale-up and read scale-out. It supports read scale-out by inheriting the strong consistency feature from PolarDB, making it possible to process strongly consistent reads on secondary nodes. In the pursuit of achieving seamless migration, PolarDB Serverless introduces a transaction migration policy. It ensures there is no interruption to the application during migrations, allowing transactions to continue on the new instance without any disruptions. It also minimizes the overhead of migration, achieving a fast migration. In our evaluation, especially in the context of database migration scenarios, it's noteworthy that the migration of a database instance takes just half a second without causing any exceptions for applications. PolarDB Serverless is the first shared-storage-based serverless database supporting both seamless scale-up and read scale-out and is already commercially available at Alibaba Cloud.}
}


@inproceedings{DBLP:conf/icde/RavellaPKBRCSAR24,
	author = {Chaitanya Sreenivas Ravella and
                  Prashanth Purnananda and
                  Hanuma Kodavalla and
                  Peter Byrne and
                  Adrian{-}Leonard Radu and
                  Wayne Chen and
                  Srikanth Sampath and
                  Naga Bhavana Atluri and
                  Srinag Rao and
                  Priyanka Kakade},
	title = {Optimized Locking in {SQL} Azure},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5132--5141},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00385},
	doi = {10.1109/ICDE60146.2024.00385},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/RavellaPKBRCSAR24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {SQL Azure's concurrency control relies on multi-versioning to prevent readers and writers from blocking each other and on in-memory row locks to prevent multiple writers modifying the same row. If the number of in-memory locks exceeds a threshold, then to reduce memory used for locking, table-level lock escalation occurs which severely reduces concurrency. This paper presents a technique called transaction-id locking that drastically reduces the number of in-memory locks and eliminates lock escalation. It also describes another technique called lock after qualification where rows are qualified without locking thereby letting concurrent transactions interested in mutually exclusive sets of rows execute without blocking each other. Optimized locking combines these two techniques with the prior scheme of in-memory row locks. This combination to improve common isolation levels (like Read Committed Snapshot Isolation) while retaining support for Serializable isolation level in a developer-friendly manner distinguishes this work from prior art. The paper presents in detail this new scheme which required changes in both the storage engine and the query processing engine. It also presents the results of deploying optimized locking to more than eleven million SQL databases in Azure.}
}


@inproceedings{DBLP:conf/icde/TangCZMZFWZZLHH24,
	author = {Xin Tang and
                  Chengliang Chai and
                  Dawei Zhao and
                  Haohai Ma and
                  Yong Zheng and
                  Zhenyong Fan and
                  Xin Wu and
                  Jiaquan Zhang and
                  Rui Zhang and
                  Duanshun Li and
                  Yi He and
                  Keji Huang and
                  Guangbin Meng and
                  Yidong Wang and
                  Yuefeng Zhou and
                  Tao Tao and
                  Lirong Jian and
                  Jiwu Shu and
                  Yuping Wang and
                  Ye Yuan and
                  Guoren Wang and
                  Guoliang Li},
	title = {Separation Is for Better Reunion: Data Lake Storage at Huawei},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5142--5155},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00386},
	doi = {10.1109/ICDE60146.2024.00386},
	timestamp = {Tue, 30 Jul 2024 08:18:20 +0200},
	biburl = {https://dblp.org/rec/conf/icde/TangCZMZFWZZLHH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Huawei collaborates with some Chinese large busi-ness companies to store and process exabytes of nationwide operational data in data lake storage to provide business insights. Specifically, our customers will ask to store and process massive log message data to support their real-time and decision-making applications. Thus, we need computation and storage components in the analytic platform to process and store these data cost-efficiently. To meet these user requirements, we have designed a storage system in data lake, StreamLake, which introduces a novel design to serve log message streaming and batch data processing in distributed storage, with high scalability, efficiency, reliability and low cost. Specifically, we introduce a stream (storage) object as a storage abstraction for message streaming data to achieve the storage-disaggregated architecture with high scalability and reliability. Moreover, we utilize the erasure coding and tiered storage to save the storage cost, and furthermore, the stream object can be automatically converted to a table object such that cost-effective stream and batch data processing can be achieved. For tabular data, we implement the lakehouse functionality to support ACID via the table object, with a metadata acceleration to improve the efficiency of data access between the compute and storage engines. Also, we design a LakeBrain optimizer at the storage side to optimize the query performance and resource utilization under the storage-disaggregated architecture. Finally, we have also deployed StreamLake in China Mobile, the world's largest mobile network operator to serve over 20PB production data, and the results demonstrate improvements of 30% to 4x in terms of query performance and over 37% in terms of cost saving.}
}


@inproceedings{DBLP:conf/icde/ChowdhuryS24,
	author = {Kanchan Chowdhury and
                  Mohamed Sarwat},
	title = {Deep Learning with Spatiotemporal Data: {A} Deep Dive into GeotorchAI},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5156--5169},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00387},
	doi = {10.1109/ICDE60146.2024.00387},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ChowdhuryS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent years, numerous neural network models have been put forth, with an emphasis on the applications of raster imagery and spatiotemporal non-imagery datasets. Implementing these models using existing deep learning frame-works, such as PyTorch and TensorFlow, requires nontrivial coding efforts from the developers although these deep learning frameworks support the implementation of various state-of-the-art machine learning models, such as neural networks, hidden Markov models, and support vector machines. This is due to the fact that the models emphasized on spatiotemporal applications differ extensively from state-of-the-art models supported by existing deep learning frameworks. Moreover, existing deep learning frameworks lack the support for scalable data preprocessing, a mandatory step for converting spatiotemporal datasets into trainable tensors. Considering the limitations of existing deep learning frameworks, we present GeoTorchAI, a framework for deep learning and scalable data processing on raster imagery and spatiotemporal non-imagery datasets. GeoTorchAI enables machine learning practitioners to implement spatiotemporal deep learning models with minimum coding efforts on top of PyTorch. It provides state-of-the-art neural network models, ready-to-use benchmark datasets, and transformation operations for raster imagery and spatiotemporal non-imagery datasets. Besides deep learning, GeoTorchAI contains a data preprocessing module and a DFtoTorch Converter module that enable the formation of trainable spatiotemporal vector datasets and the mapping of preprocessed DataFrames into PyTorch tensors, respectively.}
}


@inproceedings{DBLP:conf/icde/LouLQWFAR24,
	author = {Yuze Lou and
                  Chuan Lei and
                  Xiao Qin and
                  Zichen Wang and
                  Christos Faloutsos and
                  Rishita Anubhai and
                  Huzefa Rangwala},
	title = {{DATALORE:} Can a Large Language Model Find All Lost Scrolls in a
                  Data Repository?},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5170--5176},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00388},
	doi = {10.1109/ICDE60146.2024.00388},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LouLQWFAR24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {How can we effectively generate missing data transformations among tables in a data repository? Multiple versions of the same tables are generated from the iterative process when data scientists and machine learning engineers fine-tune their ML pipelines, making incremental improvements. This process often involves data transformation and augmentation that produces an augmented table based on its base version and related tables. However, data transformations are often not well-documented or completely missing, resulting in poor traceability, reproducibility and explainability of ML pipelines. In this paper, we propose DATALoRE, a framework that explains data changes between an initial dataset and its augmented version to improves traceability. Given a base table, DATALoRE first discovers its potentially related tables from the data repository using a variety of data discovery techniques. DATALoRE then effectively leverages a large language model (LLM) to generate a variety of data transformations that lead to the augmented table. DATALoRE validates these transformations and selects the minimum number of related tables to ensure traceability and reproducibility of the ML pipelines. A preliminary experiment shows that DATALoRE is able to effectively recovery data transformations on two benchmark datasets.}
}


@inproceedings{DBLP:conf/icde/KersbergenSKGRS24,
	author = {Barrie Kersbergen and
                  Olivier Sprangers and
                  Frank Kootte and
                  Shubha Guha and
                  Maarten de Rijke and
                  Sebastian Schelter},
	title = {Etude - Evaluating the Inference Latency of Session-Based Recommendation
                  Models at Scale},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5177--5183},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00389},
	doi = {10.1109/ICDE60146.2024.00389},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/KersbergenSKGRS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Session-based recommendation (SBR) targets a core scenario in e-Commerce: Given a sequence of interactions of a visitor with a selection of items, we want to recommend the next item(s) of interest to interact with. Unfortunately, SBR models are difficult to deploy in practice, as ( $i$ ) session-based recommendations cannot be precomputed offline, but must be inferred online for ongoing user sessions with low latency, and (ii) there is a huge variety of SBR models available, typically designed by academic researchers, whose inference performance and deployment cost is unclear. As a result, data scientists must typically prototype and evaluate different deployment options in collaboration with devops teams - a tedious and costly process, which does not scale to multiple use cases. To alleviate this, we present Etude, an end-to-end bench-marking framework, which enables data scientists to automati-cally evaluate the inference performance of SBR models under different deployment options. With Etude, data scientists can declaratively specify workload statistics, hardware options, as well as latency and throughput constraints. Based on these, Etude automatically deploys and runs an inference benchmark in Kubernetes with a synthetically generated click workload. Sub-sequently, Etude provides the data scientists with measurements on the achieved throughput and latency, as a basis for deciding on feasible and cost-efficient deployment options. We detail the design of Etude and present an experimental study for ten different SBR models in challenging settings resembling real-world workloads encountered at the large Euro-pean e-Commerce platform bol.com. We determine performant and cost-efficient deployment options in terms of models and cloud instance types for a variety of online shopping use cases (ranging from grocery shopping to large e-Commerce platforms). Moreover, we identify severe performance bottlenecks in the open source TorchServe inference server from the PyTorch ecosystem and in the implementation of four SBR models from the open source RecBole library. We make the source code of our framework and experimental results publicly available.}
}


@inproceedings{DBLP:conf/icde/LiuTZZMZ0HZZMZY24,
	author = {Yilun Liu and
                  Shimin Tao and
                  Xiaofeng Zhao and
                  Ming Zhu and
                  Wenbing Ma and
                  Junhao Zhu and
                  Chang Su and
                  Yutai Hou and
                  Miao Zhang and
                  Min Zhang and
                  Hongxia Ma and
                  Li Zhang and
                  Hao Yang and
                  Yanfei Jiang},
	title = {CoachLM: Automatic Instruction Revisions Improve the Data Quality
                  in {LLM} Instruction Tuning},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5184--5197},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00390},
	doi = {10.1109/ICDE60146.2024.00390},
	timestamp = {Fri, 11 Oct 2024 21:56:05 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LiuTZZMZ0HZZMZY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Instruction tuning is crucial for enabling Language Learning Models (LLMs) in responding to human instructions. The quality of instruction pairs used for tuning greatly affects the performance of LLMs. However, the manual creation of high-quality instruction datasets is costly, leading to the adoption of automatic generation of instruction pairs by LLMs as a popular alternative. To ensure the high quality of LLM-generated instruction datasets, several approaches have been proposed. Nevertheless, existing methods either compromise dataset integrity by filtering a large proportion of samples, or are unsuitable for industrial applications. In this paper, instead of discarding low-quality samples, we propose CoachLM, a novel approach to enhance the quality of instruction datasets through automatic revisions on samples in the dataset. CoachLM is trained from the samples revised by human experts and significantly increases the proportion of high-quality samples in the dataset from 17.7% to 78.9%. The effectiveness of CoachLM is further assessed on various real-world instruction test sets. The results show that CoachLM improves the instruction-following capabilities of the instruction-tuned LLM by an average of 29.9%, which even surpasses larger LLMs with nearly twice the number of parameters. Furthermore, CoachLM is successfully deployed in a data management system for LLMs at Huawei, resulting in an efficiency improvement of up to 20% in the cleaning of 40k real-world instruction pairs. We release various assets of CoachLM, including the training data, code and test set 1 1 https://github.com/lunyiliu/CoachLM.}
}


@inproceedings{DBLP:conf/icde/LiSXLWN24,
	author = {Guoliang Li and
                  Ji Sun and
                  Lijie Xu and
                  Shifu Li and
                  Jiang Wang and
                  Wen Nie},
	title = {GaussML: An End-to-End In-Database Machine Learning System},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5198--5210},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00391},
	doi = {10.1109/ICDE60146.2024.00391},
	timestamp = {Wed, 02 Oct 2024 07:47:00 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LiSXLWN24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In-database machine learning (In-DB ML) is appealing to database users with security and privacy concerns, as it avoids copying data out of the database to a separate machine learning system. The common way to implement in-DB ML is the ML-as-UDF approach, which utilizes the User-Defined Functions (UDFs) within SQL to implement the ML training and prediction. However, UDFs may introduce security risks with vulnerable code, and suffer from performance problems, as constrained by data access and execution patterns of SQL query operators. To address these limitations, we propose a new in-database machine learning system, namely GaussML, which provides an end-to-end machine-learning ability with native SQL interface. To support ML training/inference within SQL query, GaussML directly integrates typical ML operators into the query engine without UDFs. GaussML also introduces an ML-aware cardinality and cost estimator to optimize the SQL+ML query plan. Moreover, GaussML leverages Single Instruction Multiple Data (SIMD) and data prefetching techniques to accelerate the ML operators for training. We have implemented a series of algorithms inside GaussML in openGauss database. Compared to the state-of-the-art in-DB ML systems like Apache MADlib, our GaussML achieves 2-6× speed-up in extensive experiments.}
}


@inproceedings{DBLP:conf/icde/LuHQLWYLZCD24,
	author = {Weizheng Lu and
                  Kaisheng He and
                  Xuye Qin and
                  Chengjie Li and
                  Zhong Wang and
                  Tao Yuan and
                  Xia Liao and
                  Feng Zhang and
                  Yueguo Chen and
                  Xiaoyong Du},
	title = {Xorbits: Automating Operator Tiling for Distributed Data Science},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5211--5223},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00392},
	doi = {10.1109/ICDE60146.2024.00392},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LuHQLWYLZCD24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Data science pipelines commonly utilize dataframe and array operations for tasks such as data preprocessing, analysis, and machine learning. The most popular tools for these tasks are pandas and NumPy. However, these tools are limited to executing on a single node, making them unsuitable for processing large-scale data. Several systems have attempted to distribute data science applications to clusters while maintaining interfaces similar to single-node libraries, enabling data scientists to scale their workloads without significant effort. However, existing systems often struggle with processing large datasets due to Out-of-Memory (OOM) problems caused by poor data partitioning. To overcome these challenges, we develop Xorbits, a high-performance, scalable data science framework specifically designed to distribute data science workloads across clusters while retaining familiar APIs. The key differentiator of Xorbits is its ability to dynamically switch between graph construction and graph execution. Xorbits has been successfully deployed in production environments with up to 5k CPU cores. Its applications span various domains, including user behavior analysis and recommendation systems in the e-commerce sector, as well as credit assessment and risk management in the finance industry. Users can easily scale their data science workloads by simply changing the import line of their pandas and NumPy code. Our experiments demonstrate that Xorbits can effectively process very large datasets without encountering OOM or data-skewing problems. Over the fastest state-of-the-art solutions, Xorbits achieves an impressive 2.66 × speedup on average. In terms of API coverage, Xorbits attains a compatibility rate of 96.7%, surpassing the fastest framework by an impressive margin of 60 percentage points. Xorbits is available at https://github.com/xorbitsai/xorbits.}
}


@inproceedings{DBLP:conf/icde/WangTGSWSZQT24,
	author = {Xiaoda Wang and
                  Yuan Tang and
                  Tengda Guo and
                  Bo Sang and
                  Jiewei Wu and
                  Jian Sha and
                  Ke Zhang and
                  Jiang Qian and
                  Mingjie Tang},
	title = {Couler: Unified Machine Learning Workflow Optimization in Cloud},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5224--5237},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00393},
	doi = {10.1109/ICDE60146.2024.00393},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/WangTGSWSZQT24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Machine Learning (ML) has become ubiquitous, fueling data-driven applications across various organizations. Contrary to the traditional perception of ML in research, ML workflows can be complex, resource-intensive, and time-consuming. Expanding an ML workflow to encompass a wider range of data infrastructure and data types may lead to larger workloads and increased deployment costs. Currently, numerous workflow engines are available (with over ten being widely recognized). This variety poses a challenge for end-users in terms of mastering different engine APIs. While efforts have primarily focused on optimizing ML Operations (MLOps) for a specific workflow engine, current methods largely overlook workflow optimization across different engines. In this work, we design and implement Couler, a system designed for unified ML workflow optimization in the cloud. Our main insight lies in the ability to generate an ML workflow using natural language (NL) descriptions. We integrate Large Language Models (LLMs) into workflow generation, and provide a unified programming interface for various workflow engines. This approach alleviates the need to understand various workflow engines' APIs. Moreover, Couler enhances workflow computation efficiency by introducing automated caching at multiple stages, enabling large workflow auto-parallelization and automatic hyperparameters tuning. These enhancements minimize redundant computational costs and improve fault tolerance during deep learning workflow training. Couler is extensively deployed in real-world production scenarios at Ant Group, handling approximately 22k workflows daily, and has successfully improved the CPU/Memory utilization by more than 15% and the workflow completion rate by around 17%.}
}


@inproceedings{DBLP:conf/icde/XiaoJZLHZJWZLZ24,
	author = {Youshao Xiao and
                  Lin Ju and
                  Zhenglei Zhou and
                  Siyuan Li and
                  Zhaoxin Huan and
                  Dalong Zhang and
                  Rujie Jiang and
                  Lin Wang and
                  Xiaolu Zhang and
                  Lei Liang and
                  Jun Zhou},
	title = {AntDT: {A} Self-Adaptive Distributed Training Framework for Leader
                  and Straggler Nodes},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5238--5251},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00394},
	doi = {10.1109/ICDE60146.2024.00394},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/XiaoJZLHZJWZLZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Many distributed training techniques like Parameter Server and AllReduce have been proposed to take advantage of the increasingly large data and rich features. However, stragglers frequently occur in distributed training due to resource contention and hardware heterogeneity, which significantly hampers the training efficiency. Previous works only address part of the stragglers and could not adaptively solve various stragglers in practice. Additionally, it is challenging to use a systematic framework to address all stragglers because different stragglers require diverse data allocation and fault-tolerance mechanisms. Therefore, this paper proposes a unified distributed training framework called AntDT (Ant Distributed Training Framework) to adaptively solve the straggler problems. Firstly, the framework consists of four components, including the Stateful Dynamic Data Sharding service, Monitor, Controller, and Agent. These components work collaboratively to efficiently distribute workloads and provide a range of pre-defined straggler mitigation methods with fault tolerance, thereby hiding messy details of data allocation and fault handling. Secondly, the framework provides a high degree of flexibility, allowing for the customization of straggler mitigation solutions based on the specific circumstances of the cluster. Leveraging this flexibility, we introduce two straggler mitigation solutions, namely AntDT-ND for non-dedicated clusters and AntDT-DD for dedicated clusters, as practical examples to resolve various types of stragglers at Ant Group. Justified by our comprehensive experiments and industrial deployment statistics, AntDT outperforms other SOTA methods more than 3 × in terms of training efficiency. Additionally, in Alipay's homepage recommendation scenario, using AntDT reduces the training duration of the ranking model from 27.8 hours to just 5.4 hours.}
}


@inproceedings{DBLP:conf/icde/GraurRJFDK0A24,
	author = {Dan Graur and
                  Remo R{\"{o}}thlisberger and
                  Adrian Jenny and
                  Ghislain Fourny and
                  Filip Drozdowski and
                  Choden Konigsmark and
                  Ingo M{\"{u}}ller and
                  Gustavo Alonso},
	title = {Addressing the Nested Data Processing Gap: JSONiq Queries on Snowflake
                  Through Snowpark},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5252--5265},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00395},
	doi = {10.1109/ICDE60146.2024.00395},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/GraurRJFDK0A24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Nested data is common in many use cases but querying it is still not well supported. Options available today include using: (1) SQL extensions, which are often unintuitive and error-prone; (2) user-defined functions, which limit portability and reusability, and often reduce performance; or (3) domain-specific query languages (DSQL), which often have limited scalability and performance. In this paper, we address the shortcomings of the latter approach by translating a language specifically designed for nested data, JSONiq, to a highly efficient, scalable, and feature rich RDBMS, the Snowflake Database. For this purpose, we use the Snowpark API, a data-frame-based client library for writing applications on Snowflake, which allows us to translate each JSONiq query into a single native Snowflake SQL query. In contrast to previous approaches, this does not introduce any interpretation overhead or optimization barriers that may limit efficient execution in the target system. We evaluate the resulting system on an established benchmark for large-scale nested data from the high-energy physics (HEP) domain on up to 1 TiB as well as the SSB benchmark from the relational domain. Our approach is on par or better than handwritten SQL baselines while allowing for significantly more readable query formulations and typically outperforms the state-of-the-art systems specialized for nested data by an order of magnitude.}
}


@inproceedings{DBLP:conf/icde/WangYLLLZCZZW24,
	author = {Rui Wang and
                  Xinjun Yang and
                  Feifei Li and
                  David B. Lomet and
                  Xin Liu and
                  Panfeng Zhou and
                  Yongxiang Chen and
                  David Zhang and
                  Jingren Zhou and
                  Jiesheng Wu},
	title = {Bw\({}^{\mbox{e}}\)-tree: An Evolution of Bw-tree on Fast Storage},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5266--5279},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00396},
	doi = {10.1109/ICDE60146.2024.00396},
	timestamp = {Tue, 06 Aug 2024 08:17:21 +0200},
	biburl = {https://dblp.org/rec/conf/icde/WangYLLLZCZZW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Modern data-centric applications frequently need to store and read data with low latency. These requirements are difficult to achieve, even on high performance processors paired with fast solid state drives (SSDs). To this end, LSM tree is widely used in many systems such as in RocksDB and considered as an ideal index structure that fits SSDs. However, in spite of many improvements to LSM tree over the years, fundamental problems of limited read performance and expensive compaction operations remain. Microsoft Research proposed Bw-tree, a variant of B+ tree layered on top of log structured storage. Bw-tree achieves fast ingestion of data, similar to LSM tree, meanwhile it has less drawback on read performance and compaction. However, except for Microsoft, the industrial strength implementation of Bw-tree is rare. The open source OpenBw-Tree from Carnegie Mellon University was designed only for main memory. This paper describes Bw e -tree, an implementation and a significant evolution of Bw-tree on fast storage. It makes two contributions. First, Bw e -tree addresses reliability and performance issues revealed during running Bw-tree on fast storage in production, by revising structural modification operations, introducing page concurrency control, and storing large-size values off-tree. Performance improvements over Bw-tree are verified by experiments. Second, it demonstrates that Bw-tree is an effective alternative tree structure on SSDs. Compared to RocksDB (LSM tree) and BerkeleyDB (B+ tree), Bw e -vtree performs dramatically better (up to 3X or more) for the YCSB workloads. Our Bw e -vtree implementation has been integrated into production systems in Alibaba, including a flagshin cloud-native database service.}
}


@inproceedings{DBLP:conf/icde/ChenJCLZHYJCXCS24,
	author = {Zuzhi Chen and
                  Fuxin Jiang and
                  Binbin Chen and
                  Yu Li and
                  Yunkai Zhang and
                  Chao Huang and
                  Rui Yang and
                  Fan Jiang and
                  Jianjun Chen and
                  Wu Xiang and
                  Guozhu Cheng and
                  Rui Shi and
                  Ning Ma and
                  Wei Zhang and
                  Tieying Zhang},
	title = {Resource Allocation with Service Affinity in Large-Scale Cloud Environments},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5280--5293},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00397},
	doi = {10.1109/ICDE60146.2024.00397},
	timestamp = {Sun, 06 Oct 2024 21:04:56 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ChenJCLZHYJCXCS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Containerization has garnered substantial favor among cloud service providers. Nevertheless, the notable network overhead incurred between containers has prompted concerns within the community. In cloud resource scheduling, collocating service containers that frequently communicate to the same machine - termed “service affinity” - is instrumental in enhancing application performance. In response to this concern, we present a solution that harnesses service affinity and collocates containers to enhance the overall system performance and stability. To maximize the benefits of collocating containers, it is necessary to calculate a new schedule that optimally and efficiently maximizes service affinity, especially within the expansive domain of industry-scale cloud environments. In pursuit of this, we leverage the skewness property of affinity and machine learning to fuse solver-based algorithms, thereby assuring both quality and efficiency for problems at scale. Our methodology encompasses the partitioning of a given task into discrete subproblems, with a keen focus on resolving the most critical ones. Via a graph neural network classifier, we assign each subproblem to be solved independently using methods based on off-the-shelf solvers in our algorithm pool - namely, MIP-based, or column generation. This strategic approach enables the efficient computation of a schedule for a cloud cluster that fully optimizes the overall service affinity. We further propose a heuristic algorithm to compute executable container migration plans for practical use, facilitating the transition to the new placement where service affinity is well optimized. Our solution has been deployed in our large-scale production environment, covering over a million cores within ByteDance. Through the successful real-world production deployment, our approach exhibits an average improvement in end-to-end latency by 23.75% and a reduction in request error rates by 24.09% compared to the original system.}
}


@inproceedings{DBLP:conf/icde/PengCYLCSSX24,
	author = {Gan Peng and
                  Peng Cai and
                  Kaikai Ye and
                  Kai Li and
                  Jinlong Cai and
                  Yufeng Shen and
                  Han Su and
                  Weiyuan Xu},
	title = {Online Index Recommendation for Slow Queries},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5294--5306},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00398},
	doi = {10.1109/ICDE60146.2024.00398},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/PengCYLCSSX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Database autonomy service (DAS) is a platform that provides assistance to database maintainers or administrators in managing a large number of database instances in major internet companies. An important task of DAS is to find missing indexes to improve the performance of slow queries reported from its managed online database instances. Traditional database systems provide the “what-if” function or the hypothetical index technique. Index metadata is modified to simulate the benefits of indexes for queries without creating physical index files. Decades of research have led to plenty of ideas for index recommendation through the use of the “what-if” function and different search strategies. However, the popular open-source database system MySQL, used by most internet companies, has not provided the “what-if” function. In Meituan, tens of thousands of MySQL instances have been deployed across many business lines. Consequently, the DAS platform has accumulated lots of index creation samples. In this paper, we introduce index learner (IdxL), designed to learn index creation knowledge from these informative index data. IdxL resolves the problem of index recommendation by formulating it into an end-to-end supervised learning problem. Given a slow query, IdxL uses learned index creation knowledge to directly predict the missing indexes. Experimental results demonstrate: (1) IdxL is superior to the state-of-the-art index recommendation methods, especially when the error in cost estimation was propagated to the search in candidate index space, and (2) in particular, IdxL achieves up to 97% performance gain over a state-of-the-art method relying on the optimizer's cost estimation in the Meituan-specific index recommendation scenario. Finally, we present the applied results of IdxL in the Meituan DAS platform, demonstrating its ability to transfer index creation knowledge from certain databases to others.}
}


@inproceedings{DBLP:conf/icde/JiangHSWW24,
	author = {Tian Jiang and
                  Xiangdong Huang and
                  Shaoxu Song and
                  Chen Wang and
                  Jianmin Wang},
	title = {On Tuning Raft for IoT Workload in Apache IoTDB},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5307--5319},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00399},
	doi = {10.1109/ICDE60146.2024.00399},
	timestamp = {Mon, 09 Sep 2024 19:07:30 +0200},
	biburl = {https://dblp.org/rec/conf/icde/JiangHSWW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Raft has been widely adopted as the consensus protocol in various distributed systems, owing to its straight-forward interpretation and implementation. However, directly applying Raft may not fully meet the extremely high throughput requirement in the Internet of Things (IoT) scenarios. The case study on real IoT applications reveals unique features, such as high concurrency, fluctuating traffic, fixed-size requests, and compressible data. It explains the bottlenecks of the Raft leader in dispatching, persistence, and memory management, for IoT applications. To this end, we propose to explore the opportunities of tuning Raft for the particular IoT workload, including alternative data structures, various compression algorithms, memory recycling strategies, etc. This paper presents a systematic evaluation of Raft by tuning the aspects above, in an open-source time series database Apache IoTDB. The extensive experiments demonstrate improved system parallelism, reduced information redundancy, and increased resource utilization. The throughput improvement ranges from 10% by replacing the dispatching data structure to nearly 200% by pre-serialization. The overall throughput can reach 4x compared with the original Raft implementation.}
}


@inproceedings{DBLP:conf/icde/YetukuriWKHWL24,
	author = {Jayanth Yetukuri and
                  Yuyan Wang and
                  Ishita Khan and
                  Liyang Hao and
                  Zhe Wu and
                  Yang Liu},
	title = {Multifaceted Reformulations for Null {\&} Low queries and its
                  parallelism with Counterfactuals},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5327--5333},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00401},
	doi = {10.1109/ICDE60146.2024.00401},
	timestamp = {Fri, 13 Sep 2024 20:37:03 +0200},
	biburl = {https://dblp.org/rec/conf/icde/YetukuriWKHWL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Search engines are crucial in retrieving relevant items based on user-specified queries. A significant challenge arises when the buyer's vocabulary does not align with that of the seller, leading to a lack of sufficient recall or unsat-isfactory results. Such queries are referred to as “Null and Low” (N&L) queries which greatly hinder the overall user experience. Moreover, through analysis of user search behavioral data from a major e-commerce company, we have identified that approximately 29% of search queries exhibit multiple category interpretations, which we call “multi-faceted query interpretations”. In this study, we provide conceptual parallelism between the problem of N&L query reformulation and counterfactual explanation literature. To enhance the user experience for N&L queries, we propose a novel method that leverages the capabilities of a neural translation model to provide diverse and multiple reformulations. The proposed model demonstrated exceptional performance in our experiments, achieving an impressive 10% F-score improvement on the held-out test dataset with 5% improvement in relevance and a 100% increase in recall set size compared to a heuristic baseline, specifically for a set of N&L queries sampled from user traffic in eBay. By addressing the challenges of N&L queries and enabling the generation of diverse reformulations, our approach significantly enhances the overall search experience for users.}
}


@inproceedings{DBLP:conf/icde/LuLKWS24,
	author = {Chang Lu and
                  Liuqing Li and
                  Donghyun Kim and
                  Xinyue Wang and
                  Rao Shen},
	title = {An Effective, Efficient, and Stable Framework for Query Clustering},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5334--5340},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00402},
	doi = {10.1109/ICDE60146.2024.00402},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LuLKWS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Yahoo! Trending Now lists the most trending ten user queries from Yahoo! Search. To discover top trending queries, query clustering is a critical intermediate phase that aggregates similar queries into clusters, each representing an event or a topic. Established on a heuristic clustering framework, the existing approach can generate suboptimal results but lacks the ability to: 1) fully exploit semantic information in news articles associated with user queries, and 2) account for changes in queries and news articles over consecutive timestamps. In this paper, we first introduce a two-stage query clustering framework that leverages both match-based grouping and distance-based clustering. This novel and effective solution significantly surpasses the existing production method. Furthermore, to address the challenges posed by high time complexity and potential cluster fluctuations on account of temporal factors, we optimize the newly proposed framework by 1) utilizing a caching mechanism to store historical query features to enhance computational efficiency, and 2) applying voting and rolling average strategies at the time window level to both stages, respectively, resulting in smoother feature representations and more robust clustering out-comes. Through offline evaluation, our integrated method speeds up the baseline by 20 times and reduces cluster fluctuations by 15 times. These improvements considerably enhance the efficiency and stableness of query clustering for Yahoo! Trending Now.}
}


@inproceedings{DBLP:conf/icde/ConstantinouCKM24,
	author = {Soteris Constantinou and
                  Constantinos Costa and
                  Andreas Konstantinidis and
                  Mohamed F. Mokbel and
                  Demetrios Zeinalipour{-}Yazti},
	title = {A Framework for Continuous kNN Ranking of {EV} Chargers with Estimated
                  Components},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5341--5353},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00403},
	doi = {10.1109/ICDE60146.2024.00403},
	timestamp = {Tue, 30 Jul 2024 08:53:46 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ConstantinouCKM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we present an innovative framework whose objective is to allow drivers to recharge their Electric Vehicles (EVs) from the most environmentally friendly chargers using an intelligent hoarding approach. These chargers maximize renewable (e.g., solar) self-consumption, minimizing this way CO2 production and also the need for expensive stationary batteries on the electricity grid to store renewable energy that cannot be used otherwise. We model our problem as a Continuous k-Nearest Neighbor query, where the distance function is computed using Estimated Components (ECs), i.e., a query we term CkNN-EC. An EC defines a function that can have a fuzzy value based on some estimates. Specific ECs used in this work are: (i) the (available clean) power at the charger, which depends on the estimated weather; (ii) the charger availability, which depends on the estimated busy timetables that show when the charger is crowded; and (iii) the derouting cost, which is the time to reach the charger depending on estimated traffic. We devise the EcoCharge framework that combines these multiple non-conflicting objectives into an optimization task providing user-defined ranking means through an intuitive mobile GIS application. Particularly, our core algorithm uses lower and upper values derived from the ECs to recommend the top ranked EV chargers and present them through an intuitive map user interface to users. Our experimental evaluation with extensive synthetic and real traces from Germany, China, and USA along with EV charger data from Plugshare shows that EcoCharge meets the objective functions in an efficient manner, allowing continuous recomputation on the edge devices (e.g., Android Automotive OS, Android Auto or Apple Carplay).}
}


@inproceedings{DBLP:conf/icde/Trummer24,
	author = {Immanuel Trummer},
	title = {Large Language Models: Principles and Practice},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5354--5357},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00404},
	doi = {10.1109/ICDE60146.2024.00404},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Trummer24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The last few years have been marked by several breakthroughs in the domain of generative AI. Large language models such as GPT-4 are able to solve a plethora of tasks, ranging from text and code generation to multimodal data analysis, without task-specific training data. This tutorial, targeted at database researchers without prior background in language models, introduces language models as well as relevant use cases in the context of data management. The tutorial covers the fundamental principles enabling language models, including the Transformer architecture, pre-training, and alignment. Furthermore, the tutorial will show how to use language models in practice, leveraging OpenAI's GPT model to build a natural language query interface as a demonstration. Finally, the tutorial will discuss recent research exploiting language models in the context of data management.}
}


@inproceedings{DBLP:conf/icde/Fahrenkrog-Petersen24,
	author = {Stephan A. Fahrenkrog{-}Petersen and
                  Han van der Aa and
                  Matthias Weidlich},
	title = {Privacy-Aware Analysis based on Data Series},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5365--5370},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00406},
	doi = {10.1109/ICDE60146.2024.00406},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Fahrenkrog-Petersen24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Data that is recorded about the operations of an organization constitutes a valuable source of information for monitoring and improvement. Specific use cases include the assessment of compliance to legal regulations, the analysis of performance bottlenecks, or the optimization of resource utilization. In recent years, a plethora of algorithms for operational analysis using data series, summarized as process mining, have been developed to support these use cases, e.g., by constructing models for simulation and prediction or by comparing the recorded data against a normative specification of a process. Data series often contain sensitive information, though, about the individuals that act as service consumers or service providers. Personal information is only partially hidden by obfuscation and pseudonymization and potential privacy breaches need to be prevented for ethical, legal, and economic reasons. This tutorial is devoted to methods for privacy-aware analysis using data series. It covers essential notions, reviews privacy-disclosure attacks, and outlines techniques to give formal privacy guarantees while largely maintaining the data's utility for operational analysis. The discussion is structured by the adopted perspective on the privacy of individuals, and the degree to which a data series contains contextual information.}
}


@inproceedings{DBLP:conf/icde/KamaliKZ24,
	author = {Amin Kamali and
                  Verena Kantere and
                  Calisto Zuzarte},
	title = {Robust Query Optimization in the Era of Machine Learning: State-of-the-Art
                  and Future Directions},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5371--5375},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00408},
	doi = {10.1109/ICDE60146.2024.00408},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/KamaliKZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Query optimizers are an essential component of database management systems (DBMSs) as they search for an execution plan that is expected to be optimal for a given query. However, they commonly use parameter estimates that are often inaccurate and make assumptions that may not hold in practice. Consequently, the optimizer may select sub-optimal execution plans at runtime, when these estimates and assumptions are not valid, which may result in poor query performance. Therefore, query optimizers do not adequately support the robustness of the database system. In this tutorial, we explore the notion of robustness in the context of query optimization, as well as how it is evaluated or even further supported. Firstly, we provide a comprehensive definition for the notion of robustness in this context that accounts for risks associated with execution plans and inaccurate parameter estimates as well as the limitations of the cost models. Next, we review the approaches proposed in the literature to address the issue of robustness, including techniques that rely on query re-optimization, discovering parameters, quantifying robustness, as well as recent techniques that employ machine learning. We focus on comparing traditional cost-model-based methods with modern ML-based techniques in terms of their ability to tackle the challenge of robustness in query optimization. Finally, we discuss the limitations and gaps in the current literature and provide some recommendations for future research directions.}
}


@inproceedings{DBLP:conf/icde/0003HF24,
	author = {Rihan Hai and
                  Shih{-}Han Hung and
                  Sebastian Feld},
	title = {Quantum Data Management: From Theory to Opportunities},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5376--5381},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00410},
	doi = {10.1109/ICDE60146.2024.00410},
	timestamp = {Mon, 19 Aug 2024 20:24:08 +0200},
	biburl = {https://dblp.org/rec/conf/icde/0003HF24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Quantum computing has emerged as a transformative tool for future data management. Classical problems in database domains, including query optimization, data integration, and transaction management, have recently been addressed using quantum computing techniques. This tutorial aims to establish the theoretical foundation essential for enhancing methodologies and practical implementations in this line of research. Moreover, this tutorial takes a forward-looking approach by delving into recent strides in quantum internet technologies and the nonlocality theory. We aim to shed light on the uncharted territory of future data systems tailored for the quantum internet.}
}


@inproceedings{DBLP:conf/icde/BoniolPP24,
	author = {Paul Boniol and
                  John Paparrizos and
                  Themis Palpanas},
	title = {An Interactive Dive into Time-Series Anomaly Detection},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5382--5386},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00409},
	doi = {10.1109/ICDE60146.2024.00409},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/BoniolPP24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Anomaly detection is an important problem in data analytics with applications in many domains. In recent years, there has been an increasing interest in anomaly detection tasks applied to time series. In this tutorial, we take a holistic view of anomaly detection in time series, starting from the core definitions and taxonomies related to time series and anomaly types, to an extensive description of the anomaly detection methods proposed by different communities in the literature. We explore the literature and the proposed methods by demonstrating systems that help users understand the core computational steps of some methods and navigate benchmark results. Finally, we describe the problem of model selection for anomaly detection and discuss recent experimental results.}
}


@inproceedings{DBLP:conf/icde/Gatterbauer24,
	author = {Wolfgang Gatterbauer},
	title = {A Comprehensive Tutorial on Over 100 Years of Diagrammatic Representations
                  of Logical Statements and Relational Queries},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5387--5392},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00407},
	doi = {10.1109/ICDE60146.2024.00407},
	timestamp = {Fri, 02 Aug 2024 21:41:46 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Gatterbauer24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Query formulation is increasingly performed by systems that need to guess a user's intent (e.g. via spoken word interfaces). But how can a user know that the computational agent is returning answers to the “right” query? More generally, given that relational queries can become pretty complicated, how can we help users understand relational queries, whether human-generated or automatically generated? Now seems the right moment to revisit a topic that predates the birth of the relational model: developing visual metaphors that help users understand relational queries. This lecture-style tutorial surveys the key visual metaphors developed for diagrammatic representations of logical statements and relational expressions, across both the relational database and the much older diagrammatic reasoning communities. We survey the history and state-of-the-art of relationally-complete diagrammatic representations of relational queries, discuss the key visual metaphors developed in over a century of investigations into dia-grammatic languages, and organize the landscape by mapping the visual alphabets of diagrammatic representation systems to the syntax and semantics of Relational Algebra (RA) and Relational Calculus (RC). Tutorial website: https://northeastern-datalab.github.io/diagrammatic-representation-tutorial/}
}


@inproceedings{DBLP:conf/icde/KoehlerL24,
	author = {Henning Koehler and
                  Sebastian Link},
	title = {Entity/Relationship Profiling},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5393--5396},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00411},
	doi = {10.1109/ICDE60146.2024.00411},
	timestamp = {Fri, 02 Aug 2024 21:41:46 +0200},
	biburl = {https://dblp.org/rec/conf/icde/KoehlerL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We introduce Entity/Relationship (E/R) Profiling as the discovery-oriented, data-driven counterpart of E/R Modeling. The aim is not only to mine uniqueness and referential constraints from a given data repository, but also to identify meaningful key/foreign key relationships for the data model targeted. Our demonstration showcases the DataViadotto Profiler as a first solution to E/R Profiling.}
}


@inproceedings{DBLP:conf/icde/Kusano24,
	author = {Genki Kusano},
	title = {GA-Tag: Data Enrichment with an Automatic Tagging System Utilizing
                  Large Language Models},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5397--5400},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00412},
	doi = {10.1109/ICDE60146.2024.00412},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Kusano24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Data quality is widely recognized as being directly linked to the quality of analysis results. In this study, we introduce a tagging method that simplifies the handling of extensive data and facilitates the rapid search and extraction of relevant information. Traditional methods that search for and integrate related data from external sources to enrich input data often fail to guarantee the acquisition of desirable information for all data sets. However, the recent advancement of Large Language Models (LLMs) enables the prediction of characteristics of input data, even in the absence of relevant data. In this paper, we present the Generated and Aggregated Tag (GA-Tag), a system that employs LLMs to automatically assign appropriate tags to data and is equipped with an aggregation mechanism to manage tag diversity effectively. The adoption of GA-Tag is anticipated to enhance data analysis and management quality and efficiency, optimize monetary and time costs, and potentially bolster business intelligence and decision-making processes.}
}


@inproceedings{DBLP:conf/icde/CavalcantiCBLM24,
	author = {Luca Cavalcanti and
                  Cristian Consonni and
                  Martin Brugnara and
                  David Laniado and
                  Alberto Montresor},
	title = {Comparing Personalized Relevance Algorithms for Directed Graphs},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5401--5404},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00413},
	doi = {10.1109/ICDE60146.2024.00413},
	timestamp = {Fri, 02 Aug 2024 21:41:46 +0200},
	biburl = {https://dblp.org/rec/conf/icde/CavalcantiCBLM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We present an interactive Web platform that, given a directed graph, allows identifying the most relevant nodes related to a given query node. Besides well-established algorithms such as PageRank and Personalized PageRank, the demo includes Cyclerank, a novel algorithm that addresses some of their limitations by leveraging cyclic paths to compute personalized relevance scores. Our demo design enables two use cases: (a) algorithm comparison, comparing the results obtained with different algorithms, and (b) dataset comparison, for exploring and gaining insights into a dataset and comparing it with others. We provide 50 pre-loaded datasets from Wikipedia, Twitter, and Amazon and seven algorithms. Users can upload new datasets, and new algorithms can be easily added. By showcasing efficient algorithms to compute relevance scores in directed graphs, our tool helps to uncover hidden relationships within the data, which makes of it a valuable addition to the repertoire of graph analysis algorithms.}
}


@inproceedings{DBLP:conf/icde/Khalil0YHAL024,
	author = {Jalal Khalil and
                  Da Yan and
                  Lyuheng Yuan and
                  Jiao Han and
                  Saugat Adhikari and
                  Cheng Long and
                  Yang Zhou},
	title = {FSM-Explorer: An Interactive Tool for Frequent Subgraph Pattern Mining
                  From a Big Graph},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5405--5408},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00414},
	doi = {10.1109/ICDE60146.2024.00414},
	timestamp = {Tue, 22 Oct 2024 20:38:20 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Khalil0YHAL024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this demonstration paper, we describe FSM-Explorer, an interactive tool that makes it easier for end-users to mine frequent subgraph patterns from a big graph\nG\n, and to explore the subgraph instances in\nG\nthat match the patterns. FSM-Explorer not only supports the popular MNI support measure, but also the recently proposed Fraction-Score measure that is more accurate. Its backend engine is built on top of our recently developed T-FSM system that ensures high concurrency, bounded memory consumption, and effective load balancing. Using real-world data, we showcase how users can mine frequent subgraph patterns by parameter tuning in FSM-Explorer, and how they can conveniently examine the many matched instances in\nG\none batch at a time to improve productivity.}
}


@inproceedings{DBLP:conf/icde/LuoJLGC24,
	author = {Chengyang Luo and
                  Lu Jin and
                  Qing Liu and
                  Yunjun Gao and
                  Lu Chen},
	title = {{TASKS:} {A} Real-Time Query System for Instant Error-Tolerant Spatial
                  Keyword Queries on Road Networks},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5409--5412},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00415},
	doi = {10.1109/ICDE60146.2024.00415},
	timestamp = {Tue, 30 Jul 2024 08:18:21 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LuoJLGC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Nowadays, geo-textual data, which consists of both spatial and textual information, have become increasingly preva-lent. The location-based services are ubiquitous in daily life to help users find desirable geo-textual objects. For example, spatial keyword queries return the geo-textual objects that are the most relevant to query location and query keywords. However, entering complete queries (e.g., the query keywords) can be cumbersome and prone to errors. To overcome these limitations, we present a real-time query system called TASKS for instant error-tolerant spatial keyword queries on road networks. TASKS not only returns the results as soon as users type in some characters instead of a complete keyword, but also tolerates typographical errors of input keywords and supports the queries over road networks. We have implemented four modules for TASKS, i.e., Index Module, Query Module, Update Module, and Route Module. In this demonstration, participants will be invited to use TASKS to explore geo-textual objects and routes in a “search-as-you-type” manner.}
}


@inproceedings{DBLP:conf/icde/PavlenkoSZKCC24,
	author = {Anna Pavlenko and
                  Karla Saur and
                  Yiwen Zhu and
                  Brian Kroth and
                  Joyce Cahoon and
                  Jes{\'{u}}s Camacho{-}Rodr{\'{\i}}guez},
	title = {{VASIM:} Vertical Autoscaling Simulator Toolkit},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5413--5416},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00416},
	doi = {10.1109/ICDE60146.2024.00416},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/PavlenkoSZKCC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent years, autoscaling has garnered significant attention in cloud computing, emphasizing cost efficiency, performance optimization, and availability for dynamic workloads. New algorithms for horizontal, vertical, and hybrid scaling, targeting instances, VM specifications, and resources like CPU, memory, and IO, have emerged. Various approaches, including forecasting and custom autoscaling functions, are used. However, conducting comprehensive end-to-end testing remains a complex and costly endeavor due to the variety of technology constraints involved. This paper introduces VASIM, an autoscaling simulator toolkit designed for testing recommendation algorithms, with a particular focus on CPU usage in VMs and Kubernetes pods. The toolkit replicates common components found in autoscaler architectures, including the controller, metrics collector, recommender, and resource updater. It enables a comprehensive simulation of the entire autoscaling system's behavior, with the flexibility to customize various parameters. In our demonstration, we showcase VASIM's versatility across multiple use cases, highlighting its effectiveness in evaluating autoscaling strategies, fine-tuning parameters, comparing algorithm performance, and addressing autoscaling-related challenges. This underscores VASIM's critical role in expediting algorithm development and refinement by providing a controlled environment for testing and experimentation.}
}


@inproceedings{DBLP:conf/icde/SongLZWZ24,
	author = {Yuanfeng Song and
                  Jinwei Lu and
                  Xuefang Zhao and
                  Raymond Chi{-}Wing Wong and
                  Haodi Zhang},
	title = {Demonstration of FeVisQA: Free-Form Question Answering over Data Visualization},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5417--5420},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00417},
	doi = {10.1109/ICDE60146.2024.00417},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/SongLZWZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Question Answering (QA) systems playa vital role in knowledge acquisition. CodeQA refers to question answering (QA) over source code for code comprehension purpose. However, existing CodeQA studies mainly focus on questions related to general-purpose programming languages (GPLs) (e.g., Java and Python), and no study has been conducted on QA over declarative visualization languages (DVLs) (e.g., Vega-Lite), a kind of programming languages used for creating data visualization (DV). DVLs enjoys specific grammars that are instinct different from GPLs. This demonstration presents the first neural-based QA system for DVL, FeVisQASystem. FeVisQASystem is based on a new task named Fevisqa, short for Free-form QA over data Visualization, which takes natural language questions and DV specification as inputs to predict the answers to the questions. As a particular case of the CodeQA task, Fe VisQA enables people to better comprehend data and its DV s by conducting logical reasoning when answering these questions. Although research on question-answering and machine reading comprehension is progressing quickly, little attention has previously been paid to FeVisQA. This new system and the task can serve as a helpful pioneering study for DV comprehension. The video can be accessed via https://ldrv.ms/f/s!Ah2vhboIPBFMhk6jTYOtaIRnLC2K?e=OkJqOq}
}


@inproceedings{DBLP:conf/icde/SchreiberA24,
	author = {Ran Schreiber and
                  Yael Amsterdamer},
	title = {CleanEr: Interactive, Query-Guided Error Mitigation for Data Cleaning
                  Systems},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5421--5424},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00418},
	doi = {10.1109/ICDE60146.2024.00418},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/SchreiberA24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A key challenge in data cleaning is estimating which of the tuples in a given database are correct and which are not. However, the output of such systems typically includes both false positives and false negatives, i.e., incorrect tuples labeled as correct and vice versa. When queries are performed over the output of such cleaning systems, cleaning errors may have an intricate impact on the query results. We introduce CleanEr, a generic framework that is used on top of existing data cleaning systems and that assists users in identifying the impact of potential cleaning errors on query results, and in deciding accordingly whether and how to proceed with the cleaning. We introduce novel indicators reflecting the current uncertainty with respect to the tuples in the query result, as well as the effect of each relevant input tuple on this uncertainty. We design and implement efficient algorithms for computing these indicators in CleanEr. Based on these indicators, CleanEr helps the data analysts decide whether to trust the query output and guides them in further cleaning of relevant parts of the data through an interactive process. We propose to demonstrate CleanEr using NELL, a large database extracted from the Web.}
}


@inproceedings{DBLP:conf/icde/HajisafiSBNS24,
	author = {Arash Hajisafi and
                  Maria Despoina Siampou and
                  Jize Bi and
                  Luciano Nocera and
                  Cyrus Shahabi},
	title = {Wearables for Health {(W4H)} Toolkit for Acquisition, Storage, Analysis
                  and Visualization of Data from Various Wearable Devices},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5425--5428},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00419},
	doi = {10.1109/ICDE60146.2024.00419},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/HajisafiSBNS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Wearables for Health Toolkit (W4H Toolkit) is an open-source platform that provides a robust, end-to-end solution for the centralized management and analysis of wearable data. With integrated tools and frameworks, the toolkit facilitates seamless data acquisition, integration, storage, analysis, and visualization of both stored and streaming data from various wearable devices. The W4H Toolkit is designed to provide medical researchers and health practitioners with a unified framework that enables the analysis of health-related data for various clinical applications. We provide an overview of the system and demonstrate how it can be used by health researchers to import and analyze a wide range of wearable data and perform data analysis, highlighting the versatility and functionality of the system across diverse healthcare domains and applications.}
}


@inproceedings{DBLP:conf/icde/ZhuCNNXHWMWZTL24,
	author = {Jun{-}Peng Zhu and
                  Peng Cai and
                  Boyan Niu and
                  Zheming Ni and
                  Kai Xu and
                  Jiajun Huang and
                  Jianwei Wan and
                  Shengbo Ma and
                  Bing Wang and
                  Donghui Zhang and
                  Liu Tang and
                  Qi Liu},
	title = {Chat2Query: {A} Zero-Shot Automatic Exploratory Data Analysis System
                  with Large Language Models},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5429--5432},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00420},
	doi = {10.1109/ICDE60146.2024.00420},
	timestamp = {Sun, 06 Oct 2024 21:05:00 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhuCNNXHWMWZTL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Data analysts often encounter two primary challenges while conducting exploratory data analysis by SQL: (1) the need to skillfully craft SQL queries, and (2) the requirement to generate suitable visualizations that enhance the interpretation of query results. The emergence of large language models (LLMs) has inaugurated a paradigm shift in text-to-SQL and data-to-chart. This paper presents Chat2Query, an LLM -empowered zero-shot automatic exploration data analysis system. Firstly, Chat2Query provides a user-friendly interface that allows users to employ natural languages to interact with the database directly. Secondly, Chat2Query offers an LLM -empowered text-to-SQL generator, SQL rewriter, SQL formatter, and data-to-chart generator. Thirdly, Chat2Query is uniquely distinguished by its underlying incorporation of the TiDB Serverless, fostering superior elasticity and scalability. This strategic integration empowers Chat2Query with the capability to seamlessly adapt to change workloads, aligning with the evolving demands of the user. We have implemented and deployed Chat2Query in the production environment, and demonstrate its usability and efficiency in three representative real-world scenarios.}
}


@inproceedings{DBLP:conf/icde/AngHTH24,
	author = {Yihao Ang and
                  Qiang Huang and
                  Anthony K. H. Tung and
                  Zhiyong Huang},
	title = {{EADS:} An Early Anomaly Detection System for Sensor-Based Multivariate
                  Time Series},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5433--5436},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00421},
	doi = {10.1109/ICDE60146.2024.00421},
	timestamp = {Sun, 06 Oct 2024 21:04:56 +0200},
	biburl = {https://dblp.org/rec/conf/icde/AngHTH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Early Anomaly Detection (AD) in sensor-based Multivariate Time Series (MTS) is crucial for addressing signs of operational failures. However, existing AD methods either struggle to identify anomalies at an early stage or lean heavily on intricate neural networks and extensive data for model training, compromising clarity and interpretability. To bridge this gap, we pioneered CAD, a novel AD framework based on correlation analysis. It harnesses Time-Series Graphs (TSGs) to monitor sensor correlation changes. By meticulously analyzing these changes, CAD excels in ascertaining the precise time of anomalies and identifying the implicated sensors. In this demonstration, we introduce EADS, an Early Anomaly Detection System built upon CAD for sensor-based MTS. We navigate multiple scenarios to illustrate the prowess of EADS in serving as an early AD benchmark platform, offering insightful abnormal time interpretability, and facilitating timely predictive maintenance. The source code is available at https://github.com/YihaoAng/EADS/.}
}


@inproceedings{DBLP:conf/icde/CombettesBTO24,
	author = {Sylvain W. Combettes and
                  Paul Boniol and
                  Charles Truong and
                  Laurent Oudre},
	title = {dsymb Playground: An Interactive Tool to Explore Large Multivariate
                  Time Series Datasets},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5437--5440},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00422},
	doi = {10.1109/ICDE60146.2024.00422},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/CombettesBTO24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Exploring and comparing non-stationary multivariate time series is an important problem in many domains and real-world applications. In recent work, we introduced d symb , a symbolic representation that transforms multivariate time series into interpretable symbolic sequences that comes along with a compatible and efficient distance measure to compare the obtained symbolic sequences. We have shown how d symb can handle the non-stationarity of multivariate physiological signals, how interpretable the symbolization is, and how suitable the distance measure is compared to Dynamic Time Warping (DTW) variants. We have also empirically shown that the computation time when using d symb on a clustering time is significantly smaller than with DTW variants (typically 100 times faster). In this demonstration, we present the d symb playground, an interactive web-based tool to interpret and compare a large multivariate time series dataset quickly. We showcase the relevance of this tool in several scenarios based on real-world datasets.}
}


@inproceedings{DBLP:conf/icde/BoniolSPTP24,
	author = {Paul Boniol and
                  Emmanouil Sylligardos and
                  John Paparrizos and
                  Panos E. Trahanias and
                  Themis Palpanas},
	title = {ADecimo: Model Selection for Time Series Anomaly Detection},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5441--5444},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00423},
	doi = {10.1109/ICDE60146.2024.00423},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/BoniolSPTP24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Anomaly detection is a fundamental task for time-series analytics with important implications for the downstream performance of many applications. Despite increasing academic interest and the large number of methods proposed in the literature, recent benchmark and evaluation studies demonstrated that there exists no single best anomaly detection method when applied to heterogeneous time series datasets. Therefore, the only scalable and viable solution to solve anomaly detection over very different time series collected from diverse domains is to propose a model selection method that will choose, based on time series characteristics, the best anomaly detection method to run. This paper describes ADecimo, a modular and extensible web application that helps users understand the performance of time series classification algorithms used as model selection methods for time series anomaly detection. Overall, our system enables users to compare 17 different classifiers over 1980 time series, and decide on the most suitable time series classification method for their own time series and use cases.}
}


@inproceedings{DBLP:conf/icde/PengL00XRLX24,
	author = {Yun Peng and
                  Sen Lin and
                  Qian Chen and
                  Shaowei Wang and
                  Lyu Xu and
                  Xiaojun Ren and
                  Yafei Li and
                  Jianliang Xu},
	title = {ChatGraph: Chat with Your Graphs},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5445--5448},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00424},
	doi = {10.1109/ICDE60146.2024.00424},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/PengL00XRLX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graph analysis is fundamental in real-world applications. Traditional approaches rely on SPARQL-like languages or clicking-and-dragging interfaces to interact with graph data. However, these methods either require users to possess high programming skills or support only a limited range of graph analysis functionalities. To address the limitations, we propose a large language model (LLM)-based framework called Chat-Graph. With ChatGraph, users can interact with graphs through natural language, making it easier to use and more flexible than traditional approaches. The core of ChatGraph lies in generating chains of graph analysis APIs based on the understanding of the texts and graphs inputted in the user prompts. To achieve this, ChatGraph consists of three main modules: an API retrieval module that searches for relevant APIs, a graph-aware LLM module that enables the LLM to comprehend graphs, and an API chain-oriented finetuning module that guides the LLM in generating API chains. We have implemented ChatGraph and will showcase its usability and efficiency in four scenarios using real-world graphs.}
}


@inproceedings{DBLP:conf/icde/FejzaGL24,
	author = {Amela Fejza and
                  Pierre Genev{\`{e}}s and
                  Nabil Laya{\"{\i}}da},
	title = {A Fast Plan Enumerator for Recursive Queries},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5449--5452},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00425},
	doi = {10.1109/ICDE60146.2024.00425},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/FejzaGL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Plan enumeration is one of the most crucial components in relational query optimization. We demonstrate RLQDAG, a system implementation of a top-down plan enumerator for the purpose of transforming sets of recursive relational terms efficiently. We describe a complete system of query optimization with parsers and compilers adapted for recursive queries over knowledge and property graphs. We focus on the enumeration component of this sytem, the RLQDAG, and especially on its efficiency in generating plans out of reach of other approaches. We show graphical representations of explored plan spaces for queries on real datasets. We demonstrate the plan enumerator and its benefits in finding more efficient query plans.}
}


@inproceedings{DBLP:conf/icde/Skoufis024,
	author = {Petros Skoufis and
                  Dimitrios Skoutas},
	title = {{KGSEC:} {A} Modular Framework for Knowledge Graph Schema Extraction
                  and Comparison},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5453--5456},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00426},
	doi = {10.1109/ICDE60146.2024.00426},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Skoufis024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Finding the underlying schema in knowledge graphs is an imperative operation for various tasks, such as query formulation or exploration. This task becomes even harder, when data are incomplete, noisy or are collected via multiple sources with different schemata that are combined. Several algorithms for extracting an implicit schema from a given knowledge graph have been proposed in the literature. However, the lack of a common framework and evaluation metrics makes it difficult to combine them and compare the results. To fill this gap, we present a modular three-stage framework and we have developed a Python library and web application that performs schema extraction and allows users to visually assess and compare the results. The developed tool, called KGSEC, facilitates experimentation and increases interactivity. Given that the quality of a schema is largely subjective, depending on the user's needs and preferences, KGSEC can make it easier and faster for users to generate a schema that is better tailored to their task.}
}


@inproceedings{DBLP:conf/icde/ChasialisPFSI24,
	author = {Konstantinos Chasialis and
                  Theoni Palaiologou and
                  Yannis Foufoulas and
                  Alkis Simitsis and
                  Yannis E. Ioannidis},
	title = {QFusor: {A} {UDF} Optimizer Plugin for {SQL} Databases},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5457--5460},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00427},
	doi = {10.1109/ICDE60146.2024.00427},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ChasialisPFSI24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Modern data applications in areas such as text mining, document analysis, and data science, involve complex algorithms and logic that cannot be expressed in SQL. Therefore, SQL databases employ user-defined functions (UDFs) to extend their supported functionality. However, this comes at a significant performance cost as UDFs routinely become the bottleneck in query execution. To deal with this problem, we present QFusor, an optimizer plugin for UDF queries in relational databases. QFusor minimizes the performance overheads introduced by the impedance mismatch between the UDF and SQL execution environments by employing techniques such as vectorization, parallelization, tracing JIT compilation, and operator fusion for various types of UDF (scalar, aggregate, table UDFs) and relational operators. QFusor follows a pluggable, engine-agnostic design and can work with several popular SQL databases offering a significant boost in their UDF query performance.}
}


@inproceedings{DBLP:conf/icde/XingJ24,
	author = {Junjie Xing and
                  H. V. Jagadish},
	title = {{ARTS:} {A} System for Aggregate Related Table Search},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5461--5464},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00428},
	doi = {10.1109/ICDE60146.2024.00428},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/XingJ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Existing table search techniques define table relatedness with unionablility and/or joinability. While these are valuable, they do not suffice for most data analysis tasks that involve numerical data, which is often aggregated over geographical, temporal, or other groups. In this demonstration, we showcase ARTS, a novel table search system centered on the unique concept of aggregate relatedness. By leveraging pre-trained language models, ARTS offers a superior column semantics understanding capability, with good labels created for both textual and numerical columns. This demonstration will offer attendees hands-on interaction with our system, revealing its potential in effectively addressing real-world data analysis challenges.}
}


@inproceedings{DBLP:conf/icde/GolzadehGS24,
	author = {Kiarash Golzadeh and
                  Lukasz Golab and
                  Jaroslaw Szlichta},
	title = {Explaining Expert Search Systems with ExES},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5465--5468},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00429},
	doi = {10.1109/ICDE60146.2024.00429},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/GolzadehGS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Expert search systems operate on collaboration networks with nodes representing individuals, labeled with their skills, and edges denoting collaboration relationships. Given a query corresponding to a set of desired skills, these systems identify teams of experts that best match the query. However, state-of-the-art solutions to this problem lack transparency and interpretability. To address this issue, we demonstrate ExES, an interactive tool designed to explain expert search systems. Our system leverages saliency and counterfactual methods from the field of explainable artificial intelligence (XAI). Conference participants will use ExES to understand why individuals were or were not included in the query results and what individuals could do, in terms of perturbing skills or connections, to be included or excluded in the results.}
}


@inproceedings{DBLP:conf/icde/RorsethGGSS24,
	author = {Joel Rorseth and
                  Parke Godfrey and
                  Lukasz Golab and
                  Divesh Srivastava and
                  Jaroslaw Szlichta},
	title = {{RAGE} Against the Machine: Retrieval-Augmented {LLM} Explanations},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5469--5472},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00430},
	doi = {10.1109/ICDE60146.2024.00430},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/RorsethGGSS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper demonstrates RAGE, an interactive tool for explaining Large Language Models (LLMs) augmented with retrieval capabilities; i.e., able to query external sources and pull relevant information into their input context. Our explanations are counterfactual in the sense that they identify parts of the input context that, when removed, change the answer to the question posed to the LLM. RAGE includes pruning methods to navigate the vast space of possible explanations, allowing users to view the provenance of the produced answers.}
}


@inproceedings{DBLP:conf/icde/LassigHN24,
	author = {Nico L{\"{a}}ssig and
                  Melanie Herschel and
                  Ole Nies},
	title = {FairCR - An Evaluation and Recommendation System for Fair Classification
                  Algorithms},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5473--5476},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00431},
	doi = {10.1109/ICDE60146.2024.00431},
	timestamp = {Sun, 06 Oct 2024 21:04:57 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LassigHN24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A persistent problem of machine learning (ML) predictions is potential discrimination towards individuals from specific population groups, e.g., based on gender, religion, etc. Numerous algorithms have been proposed to tackle biased predictions leading to such discrimination, particularly for classification problems. These algorithms typically aim to reduce bias as defined by specific metrics. Given the large variety of algorithms and metrics, selecting a method suited for a particular application is tedious and challenging. FairCR is an extensible system that allows the evaluation of fair classification algorithms in a systematic and unified way. It further recommends which fair classification algorithms to use based on several application preferences. We showcase FairCR's functionality on a large set of readily implemented algorithms and metrics over multiple datasets, demonstrating how it can support the comparative evaluation of algorithms and help select specific fair classification alaorithms for given application preferences.}
}


@inproceedings{DBLP:conf/icde/LeZWW24,
	author = {Duy Le and
                  Kris Zhao and
                  Mengying Wang and
                  Yinghui Wu},
	title = {GraphLingo: Domain Knowledge Exploration by Synchronizing Knowledge
                  Graphs and Large Language Models},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5477--5480},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00432},
	doi = {10.1109/ICDE60146.2024.00432},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LeZWW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Knowledge graphs (KGs) are routinely curated to provide factual data for various domain-specific analyses. Nevertheless, it remains nontrivial to explore domain knowledge with standard query languages. We demonstrate GraphLingo, a natural language (NL)-based knowledge exploration system designed for exploring domain-specific knowledge graphs. It differs from conventional knowledge graph search tools in that it enables an interactive exploratory NL query over domain-specific knowledge graphs. GraphLingo seamlessly integrates graph query processing and large language models with a graph pattern-based prompt generation approach to guide users in exploring relevant factual knowledge. It streamlines NL-based question & answer, graph query optimization & refining, and automatic prompt generation. A unique feature of GraphLingo is its capability to enable users to explore by seamlessly switching between a more ‘open’ approach and a more relevant yet ‘conservative’ one, facilitated by diversified query suggestions. We show cases of GraphLingo in curriculum suggestion, and materials scientific data search.}
}


@inproceedings{DBLP:conf/icde/WangXW24,
	author = {Weicheng Wang and
                  Min Xie and
                  Raymond Chi{-}Wing Wong},
	title = {MixedSearch: An Interactive System of Searching for the Best Tuple
                  with Mixed Attributes},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5481--5484},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00433},
	doi = {10.1109/ICDE60146.2024.00433},
	timestamp = {Mon, 12 Aug 2024 18:35:46 +0200},
	biburl = {https://dblp.org/rec/conf/icde/WangXW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Identifying the best tuples in a large database for users has been a longstanding challenge in database community. Many interactive methods have been proposed to help users search for their best tuples in the database. Specifically, each user undergoes rounds of interaction. In each round, the user is presented with two tuples and is asked to pick the one s/he prefers more. Based on the user feedback, the user preference can be learned implicitly. Eventually, the best tuple w.r.t. the learned user preference is returned. Many systems have been designed for conducting interactive methods. However, they mainly restrict their settings on databases with numerical attributes, neglecting that in reality, databases can also be described by categorical attributes. Although there are some strategies to convert categorical attributes to numerical attributes, the conversion not only incurs poor efficiency, but also requires heavy interactive effort. In light of this, we developed an interactive system, called MixedSearch, and demonstrated that the system could find the best tuples for users in the database described by mixed attributes.}
}


@inproceedings{DBLP:conf/icde/Xiang00M024,
	author = {Siqi Xiang and
                  Zhonghao Yang and
                  Jianjun Zhao and
                  Yancan Mao and
                  Shuhao Zhang},
	title = {MorphStream: Scalable Processing of Transactions over Streams},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5485--5488},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00434},
	doi = {10.1109/ICDE60146.2024.00434},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Xiang00M024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the realm of transactional stream processing (TSP), the challenge lies in providing a unified execution model that seamlessly integrates transactional and stream-oriented capabilities. Existing TSP engines (TSPEs) largely employ non-adaptive scheduling techniques, leaving multicore parallelism underutilized due to intricate workload dependencies. We demonstrate MorphStream, a state-of-the-art TSPE built for unprecedented scalability on multicores. MorphStream distinguishes itself by employing an adaptive scheduling algorithm, explicitly designed to unlock the full potential of multicore architectures even under complex workload conditions. This enables MorphStream to make optimal trade-offs in performance metrics under varying workload characteristics. To enhance user engagement, the demonstration will showcase MorphStream's graphical user interface, specifically engineered to simplify the implementation and deployment of complex streaming applications while providing detailed and comprehensive performance monitoring and analytics for the job execution runtime.}
}


@inproceedings{DBLP:conf/icde/ShiWZW24,
	author = {Gengyuan Shi and
                  Chaokun Wang and
                  Minghao Zhang and
                  Binbin Wang},
	title = {{FONT:} {A} Flexible Polystore Evaluation Platform},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5489--5492},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00435},
	doi = {10.1109/ICDE60146.2024.00435},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ShiWZW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The concept of polystore has been proposed and studied for heterogeneous data storage and cross-model query processing. Correspondingly, the evaluation of diverse polystores is an essential yet challenging task. However, most current evaluation approaches for polystores only focus on cross-model analytical workloads and provide limited configurations. To address these problems, this paper presents a flexible polystore evaluation platform named FONT. FONT incorporates hybrid single-model and cross-model workloads that combine read and write operations, as well as diagnostic analytical workloads. FONT supports customization of both multi-model dataset generation and workload generation procedures. The proposed platform is the first visual tool for polystore evaluation, providing user-friendly graphical interfaces for user customization and displaying evaluation results.}
}


@inproceedings{DBLP:conf/icde/YuGGSS24,
	author = {Andy Yu and
                  Parke Godfrey and
                  Lukasz Golab and
                  Divesh Srivastava and
                  Jaroslaw Szlichta},
	title = {{CAMO:} Explaining Consensus Across MOdels},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5493--5496},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00436},
	doi = {10.1109/ICDE60146.2024.00436},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/YuGGSS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Explainable AI methods have been proposed to help interpret complex models, e.g., by assigning importance scores to model features or perturbing the features in a way that changes the prediction. These methods apply to one model at a time, but in practice, engineers usually select from many candidate models and hyperparameters. To assist with this task, we demonstrate Camo:a tool that explains consensus among multiple models. Conference participants will interact with CAMO using a variety of models and datasets, to explore 1) consensus patterns, such as subsets of the test dataset or intervals within feature domains where models disagree, and 2) data perturbations that would make conflicting models agree (and consistent models disagree).}
}


@inproceedings{DBLP:conf/icde/KangLABPMR024,
	author = {Yunfan Kang and
                  Yongyi Liu and
                  Hussah Alrashid and
                  Akash Bilgi and
                  Siddhant Purohit and
                  Ahmed Mahmood and
                  Sergio J. Rey and
                  Amr Magdy},
	title = {Pyneapple-R: Scalable and Expressive Spatial Regionalization},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5497--5500},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00437},
	doi = {10.1109/ICDE60146.2024.00437},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/KangLABPMR024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper demonstrates Pyneapple-R, an open-source library for scalable and expressive regionalization. Re-gionalization algorithms, also known as the ‘spatially-constrained clustering algorithms', have been widely adopted in spatial analysis tasks and now evolving towards a more large-scale and fine-scale direction. Through collaborations with social scientists and domain experts, we have identified emerging challenges in existing regionalization techniques, particularly regarding scalability and expressiveness. As data volumes continue to grow and regionalization algorithms become increasingly crucial to decision-making across various fields, enhancing these aspects can significantly impact the quality and effectiveness of re-search and applications. To address these challenges, Pyneapple-R provides novel algorithms for regionalization queries including the expressive p-regions algorithm, the scalable max-p regions algorithm, and the expressive max-p regions problem. To show-case Pyneapple-R, we have developed frontend web applications that enable users to interact with the algorithms by selecting constraints or simply engaging in conversation with the system to issue queries with the help of popular AI models. Interactive notebooks, designed to demonstrate the superiority and simplicity of Pyneapple-R, provide varying levels of detail to help social scientists and developers explore its full potential.}
}


@inproceedings{DBLP:conf/icde/0001CGOPSVW24,
	author = {Michael J. Carey and
                  Don Chamberlin and
                  Almann Goo and
                  Kian Win Ong and
                  Yannis Papakonstantinou and
                  Chris Suver and
                  Sitaram Vemulapalli and
                  Till Westmann},
	title = {{SQL++:} We Can Finally Relax!},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5501--5510},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00438},
	doi = {10.1109/ICDE60146.2024.00438},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/0001CGOPSVW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {SQL is five decades old and has outlasted many programming and query languages that have come and gone during its lifetime. It was born shortly after the introduction of the relational model, and was designed for querying a flat and typed tabular world. Support for modern, flexible data in the SQL standard and in relational database systems has largely been approached via the addition of new column types (e.g. XML or JSON) together with functions to operate on them. It is time for a cleaner solution that retains the benefits that have allowed SQL to be so successful for so long. We describe SQL++, a SQL extension that relaxes SQL's strictness in terms of both object structure (flat → nested) and schema (mandatory → optional), along with a multi-party effort to agree on a core definition and syntax supportable by multiple vendors. SQL++ sees relational data as a subset of a more flexible object model and it sees collections of document data (e.g., JSON) as a natural and supportable relaxation as opposed to a “bolt on” addition via a SQL column type. We describe the core features of SQL++ and explain how its definition can accommodate flexible data, while staying true to SQL in situations where the target data is tabular and strongly typed. Index Terms-semistructured data, query, JSON, SQL, NoSQL}
}


@inproceedings{DBLP:conf/icde/LernerA24,
	author = {Alberto Lerner and
                  Gustavo Alonso},
	title = {Data Flow Architectures for Data Processing on Modern Hardware},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5511--5522},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00439},
	doi = {10.1109/ICDE60146.2024.00439},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LernerA24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The requirements arising from ever growing amounts of data and tight performance constraints as well as the limitations encountered in improving conventional CPU performance have led to a proliferation of specialized architectures involving a wide variety of processor types (GPU, TPU, DPU, etc.) with processing becoming distributed across all points of the computing fabric (smart storage, smart memory, smart NICs, programmable switches, etc.). Examples abound both in industry and academia of new architectural configurations and hardware accelerators improving different aspects of a system. These developments raise an important question that is still open but has not attracted sufficient attention: how to design data processing engines systems over such highly heterogeneous and distributed architectures. In this paper we argue that data management engines on modern hardware will necessarily be based on data flow designs where processing happens in a streaming and pipelined fashion across the entire architecture, a radical departure from existing engines. In the paper we argue why this will be the case, the advantages of such designs, and outline a research program to allow data processing engines take advantage of hardware developments.}
}


@inproceedings{DBLP:conf/icde/Halevy0T24,
	author = {Alon Y. Halevy and
                  Yuliang Li and
                  Wang{-}Chiew Tan},
	title = {Personal Manifold: Management of Personal Data in the Age of Large
                  Language Models},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5523--5529},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00440},
	doi = {10.1109/ICDE60146.2024.00440},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Halevy0T24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The recent progress on large language models and their conversational capabilities have rekindled interest in building personal digital assistants that will help us with daily tasks, such as recommending to us which items to purchase, what content to consume, what to eat, and even how to spend our time in the most meaningful way. The recommendations these assistants will provide us will be hyper-personalized, based on detailed knowledge of our past, our preferences, our goals and our current context. Realizing this vision raises novel data management challenges. Today's language models, though they display unprecedented reasoning capabilities, do not have the ability to reliably store data they are presented with and to retrieve it when needed. This paper describes the visionary PERSONAL MANIFOLD system that supports a personal agent based on LLMs, tackles some of the associated data management challenges, and exposes others. PERSONAL MANIFOLD offers an LLM-based interface to the tools they use to manage their personal information. Users interact with PERSONAL MANIFOLD by making notes (or journal entries) and asking for recommendations. In either case, the relevant data from the interaction is also added to the relevant tool (e.g., calendar or to-do list) so it becomes actionable. One of the key aspects of PERSONAL MANIFOLD is the user's timeline, which describes the set of experiences they've had and their plans for the future. The personal timeline is constructed based on digital data that they create in the process of using other applications. The personal timeline can then be mined to extract the user's preferences and their habits, which are then used to power personalized recommendations.}
}


@inproceedings{DBLP:conf/icde/0001JLWC24,
	author = {Meihui Zhang and
                  Zhaoxuan Ji and
                  Zhaojing Luo and
                  Yuncheng Wu and
                  Chengliang Chai},
	title = {Applications and Challenges for Large Language Models: From Data Management
                  Perspective},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5530--5541},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00441},
	doi = {10.1109/ICDE60146.2024.00441},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/0001JLWC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Data management is indispensable for informed decision-making in the big data era. In the meantime, Large Language Models (LLMs), equipped with billions of model parameters and trained on extensive data corpora, have recently achieved record-breaking results in various real-world applications, such as machine translation, content generation, information retrieval, etc. The emergent abilities of LLMs, e.g., in-context learning and advanced reasoning ability, have great potential to revolutionize data management. In this paper, we first present some promising categories of data management applications where LLMs can be adapted, including data generation, data transformation, data integration, and data exploration. We then discuss the corresponding challenges for such adaption. Finally, we envision potential solutions to these challenges.}
}


@inproceedings{DBLP:conf/icde/JensenYGHT24,
	author = {Christian S. Jensen and
                  Bin Yang and
                  Chenjuan Guo and
                  Jilin Hu and
                  Kristian Torp},
	title = {Routing with Massive Trajectory Data},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5542--5547},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00442},
	doi = {10.1109/ICDE60146.2024.00442},
	timestamp = {Tue, 30 Jul 2024 14:17:02 +0200},
	biburl = {https://dblp.org/rec/conf/icde/JensenYGHT24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The unprecedented availability of new types of data coupled with the invention of new technologies combine to enable entirely new or higher-resolution services that in turn enable more rational and data-driven processes. We consider the overall process of vehicular transportation and, more specifically, the process of deciding which route to follow when having to reach a destination. Early solutions modeled a road work as a graph, used sparse in-road sensor data to assign weights to graph edges, and then applied improved versions of Dijkstra's algorithm to find routes with the lowest sums of edge weights. Since then, massive vehicle trajectory data has become available. When coupled with new technologies, this data enables entirely new and higher-resolution routing services that in turn enable better routing. For more than a decade, the authors have engaged in research aimed at exploiting trajectory data to enable better routing. The resulting technologies were developed outside a DBMS. Here, we cover aspects of this research. Further, we challenge the community to develop DBMS support for these and other aspects of routing.}
}


@inproceedings{DBLP:conf/icde/BiWL0024,
	author = {Yuran Bi and
                  Yihang Wu and
                  Jinfei Liu and
                  Kui Ren and
                  Li Xiong},
	title = {When Data Pricing Meets Non-Cooperative Game Theory},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5548--5559},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00443},
	doi = {10.1109/ICDE60146.2024.00443},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/BiWL0024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Driven by the growing field of data intelligence, data market emerges as a promising paradigm for data exchange, enabling the full utilization of data. Data pricing is an essential function in data market that reflects the values or cost of data and is dependent on interactions among multiple market participants including data buyers, data sellers, and data brokers. Game theory presents a promising approach to model the multi-participant interplay in data pricing, yet challenged by the specific nature of data. In this paper, we present a blueprint for applying game theory to data pricing. From a game-theoretic perspective, we highlight the unique characteristics of data (compared to traditional goods) and suggest important desiderata for effective data pricing. We identify four key dimensions (Participant, Object, Action, and Information) to understand the landscape of game theory based data pricing. Within each dimension, data-specific challenges and research gaps are identified. Our work establishes a foundational understanding of data pricing through the lens of game theory and opens up promising research directions in this developing field.}
}


@inproceedings{DBLP:conf/icde/Zhang0KM024,
	author = {Shufan Zhang and
                  Xi He and
                  Ashish Kundu and
                  Sharad Mehrotra and
                  Shantanu Sharma},
	title = {Secure Normal Form: Mediation Among Cross Cryptographic Leakages in
                  Encrypted Databases},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5560--5573},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00444},
	doi = {10.1109/ICDE60146.2024.00444},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Zhang0KM024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Existing secure data outsourcing systems offer users ways to select from different cryptographic primitives supported by the system to encrypt their data to strike a balance between data confidentiality and query performance. Though prior work have identified the danger of mixing cryptographic primitives, they fall short of providing a systematic approach to guide users to prevent such cross-cryptographic leakages. Inspired by the database design theory, we envision Secure Normal Form, a new approach to normalize encrypted databases such that the leakages of the partitioned databases are limited to the users' specifications. In this work, we propose a new architecture to support secure normal form. This system includes several new components for secure data outsourcing: (i) an inference mechanism that reasons about additional leakages from weaker encryption techniques, based on semantic data properties (e.g., dependence between attribute values); (ii) a normalization mechanism that converts relational data into secure normal forms, so that the information leaked by the representation is limited to that specified by the user; and (iii) a secure query execution approach over encrypted data in secure normal forms. Our initial experimental results validate the performance improvement over naïve baseline and show that a careful data representation can be allowed without compromising security. We believe that our paper opens a new direction in secure data management.}
}


@inproceedings{DBLP:conf/icde/Ceri0G24,
	author = {Stefano Ceri and
                  Anna Bernasconi and
                  Alessia Gagliardi},
	title = {Reactive Knowledge Management},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5574--5582},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00445},
	doi = {10.1109/ICDE60146.2024.00445},
	timestamp = {Sun, 06 Oct 2024 21:04:56 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Ceri0G24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Today's large knowledge graphs are conceived mainly for supporting search and e-commerce within large companies such as Google or Amazon, with well-crafted knowledge creation rules. Our recent experience of the COVID-19 pandemic, when knowledge has grown at unprecedented rates and has been often contradictory, inspired us to capture a huge gap in existing concepts and technology: today's knowledge management does not adequately support such a disruptive process. In this article, we propose the design and prototyping of the next generation of knowledge management concepts and systems, which will support domain diversity and scientific evolution as foundational ingredients. Change management is based on a reactive approach, well-established in database systems, but so far lacking in knowledge systems. We propose the reactive interaction of several knowledge hubs, each developed within a scientific domain and “owner” of a portion of a common knowledge representation. Knowledge is represented as graphs, with nodes and edges; edges may inter-connect nodes from different hubs. Most importantly, reactive rules cross the hub's borders and create the premises for a disciplined knowledge evolution, even under the pressure of crises. Similar challenges are not restricted to the recent pandemic and can address other crisis scenarios, including the catastrophic consequences of climate change or the recent (r)-evolution in artificial intelligence, studied by several scientific communities, whose management requires complex and controversial choices.}
}


@inproceedings{DBLP:conf/icde/YamadaKG24,
	author = {Hiroyuki Yamada and
                  Masaru Kitsuregawa and
                  Kazuo Goda},
	title = {LakeHarbor: Making Structures First-Class Citizens in Data Lakes},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5583--5592},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00446},
	doi = {10.1109/ICDE60146.2024.00446},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/YamadaKG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper introduces LakeHarbor, a new data management paradigm that makes structures (e.g., indexes) first-class citizens in data lakes. The LakeHarbor paradigm enables a data lake system to flexibly construct structures based on registered access method functions and execute data processing jobs efficiently with the potential parallelism that the structures inherently hold by exploiting the functions while not sacrificing flexible data processing such as schema-on-read. This paper also presents ReDe, a prototype data processing engine that implements LakeHarbor, and a motivating evaluation and a case study of ReDe to explore the potential of LakeHarbor.}
}


@inproceedings{DBLP:conf/icde/Guo024,
	author = {Yunyan Guo and
                  Guoliang Li},
	title = {A {CXL-} Powered Database System: Opportunities and Challenges},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5593--5604},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00447},
	doi = {10.1109/ICDE60146.2024.00447},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Guo024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Compute Express Link (CXL) is emerging as a significant player in the landscape of modern database man-agement systems (DBMS). CXL is an open industry-standard interconnect protocol between processors and devices such as memory buffers. Boasting high bandwidth, low latency, and support for coherency and memory semantics, CXL opens a new direction for addressing the limitations and bottlenecks faced by traditional distributed DBMS, particularly in large-scale data management, efficient query processing, and improving system availability. This paper explores the significant potential of employing CXL in constructing next-generation DBMS. Through a thorough analysis of CXL's key characteristics, this paper identifies emerging opportunities, particularly in buffer pool expansion, memory elasticity, swift data recovery, and index optimization. More importantly, this paper outlines a series of new challenges accompanying these opportunities, with the objective of inspiring cutting-edge approaches in future DBMS design that emphasize efficiency, reliability, and reduced total cost of ownership.}
}


@inproceedings{DBLP:conf/icde/ClarksonTW24,
	author = {James Clarkson and
                  Georgios Theodorakis and
                  Jim Webber},
	title = {{BIFROST:} {A} Future Graph Database Runtime},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5605--5613},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00448},
	doi = {10.1109/ICDE60146.2024.00448},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ClarksonTW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {BIFROST is a novel query engine for graph databases that supports high-fidelity data modeling on arbitrary and evolving graph topologies. It dynamically optimizes queries according to meta-level changes in the underlying graph (i.e. changes in topology) without the need for any explicit schema. This is possible by using state-of-the-art techniques from managed programming languages, such as self-optimizing ASTs and deoptimization, to combine query optimization and compilation. The approach provides high fidelity for even highly irregular labeled property graphs and gives good performance when compared to other systems that depend on fixed schemas for query planning and optimization.}
}


@inproceedings{DBLP:conf/icde/Winecki024,
	author = {Dominik Winecki and
                  Arnab Nandi},
	title = {{V2V:} Efficiently Synthesizing Video Results for Video Queries},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5614--5621},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00449},
	doi = {10.1109/ICDE60146.2024.00449},
	timestamp = {Sun, 06 Oct 2024 21:04:59 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Winecki024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Querying video data has become increasingly popular and useful. Video queries can be complex, ranging from retrieval tasks (“find me the top videos that have … ”), to analytics (“how many videos contained object X per day?”), to excerpting tasks (“highlight and zoom into scenes with object X near object Y”), or combinations thereof. Results for video queries are still typically shown as either relational data or a primitive collection of clickable thumbnails on a web page. Presenting query results in this form is an impedance mismatch with the video medium: they are cumbersome to skim through and are in a different modality and information density compared to the source data. We describe V2V, a system to efficiently synthesize video results for video queries. V2V returns a fully-edited video, allowing the user to consume results in the same manner as the source videos. A key challenge is that synthesizing video results from a collection of videos is computationally intensive, especially within interactive query response times. To address this, V2V features a grammar to express video transformations in a declarative manner and a heuristic optimizer that improves the efficiency of V2V processing in a manner similar to how databases execute relational queries. Experiments show that our V2V optimizer enables video synthesis to run 3x faster.}
}


@inproceedings{DBLP:conf/icde/SchuleH24,
	author = {Maximilian E. Sch{\"{u}}le and
                  Jakob Hornung},
	title = {Higher-Order {SQL} Lambda Functions},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5622--5628},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00450},
	doi = {10.1109/ICDE60146.2024.00450},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/SchuleH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Model databases track the accuracy of models on pre-trained weights. The models are stored as executable code and extracted on deployment. Instead of extracting runnable code and data out of a database system, we propose higher-order SQL lambda functions for in-database execution. SQL lambda expressions have been introduced to let the user customise otherwise hard-coded data mining operators such as the distance function for k-means clustering. However, database systems parse lambda expressions during the semantic analysis, which does not allow for functions as arguments. This paper proposes higher-order lambda functions that support the execution of functions from a table as input. Higher-order lambda functions expressing machine learning models allow data scientists to monitor the qualities over time and thus eliminate the need for any extraction step. This paper presents the conception of higher-order lambda functions and their embedding into relational algebra using a derived map operator. We further present the current prototype implementation on top of relational database systems and present preliminary results for data mining within SQL.}
}


@inproceedings{DBLP:conf/icde/LuH24,
	author = {Jiangtao Lu and
                  Song Huang},
	title = {{PR-GNN:} Enhancing PoC Report Recommendation with Graph Neural Network},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5629--5633},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00451},
	doi = {10.1109/ICDE60146.2024.00451},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LuH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {There has been a growing number of software supply chain vulnerabilities disclosed annually, posing increasingly formidable challenges to vulnerability validation. Timely validation plays a critical role in mitigating the security risks across the entire software supply chain. Whenever a new vulnerability is disclosed, it may be difficult to generate a corresponding PoC for verification in a short time. Expediting the validation process can be achieved through reference to similar PoC reports, potentially reducing this time. Retrieving similar PoC reports manually is labor-intensive and time-consuming due to their distributed nature across different data sources. Moreover, PoC reports encompass diverse trigger methods, including code, instruction, and action. There is a limitation in the current modeling of different types of trigger methods in PoC reports, as it mainly focuses only on code-based trigger methods while disregarding other types of trigger methods. To tackle the issues, this Ph.D. research uses graph-based method to model all types of PoC and proposes a PoC report recommendation model utilizing graph neural network (PR-GNN) to provide related PoC reports when facing a new vulnerability. In this work, a collection of heterogeneous PoC reports from various sources is assembled and modeled as PoC heterogeneous graphs. PR-GNN accurately measures similarity by incorporating graph-level embedding comparison and fine-grained comparison of trigger method type nodes. To our knowledge, this research represents the first attempt to provide more accurate and efficient recommendations for PoC reports to assist security professionals in timely vulnerability verification and maintaining software supply chain security.}
}


@inproceedings{DBLP:conf/icde/BaccaertK24,
	author = {Tim Baccaert and
                  Bas Ketsman},
	title = {Cascade: Optimal Transaction Scheduling for High-Contention Workloads},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5634--5638},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00452},
	doi = {10.1109/ICDE60146.2024.00452},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/BaccaertK24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The performance of multi-core transactional systems is a well-studied area, with the ultimate goal of optimizing the balance between high concurrency and the appearance of serial execution. In recent years, partitioning-based systems have shown that we can gain benefits from ahead-of-execution analysis on batches of transactions. However, this benefit is largely lost as contention increases. In this work, we investigate what it means for a batch to be executed optimally in the face of high contention. Intuitively, we will consider a schedule to be optimal if it minimizes the time spent waiting for exclusive access to tuples. We also design an algorithm that can optimally schedule batches, that satisfy particular properties, in quasi-linear time. We then implement it in a system called Cascade, and provide a preliminary evaluation against an existing system.}
}


@inproceedings{DBLP:conf/icde/CavalleriM24,
	author = {Emanuele Cavalleri and
                  Marco Mesiti},
	title = {Construction and Enhancement of an RNA-Based Knowledge Graph for Discovering
                  New {RNA} Drugs},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5639--5643},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00453},
	doi = {10.1109/ICDE60146.2024.00453},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/CavalleriM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cutting-edge technologies in RNA biology are pushing the study of fundamental biological processes and human diseases and accelerate the development of new drugs tailored to the patient's biomolecular characteristics. Even if many structured and unstructured data sources report the interaction among different RNA molecules and some other biomedical entities (e.g., drugs, diseases, genes), we still lack a comprehensive and well-described RNA-centered Knowledge Graph (KG) that contains such information and sophisticated services that support the user in its creation, maintenance, and enhancement. This PhD project aims to create a biomedical KG (named RNA-KG) to represent, and eventually infer, biological, experimentally validated interactions between different RNA molecules. We also wish to enhance the KG content and develop sophisticated services designed ad-hoc to support the user in predicting uncovered relationships and identifying new RNA-based drugs. Services will rely on deep learning methods that consider the heterogeneity of the graph and the presence of an ontology that describes the possible relationships existing among the involved entities. Moreover, we will consider Large Language Models (LLMs) in combination with RNA-KG for interacting with the user with the ground truth information contained in our KG for extracting relationships from unstructured data sources.}
}


@inproceedings{DBLP:conf/icde/Papon24,
	author = {Tarikul Islam Papon},
	title = {Enhancing Data Systems Performance by Exploiting {SSD} Concurrency
                  {\&} Asymmetry},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5644--5648},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00454},
	doi = {10.1109/ICDE60146.2024.00454},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Papon24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Solid-state drives (SSDs) have become the dominant storage technology because of their faster read and write speeds and superior random access performance. Unlike their ancestor hard disk drives, SSDs exhibit two distinct characteristics: (i) read/write asymmetry, where writes are slower than reads, and (ii) access concurrency, allowing multiple I/O operations to run simultaneously and fully utilize device bandwidth. Despite these, most storage-intensive applications are not optimized for SSD asymmetry and concurrency, often leading to device underuti-lization. In this thesis, we uncover these crucial SSD properties and outline how we can better exploit these properties from the application perspective. First, we augment the traditional I/O model with the Parametric I/O Model (PIO), a new storage model that faithfully represents storage devices by parameterizing read/write asymmetry\n(a)\nand access concurrency\n(k)\n. Second, using this novel storage modeling, we propose a new Asymmetry & Concurrency-aware bufferpool management (ACE) that batches writes based on device concurrency and performs them in parallel to amortize the asymmetric write cost while performing parallel prefetching to exploit the device's read concurrency. Third, we further present a Concurrency-aware graph processing engine CAVE that harnesses the parallelism supported by the underlying SSD device via concurrent I/Os. CAVE traverses multiple paths and processes multiple nodes and edges concurrently without altering the fundamental graph traversal algorithm guarantees. Overall, our analysis shows that more faithful storage modeling leads to higher performance and better device utilization.}
}


@inproceedings{DBLP:conf/icde/NakamuraM24,
	author = {Yuta Nakamura and
                  Tanu Malik},
	title = {Differential Analysis for System Provenance},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5649--5653},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00455},
	doi = {10.1109/ICDE60146.2024.00455},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/NakamuraM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Debugging and understanding system behavior pose technical challenges, often necessitating the comparison of two audited execution traces. Although provenance systems audit trace events, the audited traces at most enable causal analysis within a single known execution. As a result, utilizing provenance systems for debugging and reasoning is a challenging task. This paper addresses the challenge of using provenance within the context of debugging by developing methods for differential analysis of system provenance. Our approach emphasizes the importance of knowing the application's provenance graph structure and embedding this graph structure information within traces to conduct precise differential analysis of system provenance. We develop algorithms that report all the differences precisely across two execution traces generated from the same application's provenance graph structure. Our framework shows that current provenance systems must audit at a higher granularity to accu-rately report results of a differential analysis. We show that such overheads can be potentially offset by statically analyzing the application's provenance graph structure. Finally, we outline the challenges of performing differential analysis on real distributed execution traces.}
}


@inproceedings{DBLP:conf/icde/000124,
	author = {Arijit Khan},
	title = {Synergies Between Graph Data Management and Machine Learning in Graph
                  Data Pipeline},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5655--5656},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00457},
	doi = {10.1109/ICDE60146.2024.00457},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/000124.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graphs are popular mathematical tools to model data with relations, such as the Web, social and biological networks, financial transactions, and knowledge bases. Machine learning and recently, deep learning over graphs becomes preva-lent. In modern data science applications, complex data move through various processes involved in machine learning to gen-erate the final predictive output, thereby creating a data pipeline consisting of graph data extraction, acquisition, and cleaning, graph embedding, machine learning training and inference, downstream tasks, explainability, and adding human in-the-loop, as depicted in Figure 1. We investigate how graph data management, which deals with effective, efficient, scalable, and user-friendly systems and algorithms for storing, processing, and analyzing large volumes of heterogeneous and complex graphs, could benefit from graph machine learning and vice versa, over the end-to-end graph data pipeline. We shall emphasize on (1) how graph data management helps in graph machine learning, e.g., in scalable graph embedding and designing user-friendly explainability methods; and (2) how graph machine learning helps in graph data management, e.g., in question answering over knowledge graphs.}
}


@inproceedings{DBLP:conf/icde/Papotti24,
	author = {Paolo Papotti},
	title = {Large Language Models as Storage for {SQL} Querying},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5657--5658},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00458},
	doi = {10.1109/ICDE60146.2024.00458},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Papotti24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Declarative querying is one of the main features behind the popularity of databases. However, SQL can be executed only on structured datasets, leaving out of immediate reach infor-mation in unstructured text. Technologies have been deployed to extract structured data from unstructured text and to model such data in relations or triples, but creating well-formed data from text is still time consuming and error prone.}
}


@inproceedings{DBLP:conf/icde/MohammedYFZS024,
	author = {Haneen Mohammed and
                  Alexander Yao and
                  Lampros Flokas and
                  Hongbin Zhong and
                  Charlie Summers and
                  Eugene Wu},
	title = {Accelerating Deletion Interventions on {OLAP} Workload},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5659},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00459},
	doi = {10.1109/ICDE60146.2024.00459},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/MohammedYFZS024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Deletion based view maintenance is a building block in many query explanation and analytics applications, such as sensitivity analysis, what-if analysis, data cleaning, and probabilistic databases, which require exploring how a query's output result changes when excluding (deleting) subsets of input relations (referred to as “deletion interventions”). These applications' ability to remain interactive is limited by how fast they can recompute output results, especially over complex queries and large data. A critical limitation in existing engines is their performance. To remain interactive, existing approaches either restrict the types of aggregation functions, require explanations to be pre-specified, or apply sampling and approximation. We show how to build an interactive deletion intervention evaluation engine for SPJA queries, by Ieveraging recent advances in fast fine-grained provenance that captures input/output relationship for each physical operator in a denormalized compact pointer-free format. We use provenance to propagate the deletion status of tuples per operator, in a tight loop that leads to improvement in instruction and data locality. In addition, this representation is amenable to a variety of physical optimizations, such as dictionary-encoding, bit-packing, vectorization, and parallelization. Operators' output tuples can be evenly split across threads, and their deletion status can be computed independently. Our preliminary results show that on the TPC-H workload, our engine takes on average 9ms to evaluate 1K deletion interventions at a time, achieving on average wins of 3 orders of magnitude over DBToaster, a state-of-the art IVM based engine, and wins of 4 orders of magnitude against existing provenance based approaches. Utilizing tight loops and a cache-friendly provenance and intervention representation enable us to evaluate thousands of deletion interventions at interactive speed, and enable interactive time query explanations over more complex queries and data than previously possible.}
}


@inproceedings{DBLP:conf/icde/SahaABT24,
	author = {Sanad Saha and
                  Nischal Aryal and
                  Leilani Battle and
                  Arash Termehchy},
	title = {User Learning In Interactive Data Exploration},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5660--5661},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00460},
	doi = {10.1109/ICDE60146.2024.00460},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/SahaABT24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Users explore large, complex datasets to find interesting hypotheses and previously unseen insights. In this process, known as data exploration, users often generate database queries without any precise goals or concrete information need, posing challenges for database systems that assume the user has a clear intent a priori. In response, system developers often model users' exploration strategies over time, which could enable the system to predict and adapt to users' subsequent actions. However, current models generally treat users' exploration behavior as static, whereas in reality, users dynamically change their behavior in response to what they learn during exploration. In this paper, we present an analysis of existing data exploration logs to quantify shifts in users' data exploration strategies over time. Our analysis confirms that users shift their behavior over time, and state-of-the-art learning algorithms struggle to adapt to this evolution, revealing new avenues for building more accurate models of user exploration behavior within data exploration systems.}
}


@inproceedings{DBLP:conf/icde/Papapetroud24,
	author = {Odysseas Papapetrou and
                  Jens E. d'Hondt},
	title = {Multivariate Similarity Search - {A} Call for a New Breed of Similarity
                  Search Algorithms},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5662},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00461},
	doi = {10.1109/ICDE60146.2024.00461},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Papapetroud24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The similarity search task involves identifying pairs of similar vectors, e.g., time series. For example, given a query\nq\n, the user might wish to find all vectors in a dataset with a cosine similarity with\nq\nhigher than a threshold\nt\n, or to find the top-k most similar vectors with\nq\n, using Euclidean distance. The task has been widely considered in different domains, ranging from data science for detecting correlations that help the analyst extract insights from the data, to e-commerce for recommending additional purchases to the users based on their shopping behavior. Accordingly, many similarity search algorithms and indices were proposed in the literature, focusing on efficiency, scalability for big datasets, and different distance measures. However, the majority of past work only considers pairwise similarity/distance measures. In this talk we will revisit similarity search under the lens of multivariate similarity measures.}
}


@inproceedings{DBLP:conf/icde/LanghiB024,
	author = {Samuele Langhi and
                  Angela Bonifati and
                  Riccardo Tommasini},
	title = {Towards Streaming Consistency Management},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5663},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00462},
	doi = {10.1109/ICDE60146.2024.00462},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LanghiB024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Stream processing is designed to query unbounded and timely-ordered data flows in real-time while guaranteeing low latency and high throughput.}
}


@inproceedings{DBLP:conf/icde/0001IV24,
	author = {George Papadakis and
                  Ekaterini Ioannou and
                  Yannis Velegrakis},
	title = {Unveiling Dis-Integration},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5664},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00463},
	doi = {10.1109/ICDE60146.2024.00463},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/0001IV24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Entity Resolution (ER) has been extensively studied over the last decade, with a plethora of algorithmic solutions, techniques, and methodologies having been proposed [1]. The individual state-of-the-art ER algorithms are offered through open-source systems, such as Magellan [2] and JedAI [3], which typically implement end-to-end solutions through a sequence of workflow steps. Each workflow step requires its own special configuration and fine tuning, thus turning the creation of complete ER solutions into a non-trivial, time-consuming process that requires adapting, among others, to the characteristics of the data to be resolved (e.g., relational, semi-structured, etc.), to its intrinsic noise (e.g., misspellings, abbreviations, etc.) as well as to application constraints (e.g., execution time).}
}


@inproceedings{DBLP:conf/icde/Sun024,
	author = {Wenbo Sun and
                  Rihan Hai},
	title = {Cross-Source {ML} Model Training},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5665--5666},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00464},
	doi = {10.1109/ICDE60146.2024.00464},
	timestamp = {Mon, 19 Aug 2024 20:24:08 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Sun024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Machine learning (ML) often operates on data fragmented across silos through two paradigms: distributed or centralized. This study illuminates the underexplored signifi-cance of data integration (DI) metadata in both methodologies. Our contribution is threefold. First, we formalize the complex relationships of data sources with DI metadata. Second, we propose an approach that transforms DI metadata into matrix representations, and streamlines data transformation and linear algebra operations over source datasets. Third, we present an optimization method, effectively deciding between factorization versus materialization. By leveraging logic-based pruning rules and an ML-based cost estimator, our approach outperforms state-of-the-art baselines and makes the trade-off of factorization and materialization with up to 90.5% accuracy.}
}


@inproceedings{DBLP:conf/icde/Jensen0PMA24,
	author = {S{\o}ren Kejser Jensen and
                  Christian Thomsen and
                  Torben Bach Pedersen and
                  Carlos Enrique Mu{\~{n}}iz{-}Cuza and
                  Abduvoris Abduvakhobov},
	title = {Why Model-Based Lossy Compression is Great for Wind Turbine Analytics},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5667--5668},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00465},
	doi = {10.1109/ICDE60146.2024.00465},
	timestamp = {Sun, 06 Oct 2024 21:04:57 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Jensen0PMA24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Modern wind turbines are equipped with wired high-quality sensors that produce high-frequency sensor data in the form of time series as shown in Figure 1 a. From working with multiple different practitioners, we have learned that relatively few but very long high-quality time series are produced. The time series are either univariate, i.e., have one value per timestamp, or multivariate, i.e., have multiple values per timestamp. Further, they are either regular, i.e., have a fixed time interval between consecutive data points, or irregular. Despite these differences, the volume and velocity of the time series that are being produced are generally major challenges. For example, if the sensors are sampled at 100Hz, a single park of 100 wind turbines generates more than 11 PiB of data each year [1]. The sensor data is collected by weak edge devices and then transferred to powerful cloud servers over a relatively slow connection as shown in Figure 2. However, it is infeasible to transfer and store the raw time series due to their volume and velocity. Renewable energy system installations use low-end commodity PCs on the edge, e.g., 4 CPU cores, 4 GiB RAM, and an HDD [1]. In addition, the bandwidth between the edge and the cloud can be as low as 0.5-5 Mbit/s [1]. Thus, practitioners use simple aggregates, e.g., 10-minute averages, which remove valuable outliers and fluctuations as shown in Figure 1b. To remedy this, practitioners want to use lossy compression with a per-value error bound (E) to collect more high-frequency time series and thus improve their analytics.}
}


@inproceedings{DBLP:conf/icde/RorsethGGSS24a,
	author = {Joel Rorseth and
                  Parke Godfrey and
                  Lukasz Golab and
                  Divesh Srivastava and
                  Jaroslaw Szlichta},
	title = {Towards Explainability in Retrieval-Augmented LLMs},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5669--5670},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00466},
	doi = {10.1109/ICDE60146.2024.00466},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/RorsethGGSS24a.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In an era where artificial intelligence (AI) is re-shaping countless aspects of society, we present a forward-looking perspective for enhancing the explainability of large language models (LLMs), with a particular focus on the retrieval-augmented generation (RAG) prompting technique. We motivate the urgency for developing techniques to explain LLM decision-making behaviour, especially as these models are deployed in critical sectors. Central to this effort is RAGE, our novel explain-ability tool that can trace the provenance of an LLM's answer back to external knowledge sources provided via RAG. RAGE builds upon established explainability techniques to recover citations for LLM answers, identify context biases, and mine answer rules. Through our novel explainability formulations and practical use cases, we chart a course toward more transparent and trustworthy AI technologies.}
}


@inproceedings{DBLP:conf/icde/LaignerZ24,
	author = {Rodrigo Laigner and
                  Yongluan Zhou},
	title = {Benchmarking Data Management Systems for Microservices},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5671--5672},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00467},
	doi = {10.1109/ICDE60146.2024.00467},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LaignerZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Microservice architectures emerged as a popular architecture for designing scalable applications. This architecture promotes the decomposition of an application into independently deployable small services each encapsulating a private state [1]. Data exchanges and communication among microservices are often achieved via asynchronous events. This architecture enables practitioners to reap benefits associated with loose coupling, fault isolation, higher data availability, independent schema evolution, and increased scalability [2].}
}


@inproceedings{DBLP:conf/icde/YuGGSS24a,
	author = {Andy Yu and
                  Parke Godfrey and
                  Lukasz Golab and
                  Divesh Srivastava and
                  Jaroslaw Szlichta},
	title = {Exploring the Space of Model Comparisons},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5673--5674},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00468},
	doi = {10.1109/ICDE60146.2024.00468},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/YuGGSS24a.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Deploying machine-learning (ML) models is difficult and fraught with peril. Replacing an old model with a new one may introduce new biases and weaknesses that were easily over-looked. Unlike software updates where we have best practices (unit tests and the like), such best practices for ML are only now evolving. The ML deployment pipeline suffers further from a fracture: on the one side, one has the “data-science” (DS) pipeline, in which one extracts, loads, transforms, and maintains the vast lakes of data the models need to be trained on; on the other side, one has the “ML” pipeline in which experts test and evaluate models, often comparing many, for fitness for the task. To progress ultimately, these two pipelines must be integrated into a single DS/ML pipeline. We posit that doing so rests on model explainability and comparison.}
}


@inproceedings{DBLP:conf/icde/Aref24,
	author = {Walid G. Aref},
	title = {On Native Location-Optimized Data Systems},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5675--5676},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00469},
	doi = {10.1109/ICDE60146.2024.00469},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Aref24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the ubiquity of location detection devices and location services and the massive amounts of the location data being produced, there is dire need for developing highly scalable location data systems. Currently, location data is usually supported as an afterthought in existing data systems, and hence these systems are not optimized natively for location data handling. This short paper reflects a lightning talk presented by the author. It calls for designing systems with location data being a first-class citizen, and highlights several important aspects that characterize location-optimized data systems. These include deterministic performance, supporting write-optimization, update tolerance, having adaptive location indexes and adaptive data stores, and having tight integration with the graph, document, relational and other multi data models for optimized performance.}
}


@inproceedings{DBLP:conf/icde/0008Z24,
	author = {Cheng Chen and
                  Shuai Zhang},
	title = {Observations and Opportunities in Solving Large-Scale Graph Data Processing
                  Challenges at ByteDance by Using Heterogeneous Hardware},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5677--5678},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00470},
	doi = {10.1109/ICDE60146.2024.00470},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/0008Z24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {ByteDance stores vast amounts of data in graph form, witnessing rapid growth due to advancements in recommendation, e-commerce, etc. Traditional CPU-based graph processing systems fall short in handling time-sensitive computations and Graph Neural Network tasks on large-scale graph data. This talk will outline the challenges ByteDance encounters in scaling and processing graph data and will highlight two scenarios: real-time incremental graph processing using CPU-GPU combinations (speed up 13.1x), and dynamic graph random walks on FPGA clusters (speed up 6x). We will discuss how leveraging heterogeneous hardware addresses these complex business requirements.}
}


@inproceedings{DBLP:conf/icde/0003KQJ24,
	author = {Rihan Hai and
                  Christos Koutras and
                  Christoph Quix and
                  Matthias Jarke},
	title = {Data Lakes: {A} Survey of Functions and Systems (Extended abstract)},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5679--5680},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00471},
	doi = {10.1109/ICDE60146.2024.00471},
	timestamp = {Mon, 19 Aug 2024 20:24:08 +0200},
	biburl = {https://dblp.org/rec/conf/icde/0003KQJ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Data lakes are becoming increasingly prevalent for big data management and data analytics. In contrast to traditional ‘schema-on-write’ approaches such as data warehouses, data lakes are repositories storing raw data in its original formats and providing a common access interface. Despite the strong interest raised from both academia and industry, there is a large body of ambiguity regarding the definition, functions and available technologies for data lakes. A complete, coherent picture of data lake challenges and solutions is still missing. This survey reviews the development, architectures, and systems of data lakes. We provide a comprehensive overview of research questions for designing and building data lakes. We classify the existing approaches and systems based on their provided functions for data lakes, which makes this survey a useful technical reference for designing, implementing and deploying data lakes. We hope that the thorough comparison of existing solutions and the discussion of open research challenges in this survey will motivate the future development of data lake research and practice.}
}


@inproceedings{DBLP:conf/icde/LiWZ024,
	author = {Haoyang Li and
                  Xin Wang and
                  Ziwei Zhang and
                  Wenwu Zhu},
	title = {{OOD-GNN:} Out-of-Distribution Generalized Graph Neural Network: (Extended
                  Abstract)},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5681--5682},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00472},
	doi = {10.1109/ICDE60146.2024.00472},
	timestamp = {Wed, 09 Oct 2024 07:56:13 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LiWZ024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graph neural networks (GNNs) have achieved impressive performance when testing and training graph data come from identical distribution. However, existing GNNs lack out-of-distribution generalization abilities so that their performance substantially degrades when there exist distribution shifts between testing and training graph data. To solve this problem, we propose an out-of-distribution generalized graph neural network (OOD-GNN) for achieving satisfactory performance on unseen testing graphs that have different distributions with training graphs. OOD-GNN employs a novel nonlinear graph representation decorrelation method utilizing random Fourier features, which encourages the model to eliminate the statistical dependence between relevant and irrelevant graph representations through iteratively optimizing the sample graph weights and graph encoder. The learned weights help the graph encoder to get rid of spurious correlations and, in turn, concentrate more on the true connection between learned discriminative graph representations and their ground-truth labels. We conduct extensive experiments to validate the out-of-distribution generalization abilities on two synthetic and 12 real-world datasets with distribution shifts. The results demonstrate that our proposed OOD-GNN significantly outperforms state-of-the-art baselines.}
}


@inproceedings{DBLP:conf/icde/LiuJ00LX24,
	author = {Ning Liu and
                  Songlei Jian and
                  Dongsheng Li and
                  Yiming Zhang and
                  Zhiquan Lai and
                  Hongzuo Xu},
	title = {Hierarchical Adaptive Pooling by Capturing High-order Dependency for
                  Graph Representation Learning (Extended Abstract)},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5683--5684},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00473},
	doi = {10.1109/ICDE60146.2024.00473},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LiuJ00LX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graph pooling technique in GNNs for learning expressive graph-level representation is critical yet still chal-lenging. Existing pooling methods either struggle to capture local substructures or fail to utilize high-order dependency, thus diminishing the expression capability. To solve this problem, we propose HAP, a hierarchical graph-level representation learning framework adaptively sensitive to graph structures. Specifically, HAP utilizes a novel cross-level attention mechanism MOA to naturally focus more on the close neighborhood while effectively capturing higher-order dependency. It also learns a global graph content GCont that extracts the graph pattern properties to stabilize the pre- and post-coarsening graph content, thus providing global guidance in graph coarsening. Experiments show that HAP significantly outperforms the state-of-the-art graph pooling methods.}
}


@inproceedings{DBLP:conf/icde/Chan0UC24,
	author = {Tsz Nam Chan and
                  Zhe Li and
                  Leong Hou U and
                  Reynold Cheng},
	title = {{PLAME:} Piecewise-Linear Approximate Measure for Additive Kernel
                  {SVM} (Extended abstract)},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5685--5686},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00474},
	doi = {10.1109/ICDE60146.2024.00474},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Chan0UC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Additive Kernel SVM has been extensively used in many applications, including human activity detection and pedestrian detection. Since training an additive kernel SVM model is very time-consuming, which is not scalable to largescale datasets, many efficient solutions have been developed in the past few years. However, most of the existing methods normally fail to achieve one of these three important conditions which are (1) low classification error, (2) low memory space, and (3) low training time. In order to simultaneously fulfill these three conditions, we develop the new piecewise-linear approximate measure (PLAME) for training additive kernel SVM models. Experimental results verify that this approach can achieve the best trade-off between accuracy, memory space, and training time compared with different types of state-of-the-art methods.}
}


@inproceedings{DBLP:conf/icde/NajafipourHH0024,
	author = {Saeed Najafipour Najafipour and
                  Saeid Hosseini and
                  Wen Hua and
                  Mohammad Reza Kangavari and
                  Xiaofang Zhou},
	title = {Short-Text Author Linking Through Multi-Facet Temporal-Textual Embedding
                  (Extended Abstract)},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5687--5688},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00475},
	doi = {10.1109/ICDE60146.2024.00475},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/NajafipourHH0024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We devise a neural network-based temporal-textual framework that generates subgraphs with highly correlated authors from short-text contents. Our approach computes the relevance score (edge weight) between authors by considering a portmanteau of contents and concepts. It then employs a stack-wise graph-cutting algorithm to extract communities of related authors. Experimental results show that our multi-aspect vector space model can gain higher performance than other knowledge-centered competitors in linking short-text authors.}
}


@inproceedings{DBLP:conf/icde/JiangCHXB24,
	author = {Jiaxin Jiang and
                  Byron Choi and
                  Xin Huang and
                  Jianliang Xu and
                  Sourav S. Bhowmick},
	title = {{DKWS:} {A} Distributed System for Keyword Search on Massive Graphs
                  (Extended Abstract)},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5689--5690},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00476},
	doi = {10.1109/ICDE60146.2024.00476},
	timestamp = {Thu, 08 Aug 2024 08:11:02 +0200},
	biburl = {https://dblp.org/rec/conf/icde/JiangCHXB24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Addressing the complexities of querying unstructured graphs such as knowledge graphs and social networks, this paper introduces D KWS, a novel distributed keyword search system. Leveraging a monotonic property, we ensure correct parallelization of our advanced keyword search algorithm, which incorporates tight pruning bounds and is divided into monotonic backward and forward search phases. The system is further augmented by the notify-push paradigm and the PINE programming model, facilitating asynchronous communication and preemptive searches to mitigate staleness in distributed environments. Extensive experiments on real-world datasets demonstrate DKWS's performance advantage, being up to two orders of magnitude faster and incurring 7.6 times lower communication costs than the existing systems.}
}


@inproceedings{DBLP:conf/icde/ZhongL024,
	author = {Zhiqiang Zhong and
                  Cheng{-}Te Li and
                  Jun Pang},
	title = {Multi-Grained Semantics-Aware Graph Neural Networks (Extended abstract)},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5691--5692},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00477},
	doi = {10.1109/ICDE60146.2024.00477},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhongL024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graph Neural Networks (GNNs) are powerful techniques in representation learning for graphs and have been increasingly deployed in a multitude of different applications that involve node- and graph-wise tasks. Most existing studies solve either the node-wise task or the graph-wise task independently while they are inherently correlated. This work proposes a unified model, AdamGNN, to interactively learn node and graph representations in a mutual-optimisation manner. Compared with existing GNN models and graph pooling methods, AdamGNN enhances the node representation with the learned multi-grained semantics and avoids losing node features and graph structure information during pooling. Experiments on 14 real-world graph datasets show that AdamGNN can significantly outperform 17 competing models on both node- and graph-wise tasks. The ablation studies confirm the effectiveness of AdamGNN's components, and the last empirical analysis further reveals the ingenious ability of AdamGNN in capturing long-range interactions. This work was published at IEEE TKDE 1 1 Full paper is available at https://ieeexplore.ieee.org/document/9844866/.}
}


@inproceedings{DBLP:conf/icde/NardiniRTV24,
	author = {Franco Maria Nardini and
                  Cosimo Rulli and
                  Salvatore Trani and
                  Rossano Venturini},
	title = {Distilled Neural Networks for Efficient Learning to Rank: (Extended
                  Abstract)},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5693--5694},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00478},
	doi = {10.1109/ICDE60146.2024.00478},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/NardiniRTV24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recent studies in Learning to Rank (LtR) have shown the possibility of effectively distilling a neural network from an ensemble of regression trees. This fully enables the use of neural-based ranking models in query processors of modern Web search engines. Nevertheless, ensembles of regression trees outperform neural models both in terms of efficiency and effectiveness on CPU. In this paper, we propose a framework to design and train neural networks outperforming ensembles of regression trees. After distilling the networks from tree-based models, we exploit an efficiency-oriented pruning technique that works by sparsifying the most computationally intensive layers of the model. Moreover, we develop inference time predictors, which help devise neural network architectures that match the desired efficiency requirements. Comprehensive experiments on two public learning-to-rank datasets show that the neural networks produced with our novel approach are competitive in terms of effectiveness-efficiency trade-off when compared with tree-based ensembles by providing up to 4x inference time speed-up without degradation of the ranking quality.}
}


@inproceedings{DBLP:conf/icde/ChenY0Q24,
	author = {Zi Chen and
                  Long Yuan and
                  Li Han and
                  Zhengping Qian},
	title = {Higher-Order Truss Decomposition in Graphs (Extended Abstract)},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5695--5696},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00479},
	doi = {10.1109/ICDE60146.2024.00479},
	timestamp = {Sun, 04 Aug 2024 19:37:45 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ChenY0Q24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graphs have been widely used to represent the relationships of entities in real-world applications [1], [2]. k-truss model is a typical cohesive subgraph model and has received considerable attention due to its unique cohesive properties on degree and bounded diameter [3], [4].}
}


@inproceedings{DBLP:conf/icde/ZhaoC0W0024,
	author = {Yiwei Zhao and
                  Zi Chen and
                  Chen Chen and
                  Xiaoyang Wang and
                  Xuemin Lin and
                  Wenjie Zhang},
	title = {Finding the Maximum k- Balanced Biclique on Weighted Bipartite Graphs
                  (Extended abstract)},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5697--5698},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00480},
	doi = {10.1109/ICDE60146.2024.00480},
	timestamp = {Sun, 04 Aug 2024 19:37:45 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhaoC0W0024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As a popular data structure, bipartite graph is widely used to model the complex relationships between two types of entities widely in many real world application domains[1]. Detecting cohesive subgraphs, such as biclique, is a fundamental problem in graph analysis[2], [3]. Given a bipartite graph\nG\n, a subgraph\nB=(X, Y)\nis a biclique if\nB\nis a complete subgraph.}
}


@inproceedings{DBLP:conf/icde/CuiW0ZYXC024,
	author = {Ningning Cui and
                  Dong Wang and
                  Jianxin Li and
                  Huaijie Zhu and
                  Xiaochun Yang and
                  Jianliang Xu and
                  Jie Cui and
                  Hong Zhong},
	title = {Enabling Efficient, Verifiable, and Secure Conjunctive Keyword Search
                  in Hybrid-Storage Blockchains},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5699--5700},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00481},
	doi = {10.1109/ICDE60146.2024.00481},
	timestamp = {Tue, 30 Jul 2024 08:18:19 +0200},
	biburl = {https://dblp.org/rec/conf/icde/CuiW0ZYXC024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Blockchain has emerged as a prevailing paradigm for decentralized applications due to its reliability and transparency. To scale up retrieval services, a common strategy is to use a hybrid storage model, where on-chain storage is responsible for small metadata and off-chain storage is for outsourced raw data. However, data security and result authenticity are ongoing challenges in this scenario, and little work has been done due to the difficulty of combining result verification and privacy preservation, especially for dynamic updates while supporting forward privacy. In this paper, we formally define the problem of efficient, verifiable, and secure conjunctive keyword search in hybrid-storage blockchains (vsChain) and propose a novel hybrid index that achieves efficient query and verification while supporting dynamic updates with forward privacy guarantee. Finally, we provide empirical evaluations using real and synthetic datasets to demonstrate the feasibility of our proposed scheme.}
}


@inproceedings{DBLP:conf/icde/0001MWWWMH24,
	author = {Jiping Zheng and
                  Fanxu Meng and
                  Yanhao Wang and
                  Xiaoyang Wang and
                  Sheng Wang and
                  Yuan Ma and
                  Zhiyang Hao},
	title = {Hybrid Regret Minimization: {A} Submodular Approach (Extended Abstract)},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5701--5702},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00482},
	doi = {10.1109/ICDE60146.2024.00482},
	timestamp = {Tue, 30 Jul 2024 09:13:19 +0200},
	biburl = {https://dblp.org/rec/conf/icde/0001MWWWMH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we investigate the hybrid regret min-imization (HRM) query, a new method to extract representative tuples from databases. The HRM query combines the two types of regret minimization queries in the literature, namely maximum regret minimization (MRM) and average regret minimization (ARM) queries, aiming to select a size-k subset of tuples from a database to simultaneously minimize the maximum and average regret ratios. We show the NP-hardness of the HRM problem and propose an asymptotic algorithmic (AA) framework with several optimization techniques and a multiplicative weights update (MWU) algorithm to process HRM queries efficiently with theoretical guarantees. Finally, we demonstrate that our proposed algorithms achieve better performance for HRM queries than existing methods specific to MRM and ARM queries through extensive experiments on real-world and synthetic datasets.}
}


@inproceedings{DBLP:conf/icde/ZeighamiSS24,
	author = {Sepanta Zeighami and
                  Raghav Seshadri and
                  Cyrus Shahabi},
	title = {A Neural Database for Answering Aggregate Queries on Incomplete Relational
                  Data (Extended Abstract)},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5703--5704},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00483},
	doi = {10.1109/ICDE60146.2024.00483},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZeighamiSS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Real-world datasets are often incomplete due to data collection cost, privacy considerations or as a side effect of data integration/preparation. We focus on answering aggregate queries on such datasets, where data incompleteness causes the answers to be inaccurate. To address this problem, assuming typical relational data, existing work generates synthetic data to complete the database, a challenging task, especially in the presence of bias in observed data.}
}


@inproceedings{DBLP:conf/icde/Yan0LZS024,
	author = {Kefei Yan and
                  Wei Fang and
                  Hengyang Lu and
                  Xin Zhang and
                  Jun Sun and
                  Xiaojun Wu},
	title = {Mutual Information-Guided {GA} for Bayesian Network Structure Learning
                  (Extended Abstract)},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5705--5706},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00484},
	doi = {10.1109/ICDE60146.2024.00484},
	timestamp = {Thu, 08 Aug 2024 08:11:04 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Yan0LZS024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Bayesian network structure learning (BNSL) from data is an NP-hard problem. Genetic algorithms are powerful for solving combinatorial optimization problems, but the lack of effective guidance results in slow convergence and low accuracy regarding BNSL. To address this problem, we propose a mutual information (MI) guided genetic algorithm (MIGA) for BNSL in this paper, which uses MI to effectively search BN structures. In the initialization phase of MIGA, the population is generated by adding additional constraints based on MI to reach a higher score without losing diversity. By employing normalized MI and defining the population support, the potential dominance in the population can be identified and then used to design a novel crossover operator in order to preserve the dominant genes with a higher probability. Moreover, with the guidance of MI for removing loops from the structures, infeasible solutions can be handled in a straightforward and practical way. The proposed MIGA is evaluated on eleven well-known benchmark datasets and compared with four GA-based methods and four other state-of-the-art BNSL algorithms. Experimental results show that MIGA outperforms the compared algorithms in convergence and learning accuracy.}
}


@inproceedings{DBLP:conf/icde/WanHW024,
	author = {Xiaolong Wan and
                  Xixian Han and
                  Jinbao Wang and
                  Jianzhong Li},
	title = {Efficient Discovery of Functional Dependencies on Massive Data (Extended
                  Abstract)},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5707--5708},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00485},
	doi = {10.1109/ICDE60146.2024.00485},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/WanHW024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Functional dependencies (FDs) are the most common constraints in the design theory for relational databases, generalizing the concept of a key for a relation. Given an attribute subset X\nand an attribute A\nin relation schema, a functional dependency (FD) X\\rightarrow A\nmeans that the value of A\nis uniquely determined by the values of X\n. An FD X\\rightarrow A\nis minimal if A\nis not determined by any proper subset of X\n, and is nontrivial if A\nis not contained in X\nThe FD discovery problem is to determine all minimal nontrivial functional dependencies over a given relation instance.}
}


@inproceedings{DBLP:conf/icde/WangYW0Z024,
	author = {Hanchen Wang and
                  Jianke Yu and
                  Xiaoyang Wang and
                  Chen Chen and
                  Wenjie Zhang and
                  Xuemin Lin},
	title = {Neural Similarity Search on Supergraph Containment (Extended Abstract)},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5709--5710},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00486},
	doi = {10.1109/ICDE60146.2024.00486},
	timestamp = {Sun, 06 Oct 2024 21:04:59 +0200},
	biburl = {https://dblp.org/rec/conf/icde/WangYW0Z024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Supergraph search is a fundamental graph query processing problem. Supergraph search aims to find all data graphs contained in a given query graph based on the subgraph isomorphism. In other words, the goal is to determine if part of the query graph is the same as a smaller data graph. Existing algorithms construct the indices and adopt the filtering-and-verification framework, which is usually computationally expensive and can cause redundant computations. Recently, various learning-based methods have been proposed for a good trade-off between accuracy and efficiency for query processing tasks. However, to our knowledge, no learning-based method is proposed for the supergraph search task. In this paper, we propose the first learning-based method for similarity search on supergraph containment, named Neural Supergraph similarity Search (NSS). NSS first learns the representations for query and data graphs and then efficiently conducts the supergraph search on the representation space, the complexity of which is linear to the number of data graphs. The carefully designed Wasserstein discriminator and reconstruction network enable NSS to capture better the interrelation, structural and label information between and within the query and data graphs. Experiments demonstrate that the NSS is up to 6 orders of magnitude faster than the state-of-the-art exact supergraph search algorithm in query processing and is more accurate than the other learning-based solutions.}
}


@inproceedings{DBLP:conf/icde/00030LCC24,
	author = {Tiantian Liu and
                  Huan Li and
                  Hua Lu and
                  Muhammad Aamir Cheema and
                  Harry Kai{-}Ho Chan},
	title = {Contact Tracing over Uncertain Indoor Positioning Data (Extended Abstract)},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5711--5712},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00487},
	doi = {10.1109/ICDE60146.2024.00487},
	timestamp = {Sun, 06 Oct 2024 21:04:56 +0200},
	biburl = {https://dblp.org/rec/conf/icde/00030LCC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Pandemics like COVID-19 often cause dramatic losses of human lives and societal impacts, urging efficient and effective contact tracing, especially in indoor venues where the risk of infection is higher. In this work, we formulate a novel query called Indoor Contact Query (ICQ) over raw, uncertain indoor positioning data that digitalizes people's indoor mobility. Given a query object\no\n, e.g., a virus-carrying person, an ICQ analyzes uncertain indoor positioning data to find objects that most likely had close contact with\no\nfor a long period of time. To process ICQ, we propose a set of techniques. First, we design an enhanced indoor graph model to organize different types of data necessary for ICQ. Second, for indoor moving objects, we devise methods to determine uncertain regions and to derive positioning samples missing in the raw data. Third, we propose a query processing framework with a close contact determination method, a search algorithm, and multiple acceleration strategies. We conduct extensive experiments on synthetic and real datasets, which verify the efficiency and effectiveness of our proposals.}
}


@inproceedings{DBLP:conf/icde/Wan024,
	author = {Xiaolong Wan and
                  Hongzhi Wang},
	title = {Efficient Semi-External {SCC} Computation (Extended Abstract)},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5713--5714},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00488},
	doi = {10.1109/ICDE60146.2024.00488},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Wan024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Computing strongly connected components (SCC) is a key operation for many applications on directed graphs. Specifically, a SCC of a directed graph\nG\nis one of its maximal subgraphs, in which any two nodes are reachable to each other.}
}


@inproceedings{DBLP:conf/icde/SaakiHR0HZ24,
	author = {Mohsen Saaki and
                  Saeid Hosseini and
                  Sana Rahmani and
                  Mohammad Reza Kangavari and
                  Wen Hua and
                  Xiaofang Zhou},
	title = {Value-Wise ConvNet for Transformer Models: An Infinite Time-Aware
                  Recommender System (Extended Abstract)},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5715--5716},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00489},
	doi = {10.1109/ICDE60146.2024.00489},
	timestamp = {Wed, 14 Aug 2024 10:20:10 +0200},
	biburl = {https://dblp.org/rec/conf/icde/SaakiHR0HZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Addressing the challenge of matching queries with the right experts amid temporal-textual inconsistencies, we present a novel approach that combines an attention-based text embedding model with a continuous-time module. This method effectively maps queries to relevant experts by analyzing concept-oriented vectors and user behavior, demonstrating significant effectiveness on StackOverflow and Yahoo datasets.}
}


@inproceedings{DBLP:conf/icde/Lin0ZPHXZ24,
	author = {Qika Lin and
                  Jun Liu and
                  Lingling Zhang and
                  Yudai Pan and
                  Xin Hu and
                  Fangzhi Xu and
                  Hongwei Zeng},
	title = {Contrastive Graph Representations for Logical Formulas Embedding (Extended
                  Abstract)},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5717--5718},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00490},
	doi = {10.1109/ICDE60146.2024.00490},
	timestamp = {Tue, 08 Oct 2024 17:17:06 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Lin0ZPHXZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Embedding symbolic logical formulas into a low-dimensional continuous space provides an effective way for the Neural-Symbolic system. However, current studies are all constrained by the syntactic structure modeling and fail to preserve intrinsic semantics. To this end, we propose a novel model of Contrastive Graph Representations (ConGR) for logical formulas embedding. Firstly, it introduces a densely connected graph convolutional network (GCN) with an attention mechanism to process syntax parsing graphs of formulas. Secondly, the contrastive instances for each anchor formula are generated by the transformation under the guidance of logical properties. Two types of contrast, global-local and global-global, are carried out to refine formula embeddings with semantic information. Extensive experiments demonstrate that ConGR obtains superior performance against state-of-the-art baselines.}
}


@inproceedings{DBLP:conf/icde/ShaoWCZZ24,
	author = {Xinyue Shao and
                  Hongzhi Wang and
                  Xiang Chen and
                  Xiao Zhu and
                  Yan Zhang},
	title = {{CUBE:} Causal Intervention-based Counterfactual Explanation for Prediction
                  Models (Extended Abstract)},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5719--5720},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00491},
	doi = {10.1109/ICDE60146.2024.00491},
	timestamp = {Mon, 02 Dec 2024 08:28:18 +0100},
	biburl = {https://dblp.org/rec/conf/icde/ShaoWCZZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the explosion of artificial intelligence in various fields, providing causal explanations for predictive models becomes urgent. In this study, we investigate causal counterfactual explanation generation and propose CUBE, a causal intervention-based counterfactual explanation method. This work models the counterfactual generation process as a causal intervention model for the first time and employs a causal director to integrate causal relationships. Furthermore, this work proposes a model-based framework to improve counterfactual generation efficiency. The experimental results validate that CUBE outperforms baselines in terms of both lower time costs and higher explanation quality.}
}


@inproceedings{DBLP:conf/icde/MaYH0B024,
	author = {Chuan Ma and
                  Long Yuan and
                  Li Han and
                  Ming Ding and
                  Raghav Bhaskar and
                  Jun Li},
	title = {Data Level Privacy Preserving: {A} Stochastic Perturbation Approach
                  Based on Differential Privacy (Extended abstract)},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5721--5722},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00492},
	doi = {10.1109/ICDE60146.2024.00492},
	timestamp = {Thu, 14 Nov 2024 14:45:53 +0100},
	biburl = {https://dblp.org/rec/conf/icde/MaYH0B024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the great amount of available data, especially collected from the ubiquitous Internet of Things (IoT), the issue of privacy leakage has been an increasing concern recently. To preserve the privacy of IoT datasets, traditional methods usually calibrate random noises on the data values to achieve differential privacy (DP) [1]. However, the amount of calibrating noises should be carefully designed and a heedless value will definitely degrade the availability of datasets.}
}


@inproceedings{DBLP:conf/icde/CaiYLSYWZG24,
	author = {Taotao Cai and
                  Shuiqiao Yang and
                  Jianxin Li and
                  Quan Z. Sheng and
                  Jian Yang and
                  Xin Wang and
                  Wei Emma Zhang and
                  Longxiang Gao},
	title = {Incremental Graph Computation: Anchored Vertex Tracking in Dynamic
                  Social Networks (Extended Abstract)},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5723--5724},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00493},
	doi = {10.1109/ICDE60146.2024.00493},
	timestamp = {Sun, 06 Oct 2024 21:04:56 +0200},
	biburl = {https://dblp.org/rec/conf/icde/CaiYLSYWZG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {User engagement has recently received significant attention in understanding the decay and expansion of communities in many online social networking platforms. Many user engagement studies have been conducted to find a set of critical (anchored) users in the static social network. However, social networks are highly dynamic and their structures are continuously evolving. In this paper, we target a new research problem called Anchored Vertex Tracking (AVT), aiming to track the anchored users at each timestamp of evolving networks. To address the AVT problem, we develop a greedy algorithm inspired by the previous anchored k-core study in the static networks. Furthermore, we design an incremental algorithm to efficiently solve the AVT problem by utilizing the smoothness of the network structure's evolution. The extensive experiments demonstrate the performance of our proposed algorithms.}
}


@inproceedings{DBLP:conf/icde/PaganelliSPI024,
	author = {Matteo Paganelli and
                  Paolo Sottovia and
                  Kwanghyun Park and
                  Matteo Interlandi and
                  Francesco Guerra},
	title = {Pushing {ML} Predictions into DBMSs (Extended Abstract)},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5725--5726},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00494},
	doi = {10.1109/ICDE60146.2024.00494},
	timestamp = {Mon, 02 Sep 2024 20:32:18 +0200},
	biburl = {https://dblp.org/rec/conf/icde/PaganelliSPI024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We explore the use of Relational Database Manage-ment Systems to reduce technical debt in Machine Learning de-ployments, specifically focusing on in-DBMS prediction serving. We evaluate the performance of ML pipelines in Sklearn and ML.NET against their SQL counterparts executed on MySQL and SQL Server. Results suggest comparable performance when data resides in the database, indicating the potential feasibility of executing prediction processes directly in SQL on DBMSs.}
}


@inproceedings{DBLP:conf/icde/Abidi00L24,
	author = {Aman Abidi and
                  Lu Chen and
                  Rui Zhou and
                  Chengfei Liu},
	title = {Searching Personalized k-wing in Bipartite Graphs (Extended Abstract)},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5727--5728},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00495},
	doi = {10.1109/ICDE60146.2024.00495},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Abidi00L24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Enumerating all the bipartite cohesive subgraphs in a bipartite graph has been studied extensively. However, for some applications, one is interested in finding bipartite cohesive subgraphs containing a specific vertex. In this paper, we study a new query-dependent bipartite cohesive subgraph search problem based on k-wing model. To address the problem, we propose two efficient and wing number conserving indexing schemes, EquiWing-Graph and a more compact index, EquiWing-Tree, which is achieved by using our proposed k-butterfly loose approach and discovered hierarchy properties. Moreover, we discover novel properties that help us localize the scope of the maintenance in our proposed indices at a lower cost for evolving bipartite graphs. Extensive experimental results evidence the efficiency and effectiveness of our proposed approaches.}
}


@inproceedings{DBLP:conf/icde/ChenZCCSZ24,
	author = {Xi Chen and
                  Xiangmin Zhou and
                  Jeffrey Chan and
                  Lei Chen and
                  Timos Sellis and
                  Yanchun Zhang},
	title = {Complex Event Summarization Using Multi-Social Attribute Correlation
                  (Extended Abstract)},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5729--5730},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00496},
	doi = {10.1109/ICDE60146.2024.00496},
	timestamp = {Tue, 30 Jul 2024 08:18:19 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ChenZCCSZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Complex social event summarization is a problem which has been important for real-world applications, including crisis management, rumor control and government policy tracking. However, in many critical situations, social events are complex and context-sensitive, which demands the online summarization of social events in an integrated manner. Motivated by this, we propose an online complex social event summarization approach, namely SOMA, which summarizes the complex social events over multiple attributes including media content and contexts simultaneously. The evaluation shows that our proposed approach outperforms the existing solutions for event summarizaiton in terms of effectiveness and efficiency.}
}


@inproceedings{DBLP:conf/icde/LiZLWW24,
	author = {Ling Li and
                  Yuhai Zhao and
                  Siqiang Luo and
                  Guoren Wang and
                  Zhengkui Wang},
	title = {Efficient Community Search in Edge-Attributed Graphs (Extended Abstract)},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5731--5732},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00497},
	doi = {10.1109/ICDE60146.2024.00497},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/LiZLWW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Community search is a fundamental problem in graph analysis. However, prevailing community search models predominantly focus on non-attributed or vertex-attributed graphs. Real-world graphs often bear crucial information within their edges, depicting intricate interactions among vertices. Integrating this edge-based information becomes pivotal in refining community search methodologies. In this paper, we proposed the Edge-Attributed Community Search (EACS) problem and proved that the EACS problem is NP-hard. Advanced exact and 2-approximation algorithms are proposed to address the EACS problem. Extensive experiments demonstrate the efficiency and effectiveness of our algorithms.}
}


@inproceedings{DBLP:conf/icde/FangJLSWL24,
	author = {Wei Fang and
                  Haipeng Jiang and
                  Hengyang Lu and
                  Jun Sun and
                  Xiaojun Wu and
                  Jerry Chun{-}Wei Lin},
	title = {GPU-Based Efficient Parallel Heuristic Algorithm for High-Utility
                  Itemset Mining in Large Transaction Datasets (Extended Abstract)},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5733--5734},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00498},
	doi = {10.1109/ICDE60146.2024.00498},
	timestamp = {Sun, 06 Oct 2024 21:04:57 +0200},
	biburl = {https://dblp.org/rec/conf/icde/FangJLSWL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Heuristic algorithms have been developed to find approximate solutions for high-utility itemset mining (HUIM) problems that compensate for the performance bottlenecks of exact algorithms. However, heuristic algorithms still face the problem of long runtime and insufficient mining quality, especially for large transaction datasets with thousands to tens of thousands of items and up to millions of transactions. To solve these problems, a novel GPU-based efficient parallel heuristic algorithm for HUIM (PHA-HUIM) is proposed in this paper. The iterative process of PHA-HUIM consists of three main steps: the search strategy, fitness evaluation, and ring topology communication. The search strategy and ring topology communication are designed to run in constant time on GPU. The parallelism of fitness evolution helps to substantially accelerate the algorithm. To improve the mining quality, a multi-start strategy with an unbalanced allocation strategy is employed in the search process. Ring topology communication is adopted to maintain population diversity. A load balancing strategy is introduced to reduce the thread divergence to improve the parallel efficiency. The experimental results on nine large datasets show that PHA-HUIM outperforms state-of-the-art HUIM algorithms in terms of speedup performance, runtime, and mining quality.}
}


@inproceedings{DBLP:conf/icde/AzharPDJ24,
	author = {Nur Athirah Azhar and
                  Muhammad Syafiq Mohd Pozi and
                  Aniza Mohamed Din and
                  Adam Jatowt},
	title = {An Investigation of {SMOTE} Based Methods for Imbalanced Datasets
                  with Data Complexity Analysis (Extended Abstract)},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5735--5736},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00499},
	doi = {10.1109/ICDE60146.2024.00499},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/AzharPDJ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This extended abstract highlights challenges with imbalanced datasets in real-world applications, where issues like noise, class overlap, and small subsets of data impact classification accuracy. While the Synthetic Minority Oversampling Technique (SMOTE) addresses imbalanced datasets by increasing minority class examples, it struggles with handling these data complexities and might worsen the situation. As a result, several SMOTE variants have emerged, aiming to improve its effectiveness by integrating it with other methods or altering its approach. This paper offers a comparative analysis of these variants, examining how each tackles specific data complexities. Through experiments on 24 imbalanced datasets, changes in complexity measures resulting from these SMOTE variants, in terms of F1-Score and data complexity metrics are observed and demonstrated.}
}


@inproceedings{DBLP:conf/icde/MiaoWCGY24,
	author = {Xiaoye Miao and
                  Yangyang Wu and
                  Lu Chen and
                  Yunjun Gao and
                  Jianwei Yin},
	title = {An Experimental Survey of Missing Data Imputation Algorithms (Extended
                  Abstract)},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5737--5738},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00500},
	doi = {10.1109/ICDE60146.2024.00500},
	timestamp = {Tue, 30 Jul 2024 08:18:18 +0200},
	biburl = {https://dblp.org/rec/conf/icde/MiaoWCGY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Due to the ubiquity of missing data, data imputation has received extensive attention in the past decades. It is a well-recognized problem impacting almost all fields of scientific study. Existing imputation algorithms differ in problem settings, model selection, and data evaluation. There is a lack of systematic comparison study among imputation algorithms. In this paper, we survey this interesting and evolving research topic by broadly reviewing and experimentally comparing the state-of-the-art missing data imputation algorithms. We analyze and categorize 19 imputation algorithms. Extensive experiments over 15 real-world benchmark datasets are conducted under various settings of data types, missing mechanisms, missing rates, dataset parameters, as well as the post-imputation prediction task. We shed light on a series of constructive insights on imputation algorithms to tackle missing data problem in real-life scenarios. Moreover, we put forward promising future directions for data imputation.}
}


@inproceedings{DBLP:conf/icde/WuWMWY24,
	author = {Yangyang Wu and
                  Jun Wang and
                  Xiaoye Miao and
                  Wenjia Wang and
                  Jianwei Yin},
	title = {Differentiable and Scalable Generative Adversarial Models for Data
                  Imputation (Extended Abstract)},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5739--5740},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00501},
	doi = {10.1109/ICDE60146.2024.00501},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/WuWMWY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The dramatically increasing volume of incomplete data makes the imputation models computationally infeasible in many real-life applications. In this paper, we propose an effective scalable imputation system named SCIS to significantly speed up the training of the differentiable generative adversarial imputation models under accuracy-guarantees for large-scale incomplete data. SCIS consists of two modules, differentiable imputation modeling (DIM) and sample size estimation (SSE). DIM leverages a new masking Sinkhorn divergence function to make an arbitrary generative adversarial imputation model differentiable, while for such a differentiable imputation model, SSE can estimate an appropriate sample size to ensure the user-specified imputation accuracy of the final model. Moreover, SCIS can also accelerate the autoencoder based imputation models. Extensive experiments upon several real-life large-scale datasets demonstrate that, our proposed system can accelerate the generative adversarial model training by 6.23x. Using around 1.27% samples, SCIS yields competitive accuracy with the state-of-the-art imputation methods in much shorter computation time.}
}


@inproceedings{DBLP:conf/icde/Zeng0TTC24,
	author = {Weixin Zeng and
                  Xiang Zhao and
                  Zhen Tan and
                  Jiuyang Tang and
                  Xueqi Cheng},
	title = {Matching Knowledge Graphs in Entity Embedding Spaces: An Experimental
                  Study [Extended Abstract]},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5741--5742},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00502},
	doi = {10.1109/ICDE60146.2024.00502},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/Zeng0TTC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Entity alignment (EA) identifies equivalent entities that locate in different knowledge graphs (KGs), and has attracted growing research interests over the last few years with the advancement of KG embedding techniques. Although a pile of embedding-based EA frameworks have been developed, they mainly focus on improving the performance of entity representation learning, while largely overlook the subsequent stage that matches KGs\nin entity embedding spaces. Nevertheless, accurately matching entities based on learned entity representations is crucial to the overall alignment performance, as it coordinates individual alignment decisions and determines the global matching result. Hence, it is essential to understand how well existing solutions for matching KGs in entity embedding spaces perform on present benchmarks, as well as their strengths and weaknesses. To this end, in this article we provide a comprehensive survey and evaluation of matching algorithms for KGs in entity embedding spaces in terms of effectiveness and efficiency on both classic settings and new scenarios that better mirror real-life challenges. Based on in-depth analysis, we provide useful insights into the design trade-offs and good paradigms of existing works, and suggest promising directions for future development.}
}


@inproceedings{DBLP:conf/icde/ZhangL24,
	author = {Delvin Ce Zhang and
                  Hady Wirawan Lauw},
	title = {Topic Modeling on Document Networks with Dirichlet Optimal Transport
                  Barycenter},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5743--5744},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00503},
	doi = {10.1109/ICDE60146.2024.00503},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhangL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Texts are often interconnected in a network structure, e.g., academic papers via citations. On the one hand, though Graph Neural Networks (GNNs) have shown promising ability to derive effective embeddings for networked documents, they do not assume latent topics, resulting in uninterpretahle embeddings. On the other hand, topic models can infer interpretable document representations. However, most topic models focus on plain text and fail to leverage network structure across documents. In this paper, we propose a GNN-based topic model that both captures network connection and derives semantically interpretable text representations. For network modeling, we build our model with Optimal Transport Barycenter. For semantic interpretability, we extend optimal transport with pre-trained word embeddings.}
}


@inproceedings{DBLP:conf/icde/XieWZ0YZ0024,
	author = {Yuan Xie and
                  Fan Wu and
                  Xu Zhou and
                  Wensheng Luo and
                  Yifang Yin and
                  Roger Zimmermann and
                  Keqin Li and
                  Kenli Li},
	title = {Trajectory-Aware Task Coalition Assignment in Spatial Crowdsourcing
                  (Extended Abstract)},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5745--5746},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00504},
	doi = {10.1109/ICDE60146.2024.00504},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/XieWZ0YZ0024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the popularity of GPS-equipped smart devices, spatial crowdsourcing (SC) techniques have attracted growing attention in both academia and industry. In existing trajectory-aware task assignment approaches, tasks assigned to a worker may be far apart from each other, resulting in a higher detour cost as the worker needs to deviate from the original trajectory more often than necessary. Motivated by the above observations, we investigate a trajectory-aware task coalition assignment (TCA) problem and prove it to be NP-hard. The goal is to maximize the number of assigned tasks by assigning task coalitions to workers based on their preferred trajectories. To tackle the TCA problem, we develop a batch-based three-stage framework consisting of task grouping, planning, and assignment. Extensive experiments on real and synthetic datasets demonstrate the effectiveness and efficiency of the proposed algorithms.}
}


@inproceedings{DBLP:conf/icde/ZhuL0SLCWN24,
	author = {Yifan Zhu and
                  Qika Lin and
                  Hao Lu and
                  Kaize Shi and
                  Donglei Liu and
                  James Chambua and
                  Shanshan Wan and
                  Zhendong Niu},
	title = {Recommending Learning Objects through Attentive Heterogeneous Graph
                  Convolution and Operation- Aware Neural Network (Extended Abstract)},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5747--5748},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00505},
	doi = {10.1109/ICDE60146.2024.00505},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhuL0SLCWN24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Currently, the increasing information overload on Massive Open Online Courses(MOOCs) inhibits the appropriate choice of learning objects by learners, leading to low efficiency and high dropout rates. However, in MOOC platforms, recommendation network structures that can selectively extract implicit features such as heterogeneous learning preference and knowledge organization of learning objects are still not comprehensively studied. To this end, we propose a learning object recommendation model namely ACGCN based on heterogeneous learning behavior and knowledge graph. By introducing an attention mechanism, information is amplified when updating the representation of the heterogeneous graph, which eliminates the impact of noise and improves the robustness of ACGCN. Experimental results using a real-world dataset revealed that our proposed model has the best performance compared to those of several existing baselines.}
}


@inproceedings{DBLP:conf/icde/DooK24,
	author = {Woojin Doo and
                  Heeyoung Kim},
	title = {Simultaneous Deep Clustering and Feature Selection via K-concrete
                  Autoencoder (Extended abstract)},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5749--5750},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00506},
	doi = {10.1109/ICDE60146.2024.00506},
	timestamp = {Fri, 02 Aug 2024 21:41:46 +0200},
	biburl = {https://dblp.org/rec/conf/icde/DooK24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Existing deep learning methods for clustering high-dimensional data perform feature selection and clustering separately, which can result in the exclusion of some important features for clustering. In this paper, we propose a method that performs deep clustering and feature selection simultaneously by inserting a concrete selector layer between the input layer and the first encoder layer of a modified autoencoder. The concrete selector layer performs feature selection, while the modified autoencoder performs clustering in the latent space by incorporating K-means loss and inter-cluster distances. The proposed method, called the K-concrete autoencoder, selects features important for clustering and uses only the selected features to learn K-means-friendly latent representations of the data. Moreover, we propose an extension of the K-concrete autoencoder to provide relative importance of each selected feature. We demonstrate the effectiveness of the proposed method using simulated and real datasets.}
}


@inproceedings{DBLP:conf/icde/PourHH0024,
	author = {Saeed Najafi Pour and
                  Saeid Hosseini and
                  Wen Hua and
                  Mohammad Reza Kangavari and
                  Xiaofang Zhou},
	title = {SoulMate: Short-Text Author Linking Through Multi-Aspect Temporal-Textual
                  Embedding (Extended Abstract)},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5751--5752},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.00508},
	doi = {10.1109/ICDE60146.2024.00508},
	timestamp = {Mon, 29 Jul 2024 16:48:43 +0200},
	biburl = {https://dblp.org/rec/conf/icde/PourHH0024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We devise a neural network-based temporal-textual framework that generates subgraphs with highly correlated authors from short-text contents. Our approach computes the relevance score (edge weight) between authors by considering a portmanteau of contents and concepts. It then employs a stack-wise graph-cutting algorithm to extract communities of related authors. Experimental results show that our multi-aspect vector space model can gain higher performance than other knowledge-centered competitors in linking short-text authors.}
}


@inproceedings{DBLP:conf/icde/ZhangCCMZ24,
	author = {Yufeng Zhang and
                  Wei Chen and
                  Xi Chen and
                  Qingzhi Ma and
                  Lei Zhao},
	title = {Inductive Link Prediction for Sequential-emerging Knowledge Graph},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5753--5766},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.10637914},
	doi = {10.1109/ICDE60146.2024.10637914},
	timestamp = {Sat, 31 Aug 2024 21:23:36 +0200},
	biburl = {https://dblp.org/rec/conf/icde/ZhangCCMZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Inductive Link Prediction (ILP) aims to predict links for unseen entities in emerging Knowledge Graphs (KGs), where a more realistic scenario is that unseen entities do not emerge all at once but emerge sequentially in multiple stages. Unfortunately, existing studies neglect the sequential-emerging nature of KGs and simplify this scenario into multi-batch unseen entities emerging simultaneously. Subsequently, two problems arise and restrict the performance of existing methods: (1) lack of the capability to model the long-dependency interactions between entities across different stages; (2) unable to exploit the incremental characteristics when KGs emerge in sequence. To address the problems effectively, we dive into the practical scenario formulated as Sequential-emerging Knowledge Graphs (SEKGs), and propose a novel model entitled ISE 2 (Inductive Sequential Emerging Embedding). Specifically, ISE 2 is composed of the following two modules: (1) a relational graph-transformer network is designed to capture long-dependency interactions with the full-graph receptive field; (2) an adaptive attention mechanism is developed to iteratively integrate emerging KGs into a whole, fully utilizing the incremental characteristic in SEKGs. Furthermore, a new benchmark that conforms to the data distribution of real-world sequential-emerging is constructed. The experimental results demonstrate the superiority of ISE 2 compared with the state-of-the-art methods in SEKGs scenario.}
}


@inproceedings{DBLP:conf/icde/ZhangYLC24,
	author = {Nan Zhang and
                  Yutong Ye and
                  Xiang Lian and
                  Mingsong Chen},
	title = {Top-\emph{L} Most Influential Community Detection Over Social Networks},
	booktitle = {40th {IEEE} International Conference on Data Engineering, {ICDE} 2024,
                  Utrecht, The Netherlands, May 13-16, 2024},
	pages = {5767--5779},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/ICDE60146.2024.10639540},
	doi = {10.1109/ICDE60146.2024.10639540},
	timestamp = {Mon, 09 Dec 2024 07:44:48 +0100},
	biburl = {https://dblp.org/rec/conf/icde/ZhangYLC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In many real-world applications such as social network analysis and online marketing/advertising, community detection is a fundamental task to identify communities (subgraphs) in social networks with high structural cohesiveness. While previous works focus on detecting communities alone, they do not consider the collective influences of users in these communities on other user nodes in social networks. Inspired by this, in this paper, we investigate the influence propagation from some seed communities and their influential effects that result in the influenced communities. We propose a novel problem, named Top-L most Influential Community DEtection ( \\text{Top}L\n-ICDE) over social networks, which aims to retrieve top- L\nseed communities with the highest influences, having high structural cohesiveness, and containing user-specified query keywords. To efficiently tackle the \\text{Top}L\n-ICDE problem, we design effective pruning strategies to filter out false alarms of seed communities and propose an effective index mechanism to facilitate efficient Top- L\ncommunity retrieval. We develop an efficient \\text{Top}L\n-ICDE answering algorithm by traversing the index and applying our proposed pruning strategies. We also formulate and tackle a variant of \\text{Top}L\n-ICDE, named diversified top-L most influential community detection ( \\text{Top}L\n-ICDE), which returns a set of L\ndiversified communities with the highest diversity score (i.e., collaborative influences by L\ncommunities). We prove that \\text{DTop}L\n-ICDE is NP-hard, and propose an efficient greedy algorithm with our designed diversity score pruning. Through extensive experiments, we verify the efficiency and effectiveness of our proposed \\text{Top}L\n-ICDE and \\text{DTop}L\n-ICDE approaches over real/synthetic social networks under various parameter settings.}
}
