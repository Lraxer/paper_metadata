@article{DBLP:journals/pacmnet/MelliaSQT25,
	author = {Marco Mellia and
                  Peter Steenkiste and
                  Ihsan Ayyub Qazi and
                  Gareth Tyson},
	title = {{PACMNET} V3, N1, March 2025 Editorial},
	journal = {{PACMNET}},
	volume = {3},
	number = {CoNEXT1},
	pages = {1:1},
	year = {2025},
	url = {https://doi.org/10.1145/3709375},
	doi = {10.1145/3709375},
	timestamp = {Tue, 01 Apr 2025 19:03:21 +0200},
	biburl = {https://dblp.org/rec/journals/pacmnet/MelliaSQT25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Proceedings of the ACM on Networking (PACMNET) series showcases top-tier research in emerging computer networks and their applications. We welcome submissions introducing new technologies, innovative experiments, creative applications of networking technologies, and fresh insights gained through analysis. Supported by the ACM Special Interest Group on Communications and Computer Networks (SIGCOMM), the journal is backed by a distinguished Editorial Board composed of leading researchers in the field. This issue begins the third volume of PACMNET. It features 6 articles, all submitted by the June 2024 deadline when 121 submissions in total were received. Each submission underwent a thorough review process involving over 80 Editors, coordinated by two Associate Editors. In the initial phase, every article received a minimum of three reviews. Following an online discussion, roughly half of the submissions were rejected, while the other half advanced to a second review phase. In this phase, Editors produced at least two additional reviews per article. After further discussion and remote Editors' meeting, 8 articles were given one-shot major revision. The same Editors reviewed the revised version the Authors prepared, and 6 out of 8 articles were finally selected. These 6 articles appear in this issue. Topics include network support for large language models and deep learning, security, and wireless networking. All papers include a thorough set of experiments to validate the proposed solutions. From a methodological perspective, machine learning and artificial intelligence-based solutions are becoming central in developing novel networking solutions. We want to express our gratitude to all those who contributed to this issue of PACMNET, especially the Authors for submitting their finest work and the Associate Editors for offering valuable feedback in their reviews and engaging in the discussions. Our thanks also go to the SIGCOMM Executive Committee Chair and the CoNEXT Steering Committee members for their continued support and guidance, providing essential suggestions and insights throughout the article selection process.}
}


@article{DBLP:journals/pacmnet/GeMGFMPS25,
	author = {Changhan Ge and
                  Ajay Mahimkar and
                  Zihui Ge and
                  Romeo Fernandez and
                  Joseph Maniaci and
                  Shomik Pathak and
                  Maulik Shah},
	title = {Iridescence: Improving Configuration Tuning in the Presence of Confounders
                  for 5G {NSA} Networks},
	journal = {{PACMNET}},
	volume = {3},
	number = {CoNEXT1},
	pages = {2:1--2:22},
	year = {2025},
	url = {https://doi.org/10.1145/3709378},
	doi = {10.1145/3709378},
	timestamp = {Tue, 01 Apr 2025 19:03:20 +0200},
	biburl = {https://dblp.org/rec/journals/pacmnet/GeMGFMPS25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Configuration tuning is one of the top network operational tasks for Cellular Service Providers (CSPs), and is typically done to either restore performance during degraded network conditions such as congestion, failure, planned upgrades, or optimize service performance through change trials. A long-standing challenge in tuning has been to associate a causal relationship between a configuration change and a service performance impact. Confounders (or, external factors) make this extremely hard. In this paper, we focus on improving configuration tuning in the presence of confounders for 5G Non-standalone (NSA) networks. We propose a new solution Iridescence that uses advanced machine learning techniques such as XGBoost or transformers to first de-confound the performance impacts, and then improve the impact classification process for configuration tuning. We thoroughly evaluate Iridescence using a very large data set collected from an operational 5G NSA network. We share our findings with network engineering and operations teams and confirm the configuration changes that have high likelihood of improving the 5G NSA performance. Our preliminary trials demonstrate that Iridescence can achieve performance improvements in operational 5G networks.}
}


@article{DBLP:journals/pacmnet/GandhiN25,
	author = {Rohan Gandhi and
                  Srinivas Narayana},
	title = {KnapsackLB: Enabling Performance-Aware Layer-4 Load Balancing},
	journal = {{PACMNET}},
	volume = {3},
	number = {CoNEXT1},
	pages = {3:1--3:20},
	year = {2025},
	url = {https://doi.org/10.1145/3709377},
	doi = {10.1145/3709377},
	timestamp = {Sat, 15 Nov 2025 13:53:54 +0100},
	biburl = {https://dblp.org/rec/journals/pacmnet/GandhiN25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The layer-4 load balancer (LB) is one of the key building blocks of online services. In this paper, we empower such LBs to adapt to different and dynamic performance of backend instances (DIPs). Our system, KnapsackLB, is generic (can work with variety of LBs), does not require agents on DIPs, LBs or clients, and scales to large numbers of DIPs. KnapsackLB uses judicious active probes to learn a mapping from LB weights to the response latency of each DIP, and then applies Integer Linear Programming (ILP) to calculate LB weights that optimize latency, using an iterative method to scale the computation to large numbers of DIPs. Using testbed experiments and simulations, we show that KnapsackLB load balances traffic according to DIP performance and cuts average latency by up to 45% compared to existing designs.}
}


@article{DBLP:journals/pacmnet/KulkarniDCAASF25,
	author = {Umakant Kulkarni and
                  Khaled Diab and
                  Lianjie Cao and
                  Faraz Ahmed and
                  Shivang Aggarwal and
                  Puneet Sharma and
                  Sonia Fahmy},
	title = {Maestro: QoE-Aware Dynamic Resource Allocation in Wi-Fi Networks},
	journal = {{PACMNET}},
	volume = {3},
	number = {CoNEXT1},
	pages = {4:1--4:24},
	year = {2025},
	url = {https://doi.org/10.1145/3709371},
	doi = {10.1145/3709371},
	timestamp = {Tue, 15 Apr 2025 16:04:33 +0200},
	biburl = {https://dblp.org/rec/journals/pacmnet/KulkarniDCAASF25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Wi-Fi is an integral part of today's Internet infrastructure, enabling a diverse range of applications and services. Prior approaches to Wi-Fi resource allocation optimized Quality of Service (QoS) metrics, which often do not accurately reflect the user's Quality of Experience (QoE). To address the gap between QoS and QoE, we introduce Maestro, an adaptive method that formulates the Wi-Fi resource allocation problem as a partially observable Markov decision process (PO-MDP) to maximize the overall system QoE and QoE fairness. Maestro estimates QoE without using any application or client data; instead, it treats them as black boxes and leverages temporal dependencies in network telemetry data. Maestro dynamically adjusts policies to handle different classes of applications and variable network conditions. Additionally, Maestro uses a simulation environment for practical training. We evaluate Maestro in an enterprise-level Wi-Fi testbed with a variety of applications, and find that Maestro achieves up to 25× and 78% improvement in QoE and fairness, respectively, compared to the widely-deployed Wi-Fi Multimedia (WMM) policy. Compared to the state-of-the-art learning approach QFlow, Maestro increases QoE by up to 69%. Unlike QFlow which requires modifications to clients, we demonstrate that Maestro improves QoE of popular over-the-top services with unseen traffic without control over clients or servers.}
}


@article{DBLP:journals/pacmnet/LiuDA0X25,
	author = {Chenyi Liu and
                  Haotian Deng and
                  Vaneet Aggarwal and
                  Yuan Yang and
                  Mingwei Xu},
	title = {Shooting Large-scale Traffic Engineering by Combining Deep Learning
                  and Optimization Approach},
	journal = {{PACMNET}},
	volume = {3},
	number = {CoNEXT1},
	pages = {5:1--5:21},
	year = {2025},
	url = {https://doi.org/10.1145/3709372},
	doi = {10.1145/3709372},
	timestamp = {Sun, 07 Dec 2025 22:16:41 +0100},
	biburl = {https://dblp.org/rec/journals/pacmnet/LiuDA0X25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The rapid growth of global modern wide area networks has posed significant challenges to traffic engineering (TE). Existing TE methods often struggle to balance optimality with tractability, while recent machine learning based approaches fail to develop reliable strategies across diverse network scenarios. To address these issues, we introduce LO-TE, a novel TE solution integrating deep Learning and Optimization techniques. LO-TE operates in two phases: obtaining an initial solution and refining it to achieve a near-optimal TE solution. Our approach utilizes a scalable graph attention network for finding the necessary flows for refinement, paired with a refining algorithm based on linear programming. We demonstrate the application of LO-TE on three typical TE problems. We evaluate LO-TE on both real-world and self-generated large-scale topologies, demonstrating its strong generalizability across various TE problems and traffic models. The evaluation results indicate that LO-TE is 12x-188x faster than traditional TE optimization methods on large-scale network topologies, with an average performance gap of less than 6% compared to the optimal solution. Moreover, LO-TE outperforms state-of-the-art deep learning-based TE methods using limited training data, achieving only 1.8%-69% maximum link utilization under dynamic traffic conditions.}
}


@article{DBLP:journals/pacmnet/KuzniarK025,
	author = {Carson Kuzniar and
                  Hyojoon Kim and
                  Israat Haque},
	title = {Spotlight: Shining a Light on Pivot Attacks Using In-network Computing},
	journal = {{PACMNET}},
	volume = {3},
	number = {CoNEXT1},
	pages = {6:1--6:18},
	year = {2025},
	url = {https://doi.org/10.1145/3709373},
	doi = {10.1145/3709373},
	timestamp = {Tue, 01 Apr 2025 19:03:21 +0200},
	biburl = {https://dblp.org/rec/journals/pacmnet/KuzniarK025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Pivoting remains an economical and practical penetration method as it allows a malevolent actor to obtain access to a private network through compromised devices. There are various tools both on the web and native to many operating systems, making pivoting simple to execute, even with limited system access. Preventing these attacks is traditionally performed with detection software running on end hosts or with perimeter devices, e.g., firewalls. However, not all end-host devices are under administrator control, and attackers can work around defences using SSH tunnels or obscuring their IP addresses. Rather than relying on middleboxes or end hosts, we leverage a programmable data plane for both their unique vantage point and traffic processing capabilities. Our system makes no assumptions about the underlying traffic and requires no cooperation from end hosts. We showcase Spotlight, a P4-based system that reliably intercepts pivoting attacks while raising only a small number of alarms. We develop a prototype system and demonstrate its effectiveness against various attacks on real-world traces.}
}


@article{DBLP:journals/pacmnet/ThiagarajanCB25,
	author = {Kedar Thiagarajan and
                  Esteban Carisimo and
                  Fabi{\'{a}}n E. Bustamante},
	title = {The Aleph: Decoding Geographic Information from {DNS} {PTR} Records
                  Using Large Language Models},
	journal = {{PACMNET}},
	volume = {3},
	number = {CoNEXT1},
	pages = {7:1--7:20},
	year = {2025},
	url = {https://doi.org/10.1145/3709374},
	doi = {10.1145/3709374},
	timestamp = {Tue, 01 Apr 2025 19:03:21 +0200},
	biburl = {https://dblp.org/rec/journals/pacmnet/ThiagarajanCB25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Geolocating network devices is essential for various research areas. Yet, despite notable advancements, it continues to be one of the most challenging issues for experimentalists. An approach for geolocating that has proved effective is leveraging geolocating hints in PTR records associated with network devices. Extracting and interpreting geo-hints from PTR records is challenging because the labels are primarily intended for human interpretation rather than computational processing. Additionally, a lack of standardization across operators -- and even within a single operator, due to factors like rebranding, mergers, and acquisitions -- complicates the process. We argue that Large Language Models (LLMs), rather than humans, are better equipped to identify patterns in DNS PTR records, and significantly scale the coverage of tools like Hoiho. We introduce  The Aleph,  an approach and system for network device geolocation that utilizes information embedded in PTR records.  The Aleph  leverages LLMs to classify PTR records, generate regular expressions for these classes, and establish hint-to-location mapping per operator. We present results showing the applicability of using LLMs as a scalable approach to leverage PTR records for infrastructure geolocation.}
}


@article{DBLP:journals/pacmnet/SattlerZHGVCJ25,
	author = {Patrick Sattler and
                  Johannes Zirngibl and
                  Fahad Hilal and
                  Oliver Gasser and
                  Kevin Vermeulen and
                  Georg Carle and
                  Mattijs Jonker},
	title = {ECSeptional {DNS} Data: Evaluating Nameserver {ECS} Deployments with
                  Response-Aware Scanning},
	journal = {Proc. {ACM} Netw.},
	volume = {3},
	number = {CoNEXT2},
	pages = {1--25},
	year = {2025},
	url = {https://doi.org/10.1145/3730977},
	doi = {10.1145/3730977},
	timestamp = {Fri, 26 Dec 2025 20:52:15 +0100},
	biburl = {https://dblp.org/rec/journals/pacmnet/SattlerZHGVCJ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {DNS is one of the cornerstones of the Internet. Nowadays, a substantial fraction of DNS queries are handled by public resolvers (e.g., Google Public DNS and Cisco's OpenDNS) rather than ISP nameservers. This behavior makes it difficult for authoritative nameservers to provide answers based on the requesting resolver. The impact is especially important for entities that make client origin inferences to perform DNS-based load balancing (e.g., CDNS). The EDNS0 Client Subnet (ECS) option adds the client's IP prefix to DNS queries, which allows authoritative nameservers to provide prefix-based responses. Previous work showed the potential of data collected during ECS scans. Infrastructure can be uncovered, and operators' subnet-specific behavior can be observed. In this study, we introduce a new method for conducting ECS scans. Our method significantly reduces the required number of queries by up to 97% compared to state-of-the-art techniques and allows us to provide new insights into ECS behavior. Our approach is also the first to facilitate ECS scans for IPv6. Due to its vast address space, we have developed and analyzed different IPv6 scanning approaches. We conduct a comprehensive evaluation of the ECS landscape, examining the usage and implementation of ECS across various services. Overall, 53% of all nameservers support prefix-based responses. Furthermore, we find that Google nameservers do not comply with the Google Public DNS guidelines. Additionally, we observe that certain operators (e.g., AWS Route53) exclusively employ a single specific scope prefix length without aggregation, potentially affecting resolver cache efficiency. Lastly, we make our tool and data publicly available to foster further research in the area.}
}


@article{DBLP:journals/pacmnet/FengDGBBK25,
	author = {Yufei Feng and
                  Phuc Dinh and
                  Moinak Ghoshal and
                  Eduardo Baena and
                  Hamza Bouchebbah and
                  Dimitrios Koutsonikolas},
	title = {Vivisecting Beam Management in Operational 5G mmWave Networks},
	journal = {Proc. {ACM} Netw.},
	volume = {3},
	number = {CoNEXT2},
	pages = {1--26},
	year = {2025},
	url = {https://doi.org/10.1145/3730982},
	doi = {10.1145/3730982},
	timestamp = {Fri, 26 Dec 2025 20:52:15 +0100},
	biburl = {https://dblp.org/rec/journals/pacmnet/FengDGBBK25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Beam management plays a fundamental role in 5G mmWave networks, due to the highly directional nature of mmWave signals. Despite its importance, beam management procedures and real-world performance in operational deployments remain underexplored. This paper addresses this gap by presenting the first in-depth empirical study of beam management procedures in commercial 5G mmWave networks. Our study is based on an extensive measurement campaign across two major US operators, covering six cities, different base station types, and varying mobility scenarios, including walking and driving. We evaluate key beam management parameters on both the base station and the user equipment side, assessing their impact on network performance. In addition, we examine the interaction between beam management and two other mechanisms critical to performance, rate adaptation and carrier aggregation. Finally, we quantify the beamforming overhead and analyze the effectiveness of beam tracking. Our findings provide novel insights into the real-world performance of beam management in 5G mmWave networks, offering guidance for further optimization.}
}


@article{DBLP:journals/pacmnet/SchmidSFV25,
	author = {Roland Schmid and
                  Tibor Schneider and
                  Georgia Fragkouli and
                  Laurent Vanbever},
	title = {Transient Forwarding Anomalies and How to Find Them},
	journal = {Proc. {ACM} Netw.},
	volume = {3},
	number = {CoNEXT2},
	pages = {1--23},
	year = {2025},
	url = {https://doi.org/10.1145/3730973},
	doi = {10.1145/3730973},
	timestamp = {Fri, 26 Dec 2025 20:52:15 +0100},
	biburl = {https://dblp.org/rec/journals/pacmnet/SchmidSFV25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Analyzing transient violations of reachability---that happen while routing protocols are re-converging---helps in improving network availability and offering more precise SLAs. The key challenge is analyzing transient violations accurately, as they can be short-lived, for all affected prefix destinations, and practically, without worsening the network's performance. Existing approaches fail to address at least one of these goals: measurement approaches are accurate but only for the prefixes they can probe or observe traffic for, while techniques that estimate the convergence time use the same crude proxy for all prefixes. To achieve all three goals, we present TRIX, a system that infers transient violation times for BGP events from logged routing events or collected BGP messages. TRIX' key insight is that we do not need to probe all destinations if we use available information to infer the router-local forwarding state, for all destinations, and reconstruct the network-wide violations from router-level state. However, the logged events contain control-plane information that is inaccurate in terms of the content and the times of the forwarding updates, while reconstructing network-wide violations requires reasoning about the flow of traffic through the network. TRIX solves these challenges by simulating the BGP control-plane, modeling the FIB-update rate, and combining the state across routers with propagation delays. To evaluate TRIX, we implement a testbed that relies on a programmable switch and uses 12 real routers. Our evaluation shows that TRIX' inferred reachability violation times are on average within 13--25ms from the ground truth, and inference scales to large networks.}
}


@article{DBLP:journals/pacmnet/TyunyayevDEB25,
	author = {Nikita Tyunyayev and
                  Cl{\'{e}}ment Delzotti and
                  Haggai Eran and
                  Tom Barbette},
	title = {{ASNI:} Redefining the Interface Between SmartNICs and Applications},
	journal = {Proc. {ACM} Netw.},
	volume = {3},
	number = {CoNEXT2},
	pages = {1--22},
	year = {2025},
	url = {https://doi.org/10.1145/3730966},
	doi = {10.1145/3730966},
	timestamp = {Fri, 26 Dec 2025 20:52:15 +0100},
	biburl = {https://dblp.org/rec/journals/pacmnet/TyunyayevDEB25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With a budget of 300 CPU cycles per packet, Network Functions Virtualisation (NFV) scenarios require efficient packet exchange mechanisms between NICs and CPUs. However, even the latest kernel bypass techniques, such as DPDK, can eat up 20% of the budget. This paper investigates the strain on CPUs due to escalating network speeds and the ability to exchange more packet metadata due to NICs becoming more feature-fledged and ''Smart''. We advocate for NICs to adapt to software needs rather than rely on drivers as translators. We analyze different applications and compare multiple packet buffers and data organization models. We then develop an API for the datapath that will compile into different buffer management models according to the application's needs. Introducing ASNI, we explore the potential to tailor packet descriptors for different applications, offloading the driver's work from the datapath so that the application receives the packets precisely as it needs them. We advocate for a vision where only a minimal driver on the host is required, retrieving CPU cycles to applications instead. We propose a prototype implementation on NVIDIA BlueField-3 SoC. Evaluated in multiple NFV scenarios, it manages to serve 2.2x more traffic under the same loss ratio constraints than state-of-the-art solutions.}
}


@article{DBLP:journals/pacmnet/KempfTJSCZ25,
	author = {Marcel Kempf and
                  Simon Tietz and
                  Benedikt Jaeger and
                  Johannes Sp{\"{a}}th and
                  Georg Carle and
                  Johannes Zirngibl},
	title = {{QUIC} Steps: Evaluating Pacing Strategies in {QUIC} Implementations},
	journal = {Proc. {ACM} Netw.},
	volume = {3},
	number = {CoNEXT2},
	pages = {1--14},
	year = {2025},
	url = {https://doi.org/10.1145/3730985},
	doi = {10.1145/3730985},
	timestamp = {Wed, 24 Dec 2025 10:44:50 +0100},
	biburl = {https://dblp.org/rec/journals/pacmnet/KempfTJSCZ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Pacing is a key mechanism in modern transport protocols, used to regulate packet transmission timing to minimize traffic burstiness, lower latency, and reduce packet loss. Standardized in 2021, QUIC is a UDP-based protocol designed to improve upon the TCP / TLS stack. While the QUIC protocol recommends pacing, and congestion control algorithms like BBR rely on it, the user-space nature of QUIC introduces unique challenges. These challenges include coarse-grained timers, system call overhead, and OS scheduling delays, all of which complicate precise packet pacing. This paper investigates how pacing is implemented differently across QUIC stacks, including quiche, picoquic, and ngtcp2, and evaluates the impact of system-level features like GSO and Linux qdiscs on pacing. Using a custom measurement framework and a passive optical fiber tap, we establish a baseline with default settings and systematically explore the effects of qdiscs, hardware offloading using the ETF qdisc, and GSO on pacing precision and network performance. We also extend and evaluate a kernel patch to enable pacing of individual packets within GSO buffers, combining batching efficiency with precise pacing. Kernel-assisted and purely user-space pacing approaches are compared. We show that pacing with only user-space timers can work well, as demonstrated by picoquic with BBR. With quiche, we identify FQ as a qdisc well-suited for pacing QUIC traffic, as it is relatively easy to use and offers precise pacing based on packet timestamps. We uncovered that internal mechanisms, such as a library's spurious loss detection logic or algorithms such as HyStart++, can interfere with pacing and cause issues like unstable congestion windows and increased packet loss. Our findings provide new insights into the trade-offs involved in implementing pacing in QUIC and highlight potential optimizations for real-world applications like video streaming and video calls.}
}


@article{DBLP:journals/pacmnet/MelliaLZ25,
	author = {Marco Mellia and
                  Andra Lutu and
                  Ying Zhang},
	title = {{PACMNET} V3, N2, June 2025 Editorial},
	journal = {Proc. {ACM} Netw.},
	volume = {3},
	number = {CoNEXT2},
	pages = {1},
	year = {2025},
	url = {https://doi.org/10.1145/3730981},
	doi = {10.1145/3730981},
	timestamp = {Fri, 26 Dec 2025 20:52:15 +0100},
	biburl = {https://dblp.org/rec/journals/pacmnet/MelliaLZ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Proceedings of the ACM on Networking (PACMNET) series showcases top-tier research in emerging computer networks and their applications. We welcome submissions introducing new technologies, innovative experiments, creative applications of networking technologies, and fresh insights gained through analysis. Supported by the ACM Special Interest Group on Communications and Computer Networks (SIGCOMM), the journal is backed by a distinguished Editorial Board composed of leading researchers in the field.}
}


@article{DBLP:journals/pacmnet/EgloffHKSW25,
	author = {Isabell Egloff and
                  Raphael Hiesgen and
                  Maynard Koch and
                  Thomas C. Schmidt and
                  Matthias W{\"{a}}hlisch},
	title = {A Detailed Measurement View on IPv6 Scanners and Their Adaption to
                  {BGP} Signals},
	journal = {Proc. {ACM} Netw.},
	volume = {3},
	number = {CoNEXT3},
	pages = {1--23},
	year = {2025},
	url = {https://doi.org/10.1145/3749215},
	doi = {10.1145/3749215},
	timestamp = {Fri, 26 Dec 2025 20:52:15 +0100},
	biburl = {https://dblp.org/rec/journals/pacmnet/EgloffHKSW25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Scanners are daily visitors of public IPv4 hosts. Scanning IPv6 nodes successfully is still a challenge, which an increasing crowd of actors tries to master. In this paper, we analyze IPv6 scanning under various network conditions to disclose the impact on scanning. We deploy four IPv6 network telescopes, including a reactive /48 telescope and a proactive /32 telescope that is periodically reconfigured by changing BGP announcements. We provide a longitudinal study of eleven months and classify the observed scanners w.r.t. their temporal behavior, their target and network selection strategies, as well as their individual tools, fingerprints, and correlations across categories. We find that silent subnets of larger covering prefixes remain mainly invisible, whereas BGP prefix announcements quickly attract attention by scanners. Based on our findings, we derive operational guidance on how to deploy network telescopes to increase visibility for IPv6 scanners and understand corresponding biases.}
}


@article{DBLP:journals/pacmnet/RimlingerFFV25,
	author = {Hugo Rimlinger and
                  Olivier Fourmaux and
                  Timur Friedman and
                  Kevin Vermeulen},
	title = {GeoResolver: An Accurate, Scalable, and Explainable Geolocation Technique
                  Using {DNS} Redirection},
	journal = {Proc. {ACM} Netw.},
	volume = {3},
	number = {CoNEXT3},
	pages = {1--21},
	year = {2025},
	url = {https://doi.org/10.1145/3749219},
	doi = {10.1145/3749219},
	timestamp = {Fri, 26 Dec 2025 20:52:15 +0100},
	biburl = {https://dblp.org/rec/journals/pacmnet/RimlingerFFV25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Obtaining an accurate, explainable and Internet scale IP geolocation dataset has been a longstanding goal of the research community. Despite decades of research on IP geolocation, no current technique can provide such a dataset. In particular, latency-based geolocation techniques do not scale, because, on one hand, we have thousands of available vantage points to perform measurements, but on the other hand, we have no way to select the right ones for each IP address. In this paper, we present GeoResolver, which is a serious step towards our goal, by using the idea that when multiple operators redirect two prefixes to the same servers, these prefixes should be close to each other. With this intuition, we define a methodology to measure and compare the redirection of prefixes to servers using ECS DNS measurements, and select the prefixes with the smallest redirection distance to a target prefix to issue the latency measurements to targets in that prefix. GeoResolver performs nearly as well as a brute force approach, geolocating 94% of the targets that could actually be geolocated at metro level, while using 4.3% of the probing budget compared to the state of the art. On the Internet scale CAIDA ITDK dataset, GeoResolver geolocates 16% of the IP addresses at metro level, 3.4 times more than the state of the art. In addition, GeoResolver is robust to public resolvers or hypergiants stopping supporting ECS.}
}


@article{DBLP:journals/pacmnet/KimBHKPL25,
	author = {Heewon Kim and
                  Chanbin Bae and
                  Junkyu Hong and
                  Haneul Ko and
                  Sangheon Pack and
                  Dongjin Lee},
	title = {{FAT-INT:} Frequency-Aware and Item-Wise In-band Network Telemetry
                  for Low-Overhead and Accurate Measurement},
	journal = {Proc. {ACM} Netw.},
	volume = {3},
	number = {CoNEXT3},
	pages = {1--23},
	year = {2025},
	url = {https://doi.org/10.1145/3749218},
	doi = {10.1145/3749218},
	timestamp = {Fri, 26 Dec 2025 20:52:15 +0100},
	biburl = {https://dblp.org/rec/journals/pacmnet/KimBHKPL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In-band network telemetry (INT) is a promising technique to investigate the real-time state of networks. However, it inevitably generates a considerable transmission overhead due to the operational feature of directly inserting telemetry data into the packet header. One of the widely used methods to alleviate such overhead is sampling, which requires a careful selection of sampling rates to control the trade-off between the monitoring accuracy and the transmission overhead. Meanwhile, INT needs to collect various kinds of telemetry items with varying frequency characteristics, leading to different sampling rates to satisfy the desired monitoring accuracy. To address these issues, we propose a frequency-aware item-wise INT (FAT-INT) scheme, which uses a novel approach to consider the frequency characteristics of each telemetry item. To this end, we first design a frequency analysis method that examines the frequency characteristics and decides a proper sampling rate for each item. To reflect different sampling rates of each telemetry item, we devise an item-wise probabilistic sampling mechanism to collect items individually considering different sampling rates. Experimental results demonstrate that FAT-INT can reduce transmission overhead by up to 57.6% of the state of the art, while achieving comparable and robust monitoring accuracy under dynamic network environments.}
}


@article{DBLP:journals/pacmnet/MostafaeiECSRB25,
	author = {Habib Mostafaei and
                  Mohammad Ezzati and
                  Pieter J. L. Cuijpers and
                  Stefan Schmid and
                  G{\'{a}}bor R{\'{e}}tv{\'{a}}ri and
                  Sem C. Borst},
	title = {Exp-PIFO: Scalable and Efficient Programmable Packet Scheduling},
	journal = {Proc. {ACM} Netw.},
	volume = {3},
	number = {CoNEXT3},
	pages = {1--20},
	year = {2025},
	url = {https://doi.org/10.1145/3749217},
	doi = {10.1145/3749217},
	timestamp = {Fri, 26 Dec 2025 20:52:15 +0100},
	biburl = {https://dblp.org/rec/journals/pacmnet/MostafaeiECSRB25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Programmable packet schedulers provide great flexibility in the ordering of packet transmission. They allow network operators to optimize crucial performance metrics, such as Flow Completion Time (FCT), using strategies that adapt to changes in the characteristics of incoming traffic. A challenge in programming these devices is that they are severely limited in registers, memory, and control flow operations. The popular scheduling strategy Push-In First-Out (PIFO), for example, cannot be straightforwardly implemented because it relies on sorting packets, which is difficult to implement at line speed on current hardware. Fixed-priority approximations of PIFO, like SP-PIFO and AIFO, do have hardware implementations but generally still do not scale well in, for example, the number of memory cells being used. This paper introduces a new PIFO approximation strategy, Exp-PIFO, which prioritizes packets based on adaptive exponential prioritization criteria, called exponential bins. Exp-PIFO approximates the behavior of PIFO using only two memory cells to keep track of its state and uses a lookup table to avoid a complex control flow. We initially expected our improvement in memory and computation to come at a cost w.r.t. FCT performance compared to PIFO and its existing approximations. However, our empirical evaluation shows that Exp-PIFO sometimes even outperforms strict PIFO. We provide an explanation for this behavior and demonstrate the practical feasibility of Exp-PIFO through a proof-of-concept implementation on an Intel Tofino switch, which uses significantly less memory than comparable implementations of SP-PIFO and AIFO.}
}


@article{DBLP:journals/pacmnet/BufalinoMFA25,
	author = {Jacopo Bufalino and
                  Jose Luis Martin{-}Navarro and
                  Mario Di Francesco and
                  Tuomas Aura},
	title = {Inside Job: Defending Kubernetes Clusters Against Network Misconfigurations},
	journal = {Proc. {ACM} Netw.},
	volume = {3},
	number = {CoNEXT3},
	pages = {1--25},
	year = {2025},
	url = {https://doi.org/10.1145/3749220},
	doi = {10.1145/3749220},
	timestamp = {Fri, 26 Dec 2025 20:52:15 +0100},
	biburl = {https://dblp.org/rec/journals/pacmnet/BufalinoMFA25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Kubernetes has emerged as the de facto standard for container orchestration. Unfortunately, its increasing popularity has also made it an attractive target for malicious actors. Despite extensive research on securing Kubernetes, little attention has been paid to the impact of network configuration on the security of application deployments. This paper addresses this gap by conducting a comprehensive analysis of network misconfigurations in a Kubernetes cluster with specific reference to lateral movement. Accordingly, we carried out an extensive evaluation of 287 open-source applications belonging to six different organizations, ranging from IT companies and public entities to non-profits. As a result, we identified 634 misconfigurations, well beyond what could be found by solutions in the state of the art. We responsibly disclosed our findings to the concerned organizations and engaged in a discussion to assess their severity. As of now, misconfigurations affecting more than thirty applications have been fixed with the mitigations we proposed.}
}


@article{DBLP:journals/pacmnet/MelliaZL25,
	author = {Marco Mellia and
                  Ying Zhang and
                  Andra Lutu},
	title = {{PACMNET} V3, N3, September 2025 Editorial},
	journal = {Proc. {ACM} Netw.},
	volume = {3},
	number = {CoNEXT3},
	pages = {1--2},
	year = {2025},
	url = {https://doi.org/10.1145/3749214},
	doi = {10.1145/3749214},
	timestamp = {Fri, 26 Dec 2025 20:52:15 +0100},
	biburl = {https://dblp.org/rec/journals/pacmnet/MelliaZL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Proceedings of the ACM on Networking (PACMNET) series showcases top-tier research in emerging computer networks and their applications. We welcome submissions introducing new technologies, innovative experiments, creative applications of networking technologies, and fresh insights gained through analysis. Supported by the ACM Special Interest Group on Communications and Computer Networks (SIGCOMM), the journal is backed by a distinguished Editorial Board composed of leading researchers in the field.}
}


@article{DBLP:journals/pacmnet/ShahinfarMPA25,
	author = {Farbod Shahinfar and
                  Sebastiano Miano and
                  Aurojit Panda and
                  Gianni Antichi},
	title = {Demystifying Performance of eBPF Network Applications},
	journal = {Proc. {ACM} Netw.},
	volume = {3},
	number = {CoNEXT3},
	pages = {1--21},
	year = {2025},
	url = {https://doi.org/10.1145/3749216},
	doi = {10.1145/3749216},
	timestamp = {Fri, 26 Dec 2025 20:52:15 +0100},
	biburl = {https://dblp.org/rec/journals/pacmnet/ShahinfarMPA25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recently, eBPF has emerged as the latest answer to how we should accelerate networked applications. In this paper we ask can all networked applications benefit from eBPF? We answer this question by running several benchmarks under different workloads and by designing different test cases. Our results show that in reality many networked applications cannot benefit from eBPF, and worse the use of eBPF can limit how applications are deployed (because eBPF can lead to performance isolation violations) and the workloads they can handle. We then discuss whether ongoing work can fix the limitations we identify, and propose directions that the community might want to focus on.}
}


@article{DBLP:journals/pacmnet/TanveerCMKRGRBC25,
	author = {Hammas Bin Tanveer and
                  Echo Chan and
                  Ricky K. P. Mok and
                  Sebastian Kappes and
                  Philipp Richter and
                  Oliver Gasser and
                  John Ronan and
                  Arthur W. Berger and
                  K. C. Claffy},
	title = {Unveiling IPv6 Scanning Dynamics: {A} Longitudinal Study Using Large
                  Scale Proactive and Passive IPv6 Telescopes},
	journal = {Proc. {ACM} Netw.},
	volume = {3},
	number = {CoNEXT3},
	pages = {1--24},
	year = {2025},
	url = {https://doi.org/10.1145/3749221},
	doi = {10.1145/3749221},
	timestamp = {Fri, 26 Dec 2025 20:52:15 +0100},
	biburl = {https://dblp.org/rec/journals/pacmnet/TanveerCMKRGRBC25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We introduce new tools and vantage points to develop and integrate proactive techniques to attract IPv6 scan traffic, thus enabling its analysis. By deploying the largest-ever IPv6 proactive telescope in a production ISP network, we collected over 600M packets of unsolicited traffic from 1.9k Autonomous Systems in 10 months. We characterized the sources of unsolicited traffic, evaluated the effectiveness of five major features across the network stack, and inferred scanners' sources of target addresses and their strategies.}
}


@article{DBLP:journals/pacmnet/WestMJM25,
	author = {Ryan W. West and
                  Dustin Maas and
                  David Johnson and
                  Jacobus E. van der Merwe},
	title = {SpectraCert: {A} Hierarchical System for Dynamic Spectrum License
                  Enforcement},
	journal = {Proc. {ACM} Netw.},
	volume = {3},
	number = {CoNEXT4},
	pages = {1--18},
	year = {2025},
	url = {https://doi.org/10.1145/3768980},
	doi = {10.1145/3768980},
	timestamp = {Fri, 26 Dec 2025 20:52:15 +0100},
	biburl = {https://dblp.org/rec/journals/pacmnet/WestMJM25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {While various spectrum sharing approaches aim to remedy the spectrum crunch and improve spectral utilization, they typically support only radios that are certified for and physically locked down to a single frequency band and power configuration. This limits their utility and re-usability as they do not support flexible license changes post-production, but there is generally no alternative  dynamic  technical license enforcement mechanism suitable for more flexible SDRs (Software-Defined Radios). This limits the utility of SDRs: SDR operators must use unlicensed bands, or obtain special permission from the FCC via a manual process. Further, they are subject to fines if they operate outside these bounds and/or interfere with other spectrum users. In response, we present SpectraCert--a dynamic, PKI-based (Public Key Infrastructure) system that enables safe, multi-faceted spectrum sharing while simultaneously enforcing license-holder rights directly within flexible transmitting radios. Entities receive specific frequency transmission rights from government authorities or other Spectrum-Authorized Entities (SAEs) through a  spectracert  : a certificate that specifies allowed frequencies and all required transmission conditions, such as allowed times, geographic areas, maximum transmit powers, expirations and more. Child spectracerts are derived from other spectracerts and have increasingly limited transmission rights, and  trusted modules  (TMs) within radios validate spectracert authenticity to ensure the rights defined by each parental spectracert are legal and not revoked. TMs only allow transmission according to validated spectracerts and control radio configurations. Spectracerts can also be used to verify SAE attestations of spectrum interference or occupancy reports. We implement a prototype of the SpectraCert system that automatically revokes or replaces spectracerts across SAE hierarchies when license updates occur, describe an integration with the OpenZMS spectrum management system, and evaluate how SpectraCert uniquely protects license rights while simultaneously allowing for more diverse, accessible spectrum sharing methods.}
}


@article{DBLP:journals/pacmnet/ShafieiradSBMLDSWZG25,
	author = {Hossein Shafieirad and
                  Amir Shani and
                  Manaf Bin{-}Yahya and
                  Seyed Hossein Mortazavi and
                  Geng Li and
                  Xinle Du and
                  Tao Su and
                  Wei Wang and
                  Jingbin Zhou and
                  Majid Ghaderi},
	title = {Harmonics: Scalable Collective Scheduling in Multi-Tenant {GPU} Clusters},
	journal = {Proc. {ACM} Netw.},
	volume = {3},
	number = {CoNEXT4},
	pages = {1--20},
	year = {2025},
	url = {https://doi.org/10.1145/3768985},
	doi = {10.1145/3768985},
	timestamp = {Fri, 26 Dec 2025 20:52:15 +0100},
	biburl = {https://dblp.org/rec/journals/pacmnet/ShafieiradSBMLDSWZG25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Distributed machine learning (DML), such as large language model (LLM) training, has become one of the most critical services in multi-tenant cloud computing. However, communication contention among concurrent DML jobs significantly degrades overall GPU utilization, leading to inefficient training cluster performance. Existing approaches either achieve high performance at the cost of long scheduling runtime or reduce scheduling time at the expense of poor performance. We present Harmonics, a novel two-tier scheduling framework that strikes a balance between scheduling latency and performance. It coordinates decisions between Local Schedulers and a lightweight Global Coordinator to enable scalable and adaptive scheduling. By combining rack-level epoch-based optimization with global coordination, Harmonics alleviates communication contention and improves resource efficiency. We implement and evaluate Harmonics on real distributed ML workloads running on a GPU testbed. Compared to state-of-the-art methods such as fair sharing, optimal scheduling, Crux, and Cassini, Harmonics reduces training time by up to 33% and communication time by up to 48%. Large-scale simulations show that it reduces scheduling time by up to 91× while improving training time by 26% in large-cluster settings.}
}


@article{DBLP:journals/pacmnet/YoonM25,
	author = {Wonsup Yoon and
                  Sue Moon},
	title = {Secure and Efficient {RDMA} {NIC} Cryptography Offloading for Memory
                  Disaggregation},
	journal = {Proc. {ACM} Netw.},
	volume = {3},
	number = {CoNEXT4},
	pages = {1--13},
	year = {2025},
	url = {https://doi.org/10.1145/3768991},
	doi = {10.1145/3768991},
	timestamp = {Wed, 24 Dec 2025 10:44:51 +0100},
	biburl = {https://dblp.org/rec/journals/pacmnet/YoonM25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Confidentiality and integrity are essential for secure communication. In RDMA-based systems, however, they are often neglected because security mechanisms impose significant performance overheads. In this work, we design a secure RDMA data path that ensures confidentiality and integrity by protecting data in transit and at the remote side using encryption and checksums. To reduce security overhead, our system offloads cryptographic operations to the RDMA NIC (RNIC). However, hardware limitations and relatively slow cryptography performance in RNICs make a secure and efficient design challenging. We address these challenges with three key techniques: dynamic key reconfiguration, configuration-data batching, and context pooling. We also conduct a case study with RDMA memory disaggregation systems to evaluate when offloading is beneficial. We find that naive offloading degrades performance and that overlapping CPU's computation with RNIC's cryptography is essential to realizing its benefits. Our evaluation shows that overlapping achieves up to 9.63x lower P99.9 latency than a CPU-based secure RDMA data path on RocksDB.}
}


@article{DBLP:journals/pacmnet/HassanYZFCZJLJMZQ25,
	author = {Ahmad Hassan and
                  Wei Ye and
                  Anlan Zhang and
                  Rostand A. K. Fezeu and
                  Jason Carpenter and
                  Ruiyang Zhu and
                  Shuowei Jin and
                  Myungjin Lee and
                  Akshay Jajoo and
                  Z. Morley Mao and
                  Zhi{-}Li Zhang and
                  Feng Qian},
	title = {{OPCM:} Opportunistic Performance-driven Connectivity Management for
                  5G/xG Networks},
	journal = {Proc. {ACM} Netw.},
	volume = {3},
	number = {CoNEXT4},
	pages = {1--23},
	year = {2025},
	url = {https://doi.org/10.1145/3768970},
	doi = {10.1145/3768970},
	timestamp = {Fri, 26 Dec 2025 20:52:15 +0100},
	biburl = {https://dblp.org/rec/journals/pacmnet/HassanYZFCZJLJMZQ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {5G and future 6G networks deploy cells with diverse combinations of access technologies, architectures, and radio frequency bands/channels. Cellular operators also employ carrier aggregation for higher data access speeds. We investigate the fundamental question of how to intelligently and dynamically configure and reconfigure a user equipment's serving cells to deliver the best network performance. Through comprehensive measurements across 12 cities in 5 countries, we experimentally show the wide availability, heterogeneity, and untapped performance gains of today's cell deployments. We then present a principled, performance-driven connectivity management framework, dubbed OPCM. It is a centralized solution deployed at the base station, allowing it to coordinate multiple UEs, enforce operator policies, and facilitate user fairness. Extensive evaluations show that OPCM improves the application QoE by up to 65.2%.}
}


@article{DBLP:journals/pacmnet/MazumderMBKP25,
	author = {Md. Mumtahin Habib Ullah Mazumder and
                  Frost Mitchell and
                  Aditya Bhaskara and
                  Sneha Kumar Kasera and
                  Neal Patwari},
	title = {Bridging Data Gaps: Enhancing Wireless Localization with Physics-Informed
                  Data Augmentation},
	journal = {Proc. {ACM} Netw.},
	volume = {3},
	number = {CoNEXT4},
	pages = {1--15},
	year = {2025},
	url = {https://doi.org/10.1145/3768995},
	doi = {10.1145/3768995},
	timestamp = {Fri, 26 Dec 2025 20:52:15 +0100},
	biburl = {https://dblp.org/rec/journals/pacmnet/MazumderMBKP25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Machine learning (ML) models have emerged as the state-of-the-art approach for wireless applications such as transmitter localization. One of the challenges for ML models, however, is their reliance on the abundance of high quality data. Specifically for localization, a significant challenge is to obtain training data that ''covers'' the entire landscape, in order to ensure a high accuracy for the ML approaches. This issue is compounded when trying to localize multiple transmitters. To address this problem, we introduce a new data augmentation pipeline, termed Physics-informed Augmentation and RF Modeling (PhARMNet), that can combine existing data with a physics-based simulation model, producing a larger dataset with an improved coverage of the landscape of interest. Our results show that PhARMNet offers significant advantages over traditional path loss models. For localization, we demonstrate that augmenting training data with PhARMNet-produced samples improves localization accuracy, particularly in out-of-distribution regions and multi-transmitter settings.}
}


@article{DBLP:journals/pacmnet/OkelmannMMB25,
	author = {Peter Okelmann and
                  Ilya Meignan{-}Masson and
                  Masanori Misono and
                  Pramod Bhatotia},
	title = {MorphOS: An Extensible Networked Operating System},
	journal = {Proc. {ACM} Netw.},
	volume = {3},
	number = {CoNEXT4},
	pages = {1--25},
	year = {2025},
	url = {https://doi.org/10.1145/3768977},
	doi = {10.1145/3768977},
	timestamp = {Fri, 26 Dec 2025 20:52:15 +0100},
	biburl = {https://dblp.org/rec/journals/pacmnet/OkelmannMMB25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper introduces MorphOS, a novel, extensible networked operating system that addresses the runtime inflexibility of unikernels for dynamic, stateful network-intensive applications like Virtual Network Functions (VNFs). While unikernels offer superior performance and minimal resource overheads, their traditional update mechanisms require costly rebuilds and restarts, leading to service disruption and state loss. MorphOS addresses this by integrating eBPF to enable dynamic, verified code execution for seamless updates to packet processing logic. It employs an out-of-band verification service to offload computationally intensive verification tasks and utilizes hardware-assisted memory isolation (Memory Protection Keys) for enhanced execution hardening. Our evaluation of MorphOS with four VNF implementations demonstrates significant benefits: MorphOS drastically reduces reconfiguration time, effectively amortizes verification costs, and achieves up to 3× better performance compared to Linux-based VNF deployments, all while preserving the inherent lightweightness of unikernels. MorphOS thus paves the way for adaptable, efficient, and state-preserving networked applications in cloud environments.}
}


@article{DBLP:journals/pacmnet/LiuRTV25,
	author = {Zikun Liu and
                  Fan{-}Xue Gabriella Reidys and
                  Sarah Tanveer and
                  Deepak Vasisht},
	title = {Vivisecting Starlink Throughput: Measurement and Prediction},
	journal = {Proc. {ACM} Netw.},
	volume = {3},
	number = {CoNEXT4},
	pages = {1--23},
	year = {2025},
	url = {https://doi.org/10.1145/3768971},
	doi = {10.1145/3768971},
	timestamp = {Fri, 26 Dec 2025 20:52:15 +0100},
	biburl = {https://dblp.org/rec/journals/pacmnet/LiuRTV25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Internet connectivity using low earth orbit (LEO) satellites is gaining significant traction, with nearly 3 million users worldwide. While these networks promise to provide universal broadband connectivity, they suffer from large throughput fluctuations over short time scales. We conduct an extensive evaluation of Starlink's throughput across three devices in different countries, with measurement durations ranging from one to six months. We identify various factors that cause throughput variations at varying timescales. Given our analysis, we design StarNet, a new learning-based throughput prediction system. StarNet incorporates satellite network-specific insights and accurately predicts future throughput for end users. We demonstrate that StarNet's accurate predictions can improve the experience of end user applications like video streaming.}
}


@article{DBLP:journals/pacmnet/JinKHL25,
	author = {Sunghyun Jin and
                  Serae Kim and
                  Sangtae Ha and
                  Kyunghan Lee},
	title = {End-to-End Coordination of {RAN} and Edge Server for Latency-Critical
                  Inference Serving over Cellular Networks},
	journal = {Proc. {ACM} Netw.},
	volume = {3},
	number = {CoNEXT4},
	pages = {1--23},
	year = {2025},
	url = {https://doi.org/10.1145/3768987},
	doi = {10.1145/3768987},
	timestamp = {Fri, 26 Dec 2025 20:52:15 +0100},
	biburl = {https://dblp.org/rec/journals/pacmnet/JinKHL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The growing adoption of deep neural network (DNN) inference in mobile applications underscores the need for edge-assisted inference to meet the latency requirements of diverse DNN tasks, given the constrained device capabilities. However, widespread deployment remains hindered by unreliable latency due to the shared nature of cellular networks, where concurrent workloads contend across uplink, computation, and downlink stages. Although several approaches have been proposed, they primarily target specific tasks (e.g., video analytics) and lack support for diverse DNN tasks due to their uplink-centric designs. This paper presents CORA, a system that serves latency-critical DNN inference requests through end-to-end coordination between the RAN and the edge server. CORA dynamically adjusts the latency budgets across stages based on each DNN task's characteristics, balancing resource demands for the radio and compute domains to mitigate contention at each stage. It then aligns the resource schedulers with these per-stage budgets, thereby enabling end-to-end coordination without requiring modifications to end hosts. We prototype and evaluate CORA on an over-the-air testbed with diverse DNN tasks. CORA serves 3.2× more requests within the latency target and reduces the 95th percentile latency by 2.1× compared to baselines.}
}


@article{DBLP:journals/pacmnet/ZhuKMYVCCK25,
	author = {Jiangchen Zhu and
                  Thomas Koch and
                  Ilgar Mammadov and
                  Shuyue Yu and
                  Kevin Vermeulen and
                  Matt Calder and
                  {\'{I}}talo S. Cunha and
                  Ethan Katz{-}Bassett},
	title = {The New (Pareto) Frontier of Cloud Routing: High Availability, Precise
                  Control, or Configuration Stability - Choose Two},
	journal = {Proc. {ACM} Netw.},
	volume = {3},
	number = {CoNEXT4},
	pages = {1--25},
	year = {2025},
	url = {https://doi.org/10.1145/3768975},
	doi = {10.1145/3768975},
	timestamp = {Fri, 26 Dec 2025 20:52:15 +0100},
	biburl = {https://dblp.org/rec/journals/pacmnet/ZhuKMYVCCK25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Clouds provide latency-sensitive services to clients at geographically distributed sites. They need precise control of client-site mappings for performance and, if a site fails, fast failover to other sites without cascading failures due to failover-induced overload or risky routing reconfiguration. However, clouds today route clients to sites by anycast or unicast with DNS-based redirection--methods that compromise either control or availability. In fact, even beyond these existing techniques, we find that all general-purpose approaches for directing clients to sites face inevitable tradeoffs among control, availability, and routing stability. We then present new general-purpose routing techniques and demonstrate via Internet-scale experiments that they provide much better tradeoffs among these three goals than existing techniques. One of our techniques achieves anycast's advantages with much better control, and another speeds up unicast's failover while preserving its advantages. Our techniques establish a new Pareto frontier for cloud routing.}
}


@article{DBLP:journals/pacmnet/LachnitGHWHSSC25,
	author = {Stefan Lachnit and
                  Sebastian Gallenm{\"{u}}ller and
                  Eric Hauser and
                  Florian Wiedner and
                  Kilian Holzinger and
                  Henning Stubbe and
                  Thomas Senftl and
                  Georg Carle},
	title = {MoonEm - High-Precision Path Property Emulation Using {DPDK}},
	journal = {Proc. {ACM} Netw.},
	volume = {3},
	number = {CoNEXT4},
	pages = {1--21},
	year = {2025},
	url = {https://doi.org/10.1145/3768976},
	doi = {10.1145/3768976},
	timestamp = {Fri, 26 Dec 2025 20:52:15 +0100},
	biburl = {https://dblp.org/rec/journals/pacmnet/LachnitGHWHSSC25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Network path conditions, such as loss, capacity, and delay, have a significant impact on the behavior and performance of networked applications. Path property emulators are essential and widely used tools to perform evaluations under realistic conditions. However, the quality of the emulation and the potential influence on experimental results itself is rarely considered. This work highlights how the performance limitations of existing tools, such as NetEm, a network emulator based on Linux traffic control, can alter network measurements. To address these shortcomings, we introduce MoonEm, a high-performance path property emulator based on the Data Plane Development Kit (DPDK). Moreover, we present a novel approach to precisely control packet transmission times on commodity hardware. MoonEm is focused on the emulation of realistic and reproducible network conditions. Our measurements demonstrate that MoonEm achieves a maximum packet rate of 13.39 Mpps compared to 0.98 Mpps for NetEm. In contrast to NetEm, we improve latency deviation from 71.15 µs to 53 ns for the median and from 769.26 µs to 80 ns for the worst case.}
}


@article{DBLP:journals/pacmnet/LiuLZYSWRWY25,
	author = {Xinzhe Liu and
                  Yahui Li and
                  Han Zhang and
                  Xia Yin and
                  Xingang Shi and
                  Zhiliang Wang and
                  Gang Ren and
                  Jilong Wang and
                  Jiangyuan Yao},
	title = {Scalable and Interpretable Overlay Network Checking via Ensemble Verification},
	journal = {Proc. {ACM} Netw.},
	volume = {3},
	number = {CoNEXT4},
	pages = {1--25},
	year = {2025},
	url = {https://doi.org/10.1145/3768974},
	doi = {10.1145/3768974},
	timestamp = {Fri, 26 Dec 2025 20:52:15 +0100},
	biburl = {https://dblp.org/rec/journals/pacmnet/LiuLZYSWRWY25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Overlay/underlay architecture is increasingly prevalent in modern networks but also introduces greater complexity and error-proneness. Existing control plane verifiers for underlay networks face scalability and interpretability challenges when extended to overlay/underlay networks due to methodological limitations. This paper presents MEV, the first control plane verifier designed for overlay/underlay networks. MEV introduces ensemble verification, a novel verification paradigm enabling independent reasoning for behaviors within each routing instance or protocol and forwarding behaviors within each virtual network. We implement and deploy MEV on a real nationwide overlay/underlay network, FITI, where it successfully identifies 22 misconfigurations that could cause isolation and reachability issues. Furthermore, we evaluate MEV against Batfish +  on FITI and a range of synthetic networks with diverse scales, and find that it achieves up to a 10 2 × speedup over Batfish + .}
}


@article{DBLP:journals/pacmnet/LeiPKS25,
	author = {Yiran Lei and
                  Francisco Pereira and
                  Arvind Krishnamurthy and
                  Justine Sherry},
	title = {SwitchNIC: An Hybrid Architecture for Network Functions with Fast
                  and Consistent Shared State},
	journal = {Proc. {ACM} Netw.},
	volume = {3},
	number = {CoNEXT4},
	pages = {1--21},
	year = {2025},
	url = {https://doi.org/10.1145/3768993},
	doi = {10.1145/3768993},
	timestamp = {Fri, 26 Dec 2025 20:52:15 +0100},
	biburl = {https://dblp.org/rec/journals/pacmnet/LeiPKS25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {To support high-performance network functions, recent work has explored hybrid architectures that combine the flexibility of general-purpose processors with the performance of the PISA switch architecture. These designs partition code and state between switch platforms and general-purpose servers in pursuit of a ''best of both worlds'' design. However, integrating two separate platforms leads to the age-old challenge of ensuring high throughput and low latency while keeping distributed state consistent. We propose a new, tightly-coupled architecture called SwitchNIC that guarantees consistent state between switch and general-purpose processor, while offering 99-th percentile packet latency of 6 μs. The key to SwitchNIC's performance is a novel, ''on-path'' state replication protocol, with latency further tightened by implementing general-purpose processing on locally-integrated ARM cores. We prototype SwitchNIC by deploying its state replication algorithms on a Tofino switch with Ethernet-attached ARM-based SmartNICs. SwitchNIC achieves up to 5.2x better energy efficiency and 6.4x better processing latency than server-based systems, none of which completely and correctly support shared state between platforms.}
}


@article{DBLP:journals/pacmnet/LiMLK25,
	author = {Hejing Li and
                  Marvin Meiers and
                  Jialin Li and
                  Antoine Kaufmann},
	title = {SplitSim: Towards Practical Large-Scale Full-System Simulation for
                  Systems Research},
	journal = {Proc. {ACM} Netw.},
	volume = {3},
	number = {CoNEXT4},
	pages = {1--19},
	year = {2025},
	url = {https://doi.org/10.1145/3768999},
	doi = {10.1145/3768999},
	timestamp = {Fri, 26 Dec 2025 20:52:15 +0100},
	biburl = {https://dblp.org/rec/journals/pacmnet/LiMLK25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {When physical testbeds are out of reach for evaluating a networked system, we frequently turn to simulation. In today's datacenter networks, bottlenecks are often not at the network protocol level, but instead in end-host software or hardware components. Here, current protocol-level simulations are an inadequate means of evaluation. Detailed end-to-end simulations covering these components on the other hand, simply cannot achieve the required scale with feasible simulation performance and computational resources. It is fundamentally difficult to simultaneously achieve high simulation fidelity, low simulation time, and minimal resource consumption-especially for large-scale systems. With limited time and resource budgets, users must find the right compromise across these dimensions. Unfortunately, existing simulation frameworks do not offer flexible trade-offs among these aspects and are unable to make effective use of the time and resources users can afford. In this paper, we address this with SplitSim, a simulation framework for practical end-to-end evaluation for large-scale network and distributed systems. SplitSim provides the user abstractions to specify the system to be evaluated, and easily & flexibly instantiate different simulations for the same system to navigate these trade-offs. Based on these abstractions, SplitSim allows users to flexibly trade off simulation fidelity, time, and resource usage by mixing simulation models with different fidelity and controlled parallelization. Finally, SplitSim includes a profiler that identifies simulation performance bottlenecks and helps users make informed decisions about parallelization, resource allocation, and simulation detail. With these capabilities, we demonstrate that SplitSim can simulate a 1200-node datacenter network using 24 cores running end-to-end applications in 175 min for 20 s of system time.}
}


@article{DBLP:journals/pacmnet/MelliaLZ25a,
	author = {Marco Mellia and
                  Andra Lutu and
                  Ying Zhang},
	title = {{PACMNET} V3, CoNEXT4, December 2025 Editorial},
	journal = {Proc. {ACM} Netw.},
	volume = {3},
	number = {CoNEXT4},
	pages = {1--2},
	year = {2025},
	url = {https://doi.org/10.1145/3768969},
	doi = {10.1145/3768969},
	timestamp = {Fri, 26 Dec 2025 20:52:15 +0100},
	biburl = {https://dblp.org/rec/journals/pacmnet/MelliaLZ25a.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Proceedings of the ACM on Networking (PACMNET) series showcases top-tier research in emerging computer networks and their applications. We welcome submissions introducing new technologies, innovative experiments, creative applications of networking technologies, and fresh insights gained through analysis. Supported by the ACM Special Interest Group on Communications and Computer Networks (SIGCOMM), the journal is backed by a distinguished Editorial Board composed of leading researchers in the field. This issue concludes the third volume of PACMNET, which in total published 50 articles, with a growth of 56% compared to the second volume. This testifies to the success of PACMNET and its community. This issue features 32 articles, all submitted by the June 2025 deadline, when a total of 181 submissions were received, 172 of which were reviewed after we desk-rejected 9 articles. Each submission underwent a thorough review process involving 85 Editors, coordinated by two Associate Editors. In the initial phase, every article received a minimum of three reviews. Following an online discussion, roughly a third of the submissions were rejected, while the rest advanced to a second review phase. In this phase, Editors produced at least two additional reviews per article. After a second discussion phase, the Editors met online to decide which articles to accept after a minor revision, which to offer a ''one-shot-major'' revision opportunity, and which to reject. The Editors decided to offer a one-shot major revision option to 15 articles, and decided to accept with minor revisions 32 articles. This year's collection of 32 papers showcases a vibrant spectrum of innovations across networking, systems, and a significant growth of papers using machine learning for networking or networking for machine learning. The contributions span from foundational measurement studies - such as large-scale evaluations of 5G Standalone deployments and IPv6 probing techniques - to cutting-edge systems like SwitchNIC and MorphOS that redefine performance and flexibility in networked environments. Several works tackle the challenges of congestion control, latency, and energy efficiency in data centers and wireless networks, while others introduce novel frameworks for secure memory disaggregation, dynamic spectrum enforcement, and carbon-aware routing. Advances in machine learning are prominently featured, powering breakthroughs in traffic inference, wireless localization, and outage detection. The program also includes pioneering efforts in immersive media streaming, VR cloud gaming, and satellite networking, reflecting the community's commitment to shaping the future of connectivity. Collectively, these papers push the boundaries of scalability, reliability, and adaptability in modern networked systems. We want to express our gratitude to all those who contributed to this issue of PACMNET, especially the Authors for submitting their finest work and the Associate Editors for offering valuable feedback in their reviews and engaging in the discussions. Our thanks also go to the SIGCOMM Executive Committee Chair and the CoNEXT Steering Committee members for their continued support and guidance, providing essential suggestions and insights throughout the article selection process.}
}


@article{DBLP:journals/pacmnet/WangZ25,
	author = {Zhukun Wang and
                  Noa Zilberman},
	title = {NetFridgeS: Enabling Dynamic Frequency Scaling on Network Switches
                  through Carbon-Aware Routing},
	journal = {Proc. {ACM} Netw.},
	volume = {3},
	number = {CoNEXT4},
	pages = {1--20},
	year = {2025},
	url = {https://doi.org/10.1145/3768984},
	doi = {10.1145/3768984},
	timestamp = {Fri, 26 Dec 2025 20:52:15 +0100},
	biburl = {https://dblp.org/rec/journals/pacmnet/WangZ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {High performance network switches are designed to meet peak throughput demands, always operating at maximum clock frequency to avoid packet drops. However, real-world network traffic exhibits clear periodic patterns, leading to a waste of energy due to over-provisioning during non-peak hours. Dynamic frequency scaling, a popular energy saving mechanism, was not adopted by network switches due to differences in architecture from CPUs and the requirement not to drop packets. In this paper, we present NetFridgeS, enabling dynamic frequency scaling on high-performance network switches. NetFridgeS builds upon carbon-aware routing to forecast network utilization and adjust pipeline frequency. NetFridgeS is prototyped on FPGA using three distinct pipeline architectures, with sub-microsecond frequency switching times and minimal latency and resource overhead. By scaling down the frequency, NetFridgeS achieves an average energy saving of 77.74% at minimum throughput. In real network topologies, the combination of NetFridgeS and carbon-aware routing results in up to a 22.11% reduction in overall energy consumption and a 27.76% reduction in carbon emissions compared with current network deployments.}
}


@article{DBLP:journals/pacmnet/LinLZYLLYTWLX25,
	author = {Chuanqing Lin and
                  Gerui Lv and
                  Fuhua Zeng and
                  Hanlin Yang and
                  Junwei Li and
                  Xiaodong Li and
                  Jingyu Yang and
                  Yu Tian and
                  Qinghua Wu and
                  Zhenyu Li and
                  Gaogang Xie},
	title = {Oceanus: Scheduling Traffic Flows to Achieve Cost-Efficiency under
                  Uncertainties in Large-Scale Edge CDNs},
	journal = {Proc. {ACM} Netw.},
	volume = {3},
	number = {CoNEXT4},
	pages = {1--25},
	year = {2025},
	url = {https://doi.org/10.1145/3768983},
	doi = {10.1145/3768983},
	timestamp = {Fri, 26 Dec 2025 20:52:15 +0100},
	biburl = {https://dblp.org/rec/journals/pacmnet/LinLZYLLYTWLX25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Large-scale edge Content Delivery Networks (CDNs) provide low-latency content access services and suffer from high bandwidth costs. While previous studies have sought to optimize bandwidth costs under percentile billing, the efficacy is compromised due to the pervasive uncertainty inherent in practical systems, including traffic demand dynamics, performance-constrained scheduling bias, and systemic scheduling deviations. Such uncertainties can result in large gaps among optimal, expected, and actual utilization of massive vulnerable and heterogeneous edge nodes. To address these uncertainties, we propose Oceanus, a cost-effective traffic scheduling system for large-scale edge CDN systems. Oceanus decouples the bandwidth planning problem and performs on multiple timescales. In addition, Oceanus coordinates bandwidth planning with flow scheduling through the bidirectional feedback scheme. Oceanus further utilizes nodes with minimal marginal cost to reduce additional bandwidth cost. Extensive experiments in a trace-driven testbed and real-world deployment confirm the effectiveness of Oceanus. Compared to the state-of-the-art scheduling method, Oceanus achieves 79.4% (vs. 51.5%) of optimum cost reduction and reduces 21.4% (vs. 8.1%) bandwidth costs.}
}


@article{DBLP:journals/pacmnet/WuATSH25,
	author = {Ze Wu and
                  Ahmad Alhilal and
                  Yuk Hang Tsui and
                  Matti Siekkinen and
                  Pan Hui},
	title = {EyeNexus: Adaptive Gaze-Driven Quality and Bitrate Streaming for Seamless
                  {VR} Cloud Gaming Experiences},
	journal = {Proc. {ACM} Netw.},
	volume = {3},
	number = {CoNEXT4},
	pages = {1--25},
	year = {2025},
	url = {https://doi.org/10.1145/3768989},
	doi = {10.1145/3768989},
	timestamp = {Fri, 26 Dec 2025 20:52:15 +0100},
	biburl = {https://dblp.org/rec/journals/pacmnet/WuATSH25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Virtual reality cloud gaming systems render the 3D graphics on cloud servers for playing graphically demanding games on VR headsets. Delivering high-resolution game scenes is challenging due to variation in network performance. By leveraging the non-uniform human vision perception, foveated rendering and encoding have proven effective for optimized streaming in constrained networks. SoTA foveation methods either do not incorporate real-time gaze data or are unable to handle variations in network conditions, resulting in a suboptimal user experience. We introduce EyeNexus, a pioneering system that combines real-time gaze-driven spatial compression (FSC) with gaze-driven video encoding (FVE), transforming the gaze point for precise alignment and foveation. We propose a novel foveation model that dynamically adjusts the foveation region based on real-time bandwidth and gaze data. The model simplifies network-aware quality assignment in FVE, ensuring smooth and imperceptible quality gradients. We evaluate EyeNexus using objective and subjective measures with different network conditions and games. EyeNexus reduces latency by up to 70.9% and improves perceptual visual quality by up to 24.6%. Our IRB-approved user study shows that EyeNexus achieves the highest playability and visual quality, with improvements of up to 48%, while eliminating motion sickness.}
}


@article{DBLP:journals/pacmnet/WeiT25,
	author = {Yiluo Wei and
                  Gareth Tyson},
	title = {An Empirical Analysis of the Nostr Social Network: Decentralization,
                  Availability, and Replication Overhead},
	journal = {Proc. {ACM} Netw.},
	volume = {3},
	number = {CoNEXT4},
	pages = {1--23},
	year = {2025},
	url = {https://doi.org/10.1145/3768994},
	doi = {10.1145/3768994},
	timestamp = {Thu, 25 Dec 2025 12:45:42 +0100},
	biburl = {https://dblp.org/rec/journals/pacmnet/WeiT25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Nostr is a decentralized social network launched in 2022, emphasizing high availability and censorship resistance. Since launching, it has gained substantial attention, boasting over 100 million posts. From a user's perspective, it is similar to a micro-blogging service like Twitter. However, the underlying systems infrastructure is very different, and Nostr boasts a range of unique features that set it apart. Nostr introduces the concept of relays, which act as open storage servers that receive, store, and distribute user posts. Each user is uniquely identified by a public key, ensuring authenticity of posts through digital signatures. Users are able to securely replicate and retrieve posts through multiple relays, which frees them from single-server reliance and enhances post availability, thereby attempting to make Nostr censorship resistant. However, this aggressive design also presents challenges, such as the overhead required for extensive post replication and the difficulty in obtaining a global view of post replication locations, which remain unexplored or unaddressed. This necessitates a thorough understanding of the Nostr ecosystem; therefore, we conduct the first large-scale study on this topic. Our study focuses on two key aspects: Nostr relays and post replication strategies. We find that Nostr achieves superior decentralization compared to traditional Fediverse applications. However, relay availability remains a challenge, where financial sustainability (particularly for free-to-use relays) emerges as a contributing factor. We also find that the replication of posts across relays enhances censorship-resistance but introduces significant overhead. To address this, we propose two improvements: one to control the number of post replications, and another to reduce the overhead during post retrieval. Via a data-driven evaluation, we demonstrate their ability to reduce overhead without negatively impacting post availability under the simulated scenarios.}
}


@article{DBLP:journals/pacmnet/KaneriaWS25,
	author = {Darshil D. Kaneria and
                  Ranysha Ware and
                  Srinivasan Seshan},
	title = {VCCAnalyzer: Identifying Congestion Control Algorithms used by Video
                  Streaming Services},
	journal = {Proc. {ACM} Netw.},
	volume = {3},
	number = {CoNEXT4},
	pages = {1--11},
	year = {2025},
	url = {https://doi.org/10.1145/3768979},
	doi = {10.1145/3768979},
	timestamp = {Wed, 24 Dec 2025 10:44:50 +0100},
	biburl = {https://dblp.org/rec/journals/pacmnet/KaneriaWS25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {CCAnalyzer is a recent proposal for a congestion control algorithm (CCA) classifier to measure the deployment of congestion control algorithms in the Internet today by creating a controlled bottleneck and monitoring bottleneck queue occupancy between third-party websites and a controlled receiver. However, this work was designed for web traffic, whereas most internet traffic today is video streaming. Video streaming applications pose additional challenges in CCA classification due to the interactions between adaptive bitrate (ABR) algorithms and CCAs. In this work, we present VCCAnalyzer, which addresses these challenges by carefully selecting bottleneck bandwidth rates to minimize ABR interference and applying interpolation and smoothing techniques to create classifiable queue occupancy traces. VCCAnalyzer achieves 100% accuracy, higher accuracy than other approaches in video classification. To demonstrate the efficacy of VCCAnalyzer, we conduct a measurement study examining the CCA deployment across major streaming platforms, including Disney+, Hulu, Twitch, and other commonly visited websites. Our findings reveal some variations in congestion control strategies between these services. Our results demonstrate that VCCAnalyzer can effectively classify CCAs in video environments.}
}


@article{DBLP:journals/pacmnet/NadimLRBABQAZ25,
	author = {Md Nadim and
                  Xun Li and
                  Salil Reddy and
                  Sarath Babu and
                  Arsalan Ahmad and
                  Ozdal Boyraz and
                  Daji Qiao and
                  Anish Arora and
                  Hongwei Zhang},
	title = {AraOptical System and Testbed for Long-Range, High-Capacity {FSOC}
                  in Rural Wireless X-Haul Networks},
	journal = {Proc. {ACM} Netw.},
	volume = {3},
	number = {CoNEXT4},
	pages = {1--21},
	year = {2025},
	url = {https://doi.org/10.1145/3768986},
	doi = {10.1145/3768986},
	timestamp = {Fri, 26 Dec 2025 20:52:15 +0100},
	biburl = {https://dblp.org/rec/journals/pacmnet/NadimLRBABQAZ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Long-range, high-capacity free-space optical communications (FSOC) is critical for terrestrial rural wireless x-haul and rural broadband in general. Existing terrestrial FSOC systems are however designed primarily for short-range communications. Long-range FSOC faces major challenges such as scintillation, weather, telescope misalignment, and sun noise, and there is a lack of FSOC systems and testbeds for investigating the feasibility and behavior of long-range, high-capacity terrestrial FSOC in realistic rural settings. To fill the gap, we design and implement AraOptical, a first-of-its-kind 10+ km FSOC x-haul system. We permanently deploy the AraOptical system and make it publicly available as the rural ARA testbed for empowering researchers worldwide to investigate long-range FSOC and wireless x-haul solutions. The AraOptical system features innovative designs for addressing key challenges of long-range FSOC. It effectively uses optimized COTS components such as feedback-controlled-low-noise-amplifiers and transceivers compatible with conventional routers, and it invents a novel multi-level auto-alignment algorithm tailored for the AraOptical system. The software framework of the AraOptical system features custom-designed APIs and facilitates the establishment of the ARA wireless living lab for real-world experimentation. Using the field-deployed ARA, we demonstrate, for the first time, the real-world feasibility of long-range terrestrial FSOC. AraOptical achieves a maximum throughput of 2.92 Gbps on a single channel, and, with 16 parallel channels, AraOptical is well-poised to scale to an aggregate capacity of 160 Gbps using 10G SFP+ transceivers, with potential for multi-Tbps capacity using 100G/400G coherent transceivers. We also quantitatively characterize the impact of scintillation and weather on long-range terrestrial FSOC, and we will publicly share the first-of-its-kind measurement data. The unique lessons learned from this pioneering real-world deployment of long-range FSOC systems will also facilitate future real-world studies and adoption.}
}


@article{DBLP:journals/pacmnet/GhoshalBWDKFYHK25,
	author = {Moinak Ghoshal and
                  Omar Basit and
                  Sizhe Wang and
                  Phuc Dinh and
                  Imran Khan and
                  Yufei Feng and
                  Zhekun Yu and
                  Y. Charlie Hu and
                  Dimitrios Koutsonikolas},
	title = {A First Large-Scale Study of Operational 5G Standalone Networks},
	journal = {Proc. {ACM} Netw.},
	volume = {3},
	number = {CoNEXT4},
	pages = {1--21},
	year = {2025},
	url = {https://doi.org/10.1145/3768990},
	doi = {10.1145/3768990},
	timestamp = {Fri, 26 Dec 2025 20:52:15 +0100},
	biburl = {https://dblp.org/rec/journals/pacmnet/GhoshalBWDKFYHK25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As 5G technology has reached its midlife, mobile operators are increasingly rolling out 5G Standalone (SA), which is pivotal in unlocking the full potential of 5G networks. Prior research has mainly focused on 5G Non-Standalone (NSA) performance, while comprehensive evaluations of operational 5G SA deployments remain scarce. Through two cross-country US driving trips (3200+ km) in 2023 and 2024, we conduct, to the best of our knowledge, the first large-scale study of T-Mobile's 5G Standalone (SA) deployment in the US, analyzing its evolution while comparing it head-to-head with 5G NSA. Our study shows a shift in the operator's 5G deployment priorities from 2023 to 2024 in favor of 5G SA compared to 5G NSA, with 5G SA deployments extending across diverse geographical areas. Advanced features, such as higher carrier aggregation with diverse band combinations and new frequency bands with different duplexing capabilities, allow SA to achieve better performance compared to NSA, whose peak performance has plateaued, reflecting limited upgrades as the operator transitions to SA infrastructure. Additionally, we examine the handover duration and uplink power control in SA and NSA networks, offering deeper insights into the operational dynamics of the two modes.}
}


@article{DBLP:journals/pacmnet/LiPZLWWZZWLDNWZGLX25,
	author = {Luyang Li and
                  Heng Pan and
                  Pengyi Zhang and
                  Kai Lv and
                  Zilong Wang and
                  Xinchen Wan and
                  Dai Zhang and
                  Xiaolong Zhong and
                  Haoran Wei and
                  Lichao Liu and
                  Huichen Dai and
                  Qingsong Ning and
                  Xin Wei and
                  Shideng Zhang and
                  Hongtao Guan and
                  Zhenyu Li and
                  Gaogang Xie},
	title = {Taurus: Towards {A} High-Performance and Generic Congestion Control
                  Framework for Datacenter Networks},
	journal = {Proc. {ACM} Netw.},
	volume = {3},
	number = {CoNEXT4},
	pages = {1--25},
	year = {2025},
	url = {https://doi.org/10.1145/3768973},
	doi = {10.1145/3768973},
	timestamp = {Fri, 26 Dec 2025 20:52:15 +0100},
	biburl = {https://dblp.org/rec/journals/pacmnet/LiPZLWWZZWLDNWZGLX25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Congestion control (CC) is crucial for datacenter networks (DCNs), and CC frameworks are proposed to enable users to easily deploy new algorithms tailored to diverse scenarios. The framework is desired to be high-performance and generic: (i) allows CC to achieve high throughput and low latency. (ii) supports various algorithms and congestion scenarios. However, prior works either suffer from performance limitations or lack sufficient generality. CCP experiences throughput degradation under heavy traffic, while DOCA-PCC improves performance using hardware but lacks support for detecting and mitigating host congestion. In this paper, we present Taurus, a high-performance and generic CC framework through hardware-software co-design. To this end, Taurus partitions CC functions into distinct tasks and maps them onto suitable hardware/software components while mitigating excessive interaction overhead. Specifically, Taurus designs a collaborative signal collection mechanism to support diverse congestion feedback, a type-aware message report engine to reduce communication overhead, and software built-in handlers to facilitate deployments. We have implemented a fully functional Taurus on commodity servers with FPGA-based NICs. Experimental results show that Taurus supports various CC algorithms in achieving their near-native performance. Compared to CCP, Taurus improves throughput by 32.3%, reduces latency by 96.4%, and lowers CPU overhead by 158.7%. Compared to DOCA-PCC, Taurus improves throughput by 9.3% and reduces latency by 28.8%.}
}


@article{DBLP:journals/pacmnet/GhoshSZYJMNORRG25,
	author = {Rajrup Ghosh and
                  Christina Suyong Shin and
                  Lei Zhang and
                  Muyang Ye and
                  Tao Jin and
                  Harsha V. Madhyastha and
                  Ravi Netravali and
                  Antonio Ortega and
                  Sanjay G. Rao and
                  Anthony Rowe and
                  Ramesh Govindan},
	title = {LiVo: Toward Bandwidth-adaptive Fully-Immersive Volumetric Video Conferencing},
	journal = {Proc. {ACM} Netw.},
	volume = {3},
	number = {CoNEXT4},
	pages = {1--25},
	year = {2025},
	url = {https://doi.org/10.1145/3768981},
	doi = {10.1145/3768981},
	timestamp = {Fri, 26 Dec 2025 20:52:15 +0100},
	biburl = {https://dblp.org/rec/journals/pacmnet/GhoshSZYJMNORRG25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Volumetric video allows users 6 degrees of freedom (6-DoF) in viewing continuously evolving scenes in 3D. Given broadband speeds today, volumetric video conferencing will soon be feasible. Even so, these scenes will need to be compressed, and compression will need to adapt to variations in bandwidth availability. Existing 3D compression techniques cannot adapt to bandwidth availability, are slow, and utilize bandwidth inefficiently, so they don't scale well to large scene descriptions. LiVo achieves low-latency and large-scene two-way conferencing by maximally leveraging existing 2D video infrastructure, including compression standards, rate-adaptive codecs, and real-time transport protocols. To achieve high quality, LiVo must carefully compose scenes from multiple cameras into multiple streams, encode scene geometry in a novel way, adapt to and apportion available bandwidth dynamically between streams to ensure high reconstruction quality, and cull content outside the receiver's field of view to reduce information sent into the network. These novel contributions enable LiVo to outperform the state-of-the-art by over 20% in objective quality. In a user study, LiVo achieves a mean opinion score of 4.1, while other approaches achieve significantly lower values.}
}


@article{DBLP:journals/pacmnet/MuckeNHSZCLSW25,
	author = {Jonas M{\"{u}}cke and
                  Marcin Nawrocki and
                  Raphael Hiesgen and
                  Patrick Sattler and
                  Johannes Zirngibl and
                  Georg Carle and
                  Jan Luxemburk and
                  Thomas C. Schmidt and
                  Matthias W{\"{a}}hlisch},
	title = {Waiting for {QUIC:} Passive Measurements to Understand {QUIC} Deployments},
	journal = {Proc. {ACM} Netw.},
	volume = {3},
	number = {CoNEXT4},
	pages = {1--26},
	year = {2025},
	url = {https://doi.org/10.1145/3768988},
	doi = {10.1145/3768988},
	timestamp = {Fri, 26 Dec 2025 20:52:15 +0100},
	biburl = {https://dblp.org/rec/journals/pacmnet/MuckeNHSZCLSW25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {QUIC experiences a rapid adoption since its standardization in 2021, and hypergiants configure their infrastructure to optimize for QUIC performance. In this paper, we introduce a passive measurement method to study both the progressive rollout and individual hypergiant configurations during the last five years. By analyzing backscatter traffic of the UCSD network telescope, we are able to make the following observations. First, Meta, Google, and Cloudflare configure significantly different maximal retransmission numbers and timeouts. Second, we can identify different off-net deployments of hypergiants, using packet features, such as QUIC connection IDs, packet coalescence, and packet lengths. Third, we observe changing hypergiant deployment configurations during our different measurement periods. Fourth, connection IDs can allow further insights into load balancer deployments, such as the number of servers. We bolster our results using two orthogonal measurements: passive recording of QUIC flows and active probing.}
}


@article{DBLP:journals/pacmnet/KrencHLDC25,
	author = {Thomas Krenc and
                  Shivani Hariprasad and
                  Matthew Luckie and
                  Benoit Donnet and
                  K. C. Claffy},
	title = {Towards Understanding City-Level Routing using {BGP} Location Communities},
	journal = {Proc. {ACM} Netw.},
	volume = {3},
	number = {CoNEXT4},
	pages = {1--13},
	year = {2025},
	url = {https://doi.org/10.1145/3768998},
	doi = {10.1145/3768998},
	timestamp = {Sun, 01 Feb 2026 13:42:38 +0100},
	biburl = {https://dblp.org/rec/journals/pacmnet/KrencHLDC25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {BGP communities are widely used by operators to encode routing metadata for traffic engineering, policy enforcement, and operational debugging. However, ≈90% of observed communities lack public documentation, limiting their utility for research and operational analysis. Among these, city-level communities offer valuable geographic insight into routing behavior, yet remain largely untapped. In this paper, we develop a scalable method to infer the geographic meaning of undocumented city communities using BGP data. We validate our approach against a ground truth dataset covering 1,482 city communities and through operator feedback. Applied to data from May 2025, our algorithm infers the locations of 80% of city communities with a precision of 70 km or better. We publish all code and datasets to support reproducibility and further research.}
}


@article{DBLP:journals/pacmnet/GajjarKGJMLS25,
	author = {Pranshav Gajjar and
                  Molham Khoja and
                  Abiodun Ganiyu and
                  Marc Juarez and
                  Mahesh K. Marina and
                  Andrew Lehane and
                  Vijay K. Shah},
	title = {Black-Box Evasion Attacks on Data-Driven Open {RAN} Apps: Tailored
                  Design and Experimental Evaluation},
	journal = {Proc. {ACM} Netw.},
	volume = {3},
	number = {CoNEXT4},
	pages = {1--26},
	year = {2025},
	url = {https://doi.org/10.1145/3769000},
	doi = {10.1145/3769000},
	timestamp = {Fri, 26 Dec 2025 20:52:16 +0100},
	biburl = {https://dblp.org/rec/journals/pacmnet/GajjarKGJMLS25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The impending adoption of Open Radio Access Network (O-RAN) is fueling innovation in the RAN towards data-driven operation. Unlike traditional RAN where the RAN data and its usage is restricted within proprietary and monolithic RAN equipment, the O-RAN architecture opens up access to RAN data (i.e., network telemetry), via RAN intelligent controllers (RICs), to third-party machine learning (ML) powered applications - rApps and xApps - to optimize RAN operations. Consequently, a major focus has been placed on leveraging RAN data to unlock greater efficiency gains. However, there is an increasing recognition that RAN data access to apps could become a source of vulnerability and be exploited by malicious actors. Motivated by this, we carry out a comprehensive investigation of data vulnerabilities on both xApps and rApps, respectively hosted in Near- and Non-real-time (RT) RIC components of O-RAN. Our investigation begins by qualitatively analyzing the O-RAN security mechanisms and limitations relevant to xApps and rApps, such as their onboarding authentication process and RIC database access mechanisms. Considering a threat model informed by this analysis, we design a viable and effective black-box evasion attack strategy targeting O-RAN RIC Apps while accounting for the stringent timing constraints (particularly for xApps) and attack effectiveness. The attack strategy employs four key techniques: the model cloning algorithm, input-specific perturbations, universal adversarial perturbations (UAPs), and targeted UAPs. This strategy targets ML models used by both xApps and rApps within the O-RAN system, aiming to degrade network performance. We experimentally validate the effectiveness of the designed evasion attack strategy and quantify the scale of performance degradation using a real-world O-RAN testbed and emulation environments. This evaluation is conducted using the  Interference Classification xApp  and the  Power Saving rApp  as representative applications for near-RT and non-RT RICs, respectively. Further, we show that the attack strategy is effective against prominent defense techniques for adversarial ML, such as defensive distillation and adversarial training.}
}


@article{DBLP:journals/pacmnet/WanJ25,
	author = {Haoran Wan and
                  Kyle Jamieson},
	title = {L4Span: Spanning Congestion Signaling over NextG Networks for Interactive
                  Applications},
	journal = {Proc. {ACM} Netw.},
	volume = {3},
	number = {CoNEXT4},
	pages = {1--25},
	year = {2025},
	url = {https://doi.org/10.1145/3768972},
	doi = {10.1145/3768972},
	timestamp = {Wed, 24 Dec 2025 10:44:51 +0100},
	biburl = {https://dblp.org/rec/journals/pacmnet/WanJ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Design for low latency networking is essential for tomorrow's interactive applications, but it is essential to deploy incrementally and universally at the network's last mile. While wired broadband ISPs are rolling out the leading queue occupancy signaling mechanisms, the cellular Radio Access Network (RAN), another important last mile to many users, lags behind these efforts. This paper proposes a new RAN design,  L4Span,  that abstracts the complexities of RAN queueing in a simple interface, thus tying the queue state of the RAN to end-to-end low-latency signaling all the way back to the content server. At millisecond-level timescales, L4Span predicts the RAN's queuing occupancy and performs ECN marking for both low-latency and classic flows. L4Span is lightweight, requiring minimal RAN modifications, and remains 3GPP and O-RAN compliant for maximum ease of deployment. We implement a prototype on the srsRAN open-source software in C++. Our evaluation compares the performance of low-latency as well as classic flows with or without the deployment of L4Span in various wireless channel conditions. Results show that L4Span reduces the one-way delay of both low-latency and classic flows by up to 98%, while simultaneously maintaining near line-rate throughput. The code is available at  https://github.com/PrincetonUniversity/L4Span .}
}


@article{DBLP:journals/pacmnet/MilaniVBGGKS25,
	author = {Mattia Milani and
                  Viktoria Vomhoff and
                  Dario Bega and
                  Marco Gramaglia and
                  Stefan Geissler and
                  Csaba Karsai and
                  Pablo Serrano},
	title = {Faro: {A} Scalable and Reliable Outage Detection Algorithm for IoT
                  Mobile Virtual Network Aggregators},
	journal = {Proc. {ACM} Netw.},
	volume = {3},
	number = {CoNEXT4},
	pages = {1--23},
	year = {2025},
	url = {https://doi.org/10.1145/3768982},
	doi = {10.1145/3768982},
	timestamp = {Fri, 26 Dec 2025 20:52:16 +0100},
	biburl = {https://dblp.org/rec/journals/pacmnet/MilaniVBGGKS25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Internet of Things (IoT) Mobile Network Aggregators (MNAs) are an increasingly successful paradigm for providing ubiquitous mobile Internet connectivity for Smart Devices. They leverage the 4G/5G roaming architecture offered by Mobile Network Operators (MNOs) worldwide to offer a single gateway to the Internet. In this context, promptly detecting network outages is fundamental: Mobile Network Aggregators (MNAs) do not have control over the visited network infrastructure, and they offer connectivity to a huge number of possibly unmanaged devices. However, this activity is currently a painstaking process carried out manually by network engineers, who review trends in control plane signalling messages that are forwarded in the Mobile Network Aggregators (MNAs) managed core. In this paper, we present Faro, a self-supervised solution for the automatic detection of network outages. Faro leverages a contrastive learning framework that is particularly suited for this scenario, characterised by very skewed input data, few samples, and the use of confidence scores to automatically detect changes in the input data. We evaluate Faro using a real-world dataset comprising more than 5 million control plane messages across multiple countries and over 6 months, demonstrating its ability to accurately diagnose all outage scenarios in less than 15 minutes.}
}


@article{DBLP:journals/pacmnet/JiangLNBSF25,
	author = {Xi Jiang and
                  Shinan Liu and
                  Saloua Naama and
                  Francesco Bronzino and
                  Paul Schmitt and
                  Nick Feamster},
	title = {{JITI:} Dynamic Model Serving for Just-in-Time Traffic Inference},
	journal = {Proc. {ACM} Netw.},
	volume = {3},
	number = {CoNEXT4},
	pages = {1--24},
	year = {2025},
	url = {https://doi.org/10.1145/3768992},
	doi = {10.1145/3768992},
	timestamp = {Fri, 26 Dec 2025 20:52:16 +0100},
	biburl = {https://dblp.org/rec/journals/pacmnet/JiangLNBSF25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Accurate and efficient inference on network traffic through machine learning models is important for many management tasks, from traffic prioritization to anomaly detection. Existing ML inference pipelines differ primarily in their feature design: those based on summary flow statistics (e.g., packet sizes, inter-arrival times) are lightweight and efficient, though they may be less accurate for fine-grained classification, whereas pipelines that consume features directly from raw packet capture data can achieve higher accuracy but at significantly greater computational and resource cost. In this paper, we develop Just-in-Time Traffic Inference(JITI), a model serving system to support fast and accurate network traffic inference in raw packet-capture-based machine learning inference pipelines. Offline, JITI builds a curated pool of diverse trained models with varied feature and performance requirements. Online, JITI responds to traffic fluctuations via an adaptive scheduler that selects the model from the pool that offers the highest accuracy-to-efficiency ratio within system resource limits, thereby providing inference accuracy comparable to the more complex and resource-intensive packet-capture-based methods, with minimal efficiency compromise. Using traffic application inference as an example task, our evaluation shows that JITI improves inference performance by 18% over flow-statistics-based methods; when benchmarked against state-of-the-art packet-capture-based methods, JITI results in a worst-case drop in F1-Score of only 12.3%, while reducing the average inference decision time by ~127x.}
}


@article{DBLP:journals/pacmnet/KochHNSW25,
	author = {Maynard Koch and
                  Raphael Hiesgen and
                  Marcin Nawrocki and
                  Thomas C. Schmidt and
                  Matthias W{\"{a}}hlisch},
	title = {Scanning the IPv6 Internet Using Subnet-Router Anycast Probing},
	journal = {Proc. {ACM} Netw.},
	volume = {3},
	number = {CoNEXT4},
	pages = {1--15},
	year = {2025},
	url = {https://doi.org/10.1145/3768997},
	doi = {10.1145/3768997},
	timestamp = {Fri, 26 Dec 2025 20:52:16 +0100},
	biburl = {https://dblp.org/rec/journals/pacmnet/KochHNSW25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Identifying active IPv6 addresses is challenging. Various methods emerged to master the measurement challenge in this huge address space, including hitlists, new probing techniques, and AI-generated target lists. In this paper, we apply active Subnet-Router anycast (SRA) probing, a commonly unused method to explore the IPv6 address space. We compare our results with lists of active IPv6 nodes obtained from prior methods and with random probing. Our findings indicate that probing an SRA address reveals on average 10% more router IP addresses than random probing and is far less affected by ICMP rate limiting. Compared to targeting router addresses directly, SRA probing discovers 80% more addresses. We conclude that SRA probing is an important addition to the IPv6 measurement toolbox and may improve the stability of results significantly. We also find evidence that some active scans can cause harmful conditions in current IPv6 deployments, which we started to fix in collaboration with network operators.}
}


@article{DBLP:journals/pacmnet/EpplerOMBM25,
	author = {Manuel Eppler and
                  Lukas Osswald and
                  Nikolaos Mitsakis and
                  Andreas Blenk and
                  Michael Menth},
	title = {T(SN)-Ray: Gauging {TAS} and {PSFP} Delays of {TSN} Switches for Predictable
                  Deterministic Networking},
	journal = {Proc. {ACM} Netw.},
	volume = {3},
	number = {CoNEXT4},
	pages = {1--23},
	year = {2025},
	url = {https://doi.org/10.1145/3768996},
	doi = {10.1145/3768996},
	timestamp = {Fri, 26 Dec 2025 20:52:16 +0100},
	biburl = {https://dblp.org/rec/journals/pacmnet/EpplerOMBM25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Time-Sensitive Networking (TSN) allows for scheduling periodic traffic in Ethernet networks, i.e., sending the traffic such that the traffic encounters minimal delay in intermediate nodes. TSN has two novel features Time-Aware Shaper (TAS) and Per-Stream Filtering and Policing (PSFP) that support time-triggered forwarding at a timescale of nanoseconds. The TAS safeguards scheduled traffic from other priority traffic by opening and closing of transmission gates in TSN switches. PSFP accepts scheduled traffic only when it arrives in the scheduled intervals. As switch-internal forwarding delays are also at this timescale, their knowledge is needed for the computation of schedules that define (1) the transmission of Ethernet frames at Talkers, (2) the opening and closing of the transmission gates in TSN switches, and (3) the configuration of the time-based filter in PSFP also in TSN switches. While it is known that such delays exist and matter, they are not indicated on data sheets, and a measurement methodology to derive them is still lacking. This work fills this gap with T-Ray, a black-box measurement approach. A delay model for TSN switches is proposed together with a measurement methodology to quantify the parameters of the delay model for a given TSN switch. The suggested gauging is illustrated with switches from Kontron and Relyum, and the results reveal operation delays of ∼ 1 μs.}
}


@article{DBLP:journals/pacmnet/MatsonLS25,
	author = {N. Cameron Matson and
                  Yu{-}Tai Lin and
                  Karthikeyan Sundaresan},
	title = {A Holistic Approach to Non-Terrestrial 5G Networking with {LEO} Satellites:
                  Algorithms, Experiments, and Insights},
	journal = {Proc. {ACM} Netw.},
	volume = {3},
	number = {CoNEXT4},
	pages = {1--24},
	year = {2025},
	url = {https://doi.org/10.1145/3769001},
	doi = {10.1145/3769001},
	timestamp = {Fri, 26 Dec 2025 20:52:16 +0100},
	biburl = {https://dblp.org/rec/journals/pacmnet/MatsonLS25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Non-terrestrial networks (NTNs) have been proposed as a key component of next generation of mobile networks. Satellite networks can potentially enable connectivity anywhere on earth, and modern satellites are capable of providing high throughput connectivity. However, there remain several open questions about how NTN will work in practice. We show that blindly applying terrestrial RAN architectures and connectivity management algorithms to the NTN context fails to deliver on multiple network and user level metrics. In this work we present an NTN system that takes a holistic view of the problem, considering both the radio access network architecture as well as the algorithms that drive user session orchestration in the face of satellite mobility. Using a realistic satellite emulation platform as well as large-scale simulations we show that our proposed system outperforms baseline solutions in simultaneously balancing multiple key performance indicators including throughput, coverage, and stability by reducing the impact of satellite mobility.}
}


@article{DBLP:journals/pacmnet/TianLLWZLZLLWMTXLX25,
	author = {Yu Tian and
                  Zhenyu Li and
                  Matthew Yang Liu and
                  Qinghua Wu and
                  Zhaoxue Zhong and
                  Ao Li and
                  Jiaxing Zhang and
                  Gerui Lv and
                  Chuanqing Lin and
                  Xi Wang and
                  Jian Mao and
                  Gareth Tyson and
                  Jie Xiong and
                  Zhenhua Li and
                  Gaogang Xie},
	title = {Cost-efficient Request Mapping for Large-scale Live Streaming Services},
	journal = {Proc. {ACM} Netw.},
	volume = {3},
	number = {CoNEXT4},
	pages = {1--26},
	year = {2025},
	url = {https://doi.org/10.1145/3768978},
	doi = {10.1145/3768978},
	timestamp = {Fri, 26 Dec 2025 20:52:16 +0100},
	biburl = {https://dblp.org/rec/journals/pacmnet/TianLLWZLZLLWMTXLX25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The live streaming landscape has shifted to a crowd-sourced paradigm, resulting in highly volatile and geographically diverse viewer demand. To handle growing traffic, Content Delivery Networks (CDNs) increasingly rely on a mix of dedicated infrastructure and lower-cost, heterogeneous edge resources. Our analysis of production data reveals two emerging characteristics in modern live delivery: dynamic regional supply-demand imbalance and per-stream heterogeneity in popularity and geography. However, existing request mapping solutions fall short in this new landscape, as they assume stable regional capacity and overlook stream-level heterogeneity. This paper proposes  LiveMap , a cost-efficient and latency-aware request mapping system for live CDNs.  LiveMap  performs online bandwidth provisioning via dual-level coordination to resolve regional supply-demand imbalances and reduce bandwidth costs. Further,  LiveMap  introduces an adaptive stream mapping strategy that dynamically forms per-stream delivery groups based on real-time popularity and system load. Deployed in Bilibili CDN serving crowdsourced live streaming over a year,  LiveMap  reduces bandwidth costs by 42.18% and access latency by 20.26%, outperforming the state-of-the-art solutions.}
}
