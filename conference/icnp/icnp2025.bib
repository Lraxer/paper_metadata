@inproceedings{DBLP:conf/icnp/GuoLZWSW25,
	author = {Kejun Guo and
                  Fuliang Li and
                  Yunjie Zhang and
                  Haorui Wan and
                  Jiaxing Shen and
                  Xingwei Wang},
	title = {MEC-Sketch: Memory-Efficient Per-Flow Cardinality Measurement in High-Speed
                  Networks},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--11},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192327},
	doi = {10.1109/ICNP65844.2025.11192327},
	timestamp = {Thu, 13 Nov 2025 08:55:56 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/GuoLZWSW25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Per-Flow cardinality measurement in high-speed networks is essential for network security and traffic analysis applications. Flow cardinality refers to the number of distinct elements within a flow, such as the number of unique destination IPs associated with a given source IP. While extensive research has been conducted on single-flow cardinality estimation, achieving accurate per-flow cardinality measurement with real-time performance and low memory overhead remains challenging in large-scale network environments, particularly given the highly skewed distribution of flow cardinalities where mouse flows with smaller cardinalities dominate, and elephant flows with larger cardinalities are fewer. This paper introduces MEC-Sketch, a memory-efficient cardinality estimation data structure that leverages the inherently skewed distribution of flow cardinalities in network traffic. MEC-Sketch employs a dual-component architecture: a heavy part utilizing a majority vote algorithm for precise super-spreader detection, and a light part implementing compact cardinality estimators for memory-efficient measurement of mouse flows. We address two fundamental technical challenges: (1) adapting the majority vote algorithms to operate with cardinality estimators that lack native support for real-time queries, and (2) implementing an effective mapping strategy between large estimators in the heavy part and small estimators in the light part during elephant-mouse flow separation. Comprehensive evaluations on real-world network traces demonstrate that MEC-Sketch significantly outperforms state-of-the-art solutions in terms of estimation accuracy, memory efficiency, and computational performance for both cardinality estimation and super-spreader detection tasks.}
}


@inproceedings{DBLP:conf/icnp/WagnerHBWS25,
	author = {Eric Wagner and
                  David Heye and
                  Jan Bauer and
                  Klaus Wehrle and
                  Martin Serror},
	title = {{MAC} Aggregation over Lossy Channels in {DTLS} 1.3},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--11},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192339},
	doi = {10.1109/ICNP65844.2025.11192339},
	timestamp = {Thu, 25 Dec 2025 12:47:55 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/WagnerHBWS25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Aggregating Message Authentication Codes (MACs) promises to save valuable bandwidth in resource-constrained environments. The idea is simple: Instead of appending an authentication tag to each message in a communication stream, the integrity protection of multiple messages is aggregated into a single tag. Recent studies postulate, e.g., based on simulations, that these benefits also spread to wireless, and thus lossy, scenarios despite each lost packet typically resulting in the loss of integrity protection information for multiple messages. In this paper, we investigate these claims in a real deployment. Therefore, we first design a MAC aggregation extension for the Datagram Transport Layer Security (DTLS) 1.3 protocol. Afterward, we extensively evaluate the performance of MAC aggregation on a complete communication protocol stack on embedded hardware. We find that MAC aggregation can indeed increase goodput by up to 50 % and save up to 17 % of energy expenditure for the transmission of short messages, even in lossy channels.}
}


@inproceedings{DBLP:conf/icnp/ChenLYWCXDXW25,
	author = {Zirui Chen and
                  Jiang Li and
                  Shucan Yang and
                  Yuqian Wang and
                  Jiahao Cao and
                  Mingwei Xu and
                  Haotian Deng and
                  Renjie Xie and
                  Yangyang Wang},
	title = {Poster: Uncovering Hidden ASes in {ROV} Deployment via Temporal Fingerprinting},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--3},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192326},
	doi = {10.1109/ICNP65844.2025.11192326},
	timestamp = {Thu, 13 Nov 2025 08:55:56 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/ChenLYWCXDXW25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {BGP, the Internet’s inter-domain routing protocol, is vulnerable to prefix hijacks due to tamperable prefix–origin bindings. RPKI addresses this by cryptographically binding prefixes to authorized ASes, enabling Route Origin Validation (ROV). Given RPKI’s critical role in Internet security, identifying the proportion of ASes that deploy ROV is a key research question. However, measuring ROV deployment is difficult due to limited visibility into private AS configurations. Existing methods suffer from low accuracy, restricted coverage, and the inability to detect hidden ASes whose behavior is masked by upstream ROV deployment. To address these limitations, we propose RIFT, a novel inference method based on temporal fingerprinting. RIFT leverages the insight that periodic ROA retrieval creates distinctive temporal patterns in the routing behavior of ROV-deployed ASes. Experiments show that RIFT achieves 94% accuracy and an F1 score of 0.88 in identifying ROV deployment.}
}


@inproceedings{DBLP:conf/icnp/WangCL25,
	author = {Xinshuo Wang and
                  Baihua Chen and
                  Lei Liu},
	title = {{LIBRA:} Multi-Path Transport in Distributed Training Data Center
                  Network},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--12},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192456},
	doi = {10.1109/ICNP65844.2025.11192456},
	timestamp = {Thu, 13 Nov 2025 08:55:56 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/WangCL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Effective networking is crucial for the efficient and cost-effective training of artificial intelligence (AI) models. Remote Direct Memory Access (RDMA) has gained widespread adoption due to its low latency, high throughput, and minimal CPU overhead. However, current RDMA implementations remain constrained by underlying Equal-Cost Multi-Path (ECMP) forwarding mechanisms, hindering the full exploitation of parallel paths within distributed training data centers. Furthermore, the rapid evolution of network interface bandwidth necessitates the re-evaluation of existing multi-path approaches due to ineffective scaling to high-speed network environments.This study introduces LIBRA, a novel multi-path transmission method for RDMA within high-speed network environments, enabling efficient utilization of abundant network paths in modern data centers. LIBRA integrates segment routing with packet-level multi-path spraying. Deterministic path assignment eliminates the need for sender-side path detection, simplifying load-balancing design and enhancing overall system efficiency. Furthermore, novel algorithms are proposed to decouple multi-path load balancing from congestion control (CC). These algorithms identify network congestion positions and implement tailored traffic control strategies through fine-grained control mechanisms. The feasibility of the hardware implementation for LIBRA was experimentally validated using FPGA and Tofino-based prototypes. Large-scale simulations demonstrate that LIBRA effectively and robustly leverages the rich network multi-paths within data centers, yielding a 2~4× reduction in tail latency for large message transmission scenarios. Our simulation code will be released as open source at the time of publication.}
}


@inproceedings{DBLP:conf/icnp/PengLWLC25,
	author = {Siyuan Peng and
                  Zhirong Liu and
                  Zedike Wei and
                  Lingang Li and
                  Yongrui Chen},
	title = {Poster: Bidirectional Physical-Layer {CTC} between Wi-Fi and {BLE}
                  {COTS} devices},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--3},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192402},
	doi = {10.1109/ICNP65844.2025.11192402},
	timestamp = {Thu, 13 Nov 2025 08:55:56 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/PengLWLC25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Bidirectional Cross-technology Communication (CTC) between WiFi and BLE demonstrates a wide range of applications prospects, such as temperature/humidity monitoring in smart home, LE-Audio relaying by WiFi APs, etc. However, existing CTC techniques between WiFi and BLE only support one-way transmission and are unable to be implemented on Commercial Off-The-Shelf (COTS) devices. This paper proposes BiCross, a bidirectional CTC scheme between WiFi and BLE which requires only software update on COTS devices. In essence, BiCross first presents a channel-specific symbol mapping technique to support all-channel reliable downlink CTC for BLE channel hopping. Then, BiCross leverages the spectrum scan capacity of WiFi Network Interface Cards (NICs) and analyzes the spectral characteristics of BLE frames to achieve uplink CTC. Finally, BiCross solves the problem of discontinuous and uncertain interval of spectrum analysis on commodity WiFi NICs through the design of BLE payload symbols and CRC-based error correction. The evaluation results demonstrate that BiCross achieves high reliability (downlink FRR > 95%, uplink FRR > 90%) and high throughput (downlink 854kbps, uplink 732kbps), and we showcase the application of BiCross on temperature acquisition in smart home scenario.}
}


@inproceedings{DBLP:conf/icnp/PengSSDCYJTL25,
	author = {Peng Peng and
                  Xun Sun and
                  Zhengtao Shen and
                  Feiyang Ding and
                  Jiawei Chen and
                  Lizhao You and
                  Weirong Jiang and
                  Yongping Tang and
                  Feng Luo},
	title = {HeTu: High-Performance Centralized Parallel Data-Plane Verification
                  for Hyper-Scale DCNs},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--11},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192409},
	doi = {10.1109/ICNP65844.2025.11192409},
	timestamp = {Thu, 13 Nov 2025 08:55:56 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/PengSSDCYJTL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Existing data-plane verifiers face severe performance challenges in verifying hyper-scale underlay data center networks (DCNs) – centralized verifiers often fail to fully exploit the parallelism offered by the modern multi-core CPUs, while distributed verifiers suffer from high overhead due to task distribution and inter-node communication. To overcome these limitations, this paper introduces HeTu, a high-performance centralized parallel data-plane verifier specifically for verifying hyper-scale underlay DCNs. HeTu achieves ultra-fast verification through three key designs: (1) a fully parallel verification framework with small graph construction overhead, (2) a new binary decision diagram management strategy that enables full parallelism by using separated storage and selectively indexing and caching network-level predicates to reduce redundant operations, and (3) an optimized forwarding graph model that aggregates parallel tasks to eliminate redundant computation. Extensive evaluations on synthetic FatTree and large-scale production datasets show that HeTu outperforms state-of-the-art algorithms in runtime by 100× to 6000×, demonstrating its superior scalability and efficiency in data-plane verification of hyper-scale DCNs.}
}


@inproceedings{DBLP:conf/icnp/HuangSLWZZZY25,
	author = {Jiawei Huang and
                  Jing Shao and
                  Sitan Li and
                  Zirong Wei and
                  Shengwen Zhou and
                  Wenlu Zhang and
                  Yilin Zhao and
                  Jin Ye},
	title = {Borrow Counter: {A} Generic Sketch Framework for Non-uniform Flow
                  Estimation},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--11},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192377},
	doi = {10.1109/ICNP65844.2025.11192377},
	timestamp = {Sun, 01 Feb 2026 13:27:01 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/HuangSLWZZZY25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Compact data structures, such as sketches and Bloom filters, are extensively studied by researchers in network measurements. Since the fixed-size counter cannot adapt to the non-uniform distribution of real network traffic, a class of frameworks has been proposed to improve memory efficiency and measurement accuracy of sketches and Bloom filters. However, existing frameworks either extend the counting range with a certain probability, which introduces errors, or utilize predefined hierarchical structures that are not suitable for various scenarios. In this paper, considering the non-uniform flow distribution, we propose a new framework called Borrow Counter, whose key idea is to borrow idle bits from adjacent counters and record more significant bits to extend the counting range, while still ensuring accuracy. It shows good generality and can be applied to most sketches and Bloom filters. Extensive experimental results demonstrate that, compared to state-of-the-art frameworks, Borrow Counter improves the accuracy by up to 32%.}
}


@inproceedings{DBLP:conf/icnp/WangMX25,
	author = {Huayi Wang and
                  Jingfan Meng and
                  Jun Xu},
	title = {OddEEC: {A} New Sketch Technique for Error Estimating Coding},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--11},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192398},
	doi = {10.1109/ICNP65844.2025.11192398},
	timestamp = {Thu, 13 Nov 2025 08:55:56 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/WangMX25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Error estimating coding (EEC) is a standard technique for estimating the number of bit errors during packet transmission over wireless networks. In this paper, we propose OddEEC, a novel EEC scheme. OddEEC is a nontrivial adaptation of a data sketching technique named Odd Sketch to EEC, addressing new challenges therein by its bit sampling technique and maximum likelihood estimator. Our experiments show that OddEEC overall achieves comparable estimation accuracy as competing schemes such as gEEC and mEEC, with much smaller decoding complexity.}
}


@inproceedings{DBLP:conf/icnp/SaimAHLM25,
	author = {Saim and
                  Saad Ullah Akram and
                  Erkki Harjula and
                  Lauri Lov{\'{e}}n and
                  Hassan Mehmood},
	title = {MLOps for Medical Imaging: {A} Cloud-Edge architecture for Experiment
                  Tracking and Model Evaluation},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--6},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192460},
	doi = {10.1109/ICNP65844.2025.11192460},
	timestamp = {Thu, 13 Nov 2025 08:55:56 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/SaimAHLM25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Artificial intelligence (AI) is increasingly transforming the healthcare sector by enabling advanced automated decision-making. However, implementing Machine Learning (ML) systems in medical imaging applications presents significant challenges, such as ensuring consistent results across different environments, maintaining comprehensive records of experimental processes, and establishing reliable methods for model comparison and evaluation. These issues become more evident as medical AI shifts towards a hybrid Cloud-Edge Continuum (CEC), adding complexity to workload orchestration and performance monitoring across diverse infrastructures. To address these challenges, this work introduces a modular Edge Micro Data Centre (EMDC) architecture that supports a scalable experiment tracking framework designed for AI model deployments in healthcare. The approach extends MLflow with a domain-specific module for medical image segmentation, incorporating several clinically relevant performance metrics. The EMDC architecture enables distributed processing and performance monitoring within a hybrid CEC environment. By aligning MLOps principles with CEC infrastructure, the proposed system facilitates reliable and scalable AI integration into the healthcare sector.}
}


@inproceedings{DBLP:conf/icnp/HeiZLGLSW25,
	author = {Chenyang Hei and
                  Yi Zhao and
                  Fuliang Li and
                  Chengxi Gao and
                  Tongrui Liu and
                  Xiuzhu Sha and
                  Xingwei Wang},
	title = {Canvas: Scalable Collective Communication Scheduling for Large-Scale
                  {GPU} Clusters},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--11},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192367},
	doi = {10.1109/ICNP65844.2025.11192367},
	timestamp = {Thu, 13 Nov 2025 08:55:56 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/HeiZLGLSW25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {State-of-the-art deep learning models rely on large GPU clusters and various parallelism strategies, which in turn depend on collective communication (CC) operators to synchronize data. While vendor libraries (e.g., NCCL, RCCL) provide standard CC algorithms, they often suffer from bandwidth bottlenecks in imbalanced topologies. Recent synthesis-based methods improve performance but face three key limitations: poor scalability due to the combinatorial explosion of scheduling space, lack of support for multistage execution, and suboptimal communication throughput. We propose Canvas, a scalable and near-optimal CC scheduling framework that addresses these challenges. Canvas introduces: (1) Hierarchical synthesis to decompose the global scheduling problem into tractable subproblems for scalability. (2) Collective decomposition to enable structured, multi-stage algorithm generation. (3) Cross-micro-batch pipeline scheduling to parallelize communication across micro-batches and maximize link utilization. Evaluations show that Canvas achieves up to 1.98× bandwidth speedup over TACCL and 3.56× over TE-CCL, and synthesizes algorithms for 512-GPU topologies within 1.77 hours, whereas TACCL fails to produce results within 24 hours.}
}


@inproceedings{DBLP:conf/icnp/DeccioRBC25,
	author = {Casey T. Deccio and
                  Robert Richardson and
                  Nathaniel Bennett and
                  Nathan Craddock},
	title = {Modeling {DNS} Queries and Caching to Evaluate the Merits of {QNAME}
                  Minimization},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--11},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192453},
	doi = {10.1109/ICNP65844.2025.11192453},
	timestamp = {Thu, 13 Nov 2025 08:55:56 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/DeccioRBC25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {QNAME minimization is an extension to the DNS protocol, designed to allow DNS resolvers to prevent disclosure of DNS activity beyond that which is necessary for resolution. Since it was originally proposed in 2014, QNAME minimization has been incorporated into most of the well-known DNS resolvers. But the question remains: how effective is QNAME minimization at preserving privacy in practice? We answer that question by creating a model that defines DNS privacy roles and quantifies information leakage to third parties. We apply that model to DNS query data from a large university. We observe that QNAME minimization adds modest privacy gains and suggest that its benefits be considered alongside its costs.}
}


@inproceedings{DBLP:conf/icnp/MaZLY25,
	author = {Chongxi Ma and
                  Chengyun Zhang and
                  Long Luo and
                  Hongfang Yu},
	title = {Poster: Simulation-Guided Strategy Generation for Intent-Aware Distributed
                  LLMs Training},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--3},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192336},
	doi = {10.1109/ICNP65844.2025.11192336},
	timestamp = {Thu, 13 Nov 2025 08:55:56 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/MaZLY25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Training distributed large language models (LLMs) for diverse user intents is challenging due to a high-dimensional, hybrid strategy space and heterogeneous workloads. We present SG2, a simulation-guided strategy generation framework that tackles intent-aware distributed LLM training by unifying Bayesian Optimization with a simulation-based evaluation loop. By leveraging near-realistic performance and intent-satisfaction metrics in simulation, SG2 iteratively refines candidate training strategies before real deployment, significantly reducing exploration cost and failure risk. Experiments on heterogeneous LLM training workloads show that SG2 consistently achieves higher intent-satisfaction rates and better multi-objective trade-offs than baselines, demonstrating its effectiveness for intent-aware distributed LLM training.}
}


@inproceedings{DBLP:conf/icnp/BinYahyaSSMYWLG25,
	author = {Manaf Bin{-}Yahya and
                  Amir Shani and
                  Hossein Shafieirad and
                  Seyed Hossein Mortazavi and
                  Chen Ying and
                  Aaron Wang and
                  Geng Li and
                  Majid Ghaderi},
	title = {Symphony: Collective Coordination in Multi-Tenant {GPU} Clusters},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--13},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192450},
	doi = {10.1109/ICNP65844.2025.11192450},
	timestamp = {Thu, 13 Nov 2025 08:55:56 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/BinYahyaSSMYWLG25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Multi-tenant GPU clusters are designed to concurrently run multiple distributed ML training workloads. However, frequent data transfers among GPUs via collective operations can slow down training, as collectives from different tenants compete for network bandwidth. Recent work (e.g., CASSINI) has considered collective coordination to prevent network contention, but primarily focused on static job-level optimizations at deployment time, oblivious to runtime network conditions and the specific traffic pattern of each workload. In this paper, we present Symphony, an application-layer solution that dynamically coordinates collective operations across tenants at runtime. Symphony integrates seamlessly with existing clusters with minimal modifications to the collective communication library and includes a lightweight online scheduling mechanism that requires no advance information about the workloads or their collectives. We evaluate Symphony using both a real GPU testbed implementation and trace-driven simulations. Specifically, using realistic ML workloads in our testbed, we observe improvements of up to 13.2% in average communication time and 9.6% in training time compared to state-of-the-art solutions.}
}


@inproceedings{DBLP:conf/icnp/NiuZZXYH25,
	author = {Zihan Niu and
                  Menghao Zhang and
                  Jue Zhang and
                  Renjie Xie and
                  Yuan Yang and
                  Xiaohe Hu},
	title = {{THEMIS:} Addressing Congestion-Induced Unfairness in Long-Haul {RDMA}
                  Networks},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--13},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192376},
	doi = {10.1109/ICNP65844.2025.11192376},
	timestamp = {Thu, 25 Dec 2025 12:47:55 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/NiuZZXYH25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {RDMA is promising for enhancing the performance of cross-datacenter (DC) services. However, deploying RDMA over wide-area networks introduces severe congestion control unfairness, primarily due to asymmetric congestion feedback delays between inter-DC flows and intra-DC flows. As a result, intra-DC flows often bear the full burden of congestion response, leading to drastically increased flow completion times (FCT). In this work, we identify two key forms of unfairness — near-source and near-destination — depending on whether congestion occurs near the sender or receiver of inter-DC flows. Based on this, we propose THEMIS, a fairness maintenance patch for long-haul RDMA networks. To mitigate near-source unfairness, THEMIS devises a Proactive Notification Point to shorten the congestion feedback loop within a single DC. To alleviate near-destination unfairness, THEMIS introduces a Temporary Reaction Point to temporarily slow down the target inter-DC flow until the sender receives the corresponding congestion feedback. We implement an open-source prototype of THEMIS, and evaluate it on both real-world testbed and large-scale simulations. Compared to DCQCN, Annulus and BiCC, THEMIS reduces the intra-DC FCT by up to 79.2%, 63.6% and 55.6%, and decreases overall FCT by up to 61.2%, 31.9% and 59.5% respectively.}
}


@inproceedings{DBLP:conf/icnp/LiHLLGSW25,
	author = {Ziming Li and
                  Chenyang Hei and
                  Fuliang Li and
                  Tongrui Liu and
                  Chengxi Gao and
                  Xiuzhu Sha and
                  Xingwei Wang},
	title = {TuCCL: Tailored and Unified Configuration Optimizations for High-Performance
                  Collective Communication Library},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--11},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192370},
	doi = {10.1109/ICNP65844.2025.11192370},
	timestamp = {Thu, 13 Nov 2025 08:55:56 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/LiHLLGSW25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Modern distributed training systems face escalating communication bottlenecks as GPU clusters scale to accommodate large models. While collective communication libraries and automated synthesizers address algorithmic efficiency, they suffer from three critical limitations including labor-intensive manual intervention requirement, overreliance on predefined input optimization, and suboptimal isolated configuration optimization. To solve these problems, we present TuCCL, a systematic framework that co-optimizes communication algorithms and runtime parameters through three innovations: Topology-Aware Sketch Generation that automatically produces high-performance primitives, Hierarchical Configuration Optimization modeling nonlinear parameter-performance relationships, and Multi-phase Resource-Aware Configuration Optimization enabling joint configuration tuning with adaptive search space pruning. Evaluations demonstrate TuCCL’s superiority over state-of-the-art systems with 1.75x–11.49x bandwidth improvements for AllGather/AllReduce on NVIDIA V100/A100 clusters, 90.2% faster configuration search than grid methods, and 1.22x-2.52x end-to-end training speedups across diverse model scales.}
}


@inproceedings{DBLP:conf/icnp/HuZLLPH25,
	author = {Yuxuan Hu and
                  Jiao Zhang and
                  Dexuan Liao and
                  Yuan Li and
                  Yongchen Pan and
                  Tao Huang},
	title = {Valve: Scalable {RDMA} with Gap-based Cache Control Middleware for
                  Data Center Networks},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--12},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192330},
	doi = {10.1109/ICNP65844.2025.11192330},
	timestamp = {Sat, 15 Nov 2025 13:46:43 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/HuZLLPH25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Remote Direct Memory Access (RDMA) has become a cornerstone technology in Data Center Networks (DCNs). However, DCNs have expanded substantially, leading to severe connection scalability issues for RDMA. The critical reason behind these issues stems from frequent cache misses on RDMA NICs (RNICs) when handling numerous Queue Pair (QP) connections. Cache misses require time-consuming retrievals from the host via PCIe, resulting in a degradation in RDMA performance. Existing software solutions primarily aim to alleviate QP Context (QPC) cache pressure, while hardware solutions incur prohibitive costs. In this paper, we identify Work Queue Element (WQE) cache, rather than QPC cache, as the fundamental bottleneck limiting connection scalability. Hence, we propose a software middleware, Valve, designed to mitigate cache misses through WQE cache control. Valve regulates WQE posting to control WQE cache by monitoring RNIC cache usage and adaptively adjusting the gap of WQE posting. Valve boasts ease of deployment, requiring the addition of approximately 1000 lines of code, and incurs low CPU overhead. Valve maintains peak performance of RNIC throughput regardless of the number of QPs and considerably reduces observable cache misses (such as ICM, MTT, and MPT cache misses) by 2.8× to 3.1× compared to XRC and DCT.}
}


@inproceedings{DBLP:conf/icnp/HuangXWPLZQZC25,
	author = {Sijiang Huang and
                  Xiaohui Xie and
                  Mowei Wang and
                  Lingfeng Peng and
                  Cong Li and
                  Yong Zhang and
                  Yingjie Qin and
                  Liang Zhang and
                  Yong Cui},
	title = {Modeling Flow-level Traffic Demand for Network Performance Evaluation
                  and Optimization},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--13},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192364},
	doi = {10.1109/ICNP65844.2025.11192364},
	timestamp = {Thu, 13 Nov 2025 08:55:56 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/HuangXWPLZQZC25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Modeling traffic demand at the flow level is essential for accurate network performance evaluation and optimization. However, despite its prevalence, the common practice is oversimplified and relies on unsubstantiated assumptions of traffic homogeneity and independent arrivals. In this paper, we analyze real-world traffic data collected from production environments to challenge these assumptions. Our findings reveal notable fidelity issues in the common practice, compromising the reliability of network performance evaluation and optimization. To address these limitations, we introduce Encore, a flow-level traffic demand modeling framework that captures key traffic characteristics and generates high-fidelity synthetic traces. Encore adopts a divide-and-conquer strategy, employing tailored machine learning models for distributional and sequential modeling, along with problem-specific enhancements. Systematic evaluations demonstrate that Encore outperforms existing traffic modeling methods in terms of accuracy and coverage in distribution modeling, and fidelity in sequential modeling. In addition to accurately restoring key characteristics of real traffic, Encore improves simulation performance consistency by a factor of 4 to 17 over the common practice. Moreover, Encore achieves a ~0.88 correlation in parameter ranking compared to the ground truth, showcasing its practical utility for network optimization.}
}


@inproceedings{DBLP:conf/icnp/HeyeIPW25,
	author = {David Heye and
                  Sahi Islam and
                  Jan Pennekamp and
                  Klaus Wehrle},
	title = {Poster: Transport Security Orchestration Using {DNS}},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--3},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192410},
	doi = {10.1109/ICNP65844.2025.11192410},
	timestamp = {Thu, 25 Dec 2025 12:47:55 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/HeyeIPW25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Communication networks enable the exchange of data with varying sensitivity, from non-sensitive public files to highly confidential healthcare or financial records. Cryptographic protection introduces significant computational and communication overhead. While lightweight ciphers have been proposed to reduce this burden, they compromise security and are unsuitable for sensitive data. We propose a system that enables adaptive security by embedding service sensitivity information in the Domain Name System (DNS), allowing peers to select appropriate cryptographic primitives based on data requirements. This approach ensures adequate protection while minimizing overhead. Additionally, it can be seamlessly integrated into existing networks without additional hardware. Initial results indicate improved throughput and reduced computational load on hosts.}
}


@inproceedings{DBLP:conf/icnp/AokiY25,
	author = {Keita Aoki and
                  Miki Yamamoto},
	title = {Poster: Time Window {ECN} Filtering for Multiple-bottleneck {RDMA}
                  Congestion Control},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--3},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192331},
	doi = {10.1109/ICNP65844.2025.11192331},
	timestamp = {Thu, 13 Nov 2025 08:55:56 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/AokiY25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In RDMA data center networks with multiple bottlenecks, a sender may overestimate level of congestion because ECNs are marked independently at multiple bottleneck switches along the path. This congestion overestimation problem is difficult to address because the sender cannot identify where congestion signals are originated. In this paper, we propose a selective ECN marking method in which each switch filters ECN marks based on local congestion severity. Simulation results show that our method improves fairness and prevents excessive rate reduction in multiple-bottleneck scenarios.}
}


@inproceedings{DBLP:conf/icnp/KimL25,
	author = {Dong{-}Hoon Kim and
                  Jae{-}Han Lim},
	title = {CodeScatter: Distortion-Aware Collision Resolution for Concurrent
                  Multiple Access in Backscatter Networks},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--11},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192442},
	doi = {10.1109/ICNP65844.2025.11192442},
	timestamp = {Thu, 13 Nov 2025 08:55:56 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/KimL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Concurrent transmission with collision resolution has been considered as the multiple access solution in backscatter networks. However, designing practical collision resolution mechanisms in backscatter networks is challenging for the following reasons. First, interference from multiple tags accumulates, resulting in strong and complicated inter-tag interference. Second, transmitted signals are distorted by various factors (e.g., imperfect digital filter), which have not been considered in previous collision resolution schemes. Due to these distortions, tag-side mechanism like orthogonal codes, which assume undistorted conditions, are not effective for resolving collision at the receiver. Third, variation in received signal levels across tags often degrades performance in concurrent transmissions (i.e., near-far problem). Although transmit power control was proposed as a solution, it increases tag complexity and energy consumption. To address the challenges, we propose CodeScatter, a distortion-aware design for collision resolution that is robust to near-far problem in backscatter networks. The innovative features of CodeScatter are 1) distortion-aware design and 2) robustness to near-far problem without transmit power control. CodeScatter achieves these features by employing two mechanisms: 1) Distortion-aware Successive Decoding (DSD), which iteratively isolates individual tag signals while accounting for distortions and 2) Distortion-aware Orthogonal Codes (DOC), which ensures orthogonality even in the presence of distortions. To our knowledge, CodeScatter is the first distortion-aware design for collision resolution in backscatter networks. We implement a prototype using COTs RF switch and USRPN210. Experimental results demonstrate that CodeScatter outperforms previous proposals in terms of BER and throughput.}
}


@inproceedings{DBLP:conf/icnp/ZhouLHYSCWFS25,
	author = {Jiasheng Zhou and
                  Ying Liu and
                  Lin He and
                  Yifan Yang and
                  Xiaoyi Shi and
                  Daguo Cheng and
                  Chentian Wei and
                  Yun Fan and
                  Guanglei Song},
	title = {SubRecon: Efficient Internet-Wide IPv6 Subnet Discovery and Its Applications},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--12},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192387},
	doi = {10.1109/ICNP65844.2025.11192387},
	timestamp = {Thu, 13 Nov 2025 08:55:56 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/ZhouLHYSCWFS25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The vastness of the IPv6 address space has led to the common practice of allocating prefixes to end users rather than individual addresses. Users can assign these prefixes as a single subnet or divide them into multiple subnets for different purposes. Allocation strategies vary significantly in terms of prefix granularity, and identifying the actual granularity of subnet assignments is crucial for improving measurement efficiency, accuracy, and for better IPv6 network management. However, no existing method can discover IPv6 subnets at an Internet-Wide scale.To this end, we propose SubRecon, an Internet-Wide IPv6 subnet discovery system. SubRecon consists of two key phases: subnet delimitation and target expansion. In the subnet delimitation phase, we perform a systematic scan across the entire IPv6 address space without relying on any existing seed dataset. This phase adopts a top-down approach, probing prefixes from the shortest to the longest in a hierarchical manner. At each level, we recursively refine prefixes and discard sub-prefixes that do not meet the convergence condition. This pruning strategy eliminates redundant probes in unallocated regions, significantly reducing the search space and improving probing efficiency. To further improve coverage, the target expansion phase leverages the active address dataset as an auxiliary input. It identifies active addresses not covered by previously discovered subnets, expands them into new candidate target prefixes, and performs another round of subnet delimitation. This helps enhance the completeness and coverage of the final discovered subnet set. Experimental results show that SubRecon discovers 8,381,974 IPv6 subnets across 14,147 autonomous systems, and the resulting subnet list can serve as high-quality input for topology discovery. Additionally, during the subnet discovery process, SubRecon identifies a large number of last-hop router interfaces, discovering approximately 10 million more than the current state-of-the-art methods.}
}


@inproceedings{DBLP:conf/icnp/WangWSH25,
	author = {Bichen Wang and
                  Jingzhou Wang and
                  Yu{-}E Sun and
                  He Huang},
	title = {Copo: Joint Cost and Performance Optimization for Task Placement in
                  Geo-Distributed Clouds},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--12},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192448},
	doi = {10.1109/ICNP65844.2025.11192448},
	timestamp = {Tue, 18 Nov 2025 15:28:32 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/WangWSH25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {To provide a wide range of services for global users, cloud providers tend to build geo-distributed regions all over the world. With the rapid growth of cloud services, massive workloads and inter-region traffic have been introduced to current cloud networks, resulting in huge expenditure. Therefore, it is essential for a cloud provider to carefully place tasks and transfer traffic among regions to minimize the total operating costs. Existing solutions typically focus on optimizing either placement costs (e.g., computing resources, and electricity) or bandwidth costs, and overlook performance metrics, which leads to increased overall operating costs or lower user QoS. To bridge the gap, this paper proposes Copo, a joint cost and performance optimization framework for tenant task placement in geo-distributed clouds. We first formalize the cost optimization problem as an undetermined multi-commodity flow problem which has never been studied before, and propose a graph transformation algorithm to reduce the complexity. Then we combine the cost optimization with the performance optimization as the final framework. The key idea of Copo is leveraging KKT conditions to transfer the bi-level optimization to a single level. To efficiently acquire the joint task placement and traffic transfer decisions, we leverage McCormick Envelope-based relaxation to design a randomized rounding-based approximation algorithm. Extensive experiments based on real-world data show the superior cost-efficiency and performance of Copo compared with state-of-the-art solutions.}
}


@inproceedings{DBLP:conf/icnp/LiaoWYZLLZCW25,
	author = {Lida Liao and
                  Yuhan Wu and
                  Jiashuo Yu and
                  Longlong Zhu and
                  Hongyan Liu and
                  Junjie Lin and
                  Dong Zhang and
                  Xiang Chen and
                  Chunming Wu},
	title = {EffiMatch: Enabling Fast and Accurate Learning-based Packet Classification},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--12},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192436},
	doi = {10.1109/ICNP65844.2025.11192436},
	timestamp = {Thu, 13 Nov 2025 08:55:56 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/LiaoWYZLLZCW25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Learning-based Packet Classification methods reduce memory overhead by using lightweight Recursive Model Index(RMI) structures to limit the search range, followed by linear matching. However, they face a trade-off: complex RMI structures achieve smaller search ranges but slow down lookup, while simpler ones are faster but require larger scans. In this paper, we propose EffiMatch, a parallel multi-model lookup architecture aimed at resolving the trade-off between RMI complexity and linear search range in learning-based index systems. We propose two key designs: 1) We design a partitioning strategy called Distribution-Distance Partitioning (DDP), which groups data points with similar trends into the same segment. Combined with parallel lookup, this reduces the linear search range while maintaining high lookup speed. 2) We propose a more fine-grained binarization method, Base-Index Representation (BI), which approximates floating-point operations using integers. This method further reduces the search range without increasing model complexity. Experimental results show that EffiMatch reduces the linear search range by 26.84% using lower-complexity RMI models, which improves lookup speed by up to 6× and reduces construction time by up to 4 orders of magnitude compared to state-of-the-art LPC methods.}
}


@inproceedings{DBLP:conf/icnp/ChenYLZZLZZLHZW25,
	author = {Xiang Chen and
                  Xin Yao and
                  Jiayu Li and
                  Longlong Zhu and
                  Linying Zheng and
                  Hongyan Liu and
                  Jianshan Zhang and
                  Dong Zhang and
                  Xuan Liu and
                  Qun Huang and
                  Haifeng Zhou and
                  Chunming Wu},
	title = {Carrera: Enabling High-Performance eBPF-based Sketches in Network
                  Measurement},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--12},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192430},
	doi = {10.1109/ICNP65844.2025.11192430},
	timestamp = {Thu, 13 Nov 2025 08:55:56 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/ChenYLZZLZZLHZW25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {To achieve dynamic network measurement, trends build sketches on eBPF to avoid service interruptions. However, existing eBPF-based sketches suffer from high CPU consumption, leading to poor throughput and high latency and making them hard to measure high-speed traffic. Optimizing their performance requires users to refactor codes based on each sketch’s characteristics on eBPF, which is highly complex and time-consuming.In this paper, we argue that users should write sketches without concerning low-level eBPF performance optimizations, with the deployment automatically activating cross-sketch performance optimizations. We present Carrera, a library that offers domain-specific optimizations for eBPF-based sketches. Our contributions are (1) systematically analyzing the performance bottlenecks of eBPF-based sketches through microbenchmarks, (2) identifying practical optimizations, including hardware offloading, SIMD-accelerated hashing, traffic-aware flow index caching, prefetched randomization, and active data collection, to address the identified bottlenecks in eBPF-based sketches, (3) evaluating these optimizations with state-of-the-art sketches and demonstrating that Carrera improves throughput by up to 65% and reduces latency by up to 93% via testbed experiments.}
}


@inproceedings{DBLP:conf/icnp/HuXCHHYL25,
	author = {Guangwu Hu and
                  Xi Xiao and
                  Zongchen Cai and
                  Cheng Huang and
                  Yuzhang Huang and
                  Yongjie Yin and
                  Wei Liu},
	title = {{CLRDMMF:} {A} Contrastive Learning-based Rumor Detection Model with
                  Multi-feature Fusion},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--6},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192457},
	doi = {10.1109/ICNP65844.2025.11192457},
	timestamp = {Tue, 18 Nov 2025 14:49:38 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/HuXCHHYL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Current social media platforms provide conditions for the widespread propagation of rumors, which can harm public opinion and even social stability. To automatically detect rumors, rumor detection methods employ graph neural networks to extract structural features in the rumor propagation process and achieve good classification performance. However, these methods have the following three limitations, i.e., the model architecture, information utilization and training methods. In order to overcome these limitations, in this paper, we design a Contrastive Learning-based Rumor Detection Model with Multi-feature Fusion (CLRDMMF). First, CLRDMMF designs a powerful GNN propagation structural feature extractor called Cross-directional Attention Graph Isomorphism Network (CA-GIN). Then, CLRDMMF extracts and fuses multiple kinds of features from the propagation tree, source text and Kernel Subtree. After that, we build the classification model with both the supervised and unsupervised contrastive learning. Finally, we conduct evaluation experiments and demonstrate that the proposed method outperforms the best baseline with 1.9% and 2.8% in accuracy on two datasets.}
}


@inproceedings{DBLP:conf/icnp/XiaYWYRYL25,
	author = {Linhan Xia and
                  Mingzhan Yang and
                  Jingjing Wang and
                  Ziwei Yan and
                  Yakun Ren and
                  Guo Yu and
                  Kai Lei},
	title = {Mamba4Net: Distilled Hybrid Mamba Large Language Models For Networking},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192368},
	doi = {10.1109/ICNP65844.2025.11192368},
	timestamp = {Thu, 13 Nov 2025 08:55:56 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/XiaYWYRYL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Transformer-based large language models (LLMs) are increasingly being adopted in networking research to address domain-specific challenges. However, their quadratic time complexity and substantial model sizes often result in significant computational overhead and memory constraints, particularly in resource-constrained environments. Drawing inspiration from the efficiency and performance of the Deepseek-R1 model within the knowledge distillation paradigm, this paper introduces Mamba4Net, a novel cross-architecture distillation framework. Mamba4Net transfers networking-specific knowledge from transformer-based LLMs to student models built on the Mamba architecture, which features linear time complexity. This design substantially enhances computational efficiency compared to the quadratic complexity of transformer-based models, while the reduced model size further minimizes computational demands, improving overall performance and resource utilization. To evaluate its effectiveness, Mamba4Net was tested across three diverse networking tasks: viewport prediction, adaptive bitrate streaming, and cluster job scheduling. Compared to existing methods that do not leverage LLMs, Mamba4Net demonstrates superior task performance. Furthermore, relative to direct applications of transformer-based LLMs, it achieves significant efficiency gains, including a throughput 3.96 times higher and a storage footprint of only 5.48% of that required by previous LLM-based approaches. These results highlight Mamba4Net’s potential to enable the cost-effective application of LLM-derived knowledge in networking contexts. The source code is openly available to support further research and development.}
}


@inproceedings{DBLP:conf/icnp/CapovaMLD25,
	author = {Cveta Capova and
                  Andrea Morichetta and
                  Anna Lackinger and
                  Schahram Dustdar},
	title = {Intent-to-Learning Translation for Computing Continuum Management},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--6},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192441},
	doi = {10.1109/ICNP65844.2025.11192441},
	timestamp = {Sun, 01 Feb 2026 13:27:01 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/CapovaMLD25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper offers a solution to generate concrete goals for automating the fulfillment of user intents in the computing continuum. The computing continuum guarantees a flexible infrastructure for services at the cost of more complex handling. Our proposed method innovates the state of the art, helping build performative automated strategies through the translation of service owner intents into concrete targets. We improve on existing intent-based systems by offering support for multi-domain infrastructures. Furthermore, we go beyond current computing continuum management solutions, offering full automation by generating concrete targets for the continuum of automated agents. We achieve that through a multi-agent system built on Large Language Models (LLMs) that translates high-level business intents into executable Reinforcement Learning (RL) environments. By leveraging infrastructure representations in the form of Knowledge Graphs, the framework identifies which system components require adaptation and estimates the target metric values needed to fulfill the intent. We evaluate it on a realistic use case with promising results. We can deploy a fully working RL agent to manage network and computing resources, achieving a success rate higher than 80% after preliminary training.}
}


@inproceedings{DBLP:conf/icnp/Gao25,
	author = {Shen Gao},
	title = {Cloud Network Convergence Disaster Recovery Approach for Reliable
                  Virtual Network Function},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--6},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192394},
	doi = {10.1109/ICNP65844.2025.11192394},
	timestamp = {Thu, 13 Nov 2025 08:55:56 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/Gao25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The evolution of Network Function Virtualization (NFV) has transformed telecommunications by shifting from Physical Network Functions (PNFs) to Virtual Network Functions (VNFs), offering improved flexibility, scalability, and resource efficiency. However, this transition has also introduced new challenges, particularly vulnerabilities stemming from Cloud Operating System failures. Traditional NFV reliability measures, which focus on resource allocation and fault recovery, have struggled to bridge the reliability gap between cloud infrastructure and network services. Addressing these limitations, this paper proposes a novel disaster recovery framework that integrates cloud technologies, including multi-region and multi-Availability Zone (AZ) architectures, to significantly enhance VNF reliability. The framework is designed to leverage the fault tolerance and redundancy of cloud architectures for improved disaster recovery performance in VNFs. We evaluate its feasibility and effectiveness through a comparative analysis of disaster recovery performance between traditional NFV setups and the proposed framework. Experimental results show that the 3AZ architecture improves Recovery Time Objective (RTO) through fully automated recovery processes and a fault-isolated design, while the 2AZ with Arbiter setup also achieves notable RTO improvements.}
}


@inproceedings{DBLP:conf/icnp/ChoiJCB25,
	author = {Dongrak Choi and
                  Yonghoon Jeong and
                  Yubin Choi and
                  Saewoong Bahk},
	title = {Demo: {A} Programmable High-Throughput Duplex {DC-PLC} Testbed for
                  Power and Data Integration},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--3},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192329},
	doi = {10.1109/ICNP65844.2025.11192329},
	timestamp = {Thu, 13 Nov 2025 08:55:56 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/ChoiJCB25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Interest in Direct Current Power Line Communication (DC-PLC) is growing as industries seek to reduce wiring complexity and cost by combining power and data over a single medium. A programmable DC-PLC testbed is developed to enable power transfer and bidirectional communication over a shared DC power line bus. The system employs a master–slave scheme in half-duplex mode under a flexible MAC protocol, using Voltage Polarity Modulation (VPM) for downlink and Current Amplitude Modulation (CAM) for uplink. Implemented with low-cost microcontrollers, the master and slave are designed as modular units for easy connection and expansion. The platform achieves approximately 100 kbps throughput in both directions and demonstrates reliable operation with a simple polling-based MAC protocol, highlighting its potential for future DC-PLC research and applications.}
}


@inproceedings{DBLP:conf/icnp/GhalebDPB25,
	author = {Rami Ghaleb and
                  Mithun Dharmaraj and
                  Srikar Prayaga and
                  Tarun Banka},
	title = {Demo: Conversational {AI} Agent for {ML} Infrastructure Monitoring
                  and Analysis},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--3},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192362},
	doi = {10.1109/ICNP65844.2025.11192362},
	timestamp = {Thu, 13 Nov 2025 08:55:56 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/GhalebDPB25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We present a conversational AI framework for monitoring and analysis of distributed AI/ML infrastructure based on a multi-agent architecture. The system incorporates specialized agents for topology discovery, health assessment, network flow analysis, and root cause analysis (RCA), accessible through a natural language interface. An agent orchestration component parses and routes user queries, allowing the platform to support a range of cluster observability and troubleshooting tasks using both sequential and parallel agent workflows. Each agent interacts with dedicated analytical microservices via Model Context Protocol (MCP), enabling modular and extensible evaluation of infrastructure state. We detail the system architecture, agent design, setup used for experiments and discuss the implications of conversational AI agents for automated RCA and operational efficiency in monitoring and troubleshooting large-scale ML infrastructure.}
}


@inproceedings{DBLP:conf/icnp/WeiLHCZ25,
	author = {Chentian Wei and
                  Ying Liu and
                  Lin He and
                  Daguo Cheng and
                  Jiasheng Zhou},
	title = {Gungnir: Autoregressive Model for Unified Generation of IPv6 Fully
                  Responsive Prefixes},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--12},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192425},
	doi = {10.1109/ICNP65844.2025.11192425},
	timestamp = {Thu, 13 Nov 2025 08:55:56 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/WeiLHCZ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the widespread adoption of IPv6, its vast address space presents significant challenges for network asset discovery. Traditional exhaustive scanning approaches are no longer practical, while strategies based on target generation algorithms are increasingly undermined by the existence of Fully Responsive Prefixes (FRPs)—prefixes in which all addresses appear responsive to probing. FRPs distort scanning results, introducing bias and inefficiency. Existing FRP probing techniques suffer from limited scalability, poor accuracy, and restricted applicability in large-scale IPv6 environments.To this end, we propose Gungnir, a multi-protocol unified FRP probing algorithm based on autoregressive semantic modeling. Gungnir captures the intricate relationships between FRP patterns and their influencing factors through a deep semantic learning architecture. It leverages prefix inference and a granularity correction mechanism to accurately predict and validate FRPs, while mitigating errors from incorrect prefix-length estimation. Extensive experiments demonstrate that Gungnir outperforms state-of-the-art techniques, achieving up to 27× higher efficiency, 4.2× wider address space coverage, and broader coverage of both autonomous systems and routing prefixes under the same probing budget. Beyond performance, we further analyze the service and port distributions of the discovered FRPs, uncovering operational patterns and potential security implications. These insights offer valuable guidance for IPv6 measurement, address discovery, and network defense.}
}


@inproceedings{DBLP:conf/icnp/MGSB25,
	author = {Preetham M. and
                  Jit Gupta and
                  Rahul Singh and
                  Tarun Banka},
	title = {Demo: Real-Time Collective Communication Log Analyzer for Distributed
                  {AI/ML} Workloads},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--3},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192446},
	doi = {10.1109/ICNP65844.2025.11192446},
	timestamp = {Thu, 13 Nov 2025 08:55:56 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/MGSB25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We present a log analytics framework that collects collective communication logs from real-time distributed AI/ML workloads such as Large Language Models training, finetuning and inferencing jobs. It is designed to handle massive log volumes from frameworks such as NVIDIA’s Collective Communication Library (NCCL) during distributed GPU operations, the framework ingests heterogeneous log streams as these logs are often the first indicators of faults in the end-to-end path. Using NLP-based parsing, log template clustering, temporal correlation for related logs, and anomaly pattern detection, it links critical log events to performance metrics across layers which enable fault localization in GPU-to-GPU communication. Beyond fault detection, it provides comprehensive performance analytics from byte exchange patterns to identify network bottlenecks like low-latency links, bandwidth-constrained node pairs, and network pressure points that increasingly constrain modern AI workloads. In case of distributed inferencing workloads (ex. DeepSeek R1 Distilled 8B), it captures phase-specific (prefill/decode) and collective operation-specific metrics, revealing communication bottlenecks affecting end-to-end response time.}
}


@inproceedings{DBLP:conf/icnp/WeiGCDQZ25,
	author = {Jingtian Wei and
                  Xingrong Gao and
                  Xinyi Cao and
                  Huiqi Deng and
                  Yi Qian and
                  Peng Zhang},
	title = {Let's Synthesize Step-by-Step: Generating Network Configurations
                  with Chain of Thought},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--6},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192427},
	doi = {10.1109/ICNP65844.2025.11192427},
	timestamp = {Thu, 13 Nov 2025 08:55:56 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/WeiGCDQZ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Configuring networks is a highly-demanding and error-prone process. Recently, large language models (LLMs) have been used to synthesize network configurations. Even showing great potential in automatically configuring networks, we find that the accuracy of the generated configuration is still unsatisfactory, due to two reasons: (1) generating the entire configuration in a single-step is too hard, which overwhelms the model’s ability to reason over complex topologies and device roles; (2) LLMs lack sufficient domain knowledge and procedural understanding to handle structured tasks like protocol inference and parameter allocation. This paper proposes CoTNet, an LLM-based network synthesizer, which consists of two major steps: (1)CoTNet decomposes configuration generation into a two-stage process—first generating configuration templates, then assigning concrete parameters—to ensure correctness and consistency; (2)it further fine-tunes a lightweight LLM on a large-scale Chain-of-Thought (CoT) inference dataset, enabling the model to internalize domain-specific knowledge and structured reasoning patterns. Experimental results demonstrate that CoTNet achieves 94.5% device-level and 89% network-level accuracy in generating configurations for connectivity intents. Ablation studies further confirm that both CoT inference and two-stage task decomposition are critical to ensuring the correctness of configuration synthesis.}
}


@inproceedings{DBLP:conf/icnp/YanHHMTW25,
	author = {Wenwu Yan and
                  Bo Hu and
                  Weiqing Huang and
                  Chao Ma and
                  Xiaobin Tian and
                  Dong Wei},
	title = {{UPEA:} {A} Novel {BGP} Convergence Verification Algorithm with Zero
                  False Positives and Minimal False Negatives},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--14},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192437},
	doi = {10.1109/ICNP65844.2025.11192437},
	timestamp = {Thu, 13 Nov 2025 08:55:56 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/YanHHMTW25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Border Gateway Protocol (BGP) is the core routing protocol for inter-domain routing, providing substantial flexibility but lacking convergence guarantees, which can lead to network oscillations and instability. Despite prior research proposing various methods to address these issues, existing algorithms still fall short in terms of accuracy and efficiency.In this paper, we introduce a novel and efficient algorithm that statically analyzes BGP configurations to accurately determine routing convergence. Our algorithm achieves several major advancements:•Superior Accuracy: It outperforms the state-of-the-art algorithm by correctly identifying a broader range of configurations.•Scalability: It is highly efficient, capable of analyzing Internet-scale configurations within polynomial time complexity.•Reliability: It eliminates false positives, ensuring that potentially oscillating configurations are never incorrectly reported as convergence.Our experimental results demonstrate that the proposed algorithm significantly enhances accuracy and efficiency compared to existing methods, making it highly suitable for large-scale Internet applications. This work represents a substantial step forward in ensuring the stability and reliability of BGP routing, addressing critical challenges in modern Internet infrastructure.}
}


@inproceedings{DBLP:conf/icnp/PazhooheshyAG25,
	author = {Parsa Pazhooheshy and
                  Soheil Abbasloo and
                  Yashar Ganjali},
	title = {Mahak: An Automated and Efficient Assessment Framework for Internet
                  Control Algorithms},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--13},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192397},
	doi = {10.1109/ICNP65844.2025.11192397},
	timestamp = {Thu, 13 Nov 2025 08:55:56 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/PazhooheshyAG25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Network protocols often suffer from undetected performance degradations due to inadequate testing and a lack of efficient and accurate evaluation tools across diverse network configurations. Current methodologies face challenges like pre-modeling, oversimplifications, and focusing on limited failure modes, making them costly, impractical, or imprecise.We propose Mahak, a novel black-box framework that reconstructs the empirical performance of a given protocol throughout the multidimensional configuration space using an active learning-guided sampling strategy, without prior modeling or knowledge of the internal algorithm of the protocol. Applied to state-of-the-art Internet Congestion Control (e.g., BBR2, Sage, Orca) and Adaptive Bitrate Streaming protocols (e.g. Pensieve, BOLA, RobustMPC), Mahak explores less than 0.1% of the configuration space, and achieves up to a 12.5× reduction in mapping error compared to interpolation-based methods.By systematically identifying the complete empirical performance surface, rather than focusing on a single prominent failure, Mahak uncovers issues that would otherwise remain hidden. This end-to-end mapping equips protocol designers, QA engineers, and network operators with actionable data-driven insights across diverse metrics and configurations, supporting more reliable deployments.}
}


@inproceedings{DBLP:conf/icnp/MoraJKCF25,
	author = {Alan Cueva Mora and
                  K. P. N. Jayasena and
                  Robert Krahn and
                  Enrique Chirivella{-}Perez and
                  Christof Fetzer},
	title = {Understanding the Latency-Security Tradeoff: TEE-based Confidential
                  Computing for Streaming Workloads},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--6},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192400},
	doi = {10.1109/ICNP65844.2025.11192400},
	timestamp = {Sun, 01 Feb 2026 13:27:01 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/MoraJKCF25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Distributed streaming platforms such as Pravega, Kafka, and Pulsar are widely used for high-throughput, low-latency data processing. As these platforms increasingly handle sensitive data, ensuring data confidentiality and integrity becomes critical. Trusted Execution Environments (TEEs) offer secure computations that can be used on client-side processing, but their impact on performance must be carefully assessed. This study evaluates the write latency of Pravega clients running in TEEs compared to those in standard (non-secured) environments. We found that under typical workloads, TEE-based clients experience approximately 50% higher latency due to the overhead of secure executions. However, when data rates exceed 976 MB/s, the Pravega broker reaches its throughput limit, causing latency to spike for standard clients. In contrast, TEE-based clients exhibit more stable latency under these high-throughput conditions. These findings can be helpful for data architects, as systems highlight a trade-off: while latency may increase, the impact could be acceptable in certain scenarios given the enhanced security benefits.}
}


@inproceedings{DBLP:conf/icnp/GuanLYHQLFGX25,
	author = {Jianfeng Guan and
                  Kexian Liu and
                  Su Yao and
                  Xiaolong Hu and
                  Ye Qin and
                  Jianli Liu and
                  Songtao Fu and
                  Xiangyu Gao and
                  Ke Xu},
	title = {{PIPE:} Identity-Aware Privacy-Enhanced Source and Path Verification
                  for Strengthened Network Accountability},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--11},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192382},
	doi = {10.1109/ICNP65844.2025.11192382},
	timestamp = {Sun, 04 Jan 2026 13:43:26 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/GuanLYHQLFGX25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Network-layer security threats have become increasingly sophisticated, exposing significant vulnerabilities in the current Internet architecture. Despite various proposed solutions, the field faces fundamental challenges in balancing user privacy with network security and achieving practical deployment. This paper presents a novel approach called PIPE (Privacy-preserving Identity and Path Enhancement), which leverages a distributed infrastructure of Key Distribution Servers (KDS) to integrate Decentralized Identity (DID) with source and path verification. Our solution binds user identity, address, path, and data while maintaining privacy through encryption and per-hop address transformation. By embedding DID information in address and implementing encrypted path verification, we achieve enhanced network accountability without compromising privacy. Experimental results demonstrate PIPE’s practicality and advantages over existing approaches in terms of deployment flexibility and security guarantees. Our work contributes to the evolution of secure network architectures by balancing accountability requirements with privacy protection while ensuring practical deployability.}
}


@inproceedings{DBLP:conf/icnp/RenZDXZCW25,
	author = {Shaorui Ren and
                  Jia Zhang and
                  Enhuan Dong and
                  Mingwei Xu and
                  Yixuan Zhang and
                  Jiahao Cao and
                  Jianping Wu},
	title = {Undermining Delay-based {QUIC} Congestion Control: {A} Receiver-driven
                  Attack via Crafted Host Delays},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--12},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192451},
	doi = {10.1109/ICNP65844.2025.11192451},
	timestamp = {Sun, 07 Dec 2025 22:11:03 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/RenZDXZCW25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {QUIC gains significant attention due to its superior transmission performance, achieving widespread adoption in both academia and industry. To improve round-trip time (RTT) estimation, QUIC introduces the Host Delay field, enabling senders to exclude receiver-induced delays. Many delay-based congestion control algorithms (CCAs) rely on these RTT estimates to detect congestion and regulate sending rates. However, we find that malicious Host Delay values can distort RTT measurements, causing inappropriate rate adjustments by CCAs.In this paper, we investigate a new class of attacks leveraging maliciously crafted Host Delay values. To our knowledge, we are the first to analyze the vulnerability of Host Delay and present QUDIT, a universal receiver-driven attack targeting delay-based QUIC CCAs. Unlike prior attacks that presume full network queuing delays visibility and undetected injection capabilities, our attacker model only grants the adversary access as a standard QUIC receiver with limited knowledge of bottleneck conditions. We minimally modify the QUIC receiver to infer bottleneck queuing behavior in real time. Based on these inferences, we design dynamic Host Delay crafting strategies tailored to the specific behavior of various delay-based CCAs and accounting for random network fluctuations. Our attack prompts the sender to overshoot its rate, leading to excessive bandwidth consumption at the bottleneck and degradation of competing flows. Results demonstrate the throughput degradation of victim flow achieves up to 60% within 0.3 s and amplification gains between 200× and 600×. We propose defenses mitigating QUDIT, with vulnerabilities reported to IETF and QUIC maintainers.}
}


@inproceedings{DBLP:conf/icnp/LiLL25,
	author = {Sijia Li and
                  Yumeng Liang and
                  Jianjiang Li},
	title = {Robust Mobile-Cloud Collaborative {CNN} Inference under Unreliable
                  Wireless Networks},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--6},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192434},
	doi = {10.1109/ICNP65844.2025.11192434},
	timestamp = {Thu, 13 Nov 2025 08:55:56 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/LiLL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Mobile-cloud collaborative Convolutional Neural Network (CNN) inference enables the efficient execution of CNN models by offloading partial inference workloads from mobile devices to the cloud. Although model partitioning for collaborative inference has been extensively studied, most existing approaches assume reliable mobile-cloud transmission, which often breaks down in real-world wireless environments with packet loss. In such scenarios, incomplete feature transmission can result in a significant drop in inference accuracy. In this paper, a joint scheduling approach is proposed to address this challenge, leveraging a search-based algorithm to determine both the model partition layer and redundancy level, to balance inference accuracy and latency under packet loss conditions. The proposed method is evaluated in a real-world mobile-cloud environment. Results show that it reduces the inference latency by up to 30.3% compared to the non-redundant baseline with the same accuracy threshold.}
}


@inproceedings{DBLP:conf/icnp/LiuTPDSDASGBN25,
	author = {Peini Liu and
                  Joan Oliveras Torra and
                  Marc Palac{\'{\i}}n and
                  Michail Dalgitsis and
                  Maria A. Serrano and
                  Eftychia G. Datsika and
                  Angelos Antonopoulos and
                  Javier Santaella S{\'{a}}nchez and
                  Jordi Guitart and
                  Josep Llu{\'{\i}}s Berral and
                  Ramon Nou},
	title = {Mobility Usecase: Intelligent Service Migration in Cloud-Edge Continuum},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--6},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192452},
	doi = {10.1109/ICNP65844.2025.11192452},
	timestamp = {Thu, 13 Nov 2025 08:55:56 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/LiuTPDSDASGBN25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As industries increasingly embrace digital and intelligent transformation, enterprises face significant challenges in the containerization upgrades for their Artificial Intelligence(AI) applications and dynamic service migration and management in Cloud-Edge continuum(CEC). This paper presents CloudSkin, an innovative platform designed to realize streamlined, seamless and intelligent service migration in Cloud-Edge Continuum by integrating advanced containerization techniques and AI-driven orchestration capabilities. Our approach, leveraging intelligent algorithms for service migration, can seamlessly transit services between cloud and edge environments, ensuring optimised resource allocation and reducing service latency to assure quality of service(QoS). CloudSkin has been enabled in a Mobility Usecase, empowering Cellnex businesses undergoing digital transformation to achieve higher operational efficiency. The experimental results show that compared to traditional reactive service migration, using intelligent proactive service migration can provide better migration detection, improving F1-Score up to 23.5%, and reducing 28.9% the service running time where the service latency violates SLA.}
}


@inproceedings{DBLP:conf/icnp/BiZQJW25,
	author = {Haisong Bi and
                  Jin Zhao and
                  Kun Qiu and
                  Tiezhen Jia and
                  Yu Wang},
	title = {Poster: Generative Resilient Network Architecture in Untrusted Network
                  Environments},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--2},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192369},
	doi = {10.1109/ICNP65844.2025.11192369},
	timestamp = {Thu, 13 Nov 2025 08:55:56 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/BiZQJW25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In adversarial and untrusted network environments characterized by strict traffic controls and infrastructure surveillance, communications face persistent threats to reliability, security, and accessibility. To counter these challenges, we present the Generative Resilient Network (GRN), a three-layer architecture that combines cloud-based resource agility, hybrid secure transmission, and large language model (LLM)-driven adaptive control to maintain connectivity under adversarial conditions. Preliminary experiments demonstrate GRN’s scalability, robustness, and resilience against interference across both low-latency and high-anonymity scenarios.}
}


@inproceedings{DBLP:conf/icnp/HongKBKP25,
	author = {Junkyu Hong and
                  Heewon Kim and
                  Chanbin Bae and
                  Hwimo Ku and
                  Sangheon Pack},
	title = {Poster: Prediction-Based Low-overhead In-band Network Telemetry},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--3},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192363},
	doi = {10.1109/ICNP65844.2025.11192363},
	timestamp = {Thu, 13 Nov 2025 08:55:56 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/HongKBKP25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In-band network telemetry (INT) enables real-time and fine-grained network monitoring but incurs high transmission overhead. To mitigate this, encoding-based INT methods have been introduced to collect telemetry items using fewer bits than their original bits. However, prior works struggle to reduce encoding bit length when the magnitudes of telemetry items vary widely, as they rely on transmitting raw values. To address this challenge, we propose a prediction-based INT framework that effectively minimizes encoding bit length by collecting prediction errors instead of raw values. Our framework leverages both temporal patterns and inter-item correlations to robustly reduce prediction errors, thereby significantly lowering encoding bits while ensuring accurate reconstruction of original values.}
}


@inproceedings{DBLP:conf/icnp/YinCHSLY25,
	author = {Junnan Yin and
                  Lei Cui and
                  Zhiyu Hao and
                  Jiawei Sun and
                  Peng Liu and
                  Xiaochun Yun},
	title = {BTRFormer: Hierarchical Learning of Encrypted Traffic Using a Masked
                  Autoencoder with Block-Based Traffic Representation},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--12},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192383},
	doi = {10.1109/ICNP65844.2025.11192383},
	timestamp = {Thu, 13 Nov 2025 08:55:56 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/YinCHSLY25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Encrypted traffic classification (ETC) is essential for ensuring network security and efficient management. Despite advances in deep learning, ETC remains challenging as existing models struggle to learn robust, discriminative representations from content-encrypted, highly imbalanced traffic.To address these challenges, we propose BTRFormer, a novel ETC approach that capitalizes on the inherent properties of encryption algorithms to enhance classification accuracy. At the core of BTRFormer lies a block-based, multi-layer traffic representation that adopts a 4×4 block as the fundamental unit, inspired by the encryption algorithm’s use of 16-byte blocks for encryption operations. This representation preserves the intrinsic structure of encrypted payloads, facilitating the model’s ability to learn deep semantic features. Subsequently, a transformer-based model is employed to learn from the multi-layer representation, capturing intra-block, inter-block, and inter-packet dependencies through block-wise attention mechanisms. Finally, BTRFormer leverages a pre-training phase on large-scale unlabeled data, followed by fine-tuning with a minimal amount of labeled samples to improve generalization and adaptability. Experimental results show that BTRFormer significantly outperforms SOTA methods on six real-world datasets, highlighting its effectiveness in encrypted traffic classification and secure network management.}
}


@inproceedings{DBLP:conf/icnp/WangLQ25,
	author = {Shengze Wang and
                  Yi Liu and
                  Chen Qian},
	title = {Poster: Vortex: Efficient Decentralized Vector Overlay for Similarity
                  Search and Delivery},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--3},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192399},
	doi = {10.1109/ICNP65844.2025.11192399},
	timestamp = {Thu, 13 Nov 2025 08:55:56 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/WangLQ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Nearest-neighbor search over embeddings has become a core primitive for AI and LLM-centric workloads. However, prevailing vector databases remain centralized or cluster-bound, introducing single control points, privacy vulnerabilities, and cost/latency bottlenecks. We present Vortex, a decentralized vector overlay that delivers planet-scale approximate nearest neighbor (ANN) search without a centralized control plane. Vortex integrates three key components: (1) Distributed Learned Hashing (DLH), which collaboratively learns piecewise similarity-preserving hash functions to map semantically related vectors to nearby key ranges while balancing load; (2) a Distributed Hash Table (DHT) for scalable, fault-tolerant routing and churn resilience; and (3) a co-designed Distributed HNSW (DHNSW) index for high-recall, low-latency search on each peer. Preliminary results show that Vortex matches the accuracy and latency of leading centralized systems while reducing per-peer index memory requirements by two orders of magnitude and eliminating any central coordinator—enabling fully decentralized, self-organizing ANN overlay for next-generation AI systems.}
}


@inproceedings{DBLP:conf/icnp/KochiyamaYTKH25,
	author = {Mio Kochiyama and
                  Yutaro Yoshinaka and
                  Junji Takemasa and
                  Yuki Koizumi and
                  Toru Hasegawa},
	title = {pPHI: Path Validation for a Lightweight Anonymity Protocol},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--11},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192406},
	doi = {10.1109/ICNP65844.2025.11192406},
	timestamp = {Thu, 13 Nov 2025 08:55:56 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/KochiyamaYTKH25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Lightweight anonymity protocols provide a well-balanced anonymity and performance by encrypting and decrypting only packet headers under the active and local adversary threat model. Among them, PHI and dPHI are promising in universally providing relationship anonymity. However, when overlaid onto IP, they are susceptible to the router skipping attack, where honest routers are skipped by malicious routers. Although this attack poses a significant threat to anonymity, its prevention is challenging due to the lack of path integrity in these protocols. To address this limitation, this paper integrates path validation into dPHI. This integration is non-trivial, as anonymity and path validation are inherently contradictory requirements. This paper designs and implements pPHI, a novel protocol, and analyzes pPHI in terms of security and performance.}
}


@inproceedings{DBLP:conf/icnp/KimJL25,
	author = {Chang Kyung Kim and
                  Junho Jeong and
                  SuKyoung Lee},
	title = {Poster: UAV-Assisted Cooperative Perception in Vehicular Network},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--3},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192395},
	doi = {10.1109/ICNP65844.2025.11192395},
	timestamp = {Thu, 13 Nov 2025 08:55:56 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/KimJL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper proposes a UAV-assisted cooperative perception framework for vehicular networks, ensuring the timely transmission of image feature extraction results from vehicles to the RSU, thereby enabling cooperative perception such as HD map construction and object-level tracking in smart cities. We analyze the success probability that vehicles can complete image feature extraction and transmit the result before leaving the RSU’s communication range with the assistance of UAVs. The simulation results demonstrate that the proposed algorithm outperforms benchmark schemes in terms of success probability.}
}


@inproceedings{DBLP:conf/icnp/GuoZ25,
	author = {Chaoqun Guo and
                  Dalin Zhang},
	title = {Poster: {SCL-IDS} - {A} Semi-Supervised Continual Learning Framework
                  for Adaptive Intrusion Detection},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--3},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192323},
	doi = {10.1109/ICNP65844.2025.11192323},
	timestamp = {Thu, 13 Nov 2025 08:55:56 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/GuoZ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As modern network infrastructures grow in complexity, intrusion detection systems (IDS) face increasing challenges in detecting emerging threats under non-stationary conditions. Real-world traffic is characterized by continual attack evolution, severe label scarcity, and imbalanced distributions. Traditional IDS approaches often fail to maintain accuracy over time due to catastrophic forgetting, while supervised methods demand costly manual annotations.}
}


@inproceedings{DBLP:conf/icnp/YeWSHLZH25,
	author = {Jin Ye and
                  Zirong Wei and
                  Jing Shao and
                  Huilin Hu and
                  Sitan Li and
                  Yilin Zhao and
                  Jiawei Huang},
	title = {SplitSketch: Achieving Accurate Quantile Estimation under Highly Dynamic
                  Traffic Distribution},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--11},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192374},
	doi = {10.1109/ICNP65844.2025.11192374},
	timestamp = {Sun, 01 Feb 2026 13:27:01 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/YeWSHLZH25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Quantiles over data stream have been recognized to be an essential feature in network traffic. To provide accurate estimation results, current quantile estimation approaches are preconfigured according to traffic distributions such as log-normal and Pareto distributions. In most practical applications, however, the traffic distributions are not known a priori or are highly dynamic, disturbing estimation results. In this paper, we propose SplitSketch, a sketch-based mechanism that aims to accurately estimate quantiles over data stream without any prior knowledge of traffic distributions. SplitSketch adjusts its estimation granularity according to the changing process of the traffic distribution. The granularities with denser distribution will be recorded with the finer granularity to provide more accurate estimation results. Experimental results demonstrate that, compared to existing approaches, SplitSketch reduces the absolute error in quantile estimation by 59.1% for heavy-tailed distributions and 79.2% for general distributions.}
}


@inproceedings{DBLP:conf/icnp/SunF25,
	author = {Wei Sun and
                  Minghong Fang},
	title = {A Power Line Backbone-Assisted Wireless Transit Network},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--11},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192444},
	doi = {10.1109/ICNP65844.2025.11192444},
	timestamp = {Sun, 07 Dec 2025 22:11:03 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/SunF25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Power line communication (PLC) is emerging as the preferred connectivity solution to enlarge WiFi’s communication range for mobile clients. However, we have to consider the mobility in power-line assisted WiFi for a seamless mobile experience and wide connectivity. To this end, in this paper, we exploit the power line backbone to achieve seamless mobility and wide connectivity for mobile clients in a power line-assisted wireless transit network. To do so, we introduce TurboGrid that characterizes the power-line backbone and allows the network infrastructure to make performance-impacting decisions on roaming between PLC adapters. We first characterize the power line channel over time and space in the powerline infrastructure. Then, we show that the existing WiFi handover approaches cannot be directly applied when integrating power lines to assist WiFi communication. Therefore, we propose to integrate the link quality on the power line backbone with link quality over the air for seamless mobile client switching. The systematic evaluation and implementation of commodity WiFi AP and PLC adapters show the efficacy of our TurboGrid during the mobile client’s mobility.}
}


@inproceedings{DBLP:conf/icnp/GuanQZ25,
	author = {Jingyi Guan and
                  Kun Qiu and
                  Jin Zhao},
	title = {ReWeave: Traffic Engineering with Robust Path Weaving for Localized
                  Link Failure Recovery},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192396},
	doi = {10.1109/ICNP65844.2025.11192396},
	timestamp = {Thu, 13 Nov 2025 08:55:56 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/GuanQZ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Link failures occur frequently in Internet Service Provider (ISP) networks and pose significant challenges for Traffic Engineering (TE). Existing TE schemes either reroute traffic over vulnerable static paths, leading to performance degradation, or precompute backup routes for a broad range of failure scenarios, which introduces high overhead and limits scalability. Hence, an effective failure recovery mechanism is required to offer sufficient path diversity under constrained overhead, thereby ensuring robust and performant network operation. This paper presents ReWeave, a scalable and efficient link-level TE scheme that enables localized rerouting by equipping each link with a compact set of adjacent-only backup paths. Upon detecting a failure, only the routers at both ends of the failed link reroute traffic dynamically using SRv6-based detours, without controller intervention or full-path recomputation. Evaluation results on large-scale backbone networks demonstrate that ReWeave outperforms existing TE schemes in link failure scenarios. Compared to HARP, the state-of-the-art failure recovery scheme based on centralized control and dynamic traffic reallocation, our approach reduces the average maximum link utilization by 10.5%–20.1%, and lowers the worst-case utilization by 29.5%– 40.9%. When compared with Flexile, a protection-based scheme that precomputes routes for multi-failure scenarios, ReWeave achieves a similarly low packet loss rate in 90% of failure cases, while maintaining a response speed comparable to the fastest router-based local rerouting schemes.}
}


@inproceedings{DBLP:conf/icnp/Huang25,
	author = {Xiaoyao Huang},
	title = {Latency-Aware Transformer Partitioning for Heterogeneous Edge Inference},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--6},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192426},
	doi = {10.1109/ICNP65844.2025.11192426},
	timestamp = {Thu, 13 Nov 2025 08:55:56 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/Huang25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Deploying transformer models in heterogeneous edge environments poses significant challenges due to limited memory, varied compute capabilities, and asymmetric inter-node bandwidth. To enable efficient distributed inference, it is necessary to partition the model into segments that can be collaboratively executed across multiple edge nodes. However, previous works predominantly focus on either single-point partitioning or static scheduling strategies, which fall short in capturing the joint impact of segmentation and assignment on end-to-end latency. In this work, we formulate a latency-aware transformer deployment problem that jointly optimizes model segmentation and segment-to-node assignment, explicitly accounting for memory constraints and heterogeneous communication costs. We propose efficient algorithms to explore the solution space, including a latency-aware balanced partitioning heuristic (LaBP) and a dynamic programming-based optimal strategy (DP-MCP). Extensive experiments demonstrate that our approach consistently achieves significantly lower inference latency compared to existing baselines while maintaining feasibility under stringent resource constraints.}
}


@inproceedings{DBLP:conf/icnp/LeeKCP25,
	author = {Sanghoon Lee and
                  Taehun Kim and
                  Jiyeong Chae and
                  Kyung{-}Joon Park},
	title = {Poster: How to Send Large Data in {ROS} 2},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--3},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192433},
	doi = {10.1109/ICNP65844.2025.11192433},
	timestamp = {Thu, 13 Nov 2025 08:55:56 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/LeeKCP25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {High-resolution data streams-such as images, Li-DAR point-clouds-are common in robotic communication, yet Robot Operating System 2 (ROS 2) struggles to transmit these streams due to increased average latency. On lossy wireless links, the default DDS communication stack in ROS 2 suffers significant performance degradation. This paper presents the first comprehensive network-layer analysis of ROS 2’s DDS stack operating over wireless links with large payloads. We analyze three network bottlenecks that emerge during large-payload data transfers and presents DDS-level optimizations for each one. The proposed solutions are exposed through an XML-based QoS configuration interface, allowing them to be easily tuned. Experiments demonstrate that our approach transmits large-payload data successfully while maintaining lower latency than existing methods.}
}


@inproceedings{DBLP:conf/icnp/WangZZZWY25,
	author = {Jun Wang and
                  Yuchao Zhang and
                  Gaoxiong Zeng and
                  Chenyue Zheng and
                  Wendong Wang and
                  Haipeng Yao},
	title = {Sub-RTT Congestion Control for Inter-Datacenter Networks},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--6},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192335},
	doi = {10.1109/ICNP65844.2025.11192335},
	timestamp = {Thu, 13 Nov 2025 08:55:56 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/WangZZZWY25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the explosive growth in the scale and complexity of large language models (LLMs), there is an urgent need to extend training and inference workloads from within a single data center to across multiple data centers. However, this also introduces new challenges for network transport protocols. To address these issues, we propose SRCC (Sub-RTT Congestion Control), a method designed for inter-datacenter networks. Specifically, SRCC introduces a flowset-based mechanism along with shared node tables, enabling Datacenter Interconnect (DCI) switches to be aware of the path status of each flow. By leveraging information shared among different flows, SRCC can accurately adjust the sending rate at a sub-RTT timescale, thereby significantly improving network performance. Building on this approach, we design detailed mechanisms to address the following challenges: (1) applying INT technology in wide-area networks; (2) acquiring INT information with low overhead; and (3) achieving precise congestion window adjustments under sub-RTT perception.We conducted large-scale simulations using NS3, and the experimental results show that our scheme reduces the average FCT slowdown by 44.17% and 53.86% compared to HPCC and DCTCP, respectively.}
}


@inproceedings{DBLP:conf/icnp/ParkB25,
	author = {Junha Park and
                  Saewoong Bahk},
	title = {Poster: Seamless Cellular-WLAN Aggregation with Connectivity-Aware
                  Flow Control},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--3},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192380},
	doi = {10.1109/ICNP65844.2025.11192380},
	timestamp = {Thu, 13 Nov 2025 08:55:56 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/ParkB25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Rapid growth in application bandwidth demand has challenged cellular networks to maintain high Quality of Service (QoS) using licensed spectrum alone. NR-WLAN Aggregation (NWA), standardized in 3GPP Release 16, addresses this by combining licensed and unlicensed spectrum resources. However, current flow control mechanisms are inadequate for heterogeneous dual-connectivity environments where frequent WLAN disconnections occur. This paper identifies disconnection timing prediction as a fundamental bottleneck in NWA flow control and proposes a connectivity-aware transmission volume fitting approach to minimize packet loss, reduce recovery time, and maximize throughput.}
}


@inproceedings{DBLP:conf/icnp/WeiXHZCCC25,
	author = {Yunze Wei and
                  Xiaohui Xie and
                  Tianshuo Hu and
                  Yiwei Zuo and
                  Xinyi Chen and
                  Kaiwen Chi and
                  Yong Cui},
	title = {{INTA:} Intent-Based Translation for Network Configuration with {LLM}
                  Agents},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--16},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192391},
	doi = {10.1109/ICNP65844.2025.11192391},
	timestamp = {Thu, 13 Nov 2025 08:55:56 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/WeiXHZCCC25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Translating configurations between different network devices is a common yet challenging task in modern network operations. This challenge arises in typical scenarios such as replacing obsolete hardware and adapting configurations to emerging paradigms like Software Defined Networking (SDN) and Network Function Virtualization (NFV). Engineers need to thoroughly understand both source and target configuration models, which requires considerable effort due to the complexity and evolving nature of these specifications. To promote automation in network configuration translation, we propose INTA, an intent-based translation framework that leverages Large Language Model (LLM) agents. The key idea of INTA is to use configuration intent as an intermediate representation for translation. It first employs LLMs to decompose configuration files and extract fine-grained intents for each configuration fragment. These intents are then used to retrieve relevant manuals of the target device. Guided by a syntax checker, INTA incrementally generates target configurations. The translated configurations are further verified and refined for semantic consistency. We implement INTA and evaluate it on real-world configuration datasets from the industry. Our approach outperforms state-of-the-art methods in translation accuracy and exhibits strong generalizability. INTA achieves an accuracy of 98.15% in terms of both syntactic and view correctness, and a command recall rate of 84.72% for the target configuration. The semantic consistency report of the translated configuration further demonstrates its practical value in real-world network operations.}
}


@inproceedings{DBLP:conf/icnp/DaumSBH25,
	author = {Shilo Daum and
                  Tal Shapira and
                  Anat Bremler{-}Barr and
                  David Hay},
	title = {Non-uniformity is All You Need: Efficient and Timely Encrypted Traffic
                  Classification With {ECHO}},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--12},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192379},
	doi = {10.1109/ICNP65844.2025.11192379},
	timestamp = {Thu, 13 Nov 2025 08:55:56 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/DaumSBH25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With 95% of Internet traffic now encrypted, an effective approach to classifying this traffic is crucial for network security and management. This paper introduces ECHO—a novel optimization process for ML/DL-based encrypted traffic classification that can significantly improve many suggested classification schemes. ECHO targets both classification time and memory utilization and incorporates two innovative techniques.The first component, HO (Hyperparameter Optimization of binnings), aims at creating efficient traffic representations. While previous research often uses representations that map packet sizes and packet arrival times to fixed-sized bins, we show that non-uniform binnings are significantly more efficient. These non-uniform binnings are derived by employing a hyperparameter optimization algorithm in the training stage. HO significantly improves accuracy given a required representation size, or, equivalently, achieves comparable accuracy using smaller representations.Then, we explore EC (Early Classification of traffic), which enables faster classification using a cascade of classifiers adapted for different exit times, where classification is based on the level of confidence. EC reduces the average classification latency by up to 90%. Remarkably, this method not only maintains classification accuracy but also, in certain cases, improves it.Using three publicly available datasets, we demonstrate that the combined method, Early Classification with Hyperparameter Optimization (ECHO), leads to a significant improvement in classification efficiency.}
}


@inproceedings{DBLP:conf/icnp/ChengMTXLLY25,
	author = {Zhengyi Cheng and
                  Chongxi Ma and
                  Mingxuan Tang and
                  Jie Xu and
                  Quan Li and
                  Long Luo and
                  Hongfang Yu},
	title = {Poster: {LLM} Multi-Agent Collaboration for Network Deployment and
                  Management},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--2},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192375},
	doi = {10.1109/ICNP65844.2025.11192375},
	timestamp = {Fri, 14 Nov 2025 07:30:20 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/ChengMTXLLY25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper presents the MAPLE framework, which harnesses large language models (LLMs) to facilitate multi-agent collaboration for fully automated deployment and management of large-scale networks. Within MAPLE, a supervisor agent interprets natural language instructions from users, orchestrates specialized agents to execute tasks, and validates outcomes through integration with a network simulation platform. Experimental findings show that MAPLE outperforms single-agent approaches in terms of success rates for topology deployment and service configuration. Moreover, experiments reveal that by adaptively employing LLMs with varying capabilities according to task requirements and inter-agent dependencies, the framework effectively balances task success rates with cost efficiency.}
}


@inproceedings{DBLP:conf/icnp/ChoiPLLL25,
	author = {Yoonsoo Choi and
                  Jaeseong Park and
                  Sugyeong Lee and
                  Gayeong Lee and
                  SuKyoung Lee},
	title = {Poster: {A} Routing Algorithm for Enhancing {TCP} Performance in {LEO}
                  Satellite Networks},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--2},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192429},
	doi = {10.1109/ICNP65844.2025.11192429},
	timestamp = {Thu, 13 Nov 2025 08:55:56 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/ChoiPLLL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The rapid changes in network topology caused by the mobility of LEO satellites lead to inter-satellite link (ISL) disconnections. Accordingly, such disconnections will degrade TCP throughput of LEO services. In this paper, we propose a routing algorithm for LEO satellite networks that reduces path changes by avoiding ISLs prone to disconnection. The simulation results demonstrate that the proposed algorithm achieves higher TCP throughput compared to the benchmark methods.}
}


@inproceedings{DBLP:conf/icnp/MorichettaBKDMLCSDKAMD25,
	author = {Andrea Morichetta and
                  Juan Brenes and
                  Mikhail Kolobov and
                  Djawida Dib and
                  Thijs Metsch and
                  Anna Lackinger and
                  Cveta Capova and
                  Hui Song and
                  Rustem Dautov and
                  Ahmed Khalid and
                  Sigmund Akselsen and
                  Arne Munch{-}Ellingsen and
                  Schahram Dustdar},
	title = {inCoord: Intent-based Coordination in the Multi-domain Cloud-Edge
                  Continuum},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--6},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192462},
	doi = {10.1109/ICNP65844.2025.11192462},
	timestamp = {Sun, 01 Feb 2026 13:27:01 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/MorichettaBKDMLCSDKAMD25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The computing continuum aims to break the isolation of edge and cloud computing, creating a smooth and heterogeneous infrastructure surface for deploying applications. However, the continuum is practically fragmented, with infrastructure managed in isolation by various parties in a vertical dimension, i.e., edge, fog, and cloud layers, and horizontally, i.e., computing, network, and storage domains. This scenario negatively impacts the fulfillment of the application objectives. We propose inCoord, an intent-aware solution that enables the creation of a unified computing continuum by coordinating its instances to fulfill application objectives. Each instance represents a cluster of (compute, storage, or network) nodes with their own manager component. Traditionally, systems take low-level actions on these instances. In contrast, inCoord learns their emerging behaviors and adapts their managers’ objectives to fulfill the application’s intents. Here, through a Reinforcement-Learning-based Proof of Concept, we show the potential of this system to understand emerging behavior and manage multi-domain, independently managed instances.}
}


@inproceedings{DBLP:conf/icnp/WangLZHQ25,
	author = {Shengze Wang and
                  Yi Liu and
                  Xiaoxue Zhang and
                  Liting Hu and
                  Chen Qian},
	title = {A Distributed Learned Hash Table},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--11},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192384},
	doi = {10.1109/ICNP65844.2025.11192384},
	timestamp = {Thu, 13 Nov 2025 08:55:56 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/WangLZHQ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Distributed Hash Tables (DHTs) are pivotal in numerous high-impact key-value applications built on distributed networked systems, offering a decentralized architecture that avoids single points of failure and improves data availability. Despite their widespread utility, DHTs face substantial challenges in handling range queries, which are crucial for applications such as LLM serving, distributed storage, databases, content delivery networks, and blockchains. To address this limitation, we present LEAD, a novel system incorporating learned models within DHT structures to significantly optimize range query performance. LEAD utilizes a recursive machine learning model to map and retrieve data across a distributed system while preserving the inherent order of data. LEAD includes the designs to minimize range query latency and message cost while maintaining high scalability and resilience to network churn. Our comprehensive evaluations, conducted in both testbed implementation and simulations, demonstrate that LEAD achieves tremendous advantages in system efficiency compared to existing range query methods in large-scale distributed systems, reducing query latency and message cost by 80% to 90%+. Furthermore, LEAD exhibits remarkable scalability and robustness against system churn, providing a robust, scalable solution for efficient data retrieval in distributed key-value systems.}
}


@inproceedings{DBLP:conf/icnp/ZhangLCTLZD25,
	author = {Xiaoquan Zhang and
                  Waiming Lau and
                  Lin Cui and
                  Fung Po Tso and
                  Zhuoqian Liang and
                  Zhen Zhang and
                  Yuhui Deng},
	title = {Planner: {A} Generative Graph Learning Framework for Noisy and Dynamic
                  In-band Network Telemetry},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--11},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192325},
	doi = {10.1109/ICNP65844.2025.11192325},
	timestamp = {Sun, 07 Dec 2025 22:11:03 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/ZhangLCTLZD25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In-band network telemetry (INT) enables real-time network monitoring by embedding telemetry data into packets. The advent of programmable switches further enhances the flexibility of INT by enabling dynamic customization of telemetry collection at the hardware level. However, the practical application of INT is hampered by significant challenges arising from data noise (due to packet loss, delay, and measurement inaccuracies) and network dynamics (such as changing INT paths and feature requirements). These issues severely degrade the performance of machine learning models used for analyzing INT data, hindering the accurate capture of spatio-temporal network characteristics. This paper presents Planner, a novel generative graph learning framework designed to address these limitations. Planner enables the collection of network features at various levels of granularity on programmable switches. Crucially, it constructs dynamic graphs representing evolving INT paths and employs a hybrid Graph Neural Network (GNN) and Recurrent Neural Network (RNN) architecture to effectively learn spatial and temporal dependencies. Furthermore, Planner incorporates variational inference to generate robust latent representations, mitigating the detrimental effects of noise and instability in INT data. We have implemented a testbed prototype of Planner using Intel Tofino ASIC switches. Extensive experiments demonstrate the performance superiority and robustness of Planner over the baseline methods, achieving a 23.2% improvement in F1 score.}
}


@inproceedings{DBLP:conf/icnp/LiuHLGW25,
	author = {Yang Liu and
                  Chenyang Hei and
                  Fuliang Li and
                  Chengxi Gao and
                  Xingwei Wang},
	title = {{MAZ3:} Memory-Assisted ZeRO-3 for Efficient Collective Communication},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--11},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192443},
	doi = {10.1109/ICNP65844.2025.11192443},
	timestamp = {Thu, 13 Nov 2025 08:55:56 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/LiuHLGW25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Large Language Models (LLMs) have advanced rapidly, but their growing parameter scales and memory demands pose critical challenges for distributed training. Although GPU memory capacity improves steadily, model sizes expand much faster, causing frequent Out-of-Memory (OOM) errors and rising training costs. Existing memory optimization approaches, such as ZeRO-3 and offloading, alleviate per-GPU memory pressure but introduce excessive collective communication, limited computation–communication overlap, and degraded scalability. We present MAZ3, a distributed training framework that mitigates these limitations through three key techniques: (1) Collaborative CPU–GPU memory management, storing full parameters in CPU memory and broadcasting them within nodes to reduce global synchronization; (2) Fine-grained communication–computation overlap, aligning collective operations with model computation to hide latency; (3) Hierarchical aggregation operators, leveraging intra-node NVLink and inter-node NIC channels concurrently to minimize communication overhead. We implement MAZ3 on a multi-GPU cluster and evaluate it with large-scale models. Results show that MAZ3 reduces inter-node model communication (gradients and parameters) by 33%, improves training efficiency by 40.3%, and increases throughput by 67.9% compared with ZeRO-3. Moreover, MAZ3 retains the memory efficiency of ZeRO-3 while approaching the training efficiency and throughput of ZeRO-2 Offload, achieving a balanced trade-off between memory optimization and performance.}
}


@inproceedings{DBLP:conf/icnp/ZhouZWCD25,
	author = {Minyuan Zhou and
                  Jiaqi Zheng and
                  Congying Wang and
                  Guihai Chen and
                  Wanchun Dou},
	title = {AnyTuner: Optimizing {IP} Anycast Performance via Strategic {BGP}
                  Routing Policy},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--12},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192428},
	doi = {10.1109/ICNP65844.2025.11192428},
	timestamp = {Thu, 13 Nov 2025 08:55:56 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/ZhouZWCD25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Optimizing anycast catchment to ensure clients connect to their expected PoPs remains a significant challenge in production networks, primarily due to BGP’s inherent lack of performance awareness. Existing approaches either lack fine-grained routing policy control or prove operationally impractical. In this paper, we present AnyTuner, an automatic route management system that strategically optimizes anycast performance through AS-path prepending and BGP communities. AnyTuner integrates three key components: a measurement-driven optimization loop, a neural network for PoP traffic matrix prediction, and an automated recommendation engine for configuration generation. Deployed for over two years on a commercial cloud platform, AnyTuner demonstrates remarkable efficacy in our evaluation across 18 PoPs and 9,000+ probes, achieving a 39.9% reduction in median RTT (from 36.3 ms to 21.8 ms) compared to policy-free baseline configurations and outperforming state-of-the-art alternatives like AnyOpt by 27.8%.}
}


@inproceedings{DBLP:conf/icnp/ChenZZXXLM25,
	author = {Haoyang Chen and
                  Yucheng Zhang and
                  Xuan Zhao and
                  Yao Xiao and
                  Pengjin Xie and
                  Liang Liu and
                  Huadong Ma},
	title = {Exploring Potential Vulnerabilities in DRL-Based Congestion Control
                  with Adversarial Policy},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--11},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192461},
	doi = {10.1109/ICNP65844.2025.11192461},
	timestamp = {Thu, 13 Nov 2025 08:55:56 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/ChenZZXXLM25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {While deep reinforcement learning (DRL)-based congestion control (CC) algorithms outperform traditional TCP methods in dynamic networks, their robustness is challenged by the complex influence caused by state perturbations from competing flows. Existing DRL-based CC models, constrained by their black-box nature, often suffer performance degradation under dynamic network conditions, which may indirectly alter their observations. To address this challenge, we propose Mona, an adversarial attack framework that explores vulnerabilities in existing DRL-based CC schemes while helping improve their robustness. Leveraging a dual-Critic architecture and a global state representation, Mona enables centralized training with an explicit estimation mechanism embedded in the reward function, facilitating targeted attacks without direct access to the victim’s state. Based on this design, Mona can be distributedly deployed to indirectly perturb the victim flow’s observations by injecting a stealthy flow into the bottleneck link, ultimately inducing suboptimal decisions. Experiments demonstrate Mona’s effectiveness across diverse CC models, reducing victim flow throughput by 8.69%–26.67% under various network conditions in both simulated environments and real-world network deployments, and we conduct a preliminary exploration of defense strategies through a minimax-based adversarial training framework that improves model robustness by 20%.}
}


@inproceedings{DBLP:conf/icnp/ZhaoZTLSWYW25,
	author = {Kaiyang Zhao and
                  Han Zhang and
                  Yao Tong and
                  Yahui Li and
                  Xingang Shi and
                  Zhiliang Wang and
                  Xia Yin and
                  Jianping Wu},
	title = {SRmesh: Deterministic and Efficient Diagnosis of Latency Bottleneck
                  Links in SRv6 Networks},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--12},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192455},
	doi = {10.1109/ICNP65844.2025.11192455},
	timestamp = {Tue, 16 Dec 2025 15:44:39 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/ZhaoZTLSWYW25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Segment Routing over IPv6 (SRv6) has attracted more attention from network operators. Diagnosing performance bottlenecks for SRv6 tunnels is critical to maintaining network quality. However, SRv6 introduces priority policies, special forms of multipath routing, and SR-based network slicing, all of which make existing methods difficult to apply. In this paper, we present SRmesh, a framework for diagnosing latency bottleneck links specifically tailored for SRv6 tunnel performance analysis. First, we adopt SR-based probing to deterministically control routing paths and ensure that probe packets emulate real production traffic. Second, we employ a latency-based multipath inference to resolve routing ambiguities caused by SR. Third, we introduce a topology-independent progressive diagnosis that incrementally reuses probe results to reduce redundant measurements, optimizing diagnostic overhead for large-scale SRv6 overlay networks. We implement a prototype of SRmesh and conduct extensive evaluations on real network topologies. The results indicate that SRmesh achieves high diagnostic accuracy with up to a 91.9% reduction in probe overhead, demonstrating its practicality and scalability in large-scale SRv6 environments.}
}


@inproceedings{DBLP:conf/icnp/JiangYWLZW25,
	author = {Jiamin Jiang and
                  Shiming Yu and
                  Hao Wang and
                  Haiyang Li and
                  Yuanqing Zheng and
                  Lu Wang},
	title = {SlideLoRa: Reliable Channel Activity Monitoring across Massive Logical
                  Channels in LoRa Networks},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--12},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192378},
	doi = {10.1109/ICNP65844.2025.11192378},
	timestamp = {Fri, 14 Nov 2025 07:30:20 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/JiangYWLZW25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {LoRa technology has been extensively implemented in various IoT applications, offering widespread low-power connectivity for millions of nodes across thousands of logical channels. However, current LoRa networks lack an efficient mechanism for monitoring channel activity across these numerous channels, which prevents network operators from effectively detecting physical layer activities and implementing additional functionalities (e.g., channel access control). Existing solutions either involve complex iterations over each logical channel or fail to detect extremely weak packets in low SNR conditions. These limitations affect their scalability and robustness in monitoring the vast number of logical channels available in the LoRa spectrum. To address this issue, this paper introduces SlideLoRa, an innovative packet detection method that enables detection across all logical channels under various channel conditions. SlideLoRa consolidates the complete energy of LoRa symbols using an expanded demodulation window combined with a fine-grained sliding window, effectively reconstructing the distorted frequency-domain information of LoRa packets. To achieve this, SlideLoRa incorporates a series of novel solutions, including peak tracking in low SNR, peak sequence matching, peak extraction, and packet parameter retrieval. Experimental results demonstrate that SlideLoRa enhances packet detection capability by 1.7× compared to the state-of-the-art.}
}


@inproceedings{DBLP:conf/icnp/KeersmaekerBPS25,
	author = {Fran{\c{c}}ois De Keersmaeker and
                  R{\'{e}}mi Van Boxem and
                  Cristel Pelsser and
                  Ramin Sadre},
	title = {The Forest Behind the Tree: Revealing Hidden Smart Home Communication
                  Patterns},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--12},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192388},
	doi = {10.1109/ICNP65844.2025.11192388},
	timestamp = {Sat, 15 Nov 2025 13:46:43 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/KeersmaekerBPS25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The widespread use of Smart Home devices has attracted significant research interest in understanding their behavior within home networks. Unlike general-purpose computers, these devices exhibit relatively simple and predictable network activity patterns. However, previous studies have primarily focused on normal network conditions, overlooking potential hidden patterns that emerge under challenging conditions. Discovering the latter is crucial for assessing device robustness.This paper addresses this gap by presenting a framework that systematically and automatically reveals these hidden communication patterns. By actively disturbing communication and blocking observed traffic, the framework generates comprehensive profiles structured as behavior trees, uncovering traffic flows that are missed by more shallow methods. This approach was applied to ten real-world devices, identifying 254 unique flows, with over 27% only discovered through this new method. These insights enhance our understanding of device robustness, and the thus obtained profiles provide a more complete description of the network behavior of devices, as needed, for example, for the configuration of security solutions.}
}


@inproceedings{DBLP:conf/icnp/ChenXDZHDM25,
	author = {Yihan Chen and
                  Haowen Xu and
                  Yi Dong and
                  Benteng Zhang and
                  Xiaoming He and
                  Miao Du and
                  Yingchi Mao},
	title = {Energy-Efficient Federated Learning via Dynamic Distillation and Cloud-Network
                  Collaboration},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--6},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192392},
	doi = {10.1109/ICNP65844.2025.11192392},
	timestamp = {Thu, 13 Nov 2025 08:55:56 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/ChenXDZHDM25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The extensive local training in Hierarchical Federated Learning (HFL) imposes a substantial computational energy burden on end devices, a problem intensified by inherent system and data heterogeneity. While prior works attempt to mitigate this by using heterogeneous models or adjusting local training, they often suffer from critical drawbacks such as accuracy degradation from update biases and an inability to adapt to the dynamic nature of device resources. This paper introduces FedE2AD (Federated Energy-Efficient Adaptive Distillation), a novel cloud-network collaboration framework that leverages dynamic distillation to holistically optimize the energy-accuracy balance. At its core, FedE2AD implements this collaboration through a multi-level optimization approach. At the cloud layer, a Dynamic Model Allocation strategy intelligently assigns model architectures by assessing device status from static, dynamic, and data-centric perspectives. At the device layer, Variable Local Iterations enable real-time adaptation to fluctuating computational power. Crucially, to counteract model divergence, FedE2AD employs a Dual Knowledge Sharing mechanism at the edge layer, which uniquely combines direct aggregation of shared structures with data-free model distillation to ensure robust knowledge transfer. Experiments conducted on simulation platforms show that FedE2AD markedly outperforms existing methods. For instance, on the CIFAR-10 dataset under strong heterogeneity, it reduces single-round computation energy by 21.1% and increases final model accuracy by 1.42% compared to HDHRFL.}
}


@inproceedings{DBLP:conf/icnp/ZhangZWJWDZNW25,
	author = {Yuchao Zhang and
                  Chenyue Zheng and
                  Wenfei Wu and
                  Zhuo Jiang and
                  Lei Wang and
                  Huichen Dai and
                  Zhang Zhang and
                  Jianglong Nie and
                  Wendong Wang},
	title = {{MORS:} Traffic-Aware Routing based on Temporal Attributes for Model
                  Training Clusters},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--12},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192407},
	doi = {10.1109/ICNP65844.2025.11192407},
	timestamp = {Thu, 13 Nov 2025 08:55:56 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/ZhangZWJWDZNW25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {To train large AI models, clusters are constructed with abundant connectivity and bandwidth; but the commodity protocol ECMP and recent proposals fail to fully utilize the network bandwidth for AI traffic pattern. As model training jobs and AI clusters exhibit a predictable and periodic traffic pattern, so in this paper, we propose a MOdel training Routing System — MORS — for traffic routing in AI clusters. MORS defines temporal attributes to characterize the periodic traffic pattern of flows and network links, and temporal quality to quantify whether a path could deliver a flow quickly in the near future. MORS runs In-band Network Telemetry (INT) to collect temporal attributes of the network, and periodic analysis to extend the collected attributes in the time domain. Based on the time series of link utilization and latency, MORS computes the temporal quality of candidate paths. It enforces high-quality path selection while maintaining compatibility with commodity ECMP by manipulating the source UDP port to ensure the flow complies with the target path in the ECMP protocol. MORS is light-weight and readily deployable in the RDMA commodity cluster. Our prototype and experiments demonstrate that MORS achieves performance comparable to adaptive routing and delivers up to 14% and 50% better FCT than PLB and ECMP, respectively.}
}


@inproceedings{DBLP:conf/icnp/XueLLSF25,
	author = {Yujie Xue and
                  Lin Liu and
                  Yuchuan Luo and
                  Bing Sun and
                  Shaojing Fu},
	title = {PrivMLLM: Efficient Three-Party Multimodal Large Language Model Secure
                  Inference Supported Prompt Privacy},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--24},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192338},
	doi = {10.1109/ICNP65844.2025.11192338},
	timestamp = {Thu, 13 Nov 2025 08:55:56 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/XueLLSF25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Multimodal Large Language Models (MLLMs) represent the next frontier in artificial intelligence (AI), capable of processing and integrating diverse data types (text, images, audio and video) for richer understanding and generation. However, their potential is limited by privacy constraints: sensitive data resides with different owners who must keep it local, while MLLM parameters themselves require protection. We address this challenge by pioneering complete end-to-end privacy protection that simultaneously secures prompts, multimedia data, and MLLM parameters.In this work, we present PrivMLLM, the first general-purpose secure three-party (3PC) inference framework for MLLMs that serves two data owners while protecting both model parameters and inputs. Our approach is based on three key insights: (1) domain knowledge-aware optimization of fixed-point arithmetic for global performance gains, (2) hybrid secret-sharing protocols that reduce communication and rounds for linear/non-linear operations, and (3) constant-round function secret sharing (FSS)-based protocols for private embedding and maximum.We formally prove PrivMLLM’s security under the rigorous Universal Composability (UC) framework and demonstrate the first end-to-end secure inference system for MLLMs. Experimental results show that our solution enables secure inference for Llama3.2-11B-vision in under 0:5-minute per token, achieving 16 and 8 speedups compared to our implementations built with the SOTA 2PC (CrypTen+) and 3PC (ABY3+) privacypreserving machine learning (PPML) frameworks respectively. Moreover, we benchmark the submodules ViT and LLM against the SOTA schemes, SHAFT (NDSS 2025) and SIGMA (PETS 2024), achieving 1:3~3× performance gains.}
}


@inproceedings{DBLP:conf/icnp/MafeniTK25,
	author = {Vitumbiko Mafeni and
                  Phuong Bac Ta and
                  Younghan Kim},
	title = {Demo: GitOps-Based Automation for Distributed NFs Reconfiguration
                  in Cloud-Native {O-RAN}},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--3},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192324},
	doi = {10.1109/ICNP65844.2025.11192324},
	timestamp = {Thu, 13 Nov 2025 08:55:56 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/MafeniTK25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {O-RAN disaggregation introduces flexibility in deploying Central Units (CUs) and Distributed Units (DUs) as independent network functions (NFs) connected via midhaul (F1 interface). In cloud-native deployments, multiple CU instances may coexist across clusters, each with varying compute load and network distance. In current practice, CU–DU associations are typically static and do not adapt to changing runtime conditions, making it difficult to apply consistent, timely configuration changes when a CU becomes overloaded. This demo presents a GitOps-based automation framework for runtime reconfiguration of distributed NFs in cloud-native O-RAN. The framework continuously collects NF telemetry and evaluates reconfiguration triggers, applying declarative updates via GitOps workflows to ensure consistency, traceability, and rapid propagation across clusters. As an illustrative scenario, we demonstrate CU–DU coordination under compute stress: when a CU instance becomes overloaded, the system automatically initiates reconfiguration or DU reassociation to an alternative CU. During the demo, attendees will observe live telemetry, configuration commits, and protocol traces showing CU-DU reassociation in response to induced load, illustrating a practical realization of automated NF reconfiguration in cloud-native O-RAN.}
}


@inproceedings{DBLP:conf/icnp/WangWHWGZG25,
	author = {Xingkai Wang and
                  Fudi Wu and
                  Xingwang Huang and
                  Qiefu Wuri and
                  Dujuan Gu and
                  Runzi Zhang and
                  Shen Gao},
	title = {Enterprise Threat Detection with Explainable {AI} for Cloud-Network
                  Convergence},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--6},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192393},
	doi = {10.1109/ICNP65844.2025.11192393},
	timestamp = {Thu, 13 Nov 2025 08:55:56 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/WangWHWGZG25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the rapid development of cloud-network convergence, alert data processing has become a critical task in intelligent cloud-network operations and maintenance. Enterprise threat detection systems serve as a vital defense against cyberattacks. However, due to well-known challenges such as massive unlabeled data, false alerts, and lack of interpretability, threat detection remains a formidable challenge. To address these issues, we propose the Enterprise Threat Detection Explainer (ETDE), an interpretable graph neural network (GNN)-based framework designed to automatically identify attackers from intrusion prevention system (IPS) alerts. ETDE extracts relevant subgraph structures and features from security attribute graphs to model attack patterns, while providing comprehensive explanations to help security teams rapidly pinpoint threats and accelerate incident response. Evaluations on real-world operational data demonstrate that ETDE significantly reduces the manual workload for security analysts, enhancing both efficiency and reliability in threat detection.}
}


@inproceedings{DBLP:conf/icnp/PardeshiSS25,
	author = {Bhaskar Pardeshi and
                  Eric Stuhr and
                  Ahmed Saeed},
	title = {CoreSync: {A} Protocol for Joint Core Scheduling and Overload Control
                  of {\(\mathrm{\mu}\)}s-Scale Tasks},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--11},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192365},
	doi = {10.1109/ICNP65844.2025.11192365},
	timestamp = {Thu, 13 Nov 2025 08:55:56 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/PardeshiSS25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Modern servers employ multiple resource management algorithms, including fast core schedulers and overload controllers to balance application performance and resource utilization. Individual algorithms and their amalgamation are required to meet these tight performance requirements. In this paper, we demonstrate that state-of-the-art core schedulers and overload controllers produce poor performance when deployed simultaneously. Fundamentally, the design assumptions of each controller are violated by the other controller. An overload controller assumes that all resources are dedicated to an application, while a core scheduler assumes that all incoming load will be admitted. To overcome this fundamental limitation, we present CoreSync, a server-driven credit-based protocol for joint core scheduling and overload control. CoreSync relies on the basic idea that the admitted load should be proportional to the allocated resources. However, strict proportionality can lead to low utilization when admitted load does not materialize at the server (e.g., when demand drops). Thus, CoreSync uses partial proportionality to balance latency, throughput, and utilization. Our evaluation across synthetic and real-world workloads shows that CoreSync outperforms state-of-the-art schedulers and overload controllers. In particular, in overload scenarios, CoreSync improves throughput by up to 6%. At low loads, CoreSync reduces the 99th percentile latency by up to 1.7× and improves CPU utilization by up to 1.4×.}
}


@inproceedings{DBLP:conf/icnp/QiuWLZ25,
	author = {Kun Qiu and
                  Ying Wang and
                  Baoqian Li and
                  Wenjun Zhu},
	title = {Poster: Unsupervised Dataset Cleaning Framework for Encrypted Traffic
                  Classification},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--3},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192404},
	doi = {10.1109/ICNP65844.2025.11192404},
	timestamp = {Thu, 13 Nov 2025 08:55:56 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/QiuWLZ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Traffic classification, a technique for assigning network flows to predefined categories, has been widely deployed in enterprise and carrier networks. With the massive adoption of mobile devices, encryption is increasingly used in mobile applications to address privacy concerns. Consequently, traditional methods such as Deep Packet Inspection (DPI) fail to distinguish encrypted traffic. To tackle this challenge, Artificial Intelligence (AI)—in particular Machine Learning (ML)—has emerged as a promising solution for encrypted traffic classification. A crucial prerequisite for any ML-based approach is traffic data cleaning, which removes flows that are not useful for training (e.g., irrelevant protocols, background activity, control-plane messages, and long-lived sessions). Existing cleaning solutions depend on manual inspection of every captured packet, making the process both costly and time-consuming. In this poster, we present an unsupervised framework that automatically cleans encrypted mobile traffic. Evaluation on real-world datasets shows that our framework incurs only a 2% ∼ 2.5% reduction in classification accuracy compared with manual cleaning. These results demonstrate that our method offers an efficient and effective preprocessing step for ML-based encrypted traffic classification.}
}


@inproceedings{DBLP:conf/icnp/GuoLLSW25,
	author = {Kejun Guo and
                  Fuliang Li and
                  Yuting Liu and
                  Jiaxing Shen and
                  Xingwei Wang},
	title = {RA-Sketch: {A} Unified Framework for Rapid and Accurate Sketch Configurations},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--11},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192332},
	doi = {10.1109/ICNP65844.2025.11192332},
	timestamp = {Thu, 13 Nov 2025 08:55:56 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/GuoLLSW25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Network measurement sketches enable efficient traffic monitoring but require careful parameter configuration to balance accuracy and memory efficiency. We present RA-Sketch, a framework for generating memory-optimal sketch configurations that satisfy user-defined error constraints across diverse network measurement tasks. Unlike existing approaches that rely on computationally intensive experimental testing, RA-Sketch introduces: 1) Poisson-distributed collision modeling to construct error predictors for both frequency-independent tasks (membership query, heavy-hitter detection) and frequency-dependent tasks (frequency/cardinality estimation), eliminating the need for empirical validation; 2) A hierarchical search strategy combining power-of-two scaling and binary search, reducing iterations through optimized parameter initialization. RA-Sketch supports 10+ sketch architectures including Bloom Filter, Elastic Sketch, HeavyGuardian, HeavyKeeper, CM/CO Sketch, gSkt, rSkt1 and so on. Evaluations on real-world network traces demonstrate: 1) 6–7 orders of magnitude faster configuration than benchmark-based methods; 2) Prediction errors ≤10% for heavy-hitter detection, while prediction errors for membership query, and frequency/cardinality estimation are close to zero; 3) Memory utilization approaches theoretical minima. The framework’s generality and efficiency enable real-time reconfiguration of sketches under dynamic network conditions.}
}


@inproceedings{DBLP:conf/icnp/AsgharHJKKMKBL25,
	author = {Hassan Asghar and
                  Myeong{-}Ha Hwang and
                  Jeonghyun Joo and
                  Heewoon Kang and
                  YooJin Kwon and
                  Kazi Samin Mubasshir and
                  Imtiaz Karim and
                  Elisa Bertino and
                  Hyunwoo Lee},
	title = {Poster: Automated Security Property Extraction from Protocol Specifications},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--3},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192438},
	doi = {10.1109/ICNP65844.2025.11192438},
	timestamp = {Wed, 03 Dec 2025 15:49:33 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/AsgharHJKKMKBL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Formal verification of network protocols is a security-by-design approach, but extracting security properties from long, complex specifications remains manual, time-consuming, labor-intensive, and error-prone. We propose SPARTA, a framework that automatically extracts useful security properties from network specifications leveraging large language models (LLMs) and a three-step retrieval-augmented generation (RAG) pipeline.}
}


@inproceedings{DBLP:conf/icnp/ChoLLL25,
	author = {Anna Cho and
                  Gayeong Lee and
                  Sugyeong Lee and
                  SuKyoung Lee},
	title = {Poster: Computation-efficient Decentralized Federated Learning in
                  {LEO} Satellite Network},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--3},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192361},
	doi = {10.1109/ICNP65844.2025.11192361},
	timestamp = {Thu, 13 Nov 2025 08:55:56 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/ChoLLL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Decentralized satellite federated learning (DSFL) enables LEO satellites to collaboratively train models without relying on terrestrial infrastructures. In DSFL, concurrent model updates for multiple services increase the amount of computation on the satellite, which can lead to longer total training time. This paper proposes a computation-efficient DSFL framework to construct the overlay network for services to minimize the total training time. Simulation results demonstrate that the proposed scheme outperforms the baseline algorithms in terms of total training time.}
}


@inproceedings{DBLP:conf/icnp/KwonZ25,
	author = {Dae Cheol Kwon and
                  Xinyu Zhang},
	title = {CP-AgentNet: Autonomous and Explainable Communication Protocol Design
                  Using Generative Agents},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--12},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192445},
	doi = {10.1109/ICNP65844.2025.11192445},
	timestamp = {Thu, 13 Nov 2025 08:55:56 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/KwonZ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Although DRL (deep reinforcement learning) has emerged as a powerful tool for making better decisions than existing hand-crafted communication protocols, it faces significant limitations: 1) Selecting the appropriate neural network architecture and setting hyperparameters are crucial for achieving desired performance levels, requiring domain expertise. 2) The decision-making process in DRL models is often opaque, commonly described as a ‘black box’. 3) DRL models are data hungry. In response, we propose CP-AgentNet, the first framework to employ generative agents as autonomous decision-makers for communication protocol design. This approach addresses these challenges by creating an autonomous system for protocol design, significantly reducing human effort. As practical use cases, we developed LLMA (LLM-agents-based multiple access) and CPTCP (CP-Agent-based TCP) tailored for heterogeneous environments. Our comprehensive simulations have demonstrated the efficient coexistence of LLMA and CPTCP with nodes using different types of protocols, as well as enhanced explainability.}
}


@inproceedings{DBLP:conf/icnp/RenMCLWBWL25,
	author = {Yanyu Ren and
                  Yukai Miao and
                  Li Chen and
                  Dan Li and
                  Xizheng Wang and
                  Yu Bai and
                  Zhiyuan Wu and
                  Fei Long},
	title = {Towards Automatic Network Diagram Comprehension},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--15},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192381},
	doi = {10.1109/ICNP65844.2025.11192381},
	timestamp = {Sun, 01 Feb 2026 13:27:01 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/RenMCLWBWL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Network Diagram Comprehension (NDC) is a vital task for networking professionals, offering essential insights into network topology and configurations. However, NDC remains a labor-intensive process heavily reliant on human expertise, with existing tools falling short in addressing this challenge. It is critical to develop an Automatic NDC (ANDC) system that ensures high faithfulness and completeness in information extraction while supporting practical, end-to-end NDC applications. Moreover, a comprehensive dataset and benchmark are necessary to systematically evaluate and drive the progress of ANDC.In this work, we introduce Layered Extractor of Network Diagrams (LEND), the first ANDC system designed to comprehensively and faithfully extract and utilize information from network diagrams. LEND employs a three-stage pipeline: (1) a layer extractor to decompose diagrams and identify key elements with a denoising cascade, (2) an inter-layer combiner to reconstruct entity relations with positional and domain knowledge, and (3) a task-specific interpreter for networking applications.To support this effort, we develop two extensive NDC datasets comprising over 4,000 network diagrams and icons from diverse sources, along with the first benchmark to evaluate ANDC systems across three distinct metrics. Empirical experiments demonstrate that LEND outperforms existing methods by achieving at 1.21– 5.10× better faithfulness and completeness, and improves its capability as a NetOps engineer by 30.5% on the Cisco Certified Network Associate (CCNA) exam.}
}


@inproceedings{DBLP:conf/icnp/YiWDXDDC25,
	author = {Gang Yi and
                  Tongze Wang and
                  Liang Du and
                  Xiaohui Xie and
                  Ling Deng and
                  Shixian Deng and
                  Yong Cui},
	title = {6GQoS: {A} Flow-Level QoS Assurance Framework for Next-Generation
                  6G Networks},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--11},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192390},
	doi = {10.1109/ICNP65844.2025.11192390},
	timestamp = {Thu, 13 Nov 2025 08:55:56 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/YiWDXDDC25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The 6G network aspires to deliver everyone-centric services with stringent and dynamic QoS demands. Compared to 4G/5G, 6G requires finer-grained, per-flow resource allocation that accounts for real-time traffic variations and highly dynamic wireless channel conditions to improve user satisfaction. However, enabling per-flow QoS introduces substantial complexity in scheduling, and existing heuristic-based approaches—lacking long-term resource planning and global channel awareness—struggle to ensure fairness and service satisfaction, especially under high load and large-scale scenarios.In this paper, we present 6GQoS, a flow-level QoS assurance framework that integrates real-time QoS target setting, long-term resource management, and global channel awareness. 6GQoS continuously monitors user channel conditions, traffic demands, and service-level objectives to dynamically adjust per-flow service targets. It models long-term resource allocation via Lyapunov control theory and incorporates a novel BestUsage algorithm to guide scheduling decisions based on queue states, bandwidth gains, and resource costs. Extensive evaluations show that 6GQoS outperforms all baselines, achieving 40%–80% higher service satisfaction, reducing radio resource usage by 20%–80%, and consistently ensuring 100% fairness.}
}


@inproceedings{DBLP:conf/icnp/TaiLKLHL25,
	author = {Yi{-}An Tai and
                  Yao{-}Wen Liu and
                  Ping{-}Kuan Kao and
                  Ting{-}Yu Lee and
                  Cheng{-}I Hu and
                  Chi{-}Yu Li},
	title = {{LOMAS:} Latency-driven {OFDMA} Scheduling Design in Wi-Fi 6 Networks},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--11},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192340},
	doi = {10.1109/ICNP65844.2025.11192340},
	timestamp = {Thu, 13 Nov 2025 08:55:56 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/TaiLKLHL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The IEEE 802.11ax standard, known as Wi-Fi 6, introduces a key feature, OFDMA (Orthogonal Frequency Division Multiple Access), designed for high-efficiency Wi-Fi. It enables concurrent transmissions for multiple clients through channel multiplexing, reducing contention in dense environments and offering low latency (LL) with consistent data streams. However, our experimental study reveals that while OFDMA can reduce latency, dynamic scheduling is required to consistently meet latency requirements. Moreover, it may perform worse than conventional single-user transmissions in terms of throughput. We thus develop LOMAS (Latency-driven OfdMA Scheduling), a practical latency-driven design for OFDMA, specifically aimed at supporting LL clients in downlink transmissions while maximizing transmission efficiency and ensuring client fairness. Implemented and evaluated using a COTS Wi-Fi 6 NIC, LOMAS consistently outperforms other solutions, meeting latency requirements for LL clients while maintaining fairness with only a minor throughput trade-off. Especially for mobile LL clients, LOMAS satisfies 35.4-78.3% more packets with just a 0.8% throughput loss, given a 20 ms latency requirement. These findings confirm the practicality and effectiveness of LOMAS.}
}


@inproceedings{DBLP:conf/icnp/ZhaoHSSLXL25,
	author = {Yilin Zhao and
                  Jiawei Huang and
                  Xianshi Su and
                  Jing Shao and
                  Yijun Li and
                  Jiacheng Xie and
                  Sitan Li},
	title = {Aion: {A} Memory-Efficient Approach for Long-Term Periodic Flow Detection},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--12},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192447},
	doi = {10.1109/ICNP65844.2025.11192447},
	timestamp = {Sun, 01 Feb 2026 13:27:01 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/ZhaoHSSLXL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Sketch-based measurement approaches have recently become a promising solution for detecting periodic flows. However, current sketch approaches struggle to achieve accurate detection of periodic flows due to their short-sighted record of the flow arrival information. Recording the long-term information of flow arrivals could mitigate this issue, while the large memory consumption will hurt the detection accuracy. Consequently, achieving a satisfactory trade-off between memory efficiency and detection accuracy remains a tough challenge. To address this issue, we propose Aion for periodic flow detection. Specifically, Aion uses the Sidon sequence to compress historical flow arrival information in multiple time windows into very small size. Based on the periodicity information from successive time windows, Aion updates the estimated frequencies of periodic flows and promptly evicts non-periodic ones to enable accurate detection of frequent periodic flows. We implement Aion on a P4-based testbed and demonstrate that it achieves superior resource efficiency compared to state-of-the-art approaches. Trace-driven evaluations show that Aion improves F1-Score by up to 9.88×, particularly under small memory conditions.}
}


@inproceedings{DBLP:conf/icnp/ZhangRYH25,
	author = {Wei Zhang and
                  Gang Ren and
                  Xia Yin and
                  Lin He},
	title = {{PMAPD:} {A} Passive-Enhanced Multi-Level Aliased Prefix Detection
                  Approach for IPv6 Scanning},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--11},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192373},
	doi = {10.1109/ICNP65844.2025.11192373},
	timestamp = {Thu, 13 Nov 2025 08:55:56 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/ZhangRYH25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {IPv6 scanning is a critical technique for network security assessment and Internet measurement. However, the prevalence of aliased prefixes significantly distorts scan results and severely interferes with target generation algorithms (TGAs) that rely on dynamic density feedback. To address the limitations of existing aliased prefix detection methods, such as insufficient accuracy and excessive overhead, this paper proposes PMAPD, a Passive-Enhanced Multi-Level Aliased Prefix Detection approach. PMAPD integrates passive analysis with active probing. The passive analysis component reuses existing scan data—primarily host responsiveness obtained at no extra cost from the main address scan, and opportunistically uses port and service information if available, to enhance detection accuracy and efficiency. The active probing component builds upon the strengths of prior active methods while incorporating optimizations to achieve a better balance between detection precision and cost. Experimental results demonstrate PMAPD’s superiority in improving the discovery of de-aliased active addresses, reducing aliased addresses in scanning results, and significantly lowering detection overhead. Across three different TGAs tested (6Tree, DET, 6Sense), PMAPD significantly outperforms the widely used traditional method MAPD: it improves the de-aliased hits by 12% to 57%, substantially reduces the aliased ratio in scan results by over 9% to 94%, and dramatically lowers detection overhead, costing only 3% to 17% of MAPD’s overhead. PMAPD offers a novel and effective aliased prefix detection solution for efficient and accurate IPv6 network scanning.}
}


@inproceedings{DBLP:conf/icnp/SuWNCJYXXX25,
	author = {Qiang Su and
                  Shaofeng Wu and
                  Zhixiong Niu and
                  Haodong Chen and
                  Riff Jiang and
                  Lizhao You and
                  Qiao Xiang and
                  Hong Xu and
                  Yongqiang Xiong},
	title = {NetSophon: Enabling Runtime Copilot for Programmable Dataplane for
                  Cloud Operators},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--6},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192435},
	doi = {10.1109/ICNP65844.2025.11192435},
	timestamp = {Thu, 13 Nov 2025 08:55:56 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/SuWNCJYXXX25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Runtime traffic analysis on programmable data-plane requires substantial human effort, and the high speed and complexity of dataplane often make human capacity the efficiency bottleneck. While existing work has proposed LLM-based approaches, they typically rely on offline network logs, failing to address the human capacity limitations in real-time environments. This paper explores the potential of leveraging evolving LLMs to mitigate these human-centric challenges in real physical dataplane. It outlines a novel framework called NetSophon, which features an LLM-based brain for efficient decision-making and an effective arm to manipulate and perceive the physical programmable dataplane. Through interactions among the brain, arm, and dataplane, NetSophon acts as a "super-copilot" for human operators, facilitating real-time dataplane traffic analysis at scale. A case study demonstrates NetSophon’s potential to assist human operators in interacting with dataplane.}
}


@inproceedings{DBLP:conf/icnp/LiuTLWGW25,
	author = {Xinyi Liu and
                  Shuai Tong and
                  Hang Li and
                  Jiliang Wang and
                  Shen Gao and
                  Jie Wu},
	title = {Wireless Channels as Fingerprints: Towards Collision-Free LoRa Networks},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--11},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192385},
	doi = {10.1109/ICNP65844.2025.11192385},
	timestamp = {Thu, 13 Nov 2025 08:55:56 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/LiuTLWGW25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {LoRa enables long-range Internet of Things (IoT) connectivity but suffers from collision issues in dense deployments, where concurrent transmissions overlap at gateways, leading to decoding errors. Existing solutions rely on time/frequency separation or protocol modifications, requiring either hardware changes or dedicated codings, and failing to resolve collisions that are completely aligned in time or frequency. We present CD-LoRa, a Channel-Division based LoRa parallel transmission scheme for LoRa collisions. CD-LoRa exploits distinct channel signatures as inherent orthogonal fingerprints, enabling parallel decoding even when collisions are completely aligned. We present a phase calibration model that decouples genuine channel features from hardware imperfections and payload modulation distortions. We enhance low-SNR LoRa signals through energy-concentration processing. We address channel variations in mobile scenarios with a dynamic temporal sequence based clustering design. We implement CD-LoRa on commodity LoRa devices and evaluate its performance in real-world deployments. Experimental results show that CD-LoRa effectively decodes up to 8 time-frequency-aligned packets, and improves network throughput by 1.72× compared to state-of-the-art methods.}
}


@inproceedings{DBLP:conf/icnp/ZhuWLGSLLL25,
	author = {Biaokai Zhu and
                  Zhonghao Wang and
                  Ping Li and
                  Ruize Guo and
                  Jie Song and
                  Feng Li and
                  Yiran Li and
                  Sanman Liu},
	title = {AntScale: Extracting Target LoRa Packets for Cross-channel Collisions
                  Through Antithetical -stationary Scaling},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--11},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192372},
	doi = {10.1109/ICNP65844.2025.11192372},
	timestamp = {Thu, 13 Nov 2025 08:55:56 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/ZhuWLGSLLL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Owing to its ultra-low power consumption and long-range communication capabilities, LoRa, a prominent Low-Power Wide Area Network (LPWAN) technology, has seen widespread deployment across academic and industrial domains. However, its operation in unlicensed spectrum and reliance on ALOHA-based Medium Access Control (MAC) make it highly susceptible to packet collisions, undermining network reliability and performance. While existing efforts primarily address intra-channel collisions, the effects of cross-channel interference—caused by overlapping transmissions using different bandwidths or spreading factors—remain insufficiently studied, posing challenges to communication quality, scalability, and spectrum efficiency. To bridge this gap, we propose AntScale, a novel collision resolution framework based on antithetical - stationary scaling. Specifically, AntScale introduces two key techniques: (1) it transforms minor time-domain signal distortions into robust frequency-domain features through dual antithetical scaling, enabling effective collision suppression; and (2) it employs a patching algorithm that leverages wide-bandwidth signal characteristics to identify and isolate dominant interference components for targeted decoding. Implementation on a USRP N210 platform demonstrates that AntScale achieves a 2.3× throughput improvement over state-of-the-art methods.}
}


@inproceedings{DBLP:conf/icnp/BerralALNSASD25,
	author = {Josep Llu{\'{\i}}s Berral and
                  David Aguilera{-}Luz{\'{o}}n and
                  Peini Liu and
                  Ramon Nou and
                  Maria A. Serrano and
                  Angelos Antonopoulos and
                  Javier Santaella S{\'{a}}nchez and
                  Mario Jos{\'{e}} Div{\'{a}}n},
	title = {Integrating Reliability into Intent-Driven Orchestration on Kubernetes-based
                  Edge Nodes},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--6},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192389},
	doi = {10.1109/ICNP65844.2025.11192389},
	timestamp = {Thu, 13 Nov 2025 08:55:56 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/BerralALNSASD25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Placing workloads across the Edge and Cloud can be performed through containerization. However, conditions in Edge nodes are very different from Cloud, as environmental factors such as temperature, humidity, voltage provisioning or dust, heavily affect execution performance and device health. Reliability is an important factor when deciding to deploy such load onto Edge devices, indicating their capability to achieve a desired Quality of Service (QoS). For this, research on Edge computing must focus on how to monitor, estimate and manage devices, in a distributed, autonomous and reliable manner. Our current efforts on performance analysis for devices under "wild conditions" are moving towards integrating reliability into orchestrator systems. Here we present our vision and roadmap for expanding Cloud orchestration towards the Edge with technologies capable of providing knowledge about node environmental conditions and mitigate its impact. Through Out-Of-Band telemetry, we can retrieve temperature and power consumption variables from node components, indicating its health and estimating its reliability given external stress factors. In particular, using intent-based orchestration for containerized platforms, such factors can be used for enforcing reliability as a key-performance indicator. The current work in progress focuses on industrial and commercial scenarios, e.g., Edge computing for urban mobility, with road-side nodes performing AI-based Video-Analytics, exposed to uncontrolled weather conditions. The principal objective is to achieve an Edge network orchestration that takes into account node health in an automatic manner for reducing operational costs such as energy consumption, device repair and replacement, while maintaining QoS in the Edge.}
}


@inproceedings{DBLP:conf/icnp/ZhangFGGC25,
	author = {Ying Zhang and
                  Yimeng Feng and
                  Lili Guo and
                  Yue Gao and
                  Zhe Chen},
	title = {{ERA-LEO:} An Efficient Rate Adaptation with Probabilistic Constellation
                  Shaping for {LEO} Satellite Networks},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--12},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192403},
	doi = {10.1109/ICNP65844.2025.11192403},
	timestamp = {Thu, 13 Nov 2025 08:55:56 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/ZhangFGGC25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the increasing deployment of Low Earth Orbit (LEO) satellites (e.g., Starlink), rate adaptation has been widely applied in satellite communication systems to rapidly adapt changing satellite-ground channel. However, the state-of-the-art rate adaptation solutions still do not approach the Shannon capacity, since they always operates in discrete steps (e.g., switching between fixed modulation orders and coding rates), leading to abrupt performance deterioration when the channel fluctuates between two thresholds. We propose a new plug-and-play rate adaptation, called ERA-LEO integrated to satellite communication systems without any extra hardware modification. For adapting smoothly to changes in channels, we first design a probabilistic constellation shaping enabled system to provide a continuous and more granular adjustment of the constellation by tuning the probability distribution of symbols. Second, to avoid the frequent feedback, used to select a target probability distribution based on the channel condition, we establish a theoretical model to demonstrate that the SNR of the return link can reliably predict that of the forward link, and present a lightweight prediction mechanism based on neural network. We also implement ERA-LEO prototype using FPGA-based software defined radio platforms. The extensive evaluations demonstrate ERA-LEO achieves an average gain of 2.19 dB compared to state-of-the-art baselines and a 43.08% improvement in network throughput.}
}


@inproceedings{DBLP:conf/icnp/DalgitsisDPLSSA25,
	author = {Michail Dalgitsis and
                  Eftychia G. Datsika and
                  Marc Palac{\'{\i}}n and
                  Peini Liu and
                  Javier Santaella S{\'{a}}nchez and
                  Maria A. Serrano and
                  Angelos Antonopoulos},
	title = {Coupling Orchestration and {DNS} for Seamless Service Migration in
                  the Edge-Cloud Continuum},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--6},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192408},
	doi = {10.1109/ICNP65844.2025.11192408},
	timestamp = {Thu, 13 Nov 2025 08:55:56 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/DalgitsisDPLSSA25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Modern distributed applications increasingly span an edge-cloud continuum, where services may need to dynamically migrate between far-edge, near-edge, and cloud environments to meet latency, resource, or policy constraints. Ensuring seamless service continuity during such migrations remains a significant challenge, particularly due to delays in DNS resolution and inconsistent client routing. This paper presents a modular DNS-driven orchestration framework designed for Kubernetes-based infrastructures. Our approach integrates service orchestration logic with a shared DNS component to enable fast and autonomous service redirection without relying on public DNS providers or complex service meshes. By coupling orchestrator-triggered migrations with DNS record updates, the system ensures immediate service reachability after migration. An optional analytics and decision engine complements the framework by triggering orchestrator actions based on monitoring insights. We evaluate the DNS reconfiguration performance of our solution compared to traditional ExternalDNS-based architectures, demonstrating significantly lower propagation latency and higher determinism during service migrations across the edge–cloud continuum.}
}


@inproceedings{DBLP:conf/icnp/CuiLLWS25,
	author = {Jiamin Cui and
                  Cheng Long and
                  Zonghui Li and
                  Rui Wang and
                  Kang G. Shin},
	title = {Time-Triggered Flow Scheduling for Synchronization-Deviation-Tolerant
                  {TSN}},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--11},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192458},
	doi = {10.1109/ICNP65844.2025.11192458},
	timestamp = {Thu, 13 Nov 2025 08:55:56 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/CuiLLWS25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Time-sensitive networking (TSN) has been widely used in industrial automation and automotive applications by precisely opening and closing the gates of packet queues. However, both clock drift and network congestion will likely result in timing misalignment when the clock synchronization protocol gPTP (802.1 AS) is used. This timing misalignment may, in turn, cause failure in forwarding packets at scheduled times and hence unexpected delay jitters, or even miss application deadlines. To address this acute problem, we propose a novel TSN scheduling algorithm, called SDT-TSN (Synchronization-Deviation-Tolerant TSN), to ensure that packets can still arrive on time and be transmitted deterministically even in the presence of inexact time synchronization. First, we formalize the linear constraint model of flow scheduling to maximize the tolerance of inexact time synchronization. Then, we propose an optimal algorithm based on SMT (Satisfiability Modulo Theories) and a fast heuristic algorithm to solve the packet scheduling problem under inexact network synchronization. SDT-TSN is the first to derive the maximum tolerable time-synchronization deviation. Finally, we evaluate SDT-TSN, demonstrating its capability of eliminating packet-forwarding failures due to the commonly-used/assumed constant time-synchronization deviation and increasing the tolerable synchronization deviation from 140µs to 480µs.}
}


@inproceedings{DBLP:conf/icnp/WangZLZJ25,
	author = {Lei Wang and
                  Qingsong Zou and
                  Qing Li and
                  Jianping Zhang and
                  Yong Jiang},
	title = {{ARTEMIS:} Adaptive Reweighing for Transferable Evasion via Meta-learning
                  in Zero-Query Network Intrusion Detection Systems},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--12},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192405},
	doi = {10.1109/ICNP65844.2025.11192405},
	timestamp = {Thu, 13 Nov 2025 08:55:56 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/WangZLZJ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Machine Learning-based Network Intrusion Detection Systems (ML-NIDSes) are vital for cyber-security, yet their inherent vulnerability to adversarial attacks poses a persistent challenge. Among these, zero-query transfer-based attacks present a particularly realistic and formidable threat, as adversaries operate with no knowledge of or interaction with the target NIDS. However, the efficacy of such attacks is critically hampered by poor adversarial transferability across diverse NIDS model architectures and by strict protocol-defined constraints on network traffic modifications. To probe the robustness of NIDSes under zero-query attacks, we introduce ARTEMIS, a novel hybrid attack framework engineered to dramatically enhance adversarial transferability for zero-query attacks. ARTEMIS leverages the generalization capabilities of meta-learning to adapt to unknown target models by simulating diverse black-box transfer tasks. Simultaneously, it combines a reinforcement learning-inspired adaptive reweighing mechanism to maximize transfer potential by promoting the effective use of heterogeneous substitute ensembles. Extensive evaluations on the BCCC-CIC-IDS2017/2018 datasets across closed-set, open-set, and cross-set zero-query scenarios confirm that ARTEMIS significantly outperforms state-of-the-art baselines. Our work presents a powerful methodology for NIDS vulnerability assessment and provides crucial insights for developing defenses against transfer-based evasions.}
}


@inproceedings{DBLP:conf/icnp/ZhouLHSYWCGY25,
	author = {Jiasheng Zhou and
                  Ying Liu and
                  Lin He and
                  Xiaoyi Shi and
                  Yifan Yang and
                  Chentian Wei and
                  Daguo Cheng and
                  Wenwen Gong and
                  Jiahai Yang},
	title = {Lightning in the Dark: Uncovering Global IPv6 Router Interfaces and
                  Their Security Implications},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--14},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192454},
	doi = {10.1109/ICNP65844.2025.11192454},
	timestamp = {Thu, 13 Nov 2025 08:55:56 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/ZhouLHSYWCGY25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The IPv6 routing infrastructure is an important part of the modern Internet, and the collection of its interface addresses is greatly significant in network security, performance optimization, and measurement analysis. However, existing methods suffer from two major problems: the lack of flexibility in budget allocation across probing rounds and the absence of a dynamic hop limit adjustment mechanism based on feedback. These problems lead to the low hit rate and inefficiency of existing methods for discovering router interfaces, which seriously hinders the comprehensive knowledge of IPv6 routing infrastructure.To this end, we propose Helixir, a feedback-based, high hit-rate, and efficient IPv6 router interface discovery system. Helixir’s core design includes a dynamic budget allocation mechanism across probing rounds, an inter-prefix budget allocation strategy that adequately trades off exploration and exploitation, and a hop limit selection method based on Thompson sampling. Real-world experiments show that with a 100M budget, Helixir achieves a hit rate 3.64× that of state-of-the-art methods on the BGP prefixes dataset, and Helixir successfully discovers over 31 million IPv6 router interface addresses in total within half an hour. In addition, a systematic security analysis of the discovered router interfaces shows that many devices open sensitive ports and expose hundreds of potential CVE vulnerabilities, highlighting the security risks in the IPv6 network.}
}


@inproceedings{DBLP:conf/icnp/KhalidAZS25,
	author = {Ahmed Khalid and
                  Ali Amin and
                  Tarek Zaarour and
                  Michal Sworzeniowski},
	title = {Intent-Based Agentic {AI} Framework For Data Placement in Compute
                  Continuum},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--6},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192424},
	doi = {10.1109/ICNP65844.2025.11192424},
	timestamp = {Thu, 13 Nov 2025 08:55:56 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/KhalidAZS25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Modern data-intensive applications require adaptive, goal-driven infrastructures, yet the growing complexity of the compute continuum makes it increasingly difficult for existing approaches to autonomously manage data placement in accordance with evolving user intents and real-time system states. In this paper, we propose a modular Intent-Based Agentic AI Framework that can accurately capture high-level user objectives, reason over distributed resource conditions, and automate data placement in a scalable and interpretable manner. Unlike static rule-based systems, our framework supports interactive user-agent interactions and adaptive forecasting to recommend and apply optimal storage and caching strategies across distributed cloud-edge environments. Our prototype implementation showed an accurate response to user inputs at 88%, and achieved objectives in around 30 seconds. This implementation and results demonstrate the feasibility and efficacy of the proposed solution.}
}


@inproceedings{DBLP:conf/icnp/DuDGZTG25,
	author = {Jialu Du and
                  Lintong Du and
                  Zeming Gao and
                  Yuchao Zhang and
                  Ye Tian and
                  Xiangyang Gong},
	title = {A CoT Reasoning-Based Computation and Network Resource Deployment
                  Intent Translation Framework},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--6},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192366},
	doi = {10.1109/ICNP65844.2025.11192366},
	timestamp = {Thu, 13 Nov 2025 08:55:56 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/DuDGZTG25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Advancements in distributed machine learning have led to a demand for engineers with knowledge in AI, hardware, and networking. Research aims to automate deployment based on user intent to improve development efficiency. Large Language Models (LLMs) assist in translating user intent for resource allocation but face challenges in translation accuracy and contextual integrity. The Chain-of-Thought (CoT) improves LLM reasoning by breaking down problems into sequential steps. However, the reasoning steps and dependencies between the model requirements and the computation and network configurations are complex, requiring the selection of an appropriate thought path to construct the CoT framework. To address these issues, we propose a computation and network resource deployment intent translation framework based on CoT reasoning and create a benchmark for user intent in distributed learning. This framework translates user intent into hardware and network configurations, using LLMs to optimize translation accuracy through logical reasoning. Experiments on four LLM models show significant accuracy improvements with CoT compared to traditional prompts. The feasibility of our framework has been validated through its implementation and testing on a real-world testbed.}
}


@inproceedings{DBLP:conf/icnp/ZhangLZSGCLXW25,
	author = {Yaqiang Zhang and
                  Rengang Li and
                  Yaqian Zhao and
                  Hongzhi Shi and
                  Fei Gao and
                  Xiaolin Chen and
                  Xiao Li and
                  Guangyuan Xu and
                  Ke Wang},
	title = {Proactive Fault-tolerance Driven Task Scheduling System for IoV Edge
                  Networks},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--6},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192432},
	doi = {10.1109/ICNP65844.2025.11192432},
	timestamp = {Thu, 13 Nov 2025 08:55:56 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/ZhangLZSGCLXW25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The emergence of Internet of Vehicles (IoV) technology provides a wider range of application scenarios for edge computing based on Vehicle-to-everything (V2X). It is essential to ensure the high availability and reliability of services in IoV systems. Currently, cloud service providers have established a data center level of fault tolerance, such as redundancy and checkpoints, guaranteeing the reliability of cloud infrastructure and reducing phenomena such as service termination or downtime. However, current computing systems reactively handle failures. Especially in edge computing, this approach not only lacks flexibility but also consumes excessive system resources, which is not conducive to ensuring the reliability in resource-constrained systems and poses security risks to end users. To mitigate this problem, we propose a Proactive Fault-tolerance Driven Task Scheduling System. Different from the traditional reactive strategies, the proposed framework predicts the possible system crashes by monitoring the critical state indicators of the computing system. According to the prediction results, a class of tasks or services that are most likely to be terminated are rescheduled in advance. Extensive experiments are conducted, and evaluation results demonstrate that our proposed proactive fault tolerance framework can effectively improve the long-term performance of the IoV edge system.}
}


@inproceedings{DBLP:conf/icnp/LuoZC25,
	author = {Zhuangye Luo and
                  Feng Zeng and
                  Xi Chen},
	title = {TSN-Counter: Dual-Granularity Cooperative Time Failure Detection and
                  Classification in {TSN}},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--11},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192337},
	doi = {10.1109/ICNP65844.2025.11192337},
	timestamp = {Thu, 13 Nov 2025 08:55:56 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/LuoZC25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Time Sensitive Networking (TSN) provides deterministic transmission services for critical traffic (CT) through clock synchronization, traffic shaper, and traffic scheduling algorithms. However, time failures occurring at network nodes may cause some CT packets to be forwarded unscheduled, thereby destroying deterministic guarantees and affecting overall system stability. In this paper, we classify time failures into node-level and port-level failures, and present a counter-based mechanism called TSN-Counter for failure detection in TSN, which leverages periodic CT behavior to detect and classify timing faults with minimal overhead. First, a lightweight twostage detector flags any coarse-slot violation and immediately pinpoints the culprit port in a fine-slot pass. Next, a compact hash-tree structure with bounded fallback efficiently narrows down the set of affected flows, and a simple time-window check prunes spurious alarms. Finally, concise per-switch reports are aggregated at the controller for accurate fault tracing. Simulation results demonstrate that TSN-Counter can obtain much better performance than baseline methods, achieving 100% precision with over 98% recall and near-zero relative error. Compared with the state-of-the-art designs, TSN-Counter has the failure detection time decreased by 75.9% in various fault scenarios.}
}


@inproceedings{DBLP:conf/icnp/LiBCFP25,
	author = {Weihe Li and
                  Beyza B{\"{u}}t{\"{u}}n and
                  Tianyue Chu and
                  Marco Fiore and
                  Paul Patras},
	title = {Pallas: {A} Data-Plane-Only Approach to Accurate Persistent Flow Detection
                  on Programmable Switches in High-Speed Networks},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--11},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192401},
	doi = {10.1109/ICNP65844.2025.11192401},
	timestamp = {Thu, 13 Nov 2025 08:55:56 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/LiBCFP25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In high-speed data center networks, persistent flows are repeatedly observed over extended periods, potentially signaling threats such as stealthy DDoS or botnet attacks. Monitoring every flow in production-grade hardware switches that feature limited memory, however, is challenging under typical high flow rates and data volumes. To tackle this, approximate data structures, like sketches, are often employed. Yet many existing methods rely on per-time-window flag resets, which require frequent control-plane interventions that make them unsuitable for high-speed traffic. This paper introduces Pallas, a fully data-plane-implementable sketch for detecting persistent flows in high-speed networks with high accuracy, obviating the need for time-window-based resets. We further propose Opt-Pallas, an enhanced variant of Pallas that improves detection accuracy by incorporating flow arrival patterns. We present a rigorous error bound analysis for both Pallas and Opt-Pallas, along with extensive performance evaluations using a P4-based prototype on an Intel Tofino switch. Pallas scales persistent flow detection to line-rate capacity, while state-of-the-art solutions fail to operate beyond a few Mbps. Our results show that Pallas and Opt-Pallas can accurately detect persistent flows in traffic volumes over 60× higher than those handled by the best existing approach. Additionally, even under low-speed traffic, Pallas and Opt-Pallas achieve 4.21% and 7.85% higher lookup accuracy while consuming only 8.5% and 9.7% of switch resources, respectively. Extensive trace-driven results on a CPU platform further validate the high detection accuracy of Opt-Pallas compared to existing methods.}
}


@inproceedings{DBLP:conf/icnp/SchneiderMV25,
	author = {Tibor Schneider and
                  Jean M{\'{e}}gret and
                  Laurent Vanbever},
	title = {Guided Exploration of Control-Plane Routing States},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--12},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192328},
	doi = {10.1109/ICNP65844.2025.11192328},
	timestamp = {Sun, 07 Dec 2025 22:11:03 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/SchneiderMV25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent years, significant progress has been made towards scalable network control-plane verification. Yet, operators are still hesitant to deploy such systems. We argue that this reluctance is in part due to a semantic gap between operators reasoning about routing states and verifiers exploring the space of environments. Indeed, operators express the specification in terms of behavior of routing states, while verifiers usually rely on solvers to find specific environments that violate the specification. This semantic gap prevents users from guiding these solvers to directly explore routing states that violate the specification, or to search for states that are most relevant or likely.In this paper, we present a new approach for flexible control-plane verification. Instead of relying on rigid off-the-shelf solvers, we design a novel backtracking algorithm to directly explore the space of routing states. This enables users to guide the exploration according to the specification and domain-specific knowledge from operators. This algorithm paves the way for novel use cases, ranging from finding relevant (e.g., likely) counterexamples to performing verification of probabilistic specifications.}
}


@inproceedings{DBLP:conf/icnp/GongXSYPX25,
	author = {Qianyun Gong and
                  Jiapei Xu and
                  Jianxin Shi and
                  Xinjing Yuan and
                  Lingjun Pu and
                  Jingdong Xu},
	title = {Flick: Frame-Perceptive Packet Scheduling for Low-Latency Video Services
                  in Wi-Fi Networks},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--13},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192371},
	doi = {10.1109/ICNP65844.2025.11192371},
	timestamp = {Thu, 22 Jan 2026 07:41:23 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/GongXSYPX25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Emerging low-latency video (LLV) services, such as cloud gaming, video conferencing, and virtual reality, demand ultra-low latency for smooth interaction. However, existing methods often overlook the misalignment between frame-level perception and packet-level scheduling in ubiquitous Wi-Fi networks, causing high tail latency and degraded user experience. To this end, we propose Flick, a frame-perceptive packet scheduling framework at Wi-Fi access points (APs). It leverages the periodic per-frame transmission behavior and the LLV traffic distribution characteristics to infer the end-to-end frame latency at APs. Flick consists of three components: a Frame Boundary Identifier that detects video frame boundaries using only packet size, an End-to-End Frame Latency Estimator that estimates the end-to-end latency without sender or receiver timestamps, and a Fast-Send, Slow-Recovery Scheduler that dynamically adjusts scheduling priority based on inferred latency. We implement Flick on a commercial Wi-Fi AP. Testbed results show that Flick reduces P99 latency and stall rate by 57% and 81%, respectively, while preserving 95% throughput and maintaining high fairness.}
}


@inproceedings{DBLP:conf/icnp/ZuZCJZW25,
	author = {Jinghan Zu and
                  Zhengyan Zhou and
                  Lingfei Cheng and
                  Zhongfeng Jin and
                  Haifeng Zhou and
                  Chunming Wu},
	title = {SkewTide: Bridging Efficiency and Tail Latency in Key-Value Stores
                  via Kernel Re-Architecture},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--12},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192439},
	doi = {10.1109/ICNP65844.2025.11192439},
	timestamp = {Thu, 13 Nov 2025 08:55:56 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/ZuZCJZW25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Key-value stores are the key building block of online services such as e-commerce. However, highly skewed workloads (i.e., skewed access frequency and request size) may cause severe load imbalance and head-of-line blocking, resulting in significant performance penalty (e.g., low throughput and high latency). Existing works mitigate skewed workloads, but often struggle to balance CPU efficiency with low tail latency or require specialized hardware. In this paper, we present SkewTide, an in-kernel architecture that breaks this trade-off through workload-aware request pre-processing and bypassing unnecessary network stack operations. Moreover, SkewTide carefully orchestrates size-aware parsing, sharding, caching, and queueing in the kernel. Both designs enable efficient CPU multiplexing and preserve low tail latency without specialized hardware. We implement SkewTide as an out-of-the-box framework using eBPF, making it readily deployable in existing key-value store infrastructure. Evaluation with YCSB traces shows that SkewTide achieves up to 8.1× higher throughput, 37% lower 99th-percentile latency, and 32% lower CPU usage compared to existing systems.}
}


@inproceedings{DBLP:conf/icnp/ZhouWZHLY25,
	author = {Yunxiang Zhou and
                  Junzhe Wu and
                  Daolin Zou and
                  Yanan Huang and
                  Long Luo and
                  Hongfang Yu},
	title = {Poster: Optimizing Transmission for Privacy-Preserving Edge-Cloud
                  Split {LLM} Inference},
	booktitle = {33rd {IEEE} International Conference on Network Protocols, {ICNP}
                  2025, Seoul, Republic of Korea, September 22-25, 2025},
	pages = {1--2},
	publisher = {{IEEE}},
	year = {2025},
	url = {https://doi.org/10.1109/ICNP65844.2025.11192440},
	doi = {10.1109/ICNP65844.2025.11192440},
	timestamp = {Thu, 13 Nov 2025 08:55:56 +0100},
	biburl = {https://dblp.org/rec/conf/icnp/ZhouWZHLY25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Today’s cloud-centric Large Language Model (LLM) inference can raise privacy concerns, as raw user data is sent over public networks. Split LLM inference offers a promising alternative by handling sensitive stages, such as prefill and input/output decoding, locally at the edge while offloading heavy intermediate decoding layers to the cloud. This approach could enhance privacy, yet it introduces a key challenge: how to transfer large intermediate vectors with ultra-low latency and high reliability over dynamic networks. We explore a potential transmission framework combining (i) dynamic congestion control to adapt flow and reduce queueing/loss, and (ii) adaptive FEC and quantization to balance redundancy with compression. Preliminary results indicate that this approach can achieve lower per-token latency and higher throughput than TCP/QUIC, enabling privacy-preserving LLM services that remain highly responsive and aligned with real-time user experience demands.}
}
