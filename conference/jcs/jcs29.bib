@article{DBLP:journals/jcs/ShiraziBRA21,
	author = {Hossein Shirazi and
                  Bruhadeshwar Bezawada and
                  Indrakshi Ray and
                  Chuck Anderson},
	title = {Directed adversarial sampling attacks on phishing detection},
	journal = {J. Comput. Secur.},
	volume = {29},
	number = {1},
	pages = {1--23},
	year = {2021},
	url = {https://doi.org/10.3233/JCS-191411},
	doi = {10.3233/JCS-191411},
	timestamp = {Mon, 28 Aug 2023 21:25:00 +0200},
	biburl = {https://dblp.org/rec/journals/jcs/ShiraziBRA21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Phishing websites trick honest users into believing that they interact with a legitimate website and capture sensitive information, such as user names, passwords, credit card numbers, and other personal information. Machine learning is a promising technique to distinguish between phishing and legitimate websites. However, machine learning approaches are susceptible to adversarial learning  attacks where a phishing sample can bypass classifiers. Our experiments on publicly available datasets reveal that the phishing detection mechanisms are vulnerable to adversarial learning attacks. We investigate the robustness of machine learning-based phishing detection in the face of adversarial learning attacks.  We propose a practical approach to simulate such attacks by generating adversarial samples through direct feature manipulation. To enhance the sample’s success probability, we describe a clustering approach that guides an attacker to select the best possible phishing samples that can bypass the classifier by appearing as legitimate samples. We define the notion of vulnerability level  for each dataset that measures the number of features that can be manipulated and the cost for such manipulation. Further, we clustered phishing samples and showed that some clusters of samples are more likely to exhibit higher vulnerability levels than others. This helps an adversary identify the best candidates of phishing samples to generate adversarial samples at a lower cost. Our finding can be used to refine the dataset and develop better learning models to compensate for the weak samples in the training dataset. }
}


@article{DBLP:journals/jcs/HuAB21,
	author = {Qinwen Hu and
                  Muhammad Rizwan Asghar and
                  Nevil Brownlee},
	title = {A large-scale analysis of {HTTPS} deployments: Challenges, solutions,
                  and recommendations},
	journal = {J. Comput. Secur.},
	volume = {29},
	number = {1},
	pages = {25--50},
	year = {2021},
	url = {https://doi.org/10.3233/JCS-200070},
	doi = {10.3233/JCS-200070},
	timestamp = {Mon, 05 Feb 2024 20:26:30 +0100},
	biburl = {https://dblp.org/rec/journals/jcs/HuAB21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {HTTPS refers to an application-specific implementation that runs HyperText Transfer Protocol (HTTP) on top of Secure Socket Layer (SSL) or Transport Layer Security (TLS). HTTPS is used to provide encrypted communication and secure identification of web servers and clients, for different purposes such as online banking and e-commerce. However, many HTTPS vulnerabilities have been disclosed in recent years. Although many studies have pointed out that these vulnerabilities can lead to serious consequences, domain administrators seem to ignore them. In this study, we evaluate the HTTPS security level of Alexa’s top 1 million domains from two perspectives. First, we explore which popular sites are still affected by those well-known security issues. Our results show that less than 0.1% of HTTPS-enabled servers in the measured domains are still vulnerable to known attacks including Rivest Cipher 4 (RC4), Compression Ratio Info-Leak Mass Exploitation (CRIME), Padding Oracle On Downgraded Legacy Encryption (POODLE), Factoring RSA Export Keys (FREAK), Logjam, and Decrypting Rivest–Shamir–Adleman (RSA) using Obsolete and Weakened eNcryption (DROWN). Second, we assess the security level of the digital certificates used by each measured HTTPS domain. Our results highlight that less than 0.52% domains use the expired certificate, 0.42% HTTPS certificates contain different hostnames, and 2.59% HTTPS domains use a self-signed certificate. The domains we investigate in our study cover 5 regions (including ARIN, RIPE NCC, APNIC, LACNIC, and AFRINIC) and 61 different categories such as online shopping websites, banking websites, educational websites, and government websites. Although our results show that the problem still exists, we find that changes have been taking place when HTTPS vulnerabilities were discovered. Through this three-year study, we found that more attention has been paid to the use and configuration of HTTPS. For example, more and more domains begin to enable the HTTPS protocol to ensure a secure communication channel between users and websites. From the first measurement, we observed that many domains are still using TLS 1.0 and 1.1, SSL 2.0, and SSL 3.0 protocols to support user clients that use outdated systems. As the previous studies revealed security risks of using these protocols, in the subsequent studies, we found that the majority of domains updated their TLS protocol on time. Our 2020 results suggest that most HTTPS domains use the TLS 1.2 protocol and show that some HTTPS domains are still vulnerable to the existing known attacks. As academics and industry professionals continue to disclose attacks against HTTPS and recommend the secure configuration of HTTPS, we found that the number of vulnerable domain is gradually decreasing every year. }
}


@article{DBLP:journals/jcs/GriscioliP21,
	author = {Federico Griscioli and
                  Maurizio Pizzonia},
	title = {USBCaptchaIn: Preventing (un)conventional attacks from promiscuously
                  used {USB} devices in industrial control systems},
	journal = {J. Comput. Secur.},
	volume = {29},
	number = {1},
	pages = {51--76},
	year = {2021},
	url = {https://doi.org/10.3233/JCS-191404},
	doi = {10.3233/JCS-191404},
	timestamp = {Mon, 28 Aug 2023 21:25:03 +0200},
	biburl = {https://dblp.org/rec/journals/jcs/GriscioliP21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Industrial Control Systems (ICS) are sensible targets for high profile attackers and advanced persistent threats, which are known to exploit USB thumb drives as an effective spreading vector. In ICSes, thumb drives are widely used to transfer files among disconnected systems and represent a serious security risks, since, they may be promiscuously used in both critical and regular systems. The threats come both from malware hidden in files stored in the thumb drives and from BadUSB attacks. BadUSB leverages the modification of firmware of USB devices in order to mimic the behaviour of a keyboard and send malicious commands to the host.  We present a solution that allows a promiscuous use of USB thumbs drives while protecting critical machines from malware, that spreads by regular file infection or by firmware infection. The main component of the architecture we propose is an hardware, called USBCaptchaIn, intended to be in the middle between critical machines and connected USB devices. We do not require users to change the way they use thumb drives. To avoid human-errors, we do not require users to take any decision. The proposed approach is highly compatible with already deployed products of a ICS environment and proactively blocks malware before they reach their targets. We describe our solution, provide a thorough analysis of the security of our approach in the ICS context, and report the informal feedback of some experts regarding our first prototypes. }
}


@article{DBLP:journals/jcs/BodeiCDFGLTV21,
	author = {Chiara Bodei and
                  Lorenzo Ceragioli and
                  Pierpaolo Degano and
                  Riccardo Focardi and
                  Letterio Galletta and
                  Flaminia L. Luccio and
                  Mauro Tempesta and
                  Lorenzo Veronese},
	title = {{FWS:} Analyzing, maintaining and transcompiling firewalls},
	journal = {J. Comput. Secur.},
	volume = {29},
	number = {1},
	pages = {77--134},
	year = {2021},
	url = {https://doi.org/10.3233/JCS-200017},
	doi = {10.3233/JCS-200017},
	timestamp = {Mon, 28 Aug 2023 21:25:00 +0200},
	biburl = {https://dblp.org/rec/journals/jcs/BodeiCDFGLTV21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Firewalls are essential for managing and protecting computer networks. They permit specifying which packets are allowed to enter a network, and also how these packets are modified by IP address translation and port redirection. Configuring a firewall is notoriously hard, and one of the reasons is that it requires using low level, hard to interpret, configuration languages. Equally difficult are policy maintenance and refactoring, as well as porting a configuration from one firewall system to another.  To address these issues we introduce a pipeline that assists system administrators in checking if: (i) \xa0the intended security policy is actually implemented by a configuration; (ii) \xa0two configurations are equivalent; (iii) \xa0updates have the desired effect on the firewall behavior; (iv) \xa0there are useless or redundant rules; additionally, an administrator can (v) \xa0transcompile a configuration into an equivalent one in a different language; and (vi) \xa0maintain a configuration using a generic, declarative language that can be compiled into different target languages.  The pipeline is based on IFCL , an intermediate firewall language equipped with a formal semantics, and it is implemented in an open source tool called FWS. In particular, the first stage decompiles real firewall configurations for iptables , ipfw , pf \xa0and (a subset of) Cisco\xa0IOS \xa0into IFCL . The second one transforms an IFCL \xa0configuration into a logical predicate and uses the Z3 solver to synthesize an abstract specification that succinctly represents the firewall behavior. System administrators can use FWS\xa0to analyze the firewall by posing SQL-like queries, and update the configuration to meet the desired security requirements. Finally, the last stage allows for maintaining a configuration by acting directly on its abstract specification and then compiling it to the chosen target language. Tests on real firewall configurations show that FWS\xa0can be fruitfully used in real-world scenarios. }
}


@article{DBLP:journals/jcs/MittalR21,
	author = {Sonam Mittal and
                  K. R. Ramkumar},
	title = {Research perspectives on fully homomorphic encryption models for cloud
                  sector},
	journal = {J. Comput. Secur.},
	volume = {29},
	number = {2},
	pages = {135--160},
	year = {2021},
	url = {https://doi.org/10.3233/JCS-200071},
	doi = {10.3233/JCS-200071},
	timestamp = {Mon, 28 Aug 2023 21:25:03 +0200},
	biburl = {https://dblp.org/rec/journals/jcs/MittalR21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As there is a continuous delivery of big data, the researchers are showing interest in the applications of cloud computing concerning privacy, and security. On the other hand, many researchers and experts of cybersecurity have commenced on a quest for improving the data encryption to the models of big data and applications of cloud computing. Since many users of the cloud become public cloud services, confidentiality turns out to be a more compound problem. To solve the confidentiality problem, cloud clients maintain the data on the public cloud. Under this circumstance, Homomorphic Encryption (HE) appears as a probable solution, in which the information of the client is encrypted on the cloud in such a process that it permits few manipulation operations without decryption. The main intent of this paper is to present the systematic review of research papers published in the field of Fully Homomorphic Encryption (FHE) over the past 10 years. The encryption scheme is considered full when it consists of plaintext, a ciphertext, a keyspace, an encryption algorithm, and a decryption algorithm. Hence, the review mostly concentrates on reviewing more powerful and recent FHE. The contributions using different algorithms in FHE like Lattice-based, integer-based, Learning With Errors (LWE), Ring Learning With Errors (RLWE), and Nth degree Truncated polynomial Ring Units (NTRU) are also discussed. Finally, it highlights the challenges and gaps to be addressed in modeling and learning about competent, effectual, and vigorous FHE for the cloud sector and pays attention to directions for better future research. }
}


@article{DBLP:journals/jcs/XuCTLS21,
	author = {Zhiwu Xu and
                  Hongxu Chen and
                  Alwen Tiu and
                  Yang Liu and
                  Kunal Sareen},
	title = {A permission-dependent type system for secure information flow analysis},
	journal = {J. Comput. Secur.},
	volume = {29},
	number = {2},
	pages = {161--228},
	year = {2021},
	url = {https://doi.org/10.3233/JCS-200036},
	doi = {10.3233/JCS-200036},
	timestamp = {Fri, 24 Nov 2023 19:42:21 +0100},
	biburl = {https://dblp.org/rec/journals/jcs/XuCTLS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We introduce a novel type system for enforcing secure information flow in an imperative language. Our work is motivated by the problem of statically checking potential information leakage in Android applications. To this end, we design a lightweight type system featuring Android permission model, where the permissions are statically assigned to applications and are used to enforce access control in the applications. We take inspiration from a type system by Banerjee and Naumann to allow security types to be dependent on the permissions of the applications. A\xa0novel feature of our type system is a typing rule for conditional branching induced by permission testing, which introduces a merging operator on security types, allowing more precise security policies to be enforced. The soundness of our type system is proved with respect to non-interference. A\xa0type inference algorithm is also presented for the underlying security type system, by reducing the inference problem to a constraint solving problem in the lattice of security types. In addition, a new way to represent our security types as reduced ordered binary decision diagrams is proposed. }
}


@article{DBLP:journals/jcs/GrontasPZZ21,
	author = {Panagiotis Grontas and
                  Aris Pagourtzis and
                  Alexandros Zacharakis and
                  Bingsheng Zhang},
	title = {Publicly auditable conditional blind signatures},
	journal = {J. Comput. Secur.},
	volume = {29},
	number = {2},
	pages = {229--271},
	year = {2021},
	url = {https://doi.org/10.3233/JCS-181270},
	doi = {10.3233/JCS-181270},
	timestamp = {Mon, 28 Aug 2023 21:25:04 +0200},
	biburl = {https://dblp.org/rec/journals/jcs/GrontasPZZ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This work formalizes Publicly Auditable Conditional Blind Signatures (PACBS) , a new cryptographic primitive that allows the verifiable issuance of blind signatures, the validity of which is contingent upon a predicate and decided by a designated verifier. In particular, when a user requests the signing of a message, blinded to protect her privacy, the signer embeds data in the signature that makes it valid if and only if a condition holds. A verifier, identified by a private key, can check the signature and learn the value of the predicate. Auditability mechanisms in the form of non-interactive zero-knowledge proofs are provided, so that a cheating signer cannot issue arbitrary signatures and a cheating verifier cannot ignore the embedded condition. The security properties of this new primitive are defined using cryptographic games. A proof-of-concept construction, based on the Okamoto–Schnorr blind signatures infused with a plaintext equivalence test is presented and its security is analyzed. }
}


@article{DBLP:journals/jcs/TianLDSY21,
	author = {Yangguang Tian and
                  Yingjiu Li and
                  Robert H. Deng and
                  Binanda Sengupta and
                  Guomin Yang},
	title = {Lattice-based remote user authentication from reusable fuzzy signature},
	journal = {J. Comput. Secur.},
	volume = {29},
	number = {3},
	pages = {273--298},
	year = {2021},
	url = {https://doi.org/10.3233/JCS-191370},
	doi = {10.3233/JCS-191370},
	timestamp = {Mon, 28 Aug 2023 21:25:02 +0200},
	biburl = {https://dblp.org/rec/journals/jcs/TianLDSY21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we introduce a new construction of reusable fuzzy signature based remote user authentication that is secure against quantum computers. We investigate the reusability of fuzzy signature, and we prove that the fuzzy signature schemes provide biometrics reusability (aka. reusable fuzzy signature). We define formal security models for the proposed construction, and we prove that it achieves user authenticity and user privacy. The proposed construction ensures: 1) a user’s biometrics can be securely reused in remote user authentication; 2) a third party having access to the communication channel between a user and the authentication server cannot identify the user. }
}


@article{DBLP:journals/jcs/UrquizaAKKNST21,
	author = {Abra{\~{a}}o Aires Urquiza and
                  Musab A. Alturki and
                  Tajana Ban Kirigin and
                  Max I. Kanovich and
                  Vivek Nigam and
                  Andre Scedrov and
                  Carolyn L. Talcott},
	title = {Resource and timing aspects of security protocols},
	journal = {J. Comput. Secur.},
	volume = {29},
	number = {3},
	pages = {299--340},
	year = {2021},
	url = {https://doi.org/10.3233/JCS-200012},
	doi = {10.3233/JCS-200012},
	timestamp = {Mon, 28 Aug 2023 21:24:59 +0200},
	biburl = {https://dblp.org/rec/journals/jcs/UrquizaAKKNST21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Protocol security verification is one of the best success stories of formal methods. However, some aspects important to protocol security, such as time and resources, are not covered by many formal models. While timing issues involve e.g. , network delays and timeouts, resources such as memory, processing power, or network bandwidth are at the root of Denial of Service (DoS) attacks which have been a serious security concern. It is useful in practice and more challenging for formal protocol verification to determine whether a service is vulnerable not only to powerful intruders, but also to resource-bounded intruders that cannot generate or intercept arbitrarily large volumes of traffic. A\xa0refined Dolev–Yao intruder model is proposed, that can only consume at most some specified amount of resources in any given time window. Timed protocol theories that specify service resource usage during protocol execution are also proposed. It is shown that the proposed DoS problem is undecidable in general and is PSPACE-complete for the class of resource-bounded, balanced systems. Additionally, we describe a decidable fragment in the verification of the leakage problem for resource-sensitive timed protocol theories. }
}


@article{DBLP:journals/jcs/HessamSA21,
	author = {Ghandi Hessam and
                  Ghassan Saba and
                  M. Iyad Alkhayat},
	title = {A new approach for detecting violation of data plane integrity in
                  Software Defined Networks},
	journal = {J. Comput. Secur.},
	volume = {29},
	number = {3},
	pages = {341--358},
	year = {2021},
	url = {https://doi.org/10.3233/JCS-200094},
	doi = {10.3233/JCS-200094},
	timestamp = {Tue, 16 Aug 2022 23:04:59 +0200},
	biburl = {https://dblp.org/rec/journals/jcs/HessamSA21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The scale of Software Defined Networks (SDN) is expanding rapidly and the demands for security reinforcement are increasing. SDN creates new targets for potential security threats such as the SDN controller and networking devices in the data plane. Violation of data plane integrity might lead to abnormal behaviors of the overall network. In this paper, we propose a new security approach for OpenFlow-based SDN in order to detect violation of switches flow tables integrity and successfully locate the compromised switches online. We cover all aspects of integrity violation including flow rule adding, modifying and removing by an unauthorized entity. We achieve this by using the cookie field in the OpenFlow protocol to put in a suitable digest (hash) value for each flow entry. Moreover, we optimize our method performance by calculating a global digest value for the entire switch’s flow table that decides whether a switch is suspected of being compromised. Our method is also able to determine and handle false alarms that affect the coherence of a corresponding table digest. The implementation is a reactive java module integrated with the Floodlight controller. In addition, we introduce a performance evaluation for three different SDN topologies. }
}


@article{DBLP:journals/jcs/BichhawatRGH21,
	author = {Abhishek Bichhawat and
                  Vineet Rajani and
                  Deepak Garg and
                  Christian Hammer},
	title = {Permissive runtime information flow control in the presence of exceptions},
	journal = {J. Comput. Secur.},
	volume = {29},
	number = {4},
	pages = {361--401},
	year = {2021},
	url = {https://doi.org/10.3233/JCS-211385},
	doi = {10.3233/JCS-211385},
	timestamp = {Mon, 28 Aug 2023 21:24:58 +0200},
	biburl = {https://dblp.org/rec/journals/jcs/BichhawatRGH21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Information flow control (IFC) has been extensively studied as an approach to mitigate information leaks in applications. A\xa0vast majority of existing work in this area is based on static analysis. However, some applications, especially on the Web, are developed using dynamic languages like JavaScript where static analyses for IFC do not scale well. As a result, there has been a growing interest in recent years to develop dynamic or runtime information flow analysis techniques. In spite of the advances in the field, runtime information flow analysis has not been at the helm of information flow security, one of the reasons being that the analysis techniques and the security property related to them (non-interference) over-approximate information flows (particularly implicit flows), generating many false positives.  In this paper, we present a sound and precise approach for handling implicit leaks at runtime. In particular, we present an improvement and enhancement of the so-called permissive-upgrade strategy, which is widely used to tackle implicit leaks in dynamic information flow control. We improve the strategy’s permissiveness and generalize it. Building on top of it, we present an approach to handle implicit leaks when dealing with complex features like unstructured control flow and exceptions in higher-order languages. We explain how we address the challenge of handling unstructured control flow using immediate post-dominator analysis. We prove that our approach is sound and precise. }
}


@article{DBLP:journals/jcs/JiangLWLLHLY21,
	author = {Jianguo Jiang and
                  Boquan Li and
                  Baole Wei and
                  Gang Li and
                  Chao Liu and
                  Weiqing Huang and
                  Meimei Li and
                  Min Yu},
	title = {FakeFilter: {A} cross-distribution Deepfake detection system with
                  domain adaptation},
	journal = {J. Comput. Secur.},
	volume = {29},
	number = {4},
	pages = {403--421},
	year = {2021},
	url = {https://doi.org/10.3233/JCS-200124},
	doi = {10.3233/JCS-200124},
	timestamp = {Sat, 30 Sep 2023 10:18:38 +0200},
	biburl = {https://dblp.org/rec/journals/jcs/JiangLWLLHLY21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Abuse of face swap techniques poses serious threats to the integrity and authenticity of digital visual media. More alarmingly, fake images or videos created by deep learning technologies, also known as Deepfakes, are more realistic, high-quality, and reveal few tampering traces, which attracts great attention in digital multimedia forensics research. To address those threats imposed by Deepfakes, previous work attempted to classify real and fake faces by discriminative visual features, which is subjected to various objective conditions such as the angle or posture of a face. Differently, some research devises deep neural networks to discriminate Deepfakes at the microscopic-level semantics of images, which achieves promising results. Nevertheless, such methods show limited success as encountering unseen Deepfakes created with different methods from the training sets. Therefore, we propose a novel Deepfake detection system, named FakeFilter , in which we formulate the challenge of unseen Deepfake detection into a problem of cross-distribution data classification, and address the issue with a strategy of domain adaptation. By mapping different distributions of Deepfakes into similar features in a certain space, the detection system achieves comparable performance on both seen and unseen Deepfakes. Further evaluation and comparison results indicate that the challenge has been successfully addressed by FakeFilter . }
}


@article{DBLP:journals/jcs/AlamW21,
	author = {Md. Morshed Alam and
                  Weichao Wang},
	title = {A comprehensive survey on data provenance: State-of-the-art approaches
                  and their deployments for IoT security enforcement},
	journal = {J. Comput. Secur.},
	volume = {29},
	number = {4},
	pages = {423--446},
	year = {2021},
	url = {https://doi.org/10.3233/JCS-200108},
	doi = {10.3233/JCS-200108},
	timestamp = {Mon, 28 Aug 2023 21:25:00 +0200},
	biburl = {https://dblp.org/rec/journals/jcs/AlamW21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Data provenance collects comprehensive information about the events and operations in a computer system at both application and kernel levels. It provides a detailed and accurate history of transactions that help delineate the data flow scenario across the whole system. Data provenance helps achieve system resilience by uncovering several malicious attack traces after a system compromise that are leveraged by the analyzer to understand the attack behavior and discover the level of damage. Existing literature demonstrates a number of research efforts on information capture, management, and analysis of data provenance. In recent years, provenance in IoT devices attracts several research efforts because of the proliferation of commodity IoT devices. In this survey paper, we present a comparative study of the state-of-the-art approaches to provenance by classifying them based on frameworks, deployed techniques, and subjects of interest. We also discuss the emergence and scope of data provenance in IoT network. Finally, we present the urgency in several directions that data provenance needs to pursue, including data management and analysis. }
}


@article{DBLP:journals/jcs/LiS0RKP21,
	author = {Guangjun Li and
                  Preetpal Sharma and
                  Lei Pan and
                  Sutharshan Rajasegarar and
                  Chandan K. Karmakar and
                  Nicholas Charles Patterson},
	title = {Deep learning algorithms for cyber security applications: {A} survey},
	journal = {J. Comput. Secur.},
	volume = {29},
	number = {5},
	pages = {447--471},
	year = {2021},
	url = {https://doi.org/10.3233/JCS-200095},
	doi = {10.3233/JCS-200095},
	timestamp = {Mon, 28 Aug 2023 21:25:00 +0200},
	biburl = {https://dblp.org/rec/journals/jcs/LiS0RKP21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the development of information technology, thousands of devices are connected to the Internet, various types of data are accessed and transmitted through the network, which pose huge security threats while bringing convenience to people. In order to deal with security issues, many effective solutions have been given based on traditional machine learning. However, due to the characteristics of big data in cyber security, there exists a bottleneck for methods of traditional machine learning in improving security. Owning to the advantages of processing big data and high-dimensional data, new solutions for cyber security are provided based on deep learning. In this paper, the applications of deep learning are classified, analyzed and summarized in the field of cyber security, and the applications are compared between deep learning and traditional machine learning in the security field. The challenges and problems faced by deep learning in cyber security are analyzed and presented. The findings illustrate that deep learning has a better effect on some aspects of cyber security and should be considered as the first option. }
}


@article{DBLP:journals/jcs/Akinyelu21,
	author = {Andronicus Ayobami Akinyelu},
	title = {Advances in spam detection for email spam, web spam, social network
                  spam, and review spam: ML-based and nature-inspired-based techniques},
	journal = {J. Comput. Secur.},
	volume = {29},
	number = {5},
	pages = {473--529},
	year = {2021},
	url = {https://doi.org/10.3233/JCS-210022},
	doi = {10.3233/JCS-210022},
	timestamp = {Mon, 28 Aug 2023 21:24:58 +0200},
	biburl = {https://dblp.org/rec/journals/jcs/Akinyelu21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Despite the great advances in spam detection, spam remains a major problem that has affected the global economy enormously. Spam attacks are popularly perpetrated through different digital platforms with a large electronic audience, such as emails, microblogging websites (e.g. Twitter), social networks (e.g. Facebook), and review sites (e.g. Amazon). Different spam detection solutions have been proposed in the literature, however, Machine Learning (ML) based solutions are one of the most effective. Nevertheless, most ML algorithms have computational complexity problem, thus some studies introduced Nature Inspired (NI) algorithms to further improve the speed and generalization performance of ML algorithms. This study presents a survey of recent ML-based and NI-based spam detection techniques to empower the research community with information that is suitable for designing effective spam filtering systems for emails, social networks, microblogging, and review websites. The recent success and prevalence of deep learning show that it can be used to solve spam detection problems. Moreover, the availability of large-scale spam datasets makes deep learning and big data solutions (such as Mahout) very suitable for spam detection. Few studies explored deep learning algorithms and big data solutions for spam detection. Besides, most of the datasets used in the literature are either small or synthetically created. Therefore, future studies can consider exploring big data solutions, big datasets, and deep learning algorithms for building efficient spam detection techniques. }
}


@article{DBLP:journals/jcs/SharmaK21,
	author = {Himani Sharma and
                  Navdeep Kanwal},
	title = {Video interframe forgery detection: Classification, technique {\&}
                  new dataset},
	journal = {J. Comput. Secur.},
	volume = {29},
	number = {5},
	pages = {531--550},
	year = {2021},
	url = {https://doi.org/10.3233/JCS-200105},
	doi = {10.3233/JCS-200105},
	timestamp = {Mon, 28 Aug 2023 21:25:02 +0200},
	biburl = {https://dblp.org/rec/journals/jcs/SharmaK21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Multimedia communication as well as other related innovations are gaining tremendous growth in the modern technological era. Even though digital content has traditionally proved to be a piece of legitimate evidence. But the latest\xa0technologies have lessened this trust, as a variety of video editing tools have been developed\xa0to modify the original video. Therefore, in order to resolve this problem, a new technique has been proposed for the detection of duplicate\xa0video sequences. The present paper utilizes gray values to extract Hu\xa0moment features\xa0in the current frame. These features are further used for classification of video as authentic or forged. Afterwards there was also need to validate the proposed technique using training and test dataset. But the scarcity of training and test datasets, however, is indeed one of the key problems to validate the effectiveness of video tampering detection techniques. In this perspective, the Video Forensics Library for Frame Duplication (VLFD) dataset has been introduced for frame duplication detection purposes. The proposed dataset is made of 210 native videos, in Ultra-HD and Full-HD resolution, captured with different cameras. Every video is 6 to 15 seconds in length and runs at 30 frames per second. All the recordings have been acquired in three different scenarios (indoor, outdoor, nature) and in landscape mode(s). VLFD includes both authentic and manipulated video files. This dataset has been created as an initial repository for manipulated video and enhanced with new features and new techniques in future. }
}


@article{DBLP:journals/jcs/Smyth21,
	author = {Ben Smyth},
	title = {Ballot secrecy: Security definition, sufficient conditions, and analysis
                  of Helios},
	journal = {J. Comput. Secur.},
	volume = {29},
	number = {6},
	pages = {551--611},
	year = {2021},
	url = {https://doi.org/10.3233/JCS-191415},
	doi = {10.3233/JCS-191415},
	timestamp = {Mon, 28 Aug 2023 21:25:03 +0200},
	biburl = {https://dblp.org/rec/journals/jcs/Smyth21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We propose a definition of ballot secrecy as an indistinguishability game in the computational model of cryptography. Our definition improves upon earlier definitions to ensure ballot secrecy is preserved in the presence of an adversary that controls ballot collection. We also propose a definition of ballot independence as an adaptation of an indistinguishability game for asymmetric encryption. We prove relations between our definitions. In particular, we prove ballot independence is sufficient for ballot secrecy in voting systems with zero-knowledge tallying proofs. Moreover, we prove that building systems from non-malleable asymmetric encryption schemes suffices for ballot secrecy, thereby eliminating the expense of ballot-secrecy proofs for a class of encryption-based voting systems. We demonstrate applicability of our results by analysing the Helios voting system and its mixnet variant. Our analysis reveals that Helios does not satisfy ballot secrecy in the presence of an adversary that controls ballot collection. The vulnerability cannot be detected by earlier definitions of ballot secrecy, because they do not consider such adversaries. We adopt non-malleable ballots as a fix and prove that the fixed system satisfies ballot secrecy. }
}


@article{DBLP:journals/jcs/SheikhalishahiS21,
	author = {Mina Sheikhalishahi and
                  Ischa Stork and
                  Nicola Zannone},
	title = {Privacy-preserving policy evaluation in multi-party access control},
	journal = {J. Comput. Secur.},
	volume = {29},
	number = {6},
	pages = {613--650},
	year = {2021},
	url = {https://doi.org/10.3233/JCS-200007},
	doi = {10.3233/JCS-200007},
	timestamp = {Mon, 28 Aug 2023 21:25:00 +0200},
	biburl = {https://dblp.org/rec/journals/jcs/SheikhalishahiS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recent years have seen an increasing popularity of online collaborative systems like social networks and web-based collaboration platforms. Collaborative systems typically offer their users a digital environment in which they can work together and share resources and information. These resources and information might be sensitive and, thus, they should be protected from unauthorized accesses. Multi-party access control is emerging as a new paradigm for the protection of co-owned and co-managed resources, where the policies of all users involved in the management of a resource should be accounted for collaborative decision making. Existing approaches, however, only focus on the jointly protection of resources and do not address the protection of the individual user policies themselves, whose disclosure might leak sensitive information. In this work, we propose a privacy-preserving mechanism for the evaluation of multi-party access control policies, which preserves the confidentiality of user policies while remaining capable of making collaborative decisions. To this end, we design secure computation protocols for the evaluation of policies in protected form against an access query and realize such protocols using two privacy-preserving techniques, namely Homomorphic Encryption and Secure Functional Evaluation. We show the practical feasibility of our mechanism in terms of computation and communication costs through an experimental evaluation. }
}


@article{DBLP:journals/jcs/DounaviMNP21,
	author = {Helen{-}Maria Dounavi and
                  Anna Mpanti and
                  Stavros D. Nikolopoulos and
                  Iosif Polenakis},
	title = {A graph-based framework for malicious software detection and classification
                  utilizing temporal-graphs},
	journal = {J. Comput. Secur.},
	volume = {29},
	number = {6},
	pages = {651--688},
	year = {2021},
	url = {https://doi.org/10.3233/JCS-210057},
	doi = {10.3233/JCS-210057},
	timestamp = {Wed, 07 Dec 2022 23:04:19 +0100},
	biburl = {https://dblp.org/rec/journals/jcs/DounaviMNP21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper we present a graph-based framework that, utilizing relations between groups of System-calls, detects whether an unknown software sample is malicious or benign, and classifies a malicious software to one of a set of known malware families. In our approach we propose a novel graph representation of dependency graphs by capturing their structural evolution over time constructing sequential graph instances, the so-called Temporal Graphs. The partitions of the temporal evolution of a graph defined by specific time-slots, results to different types of graphs representations based upon the information we capture across the capturing of its evolution. The proposed graph-based framework utilizes the proposed types of temporal graphs computing similarity metrics over various graph characteristics in order to conduct the malware detection and classification procedures. Finally, we evaluate the detection rates and the classification ability of our proposed graph-based framework conducting a series of experiments over a set of known malware samples pre-classified into malware families. }
}
