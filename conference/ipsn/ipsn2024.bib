@inproceedings{DBLP:conf/ipsn/YuTMGR24,
	author = {Xiaofan Yu and
                  Anthony Thomas and
                  Ivannia Gomez Moreno and
                  Louis Gutierrez and
                  Tajana Simunic Rosing},
	title = {Intelligence Beyond the Edge using Hyperdimensional Computing},
	booktitle = {23rd {ACM/IEEE} International Conference on Information Processing
                  in Sensor Networks, {IPSN} 2024, Hong Kong, May 13-16, 2024},
	pages = {1--13},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IPSN61024.2024.00005},
	doi = {10.1109/IPSN61024.2024.00005},
	timestamp = {Mon, 10 Feb 2025 14:41:37 +0100},
	biburl = {https://dblp.org/rec/conf/ipsn/YuTMGR24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {On-device learning has emerged as a prevailing trend that avoids the slow response time and costly communication of cloud-based learning. The ability to learn continuously and indefinitely in a changing environment, and with resource constraints, is critical for real sensor deployments. However, existing designs are inadequate for practical scenarios with (i) streaming data input, (ii) lack of supervision and (iii) limited on-board resources. In this paper, we design and deploy the first on-device lifelong learning system called LifeHD for general IoT applications with limited supervision. LifeHD is designed based on a novel neurally-inspired and lightweight learning paradigm called Hyperdimensional Computing (HDC). We utilize a two-tier associative memory organization to intelligently store and manage high-dimensional, low-precision vectors, which represent the historical patterns as cluster centroids. We additionally propose two variants of LifeHD to cope with scarce labeled inputs and power constraints. We implement LifeHD on off-the-shelf edge platforms and perform extensive evaluations across three scenarios. Our measurements show that LifeHD improves the unsupervised clustering accuracy by up to 74.8% compared to the state-of-the-art NN-based unsupervised lifelong learning baselines with as much as 34.3x better energy efficiency. Our code is available at https://github.com/Orienfish/LifeHD.}
}


@inproceedings{DBLP:conf/ipsn/Dai024,
	author = {Yimin Dai and
                  Rui Tan},
	title = {FedCFC: On-Device Personalized Federated Learning with Closed-Form
                  Continuous-Time Neural Networks},
	booktitle = {23rd {ACM/IEEE} International Conference on Information Processing
                  in Sensor Networks, {IPSN} 2024, Hong Kong, May 13-16, 2024},
	pages = {14--26},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IPSN61024.2024.00006},
	doi = {10.1109/IPSN61024.2024.00006},
	timestamp = {Tue, 16 Jul 2024 16:39:53 +0200},
	biburl = {https://dblp.org/rec/conf/ipsn/Dai024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Closed-form continuous-time (CFC) neural networks have superior expressivity in modeling time series data compared with recurrent neural networks. CFC’s lower training and inference overheads also make it appealing for microcontroller-based platforms. This paper proposes FedCFC, which advances CFC from the centralized learning setting to the federated learning paradigm. FedCFC features a novel and communication-efficient aggregation strategy to address the problem of class distribution skews across clients’ training data. The strategy is designed based on a new empirical property of CFC identified in this paper, i.e., involatility of a sub-network of CFC with respect to training data’s class distribution. Extensive evaluation based on multiple time series datasets shows that FedCFC achieves higher or similar accuracy with 7.6× to 11× reduction in communication overhead, compared with recent federated learning approaches designed to address the class distribution skew problem. Implementations of FedCFC on four microcontroller platforms show its portability to low-end computing devices with 256kB memory and even less.}
}


@inproceedings{DBLP:conf/ipsn/JiangSX24,
	author = {Siyang Jiang and
                  Xian Shuai and
                  Guoliang Xing},
	title = {ArtFL: Exploiting Data Resolution in Federated Learning for Dynamic
                  Runtime Inference via Multi-Scale Training},
	booktitle = {23rd {ACM/IEEE} International Conference on Information Processing
                  in Sensor Networks, {IPSN} 2024, Hong Kong, May 13-16, 2024},
	pages = {27--38},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IPSN61024.2024.00007},
	doi = {10.1109/IPSN61024.2024.00007},
	timestamp = {Tue, 16 Jul 2024 16:39:53 +0200},
	biburl = {https://dblp.org/rec/conf/ipsn/JiangSX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated Learning (FL) has emerged as a prominent paradigm for distributed machine learning, crucial for mission-critical applications such as autonomous driving and smart health. However, existing FL systems have not adequately addressed the dynamic real-time requirements of these applications due to stringent inference deadlines and resource limitations on edge devices. In this paper, we propose ArtFL, a novel federated learning system designed to support dynamic runtime inference through multi-scale training. The key idea of ArtFL is to utilize the data resolution, i.e., frame resolution of videos, as a knob to accommodate dynamic inference latency requirements. Specifically, we initially propose data-utility-based multi-scale training, allowing the trained model to process data of varying resolutions during inference. Subsequently, we introduce an innovative strategy for frame resolution selection in inference, based on the similarity of adjacent frames. Finally, leveraging latency-based dynamic data dropping, we propose a systematic scheme to reduce the overall training time by shortening the waiting time in FL. For evaluation, we build two real-world FL testbeds for smart vehicles and healthcare applications, utilizing a heterogeneous edge platform. Extensive experiments across our testbeds and three public datasets show that ArtFL outperforms state-of-the-art baselines in overall accuracy and system performance up to 36.36% and 47.81%, respectively. A demo video of ArtFL on our smart vehicle testbed is available at https://youtu.be/eeK6yRVEG3U, and our code is available at https://github.com/siyang-jiang/ArtFL.git.CCS CONCEPTS• Computing methodologies → Machine learning.}
}


@inproceedings{DBLP:conf/ipsn/RostamiLS24,
	author = {Mohammad Rostami and
                  Alan Liu and
                  Karthikeyan Sundaresan},
	title = {Scalable Acoustic IoT through Composable Distributed Beamforming Tags},
	booktitle = {23rd {ACM/IEEE} International Conference on Information Processing
                  in Sensor Networks, {IPSN} 2024, Hong Kong, May 13-16, 2024},
	pages = {39--50},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IPSN61024.2024.00008},
	doi = {10.1109/IPSN61024.2024.00008},
	timestamp = {Tue, 16 Jul 2024 16:39:53 +0200},
	biburl = {https://dblp.org/rec/conf/ipsn/RostamiLS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the proliferation of smart acoustic devices in everyday environments, low-power acoustic tags offer a promising choice for IoT applications. However, their highly limited operational range, throughput, and energy efficiency significantly restrict their viability for practical applications. In this work, we propose a first-of-its-kind distributed acoustic system called Disco. It consists of several low-power acoustic tags that can be flexibly composed on-demand to create an aperture array capable of distributed beamforming. The innovation of Disco lies in creating a ‘virtual’ distributed 2-speaker system that serves to wirelessly synchronize and enable distributed temporal beamforming at the tags independently. The low-power tags of Disco are prototyped with simple acoustic and analog-digital elements to create arrays comprising up to 8 tags. The beamforming performance of Disco scales with the number of tags in the array, delivering a multiple-fold increase in range, throughput, and energy efficiency. This advancement brings acoustic IoT applications closer to practical implementation.}
}


@inproceedings{DBLP:conf/ipsn/WangWGJ24,
	author = {Haoyu Wang and
                  Jiazhao Wang and
                  Demin Gao and
                  Wenchao Jiang},
	title = {{NNCTC:} Physical Layer Cross-Technology Communication via Neural
                  Networks},
	booktitle = {23rd {ACM/IEEE} International Conference on Information Processing
                  in Sensor Networks, {IPSN} 2024, Hong Kong, May 13-16, 2024},
	pages = {51--62},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IPSN61024.2024.00009},
	doi = {10.1109/IPSN61024.2024.00009},
	timestamp = {Thu, 22 May 2025 17:08:34 +0200},
	biburl = {https://dblp.org/rec/conf/ipsn/WangWGJ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cross-technology communication (CTC) enables seamless interactions between diverse wireless technologies. Most existing work is based on reversing the transmission path to identify the appropriate payload to generate the waveform that the target devices can recognize. However, this method suffers from many limitations, including dependency on specific technologies and the necessity for intricate algorithms to mitigate distortion. In this work, we present NNCTC, a Neural-Network-based Cross-Technology Communication framework inspired by the adaptability of trainable neural models in wireless communications. By converting signal processing components within the CTC pipeline into neural models, the NNCTC is designed for end-to-end training without requiring labeled data. This enables the NNCTC system to autonomously derive the optimal CTC payload, which significantly eases the development complexity and showcases the scalability potential for various CTC links. Particularly, we construct a CTC system from Wi-Fi to ZigBee. The NNCTC system outperforms the well-recognized WEBee and WIDE design in error performance, achieving an average packet reception rate (PRR) of 92.3% and an average symbol error rate (SER) as low as 1.3%.}
}


@inproceedings{DBLP:conf/ipsn/TapiaXZ24,
	author = {Miguel A. Ch{\'{a}}vez Tapia and
                  Talia Xu and
                  Marco Z{\'{u}}{\~{n}}iga Zamalloa},
	title = {Sol-Fi: Enabling Joint Illumination and Communication in Enclosed
                  Areas with Sunlight},
	booktitle = {23rd {ACM/IEEE} International Conference on Information Processing
                  in Sensor Networks, {IPSN} 2024, Hong Kong, May 13-16, 2024},
	pages = {63--74},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IPSN61024.2024.00010},
	doi = {10.1109/IPSN61024.2024.00010},
	timestamp = {Mon, 03 Mar 2025 21:14:13 +0100},
	biburl = {https://dblp.org/rec/conf/ipsn/TapiaXZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Consider an enclosed area, such as a room without windows. During the day, artificial light can provide illumination and communication thanks to advances in Visible Light Communication (VLC). Artificial lighting, however, has some drawbacks compared to using daylight in enclosed spaces. First, using sunlight consumes less power. Second, the use of natural light improves the health and comfort of the occupants. We propose a system, dubbed Sol-Fi, to provide joint illumination and communication in enclosed spaces using sunlight. Sol-Fi relies on two main components: commercial sunlight collectors and a novel transmitter to modulate ambient light. The sunlight collectors utilize optical fibers to guide natural light from open to enclosed spaces, and our transmitter modulates the incoming light providing two novel features. First, to analyze the pros and cons of the optical devices used in the literature for ambient light communication, Sol-Fi examines the properties of Liquid Crystals (LCs) and Digital Micro Mirror Devices (DMDs). Second, to investigate the trade-off between single- and multi-band communication, Sol-Fi proposes an optical design that can modulate the entire spectrum or divide it into different (individually modulated) bands. Our evaluation shows that, depending on the number of bands (single or dual) and the type of modulator (LC or DMD), Sol-Fi provides a data rate between 0.8 to 80 kbps, a range between 0.5 to 5 m, and a field-of-view between 30° to 60°.}
}


@inproceedings{DBLP:conf/ipsn/HuWJJHKH24,
	author = {Jiawei Hu and
                  Yanxiang Wang and
                  Hong Jia and
                  Cheng Jiang and
                  Mahbub Hassan and
                  Brano Kusy and
                  Wen Hu},
	title = {LiDARSpectra: Synthetic Indoor Spectral Mapping with Low-cost LiDARs},
	booktitle = {23rd {ACM/IEEE} International Conference on Information Processing
                  in Sensor Networks, {IPSN} 2024, Hong Kong, May 13-16, 2024},
	pages = {75--87},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IPSN61024.2024.00011},
	doi = {10.1109/IPSN61024.2024.00011},
	timestamp = {Sun, 19 Jan 2025 14:39:38 +0100},
	biburl = {https://dblp.org/rec/conf/ipsn/HuWJJHKH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We introduce LiDARSpectra, a novel approach utilizing mobile-integrated commodity Light Detection and Ranging (LiDAR) signals for synthetic indoor light spectral mapping. Our method incorporates an innovative material estimation algorithm into the LiDAR signal processing pipeline, accurately simulating reflected wavelengths from indoor surfaces. Utilizing low-resolution LiDAR scans enriched with material information, it eliminates the need for deploying dedicated spectral sensors, greatly simplifying the spectral mapping process. We validate our synthetic spectral maps against real sensor data and demonstrate their utility in applications such as indoor localization and solar energy provisioning. This presents an efficient solution for indoor spectral mapping with wide-ranging potential across fields like lighting design, indoor planting, environmental monitoring, and location-based services.}
}


@inproceedings{DBLP:conf/ipsn/DuanCQMEG24,
	author = {Lin Duan and
                  Ying Chen and
                  Zhehan Qu and
                  Megan McGrath and
                  Erin Ehmke and
                  Maria Gorlatova},
	title = {BiGuide: {A} Bi-level Data Acquisition Guidance for Object Detection
                  on Mobile Devices},
	booktitle = {23rd {ACM/IEEE} International Conference on Information Processing
                  in Sensor Networks, {IPSN} 2024, Hong Kong, May 13-16, 2024},
	pages = {88--100},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IPSN61024.2024.00012},
	doi = {10.1109/IPSN61024.2024.00012},
	timestamp = {Tue, 16 Jul 2024 16:39:53 +0200},
	biburl = {https://dblp.org/rec/conf/ipsn/DuanCQMEG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Object detection (OD) is crucial for numerous emerging visual sensing applications. As OD models trained on unrepresentative data usually yield poor performance, collecting high-quality data in the local environment is recognized to be essential for improving model accuracy. Yet, the question of how to collect this data is currently largely overlooked; unsupported data collection tends to produce datasets with a significant proportion of redundant or uninformative data, hindering effective model training. To address this challenge, we design a real-time data importance estimation method and integrate it into BiGuide, a bi-level image data acquisition system we create for OD tasks. BiGuide assesses the importance of the captured images in real-time based on informativeness and diversity estimations and dynamically guides users in collecting useful data via image-level and object instance-level guidance. We prototype BiGuide in an edge-based architecture using commodity smartphones as mobile clients, and evaluate its performance via an IRB-approved study with 20 users. Our evaluation demonstrates that OD models trained on the data collected by BiGuide outperform models trained on the data collected by two baseline systems, achieving detection accuracy improvements of up to 33.07% and 14.57%, respectively. Over 85% of the users found BiGuide fast, helpful, and easy to understand and follow.}
}


@inproceedings{DBLP:conf/ipsn/JiangWLC024,
	author = {Jinyan Jiang and
                  Jiliang Wang and
                  Yihao Liu and
                  Yijie Chen and
                  Yunhao Liu},
	title = {WiCloak: Protect Location Privacy of WiFi Devices},
	booktitle = {23rd {ACM/IEEE} International Conference on Information Processing
                  in Sensor Networks, {IPSN} 2024, Hong Kong, May 13-16, 2024},
	pages = {101--112},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IPSN61024.2024.00013},
	doi = {10.1109/IPSN61024.2024.00013},
	timestamp = {Sun, 06 Oct 2024 21:08:38 +0200},
	biburl = {https://dblp.org/rec/conf/ipsn/JiangWLC024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The rapid development of WiFi localization poses a serious privacy threat, as eavesdroppers can locate WiFi devices without their consent. In this paper, we present WiCloak, the first system that protects WiFi device location privacy while supporting normal WiFi communication simultaneously. The high-level idea of WiCloak is to inject a fake channel into WiFi CSI at the transmitter, which renders the CIR and time information obtained by eavesdroppers meaningless. We mathematically prove that the injected fake channel is effective in any wireless environment and can strictly protect the location privacy of WiFi devices. To simultaneously support communication for commercial WiFi receivers, we propose a method to cancel out the fake channel impacts in decoding and prove that the method should not impact communication performance. WiCloak can work on commercial WiFi devices without any hardware modification. We evaluate the communication performance of WiCloak on commercial WiFi receivers (e.g., MacBook and Mac Studio) and demonstrate that it achieves the same packet reception rate as normal WiFi. We show that WiCloak increases the localization error by 22× to normal WiFi.}
}


@inproceedings{DBLP:conf/ipsn/Yan0024,
	author = {Haotian Yan and
                  Haibo Hu and
                  Qingqing Ye},
	title = {Time-Specific Integrity Service in {MQTT} Protocol},
	booktitle = {23rd {ACM/IEEE} International Conference on Information Processing
                  in Sensor Networks, {IPSN} 2024, Hong Kong, May 13-16, 2024},
	pages = {113--125},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IPSN61024.2024.00014},
	doi = {10.1109/IPSN61024.2024.00014},
	timestamp = {Tue, 16 Jul 2024 16:39:53 +0200},
	biburl = {https://dblp.org/rec/conf/ipsn/Yan0024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Message Queuing Telemetry Transport (MQTT) is a classic transmission protocol in IoT scenarios, where a subscriber subscribes to the messages, and a publisher publishes the message to the broker, who then sends the message to the subscriber. In MQTT, it is essential to ensure its security in the temporal domain. On one hand, some messages are time-sensitive, so their integrity should only be valid in a determined time interval. On the other hand, when the subscriber is out of the service, his key should not be able to verify the message, which is known as subscriber validity. This paper discusses the time-specific integrity service in the MQTT protocol. To solve the problem, we propose Time-specific Signcryption (TSSC) and the Dynamic Time-specific Signature (DTSS). Furthermore, a Progressive Dynamic Time-specific Signature scheme (Pro-DTSS) is proposed to save communication costs. The theoretical and experimental results show that our proposed schemes are more efficient than the existing solutions.}
}


@inproceedings{DBLP:conf/ipsn/WatsonATLPD24,
	author = {Jean{-}Luc Watson and
                  Saharsh Agrawal and
                  Ryan Tsang and
                  Sherry Luo and
                  Raluca Ada Popa and
                  Prabal Dutta},
	title = {Retcon: Live Updates for Embedded Event-Driven Applications},
	booktitle = {23rd {ACM/IEEE} International Conference on Information Processing
                  in Sensor Networks, {IPSN} 2024, Hong Kong, May 13-16, 2024},
	pages = {126--137},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IPSN61024.2024.00015},
	doi = {10.1109/IPSN61024.2024.00015},
	timestamp = {Tue, 16 Jul 2024 16:39:53 +0200},
	biburl = {https://dblp.org/rec/conf/ipsn/WatsonATLPD24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Embedded systems are deeply integrated into critical applications but, despite their importance, lack an effective means to apply over-the-air software patches without significant downtime. Standard mechanisms for firmware updates require device reboots that wipe important in-memory state. Prior efforts have proposed "live" updates to address this problem, applying patches to an embedded application without a reset, but they tackle a limited set of applications or propose a clean-slate design. In this paper, we present Retcon, a live update toolchain for embedded systems that supports a familiar event-driven programming model and does not require application code changes. Retcon leverages static analysis at compile time to determine when it will be safe to update a device. To find safe update points in the presence of complex asynchronous behavior, we define a novel system state, asynchronous quiescence, in which an update can be applied. We evaluate Retcon on a set of embedded event-driven applications – a dual-chamber pacemaker model, a programmable logic controller runtime, an artificial pancreas system, and a sensing node – and demonstrate Retcon’s ability to make low-overhead updates in less than one millisecond.}
}


@inproceedings{DBLP:conf/ipsn/BrunnerWBPR24,
	author = {Hannah Brunner and
                  Jasper de Winkel and
                  Carlo Alberto Boano and
                  Przemyslaw Pawelczak and
                  Kay R{\"{o}}mer},
	title = {Simba: {A} Unified Framework to Explore and Facilitate the Design
                  of Battery-Free Systems},
	booktitle = {23rd {ACM/IEEE} International Conference on Information Processing
                  in Sensor Networks, {IPSN} 2024, Hong Kong, May 13-16, 2024},
	pages = {138--150},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IPSN61024.2024.00016},
	doi = {10.1109/IPSN61024.2024.00016},
	timestamp = {Sun, 06 Oct 2024 21:08:38 +0200},
	biburl = {https://dblp.org/rec/conf/ipsn/BrunnerWBPR24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Battery-free sensing devices have gained growing popularity as they can operate relying solely on harvested energy and environmentally friendly capacitors. However, despite the increasing number of battery-free solutions, their design remains a difficult task. In fact, the limited energy storage capacity and the resulting coupling between energy supply and demand introduce new design trade-offs that cannot be explored using conventional tools that consider a constant power supply. To enable fast design space exploration and facilitate the development of battery-free systems, we introduce Simba, an open-source simulation framework that allows to investigate in detail the complex interplay between various device components. We demonstrate the benefits of Simba in two case studies, evaluated experimentally, targeting real-world, state-of-the-art battery-free devices. First, we illustrate how Simba can explore the dependencies between different component configurations and assess their impact on the overall system performance. Among others, we show that changing the storage capacity or slightly modifying the load behavior can improve data throughput by a factor of up to 5.1x and 9.7x, respectively. Second, we present how Simba allows to automatically select key parameters that optimize the operations of a battery-free system (e.g., its checkpointing mechanism), and showcase how Simba enables performance evaluations based on real-world energy harvesting traces.CCS CONCEPTS• Computer systems organization → Embedded systems.}
}


@inproceedings{DBLP:conf/ipsn/LiRZN24,
	author = {Yin Li and
                  Rohan Reddy and
                  Cheng Zhang and
                  Rajalakshmi Nandakumar},
	title = {Beyond-Voice: Towards Continuous 3D Hand Pose Tracking on Commercial
                  Home Assistant Devices},
	booktitle = {23rd {ACM/IEEE} International Conference on Information Processing
                  in Sensor Networks, {IPSN} 2024, Hong Kong, May 13-16, 2024},
	pages = {151--162},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IPSN61024.2024.00017},
	doi = {10.1109/IPSN61024.2024.00017},
	timestamp = {Tue, 15 Apr 2025 22:04:36 +0200},
	biburl = {https://dblp.org/rec/conf/ipsn/LiRZN24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The surging popularity of home assistants and their voice user interface (VUI) have made them an ideal central control hub for smart home devices. However, current form factors heavily rely on VUI, which poses accessibility and usability issues; some latest ones are equipped with additional cameras and displays, which are costly and raise privacy concerns. These concerns jointly motivate Beyond-Voice, a novel high-fidelity acoustic sensing system that allows commodity home assistant devices to track and reconstruct hand poses continuously. It transforms the home assistant into an active sonar system using its existing onboard microphones and speakers. We feed a high-resolution range profile to the deep learning model that can analyze the motions of multiple body parts and predict the 3D positions of 21 finger joints, bringing the granularity for acoustic hand tracking to the next level. It operates across different environments and users without the need for personalized training data. A user study with 11 participants in 3 different environments shows that Beyond-Voice can track joints with an average mean absolute error of 16.47mm without any training data provided by the testing subject.}
}


@inproceedings{DBLP:conf/ipsn/SenDPC24,
	author = {Argha Sen and
                  Anirban Das and
                  Swadhin Pradhan and
                  Sandip Chakraborty},
	title = {Continuous Multi-user Activity Tracking via Room-Scale mmWave Sensing},
	booktitle = {23rd {ACM/IEEE} International Conference on Information Processing
                  in Sensor Networks, {IPSN} 2024, Hong Kong, May 13-16, 2024},
	pages = {163--175},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IPSN61024.2024.00018},
	doi = {10.1109/IPSN61024.2024.00018},
	timestamp = {Fri, 18 Oct 2024 15:41:27 +0200},
	biburl = {https://dblp.org/rec/conf/ipsn/SenDPC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Continuous detection of human activities and presence is essential for developing a pervasive interactive smart space. Existing literature lacks robust wireless sensing mechanisms capable of continuously monitoring multiple users’ activities without prior knowledge of the environment. Developing such a mechanism requires simultaneous localization and tracking of multiple subjects. In addition, it requires identifying their activities at various scales, some being macro-scale activities like walking, squats, etc., while others are micro-scale activities like typing or sitting, etc. In this paper, we develop a holistic system called MARS using a single Commercial off-the-shelf (COTS) Millimeter Wave (mmWave) radar, which employs an intelligent model to sense both macro and micro activities. In addition, it uses a dynamic spatial time-sharing approach to sense different subjects simultaneously. A thorough evaluation of MARS shows that it can infer activities continuously with an accuracy of > 93% and an average response time of ≈ 2 sec, with 5 subjects and 19 different activities.}
}


@inproceedings{DBLP:conf/ipsn/AhnKC24,
	author = {Junick Ahn and
                  Daeyong Kim and
                  Hojung Cha},
	title = {Split Learning-based Sound Event Detection in Energy-Constrained Sensor
                  Devices},
	booktitle = {23rd {ACM/IEEE} International Conference on Information Processing
                  in Sensor Networks, {IPSN} 2024, Hong Kong, May 13-16, 2024},
	pages = {176--187},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IPSN61024.2024.00019},
	doi = {10.1109/IPSN61024.2024.00019},
	timestamp = {Tue, 16 Jul 2024 16:39:53 +0200},
	biburl = {https://dblp.org/rec/conf/ipsn/AhnKC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Sound event detection (SED) using lightweight sensor device has recently gained attention as a practical means to capture context and activities especially in domestic environments. However, SED applications running on sensor device are severely constrained by device’s energy capacity. One solution is to offload a portion of inference to server for reducing runtime complexity, i.e., energy consumption, of sensor device. Offloading should consider the trade-off between computation and data transmission costs adequately; more computation on sensor device reduces data to be transmitted and vice versa. To address this challenge, we propose SEDAC (Sound Event Detection with Attention-based audio Compression), a novel technique for split learning in SED that compresses data from sensor device to offload less data. SEDAC compresses the input of SED models, or Mel spectrograms, with minimal computation in sensor device. Rather than directly compressing the input, SEDAC achieves data compression by selectively capturing the key parts of sound events using an attention mechanism. The scheme also modifies an existing loss function and employs knowledge distillation to mitigate potential loss of SED accuracy due to data compression. Our evaluation shows that SEDAC outperforms the state-of-the-art data compressive split learning schemes, up to about 30%. Furthermore, our real-world deployment demonstrates that sensor devices with SEDAC successfully operate with minimal energy and memory overhead.}
}


@inproceedings{DBLP:conf/ipsn/DengWYRZWC0Z24,
	author = {Yongheng Deng and
                  Guanbo Wang and
                  Sheng Yue and
                  Wei Rao and
                  Qin Zu and
                  Wenjie Wang and
                  Shuai Chen and
                  Ju Ren and
                  Yaoxue Zhang},
	title = {RelayRec: Empowering Privacy-Preserving {CTR} Prediction via Cloud-Device
                  Relay Learning},
	booktitle = {23rd {ACM/IEEE} International Conference on Information Processing
                  in Sensor Networks, {IPSN} 2024, Hong Kong, May 13-16, 2024},
	pages = {188--199},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IPSN61024.2024.00020},
	doi = {10.1109/IPSN61024.2024.00020},
	timestamp = {Mon, 24 Mar 2025 20:40:45 +0100},
	biburl = {https://dblp.org/rec/conf/ipsn/DengWYRZWC0Z24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Click-through rate (CTR) prediction holds paramount importance across numerous applications, profoundly impacting user experience and business profitability. The freshness of a CTR prediction model significantly influences its performance, since users’ needs and interests may be changing over time, thereby requiring the model to be updated frequently. However, stringent data protection regulations have constrained the collection of users’ personal data, posing challenges to traditional model refreshing strategies that rely on centralized data collection. On-device learning techniques, such as federated learning (FL), offer a viable solution by enabling model training on devices without compromising user privacy. Nevertheless, the scarcity of training data with diverse distributions among devices presents considerable obstacles to on-device learning effectiveness. To address these challenges, we introduce RelayRec, a cloud-device relay learning framework designed for privacy-preserving CTR prediction. To establish competent initial models for devices, RelayRec categorizes pre-regulation cloud data into user preference groups, training preference-specific models for devices. Furthermore, a cloud-based automated model selector is developed to identify suitable initial models for devices. To elevate the relay learning performance of these initial models, we incorporate a personalized collaborative learning mechanism that aggregates device models based on user preferences. Extensive experimental evaluations underscore RelayRec’s superior performance compared to state-of-the-art benchmarks, affirming its efficacy in privacy-preserving CTR prediction.}
}


@inproceedings{DBLP:conf/ipsn/Sun0TGD24,
	author = {Tong Sun and
                  Borui Li and
                  Yixiao Teng and
                  Yi Gao and
                  Wei Dong},
	title = {dTEE: {A} Declarative Approach to Secure IoT Applications Using TrustZone},
	booktitle = {23rd {ACM/IEEE} International Conference on Information Processing
                  in Sensor Networks, {IPSN} 2024, Hong Kong, May 13-16, 2024},
	pages = {200--212},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IPSN61024.2024.00021},
	doi = {10.1109/IPSN61024.2024.00021},
	timestamp = {Tue, 19 Nov 2024 15:59:17 +0100},
	biburl = {https://dblp.org/rec/conf/ipsn/Sun0TGD24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Internet of Things (IoT) applications have recently been widely used in safety-critical scenarios. To prevent sensitive information leaks, IoT device vendors provide hardware-assisted protections, called Trusted Execution Environments (TEEs), like ARM Trust-Zone. Programming a TEE-based application requires separate code for two components, significantly slowing down the development process. Existing solutions tackle this issue by automatic code partition while not successfully applying it in two complicated scenarios: adding trusted logic and interactions with secure peripherals.We propose dTEE, a declarative approach to secure IoT applications based on TrustZone. dTEE proposes a rapid approach that enables developers to declare tiered-sensitive variables and functions of existing applications. Besides, dTEE automatically transforms device drivers into trusted ones. We evaluate dTEE on four real-world IoT applications and seven micro-benchmarks. Results show that dTEE achieves high expressiveness for supporting 50% more applications than existing approaches and reduces 90% of the lines of code against handcrafted development.}
}


@inproceedings{DBLP:conf/ipsn/OostvogelsM024,
	author = {Jonathan Oostvogels and
                  Sam Michiels and
                  Danny Hughes},
	title = {Twofer: Ambiguous Transmissions for Low-Latency Sensor Networks Facing
                  Noise, Privacy and Loss},
	booktitle = {23rd {ACM/IEEE} International Conference on Information Processing
                  in Sensor Networks, {IPSN} 2024, Hong Kong, May 13-16, 2024},
	pages = {213--224},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IPSN61024.2024.00022},
	doi = {10.1109/IPSN61024.2024.00022},
	timestamp = {Mon, 03 Mar 2025 21:14:13 +0100},
	biburl = {https://dblp.org/rec/conf/ipsn/OostvogelsM024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Today’s wireless sensor networks focus on achieving reliable data transfer over a lossy medium at the expense of latency. However, sensor data are often noisy and thus only lossily characterise real-world phenomena, rendering their exact transfer wasteful. Furthermore, many next-generation privacy-sensitive applications, such as smart grid control, real-time distributed object tracking, and inter-vehicle federated learning face latency and traffic bottlenecks due to the sheer amount of data collection required to overcome noise. We tackle this problem by introducing Twofer, a communication approach which reduces latency and traffic in high-noise or high-privacy settings by abandoning the focus on reliable networking. Twofer empowers developers to tune networks for latency-bound rather than reliability-bound performance; the system coordinates ambiguous transmissions, which are used to estimate the network-wide distribution of data, rather than to reliably communicate exact data from individual nodes. Twofer’s full-stack design maintains black-box compatibility with existing application code, but advocates for, and shows the value of, uncommon physical-layer features such as symbol-synchronous communication. The system is therefore implemented and evaluated on a prototype low-latency wireless mesh network called Zero-Wire. Experiments using state-of-the-art local differential privacy protocols show 25–75% latency reductions relative to conventional approaches. The results are also future-proof, with performance advantages increasing with the strength of the privacy guarantees that are offered.}
}


@inproceedings{DBLP:conf/ipsn/ChenZXWW024,
	author = {Weiwei Chen and
                  Jiefeng Zhang and
                  Xianjin Xia and
                  Shuai Wang and
                  Tian He},
	title = {Hitting the Sweet Spot: An SF-any Coding Paradigm for Empowering City-Wide
                  LoRa Communications},
	booktitle = {23rd {ACM/IEEE} International Conference on Information Processing
                  in Sensor Networks, {IPSN} 2024, Hong Kong, May 13-16, 2024},
	pages = {225--236},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IPSN61024.2024.00023},
	doi = {10.1109/IPSN61024.2024.00023},
	timestamp = {Mon, 22 Jul 2024 14:18:09 +0200},
	biburl = {https://dblp.org/rec/conf/ipsn/ChenZXWW024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {LoRa technology has garnered significant attention for its exceptional performance in city-wide applications. LoRa encodes data across multiple samples to enable long-range communication, with the level of redundancy controlled by the Spreading Factor (SF). However, practical limitations restrict how high the SF can be set. To overcome communication challenges at the highest allowable SF settings, we introduce SF-any, a software-based coding paradigm that extends an SFk packet to a quasi-SF(k + m) packet. SF-any encodes a quasi-SF(k + m) symbol with 2 m  SFk symbols. Hardware imperfections introduce time-varying frequency drifts and phase offsets, resulting in frequency leakage during quasi-SF(k +m) packet decoding. To mitigate this, we strategically insert pilots into the packet for imperfection estimation and compensation. Additionally, to maintain and exploit the coding structure in LoRa PHY, we employ a grouped repetition code at the transmitter and a joint demodulation and decoding scheme at the receiver. Comprehensive evaluations demonstrate that SF-any’s performance seamlessly scales with increasing SF, achieving up to a 14dB improvement over SF12 packets (the highest SF in LoRa PHY), and up to a 12dB improvement compared with state-of-the-art approaches.}
}


@inproceedings{DBLP:conf/ipsn/LeePPPB24,
	author = {Geonhee Lee and
                  Eunjeong Park and
                  Mingyu Park and
                  Jeongyeup Paek and
                  Saewoong Bahk},
	title = {BIC-LoRa: Bits in Chirp Shapes to Boost Throughput in LoRa},
	booktitle = {23rd {ACM/IEEE} International Conference on Information Processing
                  in Sensor Networks, {IPSN} 2024, Hong Kong, May 13-16, 2024},
	pages = {237--248},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IPSN61024.2024.00024},
	doi = {10.1109/IPSN61024.2024.00024},
	timestamp = {Tue, 16 Jul 2024 16:39:53 +0200},
	biburl = {https://dblp.org/rec/conf/ipsn/LeePPPB24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {LoRa is a low-power long-range radio technology for wide-area IoT connectivity with exceptional receiver sensitivity thanks to its chirp spread spectrum (CSS) modulation. However, insufficient data rate has always been an Achilles’ heel of LoRa. This paper proposes a novel PHY-layer design, BIC-LoRa, that leverages non-linear chirp shapes as pictograph to enhance LoRa’s data rate. It employs multiple non-linear chirps for modulation whose shapes encode additional bits to boost data rate while maintaining resilience to low SINR scenarios. To the best of our knowledge, this is the first attempt to enhance the data rate of LoRa by embedding bits in the chirp shapes. Furthermore, BIC-LoRa fully leverages the characteristics of non-linear chirps, allowing it to deal with packet collisions and increase network throughput. We implement BIC-LoRa in GNURadio and MATLAB, and compare its performance against CurveALOHA and standard LoRaWAN through real experiments on USRP B210 software-defined radios. Evaluation results demonstrate that BICLoRa achieves up to 29.4% improvement in data rate for a single link and 32% improvement in overall network throughput while retaining the low SNR robustness of LoRa in real-world scenarios.}
}


@inproceedings{DBLP:conf/ipsn/HsiaXRC24,
	author = {Chen{-}Chun Hsia and
                  Yanggang Xu and
                  Jiyuan Ren and
                  Xinlei Chen},
	title = {Demo Abstract: {CARL:} Collaborative Altitude-Adaptive Reinforcement
                  Learning for Active Search with {UAV} Swarms},
	booktitle = {23rd {ACM/IEEE} International Conference on Information Processing
                  in Sensor Networks, {IPSN} 2024, Hong Kong, May 13-16, 2024},
	pages = {249--250},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IPSN61024.2024.00025},
	doi = {10.1109/IPSN61024.2024.00025},
	timestamp = {Tue, 16 Jul 2024 16:39:53 +0200},
	biburl = {https://dblp.org/rec/conf/ipsn/HsiaXRC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Sensing noise and complex decision-making pose critical challenges to active search for lost persons amid disasters, impeding efficient rescue efforts. We introduce CARL, a collaborative altitude-adaptive reinforcement learning framework for UAV swarms. CARL integrates confidence-informed assessment with Sparse Bayesian Learning to diminish the noise impact on sensor performance, and an altitude-adaptive planner for collaborative active search strategy. Simulation experiments with up to 50 targets and 10 UAVs demonstrate CARL’s superior performance compared to baseline methods in lost person active search scenarios.}
}


@inproceedings{DBLP:conf/ipsn/WangZLZ24,
	author = {Tao Wang and
                  Yang Zhao and
                  Jie Liu and
                  Yujie Zhuang},
	title = {Demo Abstract: Underground Potato Root Tuber Sensing via a Wireless
                  Network},
	booktitle = {23rd {ACM/IEEE} International Conference on Information Processing
                  in Sensor Networks, {IPSN} 2024, Hong Kong, May 13-16, 2024},
	pages = {251--252},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IPSN61024.2024.00026},
	doi = {10.1109/IPSN61024.2024.00026},
	timestamp = {Tue, 16 Jul 2024 16:39:53 +0200},
	biburl = {https://dblp.org/rec/conf/ipsn/WangZLZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We propose to demonstrate a novel underground potato root tuber sensing framework using deep learning algorithms. We build a data acquisition system for capturing the ground truth of the tuber shape and location underground as well as the received signal strength (RSS) measurements from a wireless network. Then we design a two-stage neural network to reconstruct the cross-section images of potato tubers. Our initial experimental results show that the reconstructed images can be used to predict the size and location of various potato tubers buried underground with high accuracy. We will demonstrate the real-time performance of our prototype.}
}


@inproceedings{DBLP:conf/ipsn/WangWLGJ24,
	author = {Haoyu Wang and
                  Jiazhao Wang and
                  Xin Lv and
                  Demin Gao and
                  Wenchao Jiang},
	title = {Demo Abstract: An Interpretable and Trainable {CTC} Framework},
	booktitle = {23rd {ACM/IEEE} International Conference on Information Processing
                  in Sensor Networks, {IPSN} 2024, Hong Kong, May 13-16, 2024},
	pages = {253--254},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IPSN61024.2024.00027},
	doi = {10.1109/IPSN61024.2024.00027},
	timestamp = {Thu, 22 May 2025 17:08:34 +0200},
	biburl = {https://dblp.org/rec/conf/ipsn/WangWLGJ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cross-technology communication (CTC) enables seamless interactions between diverse wireless technologies. Most existing work is based on reversing the transmission path to identify the appropriate payload to generate the waveform that the target devices can recognize. However, this method suffers from many limitations, including dependency on specific technologies and the necessity for intricate algorithms to mitigate distortion. To address these challenges, we present NNCTC, a Neural-Network-based Cross-Technology Communication framework which can achieve reliable and interpretable Cross-Technology Communication through a training process with an example of WiFi (OFDM and CCK) to both known and unknown modulation schemes.}
}


@inproceedings{DBLP:conf/ipsn/WuLJZ0X24,
	author = {Haiyang Wu and
                  Kaiwei Liu and
                  Siyang Jiang and
                  Zhihe Zhao and
                  Zhenyu Yan and
                  Guoliang Xing},
	title = {Demo Abstract: CaringFM: An Interactive In-home Healthcare System
                  Empowered by Large Foundation Models},
	booktitle = {23rd {ACM/IEEE} International Conference on Information Processing
                  in Sensor Networks, {IPSN} 2024, Hong Kong, May 13-16, 2024},
	pages = {255--256},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IPSN61024.2024.00028},
	doi = {10.1109/IPSN61024.2024.00028},
	timestamp = {Tue, 16 Jul 2024 16:39:53 +0200},
	biburl = {https://dblp.org/rec/conf/ipsn/WuLJZ0X24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The demand for fully on-device health monitoring is huge and urgent. However, deploying Large Foundation Models conventionally relies on cloud-based computing services, which poses privacy concerns. Driven by the belief of delivering personalised healthcare to family members, this study presents the development of an innovative on-device machine learning system, CaringFM. This family caring system utilizes privacy-protecting sensors and an edge-deployed Foundation Model(FM) to offer a convenient and low-cost solution for chronic disease prediction and health condition monitoring at home. In particular, CaringFM provides general health suggestions and personalized medical information while ensuring high privacy by processing and preserving all data locally.}
}


@inproceedings{DBLP:conf/ipsn/FuCX24,
	author = {Heming Fu and
                  Hongkai Chen and
                  Guoliang Xing},
	title = {Demo Abstract: {AD-CLIP:} Privacy-Preserving, Low-Cost Synthetic Human
                  Action Dataset for Alzheimer's Patients via CLIP-based Models},
	booktitle = {23rd {ACM/IEEE} International Conference on Information Processing
                  in Sensor Networks, {IPSN} 2024, Hong Kong, May 13-16, 2024},
	pages = {257--258},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IPSN61024.2024.00029},
	doi = {10.1109/IPSN61024.2024.00029},
	timestamp = {Sun, 06 Oct 2024 21:08:38 +0200},
	biburl = {https://dblp.org/rec/conf/ipsn/FuCX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the increasing demand for smart health applications that emphasize privacy and efficiency, we introduce AD-CLIP, a synthetic data generation framework using CLIP-based models for Alzheimer’s patients. Leveraging the public dataset and data we collected from Alzheimer’s patients, AD-CLIP synthesizes human action videos featuring Alzheimer’s disease. To address privacy concerns, labeling cost, and imbalanced data distribution, AD-CLIP generates a comprehensive labeled human action skeleton dataset from depth cameras with balanced data distribution. Our preliminary experiments confirm the effectiveness of the synthesized dataset by improving the accuracy of human activity recognition up to 76.56%, which demonstrates AD-CLIP’s potential to enhance smart health applications.}
}


@inproceedings{DBLP:conf/ipsn/LiuJTLLC24,
	author = {Yi Liu and
                  Zhuozhu Jian and
                  Junbo Tan and
                  Lunfei Liang and
                  Houde Liu and
                  Xinlei Chen},
	title = {Demo Abstract: Range-SLAM: {UWB} based Realtime Indoor Location and
                  Mapping},
	booktitle = {23rd {ACM/IEEE} International Conference on Information Processing
                  in Sensor Networks, {IPSN} 2024, Hong Kong, May 13-16, 2024},
	pages = {259--260},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IPSN61024.2024.00030},
	doi = {10.1109/IPSN61024.2024.00030},
	timestamp = {Tue, 16 Jul 2024 16:39:53 +0200},
	biburl = {https://dblp.org/rec/conf/ipsn/LiuJTLLC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Simultaneous localization and mapping (SLAM) systems frequently employ LiDAR and cameras as essential sensing components. However, these sensors are proved to be unreliable in environments with poor visibility or reflective surfaces. And UWB (Ultra Wide Band) sensor with a longer wavelength shows better potential to achieve perception tasks. However, since UWB sensors can only obtain distance information from the anchors, it is difficult to densely construct the geometric structure of the environment. In this paper, We propose Range-SLAM, a method based on received signal strength indicator (RSSI) recognition and binary filtering to complete the mapping task and enhance positioning based on the map, and only require UWB as external perception sensor. Real-world experiments are conducted and prove the effectiveness, real-time performance and robustness of the Range-SLAM algorithm.}
}


@inproceedings{DBLP:conf/ipsn/ZhaoRWZ0LLWC24,
	author = {Chenyu Zhao and
                  Ciyu Ruan and
                  Shengbo Wang and
                  Jirong Zha and
                  Haoyang Wang and
                  Jiaqi Li and
                  Yuxuan Liu and
                  Xuzhe Wang and
                  Xinlei Chen},
	title = {Demo Abstract: Bio-inspired Tactile Sensing for {MAV} Landing with
                  Extreme Low-cost Sensors},
	booktitle = {23rd {ACM/IEEE} International Conference on Information Processing
                  in Sensor Networks, {IPSN} 2024, Hong Kong, May 13-16, 2024},
	pages = {261--262},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IPSN61024.2024.00031},
	doi = {10.1109/IPSN61024.2024.00031},
	timestamp = {Mon, 03 Mar 2025 21:14:13 +0100},
	biburl = {https://dblp.org/rec/conf/ipsn/ZhaoRWZ0LLWC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {MAV (Micro Aerial Vehicle) requires landing on a docking platform for recharging during or after missions due to their limited energy capacity. Inspired by biological tactile sensing, we propose a proprioceptive sensing system that allows MAV to "touch", recognize, and locate the landing platform even when visual or other positioning systems are not functioning properly. We leverage a physical phenomenon: as the MAV approaches a beneath obstacle, it experiences attitude disturbances caused by the airflow generated by the rotor’s reflections from the ground. By employing traditional signal processing and learning-based techniques to analyze signals from the IMU (Inertial Measurement Unit) and motors, the MAV can sense the edges of the platform and further calculate the precise landing coordinates. With a power consumption of less than 40 mW, our system achieves an edge detection error of less than 2 cm and a landing success rate exceeding 90%.CCS CONCEPTS• Applied computing → Aerospace; • Computing methodologies → Machine learning approaches; • Computer systems organization → Sensors and actuators.}
}


@inproceedings{DBLP:conf/ipsn/WangGZYZC24,
	author = {Xuzhe Wang and
                  Chen Gao and
                  Weichen Zhang and
                  Chengzhao Yu and
                  Chenyu Zhao and
                  Xinlei Chen},
	title = {Demo Abstract: {A} Spatio-Temporal System for Public Transit-Guided
                  Volunteer Task Matching},
	booktitle = {23rd {ACM/IEEE} International Conference on Information Processing
                  in Sensor Networks, {IPSN} 2024, Hong Kong, May 13-16, 2024},
	pages = {263--264},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IPSN61024.2024.00032},
	doi = {10.1109/IPSN61024.2024.00032},
	timestamp = {Tue, 16 Jul 2024 16:39:53 +0200},
	biburl = {https://dblp.org/rec/conf/ipsn/WangGZYZC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Volunteer activity often undergoes unique transformations with the constant changes in society. The information behind volunteer data was created to enhance public welfare efficiently and boost governmental organization productivity. This research aims to utilize public transit systems for volunteer services, reducing inequality in volunteer service provision across different regions and improving overall service efficiency. We collected and processed large-scale data related to public transit and volunteer services, conducting in-depth analysis using data mining techniques and deep learning methods. Through LDA, we annotated a large amount of volunteer data, and via data analysis, discovered patterns related to population distribution, spatial distribution, and temporal distribution. Combining public transit data and the mined features, we propose a novel spatio-temporal embedding model based on the transformer architecture, which can effectively classify and predict the matching between volunteer service demands and public transit systems. Studying the coupling between volunteer services and transportation systems helps establish a new data-driven mindset, better utilize urban resources, and provide high-quality volunteer services to the public.}
}


@inproceedings{DBLP:conf/ipsn/ZhangLWCGC24,
	author = {Weichen Zhang and
                  Yuxuan Liu and
                  Xuzhe Wang and
                  Xuecheng Chen and
                  Chen Gao and
                  Xinlei Chen},
	title = {Demo Abstract: Embodied Aerial Agent for City-level Visual Language
                  Navigation Using Large Language Model},
	booktitle = {23rd {ACM/IEEE} International Conference on Information Processing
                  in Sensor Networks, {IPSN} 2024, Hong Kong, May 13-16, 2024},
	pages = {265--266},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IPSN61024.2024.00033},
	doi = {10.1109/IPSN61024.2024.00033},
	timestamp = {Tue, 16 Jul 2024 16:39:53 +0200},
	biburl = {https://dblp.org/rec/conf/ipsn/ZhangLWCGC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As unmanned aerial vehicles (UAVs) become more prevalent in smart cities, their capacity for visual language navigation (VLN) is garnering increasing interest. VLN in cities has significant applications in delivery, rescue, and security patrol, among other fields. One of the most representative tasks is to navigate to specific locations following the language instructions. While some current methods have achieved notable results in indoor settings, challenges persist outdoors, including agents’ inaccurate spatial understanding and ambiguous language instructions. In this work, we explore an embodied navigation agent design, in which a fine-grained spatial verbalizer and a history path memory are proposed to guarantee accurate VLN in open 3D urban environments.}
}


@inproceedings{DBLP:conf/ipsn/ChuaiLLZHL24,
	author = {Xinyuan Chuai and
                  Yaoyi Li and
                  Xin Li and
                  Daxing Zhang and
                  Guobiao Hu and
                  Wei{-}Hsin Liao},
	title = {Demo Abstract: {A} Battery-free Wireless Keyboard},
	booktitle = {23rd {ACM/IEEE} International Conference on Information Processing
                  in Sensor Networks, {IPSN} 2024, Hong Kong, May 13-16, 2024},
	pages = {267--268},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IPSN61024.2024.00034},
	doi = {10.1109/IPSN61024.2024.00034},
	timestamp = {Tue, 16 Jul 2024 16:39:53 +0200},
	biburl = {https://dblp.org/rec/conf/ipsn/ChuaiLLZHL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This demonstration showcases a battery-free wireless keyboard that utilizes the kinetic energy generated from key presses to generate electrical power. Each key incorporates a Quasi-Static Toggling harvester, which employs potential energy pre-charging to ensure a consistently reliable energy output. Extensive practical testing has confirmed that this keyboard exhibits responsiveness and low latency comparable to traditional wireless keyboards. This study represents a significant improvement over previous battery-free IoT applications that often compromised service quality, as it offers a stable energy-harvesting mechanism and provides a dependable framework for designing battery-free devices.}
}


@inproceedings{DBLP:conf/ipsn/SenDPC24a,
	author = {Argha Sen and
                  Anirban Das and
                  Swadhin Pradhan and
                  Sandip Chakraborty},
	title = {Demo Abstract: {MARS} -An mmWave-based Multi-user Activity Tracking
                  Solution},
	booktitle = {23rd {ACM/IEEE} International Conference on Information Processing
                  in Sensor Networks, {IPSN} 2024, Hong Kong, May 13-16, 2024},
	pages = {269--270},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IPSN61024.2024.00035},
	doi = {10.1109/IPSN61024.2024.00035},
	timestamp = {Fri, 18 Oct 2024 15:41:27 +0200},
	biburl = {https://dblp.org/rec/conf/ipsn/SenDPC24a.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Developing robust wireless sensing mechanisms for continuously monitoring human activities and presence is crucial for creating pervasive interactive intelligent spaces. The existing literature lacks solutions that continuously monitor multiple users’ activities without prior knowledge of the environment. This requires simultaneous localization and tracking of multiple subjects and identifying their activities at various scales, including macro-scale activities like walking and squats and micro-scale activities like typing or sitting. In this demo, we present MARS , a holistic system using a single off-the-shelf mmWave radar. MARS employs an intelligent model to sense both macro and micro activities and uses a dynamic spatial time-sharing approach to sense different subjects simultaneously. Our thorough evaluation demonstrates that MARS can continuously infer activities with over 93% accuracy and an average response time of approximately 2 seconds, even with five subjects performing 19 different activities.}
}


@inproceedings{DBLP:conf/ipsn/LiGSWCV24,
	author = {Kunjun Li and
                  Manoj Gulati and
                  Dhairya Shah and
                  Steven Waskito and
                  Shantanu Chakrabarty and
                  Ambuj Varshney},
	title = {Demo Abstract: PixelGen: Rethinking Embedded Camera Systems for Mixed-Reality},
	booktitle = {23rd {ACM/IEEE} International Conference on Information Processing
                  in Sensor Networks, {IPSN} 2024, Hong Kong, May 13-16, 2024},
	pages = {271--272},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IPSN61024.2024.00036},
	doi = {10.1109/IPSN61024.2024.00036},
	timestamp = {Thu, 01 May 2025 20:23:50 +0200},
	biburl = {https://dblp.org/rec/conf/ipsn/LiGSWCV24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A confluence of advances in several fields has led to the emergence of mixed-reality headsets. They can enable us to interact with and visualize our environments in novel ways. Nonetheless, mixed-reality headsets are constrained today as their camera systems only capture a narrow part of the visible spectrum. Our environment contains rich information that cameras do not capture. It includes phenomena captured through sensors, electromagnetic fields beyond visible light, acoustic emissions, and magnetic fields. We demonstrate our ongoing work, PixelGen, to redesign cameras for low power consumption and to be able to visualize our environments in a novel manner, making some of the invisible phenomena visible. Pixel-Gen combines low-bandwidth sensors with a monochrome camera to capture a rich representation of the world. This design choice ensures information is communicated energy-efficiently. This information is then combined with diffusion-based image models to generate unique representations of the environment, visualizing the otherwise invisible fields. We demonstrate that together with a mixed reality headset, it enables us to observe the world uniquely.}
}


@inproceedings{DBLP:conf/ipsn/LinCL24,
	author = {Changyao Lin and
                  Zhenming Chen and
                  Jie Liu},
	title = {Poster Abstract: Xpi: Real-Time Progressive Inference Serving with
                  Explainable {AI} in Edge-Cloud Systems},
	booktitle = {23rd {ACM/IEEE} International Conference on Information Processing
                  in Sensor Networks, {IPSN} 2024, Hong Kong, May 13-16, 2024},
	pages = {273--274},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IPSN61024.2024.00037},
	doi = {10.1109/IPSN61024.2024.00037},
	timestamp = {Mon, 14 Apr 2025 11:20:12 +0200},
	biburl = {https://dblp.org/rec/conf/ipsn/LinCL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The constrained computing and memory resources at the edge pose challenges for satisfying different service-level objectives (SLOs) of deep learning inference requests. In this paper, we propose a novel edge-cloud progressive inference framework Xpi, which integrates explainable AI technique to facilitate early-exit, and learning-based online execution control to satisfy different SLOs and optimize edge resource overheads. We implement Xpi on an edge-cloud platform, and conduct partial experiments on two datasets. Xpi outperforms several advanced edge-cloud progressive inference frameworks in terms of accuracy and deadline satisfaction rate.}
}


@inproceedings{DBLP:conf/ipsn/WangZ24,
	author = {Pengfei Wang and
                  Zhiwei Zhao},
	title = {Poster Abstract: Ayaligo: {A} Programming Framework for Fast IoT System
                  Integration},
	booktitle = {23rd {ACM/IEEE} International Conference on Information Processing
                  in Sensor Networks, {IPSN} 2024, Hong Kong, May 13-16, 2024},
	pages = {275--276},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IPSN61024.2024.00038},
	doi = {10.1109/IPSN61024.2024.00038},
	timestamp = {Tue, 16 Jul 2024 16:39:53 +0200},
	biburl = {https://dblp.org/rec/conf/ipsn/WangZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Developing a holistic IoT application that integrates multiple IoT devices is not an easy task. Developers not only need to program the server and multiple embedded boards, but also need to connect them using designated data formats (e.g., JSON) and communication protocols (e.g., MQTT). Besides, programming frameworks are also different for different hardware (e.g., Arduino framework for Arduino UNO and Python scripts for Raspberry Pi), which also increases the development workload. In this regard, this paper presents Ayaligo, a system integration and code generation tool for IoT systems, which allows developers to directly program IoT applications as a whole, using the same syntax for framework-independent and protocol-independent programming. The tool then automatically generate codes that fit different frameworks and protocols by simply modifying the corresponding configurations, and thus can greatly boost the development life-cycle of IoT applications.}
}


@inproceedings{DBLP:conf/ipsn/ZhangLY024,
	author = {Enqi Zhang and
                  Lei Liang and
                  Lizhao You and
                  Zhaorui Wang},
	title = {Poster Abstract: Enabling Concurrent Random Access in Underwater Acoustic
                  Networks},
	booktitle = {23rd {ACM/IEEE} International Conference on Information Processing
                  in Sensor Networks, {IPSN} 2024, Hong Kong, May 13-16, 2024},
	pages = {277--278},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IPSN61024.2024.00039},
	doi = {10.1109/IPSN61024.2024.00039},
	timestamp = {Tue, 16 Jul 2024 16:39:53 +0200},
	biburl = {https://dblp.org/rec/conf/ipsn/ZhangLY024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Uncoordinated random-access protocols are especially suitable for underwater acoustic networks with long propagation delays due to their simplicity. However, their performance is limited by severe collisions caused by uncoordinated access, and the current modulations cannot handle the collisions under the multipath environment. In this paper, we propose a new modulation and a new demodulation algorithm to resolve collisions. In particular, we adopt a Zadoff-Chu (ZC) sequence with cyclic shifts as the modulation, and assign users with different ZC sequences to minimize inter-user interference. To combat the multipath challenge, we leverage the insight that the multipath interference pattern is almost constant within the same packet and the modulated data only shifts the pattern, and develop a pattern-based demodulation algorithm. Trace-driven simulation results show that our new approach allows at least five users, and outperforms the existing approach by at least 8dB. In the future, we intend to develop a real-time system in a realistic environment.}
}


@inproceedings{DBLP:conf/ipsn/XiaoLCC0C24,
	author = {Zijian Xiao and
                  Ji Luo and
                  Xuecheng Chen and
                  Yuhan Cheng and
                  Haoyang Wang and
                  Xinlei Chen},
	title = {Poster Abstract: Sprinkler-UAV Cooperative Active Scheduling System},
	booktitle = {23rd {ACM/IEEE} International Conference on Information Processing
                  in Sensor Networks, {IPSN} 2024, Hong Kong, May 13-16, 2024},
	pages = {279--280},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IPSN61024.2024.00040},
	doi = {10.1109/IPSN61024.2024.00040},
	timestamp = {Tue, 16 Jul 2024 16:39:53 +0200},
	biburl = {https://dblp.org/rec/conf/ipsn/XiaoLCC0C24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Urban particulate pollution presents considerable public health hazards, underscoring the need for effective control measures in various cities. A prevalent approach involves employing mobile sprinkling trucks. This paper proposes a Sprinkler-UAV Cooperative Active Scheduling System for enhanced efficiency in reducing particulate pollution. The system employs ground-based sprinkler trucks and airborne air pollution detection drones to actively explore and reduce PM2.5 in environments with dynamic and unknown pollution distributions. Preliminary experiments have demonstrated the effectiveness of using sprinklers for urban particulate matter control.}
}


@inproceedings{DBLP:conf/ipsn/XuJZC24,
	author = {Yanggang Xu and
                  Zhuozhu Jian and
                  Jirong Zha and
                  Xinlei Chen},
	title = {Poster Abstract: Emergency Networking Using UAVs: {A} Reinforcement
                  Learning Approach with Large Language Model},
	booktitle = {23rd {ACM/IEEE} International Conference on Information Processing
                  in Sensor Networks, {IPSN} 2024, Hong Kong, May 13-16, 2024},
	pages = {281--282},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IPSN61024.2024.00041},
	doi = {10.1109/IPSN61024.2024.00041},
	timestamp = {Tue, 16 Jul 2024 16:39:53 +0200},
	biburl = {https://dblp.org/rec/conf/ipsn/XuJZC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Utilizing unmanned aerial vehicles (UAVs) as mobile access points can assist urban communication systems in establishing emergency networks in disaster scenarios. In this paper, to organize UAVs in large-scale environments for networking purposes, we propose a multi-agent reinforcement learning (MARL) model, in which the design of a selective parameter sharing mechanism and a grouping strategy enhances the model’s scalability. Furthermore, the model adopts a reward mechanism based on intrinsic motivation, using the Large Language Model (LLM), to accelerate the optimization process. Numerical results demonstrate that this algorithm outperforms existing alternatives.}
}


@inproceedings{DBLP:conf/ipsn/LiQ0LLHJWG24,
	author = {Zongjie Li and
                  Wenying Qiu and
                  Pingchuan Ma and
                  Yichen Li and
                  You Li and
                  Sijia He and
                  Baozheng Jiang and
                  Shuai Wang and
                  Weixi Gu},
	title = {Poster Abstract: On the Accuracy and Robustness of Large Language
                  Models in Chinese Industrial Scenarios},
	booktitle = {23rd {ACM/IEEE} International Conference on Information Processing
                  in Sensor Networks, {IPSN} 2024, Hong Kong, May 13-16, 2024},
	pages = {283--284},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IPSN61024.2024.00042},
	doi = {10.1109/IPSN61024.2024.00042},
	timestamp = {Wed, 28 Aug 2024 07:47:18 +0200},
	biburl = {https://dblp.org/rec/conf/ipsn/LiQ0LLHJWG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recent studies have demonstrated that large language models (LLMs) exhibit exceptional performance across various natural language processing tasks, rivaling or even exceeding human competencies in certain areas [1] – [5] . Typically, LLMs undergo pre-training on extensive text corpora, usually using billions of tokens to develop a foundational model. To better align LLMs with human preferences and directives or to fulfill specific application needs, methods such as supervised fine-tuning (SFT), reinforcement learning from human feedback (RLHF), and direct preference optimization (DPO) have been introduced and demonstrated to be effective. These advancements facilitate more intuitive and efficient human-AI interactions. However, the substantial resource requirements throughout the training process pose challenges for individual users and smaller organizations.}
}


@inproceedings{DBLP:conf/ipsn/ChangC0ZSLJN024,
	author = {Yen{-}Cheng Chang and
                  Jesse R. Codling and
                  Yiwen Dong and
                  Jiale Zhang and
                  Jeffrey D. Shulkin and
                  Hugo Latapie and
                  Carlee Joe{-}Wong and
                  Hae Young Noh and
                  Pei Zhang},
	title = {Poster Abstract: Listen and Then Sense: Vibration-based Sports Crowd
                  Monitoring by Pre-training with Public Audio Datasets},
	booktitle = {23rd {ACM/IEEE} International Conference on Information Processing
                  in Sensor Networks, {IPSN} 2024, Hong Kong, May 13-16, 2024},
	pages = {285--286},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IPSN61024.2024.00043},
	doi = {10.1109/IPSN61024.2024.00043},
	timestamp = {Mon, 03 Mar 2025 21:14:12 +0100},
	biburl = {https://dblp.org/rec/conf/ipsn/ChangC0ZSLJN024.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper addresses challenges in monitoring human behavior in crowds through floor vibration sensing, overcoming limitations like subjective manual observation, visual occlusions, and audio interference. Our approach involves tackling limited-data vibration signal tasks by conducting pre-training across modalities, leveraging publicly available audio datasets. By leveraging self-supervised representation learning to pre-train on publicly available audio datasets, our approach reduces data requirements, improves robustness, and minimizes the need for human labeling efforts. Evaluation using in-game stadium vibration data with YouTube audio dataset demonstrates up to 5.8 × error reduction for crowd behavior.}
}


@inproceedings{DBLP:conf/ipsn/LiSXGG24,
	author = {Yixin Li and
                  Ning Sui and
                  Chenhan Xu and
                  Anil Gehi and
                  Zhishan Guo},
	title = {Poster Abstract: Real-Time Cardiovascular Disease Detection via Abnormal
                  Electrocardiogram Cycles on Embedded Systems},
	booktitle = {23rd {ACM/IEEE} International Conference on Information Processing
                  in Sensor Networks, {IPSN} 2024, Hong Kong, May 13-16, 2024},
	pages = {287--288},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IPSN61024.2024.00044},
	doi = {10.1109/IPSN61024.2024.00044},
	timestamp = {Tue, 16 Jul 2024 16:39:53 +0200},
	biburl = {https://dblp.org/rec/conf/ipsn/LiSXGG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {CCS CONCEPTS• Applied computing → Health informatics.}
}


@inproceedings{DBLP:conf/ipsn/LiRZN24a,
	author = {Yin Li and
                  Rohan Reddy and
                  Cheng Zhang and
                  Rajalakshmi Nandakumar},
	title = {Poster Abstract: Beyond-Voice - Towards Continuous 3D Hand Pose Tracking
                  on Commercial Home Assistant Devices},
	booktitle = {23rd {ACM/IEEE} International Conference on Information Processing
                  in Sensor Networks, {IPSN} 2024, Hong Kong, May 13-16, 2024},
	pages = {289--290},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IPSN61024.2024.00045},
	doi = {10.1109/IPSN61024.2024.00045},
	timestamp = {Tue, 15 Apr 2025 22:04:36 +0200},
	biburl = {https://dblp.org/rec/conf/ipsn/LiRZN24a.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The surging popularity of home assistants and their voice user interface (VUI) have made them an ideal central control hub for smart home devices. However, current form factors heavily rely on VUI, which poses accessibility and usability issues; some latest ones are equipped with additional cameras and displays, which are costly and raise privacy concerns. These concerns jointly motivate Beyond-Voice, a novel high-fidelity acoustic sensing system that allows commodity home assistant devices to track and reconstruct hand poses continuously. It transforms the device into an active sonar system using its existing onboard microphones and speakers. By feeding a high-resolution range profile to the deep learning model, we can localize 21 finger joints in 3D, bringing the granularity for acoustic hand tracking to the next level. A user study with 11 participants in 3 different environments shows that Beyond-Voice can track joints with an average mean absolute error of 16.47mm for unseen environments and users.}
}


@inproceedings{DBLP:conf/ipsn/ZhuoLWC24,
	author = {Yan Zhuo and
                  Han Li and
                  Chenlong Wang and
                  Xinlei Chen},
	title = {Poster Abstract: Adaptive Chirps Domain Window Order of MM-Wave Radar
                  for {UAV} Motion Capture},
	booktitle = {23rd {ACM/IEEE} International Conference on Information Processing
                  in Sensor Networks, {IPSN} 2024, Hong Kong, May 13-16, 2024},
	pages = {291--292},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IPSN61024.2024.00046},
	doi = {10.1109/IPSN61024.2024.00046},
	timestamp = {Tue, 16 Jul 2024 16:39:53 +0200},
	biburl = {https://dblp.org/rec/conf/ipsn/ZhuoLWC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Accurate motion capture of aerial robots in 3D is a key enabler for autonomous operation. Recently, some research considers using MM-Wave radar sensors for drone motion capture. However, due to the high noise and difficulty in capturing the center of an object in MM-Wave radar, the existing traditional methods have achieved unsatisfactory results. We develop a novel adaptive chirps domain window order method for MM-Wave radar data and customize a neural network architecture.}
}


@inproceedings{DBLP:conf/ipsn/ZhangWL24,
	author = {Yuyang Zhang and
                  Xu Weng and
                  Keck Voon Ling},
	title = {Poster Abstract: UarLogger: Logging Measurements from {UWB} and {AR}
                  Sensors on iOS Devices},
	booktitle = {23rd {ACM/IEEE} International Conference on Information Processing
                  in Sensor Networks, {IPSN} 2024, Hong Kong, May 13-16, 2024},
	pages = {293--294},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IPSN61024.2024.00047},
	doi = {10.1109/IPSN61024.2024.00047},
	timestamp = {Mon, 22 Jul 2024 20:56:17 +0200},
	biburl = {https://dblp.org/rec/conf/ipsn/ZhangWL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The multi-user Augmented Reality (AR) is powered by shared mapping and localization obtained from Visual Inertial Odometry (VIO) using AR sensors, including cameras and Inertial Measurement Units (IMU). However, VIO is vulnerable to sparse environment features, low lighting conditions, and dynamic motions. The Ultra-Wideband (UWB) transceiver, as a radio-sensing modality robust to visual and dynamic defects, has been considered as a formfitting patch on VIO to flatter multi-user AR. Nevertheless, like other wireless sensors, UWB suffers from noise and interference. Therefore, how to fuse UWB and VIO for multi-user AR is a promising but challenging research direction. To facilitate this process, we designed and released a tool, UarLogger, to log the relative location measurements from UWB and AR sensors mounted on iOS devices, as well as context-related data. We provide two examples–environmental condition evaluation and sensor fusion–to demonstrate its usefulness and showcase how it can boost the development of new algorithms with daily devices in hand.}
}


@inproceedings{DBLP:conf/ipsn/WangZLC24,
	author = {Chenlong Wang and
                  Yan Zhuo and
                  Han Li and
                  Xinlei Chen},
	title = {Poster Abstract: {TCT:} Zero-training two staged Contrastive Transformer
                  network for {SSVEP} classification},
	booktitle = {23rd {ACM/IEEE} International Conference on Information Processing
                  in Sensor Networks, {IPSN} 2024, Hong Kong, May 13-16, 2024},
	pages = {295--296},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IPSN61024.2024.00048},
	doi = {10.1109/IPSN61024.2024.00048},
	timestamp = {Tue, 16 Jul 2024 16:39:53 +0200},
	biburl = {https://dblp.org/rec/conf/ipsn/WangZLC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Steady-State Evoked Potential (SSVEP) is a brain response to specific frequency visual stimuli, used in brain-computer interfaces due to its robust and easily detectable signals. Researchers have long applied methods like Canonical Correlation Analysis and deep learning for SSVEP signal decomposition and classification. However, those methods struggle to classify SSVEP signals without new subject’s data, and calibration is time-consuming. In this paper, we propose a two-stage, two-Transformer streams network to address the challenge of classifying SSVEP signals from new subjects. We utilize hierarchical contrastive learning to project features into a more discriminable feature space before classification. The comparative experiment demonstrates that our approach exhibits superior performance relative to alternative methods in processing SSVEP signals from new subjects.}
}


@inproceedings{DBLP:conf/ipsn/YangLCHX24,
	author = {Huanqi Yang and
                  Xinyue Li and
                  Jiahuan Chen and
                  Mingda Han and
                  Weitao Xu},
	title = {Poster Abstract: Uncovering Mobile User Gait Patterns Through Contactless
                  {RF} Channels},
	booktitle = {23rd {ACM/IEEE} International Conference on Information Processing
                  in Sensor Networks, {IPSN} 2024, Hong Kong, May 13-16, 2024},
	pages = {297--298},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IPSN61024.2024.00049},
	doi = {10.1109/IPSN61024.2024.00049},
	timestamp = {Mon, 03 Mar 2025 21:14:13 +0100},
	biburl = {https://dblp.org/rec/conf/ipsn/YangLCHX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Gait-based authentication has risen to prominence for its distinctive advantages, becoming an essential security mechanism for mobile devices. These devices typically employ Inertial Measurement Units (IMUs) to capture intricate gait patterns for confirming the identity of users. However, our research highlights a vulnerability: the user’s gait data on mobile devices is susceptible to interception through a radio frequency (RF) side-channel, potentially allowing unauthorized access. We introduce Gait-Snoop as aproof-of-concept for this novel side-channel attack. Gait-Snoop utilizes the RF signals reflected during a user’s walk to extract gait information. It then correlates these RF signal patterns with IMU-derived gait data and employs a robotic arm to replicate the gait, aiming to deceive and unlock the targeted mobile devices. Our comprehensive evaluation of Gait-Snoop on smartphones demonstrates its capability to mimic IMU gait signals, underscoring the effectiveness and potential risks of such side-channel attacks.}
}


@inproceedings{DBLP:conf/ipsn/LiZWWC24,
	author = {Han Li and
                  Yan Zhuo and
                  Chenlong Wang and
                  Huandong Wang and
                  Xinlei Chen},
	title = {Poster Abstract: Generative Modeling of Post-Disaster {POI} Visits
                  Recovery},
	booktitle = {23rd {ACM/IEEE} International Conference on Information Processing
                  in Sensor Networks, {IPSN} 2024, Hong Kong, May 13-16, 2024},
	pages = {299--300},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IPSN61024.2024.00050},
	doi = {10.1109/IPSN61024.2024.00050},
	timestamp = {Tue, 16 Jul 2024 16:39:53 +0200},
	biburl = {https://dblp.org/rec/conf/ipsn/LiZWWC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The development of Internet of Things (IoT) systems has enabled disaster perception and prediction to be highly accurate. On this basis, high-quality post-disaster Point of Interest (POI) visit data can help city decision-makers develop more sophisticated recovery plans to minimize the cost of recovery. This work focuses on the problem of POI visits generation in post-disaster recovery scenarios, utilizing diffusion model to generate visit recovery curves base on the data from sensor networks. We take the disaster severity as condition and propose a disaster mapping method to map the sensor data to each POI.}
}


@inproceedings{DBLP:conf/ipsn/TileutayPK24,
	author = {Laura Tileutay and
                  Jiwoong Park and
                  Young{-}Bae Ko},
	title = {Poster Abstract: {UWB} Ranging with Scheduled Broken Packet Reception},
	booktitle = {23rd {ACM/IEEE} International Conference on Information Processing
                  in Sensor Networks, {IPSN} 2024, Hong Kong, May 13-16, 2024},
	pages = {301--302},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IPSN61024.2024.00051},
	doi = {10.1109/IPSN61024.2024.00051},
	timestamp = {Tue, 16 Jul 2024 16:39:53 +0200},
	biburl = {https://dblp.org/rec/conf/ipsn/TileutayPK24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Ultra-wideband technology has the potential to provide precise real-world localization. However, due to Non-Line-of-Sight propagation, the transmitted packet can be incomplete or lost during the ranging, which may lead to communication failure. To minimize this, we propose the scheduled signal reception technique. The proposed approach is tested in a real-world environment with Qorvo DWM3001C modules. The experimental results verify its efficiency, offering a practical solution for UWB-based localization, particularly in dynamic circumstances.}
}


@inproceedings{DBLP:conf/ipsn/XieZJJKWW24,
	author = {Qipeng Xie and
                  Zhihe Zhao and
                  Linshan Jiang and
                  Siyang Jiang and
                  Salabat Khan and
                  Weizheng Wang and
                  Kaishun Wu},
	title = {Poster Abstract: Threshold Cryptography-based Authentication Protocol
                  for Remote Healthcare},
	booktitle = {23rd {ACM/IEEE} International Conference on Information Processing
                  in Sensor Networks, {IPSN} 2024, Hong Kong, May 13-16, 2024},
	pages = {303--304},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IPSN61024.2024.00052},
	doi = {10.1109/IPSN61024.2024.00052},
	timestamp = {Tue, 16 Jul 2024 16:39:53 +0200},
	biburl = {https://dblp.org/rec/conf/ipsn/XieZJJKWW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the advancement of the Internet of Medical Things (IoMT) and cryptographic technologies, remote healthcare services have become more widespread, presenting new challenges for patient privacy and data security. Conventional security mechanisms, such as centralized authentication and key distribution systems, are susceptible to single points of failure and significant management burdens, potentially leading to compromised authentication centers and internal security threats. In response, this study presents a threshold signature algorithm, it uses Distributed Key Generation (DKG) that distributes private keys without the need for a trusted key distributor, requiring the cooperative signature of at least two nodes for authentication. This approach not only circumvents the risk of single points of failure but also enhances the system’s robustness and efficiency. The experimental results validate its prospective utility in safeguarding remote healthcare data.}
}


@inproceedings{DBLP:conf/ipsn/NisharPA24,
	author = {Abbaas Alif Mohamed Nishar and
                  Sonipriya Paul and
                  Ashwin Ashok},
	title = {Poster Abstract: Joint Optical Wireless Communication and Sensing
                  using Neuromorphic Cameras},
	booktitle = {23rd {ACM/IEEE} International Conference on Information Processing
                  in Sensor Networks, {IPSN} 2024, Hong Kong, May 13-16, 2024},
	pages = {305--306},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IPSN61024.2024.00053},
	doi = {10.1109/IPSN61024.2024.00053},
	timestamp = {Tue, 16 Jul 2024 16:39:53 +0200},
	biburl = {https://dblp.org/rec/conf/ipsn/NisharPA24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this work, we propose a novel re-use of neuromorphic (event) cameras for joint sensing and communications. Event cameras work on the principle of capturing changes in the light intensities, essentially capturing events that lead to such changes. This makes them operable at low power and sample events at fast rates (equivalent to about 40K frames-per-second compared to RGB cameras). We propose a system design to leverage the time-sampling nature of events for optical wireless communication and the ability to sample a collective area of physical space for imaging. In particular, we propose to address the challenges to achieve passive optical wireless (backscatter) communication as well as computer vision functions such as object and path detection using a single neuromorphic camera device. We posit that such an integrated functioning through a single low-power device opens new avenues for visible/invisible light communication and visual scene processing.CCS CONCEPTS•Networks → Mobile networks;•Hardware → Signal processing systems;•Computing methodologies → Computer vision.}
}


@inproceedings{DBLP:conf/ipsn/ZhangWLZ24,
	author = {Xiaotong Zhang and
                  Kun Wang and
                  Zhenjiang Li and
                  Jin Zhang},
	title = {Poster Abstract: Enhancing Human Motion Sensing with synthesized Millimeter-Waves},
	booktitle = {23rd {ACM/IEEE} International Conference on Information Processing
                  in Sensor Networks, {IPSN} 2024, Hong Kong, May 13-16, 2024},
	pages = {307--308},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IPSN61024.2024.00054},
	doi = {10.1109/IPSN61024.2024.00054},
	timestamp = {Mon, 03 Mar 2025 21:14:13 +0100},
	biburl = {https://dblp.org/rec/conf/ipsn/ZhangWLZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This poster introduces SynMotion, a novel mmWave-based human motion sensing system addressing the scarcity of training datasets. By synthesizing mmWave signals using existing vision-based human motion datasets, this system overcomes the challenge of collecting and labeling mmWave data, facilitating wider adoption of mmWave technology for applications like activity recognition, skeleton tracking and radar placement recommendation.}
}


@inproceedings{DBLP:conf/ipsn/CaoH0Q24,
	author = {Ruide Cao and
                  Qinyang He and
                  Yi Wang and
                  Zhuyun Qi},
	title = {Poster Abstract: Extending Schedule-Abstraction Graph for Event-Triggered
                  Response-Time Analysis},
	booktitle = {23rd {ACM/IEEE} International Conference on Information Processing
                  in Sensor Networks, {IPSN} 2024, Hong Kong, May 13-16, 2024},
	pages = {309--310},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IPSN61024.2024.00055},
	doi = {10.1109/IPSN61024.2024.00055},
	timestamp = {Sun, 06 Oct 2024 21:08:38 +0200},
	biburl = {https://dblp.org/rec/conf/ipsn/CaoH0Q24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {For cyber-physical systems, the predictability of their physical behaviors needs to be ensured by the determinism of cyberspace. Response-time analysis (RTA) can theoretically provide this determinism by analyzing the temporal properties of demands. However, the state-space explosion problem makes it challenging to do exact and sustainable RTA for non-preemptive systems where both release jitter and execution time variation exist, particularly when the system has event-triggered (ET) jobs. To address this issue, we propose an ET-enabled RTA based on the schedule-abstraction graph and preliminarily verify its effectiveness and scalability.}
}


@inproceedings{DBLP:conf/ipsn/BhadauriaTRGSV24,
	author = {Yuvraj Singh Bhadauria and
                  Lim Chang Quan Thaddeus and
                  C. Rajashekar Reddy and
                  Manoj Gulati and
                  Dhairya Shah and
                  Ambuj Varshney},
	title = {Poster Abstract: Enabling Non-contact, Low-Power Sensing using Tunnel
                  Diodes},
	booktitle = {23rd {ACM/IEEE} International Conference on Information Processing
                  in Sensor Networks, {IPSN} 2024, Hong Kong, May 13-16, 2024},
	pages = {311--312},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IPSN61024.2024.00056},
	doi = {10.1109/IPSN61024.2024.00056},
	timestamp = {Thu, 01 May 2025 20:23:50 +0200},
	biburl = {https://dblp.org/rec/conf/ipsn/BhadauriaTRGSV24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Tracking movements in the environment of macroscopic objects enables numerous applications, from monitoring vital signs through body movements to inferring hand gestures. However, current systems overwhelmingly rely on contact-based sensors or energy-consuming radio frequency mechanisms that necessitate complex radio transceivers for receptions. We present ongoing research on a novel low-power sensor that leverages the unique characteristics of tunnel diodes. This sensor can detect minute changes in its vicinity and communicate these changes over radio waves, all while consuming under 150 microwatts of power consumption. Notably, the transmitted radio waves are processed using low-cost, off-the-shelf radio transceivers, resulting in low cost and power consumption. The sensor’s functionality stems from the sensitivity of the resonant frequency of the tunnel diode oscillators to changes in their electromagnetic surroundings. Our early work exhibits its potential for detecting a person’s breathing patterns, and hand gestures.}
}


@inproceedings{DBLP:conf/ipsn/FanZJ24,
	author = {Guiyun Fan and
                  Yongkui Zhang and
                  Haiming Jin},
	title = {Poster Abstract: Shallowly Buried Trash Detection in Sandy Land Based
                  on {IR-UWB} Radar},
	booktitle = {23rd {ACM/IEEE} International Conference on Information Processing
                  in Sensor Networks, {IPSN} 2024, Hong Kong, May 13-16, 2024},
	pages = {313--314},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IPSN61024.2024.00057},
	doi = {10.1109/IPSN61024.2024.00057},
	timestamp = {Tue, 16 Jul 2024 16:39:53 +0200},
	biburl = {https://dblp.org/rec/conf/ipsn/FanZJ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Fast and accurate sand trash detection and localization is extremely important for trash cleaning, and at present, it still mainly depends on sanitation workers to carry out manual detection. Existing computer vision-based methods cannot detect the shallowly-buried trash. Besides, it is difficult and costly to use ground penetrating radar to detect. To overcome these limitations, we design and implement a novel detection system for shallowly buried trash in sandy land, which integrates the commercial IR-UWB radar into the intelligent unmanned vehicle. By controlling the movement of the vehicle, the radar scans the targeted sandy land and synthesizes the signal into the radar heat-map to detect and locate the shallowly buried trash. Experimental results show that the detection accuracy of the system reaches 92.3% with the radar is 75cm from the ground and the angle perpendicular to the ground is 20°. In the direction parallel to the ground, the farthest trash can be detected is 4.2m away from the radar. Within the range of 4.5m 2 , it can detect and locate up to 9 trash at the same time.}
}


@inproceedings{DBLP:conf/ipsn/MarefatNA24,
	author = {Alireza Marefat and
                  Abbaas Alif Mohamed Nishar and
                  Ashwin Ashok},
	title = {Poster Abstract: Text2Net: Transforming Plain Text into Dynamic, Interactive
                  Network Simulations},
	booktitle = {23rd {ACM/IEEE} International Conference on Information Processing
                  in Sensor Networks, {IPSN} 2024, Hong Kong, May 13-16, 2024},
	pages = {315--316},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IPSN61024.2024.00058},
	doi = {10.1109/IPSN61024.2024.00058},
	timestamp = {Tue, 16 Jul 2024 16:39:53 +0200},
	biburl = {https://dblp.org/rec/conf/ipsn/MarefatNA24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper introduces Text2Net, an innovative system designed to transform plain English descriptions into dynamic, interactive network simulations within the Emulator Virtual Engine–Next Generation (Eve-NG) environment. By integrating SOTA technologies from Natural Language Processing (NLP), Large Language Models (LLMs), and proposed adaptor software, Text2Net bridges the technical knowledge gap, enabling both technical and non-technical users to effortlessly create and interact with complex network topologies within a simulation environment. The system architecture combines an intuitive chat interface, GPT4 LLM to interpret user inputs, NLP key-value extraction, a simulation adaptor, and the EVE-NG engine. TextNet democratizes network emulation, empowering educators to efficiently construct simulations for interactive learning. It also benefits industrial prototyping and testing configurations.CCS CONCEPTS•Applied computing → Interactive learning environments; Computer-assisted instruction; IT architectures;•Networks → Network design principles; Programming interfaces; Topology analysis and generation; Logical / virtual topologies; Network manageability; Programmable networks; Network management; Network monitoring.}
}


@inproceedings{DBLP:conf/ipsn/Gupta24,
	author = {Pranjol Sen Gupta},
	title = {PhD Forum Abstract: Knowledge From Noise: EMI-Guided Power Monitoring},
	booktitle = {23rd {ACM/IEEE} International Conference on Information Processing
                  in Sensor Networks, {IPSN} 2024, Hong Kong, May 13-16, 2024},
	pages = {317--318},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IPSN61024.2024.00059},
	doi = {10.1109/IPSN61024.2024.00059},
	timestamp = {Tue, 16 Jul 2024 16:39:53 +0200},
	biburl = {https://dblp.org/rec/conf/ipsn/Gupta24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Server-level power monitoring is essential for efficient data center management. However, high expense of individual power meter for each server has hindered widespread adoption, resulting in a concentration on UPS and cluster-level monitoring in most data centers. We introduce an innovative and cost-effective power monitoring method, which utilizes a single sensor to derive power consumption data from all servers by tapping into the conducted electromagnetic interference (EMI) emitted by server power supplies. This enables the measurement of power consumption through non-invasive single-point voltage measurements. Our approach, tested with a set of ten servers from two different brands, can estimate individual server power with less than ∼7% mean absolute error.}
}


@inproceedings{DBLP:conf/ipsn/Wang24,
	author = {Yanxiang Wang},
	title = {PhD Forum Abstract: Advancing Solar Cells: Beyond Energy Harvesting
                  to Positioning and Communication},
	booktitle = {23rd {ACM/IEEE} International Conference on Information Processing
                  in Sensor Networks, {IPSN} 2024, Hong Kong, May 13-16, 2024},
	pages = {319--320},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IPSN61024.2024.00060},
	doi = {10.1109/IPSN61024.2024.00060},
	timestamp = {Tue, 16 Jul 2024 16:39:53 +0200},
	biburl = {https://dblp.org/rec/conf/ipsn/Wang24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Extensively studied for energy harvesting, solar cells present a sustainable and renewable solution for producing Internet of Things (IoT) devices that operate autonomously without the need for battery replacement. Our goal is to augment solar cells with positioning and communication capabilities, aiming to further diminish the size, weight, power consumption, and cost of IoT products. This approach leverages the photocurrent signals generated by solar cells, which are influenced by various factors, including the angle of light incidence, light intensity, and environmental reflections—attributes that can vary with location. Furthermore, by modulating the light source, we can alter the solar photocurrent, enabling the reception of data. This research explores the capability of solar cells to discern light spectral information, offering a nuanced response to illumination. This enhanced sensitivity has the potential to significantly improve localization precision and communication effectiveness.CCS CONCEPTS•Human-centered computing Ubiquitous and mobile computing.}
}


@inproceedings{DBLP:conf/ipsn/Li24,
	author = {Yao Li},
	title = {PhD Forum Abstract: Sensor Fusion for Vehicle-side and Roadside 3D
                  Object Detection and Tracking},
	booktitle = {23rd {ACM/IEEE} International Conference on Information Processing
                  in Sensor Networks, {IPSN} 2024, Hong Kong, May 13-16, 2024},
	pages = {321--322},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IPSN61024.2024.00061},
	doi = {10.1109/IPSN61024.2024.00061},
	timestamp = {Tue, 16 Jul 2024 16:39:53 +0200},
	biburl = {https://dblp.org/rec/conf/ipsn/Li24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We focus on the sensor fusion for vehicle-side and roadside 3D object detection and tracking. Although quite a few sensor fusion algorithms have been proposed, some of which are top-ranked on various leaderboards, a systematic study on how to integrate three crucial sensors (LiDAR, camera and millimeter-wave Radar sensors) to develop effective multi-modal 3D object detection and tracking for vehicle-side perception is still missing. Therefore, we first study the three sensors’ strengths and weaknesses carefully, then compare several different fusion strategies to maximize their utility. Finally, based on the lessons learnt, we propose a simple yet effective multi-modal 3D object detection and tracking framework (namely EZFusion). Without fancy network modules, our proposed EZFusion makes remarkable improvements over the LiDAR-only baseline, and achieves comparable performance. For intelligent transportation, far-range perception with roadside sensors is vital. The main challenge of far-range perception is performing accurate object detection and tracking under far distances (e.g., > 150m) at a low cost. To cope with such challenges, deploying both millimeter wave Radars and high-definition cameras, and fusing their data has become a common practice. Towards this goal, the first question is to conduct the association on the 2D image plane or the BEV plane. We argue that the former is more suitable because the magnitude of location errors in the perspective projection points is smaller at far distances on the 2D plane, leading to more accurate association. Thus, we first project the Radar points to the 2D plane and then associate them with the camera-based 2D object locations. Subsequently, we map the camera-based object locations to the BEV plane through inverse projection mapping (IPM) with the corresponding depth information from the Radar data. Finally, we engage a BEV tracking module to generate target trajectories. Our system is capable of achieving an average location accuracy of 1.3m when we extend the detection range up to 500m.}
}


@inproceedings{DBLP:conf/ipsn/Li24a,
	author = {Jiarong Li},
	title = {PhD Forum Abstract: Ubiquitous Sensing System for Activity and Gesture
                  Recognition via Optical and Energy-Harvesting Technologies},
	booktitle = {23rd {ACM/IEEE} International Conference on Information Processing
                  in Sensor Networks, {IPSN} 2024, Hong Kong, May 13-16, 2024},
	pages = {323--324},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IPSN61024.2024.00062},
	doi = {10.1109/IPSN61024.2024.00062},
	timestamp = {Tue, 16 Jul 2024 16:39:53 +0200},
	biburl = {https://dblp.org/rec/conf/ipsn/Li24a.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This research focuses on ubiquitous sensing systems for activity and gesture recognition through novel optical sensing and energy harvesting technologies such as triboelectric nanogenerators (TENG), solar cells, and visible light communication (VLC). The primary goal is to address the limitations of existing sensing systems by creating a low-cost, energy-efficient, comprehensive solution that enhances sensor integration and communication. Thus, this study utilizes TENG for contact sensing, solar cells for non-contact sensing, and VLC for spatial sensing. The applied methodologies achieve activity and gesture recognition, with accuracies up to 99.4% and 97.3%, respectively. This work has potential applications in smart home automation, health monitoring, and intelligent control by providing a more sustainable and user-friendly approach to ubiquitous sensing.}
}


@inproceedings{DBLP:conf/ipsn/Ren24,
	author = {Haojie Ren},
	title = {PhD Forum Abstract: Cooperative Perception System with Roadside Assistance},
	booktitle = {23rd {ACM/IEEE} International Conference on Information Processing
                  in Sensor Networks, {IPSN} 2024, Hong Kong, May 13-16, 2024},
	pages = {325--326},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IPSN61024.2024.00064},
	doi = {10.1109/IPSN61024.2024.00064},
	timestamp = {Tue, 16 Jul 2024 16:39:53 +0200},
	biburl = {https://dblp.org/rec/conf/ipsn/Ren24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we mainly focus on cooperative perception systems for vehicle-road coordination. Specifically, this paper encompasses two main aspects: 1) discussing the spatio-temporal synchronization issues among roadside multiple LiDARs. In this part, we design a method to synchronize the spatio-temporal data among multiple LiDARs by matching trajectory points between them; 2) designing a cooperative perception system based on uncertainty. In this part, we design a scheme to reduce the communication volume of cooperative perception by lowering the communication frequency.}
}


@inproceedings{DBLP:conf/ipsn/Liang24,
	author = {Yuzhu Liang},
	title = {PhD Forum Abstract: Exploring Service Placement and Request Scheduling
                  Based on Cooperative Edge Computing in AIoT},
	booktitle = {23rd {ACM/IEEE} International Conference on Information Processing
                  in Sensor Networks, {IPSN} 2024, Hong Kong, May 13-16, 2024},
	pages = {329--330},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IPSN61024.2024.00065},
	doi = {10.1109/IPSN61024.2024.00065},
	timestamp = {Tue, 16 Jul 2024 16:39:53 +0200},
	biburl = {https://dblp.org/rec/conf/ipsn/Liang24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The rapid growth in data generated by the Artificial Internet of Things (AIoT) necessitates an increase in computational power and presents challenges to cloud infrastructure, including traffic congestion and latency issues in AIoT systems. This trend has fostered a shift toward edge-layer computation, with cooperative edge computing emerging as a potent solution to these challenges. However, the diversity and heterogeneity of AIoT systems present significant challenges with regard to service placement, cross-regional request scheduling, and efficient resource caching. My research aims to enhance cooperative edge computing by designing an optimized clustering algorithm for efficient service placement and data processing, developing a cooperative edge request scheduling method using digital twin technology to minimize system transmission delays, and devising a resource caching method employing deep reinforcement learning in cooperative game scenarios to optimize resource allocation. This research endeavors to enhance service placement and request scheduling efficiency, thereby offering substantial computational support to AIoT systems.}
}


@inproceedings{DBLP:conf/ipsn/Wang24a,
	author = {Xuanzhi Wang},
	title = {PhD Forum Abstract: Understanding and Controlling the Sensing Coverage
                  in WiFi Sensing System},
	booktitle = {23rd {ACM/IEEE} International Conference on Information Processing
                  in Sensor Networks, {IPSN} 2024, Hong Kong, May 13-16, 2024},
	pages = {329--330},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IPSN61024.2024.00066},
	doi = {10.1109/IPSN61024.2024.00066},
	timestamp = {Tue, 16 Jul 2024 16:39:53 +0200},
	biburl = {https://dblp.org/rec/conf/ipsn/Wang24a.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the last decade, the employment of ubiquitous WiFi/4G/5G signals for wireless sensing has seen remarkable advancements, opening new vistas in the realm of wireless sensing. Despite these technological strides, the exploration into the fundamental theoretical aspects of wireless sensing, particularly concerning the sensing coverage and the mechanisms for its control, remains relatively uncharted. Addressing this critical gap, this paper introduces an innovative conceptual framework centered around the sensing signal-to-noise ratio and the application of diffraction theory to ubiquitous wireless sensing. This framework not only provides a quantitative characterization of the sensing coverage but also offers theoretical insights into controlling the sensing coverage. Understanding and adjusting sensing coverage paves the way for future innovations in sophisticated wireless signal-based sensing applications.}
}


@inproceedings{DBLP:conf/ipsn/Zou24,
	author = {Haodong Zou},
	title = {PhD Forum Abstract: Multi-View Service Provisioning in Cloud-Edge-End
                  Networks with Hierarchical Resources},
	booktitle = {23rd {ACM/IEEE} International Conference on Information Processing
                  in Sensor Networks, {IPSN} 2024, Hong Kong, May 13-16, 2024},
	pages = {333--334},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IPSN61024.2024.00067},
	doi = {10.1109/IPSN61024.2024.00067},
	timestamp = {Tue, 16 Jul 2024 16:39:53 +0200},
	biburl = {https://dblp.org/rec/conf/ipsn/Zou24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the surge of end devices and intelligent services, computing resource has begun to migrate from the cloud to end devices to meet the growing demand of users, forming a hierarchical resource distribution pattern in cloud-edge-end networks. Existing research work focuses on using edge computing technique to build a cloud-edge collaborative service offloading and task scheduling method to reduce service delay or energy consumption. However, different user groups and application scenarios may have different preferences for service quality requirements even for the same kind of service. For example, video analysis in autonomous driving focuses more on delay while video analysis in surveillance focuses more on accuracy. Meanwhile, heterogeneous cloud-edge-end devices have significant differences in the amount of resources, which poses great challenges for efficient provisioning of services. To solve this problem, we intend to propose multi-view service provisioning method in cloud-edge-end networks with hierarchically distributed resources. Firstly, we design a mapping scheme between service quality and heterogeneous resource occupation to estimate the amount of resources required for a given requirement. Secondly, we utilize model compression methods to customize powerful large models into smaller and lighter one according to the requirements of tasks. Thirdly, as resources are distributed hierarchically in cloud-edge-end networks, efficient service placement should be carried out with the goal of achieving diverse needs. The effectiveness of the proposed method is demonstrated through numerical simulations compared to state-of-the-art baselines and experiments on an implemented prototype system.}
}
