@inproceedings{DBLP:conf/ccs/Vigna25,
	author = {Giovanni Vigna},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Autonomous Vulnerability Analysis, Triaging, and Repair: {A} Historical
                  Perspective},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {1},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3748270},
	doi = {10.1145/3719027.3748270},
	timestamp = {Sun, 07 Dec 2025 22:09:45 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/Vigna25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The software components that support critical infrastructure are riddled with vulnerabilities, whose exploitation could cause service disruption, financial damage, and possibly loss of life. Although there are efforts, such as OSS-Fuzz, to continuously analyze these components for vulnerabilities, some categories of security bugs are still hard to detect. In addition, the creation of testing harnesses and the generation of effective patches still require substantial effort from human experts. To address these issues, researchers and practitioners alike have focused on automating the vulnerability analysis and repair process. In particular, DARPA has supported these research efforts with two challenges: the DARPA Cyber Grand Challenge (CGC) in 2016 and the AI Cyber Challenge (AIxCC) in 2025. In these two challenges, participants had to create Cyber Reasoning Systems (CRS) that, in different contexts, had to identify vulnerabilities, exploit them, and provide patches without any human involvement. In this talk, we take a historical look at these efforts that span a decade, especially in light of the recent advances in Large Language Models (LLMs), and highlight the lessons learned from participating in these competitions, as well as the challenges that still need to be addressed to achieve a completely autonomous vulnerability analysis, triaging, and repair process.}
}


@inproceedings{DBLP:conf/ccs/BasinHKN25,
	author = {David A. Basin and
                  Fran{\c{c}}ois Hublet and
                  Srdan Krstic and
                  Ho{\`{a}}ng Nguyen},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Mechanizing Privacy by Design},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {2--5},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3748271},
	doi = {10.1145/3719027.3748271},
	timestamp = {Fri, 26 Dec 2025 20:53:01 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/BasinHKN25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Privacy by design requires integrating data protection into systems from the outset, during their design, rather than building it in later. Related legislation does not specify how to achieve this and mainstream languages and frameworks lack support for privacy by design. To address this long-standing problem, we have developed different, effective technical solutions. First, we have developed powerful logic-based tools that enforce formal data protection policies at runtime by controlling relevant system actions. Second, we have proposed methods and tools for integrating privacy models into system design models, enabling model-driven privacy enforcement. We report on our methods, tools, and practical experiences using them.}
}


@inproceedings{DBLP:conf/ccs/DengO000025,
	author = {Gelei Deng and
                  Haoran Ou and
                  Yi Liu and
                  Jie Zhang and
                  Tianwei Zhang and
                  Yang Liu},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Oedipus: LLM-enchanced Reasoning {CAPTCHA} Solver},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {6--20},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744872},
	doi = {10.1145/3719027.3744872},
	timestamp = {Fri, 26 Dec 2025 20:53:01 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/DengO000025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {CAPTCHAs have become a ubiquitous tool in safeguarding applications from automated bots. Over time, the arms race between CAPTCHA development and evasion techniques has led to increasingly sophisticated and diverse designs. The latest iteration, reasoning CAPTCHAs, exploits tasks that are intuitively simple for humans but challenging for conventional AI technologies, thereby enhancing security measures. Driven by the evolving AI capabilities, particularly the advancements in Large Language Models (LLMs), we investigate the potential of multimodal LLMs to solve modern reasoning CAPTCHAs. Our empirical analysis reveals that, despite their reasoning capabilities, LLMs struggle to solve these CAPTCHAs effectively. In response, we introduce Oedipus, an innovative end-to-end framework for automated reasoning CAPTCHA solving. Central to this framework is a novel strategy that dissects the complex and human-easy-AI-hard tasks into a sequence of simpler and AI-easy steps. This is achieved through the development of a Domain Specific Language (DSL) for CAPTCHAs that guides LLMs in generating actionable sub-steps for each challenge. The DSL is customized to ensure that each unit operation is a highly solvable subtask by LLMs as revealed in our empirical study. These sub-steps are then tackled sequentially using the Chain-of-Thought methodology. Our evaluation shows that Oedipus effectively resolves the studied CAPTCHAs, achieving an average success rate of 63.5%. Remarkably, it also shows adaptability to the most recent CAPTCHA designs introduced in late 2023, which are not included initial study. This prompts a discussion on future strategies for designing reasoning CAPTCHAs that can effectively counter advanced AI solutions.}
}


@inproceedings{DBLP:conf/ccs/Cui00L25,
	author = {Jian Cui and
                  Mingming Zha and
                  XiaoFeng Wang and
                  Xiaojing Liao},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {The Odyssey of robots.txt Governance: Measuring Convention Implications
                  of Web Bots in Large Language Model Services},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {21--35},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765063},
	doi = {10.1145/3719027.3765063},
	timestamp = {Fri, 26 Dec 2025 20:53:01 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/Cui00L25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Web content is an essential element for large language model (LLM) services, supporting both training and inference processes. To manage the content access of web bots from LLM service vendors (i.e., LLM bots), web content publishers are increasingly incorporated content access rules into robots.txt, a long-established web content management protocol. However, the rise of proprietary LLM bots, such as OpenAI's  ChatGPT-User  and Google's  Google-Extended , has raised concerns about the transparency of web content access and whether these bots adherence to robots.txt rules. However, there is limited understanding of these LLM bots, concerning their impact on web publishers and broader web content governance. To fill this gap, we present a systematic analysis of 18 LLM bots on 582,281 robots.txt files. Our findings reveal a significant increase in robots.txt rules associated with LLM bots, particularly in domains that fall into the finance and news category. Despite the heightened integration, web publishers face challenges in managing robots.txt configurations due to the complexity of the LLM ecosystem and the involvement of third-party brokers. Furthermore, we identified several cases of robots.txt violations, including instances where LLMs memorized web content from restricted domains, and where  ChatGPT-User  ignored robots.txt and accessed restricted content. These results highlight the gaps in the current web content governance and underscore the need for enforceable content management mechanisms to respect web publishers' intentions and content control.}
}


@inproceedings{DBLP:conf/ccs/ChenJ025,
	author = {Guoqiang Chen and
                  Xin Jin and
                  Zhiqiang Lin},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {JsDeObsBench: Measuring and Benchmarking LLMs for JavaScript Deobfuscation},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {36--50},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744871},
	doi = {10.1145/3719027.3744871},
	timestamp = {Fri, 26 Dec 2025 20:53:01 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/ChenJ025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Deobfuscating JavaScript (JS) code poses a significant challenge in web security, particularly as obfuscation techniques are frequently used to conceal malicious activities within scripts. While Large Language Models (LLMs) have recently shown promise in automating the deobfuscation process, transforming detection and mitigation strategies against these obfuscated threats, a systematic benchmark to quantify their effectiveness and limitations has been notably absent. To address this gap, we present JsDeObsBench, a dedicated benchmark designed to rigorously evaluate the effectiveness of LLMs in the context of JS deobfuscation. We detail our benchmarking methodology, which includes a wide range of obfuscation techniques ranging from basic variable renaming to sophisticated structure transformations, providing a robust framework for assessing LLM performance in real-world scenarios. Our extensive experimental analysis investigates the proficiency of cutting-edge LLMs, e.g., GPT-4o, Mixtral, Llama, and DeepSeek-Coder, revealing superior performance in code simplification despite challenges in maintaining syntax accuracy and execution reliability compared to baseline methods. We further evaluate the deobfuscation of JS malware to exhibit the potential of LLMs in security scenarios. The findings highlight the utility of LLMs in deobfuscation applications and pinpoint crucial areas for further improvement.}
}


@inproceedings{DBLP:conf/ccs/HielscherG25,
	author = {Jonas Hielscher and
                  Maximilian Golla},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Quantifying Security Training in Organizations Through the Analysis
                  of {U.S.} {SEC} 10-K Filings},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {51--65},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765179},
	doi = {10.1145/3719027.3765179},
	timestamp = {Fri, 26 Dec 2025 20:53:01 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/HielscherG25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Security Awareness and Training (SAT) market exceeds multiple billion dollars annually, yet reliable data on organizational adoption remains scarce. Conflicting, survey-based figures from cybersecurity vendors leave researchers and decision-makers reliant on questionable insights. A new U.S. Securities and Exchange Commission (SEC) regulation, effective since late 2023, requires companies to disclose cybersecurity strategies in annual Form 10-K filings, offering a more consistent data source. In this study, we crawl and analyze filings from 5,286 U.S. companies across diverse sectors and sizes, using keyword searches and thematic analysis, which offers a lower-bound estimate of prevalent topics. We find that 78% of companies report implementing SAT and 27% conduct phishing simulations, with adoption varying significantly by sector and size. Larger companies report more extensive SAT efforts, often aligned with standards like NIST CSF. While multi-factor authentication (11%) is the most common employee-facing security control, many filings frame employees as a risk factor. Our findings help organizations critically assess SAT strategies and vendor claims, offer actionable insights for policymakers, and equip scholars with a coded dataset and crawling tools for ongoing longitudinal analysis.}
}


@inproceedings{DBLP:conf/ccs/MotiJMCA25,
	author = {Zahra Moti and
                  Tom Janssen{-}Groesbeek and
                  Steven Monteiro and
                  Andrea Continella and
                  Gunes Acar},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {WhisperTest: {A} Voice-Control-based Library for iOS {UI} Automation},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {66--80},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765183},
	doi = {10.1145/3719027.3765183},
	timestamp = {Fri, 26 Dec 2025 20:53:01 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/MotiJMCA25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Dynamic analysis and UI automation are essential for scalable detection of privacy leaks, vulnerabilities, and malicious code in mobile apps. While the Android ecosystem offers a variety of tools, options for iOS apps are limited and require either access to the app source code or jailbreaking the test device. To address this gap, we introduce W hisper T est , an open-source iOS UI automation library that operates without jailbreaking. W hisper T est  is based on a newly designed approach that leverages Apple's Voice Control accessibility feature to interact with app or system UIs via text-to-speech. During interactions, W hisper T est  monitors the device system logs in real time and scrapes the UI via screenshots and accessibility audits to recover app state changes. We demonstrate W hisper T est 's capabilities through a diverse set of tasks, including a web privacy measurement and a fully-automated dynamic analysis of 200 child-directed iOS apps. To overcome the challenges of automating apps with diverse UI designs, W hisper T est  optionally integrates multimodal large language models to reason about context and interact with system permission prompts, consent dialogs, subscription prompts, and age gates. Our exploratory analysis of children's apps uncovers widespread use of third-party tracking, limited recognition of user consent, and unencrypted HTTP requests. Overall, we show that W hisper T est  enables scalable dynamic analysis of iOS applications across diverse tasks, contributing to a safer and more transparent mobile ecosystem.}
}


@inproceedings{DBLP:conf/ccs/SahinSB0Z025,
	author = {Sena Sahin and
                  Burak Sahin and
                  Robin Berthier and
                  Kate Davis and
                  Saman A. Zonouz and
                  Frank Li},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {The Challenges and Opportunities with Cybersecurity Regulations: {A}
                  Case Study of the {US} Electric Power Sector},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {81--95},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765184},
	doi = {10.1145/3719027.3765184},
	timestamp = {Fri, 26 Dec 2025 20:53:01 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/SahinSB0Z025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In various industries, cybersecurity regulations have been enacted in an effort to drive improvements to organizational security postures. Despite the prominent influence of these regulations, there has been limited prior investigation of how organizations engage with these regulations and the challenges that they face. Assessing these factors is vital for understanding the impact of cybersecurity regulations in practice and how to enhance them moving forward. In this paper, we take a step towards filling this gap by investigating in depth the mature cybersecurity standard regulating the US electric power industry, NERC CIP (North American Electric Reliability Corporation Critical Infrastructure Protection), mandatory across the industry for the past 15 years. Seeking to improve this existing regulation, we assess the challenges with how this regulation is developed, adopted, and audited, and provide directions for improvement. Given the human-centric nature of regulation compliance, we do so by conducting in-depth semi-structured interviews with a diverse set of industry professionals who have direct experience with the regulation. While this standard is specific to the US energy sector, the challenges and insights uncovered through this qualitative exploration have broader lessons on how regulatory frameworks shape the security of various other industries. Our study reveals varied issues that can arise with a cybersecurity regulation, such as with the standard's specificity, burdensome compliance documentation, auditing subjectivity and inconsistency, and development processes that result in outdated guidelines. These findings in turn shed light on promising directions for policymakers, industry stakeholders, and regulatory bodies to improve cybersecurity regulations and their compliance.}
}


@inproceedings{DBLP:conf/ccs/NayakW0KF25,
	author = {Asmit Nayak and
                  Yash Wani and
                  Shirley Zhang and
                  Rishabh Khandelwal and
                  Kassem Fawaz},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Automatically Detecting Online Deceptive Patterns},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {96--110},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765191},
	doi = {10.1145/3719027.3765191},
	timestamp = {Fri, 26 Dec 2025 20:53:01 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/NayakW0KF25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Deceptive patterns in digital interfaces manipulate users into making unintended decisions, exploiting cognitive biases and psychological vulnerabilities. These patterns have become ubiquitous on various digital platforms. While efforts to mitigate deceptive patterns have emerged from legal and technical perspectives, a significant gap remains in creating usable and scalable solutions. We introduce our  AutoBot  framework to address this gap and help web stakeholders navigate and mitigate online deceptive patterns.  AutoBot  accurately identifies and localizes deceptive patterns from a screenshot of a website without relying on the underlying HTML code.  AutoBot  employs a two-stage pipeline that leverages the capabilities of specialized vision models to analyze website screenshots, identify interactive elements, and extract textual features. Next, using a large language model,  AutoBot  understands the context surrounding these elements to determine the presence of deceptive patterns. We also use  AutoBot , to create a synthetic dataset to distill knowledge from ' teacher ' LLMs to smaller language models. Through extensive evaluation, we demonstrate  AutoBot 's effectiveness in detecting deceptive patterns on the web, achieving an F1-score of 0.93 in this task, underscoring its potential as an essential tool for mitigating online deceptive patterns. We implement  AutoBot , across three downstream applications targeting different web stakeholders: (1) a local browser extension providing users with real-time feedback, (2) a Lighthouse audit to inform developers of potential deceptive patterns on their sites, and (3) as a measurement tool for researchers and regulators.}
}


@inproceedings{DBLP:conf/ccs/WangMG0G25,
	author = {Zilong Wang and
                  Gideon Mohr and
                  Klaus von Gleissenthall and
                  Jan Reineke and
                  Marco Guarnieri},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Synthesis of Sound and Precise Leakage Contracts for Open-Source {RISC-V}
                  Processors},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {111--125},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765148},
	doi = {10.1145/3719027.3765148},
	timestamp = {Thu, 29 Jan 2026 13:45:43 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/WangMG0G25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Leakage contracts have been proposed as a new security abstraction at the instruction set architecture level. Leakage contracts aim to capture the information that processors may leak via microarchitectural side channels. Recently, the first tools have emerged to verify whether a processor satisfies a given contract. However, coming up with a contract that is both sound and precise for a given processor is challenging, time-consuming, and error-prone, as it requires in-depth knowledge of the timing side channels introduced by microarchitectural optimizations. In this paper, we address this challenge by proposing L ea S yn , the first tool for automatically synthesizing leakage contracts that are both  sound  and  precise  for processor designs at register-transfer level. Starting from a user-provided contract template that captures the space of possible contracts, L ea S yn  automatically constructs a contract, alternating between contract synthesis, which ensures precision based on an empirical characterization of the processor's leaks, and contract verification, which ensures soundness. Using L ea S yn , we automatically synthesize contracts for six open-source RISC-V CPUs for a variety of contract templates. Our experiments indicate that L ea S yn 's contracts are sound and more precise ( i.e. , represent the actual leaks in the target processor more faithfully) than contracts constructed by existing approaches.}
}


@inproceedings{DBLP:conf/ccs/SchererBSM25,
	author = {Markus Scherer and
                  Jeppe Fredsgaard Blaabjerg and
                  Alexander Sj{\"{o}}sten and
                  Matteo Maffei},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Wanilla: Sound Noninterference Analysis for WebAssembly},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {126--140},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765156},
	doi = {10.1145/3719027.3765156},
	timestamp = {Fri, 26 Dec 2025 20:53:01 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/SchererBSM25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {WebAssembly (Wasm) is rapidly gaining popularity as a distribution format for software components embedded in various security-critical domains. Unfortunately, despite its prudent design, WebAssembly's primary use case as a compilation target for memory-unsafe languages leaves some possibilities for memory corruption. Independently of that, Wasm is an inherently interesting target for information flow analysis due to its interfacing role. Both the information flows between a Wasm module and its embedding context, as well as the memory integrity within a module, can be described by the hyperproperty noninterference. So far, no sound, fully static noninterference analysis for Wasm has been presented, but sound reachability analyses were. This work presents a novel and general approach to lift reachability analyses to noninterference by tracking taints on values and using value-sensitive, relational reasoning to remove them when appropriate. We implement this approach in  Wanilla,  the first automatic, sound, and fully static noninterference analysis for WebAssembly, and demonstrate its performance and precision by verifying memory integrity and other noninterference properties with several synthetic and real-world benchmarks.}
}


@inproceedings{DBLP:conf/ccs/SongDNZEC025,
	author = {Shixin Song and
                  Tingzhen Dong and
                  Kosi Nwabueze and
                  Julian Zanders and
                  Andres Erbsen and
                  Adam Chlipala and
                  Mengjia Yan},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Securing Cryptographic Software via Typed Assembly Language},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {141--155},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765116},
	doi = {10.1145/3719027.3765116},
	timestamp = {Fri, 26 Dec 2025 20:53:01 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/SongDNZEC025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Authors of cryptographic software are well aware that their code should not leak secrets through its timing behavior, and, until 2018, they believed that following industry-standard  constant-time  coding guidelines was sufficient. However, the revelation of the Spectre family of speculative execution attacks injected new complexities. To block speculative attacks, prior work has proposed annotating the program's source code to mark secret data, with hardware using this information to decide when to speculate (i.e., when only public values are involved) or not (when secrets are in play). While these solutions are able to track secret information stored on the heap, they suffer from limitations that prevent them from correctly tracking secrets on the stack, at a cost in performance. This paper introduces  SecSep , a transformation framework that rewrites assembly programs so that they partition secret and public data on the stack. By moving from the source-code level to assembly rewriting,  SecSep  is able to address limitations of prior work. The key challenge in performing this assembly rewriting stems from the loss of semantic information through the lengthy compilation process. The key innovation of our methodology is a new variant of typed assembly language (TAL),  Octal , which allows us to address this challenge. Assembly rewriting is driven by compile-time inference within  Octal . We apply our technique to cryptographic programs and demonstrate that it enables secure speculation efficiently, incurring a low average overhead of 1.2%.}
}


@inproceedings{DBLP:conf/ccs/BarbosaKLSS25,
	author = {Manuel Barbosa and
                  Matthias J. Kannwischer and
                  Thing{-}Han Lim and
                  Peter Schwabe and
                  Pierre{-}Yves Strub},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Formally Verified Correctness Bounds for Lattice-Based Cryptography},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {156--169},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765218},
	doi = {10.1145/3719027.3765218},
	timestamp = {Fri, 26 Dec 2025 20:53:01 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/BarbosaKLSS25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Decryption errors play a crucial role in the security of KEMs based on Fujisaki-Okamoto because the concrete security guarantees provided by this transformation directly depend on the probability of such an event being bounded by a small real number. In this paper we present an approach to formally verify the claims of statistical probabilistic bounds for incorrect decryption in lattice-based KEM constructions. Our main motivating example is the PKE encryption scheme underlying ML-KEM. We formalize the statistical event that is used in the literature to heuristically approximate ML-KEM decryption errors and confirm that the upper bounds given in the literature for this event are correct. We consider FrodoKEM as an additional example, to demonstrate the wider applicability of the approach and the verification of a correctness bound without heuristic approximations. We also discuss other (non-approximate) approaches to bounding the probability of ML-KEM decryption.}
}


@inproceedings{DBLP:conf/ccs/0002SRB25,
	author = {Weidong Zhu and
                  Carson Stillman and
                  Sara Rampazzi and
                  Kevin R. B. Butler},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Enabling Secure and Efficient Data Loss Prevention with a Retention-aware
                  Versioning {SSD}},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {171--185},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765135},
	doi = {10.1145/3719027.3765135},
	timestamp = {Fri, 26 Dec 2025 20:53:01 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/0002SRB25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cyberattacks resulting in data loss remain a critical concern in modern data protection. To mitigate such threats, data versioning has been introduced to recover compromised data by reverting the storage to a prior uncompromised state. However, most current versioning solutions are implemented at the host level (e.g., within the operating system), making them vulnerable to adversaries with escalated privileges who can compromise OS-level protections. Thus, device-level methods have been proposed to shift the versioning logic to hardware-isolated storage devices outside the untrusted OS. Unfortunately, these solutions suffer from limited retention times for historical data, narrowing the protection window and leaving systems exposed to persistent attacks. In this paper, we propose  LAST,  an inva L idation- A ware Ver S ioning sys T em for flash-based SSDs, that enables data versioning with enhanced awareness of data retention time, ensuring long-term availability of historical data with small performance impact. LAST modifies the SSD's flash translation layer (FTL) to retain the data invalidation order for tracking data retention time. Then, it leverages an ordered garbage collection (GC) that always reclaims versioned data with the longest retention time, as determined by the invalidation sequence. Therefore, this approach prevents the premature deletion of data with shorter retention, significantly extending the protection window and reducing the risk of data loss. Evaluated under various real-world workloads, LAST achieves a small latency overhead of 1.5% over a regular SSD while maintaining data history for up to 126.4 days with an average of 52.6 days. This significantly outperforms the average retention of current versioning methods by 61.4% at least and 165.9% at most, enhancing the protection window against data loss from cyberattacks.}
}


@inproceedings{DBLP:conf/ccs/ZhuangW0L25,
	author = {Zeyang Zhuang and
                  Zilun Wang and
                  Wei Meng and
                  Michael R. Lyu},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Don't Panic! Finding Bugs Hidden Behind Rust Runtime Safety Checks},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {186--200},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765142},
	doi = {10.1145/3719027.3765142},
	timestamp = {Fri, 26 Dec 2025 20:53:01 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/ZhuangW0L25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Rust has been extensively used in software and system development due to its guarantees for memory and concurrency safety. Fuzzing is a popular bug detection technique for examining the correctness and robustness of programs. However, we identify that current state-of-the-art Rust fuzzers are significantly impeded by the ubiquitous presence of Rust runtime safety checks, resulting in poor effectiveness and efficiency. These checks, which are inserted either implicitly by the compiler or explicitly by the compiler or developers, could cause a high number of panic crashes and early program termination in fuzzing. Consequently, current fuzzers are unable to effectively explore deep code behind the runtime safety checks, leaving potential vulnerabilities undetected. To address these limitations, we propose P anic K iller , a new Rust fuzzing technique to detect bugs hidden in deep and unsafe code. It performs a cross-IR analysis to precisely identify runtime safety checks and unsafe code in Rust programs, and employs a novel dynamic taint analysis to track the critical input bytes associated with the conditions enforced by these checks. P anic K iller  further performs novel input prioritization and mutation strategies to achieve effective and efficient fuzzing. Our evaluation shows that P anic K iller  significantly outperformed current state-of-the-art Rust fuzzers by achieving average improvements of 22.0× in bug exposure speed, 1.68× in code coverage, and 18.2× in false-positive crash reduction, and up to 129.0×, 2.10×, and 64.8× improvements, respectively. P anic K iller  further helped detect 14 and 53 previously unknown vulnerabilities in the benchmark dataset and in the real world, with 11 RustSec IDs assigned.}
}


@inproceedings{DBLP:conf/ccs/ZhongWWZT25,
	author = {Zheng Zhong and
                  Ruoyu Wu and
                  Junpeng Wan and
                  Muqi Zou and
                  Dave (Jing) Tian},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Hardening Deep Neural Network Binaries against Reverse Engineering
                  Attacks},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {201--215},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765144},
	doi = {10.1145/3719027.3765144},
	timestamp = {Fri, 26 Dec 2025 20:53:01 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/ZhongWWZT25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Deep Neural Networks (DNNs) are proprietary assets due to the expertise, confidential data, and high development costs involved in model training. Well-trained DNN models are compiled into DNN binaries to be efficiently executed on various platforms, such as edge devices and cloud infrastructures. Recent research on DNN binary decompilation shows the potential of stealing DNN models via binary reverse engineering techniques. While obfuscation is a well-studied technique to hamper binary reverse engineering, general obfuscation schemes are not designed for this new type of binary and have limitations in concealing information within DNN binaries due to the unique characteristics of DNN binaries. In this paper, we show that existing reverse engineering attacks on DNN binaries can recover 98.5% of DNN operators from DNN binaries that have been obfuscated using general obfuscators. We then propose new obfuscation schemes tailored for DNN binaries, namely, (1) Flexible Operator Fusion; (2) Fake Operator Insertion; and (3) Operator Computation Reordering. We implement our dedicated obfuscation schemes as an end-to-end obfuscation toolchain called NeuroShield. Experiments show that NeuroShield is resilient to existing model reverse engineering attacks while introducing a reasonable overhead. Specifically, NeuroShield reduces the operator recovery rate to 3.03% for CV models and 47.18% for NLP models. Moreover, it has comparable binary size overhead and significantly lower execution time overhead (7.8% - 36.1%) compared to OLLVM, one of the commonly used general obfuscators.}
}


@inproceedings{DBLP:conf/ccs/KimSY25,
	author = {Dong{-}ok Kim and
                  Juhyun Song and
                  Insu Yun},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {{CROSS-X:} Generalized and Stable Cross-Cache Attack on the Linux
                  Kernel},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {216--230},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765152},
	doi = {10.1145/3719027.3765152},
	timestamp = {Fri, 26 Dec 2025 20:53:01 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/KimSY25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The cross-cache attack is a fundamental component of modern Linux kernel exploits, spanning real-world attacks and recent research. Despite its importance, it is often regarded as unreliable due to its complex setup, and existing studies lack in-depth analysis of its mechanics. In this paper, we address this gap by: (1) reviewing public strategies and their limitations, (2) proposing two optimized strategies effective in varied conditions, and (3) introducing sys, an automated system that identifies suitable target objects for cross-cache attacks. We evaluated our strategies on a synthetic vulnerability and nine real-world CVEs, achieving over 99% and 85% success rates under idle and busy workloads, respectively. They also outperformed existing methods in 6 of 8 CVEs under idle workloads and 5 of 8 under busy workloads. For object identification, we define three key properties: (1) spray capability, (2) minimal interference, and (3) useful primitives. Based on these, sys identified seven versatile target objects and their relationship with interfering allocations. We believe our work will enhance public understanding of cross-cache attacks and contribute to improving Linux kernel security.}
}


@inproceedings{DBLP:conf/ccs/ShaikJS25,
	author = {Altaf Shaik and
                  Robert Jaschek and
                  Jean{-}Pierre Seifert},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Uncovering Hidden Paths in 5G: Exploiting Protocol Tunneling and Network
                  Boundary Bridging},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {231--245},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765206},
	doi = {10.1145/3719027.3765206},
	timestamp = {Fri, 26 Dec 2025 20:53:01 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/ShaikJS25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {5G networks are designed with a clear separation between control and user planes, interfaces, and core functions—each expected to operate within isolated trust boundaries. When these boundaries are not properly enforced, malicious traffic from user equipment can traverse unintended paths and reach sensitive components. This work demonstrates how an attacker-controlled UE can exploit such weaknesses using protocol tunneling and network boundary bridging to bypass isolation and interact with internal elements of the 5G core. To assess the real-world impact of these attack vectors, we evaluated six open-source and commercial 5G core deployments, focusing on how user-plane infrastructure processes adversarial traffic from a UE. Our findings reveal inconsistent enforcement of routing, segmentation, and validation policies—rooted in architectural misconfigurations and specification ambiguities. These systemic issues allow crafted but standards-compliant traffic to cross core boundaries. This led to the discovery of seven vulnerabilities and six previously undocumented weaknesses—including flaws in UPF forwarding logic, incomplete protocol validation, and ambiguous specification behaviors. Building on these insights, we design and evaluate three novel attacks that enable direct data injection into UEs, charging fraud via traffic reflection, and full user traffic interception through a rogue gNodeB. We conclude by outlining practical mitigations, emphasizing the need for strict interface validation and stronger isolation controls in 5G core networks.}
}


@inproceedings{DBLP:conf/ccs/0001MBS25,
	author = {Fabian B{\"{a}}umer and
                  Marcel Maehren and
                  Marcus Brinkmann and
                  J{\"{o}}rg Schwenk},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Finding {SSH} Strict Key Exchange Violations by State Learning},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {246--260},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765208},
	doi = {10.1145/3719027.3765208},
	timestamp = {Fri, 26 Dec 2025 20:53:01 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/0001MBS25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {SSH is an important protocol for secure remote shell access to servers on the Internet. At USENIX 2024, Bäumer et al. presented the Terrapin attack on SSH, which relies on the attacker injecting optional messages during the key exchange. To mitigate this attack, SSH vendors adopted an extension developed by OpenSSH called strict key exchange (''strict KEX''). With strict KEX, optional messages are forbidden during the handshake, preventing the attack. In practice, this should simplify the state machine of an SSH handshake to a linear message flow similar to that of TLS. In this work, we analyze the design, implementation, and security of strict KEX in popular SSH servers, using black-box state learning, which can uncover the hidden state machine of an implementation. In practice, it is limited by the number of learned messages and the complexity of the state machine. Thus, learning the complete state machine of SSH is infeasible. Previous research on SSH, therefore, excluded optional messages, learning only a partial state machine. However, these messages are a critical part of the Terrapin attack. We propose to instead learn the complete state machine of the handshake phase of an SSH server, but with strict KEX enabled. We investigate the security of ten SSH implementations supporting strict KEX for up to five key exchange algorithms. In total, we learn 33 state machines, revealing significant differences in the implementations. We show that seven implementations violate the strict KEX specification and find two critical security vulnerabilities. One results in a rogue session attack in the proprietary Tectia SSH implementation. Another affects the official SSH implementation of the Erlang Open Telecom Platform, and enables unauthenticated remote code execution in the security context of the SSH server.}
}


@inproceedings{DBLP:conf/ccs/Aly0Y25,
	author = {Ahmed Aly and
                  Essam Mansour and
                  Amr M. Youssef},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {{OCR-APT:} Reconstructing {APT} Stories from Audit Logs using Subgraph
                  Anomaly Detection and LLMs},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {261--275},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765219},
	doi = {10.1145/3719027.3765219},
	timestamp = {Fri, 26 Dec 2025 20:53:01 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/Aly0Y25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Advanced Persistent Threats (APTs) are stealthy cyberattacks that often evade detection in system-level audit logs. Provenance graphs model these logs as connected entities and events, revealing relationships that are missed by linear log representations. Existing systems apply anomaly detection to these graphs but often suffer from high false positive rates and coarse-grained alerts. Their reliance on node attributes like file paths or IPs leads to spurious correlations, reducing detection robustness and reliability. To fully understand an attack's progression and impact, security analysts need systems that can generate accurate, human-like narratives of the entire attack. To address these challenges, we introduce OCR-APT, a system for APT detection and reconstruction of human-like attack stories. OCR-APT uses Graph Neural Networks (GNNs) for subgraph anomaly detection, learning behavior patterns around nodes rather than fragile attributes such as file paths or IPs. This approach leads to a more robust anomaly detection. It then iterates over detected subgraphs using Large Language Models (LLMs) to reconstruct multi-stage attack stories. Each stage is validated before proceeding, reducing hallucinations and ensuring an interpretable final report. Our evaluations on the DARPA TC3, OpTC, and NODLINK datasets show that OCR-APT outperforms state-of-the-art systems in both detection accuracy and alert interpretability. Moreover, OCR-APT reconstructs human-like reports that comprehensively capture the attack story.}
}


@inproceedings{DBLP:conf/ccs/SonKOPK25,
	author = {Mincheol Son and
                  Kwangmin Kim and
                  Beomseok Oh and
                  CheolJun Park and
                  Yongdae Kim},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {CITesting: Systematic Testing of Context Integrity Violations in {LTE}
                  Core Networks},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {276--290},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765230},
	doi = {10.1145/3719027.3765230},
	timestamp = {Fri, 26 Dec 2025 20:53:01 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/SonKOPK25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cellular networks increasingly support critical infrastructure, yet their security remains an ongoing concern. While prior research has focused mainly on downlink vulnerabilities, uplink security—how user equipment (UE) affects the core network—has received limited attention. We study a class of uplink vulnerabilities, which we define as context integrity violations (CIVs), where an unauthenticated or improperly authenticated UE modifies the internal state of other subscribers. Prior work identified a few instances of CIVs, but the broader attack surface remains unexplored. We present CITesting, the first framework for systematically detecting CIVs in LTE core networks. CITesting explores diverse procedure chains, tests a broad range of Information Elements (IEs), and validates behavior across UE connection states. It introduces stateful dual-UE control testing to manage victim UE state and employs a behavioral oracle to detect context modifications in black-box networks. We evaluated CITesting on two open-source (Open5GS, srsRAN) and two commercial (Amarisoft, Nokia) LTE core network implementations, identifying 29, 22, 16, and 59 distinct CIVs after post-analysis. These findings enable remote attacks including UE detachment, IMSI exposure, and presence detection attacks. Note that traditional attack models such as fake base station and active SigOver require the active attacker to be co-located in the same cell. In contrast, our attacks require the active attacker to be in the same MME region (significantly broader than a cell) as the victim UE. All findings were responsibly disclosed, and patches were contributed to Amarisoft and Open5GS.}
}


@inproceedings{DBLP:conf/ccs/SenMB25,
	author = {Pritam Sen and
                  Yao Ma and
                  Cristian Borcea},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {CryptGNN: Enabling Secure Inference for Graph Neural Networks},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {291--305},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765232},
	doi = {10.1145/3719027.3765232},
	timestamp = {Tue, 09 Dec 2025 08:06:18 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/SenMB25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We present CryptGNN, a secure and effective inference solution for third-party graph neural network (GNN) models in the cloud, which are accessed by clients as ML as a service (MLaaS). The main novelty of CryptGNN is its secure message passing and feature transformation layers using distributed secure multi-party computation (SMPC) techniques. CryptGNN protects the client's input data and graph structure from the cloud provider and the third-party model owner, and it protects the model parameters from the cloud provider and the clients. CryptGNN works with any number of SMPC parties, does not require a trusted server, and is provably secure even if  P  -1 out of  P  parties in the cloud collude. Theoretical analysis and empirical experiments demonstrate the security and efficiency of CryptGNN.}
}


@inproceedings{DBLP:conf/ccs/YangSM0SQ0K025,
	author = {Qin Yang and
                  Nicholas Stout and
                  Meisam Mohammady and
                  Han Wang and
                  Ayesha Samreen and
                  Christopher J. Quinn and
                  Yan Yan and
                  Ashish Kundu and
                  Yuan Hong},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {{PLRV-O:} Advancing Differentially Private Deep Learning via Privacy
                  Loss Random Variable Optimization},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {306--320},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765151},
	doi = {10.1145/3719027.3765151},
	timestamp = {Fri, 26 Dec 2025 20:53:01 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/YangSM0SQ0K025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Differentially Private Stochastic Gradient Descent (DP-SGD) is a standard method for enforcing privacy in deep learning, typically using the Gaussian mechanism to perturb gradient updates. However, conventional mechanisms such as Gaussian and Laplacian noise are parameterized only by variance or scale. This single degree of freedom ties the magnitude of noise directly to both privacy loss and utility degradation, preventing independent control of these two factors. The problem becomes more pronounced when the number of composition rounds  T  and batch size  B  vary across tasks, as these variations induce task-dependent shifts in the privacy–utility trade-off, where small changes in noise parameters can disproportionately affect model accuracy. To address this limitation, we introduce  PLRV-O , a framework that defines a broad search space of parameterized DP-SGD noise distributions, where privacy loss  moments  are tightly characterized yet can be optimized more independently with respect to utility loss. This formulation enables systematic adaptation of noise to task-specific requirements, including (i) model size, (ii) training duration, (iii) batch sampling strategies, and (iv) clipping thresholds under both training and fine-tuning settings. Empirical results demonstrate that  PLRV-O  substantially improves utility under strict privacy constraints. On CIFAR-10, a fine-tuned ViT achieves 94.03% accuracy at ∈ ≈ 0.5, compared to 83.93% with Gaussian noise. On SST-2, RoBERTa-large reaches 92.20% accuracy at ∈ ≈ 0.2, versus 50.25% with Gaussian. Source code is available at https://github.com/datasec-lab/plrvo.}
}


@inproceedings{DBLP:conf/ccs/SheybaniPKRMKS25,
	author = {Nojan Sheybani and
                  Alessandro Pegoraro and
                  Jonathan Knauer and
                  Phillip Rieger and
                  Elissa Mollakuqe and
                  Farinaz Koushanfar and
                  Ahmad{-}Reza Sadeghi},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {\emph{Z}ORRO: Zero-Knowledge Robustness and Privacy for Split Learning},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {321--334},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765160},
	doi = {10.1145/3719027.3765160},
	timestamp = {Fri, 26 Dec 2025 20:53:01 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/SheybaniPKRMKS25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Split Learning (SL) is a distributed learning approach that enables resource-constrained clients to collaboratively train deep neural networks (DNNs) by offloading most layers to a central server while keeping in- and output layers on the client-side. This setup enables SL to leverage server computation capacities without sharing data, making it highly effective in resource-constrained environments dealing with sensitive data. However, the distributed nature enables malicious clients to manipulate the training process. By sending poisoned intermediate gradients, they can inject backdoors into the shared DNN. Existing defenses are limited by often focusing on server-side protection and introducing additional overhead for the server. A significant challenge for client-side defenses is enforcing malicious clients to correctly execute the defense algorithm. We present  Z ORRO, a private, verifiable, and robust SL defense scheme. Through our novel design and application of interactive zero-knowledge proofs (ZKPs), clients prove their correct execution of a client-located defense algorithm, resulting in proofs of computational integrity attesting to the benign nature of locally trained DNN portions. Leveraging the frequency representation of model partitions enables  Z ORRO to conduct an in-depth inspection of the locally trained models in an untrusted environment, ensuring that each client forwards a benign checkpoint to its succeeding client. In our extensive evaluation, covering different model architectures as well as various attack strategies and data scenarios, we show  Z ORRO's effectiveness, as it reduces the attack success rate to less than 6% while causing even for models storing 1000000 parameters on the client-side an overhead of less than 10 seconds.}
}


@inproceedings{DBLP:conf/ccs/YeSQ25,
	author = {Kai Ye and
                  Liangcai Su and
                  Chenxiong Qian},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {\emph{ImportSnare: } Directed 'Code Manual' Hijacking in Retrieval-Augmented
                  Code Generation},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {335--349},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765161},
	doi = {10.1145/3719027.3765161},
	timestamp = {Fri, 26 Dec 2025 20:53:01 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/YeSQ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Code generation has emerged as a pivotal capability of Large Language Models (LLMs), revolutionizing development efficiency for programmers of all skill levels. However, the complexity of data structures and algorithmic logic often results in functional deficiencies and security vulnerabilities in generated code, reducing it to a prototype requiring extensive manual debugging. While Retrieval-Augmented Generation (RAG) can enhance correctness and security by leveraging external code manuals, it simultaneously introduces new attack surfaces. In this paper, we pioneer the exploration of attack surfaces in Retrieval-Augmented Code Generation (RACG), focusing on malicious dependency hijacking. We demonstrate how poisoned documentation containing hidden malicious dependencies (e.g., '' matplotlib_safe '') can subvert RACG, exploiting dual trust chains: LLM reliance on RAG and developers' blind trust in LLM suggestions. To construct poisoned documents, we propose  ImportSnare,  a novel attack framework employing two synergistic strategies: 1) Position-aware beam search optimizes hidden ranking sequences to elevate poisoned documents in retrieval results, and 2) Multilingual inductive suggestions generate jailbreaking sequences to manipulate LLMs into recommending malicious dependencies. Through extensive experiments across Python, Rust, and JavaScript,  ImportSnare  achieves significant attack success rates (over 50% for popular libraries such as  matplotlib  and  seaborn ) in general, and is also able to succeed even when the poisoning ratio is as low as 0.01%, targeting both custom and real-world malicious packages. Our findings reveal critical supply chain risks in LLM-powered development, highlighting LLMs' inadequate security alignment for code generation tasks. The project homepage is https://importsnare.github.io/. Disclaimer. This paper contains examples of harmful content. Reader discretion is recommended.}
}


@inproceedings{DBLP:conf/ccs/ThiemtRBSD25,
	author = {Lea Thiemt and
                  Paul R{\"{o}}sler and
                  Alexander Bienstock and
                  Rolfe Schmidt and
                  Yevgeniy Dodis},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Generic Anonymity Wrapper for Messaging Protocols},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {350--364},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765186},
	doi = {10.1145/3719027.3765186},
	timestamp = {Fri, 26 Dec 2025 20:53:01 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/ThiemtRBSD25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Modern messengers use advanced end-to-end encryption protocols to protect message content even if user secrets are ever temporarily exposed. Yet, encryption alone does not prevent user tracking, as protocols often attach metadata, such as sequence numbers, public keys, or even plain user identifiers. This metadata reveals the social network as well as communication patterns between users. Existing protocols that hide metadata in Signal (i.e., Sealed Sender), for MLS-like constructions (Hashimoto et al., CCS 2022), or in mesh networks (Bienstock et al., CCS 2023) are relatively inefficient or specially tailored for only particular settings. Moreover, all existing practical solutions reveal crucial metadata upon exposures of user secrets. In this work, we introduce a formal definition of Anonymity Wrappers (AW) that generically hide metadata of underlying two-party and group messaging protocols. Our definition captures forward and post-compromise anonymity as well as authenticity in the presence of temporary state exposures. Inspired by prior wrapper designs, the idea of our provably secure AW construction is to use shared keys of the underlying wrapped (group) messaging protocols to derive and continuously update symmetric keys for hiding metadata. Beyond hiding metadata on the wire, we also avoid and hide structural metadata in users' local states for stronger anonymity upon their exposure. We implement our construction, evaluate its performance, and provide a detailed comparison with Signal's current approach based on Sealed Sender: Our construction reduces the wire size of small 1:1 messages from 441 bytes to 114 bytes. For a group of 100 members, it reduces the wire size of outgoing group messages from 7240 bytes to 155 bytes. We see similar improvements in computation time for encryption and decryption, but these improvements come with substantial storage costs for receivers. For this reason, we develop extensions with a Bloom filter for compressing the receiver storage. Based on this, Signal considers deploying our solution.}
}


@inproceedings{DBLP:conf/ccs/LiHZ0L0C25,
	author = {Jingyu Li and
                  Zhicong Huang and
                  Min Zhang and
                  Cheng Hong and
                  Jian Liu and
                  Tao Wei and
                  Wenguang Chen},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Panther: Private Approximate Nearest Neighbor Search in the Single
                  Server Setting},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {365--379},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765190},
	doi = {10.1145/3719027.3765190},
	timestamp = {Fri, 26 Dec 2025 20:53:01 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/LiHZ0L0C25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Approximate nearest neighbor search (ANNS), also known as vector search, is an important building block for various applications, such as recommendation systems, biometric authentication, and machine learning. In this work, we are interested in the private ANNS problem, where the client wants to learn (and can only learn) the ANNS results without revealing the query to the server. Previous private ANNS works either suffer from high communication cost (Chen et al., USENIX Security 2020) or work under a stronger security assumption of two non-colluding servers (Servan-Schreiber et al., SP 2022). We present Panther, an efficient private ANNS framework under the single server setting. Panther achieves its high performance via several novel co-designs of private information retrieval, secret-sharing, garbled circuits, and homomorphic encryption. We made extensive experiments using Panther on four public datasets, showing that Panther could answer an ANNS query on 10 million points in 18 seconds with 284 MB of communication. This is more than 7.8× faster and 20× more compact than Chen et al.}
}


@inproceedings{DBLP:conf/ccs/Dahari-GarbianN25,
	author = {Hila Dahari{-}Garbian and
                  Ariel Nof and
                  Luke Parker},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Trout: Two-Round Threshold {ECDSA} from Class Groups},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {380--393},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765192},
	doi = {10.1145/3719027.3765192},
	timestamp = {Fri, 26 Dec 2025 20:53:01 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/Dahari-GarbianN25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We present Trout (Two-ROUnd Threshold), the  first  distributed two-round ECDSA signing protocol for arbitrary thresholds. Trout has constant upload bandwidth per-party and processing time linear in the amount of participants. Moreover, Trout achieves the Identifiable Abort (IA) property, which means that if the protocol cannot terminate due to a failure, parties can attribute the failure to a specific party. We achieve this without a trusted setup. Our protocol relies on linear-homomorphic encryptions and commitments over class groups. To obtain our result, we leverage the recent construction of an exponent-VRF (Boneh et al., Eurocrypt 2025) and a novel protocol to multiply an encrypted value with a committed value and simultaneously decrypt it, which we call ''scaled decryption''. We believe that this protocol may be of independent interest. Our protocol has a very low communication cost of just 6.5 KB sent per party. Furthermore, we implemented our protocol in Rust and provide benchmarks for various configurations, showing its practicality even for 100 parties. Our implementation includes a constant-time variant which, to the best of our knowledge, is the first of its kind for class-group-based threshold ECDSA protocols.}
}


@inproceedings{DBLP:conf/ccs/BenhamoudaCHIKM25,
	author = {Fabrice Benhamouda and
                  Caicai Chen and
                  Shai Halevi and
                  Yuval Ishai and
                  Hugo Krawczyk and
                  Tamer Mour and
                  Tal Rabin and
                  Alon Rosen},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Encrypted Matrix-Vector Products from Secret Dual Codes},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {394--408},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765194},
	doi = {10.1145/3719027.3765194},
	timestamp = {Fri, 26 Dec 2025 20:53:01 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/BenhamoudaCHIKM25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Motivated by applications to efficient secure computation, we consider the following problem of  encrypted matrix-vector product  (EMVP). Let ⅇ be a finite field. In an offline phase, a client uploads an encryption of a matrix  M ∈ ⅇ m xℓ  to a server, keeping only a short secret key. The server stores the encrypted matrix  M . In the online phase, the client may repeatedly send encryptions  q i  of query vectors  q i ∈ ⅇ ℓ , which enables the client and the server to locally compute compact shares of the matrix-vector product  M q i . The server learns nothing about  M  or  q i . The shared output can either be revealed to the client or processed by another protocol. We present efficient EMVP protocols based on variants of the  learning parity with noise  (LPN) assumption and the related  learning subspace with noise  (LSN) assumption. Our EMVP protocols are  field-agnostic  in the sense that the parties only perform arithmetic operations over ⅃, and are close to optimal with respect to both communication and computation. In fact, for sufficiently large ℓ (typically a few hundreds), the online computation and communication costs of our LSN-based EMVP can be  less than twice  the costs of computing  Mq i  in the clear. Combined with suitable secure post-processing protocols on the secret-shared output, our EMVP protocols are useful for a variety of secure computation tasks, including encrypted fuzzy search and secure ML. Our technical approach builds on recent techniques for private information retrieval in the secret-key setting. The core idea is to encode the matrix  M  and the queries  q i  using a pair of secret dual linear codes, while defeating algebraic attacks by adding noise.}
}


@inproceedings{DBLP:conf/ccs/KadianakisZHB25,
	author = {George Kadianakis and
                  Arantxa Zapico and
                  Hossein Hafezi and
                  Benedikt B{\"{u}}nz},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {KZH-Fold: Accountable Voting from Sublinear Accumulation},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {409--422},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744796},
	doi = {10.1145/3719027.3744796},
	timestamp = {Fri, 26 Dec 2025 20:53:01 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/KadianakisZHB25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Accumulation schemes are powerful primitives that enable distributed and incremental verifiable computation with less overhead than recursive SNARKs. However, existing schemes with constant-size accumulation verifiers, suffer from linear-sized accumulators and deciders, leading to linear-sized proofs that are unsuitable in distributed settings. Motivated by the need for bandwidth efficient accountable voting protocols, (I) We introduce KZH, a novel polynomial commitment scheme, and (II) KZH-fold, the first sublinear accumulation scheme with a constant-size verifier (3 group scalar multiplications) and O(n 1/2  ) accumulator size and decider time. Our scheme generalizes to achieve accumulator and decider complexity of k • n 1/k  with a verifier of size  k . Using the BCLMS compiler, (III) we build the first IVC/PCD scheme with sublinear proof and decider. (IV) Next, we propose a new approach to non-uniform IVC, where the cost of proving a step is proportional to the maximum size of all instruction circuits, and unlike previous approaches, the witness size is not linear in the number of instructions. (V) Leveraging these advancements, we demonstrate the power of KZH-fold by implementing an accountable voting scheme using a novel signature aggregation protocol supporting millions of nodes, significantly reducing communication overhead and verifier time compared to BLS-based aggregation. We implemented and benchmarked our protocols, and KZH-fold achieves a 2000x reduction in communication and a 50x improvement in decider time over Nova when proving 2000 Poseidon hashes, at the cost of 3x the prover time.}
}


@inproceedings{DBLP:conf/ccs/CritesKKS25,
	author = {Elizabeth C. Crites and
                  Aggelos Kiayias and
                  Markulf Kohlweiss and
                  Amirreza Sarencheh},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {SyRA: Sybil-Resilient Anonymous Signatures with Applications to Decentralized
                  Identity},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {423--437},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744806},
	doi = {10.1145/3719027.3744806},
	timestamp = {Fri, 26 Dec 2025 20:53:01 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/CritesKKS25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We study Sybil-Resilient Anonymous (SyRA) signatures, a cryptographic primitive that enables credentialed users to generate, on demand, unlinkable pseudonyms tied to any given context, and issue signatures on behalf of these pseudonyms. Concretely, SyRA allows a distributed issuer to turn any legacy identity or personhood identifier, possibly of low entropy, into a unique associated cryptographic key of high pseudoentropy, for use in generating signatures for any given context. Sybil-resilient anonymous signatures achieve three main objectives: 1)  Sybil resilience : every user is entitled to at most one digital identity, 2)  anonymity : no information about the user's real identity is leaked, and 3)  non-interactive context switching : users can create on their own at most one credential for any given context in a manner that is unlinkable across contexts. We conceptualize the SyRA primitive as an ideal functionality in the Universal Composition (UC) setting and put forth SASSI, an efficient, pairing-based construction that realizes it by utilizing two levels of verifiable random functions (VRFs), a design which may be of independent interest. The first level consists of threshold VRF issuance of a user's unique secret key tied to their real-world identifier. The second level allows a user to create signatures for each context, under a unique pseudonym per context. Compared to prior cryptographic tools capable of realizing SyRA, SASSI has the unique feature that issuers are  stateless  and hence do not need to retain any information about past user interactions, a relevant property for a decentralized implementation. We overview various applications of SASSI in multiparty systems, such as cryptocurrency account management and airdrops, e-voting (e.g., for decentralized governance), and privacy-preserving regulatory compliance (e.g., AML/CFT checks). In the context of creating addresses for digital assets, SyRA signatures enable users to embed their legacy identity into their address in a manner that protects their privacy for each application with which they interact. We demonstrate the practicality of SASSI by providing an implementation and performance evaluation of our construction.}
}


@inproceedings{DBLP:conf/ccs/NishimuraTS25,
	author = {Takumi Nishimura and
                  Kazunari Tozawa and
                  Kunihiko Sadakane},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Surpassing the Word Size Limitation of {TFHE} with Noise Calibration},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {438--452},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744808},
	doi = {10.1145/3719027.3744808},
	timestamp = {Fri, 26 Dec 2025 20:53:01 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/NishimuraTS25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Torus fully homomorphic encryption (TFHE) is a promising solution for secure computation, offering low computational cost and simple setup requirements. A key feature of TFHE is programmable bootstrap (PBS), which enables efficient homomorphic evaluation of arbitrary functions over small domains. However, the domain size of PBS is constrained by  the word size limitation of TFHE,  an unavoidable restriction to ensure data security. This limitation raises scalability challenges for extending homomorphic function evaluation to larger domains. Existing approaches attempt to overcome this limitation but suffer from high computational costs. The vertical packing technique (Chillotti et al., 2020) supports function evaluations beyond the word size limitation but depends on circuit bootstrap, a computationally expensive primitive. The tree-based method (Guimarães et al., 2021) avoids using circuit bootstrap but introduces significant computational overhead, requiring  O (2 W ) PBS calls for a  W -bit domain. In this paper, we propose  noise calibration method  that enables homomorphic function evaluation beyond the word size limitation of TFHE. Our approach supports an  exponential expansion  of the function domain size while achieving both low computational complexity and high accuracy. For a  W -bit domain, the proposed method requires a total of only O(W 2 ) PBS calls for homomorphic function evaluation. Experimental results show that when  W  is around 10, the proposed method achieves a performance improvement of about 3 times compared to the vertical packing and 10 times compared to the tree-based method, without loss of accuracy. The main advantage of the noise calibration method is its compatibility with PBS, making it highly adaptable to large-scale applications. We demonstrate its application to oblivious stable sorting for long input arrays. Experiments show that the proposed method outperforms sorting network-based methods by about 4-8 times in speed of the 4-bit array sorting and scales efficiently to array lengths beyond the word size limitation.}
}


@inproceedings{DBLP:conf/ccs/ZhouZHZM25,
	author = {Zibo Zhou and
                  Zongyang Zhang and
                  Feng Hao and
                  Bowen Zheng and
                  Zulkarnaim Masyhur},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {QV-net: Decentralized Self-Tallying Quadratic Voting with Maximal
                  Ballot Secrecy},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {453--467},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744810},
	doi = {10.1145/3719027.3744810},
	timestamp = {Fri, 26 Dec 2025 20:53:01 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/ZhouZHZM25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Decentralized e-voting enables secure and transparent elections without relying on trusted authorities, with blockchain emerging as a popular platform. It has compelling applications in Decentralized Autonomous Organizations (DAOs), where governance relies on voting with blockchain-issued tokens. Quadratic voting (QV), a mechanism that mitigates the dominance of large token holders, has been adopted by many DAO elections to enhance fairness. However, current QV systems deployed in practice publish voters' choices in plaintext with digital signatures. The open nature of all ballots comprises voter privacy, potentially affecting voters' honest participation. Prior research proposes using cryptographic techniques to encrypt QV ballots, but they work in a centralized setting, relying on a trusted group of tallying authorities to administrate an election. However, in DAO voting, there is no trusted third party. In this paper, we propose QV Network (QV-net), the first decentralized quadratic voting scheme, in which voters do not need to trust any third party other than themselves for ballot secrecy. QV-net is self-tallying with maximal ballot secrecy. Self-tallying allows anyone to compute election results once all ballots are cast. Maximal ballot secrecy ensures that what each voter learns from QV-net is nothing more than the tally and their own ballot. We provide an open-source implementation of QV-net to demonstrate its practicality based on real-world DAO voting settings, reporting only a few milliseconds for voting and a maximum of 255 milliseconds for tallying. The exceptional efficiency of QV-net is attributed to the design of two new Zero-Knowledge Argument of Knowledge (ZKAoK) protocols for QV ballot secrecy and integrity. Previous works generally rely on pairing-friendly curves to prove the well-formedness of an encrypted QV ballot. But they incur heavy computation and large data sizes. We tackle the challenges of appropriately formalizing and proving ZKAoK relations for QV without using these curves. Specifically, we develop a succinct ZKAoK to prove a new relation: the sum of squares of a private vector's components equals a private scalar. We also introduce the first aggregated range proof to prove that values committed under different keys fall within their respective ranges. Together, these two new zero-knowledge protocols enable us to build an efficient decentralized QV scheme and are of independent interest.}
}


@inproceedings{DBLP:conf/ccs/0007S0Y25,
	author = {Ya{-}Nan Li and
                  Yaqing Song and
                  Qiang Tang and
                  Moti Yung},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {End-to-End Encrypted Git Services},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {468--482},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744815},
	doi = {10.1145/3719027.3744815},
	timestamp = {Fri, 26 Dec 2025 20:53:01 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/0007S0Y25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Git services such as GitHub, have been widely used to manage projects and enable collaborations among multiple entities. Just as in messaging and cloud storage, where end-to-end security has been gaining increased attention, such a level of security is also demanded for Git services. Content in the repositories (and the data/code supply-chain facilitated by Git services) could be highly valuable, whereas the threat of system breaches has become routine nowadays. However, existing studies of Git security to date (mostly open source projects) suffer in two ways: they provide only very weak security, and they have a large overhead. In this paper, we initiate the needed study of efficient end-to-end encrypted Git services. Specifically, we formally define the syntax and critical security properties, and then propose two constructions that provably meet those properties. Moreover, our constructions have the important property of platform-compatibility: They are compatible with current Git servers and reserve all basic Git operations, thus can be directly tested and deployed on top of existing platforms. Furthermore, the overhead we achieve is only proportional to the actual difference caused by each edit, instead of the whole file (or even the whole repository) as is the case with existing works. We implemented both constructions and tested them directly on several public GitHub repositories. Our evaluations show (1) the effectiveness of platform-compatibility, and (2) the significant efficiency improvement we got (while provably providing much stronger security than prior ad-hoc treatments).}
}


@inproceedings{DBLP:conf/ccs/ZouLS00025,
	author = {Zhenhua Zou and
                  Zhuotao Liu and
                  Jinyong Shan and
                  Qi Li and
                  Ke Xu and
                  Mingwei Xu},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {RingSG: Optimal Secure Vertex-Centric Computation for Collaborative
                  Graph Processing},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {483--497},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744824},
	doi = {10.1145/3719027.3744824},
	timestamp = {Fri, 26 Dec 2025 20:53:01 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/ZouLS00025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Collaborative graph processing refers to the joint analysis of inter-connected graphs held by multiple graph owners. To honor data privacy and support various graph processing algorithms, existing approaches employ secure multi-party computation (MPC) protocols to express the vertex-centric abstraction. Yet, due to certain computation-intensive cryptography constructions, state-of-the-art (SOTA) approaches are asymptotically suboptimal, imposing significant overheads in terms of computation and communication. In this paper, we present RingSG, the first system to attain optimal communication/computation complexity within the MPC-based vertex-centric abstraction for collaborative graph processing. This optimal complexity is attributed to Ring-ScatterGather, a novel computation paradigm that can avoid exceedingly expensive cryptography operations (e.g., oblivious sort), and simultaneously ensure the overall workload can be optimally decomposed into parallelizable and mutually exclusive MPC tasks. Within Ring-ScatterGather, RingSG improves the concrete runtime efficiency by incorporating 3-party secure computation via share conversion, and optimizing the most cost-heavy part using a novel oblivious group aggregation protocol. Finally, unlike prior approaches, we instantiate RingSG into two end-to-end applications to effectively obtain application-specific results from the protocol outputs in a privacy-preserving manner. We developed a prototype of RingSG and extensively evaluated it across various graph collaboration settings, including different graph sizes, numbers of parties, and average vertex degrees. The results show RingSG reduces the system running time of SOTA approaches by up to 15.34× and per-party communication by up to 10.36×. Notably, RingSG excels in processing sparse global graphs collectively held by more parties, consistent with our theoretical cost analysis.}
}


@inproceedings{DBLP:conf/ccs/ShamsabadiSGBH25,
	author = {Ali Shahin Shamsabadi and
                  Peter Snyder and
                  Ralph Giles and
                  Aur{\'{e}}lien Bellet and
                  Hamed Haddadi},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {\emph{Nebula: } Efficient, Private and Accurate Histogram Estimation},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {498--512},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744789},
	doi = {10.1145/3719027.3744789},
	timestamp = {Fri, 26 Dec 2025 20:53:01 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/ShamsabadiSGBH25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We present  Nebula,  a system for differentially private histogram estimation on data distributed among clients.  Nebula  allows clients to independently decide whether to participate in the system, and locally encode their data so that an untrusted server only learns data values whose multiplicity exceeds a predefined aggregation threshold, with (ε,δ) differential privacy guarantees. Compared to existing systems,  Nebula  uniquely achieves:  i)  a strict upper bound on client privacy leakage;  ii)  significantly higher utility than standard local differential privacy systems; and  iii)  no requirement for trusted third-parties, multi-party computation, or trusted hardware. We provide a formal evaluation of  Nebula  's privacy, utility and efficiency guarantees, along with an empirical assessment on three real-world datasets. On the United States Census dataset, clients can submit their data in just 0.0036 seconds and 0.0016 MB ( efficient ), under strong (ε=1,δ=10 -8 ) differential privacy guarantees ( private ), enabling  Nebula 's untrusted aggregation server to estimate histograms with over 88% better utility than existing local differential privacy deployments ( accurate ). Additionally, we describe a variant that allows clients to submit multi-dimensional data, with similar privacy, utility, and performance. Finally, we provide an implementation of  Nebula.}
}


@inproceedings{DBLP:conf/ccs/0001P25,
	author = {Zitao Chen and
                  Karthik Pattabiraman},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Anonymity Unveiled: {A} Practical Framework for Auditing Data Use
                  in Deep Learning Models},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {513--527},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744794},
	doi = {10.1145/3719027.3744794},
	timestamp = {Fri, 26 Dec 2025 20:53:01 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/0001P25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The rise of deep learning (DL) has led to a surging demand for training data, which incentivizes the creators of DL models to trawl through the Internet for training materials. Meanwhile, users often have limited control over whether their data (e.g., facial images) are used to train DL models without their consent, which has engendered pressing concerns. This work proposes  MembershipTracker , a practical data auditing tool that can empower ordinary users to reliably detect the unauthorized use of their data in training DL models. We view data auditing through the lens of membership inference (MI).  MembershipTracker  consists of a lightweight data marking component to mark the target data with small and targeted changes, which can be strongly memorized by the model trained on them; and a specialized MI-based verification process to audit whether the model exhibits strong memorization on the target samples. MembershipTracker  only requires the users to mark a small fraction of data (0.005%∼0.1% in proportion to the training set), and it enables the users to reliably detect the unauthorized use of their data (average 100% TPR@0% FPR). We show that  MembershipTracker  is highly effective across various settings, including industry-scale training on the full-size ImageNet-1k dataset. We finally evaluate  MembershipTracker  under multiple classes of countermeasures. 1Our code is available at https://github.com/DependableSystemsLab/MembershipTracker}
}


@inproceedings{DBLP:conf/ccs/YuenCPYL25,
	author = {Tsz Hon Yuen and
                  Ying{-}Teng Chen and
                  Shimin Pan and
                  Jiangshan Yu and
                  Joseph K. Liu},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Posterior Security: Anonymity and Message Hiding of Standard Signatures},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {528--542},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744797},
	doi = {10.1145/3719027.3744797},
	timestamp = {Fri, 26 Dec 2025 20:53:01 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/YuenCPYL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We introduce  posterior security  of digital signatures, the additional security features  after  the original signature is generated. It is motivated by the scenario that some people store their secret keys in secure hardware and can only obtain a standard signature through a standardized interface. In this paper, we consider two different posterior security features: anonymity and message hiding. We first introduce  incognito signature , a new mechanism to anonymize a standard signature. Different from other ring or group signatures, the signer generates a standard (non-anonymous) signature first. The signature is then anonymized by a converter before sending to the verifier, by hiding the signer public key with a set of decoy public keys. We then introduce  concealed signature  which hides the message in a commitment. The standard signature is converted such that it can be verified with the commitment. The models of  posterior anonymity  and  posterior message hiding  capture the separation of the signer and the converter. Anonymity or message hiding is provided by the converter  after  the creation of a standard signature by the signer. It is useful in applications like two-tier central bank digital currency, where users want to hide their addresses (public keys) and transaction amounts (messages) when the payment is settled in the interbank layer.}
}


@inproceedings{DBLP:conf/ccs/RussoVG25,
	author = {Alejandro Russo and
                  Elisabet Lobo Vesga and
                  Marco Gaboardi},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Accuracy for Differentially Private Quotients by Fractional Uncertainties},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {543--557},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744799},
	doi = {10.1145/3719027.3744799},
	timestamp = {Sun, 07 Dec 2025 22:09:44 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/RussoVG25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Differential Privacy (DP) is a cornerstone for ensuring privacy in data analysis by injecting carefully calibrated noise into statistical queries. While numerous DP tools focus on privacy protection, few provide accuracy information, specially for data-dependent computations like averages or quotients of DP-sums. This paper introduces a novel approach to compute confidence intervals, i.e., α-β accuracy, for these computations, leveraging principles from uncertainty propagation. Our method identifies conditions under which analytical error can be predicted, revealing two key invariants: the analytical error improves with large dataset sizes, and addition of values with higher variability require larger dataset sizes for accurate estimation. To simplify adoption, we also propose accuracy tuners to enable rapid determination of minimum dataset sizes and explore trade-offs between privacy budgets and the possibility to perform accuracy estimations. Our theoretical contributions are validated through an empirical evaluation that explores the applicability of fractional uncertainties for computing concrete α-β error across diverse scenarios.}
}


@inproceedings{DBLP:conf/ccs/CoijanovicHPS25,
	author = {Christoph Coijanovic and
                  Laura Hetz and
                  Kenneth G. Paterson and
                  Thorsten Strufe},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Sabot: Efficient and Strongly Anonymous Bootstrapping of Communication
                  Channels},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {558--572},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744803},
	doi = {10.1145/3719027.3744803},
	timestamp = {Fri, 26 Dec 2025 20:53:01 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/CoijanovicHPS25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Anonymous communication is vital for enabling individuals to participate in social discourse without fear of marginalization or persecution. An important but often overlooked part of anonymous communication is the bootstrapping of new communication channels. If Alice wants to communicate with Bob, she must first learn his in-system identifier. In synchronous designs, message exchange is only possible once both communication partners have agreed to communicate. Thus, Alice must notify Bob of her intent, Bob must learn her in-system identifier, and Bob must acknowledge her notification. This bootstrapping process is generally assumed to occur out-of-band, but if it discloses metadata, communication partners are revealed even if the channel itself is fully anonymized. We propose Sabot, the first anonymous bootstrapping protocol that achieves both strong cryptographic privacy guarantees and bandwidth-efficient communication. In Sabot, clients cooperatively generate a private relationship matrix, which encodes who wants to contact whom. Clients communicate with k ≥ 2 servers to obtain ''their'' part of the matrix and augment the received information using Private Information Retrieval (PIR) to learn about their prospective communication partners. Compared to previous solutions, Sabot achieves stronger privacy guarantees and reduces the bandwidth overhead by an order of magnitude.}
}


@inproceedings{DBLP:conf/ccs/LuL25,
	author = {Zhi Lu and
                  Songfeng Lu},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {{LZKSA:} Lattice-Based Special Zero-Knowledge Proofs for Secure Aggregation's
                  Input Verification},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {573--587},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744812},
	doi = {10.1145/3719027.3744812},
	timestamp = {Sun, 07 Dec 2025 22:09:43 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/LuL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In many fields, the need to securely collect and aggregate data from distributed systems is growing. However, designs that rely solely on encrypted data transmission make it difficult to trace malicious users. To address this challenge, we have enhanced the secure aggregation (SA) protocol proposed by Bell et al. (CCS 2020) by introducing verification features that ensure compliance with user inputs and encryption processes while preserving data privacy. We present LZKSA, a quantum-safe secure aggregation system with input verification. LZKSA employs seven zero-knowledge proof (ZKP) protocols based on the Ring Learning with Errors problem, specifically designed for secure aggregation. These protocols verify whether users have correctly used SA keys and their L ∞ , L 2  norms and cosine similarity of data, meet specified constraints, to exclude malicious users from current and future aggregation processes. The specialized ZKPs we propose significantly enhance proof efficiency. In practical federated learning scenarios, our experimental evaluations demonstrate that the proof generation time for L ∞  and L 2  constraints is reduced to about 10 -3  of that required by the current state-of-the-art method, RoFL (S&P 2023), and ACORN (USENIX 2023). For example, the proof generation/verification time of RoFL, ACORN and LZKSA for L ∞  is 94s/29.9s, 78.7s/33.9s, and 0.02s/0.0062s for CIFAR10, respectively.}
}


@inproceedings{DBLP:conf/ccs/RaymakerKWPC0ZB25,
	author = {Anna Raymaker and
                  Akshaya Kumar and
                  Miuyin Yong Wong and
                  Ryan Pickren and
                  Animesh Chhotaray and
                  Frank Li and
                  Saman A. Zonouz and
                  Raheem Beyah},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {A Sea of Cyber Threats: Maritime Cybersecurity from the Perspective
                  of Mariners},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {588--602},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744816},
	doi = {10.1145/3719027.3744816},
	timestamp = {Fri, 26 Dec 2025 20:53:01 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/RaymakerKWPC0ZB25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Maritime systems, including ships and ports, are critical components of global infrastructure, essential for transporting over 80% of the world's goods and supporting internet connectivity. However, these systems face growing cybersecurity threats, as highlighted by recent attacks disrupting Maersk, one of the world's largest shipping companies, causing widespread impacts on international trade and shipping. The unique challenges of the maritime environment-including diverse operational conditions, extensive physical access points, fragmented regulatory frameworks, and its deeply interconnected, international structure—require maritime-specific cybersecurity research. Despite the sector's critical importance, maritime cybersecurity remains an underexplored area, leaving significant gaps in our understanding of its challenges and risks. To take an early step in addressing these gaps, we investigate how operators of maritime systems perceive and navigate cybersecurity challenges within the complex maritime landscape. We conducted a user study comprising surveys and semi-structured interviews with 21 officer-level mariners. Participants reported direct experiences with shipboard cyber-attacks, including offshore GPS spoofing and logistics-disrupting ransomware, demonstrating the real-world impact of these threats. Despite this, our findings reveal systemic and human-centric issues, such as cybersecurity training that is poorly designed to address the unique challenges of maritime operations, insufficient detection and response solutions, and severe gaps in mariners' understanding of cybersecurity. Our contributions include a detailed categorization of cyber threats identified by mariners, as well as actionable recommendations for improving maritime security, including enhancements to cybersecurity training, attack response protocols, and regulatory frameworks. These insights aim to guide future research and policy to bolster the resilience of maritime systems against evolving cyber threats.}
}


@inproceedings{DBLP:conf/ccs/JiWJ0LW25,
	author = {Zimo Ji and
                  Daoyuan Wu and
                  Wenyuan Jiang and
                  Pingchuan Ma and
                  Zongjie Li and
                  Shuai Wang},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Measuring and Augmenting Large Language Models for Solving Capture-the-Flag
                  Challenges},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {603--617},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744855},
	doi = {10.1145/3719027.3744855},
	timestamp = {Fri, 26 Dec 2025 20:53:01 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/JiWJ0LW25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Capture-the-Flag (CTF) competitions are crucial for cybersecurity education and training. With the evolution of large language models (LLMs), there is growing interest in their ability to automate CTF challenge solving, with DARPA's AIxCC competition (since 2023) being a notable example. However,this demands a combination of multiple abilities of LLMs, from knowledge to reasoning and further to actions. In this paper, we highlight the importance of technical knowledge in solving CTF problems and deliberately construct a focused benchmark, CTFKnow, with 3,992 questions to measure LLMs' performance in this core aspect. Our study offers a focused and innovative measurement of LLMs' capability in understanding CTF knowledge and applying it to solve CTF challenges. Our key findings reveal that while LLMs possess substantial technical knowledge, they struggle to apply it accurately to specific scenarios and adapt based on feedback from CTF environments. Based on insights derived from this measurement study, we propose CTFAgent, a novel LLM-driven framework for advancing CTF problem-solving. CTFAgent introduces two new modules: two-stage Retrieval Augmented Generation (RAG) and interactive Environmental Augmentation, which enhance LLMs' technical knowledge and vulnerability exploitation on CTF, respectively. Experiments on two popular CTF datasets show that CTFAgent both achieves over 80% performance improvement. Moreover, in the picoCTF2024 hosted by CMU, CTFAgent ranked in the top 23.6% of nearly 7,000 participating teams. This reflects the benefit of our measurement study and the potential of our framework in advancing LLMs' capabilities in CTF problem-solving.}
}


@inproceedings{DBLP:conf/ccs/NosykKGMBOTD25,
	author = {Yevheniya Nosyk and
                  Maciej Korczynski and
                  Carlos Ga{\~{n}}{\'{a}}n and
                  Sourena Maroofi and
                  Jan Bayer and
                  Zul Odgerel and
                  Samaneh Tajalizadehkhoob and
                  Andrzej Duda},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Exposing the Roots of {DNS} Abuse: {A} Data-Driven Analysis of Key
                  Factors Behind Phishing Domain Registrations},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {618--632},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744869},
	doi = {10.1145/3719027.3744869},
	timestamp = {Fri, 26 Dec 2025 20:53:01 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/NosykKGMBOTD25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cybercriminals have long depended on domain names for phishing, spam, malware distribution, and botnet operation. To facilitate the malicious activities, they continually register new domain names for exploitation. Previous work revealed an abnormally high concentration of malicious registrations in a handful of registrars and TLDs. However, no existing study systematically analyzed the factors driving abuse, leaving a critical gap in understanding how different variables influence malicious registrations. In this paper, we carefully distill the inclinations and aversions of malicious actors during the registration of new phishing domain names. Having compiled a list of 14.5 k malicious and 15.4 k benign domains, we collect a comprehensive set of 73 features for all the domains encompassing three main latent factors: registration attributes, proactive verification, and reactive security practices. With a GLM regression analysis, we found that each dollar reduction in registration fees corresponds to a 49% increase in malicious domain registrations. The availability of free bundled services, such as web hosting, drives an 88% surge in phishing activities. Conversely, stringent registration restrictions cut down abuse by 63%, while registrars providing API access for domain registration or account creation experience a staggering 401% rise in malicious domains. The results enable intermediaries involved in domain registration to develop tailored anti-abuse practices, yet aligning them with their economic interests.}
}


@inproceedings{DBLP:conf/ccs/BrunkenSBMS25,
	author = {Lina Brunken and
                  Markus Sch{\"{o}}ps and
                  Annalina Buckmann and
                  Florian Mei{\ss}ner and
                  M. Angela Sasse},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Noise and Stress Don't Help With Learning: {A} Qualitative Study to
                  Inform Design of Effective Cybersecurity Awareness in Manufacturing
                  Environments},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {633--647},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744880},
	doi = {10.1145/3719027.3744880},
	timestamp = {Fri, 26 Dec 2025 20:53:01 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/BrunkenSBMS25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With Industry 4.0, cybersecurity risks in manufacturing contexts are increasing rapidly. Since mandatory cybersecurity awareness programs (CAP) are considered best practice, companies looking at adapting training for this group, and allowed us to conduct a study. We conducted semi-structured interviews with  n =33 manufacturing workers in 6 locations, to determine what they knew about cybersecurity risks, to what extent they consider them relevant, and what their experiences with, and perceptions of cybersecurity measures and training were. The interviews were analyzed using qualitative content analysis. Most of our participants reported only occasional interaction with what they consider ''office'' information and communication technology (ICT) in the context of their daily work. For most, the only touchpoints were HR-related transactions (pay and vacation), conducted via shared digital shopfloor kiosk PCs, through which they also received corporate communications. Most participants did not consider cybersecurity their responsibility, associating it with ''office'' and ''management'' roles. Most ICT and cybersecurity as potential threats to ''smooth running'' of work processes and their productivity. At the same time, there was positive perception of safety measures and training, with a clear preference for face-to-face team-based training in situ, so they could ask questions and point out possible issues - very different from the company's idea of individual computer-based trained, which most would receive via shared kiosk PCs on a noisy shop floor. Our results suggest that successful CAP needs to tailor content not only according to relevant risks, but relating those to key values and work practices, and consider different ways of delivering it.}
}


@inproceedings{DBLP:conf/ccs/DengLWZ25,
	author = {Sen Deng and
                  Zhibo Liu and
                  Shuai Wang and
                  Yinqian Zhang},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {An Empirical Study Measuring In-The-Wild Cryptographic Microarchitectural
                  Side-Channel Patches},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {648--662},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744881},
	doi = {10.1145/3719027.3744881},
	timestamp = {Fri, 26 Dec 2025 20:53:02 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/DengLWZ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Patching microarchitectural side channels in real-world cryptographic software is a challenging task that does not always result in efficient and secure patches. Despite the continuous efforts of researchers and developers, the security and performance of microarchitectural side-channel patches have not been comprehensively studied before. To systematically study this patching effort, this paper conducts the first measurement study on in-the-wild side-channel patches, yielding the SideBench dataset comprising 165 patches from three mainstream cryptographic libraries (OpenSSL, WolfSSL, and MbedTLS), and offering an automated analysis tool, SideEval, tailored to analyze side-channel patches through a combination of dynamic taint analysis and static symbolic execution. Our analysis reveals that even among patches written by experienced developers, 25 are insecure, leaving residual side-channel leakages potentially unnoticed by developers for years. Furthermore, some patches rashly issued to fix one microarchitectural side channel may inadvertently open new leakages against other side-channel models. We also observed that patches in different cryptographic libraries, even when fixing the same code pattern, can incur drastically different overheads, varying from 10% to 170%. Additionally, our measurements show that recent rule-based and large language model (LLM)-based automated patching tools are not as secure as expected. We summarize our findings and provide insights for developers to fix side channels securely and efficiently.}
}


@inproceedings{DBLP:conf/ccs/BouwmanEHGE25,
	author = {Xander Bouwman and
                  Aksel Ethembabaoglu and
                  Bart Hermans and
                  Carlos Ga{\~{n}}{\'{a}}n and
                  Michel van Eeten},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Can IOCs Impose Cost? The Effects of Publishing Threat Intelligence
                  on Adversary Behavior},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {663--677},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765026},
	doi = {10.1145/3719027.3765026},
	timestamp = {Fri, 26 Dec 2025 20:53:02 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/BouwmanEHGE25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Exposing intrusion campaigns has become a geopolitical tool, with governments and commercial firms publishing threat intelligence reports about hacking attempts and modus operandi. U.S. government officials have explained this as not just a defensive practice but also as a way to 'impose cost' on attackers by forcing them to develop new infrastructure, tools, and techniques. We empirically examine this claim by analyzing attacker behavior before and after publication of indicators of compromise (IOCs). Using IOC feeds from two leading commercial providers, we matched IOCs against a large dataset of real-world network traffic metadata. This enabled us to generate sightings retroactively, capturing malicious activity up to 150 days before and after publication. Unlike prior work focused on post-publication malicious activity, our method provides a more complete view over time. Our results show that most IOCs point to resources that attackers had already abandoned by publication, limiting their utility for detecting ongoing attacks and undermining the idea of 'imposing costs'. Statistical modeling further reveals that publication status has low explanatory power for sightings, suggesting that confounding variables exist. We also observed a 30-day delay between the peak of threat actor activity and IOC publication for one provider. This study is the first empirical assessment linking threat intelligence publication to attacker behavior, bridging computer science and international relations.}
}


@inproceedings{DBLP:conf/ccs/SunZXCCHJZ25,
	author = {Xieyang Sun and
                  Yuanqing Zheng and
                  Wei Xi and
                  Zuhao Chen and
                  Zhizhen Chen and
                  Han Hao and
                  Zhiping Jiang and
                  Sheng Zhong},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {TEMPEST-LoRa: Cross-Technology Covert Communication},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {678--692},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744817},
	doi = {10.1145/3719027.3744817},
	timestamp = {Fri, 26 Dec 2025 20:53:02 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/SunZXCCHJZ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Electromagnetic (EM) covert channels pose significant threats to computer and communications security in air-gapped networks. Previous works exploit EM radiation from various components ( e.g. , video cables, memory buses, CPUs) to secretly send sensitive information. These approaches typically require the attacker to deploy highly specialized receivers near the victim, which limits their real-world impact. This paper reports a new EM covert channel, TEMPEST-LoRa, that builds on Cross-Technology Covert Communication (CTCC), which could allow attackers to covertly transmit EM-modulated secret data from air-gapped networks to widely deployed operational LoRa receivers from afar. We reveal the potential risk and demonstrate the feasibility of CTCC by tackling practical challenges involved in manipulating video cables to precisely generate the EM leakage that could readily be received by third-party commercial LoRa nodes/gateways. Experiment results show that attackers can reliably decode secret data modulated by the EM leakage from a video cable at a maximum distance of 87.5m or a rate of 21.6 kbps. We note that the secret data transmission can be performed with monitors turned off (therefore covertly).}
}


@inproceedings{DBLP:conf/ccs/LuDMWZ25,
	author = {Hongyi Lu and
                  Yunjie Deng and
                  J. Sukarno Mertoguno and
                  Shuai Wang and
                  Fengwei Zhang},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {{MOLE:} Breaking {GPU} {TEE} with GPU-Embedded {MCU}},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {693--707},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744823},
	doi = {10.1145/3719027.3744823},
	timestamp = {Fri, 26 Dec 2025 20:53:02 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/LuDMWZ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graphics Processing Units (GPUs) are extensively used for applications such as machine learning, scientific computing, and graphics rendering. To protect sensitive data processed by GPUs, Trusted Execution Environments (TEEs) for GPUs have been proposed. GPU TEEs, built with hardware-based isolation primitives, can defend against high-privilege attackers like OS kernels. However, in this paper, we present MOLE, a novel attack that compromises the security of GPU TEEs on Arm Mali GPUs by exploiting the GPU-embedded Microcontroller Unit (MCU). By injecting malicious firmware into the MCU, an attacker can bypass GPU TEEs' security guarantees. We evaluated MOLE with state-of-the-art GPU TEE proposals under multiple real-world attack scenarios, such as in-GPU AES encryption and object detection tasks. Our evaluation shows that MOLE can successfully extract sensitive data or manipulate the computation results of GPU TEEs. We responsibly disclosed our findings to the authors of the affected GPU TEE proposals and received acknowledgments from all of them. Moreover, our findings prompted Arm to enhance the security of its GPU firmware supply chains.}
}


@inproceedings{DBLP:conf/ccs/SetoDACSGG25,
	author = {Alexander Seto and
                  Oytun Kuday Duran and
                  Samy Amer and
                  Jalen Chuang and
                  Stephan van Schaik and
                  Daniel Genkin and
                  Christina Garman},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {WireTap: Breaking Server {SGX} via {DRAM} Bus Interposition},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {708--722},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765204},
	doi = {10.1145/3719027.3765204},
	timestamp = {Fri, 26 Dec 2025 20:53:02 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/SetoDACSGG25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Intel's Software Guard eXtension (SGX) aims to offer strong integrity and confidentiality properties, even in the presence of root-level attackers. However, while Intel clearly indicates that SGX offers no security against attackers with physical access, many current real world SGX deployments are actually done in potentially adversarial environments, where node operators have a financial incentive to subvert computations performed inside SGX enclaves. While the two threat models clearly differ, a common conception is that physical attacks on SGX require expensive laboratory equipment, thus putting them out of reach of hobbyist-level attackers. In this work we challenge this belief, showing how simple memory bus interposition hardware can be constructed cheaply and easily in basic environments, using equipment easily purchased on the internet. We then combine our setup with SGX's recent migration from client CPUs to servers, which resulted in a weaker (and deterministic) memory encryption being used to encrypt the machine's physical memory. Applying our acquisition setup to SGX's attestation enclaves, we are able to extract an SGX attestation key from a machine in fully trusted status. Finally, we study the real world implication of such SGX breaches, by examining how SGX-backed blockchain deployments perform in the presence of these adversaries. As many of these deployments allow any SGX machine in trusted status to perform critical network functionality, we show end-to-end attacks on both confidentiality and integrity guarantees of deployments with multi-million dollar market caps, allowing attackers to disclose confidential transactions or illegitimately obtain transaction rewards.}
}


@inproceedings{DBLP:conf/ccs/ChattopadhyayCG25,
	author = {Twisha Chattopadhyay and
                  Fabricio Ceschin and
                  Marco E. Garza and
                  Dymytriy Zyunkin and
                  Animesh Chhotaray and
                  Aaron P. Stebner and
                  Saman A. Zonouz and
                  Raheem Beyah},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {One Video to Steal Them All: 3D-Printing {IP} Theft through Optical
                  Side-Channels},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {723--737},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744837},
	doi = {10.1145/3719027.3744837},
	timestamp = {Fri, 26 Dec 2025 20:53:02 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/ChattopadhyayCG25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The 3D printing industry is rapidly growing and increasingly adopted across various sectors, including manufacturing, healthcare, and defense. However, the operational setup often involves hazardous environments, necessitating remote monitoring through cameras and other sensors, which opens the door to cyber-based attacks. In this paper, we show that an adversary with access to video recordings of the 3D printing process can reverse-engineer the underlying 3D print instructions. Our model tracks the printer nozzle's movements during the printing process and maps the corresponding trajectory into G-code instructions. Further, it identifies the correct parameters, such as feed rate and extrusion rate, leading us to be able to successfully perform IP theft. To validate the success of IP theft, we design an equivalence checker that quantitatively compares two sets of 3D print instructions, evaluating their similarity in producing objects that are alike in shape, external appearance, and internal structure. Our equivalence checker, unlike other simple distance-based metrics such as normalized mean square error, is rotational as well as translational invariant. This is necessary to capture shifts in the base/start position of the reverse-engineered instructions relative to the actual 3D print instructions that can happen due to different camera positions. Our model achieves an average accuracy of 90.87% and generates 30.20% fewer instructions compared to the current state-of-the-art methods that produce instructions that either lead to faulty or incorrect (in terms of difference in shape and internal structure) 3D prints. Additionally, we use our model to reverse-engineer the 3D print instructions from a video recording and print a fully-functional counterfeit object.}
}


@inproceedings{DBLP:conf/ccs/MaW0WC025,
	author = {Chen Ma and
                  Ningfei Wang and
                  Zhengyu Zhao and
                  Qian Wang and
                  Qi Alfred Chen and
                  Chao Shen},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {ControlLoc: Physical-World Hijacking Attack on Camera-based Perception
                  in Autonomous Driving},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {738--752},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744842},
	doi = {10.1145/3719027.3744842},
	timestamp = {Fri, 26 Dec 2025 20:53:02 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/MaW0WC025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recent research shows that adversarial patches can attack object detectors in camera-based perception for Autonomous Driving (AD). However, camera-based perception includes more than object detection; it also involves Multiple Object Tracking (MOT), which enhances robustness by requiring consistent detection across multiple frames before affecting tracking and thus, driving decisions. This makes attacks on object detection alone less effective. To attack such robust systems, a digital hijacking attack has been proposed, aiming to induce dangerous scenarios such as collisions. However, this attack has limited effectiveness, especially in the physical world. In this paper, we introduce a novel physical-world adversarial patch attack, ControlLoc, which exploits hijacking vulnerabilities in entire AD camera-based perception. ControlLoc utilizes a two-stage process: 1) identifying the optimal patch location and 2) generating the patch to modify the perceived location and shape of objects at that optimal location. Extensive experiments demonstrate the superior performance of ControlLoc, with an average attack success rate of around 98.1% across various AD camera-based perception and datasets, four times higher than that of the best existing method. Furthermore, the physical-world effectiveness of ControlLoc is validated in real vehicle tests under different conditions, such as outdoor lighting, angle, and background, achieving an average ASR of 79%. We also assess AD system-level impact with a production-grade AD simulator. ControlLoc yields a vehicle collision rate of 72.5% and an unnecessary emergency stop rate of 96.3%.}
}


@inproceedings{DBLP:conf/ccs/Pan0ZCZ25,
	author = {Muchen Pan and
                  Yan Meng and
                  Yuxia Zhan and
                  Guoxing Chen and
                  Haojin Zhu},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {PipID: Light-Pupillary Response Based User Authentication for Virtual
                  Reality},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {753--767},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744850},
	doi = {10.1145/3719027.3744850},
	timestamp = {Fri, 26 Dec 2025 20:53:02 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/Pan0ZCZ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {During the use of Virtual Reality (VR) applications such as gaming, education, and military training, sensitive information may be generated or collected by VR sensors, raising user concerns about potential data leakage. This highlights the critical need for effective user authentication to prevent unauthorized access. Existing authentication methods for VR are often either cumbersome (e.g., entering passwords via handheld controllers), reliant on specialized hardware (e.g., iris recognition), or vulnerable to credential replay attacks. In this study, we propose PipID, a lightweight VR authentication approach that leverages commercial off-the-shelf (COTS) eye trackers integrated into VR headsets. PipID is based on the fact that users' pupillary responses to visual stimuli vary uniquely. Thus, by displaying lights of randomly selected colors (i.e., wavelengths) on the VR screen, PipID can utilize pupil diameter responses to these wavelengths as the basis for authentication. For pupil data collected by precision-limited COTS eye trackers, PipID mitigates the impact of unrelated eye movements (e.g., blinks) and leverages pupillary response differences between the left and right eyes to further enhance the granularity of authentication features. Additionally, the randomized sequence of light colors helps prevent replay attacks. We implemented PipID on a COTS VR headset and tested it with 52 participants. Experimental results show that PipID achieves an accuracy of 98.65% and maintains robust performance under various conditions (e.g., keeping 98% and 91% accuracy after 7 and 14 days respectively).}
}


@inproceedings{DBLP:conf/ccs/HeHQC0025,
	author = {Yibo He and
                  Cunjian Huang and
                  Xianmiao Qu and
                  Hongdeng Chen and
                  Wei Yang and
                  Tao Xie},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {RVISmith: Fuzzing Compilers for {RVV} Intrinsics},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {768--782},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744790},
	doi = {10.1145/3719027.3744790},
	timestamp = {Fri, 26 Dec 2025 20:53:02 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/HeHQC0025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Modern processors are equipped with single instruction multiple data (SIMD) instructions for fine-grained data parallelism. Compiler auto-vectorization techniques that target SIMD instructions face performance limitations due to insufficient information available at compile time, requiring programmers to manually manipulate SIMD instructions. SIMD intrinsics, a type of built-in function provided by modern compilers, enable programmers to manipulate SIMD instructions within high-level programming languages. Bugs in compilers for SIMD intrinsics can introduce potential threats to software security, producing unintended calculation results, data loss, program crashes, etc. To detect bugs in compilers for SIMD intrinsics, we propose RVISmith, a randomized fuzzer that generates well-defined C programs that include various invocation sequences of RVV (RISC-V Vector Extension) intrinsics. We design RVISmith to achieve the following objectives: (i) achieving high intrinsic coverage, (ii) improving sequence variety, and (iii) without known undefined behaviors. We implement RVISmith based on the ratified RVV intrinsic specification and evaluate our approach with three modern compilers: GCC, LLVM, and XuanTie. Experimental results show that RVISmith achieves 11.5 times higher intrinsic coverage than the state-of-the-art fuzzer for RVV intrinsics. By differential testing that compares results across different compilers, optimizations, and equivalent programs, we detect and report 13 previously unknown bugs of the three compilers under test to date. Of these bugs, 10 are confirmed and another 3 are fixed by the compiler developers.}
}


@inproceedings{DBLP:conf/ccs/HochrainerIWC25,
	author = {Christoph Hochrainer and
                  Anastasia Isychev and
                  Valentin W{\"{u}}stholz and
                  Maria Christakis},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Fuzzing Processing Pipelines for Zero-Knowledge Circuits},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {783--797},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744791},
	doi = {10.1145/3719027.3744791},
	timestamp = {Fri, 26 Dec 2025 20:53:02 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/HochrainerIWC25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Zero-knowledge (ZK) protocols have recently found numerous practical applications, such as in authentication, online-voting, and blockchain systems. These protocols are powered by highly complex pipelines that process deterministic programs, called circuits, written in one of many domain-specific programming languages, e.g., Circom, Noir, and others. Logic bugs in circuit-processing pipelines could have catastrophic consequences and cause significant financial and reputational damage. As an example, consider that a logic bug in a ZK pipeline could result in attackers stealing identities or assets. It is, therefore, critical to develop effective techniques for checking their correctness. In this paper, we present the first systematic fuzzing technique for ZK pipelines, which uses metamorphic test oracles to detect critical logic bugs. We have implemented our technique in a tool called Circuzz. We used Circuzz to test four significantly different ZK pipelines and found a total of 16 logic bugs in all pipelines. Due to their critical nature, 15 of our bugs have already been fixed by the pipeline developers.}
}


@inproceedings{DBLP:conf/ccs/Tian0W0PYL025,
	author = {Yunpeng Tian and
                  Feng Dong and
                  Junhai Wang and
                  Mu Zhang and
                  Zhiniang Peng and
                  Zesen Ye and
                  Xiapu Luo and
                  Haoyu Wang},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Error Messages to Fuzzing: Detecting {XPS} Parsing Vulnerabilities
                  in Windows Printing Components},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {798--812},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744807},
	doi = {10.1145/3719027.3744807},
	timestamp = {Fri, 26 Dec 2025 20:53:02 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/Tian0W0PYL025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Windows printing services remain a notable vector for attacks. Previous studies have predominantly targeted vulnerabilities within various control aspects of printing services, such as spooler services and firmware updates. Yet, we contend that an essential aspect of data processing—the document parser within printer drivers—has been overlooked in past research. We present a coverage-based fuzzing system, PrintXPSurge, specifically crafted to detect weaknesses in the XPS printer driver's parsing function. To craft semantically correct XPS files, we leverage a  large language model-assisted repair approach  to automate the creation of semantically correct XPS files that comply with necessary constraints. To ensure our fuzzing process effectively interacts with the XPS printer driver, we develop a  progressive state reconstruction  method that addresses individual dependency requirements across the entire printing service workflow. Furthermore, when a crash is detected, we employ backtracing to confirm its origin in the XPS parser, isolating it from other components in the pipeline. Our evaluation reveals that PrintXPSurge surpasses existing top Windows fuzzers in performance, successfully identifying 102 bugs in 10 drivers from major brands, including  17 zero-day  vulnerabilities confirmed by Microsoft and third-party vendors.}
}


@inproceedings{DBLP:conf/ccs/0006PLQS25,
	author = {Yu Hao and
                  Juefei Pu and
                  Xingyu Li and
                  Zhiyun Qian and
                  Ardalan Amiri Sani},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {SyzSpec: Specification Generation for Linux Kernel Fuzzing via Under-Constrained
                  Symbolic Execution},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {813--826},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744811},
	doi = {10.1145/3719027.3744811},
	timestamp = {Fri, 26 Dec 2025 20:53:02 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/0006PLQS25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Fuzzing has become one of the most effective and widely used techniques for discovering bugs and vulnerabilities, particularly in large-scale and complex programs like operating system kernels. A notable example is the kernel fuzzer syzkaller, which has identified over 6,800 bugs in the Linux kernel, with more than 5,500 already fixed. A crucial reason behind the success of the syzkaller is its collection of syscall descriptions, which are typically provided by human experts. Although some methods exist for automatically generating these syscall descriptions for device drivers, they often fall short when dealing with complex user inputs. These existing methods either lack precision or have a limited analysis scope, resulting in incomplete syscall descriptions. In this paper, we present SyzSpec, a tool designed to address these limitations by performing fully inter- procedural under- constrained symbolic execution on syscall handler functions. This approach enables SyzSpec to explore all possible user inputs and generate syscall descriptions with more precision. The primary innovation in SyzSpec is a novel method to improve symbolic pointer reasoning in under-constrained symbolic execution, working along with the under-under-constrained memory object (UCMO). We compared SyzSpec with existing automated solutions and manually written syscall descriptions from syzkaller. Our results demonstrate that SyzSpec achieves better coverage than other automated tools and offers coverage comparable to that of manually written syscall descriptions. Additionally, we evaluated SyzSpec on the latest stable version of the Linux kernel (v6.10) and identified 86 unique and previously unknown crashes across 11 different categories.}
}


@inproceedings{DBLP:conf/ccs/ShuiZWXS25,
	author = {Bing Shui and
                  Yufan Zhou and
                  Jielun Wu and
                  Baowen Xu and
                  Qingkai Shi},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Validating Interior Gateway Routing Protocols via Equivalent Topology
                  Synthesis},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {827--841},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744826},
	doi = {10.1145/3719027.3744826},
	timestamp = {Fri, 26 Dec 2025 20:53:02 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/ShuiZWXS25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Routers, relying on routing protocols to determine how data packets travel across the Internet, serve as the backbone of modern networks. Vulnerable routing protocols can lead to serious consequences, including data leaks and network congestion. This work focuses on validating the implementation of a key class of routing protocols known as Interior Gateway Protocols (IGPs). Unlike communication protocols such as TCP/IP, which define structured data packets and state machines to facilitate communication, IGPs are designed to automatically manage the network topology. Thus, conventional techniques, which primarily focus on communication correctness, cannot be applied directly to IGPs. We propose ToDiff, a differential validation technique to uncover IGP bugs in three steps: (1) it uses a network generation algorithm to create random yet valid IGP networks, (2) it applies a semantics-guided program synthesizer to generate equivalent topological programs, and (3) it simulates the network via the equivalent topological programs, with any discrepancies suggesting the presence of a potential bug. We have evaluated ToDiff on the implementation of two common IGP protocols, OSPF and IS-IS. The results demonstrate that ToDiff outperforms existing approaches. To date, our tool has successfully identified 26 bugs, all confirmed or fixed by developers.}
}


@inproceedings{DBLP:conf/ccs/WangSL0ZT25,
	author = {Peicheng Wang and
                  Monika Santra and
                  Mingyu Liu and
                  Cong Sun and
                  Dongrui Zeng and
                  Gang Tan},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Disa: Accurate Learning-based Static Disassembly with Attentions},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {843--857},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744828},
	doi = {10.1145/3719027.3744828},
	timestamp = {Fri, 26 Dec 2025 20:53:02 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/WangSL0ZT25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {For reverse engineering related security domains, such as vulnerability detection, malware analysis, and binary hardening, disassembly is crucial yet challenging. The fundamental challenge of disassembly is to identify instruction and function boundaries. Classic approaches rely on file-format assumptions and architecture-specific heuristics to guess the boundaries, resulting in incomplete and incorrect disassembly, especially when the binary is obfuscated. Recent advancements of disassembly have demonstrated that deep learning can improve both the accuracy and efficiency of disassembly. In this paper, we propose Disa, a new learning-based disassembly approach that uses the information of superset instructions over the multi-head self-attention to learn the instructions' correlations, thus being able to infer function entry-points and instruction boundaries. Disa can further identify instructions relevant to memory block boundaries to facilitate an advanced block-memory model based value-set analysis for an accurate control flow graph (CFG) generation. Our experiments show that Disa outperforms prior deep-learning disassembly approaches in function entry-point identification, especially achieving 9.1% and 13.2% F1-score improvement on binaries respectively obfuscated by the disassembly desynchronization technique and popular source-level obfuscator. By achieving an 18.5% improvement in the memory block precision, Disa generates more accurate CFGs with a 4.4% reduction in Average Indirect Call Targets (AICT) compared with the state-of-the-art heuristic-based approach.}
}


@inproceedings{DBLP:conf/ccs/XieTAF0J25,
	author = {Min Xie and
                  Zhengzhou Tu and
                  Man Ho Au and
                  Junbin Fang and
                  Xuan Wang and
                  Zoe Lin Jiang},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Efficient Constant-Size Linkable Ring Signatures for Ad-Hoc Rings
                  via Pairing-Based Set Membership Arguments},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {858--872},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744830},
	doi = {10.1145/3719027.3744830},
	timestamp = {Fri, 26 Dec 2025 20:53:02 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/XieTAF0J25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Linkable Ring Signatures (LRS) allow users to anonymously sign messages on behalf of ad-hoc rings, while ensuring that multiple signatures from the same user can be linked. This feature makes LRS widely used in privacy-preserving applications like e-voting and e-cash. To scale to systems with large user groups, efficient schemes with short signatures and fast verification are essential. Recent works, such as DualDory (ESORICS'22) and LLRing (ESORICS'24), improve verification efficiency through offline precomputations but rely on static rings, limiting their applicability in ad-hoc ring scenarios. Similarly, constant-size ring signature schemes based on accumulators face the same limitation. In this paper, we propose a framework for constructing constant-size LRS suitable for large ad-hoc rings. We introduce a novel pairing-based Set Membership Argument (SMA) with a proof size of only three group elements. By leveraging KZG polynomial commitments, we optimize the verification to require only constant group exponentiations and pairings, as well as linear field multiplications. Utilizing the SMA, our framework achieves constant-size signatures with verification dominated by linear field operations, outperforming existing schemes that require linear group exponentiations in ad-hoc ring settings. Moreover, it exhibits strong scalability: (i) compatibility with any PKI-based cryptosystem and (ii) scoped linkability, enabling flexible definitions of linking scope. We instantiate our framework using a discrete logarithm public key structure. On the BN254 curve, our signature size is fixed at 687 bytes, which to our best knowledge is the shortest LRS for ring sizes larger than 32. For a ring size of 1024, our verification cost is only 10.4 ms, achieving 48.6×, 2.6×–467×, 7.9×–13.2×, and 2.2×–102.5× improvements over Omniring (CCS'19), DualDory (with and without precomputation), LLRing-DL (with and without precomputation), and LLRing-P (with and without precomputation), respectively. Moreover, this performance gap continues to grow as the ring size increases.}
}


@inproceedings{DBLP:conf/ccs/NagyTSL25,
	author = {{\'{A}}bel Nagy and
                  J{\'{a}}nos Tapolcai and
                  Istv{\'{a}}n Andr{\'{a}}s Seres and
                  Bence Lad{\'{o}}czki},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Forking the {RANDAO:} Manipulating Ethereum's Distributed Randomness
                  Beacon},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {873--887},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744852},
	doi = {10.1145/3719027.3744852},
	timestamp = {Fri, 26 Dec 2025 20:53:02 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/NagyTSL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Proof-of-stake consensus protocols often rely on distributed randomness beacons (DRBs) to generate randomness for leader selection. This work analyses the manipulability of Ethereum's DRB implementation, RANDAO, in its current consensus mechanism. Even with its efficiency, RANDAO remains vulnerable to manipulation through the deliberate omission of blocks from the canonical chain. Previous research has shown that economically rational players can withhold blocks known as a block withholding attack or selfish mixing when the manipulated RANDAO outcome yields greater financial rewards. We introduce and evaluate a new manipulation strategy, the RANDAO forking attack. Unlike block withholding, whereby validators opt to hide a block, this strategy relies on selectively forking out an honest proposer's block to maximise transaction fee revenues and block rewards. In this paper, we draw attention to the fact that the forking attack is significantly more harmful than selfish mixing for two reasons. Firstly, it exacerbates the unfairness among validators. More importantly, it significantly undermines the reliability of the blockchain for the average user by frequently causing already published blocks to be forked out. By doing so, the attacker can fork the chain without losing slots, and we demonstrate that these are later fully compensated for. Our empirical measurements, investigating such manipulations on Ethereum mainnet, revealed no statistically significant traces of these attacks to date.}
}


@inproceedings{DBLP:conf/ccs/MillerPDAL25,
	author = {Lo{\"{\i}}c Miller and
                  Dorian Pacaud and
                  Nathan{\"{e}}l Derousseaux{-}Lebert and
                  Emmanuelle Anceaume and
                  Romaric Ludinard},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Mining in Logarithmic Space with Variable Difficulty},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {888--902},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744874},
	doi = {10.1145/3719027.3744874},
	timestamp = {Fri, 26 Dec 2025 20:53:02 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/MillerPDAL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper presents the first non-interactive, succinct, and secure representation of a PoW-based blockchain that operates under variable mining difficulty while satisfying both completeness and onlineness properties. Completeness ensures that provers can update an existing NIPoPoW by incorporating a newly mined block, whereas onlineness ensures that miners can extend the chain directly from a NIPoPoW. The time complexity for both the prover (to update a NIPoPoW with a new block) and the verifier is logarithmic in the number of blocks of the underlying PoW blockchain. The communication complexity required for synchronization is polylogarithmic in the length of the blockchain. We prove the correctness of our scheme in the presence of a 1/3-bounded PPT adversary.}
}


@inproceedings{DBLP:conf/ccs/SarencheANP25,
	author = {Roozbeh Sarenche and
                  Alireza Aghabagherloo and
                  Svetla Nikova and
                  Bart Preneel},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Bitcoin Under Volatile Block Rewards: How Mempool Statistics Can Influence
                  Bitcoin Mining},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {903--917},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744875},
	doi = {10.1145/3719027.3744875},
	timestamp = {Sun, 07 Dec 2025 22:09:44 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/SarencheANP25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The security of Bitcoin protocols is deeply dependent on the incentives provided to miners, which come from a combination of block rewards and transaction fees. As Bitcoin experiences more halving events, the protocol reward converges to zero, making transaction fees the primary source of miner rewards. This shift in Bitcoin's incentivization mechanism, which introduces volatility into block rewards, leads to the emergence of new security threats or intensifies existing ones. Previous security analyses of Bitcoin have either considered a fixed block reward model or a highly simplified volatile model, overlooking the complexities of Bitcoin's mempool behavior. In this paper, we present a reinforcement learning-based tool for analyzing mining strategies under a more realistic volatile reward model. The tool leverages the Asynchronous Advantage Actor-Critic (A3C) algorithm to derive near-optimal strategies while interacting with an environment that simulates the behavior of the Bitcoin mempool during any specified period, enabling analysis based on actual historical patterns. It supports the evaluation of adversarial mining strategies, such as selfish mining and undercutting, both before and after the difficulty adjustment, offering insights into the effects of mining attacks in both the short and long term. We revisit the Bitcoin security threshold presented in the WeRLman paper and demonstrate that the implicit predictability of valuable transaction arrivals in this model leads to an underestimation of the reported threshold. Additionally, we show that, while adversarial strategies like selfish mining under the fixed reward model incur an initial loss period of at least two weeks, the transition toward a transaction-fee era incentivizes mining pools to abandon honest mining for immediate profits. This incentive is expected to become more significant as the protocol reward approaches zero in the future.}
}


@inproceedings{DBLP:conf/ccs/ParkYNMK25,
	author = {Eunchan Park and
                  Taeung Yoon and
                  Hocheol Nam and
                  Deepak Maram and
                  Min Suk Kang},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {On Frontrunning Risks in Batch-Order Fair Systems for Blockchains},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {918--932},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744879},
	doi = {10.1145/3719027.3744879},
	timestamp = {Fri, 26 Dec 2025 20:53:02 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/ParkYNMK25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In timing-sensitive blockchain applications, such as decentralized finance (DeFi), achieving first-come-first-served (FCFS) transaction ordering among decentralized nodes is critical to prevent frontrunning attacks. Themis [CCS'23], a state-of-the-art decentralized FCFS ordering system, has become a key reference point for high-throughput fair ordering systems for real-world blockchain applications, such as rollup chains and decentralized sequencing, and has influenced the design of several subsequent proposals. In this paper, we critically analyze its core system property of practical batch-order fairness and evaluate the frontrunning resistance claim of Themis. We present the Ambush attack, a new frontrunning technique that achieves nearly 100% success against the practical batch-order fair system with only a single malicious node and negligible attack costs. This attack causes a subtle temporary information asymmetry among nodes, which is allowed due to the heavily optimized communication model of the system. A fundamental trade-off we identify is a challenge in balancing security and performance in these systems; namely, enforcing timely dissemination of transaction information among nodes (to mitigate frontrunning) can easily lead to non-negligible network overheads (thus, degrading overall throughput performance). We show that it is yet possible to balance these two by delaying transaction dissemination to a certain tolerable level for frontrunning mitigation while maintaining high throughput. Our evaluation demonstrates that the proposed delayed gossiping mechanism can be seamlessly integrated into existing systems with only minimal changes.}
}


@inproceedings{DBLP:conf/ccs/Bar-OnZBCES25,
	author = {Yogev Bar{-}On and
                  Roi Bar Zur and
                  Omer Ben{-}Porat and
                  Nimrod Cohen and
                  Ittay Eyal and
                  Matan Sitbon},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Aegis: Tethering a Blockchain with Primary-Chain Stake},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {933--947},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744885},
	doi = {10.1145/3719027.3744885},
	timestamp = {Fri, 26 Dec 2025 20:53:02 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/Bar-OnZBCES25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Blockchains implement decentralized monetary systems and applications. Recent advancements enable what we call tethering a blockchain to a primary blockchain, securing the tethered chain by nodes that post primary-chain tokens as collateral. The collateral ensures nodes behave as intended, until they withdraw it. Unlike a Proof of Stake blockchain which uses its own token as collateral, using primary-chain tokens shields the tethered chain from the volatility of its own token. State-of-the-art tethered blockchains either rely on centralization, or make extreme assumptions: that all communication is synchronous, that operators remain correct even post-withdrawal, or that withdrawals can be indefinitely delayed by tethered-chain failures. We prove that with partial synchrony, there is no solution to the problem. However, under the standard assumptions that communication with the primary chain is synchronous and communication among the tethered chain nodes is partially synchronous, there is a solution. We present a tethered-chain protocol called Aegis. Aegis uses references from its blocks to primary blocks to define committees, checkpoints on the primary chain to perpetuate decisions, and resets to establish new committees when previous ones become obsolete. It ensures safety at all times and rapid progress when latency among Aegis nodes is low.}
}


@inproceedings{DBLP:conf/ccs/JiangY00MS0025,
	author = {Yanna Jiang and
                  Guangsheng Yu and
                  Qin Wang and
                  Xu Wang and
                  Baihe Ma and
                  Caijun Sun and
                  Wei Ni and
                  Ren Ping Liu},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Split Unlearning},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {948--962},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744787},
	doi = {10.1145/3719027.3744787},
	timestamp = {Fri, 26 Dec 2025 20:53:02 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/JiangY00MS0025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We introduce Split Unlearning, a novel machine unlearning technology designed for Split Learning (SL), enabling the first-ever implementation of Sharded, Isolated, Sliced, and Aggregated (SISA) unlearning in SL frameworks. Particularly, the tight coupling between clients and the server in existing SL frameworks results in frequent bidirectional data flows and iterative training across all clients, violating the ''Isolated'' principle and making them struggle to implement SISA for independent and efficient unlearning. To address this, we propose SplitWiper with a new one-way-one-off propagation scheme, which leverages the inherently ''Sharded'' structure of SL and decouples neural signal propagation between clients and the server, enabling effective SISA unlearning even in scenarios with absent clients. We further design SplitWiper+ to enhance client label privacy, which integrates differential privacy and label expansion strategy to defend the privacy of client labels against the server and other potential adversaries. Experiments across diverse data distributions and tasks demonstrate that SplitWiper achieves 0% accuracy for unlearned labels, and 8% better accuracy for retained labels than non-SISA unlearning in SL. Moreover, the one-way-one-off propagation maintains constant overhead, reducing computational and communication costs by 99%. SplitWiper+ preserves 90% of label privacy when sharing masked labels with the server.}
}


@inproceedings{DBLP:conf/ccs/QiaoF0000025,
	author = {Wei Qiao and
                  Yebo Feng and
                  Teng Li and
                  Zhuo Ma and
                  Yulong Shen and
                  Jianfeng Ma and
                  Yang Liu},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Slot: Provenance-Driven {APT} Detection through Graph Reinforcement
                  Learning},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {963--977},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744788},
	doi = {10.1145/3719027.3744788},
	timestamp = {Fri, 26 Dec 2025 20:53:02 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/QiaoF0000025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Advanced Persistent Threats (APTs) represent sophisticated cyberattacks characterized by their ability to remain undetected within the victim system for extended periods, aiming to exfiltrate sensitive data or disrupt operations. Existing detection approaches often struggle to effectively identify these complex threats, construct the attack chain for defense facilitation, or resist adversarial attacks. To overcome these challenges, we propose  Slot , an advanced APT detection approach based on provenance graphs and graph reinforcement learning.  Slot  excels in uncovering multi-level hidden relationships, such as causal, contextual, and indirect connections, among system behaviors through provenance graph mining.  Slot  implements semi-supervised learning with limited labels through efficient label similarity computation, significantly enhancing both detection performance and model robustness. By pioneering the integration of graph reinforcement learning,  Slot  dynamically adapts to new user activities and evolving attack strategies, enhancing its resilience against adversarial attacks. Additionally,  Slot  automatically constructs the attack chain according to detected attacks with clustering algorithms, providing precise identification of attack paths and facilitating the development of defense strategies. Evaluations with real-world datasets demonstrate Slot's outstanding accuracy, efficiency, adaptability, and robustness in APT detection, with most metrics surpassing state-of-the-art methods. Additionally, case studies conducted to assess  Slot 's effectiveness in supporting APT defense further establish it as a practical and reliable tool for cybersecurity protection.}
}


@inproceedings{DBLP:conf/ccs/HeLQ0025,
	author = {Yiling He and
                  Junchi Lei and
                  Zhan Qin and
                  Kui Ren and
                  Chun Chen},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Combating Concept Drift with Explanatory Detection and Adaptation
                  for Android Malware Classification},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {978--992},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744792},
	doi = {10.1145/3719027.3744792},
	timestamp = {Fri, 26 Dec 2025 20:53:02 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/HeLQ0025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Machine learning-based Android malware classifiers struggle with concept drift: the rapid evolution of malware, especially with new families, can depress classification accuracy to near-random levels. Previous research has largely centered on detecting drift samples, with expert-led label revisions on these samples to guide model retraining. However, these methods often lack a comprehensive understanding of malware concepts and provide limited guidance for effective drift adaptation, leading to high human labeling costs. To combat concept drift, we propose  DREAM  a novel system that establishes an explanatory drift detection and adaptation process. Our core idea is to integrate classifier and expert knowledge within a unified model. To achieve this, we embed malware behavioral concepts within the latent space of a contrastive autoencoder, while constraining sample reconstruction based on classifier predictions. This approach enhances retraining in two key ways: 1) capturing the target classifier's characteristics to select more effective samples in detection and 2) enabling concept revisions that extend the classifier's semantics to provide explainable guidance for adaptation. Additionally,  Dream  eliminates reliance on training data during real-time drift detection and provides a behavior-based explainer to support concept revision. Our evaluation shows that  Dream  effectively improves the drift detection accuracy and reduces the expert analysis effort in adaptation across different malware datasets and classifiers. Notably, when updating a widely-used  Drebin  classifier,  Dream  achieves the same accuracy with 76.6% fewer newly labeled samples compared to the best existing methods.}
}


@inproceedings{DBLP:conf/ccs/Liu0ZZCN25,
	author = {Renyang Liu and
                  Wenjie Feng and
                  Tianwei Zhang and
                  Wei Zhou and
                  Xueqi Cheng and
                  See{-}Kiong Ng},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Rethinking Machine Unlearning in Image Generation Models},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {993--1007},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744793},
	doi = {10.1145/3719027.3744793},
	timestamp = {Fri, 26 Dec 2025 20:53:02 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/Liu0ZZCN25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the surge and widespread application of image generation models, data privacy and content safety have become major concerns and attracted great attention from users, service providers, and policymakers. Machine unlearning (MU) is recognized as a cost effective and promising means to address these challenges. Despite some advancements, image generation model unlearning (IGMU) still faces remarkable gaps in practice, e.g., unclear task discrimination and unlearning guidelines, lack of an effective evaluation framework, and unreliable evaluation metrics. These can hinder the understanding of unlearning mechanisms and the design of practical unlearning algorithms. We perform exhaustive assessments over existing state-of-the-art unlearning algorithms and evaluation standards, and discover several critical flaws and challenges in IGMU tasks. Driven by these limitations, we make several core contributions, to facilitate the comprehensive understanding, standardized categorization, and reliable evaluation of IGMU. Specifically, (1) We design CatIGMU, a novel hierarchical task categorization framework. It provides detailed implementation guidance for IGMU, assisting in the design of unlearning algorithms and the construction of testbeds. (2) We introduce EvalIGMU, a comprehensive evaluation framework. It includes reliable quantitative metrics across five critical aspects. (3) We construct DataIGM, a high-quality unlearning dataset, which can be used for extensive evaluations of IGMU, training content detectors for judgment, and benchmarking the state-of-the-art unlearning algorithms. With EvalIGMU and DataIGM, we discover that most existing IGMU algorithms cannot handle the unlearning well across different evaluation dimensions, especially for preservation and robustness. Data, source code, and models are available at https://github.com/ryliu68/IGMU.}
}


@inproceedings{DBLP:conf/ccs/0006JL0T0025,
	author = {Tong Sun and
                  Bowen Jiang and
                  Hailong Lin and
                  Borui Li and
                  Yixiao Teng and
                  Yi Gao and
                  Wei Dong},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {TensorShield: Safeguarding On-Device Inference by Shielding Critical
                  {DNN} Tensors with {TEE}},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {1008--1022},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744798},
	doi = {10.1145/3719027.3744798},
	timestamp = {Fri, 26 Dec 2025 20:53:02 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/0006JL0T0025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {To safeguard user data privacy, on-device inference has emerged as a prominent paradigm on mobile and Internet of Things (IoT) devices. This paradigm involves deploying a model provided by a third party on local devices to perform inference tasks. However, it exposes the private model to two primary security threats: model stealing (MS) and membership inference attacks (MIA). To mitigate these risks, existing wisdom deploys models within Trusted Execution Environments (TEEs), which is a secure isolated execution space. Nonetheless, the constrained secure memory capacity in TEEs makes it challenging to achieve full model security with low inference latency. This paper fills the gap with  TensorShield,  the first efficient on-device inference work that shields partial tensors of the model while still fully defending against MS and MIA. The key enabling techniques in TensorShield include: (i) a novel eXplainable AI (XAI) technique exploits the model's attention transition to assess critical tensors and shields them in TEE to achieve secure inference, and (ii) two meticulous designs with critical feature identification and latency-aware placement to accelerate inference while maintaining security. Extensive evaluations show that TensorShield delivers almost the same security protection as shielding the entire model inside TEE, while being up to 25.35× (avg. 5.85×) faster than the state-of-the-art work, without accuracy loss.}
}


@inproceedings{DBLP:conf/ccs/HailemariamE25,
	author = {Philemon Hailemariam and
                  Birhanu Eshete},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {PoisonSpot: Precise Spotting of Clean-Label Backdoors via Fine-Grained
                  Training Provenance Tracking},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {1023--1037},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744802},
	doi = {10.1145/3719027.3744802},
	timestamp = {Fri, 26 Dec 2025 20:53:02 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/HailemariamE25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Relying on untrusted data exposes machine learning models to backdoor attacks, where adversaries poison training data to embed hidden behaviors. Existing defenses struggle against increasingly stealthy attacks, particularly clean-label backdoor attacks, due to their inability to monitor fine-grained impact of individual training samples on model updates. In this paper, we present PoisonSpot, a novel system that precisely detects clean-label backdoor attacks by using  fine-grained training provenance tracking , inspired by dynamic taint tracking. PoisonSpot captures and analyzes the impact of individual training samples on model parameter updates throughout the training process. By attributing poisoning scores to suspect samples based on their impact lineage, PoisonSpot allows for accurate identification and rejection of samples carrying backdoor triggers. We evaluate PoisonSpot on multiple benchmark datasets and attack scenarios, demonstrating its superior performance compared to the state-of-the-art clean-label backdoor poisoning defense. PoisonSpot consistently achieves high true positive rates, low false positive rates, and effectively mitigates backdoor attacks, even under adaptive adversarial strategies. Furthermore, PoisonSpot operates efficiently in various training settings, including retraining and fine-tuning regimes, demonstrating its robustness and scalability.}
}


@inproceedings{DBLP:conf/ccs/DavidsonDT25,
	author = {Alex Davidson and
                  Amit Deo and
                  Louis Tremblay Thibault},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Pool: {A} Practical OT-based {OPRF} from Learning with Rounding},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {1038--1052},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765054},
	doi = {10.1145/3719027.3765054},
	timestamp = {Fri, 26 Dec 2025 20:53:02 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/DavidsonDT25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We propose Pool: a conceptually simple post-quantum (PQ) oblivious pseudorandom function (OPRF) protocol, that is round-optimal (with input-independent preprocessing), practically efficient, and has security based on the well-understood hardness of the learning with rounding (LWR) problem. Specifically, our design permits oblivious computation of the LWR-based pseudorandom function  F sk ( x ) = ⌉  H ( x ) ⊤  ⋅  sk ⌋ q,p , for random oracle  H : {0,1}  *  → ℤ  q n  and uniformly chosen  sk ∈ {0,1}  n . For 128-bits of semi-honest security, the Pool OPRF has an online communication cost of 11.9 kB, and a computational runtime of less than 3 ms on a single thread (via an open-source software implementation). This is more efficient (in either online communication cost or runtime) than constructions from well-known PQ PRFs, and is competitive even with constructions that only  conjecture  PQ security on lesser-known assumptions. As a result, our design gives high-performance, post-quantum variants of established OPRF applications in multi-party computation and private set operation protocols.}
}


@inproceedings{DBLP:conf/ccs/RiasiWBVH25,
	author = {Arman Riasi and
                  Haodi Wang and
                  Rouzbeh Behnia and
                  Viet Vo and
                  Thang Hoang},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Zero-Knowledge {AI} Inference with High Precision},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {1053--1067},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765056},
	doi = {10.1145/3719027.3765056},
	timestamp = {Fri, 26 Dec 2025 20:53:02 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/RiasiWBVH25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Artificial Intelligence as a Service (AIaaS) enables users to query a model hosted by a service provider and receive inference results from a pre-trained model. Although AIaaS makes artificial intelligence more accessible, particularly for resource-limited users, it also raises verifiability and privacy concerns for the client and server, respectively. While zero-knowledge proof techniques can address these concerns simultaneously, they incur high proving costs due to the non-linear operations involved in AI inference and suffer from precision loss because they rely on fixed-point representations to model real numbers. In this work, we present ZIP, an efficient and precise commit and prove zero-knowledge SNARK for AIaaS inference (both linear and non-linear layers) that natively supports IEEE-754 double-precision floating-point semantics while addressing reliability and privacy challenges inherent in AIaaS. At its core, ZIP introduces a novel relative-error-driven technique that efficiently proves the correctness of complex non-linear layers in AI inference computations without any loss of precision, and hardens existing lookup-table and range proofs with novel arithmetic constraints to defend against malicious provers. We implement ZIP and evaluate it on standard datasets (e.g., MNIST, UTKFace, and SST-2). Our experimental results show, for non-linear activation functions, ZIP reduces circuit size by up to three orders of magnitude while maintaining the full precision required by modern AI workloads.}
}


@inproceedings{DBLP:conf/ccs/MaFGDJ0SC25,
	author = {Xirong Ma and
                  Junling Fang and
                  Chunpeng Ge and
                  Dung Hoang Duong and
                  Yali Jiang and
                  Yanbin Li and
                  Willy Susilo and
                  Lizhen Cui},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {New Permutation Decomposition Techniques for Efficient Homomorphic
                  Permutation},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {1068--1082},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765078},
	doi = {10.1145/3719027.3765078},
	timestamp = {Tue, 27 Jan 2026 19:58:09 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/MaFGDJ0SC25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Homomorphic permutation is fundamental to privacy-preserving computations based on batch-encoding homomorphic encryption. It underpins nearly all homomorphic matrix operations and predominantly influences their complexity. Permutation decomposition as a potential approach to optimize this critical component remains underexplored. In this paper, we propose novel decomposition techniques to optimize homomorphic permutations, advancing homomorphic encryption-based privacy-preserving computations. We start by defining an ideal decomposition form for permutations and propose an algorithm searching for depth-1 ideal decompositions. Based on this, we prove the full-depth ideal decomposability of permutations used in specific homomorphic matrix transposition (HMT) and multiplication (HMM) algorithms, allowing them to achieve asymptotic improvement in speed and rotation key reduction. As a demonstration of applicability, substituting the HMM components in the best-known inference framework of encrypted neural networks with our enhanced version shows up to a 3.9× reduction in latency. We further devise a new method for computing arbitrary homomorphic permutations, specifically those with weak structures that cannot be ideally decomposed. We design a network structure that deviates from the conventional scope of decomposition and outperforms the state-of-the-art technique under a limited rotation key budget, achieving a speed-up of up to 1.69 ×.}
}


@inproceedings{DBLP:conf/ccs/Choe0SS25,
	author = {Hyeongmin Choe and
                  Jaehyung Kim and
                  Damien Stehl{\'{e}} and
                  Elias Suvanto},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Leveraging Discrete {CKKS} to Bootstrap in High Precision},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {1083--1097},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765080},
	doi = {10.1145/3719027.3765080},
	timestamp = {Fri, 26 Dec 2025 20:53:02 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/Choe0SS25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The CKKS fully homomorphic encryption (FHE) scheme enables computations on vectors of approximate complex numbers. A moderate precision of ≈ 20 bits often suffices but, in many applications, a higher precision is required for functionality and/or security. Indeed, to obtain IND-CPA-D security [Li-Micciancio; Eurocrypt'21], secure threshold-FHE [Asharov et al; Eurocrypt'12] and circuit privacy [Gentry; STOC'09], all known approaches require a precision that supports noise flooding. This may lead to a precision of ≈ 80 bits, or more. High-precision CKKS is hard to achieve, notably because of bootstrapping. The main difficulty is modulus consumption: every homomorphic multiplication consumes some, out of an overall modulus budget. Unfortunately, in high precision, most known bootstrapping algorithms consume so much modulus that one needs to increase the parameters to increase the budget. The state-of-the-art approach, Meta-BTS [Bae et al; CCS'22], performs moderate-precision bootstrapping several times to enable high-precision bootstrapping, with similar modulus consumption as the base bootstrapping it builds upon. It however damages latency. We introduce a new approach for high-precision CKKS bootstrapping, whose cost is almost independent of the precision (as opposed to Meta-BTS) and whose modulus consumption increases significantly more slowly than with classical bootstrapping algorithms. Our design relies on the EvalRound bootstrapping [Kim et al; Asiacrypt'22], which we improve in the high-precision context by leveraging and improving recent techniques for handling discrete data with CKKS. We obtain for the first time a non-iterative 80-bit precise bootstrapping algorithm which can be run in ring degree  N =2 16 , with 494 bits of remaining modulus for computations. In terms of throughput, and for 80-bit precision, our implementation shows an acceleration of 64% compared to Meta-BTS.}
}


@inproceedings{DBLP:conf/ccs/CheonCK0KMN25,
	author = {Jung Hee Cheon and
                  Hyeongmin Choe and
                  Minsik Kang and
                  Jaehyung Kim and
                  Seonghak Kim and
                  Johannes Mono and
                  Taeyeong Noh},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Grafting: Decoupled Scale Factors and Modulus in {RNS-CKKS}},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {1098--1112},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765083},
	doi = {10.1145/3719027.3765083},
	timestamp = {Sun, 07 Dec 2025 22:09:41 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/CheonCK0KMN25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The CKKS Fully Homomorphic Encryption (FHE) scheme enables approximate arithmetic on encrypted complex numbers for a desired precision. Most implementations use RNS with carefully chosen parameters to balance precision, efficiency, and security. However, a key limitation in RNS-CKKS is the rigid coupling between the scale factor, which determines numerical precision, and the modulus, which ensures security. Since these parameters serve distinct roles—one governing arithmetic correctness and the other defining cryptographic structure—this dependency imposes design constraints, such as a lack of suitable NTT primes and limited precision flexibility, ultimately leading to inefficiencies. We propose  Grafting,  a novel approach to decouple scale factors from the modulus by introducing  (universal) sprouts,  reusable modulus factors that optimize word-sized packing while allowing flexible rescaling. The universal sprouts allow rescaling by arbitrary bit-lengths and key-switching at any modulus bit-length without requiring additional key-switching keys, and thus enable universal use of the underlying parameters. Decoupling the scale factor from the modulus in Grafting yields significant efficiency gains: (1) Optimized RNS packing by decomposing the modulus into machine word-sized components, accelerating computations and reducing the ciphertext and encryption/evaluation key sizes; and (2) A freely adjustable scale factor independent of the modulus, unifying the ring structure across applications and reducing modulus consumption through adaptive scalings. Our experiments demonstrate that Grafting improves performance across standard SHE/FHE parameter sets for ring dimensions 2 14  -2 16  by up to 1.83X and 2.01X for key-switchings and multiplications, respectively, and up to 1.92X for bootstrapping. Grafting also reduces public key and ciphertext sizes by up to 62% without compression, maintaining the same number of public keys as before. As an application, we showcase the CKKS gate bootstrapping for bits (Bae et al; Eurocrypt'24), achieving 1.89X speed-up due to the reduced number of RNS factors. Finally, we revisit the homomorphic comparison (Cheon et al; Asiacrypt'20), evaluating it with carefully chosen scale factors for each iteration, reporting up to 204-bit fewer modulus consumption (27% reduction) in the standard parameter set, without precision loss.}
}


@inproceedings{DBLP:conf/ccs/Thibault025,
	author = {Louis Tremblay Thibault and
                  Michael Walter},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Towards Verifiable {FHE} in Practice: Proving Correct Execution of
                  TFHE's Bootstrapping using plonky2},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {1113--1126},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765097},
	doi = {10.1145/3719027.3765097},
	timestamp = {Sun, 07 Dec 2025 22:09:44 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/Thibault025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this work we demonstrate for the first time that a full FHE bootstrapping operation can be proven using a SNARK in practice. We do so by designing an arithmetic circuit for the bootstrapping operation and prove it using plonky2. We are able to prove the circuit on an AWS Hpc7a instance in under 20 minutes. Proof size is about 200 kB and verification takes less than 10 ms. As the basis of our bootstrapping operation we use TFHE's programmable bootstrapping and modify it in a few places to more efficiently represent it as an arithmetic circuit (while maintaining full functionality and security). In order to achieve our results in a memory-efficient way, we take advantage of the structure of the computation and plonky2's ability to efficiently prove its own verification circuit to implement a recursion-based IVC scheme. Lastly, we present a security proof in the UC model that captures active attacks in real world applications of verifiable FHE and augment our prototype to fit such applications.}
}


@inproceedings{DBLP:conf/ccs/FischlinHM25,
	author = {Marc Fischlin and
                  Moritz Huppert and
                  Sam A. Markelon},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Probabilistic Skipping-Based Data Structures with Robust Efficiency
                  Guarantees},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {1127--1141},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765149},
	doi = {10.1145/3719027.3765149},
	timestamp = {Fri, 26 Dec 2025 20:53:02 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/FischlinHM25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Probabilistic data structures like hash tables, skip lists, and treaps support efficient operations through randomized hierarchies that enable ''skipping'' elements, achieving sub-linear query complexity on average for perfectly correct responses. They serve as critical components in performance-sensitive systems where correctness is essential and efficiency is highly desirable. While simpler than deterministic alternatives like balanced search trees, these structures traditionally assume that input data are independent of the structure's internal randomness and state -- an assumption questionable in malicious environments -- potentially leading to a significantly increased query complexity. We present adaptive attacks on all three aforementioned structures that, in the case of hash tables and skip lists, cause exponential degradation compared to the input-independent setting. While efficiency-targeting attacks on hash tables are well-studied, our attacks on skip lists and treaps provide new insights into vulnerabilities of skipping-based probabilistic data structures. Next, we propose simple and efficient modifications to the original designs of these data structures to provide provable security against adaptive adversaries. Our approach is formalized through Adaptive Adversary Property Conservation (AAPC), a general security notion that captures deviation from the expected efficiency guarantees in adversarial scenarios. We use this notion to present rigorous robustness proofs for our versions of the data structures. Lastly, we perform experiments whose empirical results closely agree with our analytical results.}
}


@inproceedings{DBLP:conf/ccs/WangZLWHLD0025,
	author = {Zihan Wang and
                  Lutan Zhao and
                  Ming Luo and
                  Zhiwei Wang and
                  Haoqi He and
                  Wenzhe Lv and
                  Xuan Ding and
                  Dan Meng and
                  Rui Hou},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {ShiftPIR: An Efficient {PIR} System with Gravity Shifting from Client
                  to Server},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {1143--1157},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765153},
	doi = {10.1145/3719027.3765153},
	timestamp = {Fri, 26 Dec 2025 20:53:02 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/WangZLWHLD0025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We present ShiftPIR, a single-server Private Information Retrieval (PIR) protocol that gravity shifts both computation and communication overhead from the client to the server, thereby significantly improving overall efficiency. This shift is driven by the growing asymmetry between resource-constrained clients and compute-intensive servers, where server-side tasks can be effectively parallelized and scaled. To achieve this, ShiftPIR introduces a novel request generation method in which the client transmits only a compact plaintext offset derived from pre-uploaded seed ciphertexts. The server then reconstructs the full query ciphertexts using homomorphic rotations, eliminating the need for costly ciphertext generation and transmission on the client side. We further design a highly parallelizable query expansion mechanism that removes data dependencies between ciphertext rotations, enabling efficient GPU-based execution. Our experiments demonstrate that ShiftPIR reduces client-side latency to microseconds while maintaining a communication cost within 4X of the non-private baseline—far outperforming prior protocols with 10 4  -10 5  × overhead. Compared to the state-of-the-art protocol YPIR, ShiftPIR achieves up to 26X lower end-to-end latency.}
}


@inproceedings{DBLP:conf/ccs/DayanikliL25,
	author = {Dennis Dayanikli and
                  Anja Lehmann},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Updatable aPAKE: Security Against Bulk Precomputation Attacks},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {1158--1172},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765155},
	doi = {10.1145/3719027.3765155},
	timestamp = {Fri, 26 Dec 2025 20:53:02 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/DayanikliL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Asymmetric Password-Authenticated Key Exchange (aPAKE) enables secure key establishment between a client and a server using a pre-shared password, while providing security against offline attacks. However, aPAKE does not guarantee any precomputation resistance, and considers passwords to become immediately available upon server compromise. A recent work by Dayanikli and Lehmann (EuroS&P'24) observed that many existing aPAKE protocols provide stronger precomputation attack resistance than what is guaranteed through the aPAKE model: they often rely on salted password hashes, where a unique salt makes precomputation attacks more difficult. While these salts are sent in clear to the client during authentication, and thus trivial to obtain for an attacker, this makes a difference in multi-user settings with millions of user accounts per server. In order to run bulk precomputation attacks on all users' passwords, the attacker needs to start an authentication session on behalf of every user to obtain their salts. However, this protection is still limited as salts are static, and the attacker can gradually extract all salt values for precomputation attacks. In this work, we build upon the observation that many aPAKE protocols include salts for their password protection, and propose a new aPAKE variant that makes such bulk precomputation attacks practically infeasible. We propose  updatable  aPAKE which employs updatable salts. In updatable aPAKE, the salt is implicitly refreshed with each successful user authentication, forcing an attacker to rebuild their precomputation table after every honest user's login - offering a level of precomputation resistance similar to that of strong aPAKE protocols. We formalize the security of updatable aPAKE in the Universal Composability framework and show how OKAPE-HMQV, the currently most efficient aPAKE protocol, can be lifted to the updatable aPAKE setting in a provably secure way. The core idea is that this salt update can be integrated through relying on the password-based server-side authentication, that is already guaranteed through aPAKE. We also observe that OKAPE-HMQV is very similar to SRP-6a, the currently most widely deployed aPAKE protocol, and explain how the same idea can be used to upgrade this legacy protocol to achieve strong bulk precomputation attack resistance with minimal overhead.}
}


@inproceedings{DBLP:conf/ccs/TanGM00L25,
	author = {Gefei Tan and
                  Adri{\`{a}} Gasc{\'{o}}n and
                  Sarah Meiklejohn and
                  Mariana Raykova and
                  Xiao Wang and
                  Ning Luo},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Founding Zero-Knowledge Proof of Training on Optimum Vicinity},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {1173--1187},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744862},
	doi = {10.1145/3719027.3744862},
	timestamp = {Fri, 26 Dec 2025 20:53:02 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/TanGM00L25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Zero-knowledge proofs of training (zkPoT) allow a party to prove that a model is trained correctly on a committed dataset without revealing any additional information about the model or the dataset. Existing zkPoT protocols prove the entire training process in zero knowledge; i.e., they prove that the final model was obtained in an iterative fashion starting from the training data and a random seed (and potentially other parameters) and applying the correct algorithm at each iteration. This approach inherently requires the prover to perform work linear to the number of iterations. In this paper, we take a different approach to proving the correctness of model training. Our approach is motivated by efficiency but also more urgently by the observation that the prover's ability to pick the random seed used for training introduces the potential for it to bias the model. In other words, if the input to the training algorithm is biased, the resulting model will be biased even if the prover correctly ran the training algorithm. Rather than prove the correctness of the training process, we thus directly prove the correctness of the training model using a notion we call  optimum vicinity , which bounds the distance between the trained model and the mathematically optimal model for models that can be viewed as the solution to a convex optimization problem. We show both theoretically and experimentally that this ensures the trained model behaves similarly to the optimal model, and show this is not true for existing approaches. We also demonstrate significant performance improvements as compared to the existing zkPoT paradigm: the statement proven in ZK in our protocol has a size independent of the number of training iterations, and our Boolean (respectively arithmetic) circuit size is up to 246× (respectively 5×) smaller than that of a baseline zkPoT protocol that verifies the whole training process.}
}


@inproceedings{DBLP:conf/ccs/Orru25,
	author = {Michele Orr{\`{u}}},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Revisiting Keyed-Verification Anonymous Credentials},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {1188--1199},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765163},
	doi = {10.1145/3719027.3765163},
	timestamp = {Sun, 07 Dec 2025 22:09:43 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/Orru25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Keyed-verification anonymous credentials (KVACs) have demonstrated their practicality through large-scale deployments in Apple, Google, Signal, and Tor. Despite their widespread adoption, the theoretical framework underlying KVACs lacks the flexibility needed to support diverse applications, which in general require different security properties. For instance, rate-limiting credentials only need a weaker unforgeability notion (one-more unforgeability), yet the framework cannot easily accommodate this relaxation. Similarly, digital identity protocols require stronger properties than unforgeability -—specifically, extractability for security proofs when adversaries can observe other users' credentials. We address these limitations by introducing new notions of extractability and one-more unforgeability. We improve two foundational works in the space: The scheme by Chase et al. (CCS 2014), commonly referred to as CMZ or PS MAC can be made statistically anonymous, and issuance cost reduced from ( O ( n )) to ( O (1)). The scheme by Barki et al. (SAC 2016), known as BBDT or BBS MAC can be issued more efficiently (one less group element). We provide a security proof for both schemes in the algebraic group model (CRYPTO 2018) and describe how these core credential schemes can be extended to construct more complex anonymous credential systems such as time-based policies, pseudonyms, and rate-limiting extensions.}
}


@inproceedings{DBLP:conf/ccs/DuvergerFJNO25,
	author = {K{\'{e}}vin Duverger and
                  Pierre{-}Alain Fouque and
                  Charlie Jacomme and
                  Guilhem Niot and
                  Cristina Onete},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Subversion-resilient Key-exchange in the Post-quantum World},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {1200--1214},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765165},
	doi = {10.1145/3719027.3765165},
	timestamp = {Fri, 26 Dec 2025 20:53:02 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/DuvergerFJNO25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Subversion-resilient Authenticated key-exchange (AKE) aims to achieve the guarantees of secure AKE even in the presence of an adversary that has tampered with parts of the protocol's implementation. One way to achieve subversion-resilient AKE is the use of Reverse Firewalls (RFs), an untrusted third-party that can restore security. Recent work[17] highlights the challenges of designing RFs for practical secure channel-establishment. This paper extends existing RF-based subversion-resilient AKE at three levels: security definitions, constructions, and the use of formal verification. First, we introduce a useful relaxation of the notion of security in subversion-resilient AKE with RFs: the goal is no longer to prevent all exfiltration, but rather to restore to the AKE protocol a property lost upon subversion. We focus specifically on authenticating and (key-)securing RFs. We also discuss subversion-resilience against a  spectrum of compromises,  designing a flexible framework in which protocols are proved secure with respect to adversaries that can tamper with  some  components of the implementation, but perhaps not others. Our ultimate goal is to achieve post-quantum secure subversion-resilient key-exchange. Far from being trivial, this requires the introduction of a malleable-yet-secure notion of key-encapsulation, which we dub  re-randomizable Key Encapsulation Mechanism.  We carefully formalize this new primitive and instantiate it first based on a classical Diffie-Hellman KEM and one based on Kyber. Finally, we lay the foundations for the formal verification of RF based protocols, by formally proving our protocol with the CryptoVerif prover, in addition to computational-security proofs in usual Bellare-Rogaway methodology.}
}


@inproceedings{DBLP:conf/ccs/ZhanTLWG25,
	author = {Pei Zhan and
                  Peng Tang and
                  Yangzhuo Li and
                  Puwen Wei and
                  Shanqing Guo},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Poisoning Attacks to Local Differential Privacy for Ranking Estimation},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {1215--1229},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744821},
	doi = {10.1145/3719027.3744821},
	timestamp = {Thu, 15 Jan 2026 07:56:54 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/ZhanTLWG25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Local differential privacy (LDP) involves users perturbing their inputs to provide plausible deniability of their data. However, this also makes LDP vulnerable to poisoning attacks. In this paper, we first introduce novel poisoning attacks for ranking estimation. These attacks are intricate, as fake attackers do not merely adjust the frequency of target items. Instead, they leverage a limited number of fake users to precisely modify frequencies, effectively altering item rankings to maximize gains. To tackle this challenge, we introduce the concepts of attack cost and optimal attack item (set), and propose corresponding strategies for kRR, OUE, and OLH protocols. For kRR, we iteratively select optimal attack items and allocate suitable fake users. For OUE, we iteratively determine optimal attack item sets and consider the incremental changes in item frequencies across different sets. Regarding OLH, we develop a harmonic cost function based on the pre-image of a hash to select that supporting a larger number of effective attack items. Lastly, we present an attack strategy based on confidence levels to quantify the probability of a successful attack and the number of attack iterations more precisely. We demonstrate the effectiveness of our attacks through theoretical and empirical evidence, highlighting the necessity for defenses against these attacks. The source code and data have been made available at https://github.com/LDP-user/LDP-Ranking.git.}
}


@inproceedings{DBLP:conf/ccs/LiL0S25,
	author = {Xiaolin Li and
                  Ninghui Li and
                  Boyang Wang and
                  Wenhai Sun},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Mitigating Data Poisoning Attacks to Local Differential Privacy},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {1230--1244},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744839},
	doi = {10.1145/3719027.3744839},
	timestamp = {Tue, 20 Jan 2026 09:59:40 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/LiL0S25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The distributed nature of local differential privacy (LDP) invites data poisoning attacks and poses unforeseen threats to the underlying LDP-supported applications. In this paper, we propose a comprehensive mitigation framework for popular frequency estimation, which contains a suite of novel defenses, including malicious user detection, attack pattern recognition, and damaged utility recovery. In addition to existing attacks, we explore new adaptive adversarial activities for our mitigation design. For detection, we present a new method to precisely identify bogus reports, and thus LDP aggregation can be performed over the ''clean'' data. When the attack behavior becomes stealthy and direct filtering out malicious users is difficult, we further propose a detection that can effectively recognize hidden adversarial patterns, thus facilitating the decision-making of service providers. These detection methods require no additional data or attack information and incur minimal computational cost. Our experiment demonstrates their excellent performance and substantial improvement over previous work in various settings. In addition, we conduct an empirical analysis of LDP post-processing for corrupted data recovery and propose a new post-processing method, through which we reveal new insights into protocol recommendations in practice and key design principles for future research.}
}


@inproceedings{DBLP:conf/ccs/NasehPSCOH25,
	author = {Ali Naseh and
                  Yuefeng Peng and
                  Anshuman Suri and
                  Harsh Chaudhari and
                  Alina Oprea and
                  Amir Houmansadr},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Riddle Me This! Stealthy Membership Inference for Retrieval-Augmented
                  Generation},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {1245--1259},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744840},
	doi = {10.1145/3719027.3744840},
	timestamp = {Fri, 26 Dec 2025 20:53:02 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/NasehPSCOH25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Retrieval-Augmented Generation (RAG) enables Large Language Models (LLMs) to generate grounded responses by leveraging external knowledge databases without altering model parameters. Although the absence of weight tuning prevents leakage via model parameters, it introduces the risk of inference adversaries exploiting retrieved documents in the model's context. Existing methods for membership inference and data extraction often rely on jailbreaking or carefully crafted  unnatural  queries, which can be easily detected or thwarted with query rewriting techniques common in RAG systems. In this work, we present øurattackfull (øurattack), a membership inference technique targeting documents in the RAG datastore. By crafting natural-text queries that are answerable only with the target document's presence, our approach demonstrates successful inference with just 30 queries while remaining stealthy; straightforward detectors identify adversarial prompts from existing methods up to ~76× more frequently than those generated by our attack. We observe a 2× improvement in TPR@1%FPR over prior inference attacks across diverse RAG configurations, all while costing less than $0.02 per document inference.}
}


@inproceedings{DBLP:conf/ccs/NisenoffSC25,
	author = {Alexandra Nisenoff and
                  Deian Stefan and
                  Nicolas Christin},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Exploiting the Shared Storage {API}},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {1260--1274},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744848},
	doi = {10.1145/3719027.3744848},
	timestamp = {Sun, 07 Dec 2025 22:09:43 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/NisenoffSC25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As part of an effort to replace third-party cookies, Google introduced the Shared Storage API as one of their ''Privacy Sandbox'' proposals. The Shared Storage API seeks to replace some of the benign functionalities that third-party cookies facilitate while mitigating the potential privacy harms that they can cause, such as reidentifying users across websites. Shared Storage seeks to do this by allowing third parties to store data that is not partitioned by top-level website, but limiting read access to those data. We find that the implementation and design of the API have flaws that allow for both the reidentification of users across sites and the leakage of more data than intended by Google. With the API being deployed in Google Chrome and major advertisers and trackers having completed the processes required to gain access to the API, the Shared Storage API may not do as much as intended to improve the state of privacy on the web. We present several attacks on the API that circumvent the key goals laid out by Google as well as discuss potential extensions and mitigation strategies. While we have responsibly disclosed our attacks to Google, most attacks remain possible in Chrome.}
}


@inproceedings{DBLP:conf/ccs/SpecterCFML25,
	author = {Michael A. Specter and
                  Mihai Christodorescu and
                  Abbie Farr and
                  Bo Ma and
                  Robin Lassonde},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Fingerprinting SDKs for Mobile Apps and Where to Find Them: Understanding
                  the Market for Device Fingerprinting},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {1275--1289},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744877},
	doi = {10.1145/3719027.3744877},
	timestamp = {Fri, 26 Dec 2025 20:53:02 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/SpecterCFML25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper presents a large-scale analysis of fingerprinting-like behavior in the mobile application ecosystem. We take a market-based approach, focusing on third-party tracking as enabled by applications' common use of third-party SDKs. Our dataset consists of over 228,000 SDKs from popular Maven repositories, 178,000 Android applications collected from the Google Play store, and our static analysis pipeline detects exfiltration of over 500 individual signals. To the best of our knowledge, this represents the largest-scale analysis of SDK behavior undertaken to date. We find that Ads SDKs (the ostensible focus of industry efforts such as Apple's App Tracking Transparency and Google's Privacy Sandbox) appear to be the source of only 30.56% of the fingerprinting behaviors. A surprising 23.92% originate from SDKs whose purpose was unknown or unclear. Furthermore, Security and Authentication SDKs are linked to only 11.7% of likely fingerprinting instances. These results suggest that addressing fingerprinting solely in specific market-segment contexts like advertising may offer incomplete benefit. Enforcing anti-fingerprinting policies is also complex, as we observe a sparse distribution of signals and APIs used by likely fingerprinting SDKs. For instance, only 2% of exfiltrated APIs are used by more than 75% of SDKs, making it difficult to rely on user permissions to control fingerprinting behavior.}
}


@inproceedings{DBLP:conf/ccs/LiuQ25,
	author = {Ruiyao Liu and
                  Chenxi Qiu},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {PAnDA: Rethinking Metric Differential Privacy Optimization at Scale
                  with Anchor-Based Approximation},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {1290--1304},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765042},
	doi = {10.1145/3719027.3765042},
	timestamp = {Sun, 07 Dec 2025 22:09:43 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/LiuQ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Metric Differential Privacy (mDP)  extends the local differential privacy (LDP) framework to metric spaces, enabling more nuanced privacy protection for data such as geo-locations. However, existing mDP optimization methods, particularly those based on linear programming (LP), face scalability challenges due to the quadratic growth in decision variables. In this paper, we propose  Perturbation via Anchor-based Distributed Approximation (PA n DA),  a scalable two-phase framework for optimizing metric differential privacy (mDP). To reduce computational overhead, PA n DA allows each user to select a small set of anchor records, enabling the server to solve a compact linear program over a reduced domain. We introduce three anchor selection strategies,  exponential decay (PA n DA-e), power-law decay (PA n DA-p),  and  logistic decay (PA n DA-l) , and establish theoretical guarantees under a relaxed privacy notion called  probabilistic mDP (PmDP).  Experiments on real-world geo-location datasets demonstrate that PA n DA scales to secret domains with up to 5,000 records, two times larger than prior LP-based methods, while providing theoretical guarantees for both privacy and utility.}
}


@inproceedings{DBLP:conf/ccs/XuZYOH0S25,
	author = {Haichuan Xu and
                  Runze Zhang and
                  Mingxuan Yao and
                  David Oygenblik and
                  Yizhi Huang and
                  Jeman Park and
                  Brendan Saltaformaggio},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Lock the Door But Keep the Window Open: Extracting App-Protected Accessibility
                  Information from Browser-Rendered Websites},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {1305--1319},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744822},
	doi = {10.1145/3719027.3744822},
	timestamp = {Fri, 26 Dec 2025 20:53:02 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/XuZYOH0S25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Android accessibility (a11y) service has been widely utilized by malware to abuse benign services. To prevent such abuse, developers need to secure a11y content access in both their apps and mobile websites. However, a misalignment of a11y protection mechanisms exists between them. Prior research has focused on attacking and defending a11y information embedded in native Android apps. However, our research found that a11y malware can retrieve app-protected a11y information in its mobile browser-rendered website counterpart, leaving mobile browser users more vulnerable to a11y attacks than app users. To help benign service developers vet this attack surface, we developed SOMBRA, an automated analysis pipeline to vet browser-side leakage of a11y information that is a11y-protected in apps. Using SOMBRA, we analyzed 294 benign services and found 29 of them deploy app-side a11y protection mechanisms to secure 256 views. SOMBRA discovered that 241, 402, 244, and 251 elements corresponding to their protected app-side views are a11y-exposed in their websites rendered by Chrome, Firefox, Brave, and Edge browsers, respectively. The leaked elements contain sensitive personal identifiable information. Finally, SOMBRA discovered that most developers do not adopt browser-side a11y protections because existing mechanisms either have ineffective protection or hinder the usability of their content.}
}


@inproceedings{DBLP:conf/ccs/Liu0L0SWWL025,
	author = {Fengyu Liu and
                  Yuan Zhang and
                  Enhao Li and
                  Wei Meng and
                  Youkun Shi and
                  Qianheng Wang and
                  Chenlin Wang and
                  Zihan Lin and
                  Min Yang},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {BACScan: Automatic Black-Box Detection of Broken-Access-Control Vulnerabilities
                  in Web Applications},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {1320--1333},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744825},
	doi = {10.1145/3719027.3744825},
	timestamp = {Fri, 26 Dec 2025 20:53:02 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/Liu0L0SWWL025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Broken-Access-Control (BAC) vulnerabilities have consistently been ranked among the most critical security risks in web applications, occupying the top positions in the OWASP Top 10 over the past several years. These vulnerabilities allow attackers to bypass access control mechanisms and perform unauthorized operations, posing serious security and privacy threats to sensitive business and user data. Despite substantial attention given to BAC vulnerabilities, effective and reliable approaches to detecting these issues remain limited. In this work, we present BACScan, a novel black-box approach to detect BAC vulnerabilities in web applications. Unlike existing response similarity-based oracles that check only unauthorized read accesses, BACScan introduces an innovative feedback-driven oracle, which determines whether unauthorized read or modification operations have occurred by inferring operationally-dependent web pages and analyzing the operational feedback. We evaluated BACScan on 20 real-world applications and successfully identified 89 vulnerabilities, including 54 previously unreported ones, outperforming state-of-the-art tools. We reported all newly identified vulnerabilities to the affected vendors. To date, 35 new CVE IDs have been assigned.}
}


@inproceedings{DBLP:conf/ccs/Liu0ZLFP25,
	author = {Side Liu and
                  Jiang Ming and
                  Guodong Zhou and
                  Xinyi Liu and
                  Jianming Fu and
                  Guojun Peng},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Analyzing PDFs like Binaries: Adversarially Robust {PDF} Malware Analysis
                  via Intermediate Representation and Language Model},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {1334--1348},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744829},
	doi = {10.1145/3719027.3744829},
	timestamp = {Fri, 26 Dec 2025 20:53:02 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/Liu0ZLFP25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Malicious PDF files have emerged as a persistent threat and become a popular attack vector in web-based attacks. While machine learning-based PDF malware classifiers have shown promise, these classifiers are often susceptible to adversarial attacks, undermining their reliability. To address this issue, recent studies have aimed to enhance the robustness of PDF classifiers. Despite these efforts, the feature engineering underlying these studies remains outdated. Consequently, even with the application of cutting-edge machine learning techniques, these approaches fail to fundamentally resolve the issue of feature instability. To tackle this, we propose a novel approach for PDF feature extraction and PDF malware detection. We introduce the PDFObj IR (PDF Object Intermediate Representation), an assembly-like language framework for PDF objects, from which we extract semantic features using a pretrained language model. Additionally, we construct an Object Reference Graph to capture structural features, drawing inspiration from program analysis. This dual approach enables us to analyze and detect PDF malware based on both semantic and structural features. Experimental results demonstrate that our proposed classifier achieves strong adversarial robustness while maintaining an exceptionally low false positive rate of only 0.07% on baseline dataset compared to state-of-the-art PDF malware classifiers.}
}


@inproceedings{DBLP:conf/ccs/UkaniHSS25,
	author = {Alisha Ukani and
                  Hamed Haddadi and
                  Alex C. Snoeren and
                  Peter Snyder},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Local Frames: Exploiting Inherited Origins to Bypass Content Blockers},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {1349--1363},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744843},
	doi = {10.1145/3719027.3744843},
	timestamp = {Fri, 26 Dec 2025 20:53:02 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/UkaniHSS25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We present a study of how local frames (i.e., iframes loading content like ''about:blank'') are mishandled by a wide range of popular Web security and privacy tools. As a result, users of these tools remain vulnerable to the very attack techniques against which they seek to protect themselves, including browser fingerprinting, cookie-based tracking, and data exfiltration. The tools we study are vulnerable in different ways, but all share a root cause: legacy Web functionality interacts with browser privacy boundaries in unexpected ways, leading to systemic vulnerabilities in tools developed, maintained, and recommended by privacy experts and activists. We consider four core capabilities supported by most privacy tools and develop tests to determine whether each can be evaded through the use of local frames. We apply our tests to six popular Web privacy and security tools—identifying at least one vulnerability in each for a total of 19—and extract common patterns regarding their mishandling of local frames. Our measurement of popular websites finds that 56% employ local frames and that 73.7% of the requests made by these local frames should be blocked by popular filter lists but instead trigger the vulnerabilities we identify. From another perspective, 14.3% of all sites that we crawl make requests that should be blocked inside of local frames. We disclosed these vulnerabilities to the tool authors and discuss both our experiences working with them to patch their products and the implications of our findings for other privacy and security research.}
}


@inproceedings{DBLP:conf/ccs/FullerYABHSS25,
	author = {Jonathan Fuller and
                  Mingxuan Yao and
                  Saumya Agarwal and
                  Srimanta Barua and
                  Taleb Hirani and
                  Amit Kumar Sikder and
                  Brendan Saltaformaggio},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Enhanced Web Application Security Through Proactive Dead Drop Resolver
                  Remediation},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {1364--1378},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744860},
	doi = {10.1145/3719027.3744860},
	timestamp = {Fri, 26 Dec 2025 20:53:02 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/FullerYABHSS25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Dead Drop Resolver (DDR) malware evades traditional Command and Control (C&C) server takedowns by dynamically resolving C&C addresses hosted on popular web applications, such as Dropbox and Pastebin. These addresses are often manipulated (i.e., encoded or encrypted), rendering existing detection techniques largely ineffective. To tackle this challenge, we introduce VADER, a malware forensics system specifically designed for the proactive detection of dead drops. Analyzing a dataset of 100k malware samples collected in the wild, VADER identified 8,906 DDR malware samples from 110 families that leverage 273 dead drops across seven web applications. Additionally, it proactively uncovered 57.1% more dead drops spanning 11 web applications. Case studies revealed that over 40% of DDR malware samples employ sophisticated, layered de-manipulation algorithms, highlighting the prevalence and complexity of this evasion technique. Beyond detection, VADER enabled proactive remediation by discovering 13 previously unknown dead drops from a single DDR malware sample. This approach empowers web application providers to systematically scan their platforms, enabling the early detection and mitigation of dead drops.}
}


@inproceedings{DBLP:conf/ccs/00130WZ025,
	author = {Jiaming Li and
                  Sen Chen and
                  Chunlian Wu and
                  Yuxin Zhang and
                  Lingling Fan},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {ForeDroid: Scenario-Aware Analysis for Android Malware Detection and
                  Explanation},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {1379--1393},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765207},
	doi = {10.1145/3719027.3765207},
	timestamp = {Fri, 26 Dec 2025 20:53:02 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/00130WZ025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Android malware continues to evolve, posing significant challenges in generalization, fine-grained detection, and interpretability for existing detection systems. Existing methods struggle to generalize to unseen malware, lack fine-grained behavioral understanding, and provide limited interpretability due to their reliance on rigid rules or the inability to recover complete causal behavior paths. To this end, we present ForeDroid, a unified and interpretable framework for Android malware detection and explanation via scenario-aware analysis. ForeDroid models malicious intent as behavioral inconsistencies within functional scenarios. It clusters semantically coherent scenarios, extracts sensitive API call chains, and summarizes them into natural language using LLMs. These summaries are embedded and compared against benign behavior distributions within the same scenario for unsupervised anomaly detection. High-risk behaviors showing strong semantic inconsistency are further interpreted by an LLM-driven module that generates fine-grained anomaly reports. We evaluated ForeDroid on two challenging tasks: zero-day malware detection and fine-grained behavior analysis. The result shows ForeDroid outperforms MaMaDroid, MalScan, DeepRefiner, and a continuous learning-based approach in zero-day malware detection under the temporal-split setting. Besides, ForeDroid achieves an F1-score of 0.94 in fine-grained behavior detection on the manually annotated GPMalware dataset, surpassing ProMal. Our results demonstrate ForeDroid's ability to bridge low-level call graph analysis with high-level semantic reasoning, making it a practical, interpretable solution for malware detection.}
}


@inproceedings{DBLP:conf/ccs/GregersenAT25,
	author = {Simon Oddershede Gregersen and
                  Chaitanya Agarwal and
                  Joseph Tassarotti},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Logical Relations for Formally Verified Authenticated Data Structures},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {1394--1408},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744801},
	doi = {10.1145/3719027.3744801},
	timestamp = {Sun, 07 Dec 2025 22:09:41 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/GregersenAT25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Authenticated data structures allow untrusted third parties to carry out operations which produce proofs that can be used to verify an operation's output. Such data structures are challenging to develop and implement correctly. This paper gives a formal proof of security and correctness for a library that generates authenticated versions of data structures automatically. The proof is based on a new relational separation logic for reasoning about programs that use collision-resistant cryptographic hash functions. This logic provides a basis for constructing two semantic models of a type system, which are used to justify how the library makes use of type abstraction to enforce security and correctness. Using these models, we also prove the correctness of several optimizations to the library and then show how optimized, hand-written implementations of authenticated data structures can be soundly linked with automatically generated code. All of the results in this paper have been mechanized in the Rocq prover using the Iris framework.}
}


@inproceedings{DBLP:conf/ccs/AlmeidaBBBADG0Q25,
	author = {Jos{\'{e}} Bacelar Almeida and
                  Manuel Barbosa and
                  Gilles Barthe and
                  Lionel Blatter and
                  Gustavo Xavier Delerue Marinho Alves and
                  Jo{\~{a}}o Diogo Duarte and
                  Benjamin Gr{\'{e}}goire and
                  Tiago Oliveira and
                  Miguel Quaresma and
                  Pierre{-}Yves Strub and
                  Ming{-}Hsien Tsai and
                  Bow{-}Yaw Wang and
                  Bo{-}Yin Yang},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Jazzline: Composable CryptoLine Functional Correctness Proofs for
                  Jasmin Programs},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {1409--1423},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744814},
	doi = {10.1145/3719027.3744814},
	timestamp = {Fri, 26 Dec 2025 20:53:02 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/AlmeidaBBBADG0Q25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Jasmin is a programming language for high-speed and high-assurance cryptography. Correctness proofs of Jasmin programs are typically carried out deductively in EasyCrypt. This allows generality, modularity and composable reasoning, but does not scale well for low-level architecture-specific routines. CryptoLine offers a semi-automatic approach to formally verify algebraically-rich low-level cryptographic routines. CryptoLine proofs are self-contained: they are not integrated into higher-level formal verification developments. This paper shows how to soundly use CryptoLine to discharge subgoals in functional correctness proofs for complex Jasmin programs. We extend Jasmin with annotations and provide an automatic translation into a CryptoLine model, where most complex transformations are certified. We also formalize and implement the automatic extraction of the semantics of a CryptoLine proof to EasyCrypt. Our motivating use-case is the X-Wing hybrid KEM, for which we present the first formally verified implementation.}
}


@inproceedings{DBLP:conf/ccs/CremersDN25,
	author = {Cas Cremers and
                  Alexander Dax and
                  Aurora Naska},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Breaking and Provably Restoring Authentication: {A} Formal Analysis
                  of {SPDM} 1.2 including Cross-Protocol Attacks},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {1424--1438},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744865},
	doi = {10.1145/3719027.3744865},
	timestamp = {Fri, 26 Dec 2025 20:53:02 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/CremersDN25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The SPDM (Security Protocol and Data Model) protocol is a standard under development by the DMTF consortium, and supported by major industry players including Broadcom, Cisco, Dell, Google, HP, IBM, Intel, and NVIDIA. SPDM 1.2 is a complex protocol that aims to provide platform security, for example for communicating hardware components or cloud computing scenarios. SPDM is the core security mechanism of PCI Express (PCIe) and Compute Express Link (CXL). In this work, we provide the first holistic, formal analysis of SPDM 1.2: we model the full protocol flow of SPDM considering all of its modes -- especially the complex interaction between its different key-exchange modes -- in the framework of the Tamarin prover, making our resulting model one of the most complex Tamarin models to date. To our surprise, Tamarin finds a cross-protocol attack that allows a network attacker to completely break authentication of the pre-shared key mode. We implemented our attack on the SPDM reference implementation, and reported the issue to the SPDM developers. DMTF registered our attack as a CVE with CVSS rating 9 (critical). We propose a fix and develop the first formal symbolic proof using the Tamarin prover for the fixed SPDM 1.2 protocol as a whole. The resulting model of the main modes and their interactions is highly complex, and we develop supporting lemmas to enable proving properties in the Tamarin prover, including the absence of  all cross-protocol attacks.  Our fix has been incorporated into both the reference implementation and the newest version of the standard. Our results highlight the need for a holistic analysis of other internet standards and the importance of providing generalized security guarantees across entire protocols.}
}


@inproceedings{DBLP:conf/ccs/BhusalCS025,
	author = {Bishnu Bhusal and
                  Rohit Chadha and
                  A. Prasad Sistla and
                  Mahesh Viswanathan},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Approximate Algorithms for Verifying Differential Privacy with Gaussian
                  Distributions},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {1439--1453},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765043},
	doi = {10.1145/3719027.3765043},
	timestamp = {Fri, 26 Dec 2025 20:53:02 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/BhusalCS025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The verification of differential privacy algorithms that employ Gaussian distributions is little understood. This paper tackles the challenge of verifying such programs by introducing a novel approach to approximating probability distributions of loop-free programs that sample from both discrete and continuous distributions with computable probability density functions, including Gaussian and Laplace. We establish that verifying (∈, δ)-differential privacy for these programs is  almost decidable,  meaning the problem is decidable for all values of δ except those in a finite set. Our verification algorithm is based on computing probabilities to any desired precision by combining integral approximations, and tail probability bounds. The proposed methods are implemented in the tool, DipApprox, using the FLINT library for high-precision integral computations, and incorporate optimizations to enhance scalability. We validate DiPApprox on fundamental privacy-preserving algorithms, such as Gaussian variants of the Sparse Vector Technique and Noisy Max, demonstrating its effectiveness in both confirming privacy guarantees and detecting violations.}
}


@inproceedings{DBLP:conf/ccs/GollamudiGG25,
	author = {Tarakaram Gollamudi and
                  Anitha Gollamudi and
                  Joshua Gancher},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {{ILA:} Correctness via Type Checking for Fully Homomorphic Encryption},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {1454--1468},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765068},
	doi = {10.1145/3719027.3765068},
	timestamp = {Fri, 26 Dec 2025 20:53:02 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/GollamudiGG25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {RLWE-based Fully Homomorphic Encryption (FHE) schemes add some  small  noise to the message during encryption. The noise accumulates with each homomorphic operation. When the noise exceeds a critical value, the FHE circuit produces an incorrect output. This makes developing FHE applications quite subtle, as one must closely track the noise to ensure correctness. However, existing libraries and compilers offer limited support to statically track the noise. Additionally, FHE circuits are also plagued by wraparound errors that are common in finite modulus arithmetic. These two limitations of existing compilers and libraries make FHE applications too difficult to develop with confidence. In this work, we present a  correctness-oriented  IR, Intermediate Language for Arithmetic Circuits (ILA), for type-checking circuits intended for homomorphic evaluation. Our IR is backed by a type system that tracks low-level quantitative bounds (e.g., ciphertext noise) without using the secret key. Using our type system, we identify and prove a strong  functional correctness  criterion for ILA circuits. Additionally, we have designed ILA to be maximally general: our core type system does not directly assume a particular FHE scheme, but instead axiomitizes a  model  of FHE. We instantiate this model with the exact FHE schemes (BGV, BFV and TFHE), and obtain functional correctness for free. We implement a concrete type checker ILA, parameterized by the noise estimators for three popular FHE libraries (OpenFHE, SEAL and TFHE-rs). We also use the type checker to infer the optimal placement of  modulus switching , a common noise management operation. Evaluation shows that ILA type checker is sound (always detects noise overflows), practical (noise estimates are tight) and efficient.}
}


@inproceedings{DBLP:conf/ccs/PereiraKGLSWE0B25,
	author = {Jo{\~{a}}o C. Pereira and
                  Tobias Klenze and
                  Sofia Giampietro and
                  Markus Limbeck and
                  Dionysios Spiliopoulos and
                  Felix A. Wolf and
                  Marco Eilers and
                  Christoph Sprenger and
                  David A. Basin and
                  Peter M{\"{u}}ller and
                  Adrian Perrig},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Protocols to Code: Formal Verification of a Secure Next-Generation
                  Internet Router},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {1469--1483},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765104},
	doi = {10.1145/3719027.3765104},
	timestamp = {Fri, 26 Dec 2025 20:53:02 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/PereiraKGLSWE0B25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We present the first formally-verified Internet router, which is part of the SCION Internet architecture. SCION routers run a cryptographic protocol for secure packet forwarding in an adversarial environment. We verify both the protocol's network-wide security properties and the low-level properties of its implementation. Namely, we develop a series of protocol models by refinement in Isabelle/HOL and we use an automated program verifier to prove that the router's Go code satisfies crash freedom, freedom from data races, and adheres to the most concrete model in our series of refinements. Both verification efforts are soundly linked together. Our work demonstrates the feasibility of coherently verifying a security-critical network component from high-level protocol models down to performance-optimized production code, developed by an independent team. In the process, we uncovered critical attacks and bugs in both the protocol and its implementation, which were confirmed by the code developers, and we strengthened the protocol's security properties. This paper presents the challenges we faced when verifying an existing real-world system, explains our approach to tackling these challenges, summarizes the main results, and distills valuable lessons for the verification of secure systems, in particular for the techniques and tools employed.}
}


@inproceedings{DBLP:conf/ccs/Sun00LWLHRLX025,
	author = {Yue Sun and
                  Yan Kang and
                  Chenggang Wu and
                  Kangjie Lu and
                  Jiming Wang and
                  Xingwei Li and
                  Yuhao Hu and
                  Jikai Ren and
                  Yuanming Lai and
                  Mengyao Xie and
                  Zhe Wang},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {SyzParam: Incorporating Runtime Parameters into Kernel Driver Fuzzing},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {1484--1498},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744838},
	doi = {10.1145/3719027.3744838},
	timestamp = {Fri, 26 Dec 2025 20:53:02 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/Sun00LWLHRLX025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Under the monolithic architecture of the Linux kernel, all its components operate within the same address space. Notably, device drivers constitute over half of the kernel codebase yet are particularly prone to bugs. Therefore, exploring vulnerabilities in drivers is critical for ensuring kernel security. Extensive research has been done to fuzz kernel drivers through system calls and hardware interrupts. Through a comprehensive study of the Linux Kernel Device Model, we identified that the execution of device drivers is also influenced by runtime parameters, including device attributes and kernel module parameters. Our analysis reveals that large portions of the uncovered code are masked by these parameters, which are exposed to the userspace through a specialized virtual file system known as  sysfs.  Furthermore, adjacent devices interconnected within the same device tree also impact drivers' behavior. This paper introduces a novel fuzzing framework, SyzParam, which incorporates runtime parameters into the fuzzing process. Achieving this objective requires addressing several key challenges, including valid value extraction, inter-device relation construction, and fuzz engine integration. By inspecting the data structures and functions associated with the LKDM, our tool can extract runtime parameters across various drivers through static analysis. Additionally, SyzParam collects inter-device relations and identifies associations between runtime parameters and drivers. Furthermore, SyzParam proposes a novel mutation strategy, which leverages these relations and prioritizes parameter modification during related driver execution. Our evaluation demonstrates that SyzParam outperforms existing fuzzing works in driver code coverage and bug-detection capabilities. To date, we have identified 30 unique bugs in the latest kernel upstreams, including 10 CVEs.}
}


@inproceedings{DBLP:conf/ccs/ZhangLLCHZG25,
	author = {Hao Zhang and
                  Jian Liu and
                  Jie Lu and
                  Shaomin Chen and
                  Tianshuo Han and
                  Bolun Zhang and
                  Xiaorui Gong},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Reviving Discarded Vulnerabilities: Exploiting Previously Unexploitable
                  Linux Kernel Bugs Through Control Metadata Fields},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {1499--1513},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744841},
	doi = {10.1145/3719027.3744841},
	timestamp = {Thu, 01 Jan 2026 19:11:53 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/ZhangLLCHZG25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Linux kernel vulnerabilities represent a critical security threat in modern computing systems, with hundreds of new vulnerabilities discovered annually. Traditional security practices often discard vulnerabilities offering only weak primitives as ''unexploitable'', creating a significant blind spot in kernel security. This paper presents a novel approach to revive these previously discarded vulnerabilities by exploiting Control Metadata Fields (CMFs) within Linux objects, rather than traditional pointer manipulation. Our CMF-based method overcomes two major limitations of existing approaches: it bypasses modern security measures like pointer authentication code and eliminates the need for precise pointer alignment that weak primitives cannot reliably achieve. Using MetaXploit, our automated analysis tool, we identified 54 exploitable CMFs across Ubuntu and Debian distributions. Empirical testing against 20 real-world vulnerabilities demonstrated successful exploitation in 18 cases, including 12 previously discarded vulnerabilities. These results challenge traditional assumptions about vulnerability exploitability and suggest that many discarded vulnerabilities in the Linux kernel warrant reevaluation.}
}


@inproceedings{DBLP:conf/ccs/YouSLCP25,
	author = {Junseung You and
                  Jiwon Seo and
                  Kyeongryong Lee and
                  Yeongpil Cho and
                  Yunheung Paek},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {{BASTAG:} Byte-level Access Control on Shared Memory using {ARM} Memory
                  Tagging Extension},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {1514--1528},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744849},
	doi = {10.1145/3719027.3744849},
	timestamp = {Fri, 26 Dec 2025 20:53:02 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/YouSLCP25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As software grows in size and complexity, modular designs are increasingly adopted, leading to frequent interactions via shared memory between components. This design however increases the risk of vulnerabilities from uncontrolled memory access to shared memory. Enforcing byte-level access control can mitigate these risks by enabling byte-level permissions on complex shared objects and their sub-elements. However, existing approaches face performance limitations as they increase the granularity of control to byte level. In this paper, we present BASTAG, a novel system that leverages ARM's Memory Tagging Extension (MTE) to tack this challenge. Although MTE enforces tag-matching between pointers and memory, its hardware-defined granularity is too coarse to support byte-level control on its own. To address the inherent limitations of applying MTE for nuanced access control, BASTAG incorporates a technique known as shadow memory tagging that places separate, but associated MTE tags for the actual memory targets, allowing for more flexible and finer access control with efficiency. We implemented a BASTAG prototype on AArch64 hardware with MTE support and evaluated it on three real-world use cases. Our results demonstrate that BASTAG significantly outperforms existing byte-level access control mechanisms.}
}


@inproceedings{DBLP:conf/ccs/JeongCCCKJ25,
	author = {Seongyun Jeong and
                  Minseong Choi and
                  Haehyun Cho and
                  Seokwoo Choi and
                  Hyungsub Kim and
                  Yuseok Jeon},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Intent-aware Fuzzing for Android Hardened Application},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {1529--1543},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744858},
	doi = {10.1145/3719027.3744858},
	timestamp = {Fri, 26 Dec 2025 20:53:02 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/JeongCCCKJ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The widespread adoption of app hardening techniques in Android applications makes it more challenging for current analysis techniques to analyze hardened apps, leading to limited analysis coverage. This limitation is mainly due to the difficulties in obtaining detailed information about Intents, which is essential for component communication and the execution of specific events in Android applications. In this paper, we introduce eBPF-based AHA-Fuzz, the first intent-aware greybox fuzzing framework for Android hardened applications. AHA-Fuzz proposes a valid intent generator to create valid intent inputs that can trigger diverse Android app behaviors. To precisely evaluate the impact of these inputs, AHA-Fuzz presents a selective coverage feedback approach. Additionally, AHA-Fuzz introduces approaches for efficiently triggering hard-to-trigger bugs (e.g., scheduled malware) and detecting information leaks in hardened applications. Our evaluation results demonstrate that AHA-Fuzz triggers 92.3% more intents 3.45× faster and executes 23.9% more methods than previous approaches. Additionally, AHA-Fuzz has discovered 47 previously unknown bugs that existing approaches cannot detect. The developers of Google, Firefox, and Facebook have acknowledged 6 out of 47 bugs, and have already fixed three of them.}
}


@inproceedings{DBLP:conf/ccs/YuHCCS25,
	author = {Jason Z. Yu and
                  Fangqi Han and
                  Kaustab Choudhury and
                  Trevor E. Carlson and
                  Prateek Saxena},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Securing Mixed Rust with Hardware Capabilities},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {1544--1558},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744861},
	doi = {10.1145/3719027.3744861},
	timestamp = {Wed, 31 Dec 2025 22:13:25 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/YuHCCS25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Rust programming language enforces three basic  Rust principles , namely ownership, borrowing, and AXM (Aliasing Xor Mutability) to prevent security bugs such as memory safety violations and data races. However, Rust projects often have  mixed code , i.e., code that also uses unsafe Rust, FFI (Foreign Function Interfaces), and inline assembly for low-level control. The Rust compiler is unable to statically enforce Rust principles in mixed Rust code which can lead to many security vulnerabilities. In this paper, we propose CapsLock, a security enforcement mechanism that can run at the level of machine code and detect Rust principle violations at run-time in mixed code. CapsLock is kept simple enough to be implemented into recent capability-based hardware abstractions that provide low-cost spatial memory safety. CapsLock introduces a novel  revoke-on-use  abstraction for capability-based designs, wherein accessing a memory object via a capability  implicitly  invalidates certain other capabilities pointing to it, thereby also providing temporal memory safety automatically, without requiring software to explicitly specify such invalidation. Thus, CapsLock is the first mechanism capable of providing cross-language enforcement of Rust principles. We implemented a prototype of CapsLock on QEMU. Evaluation results show that CapsLock is highly compatible with existing Rust code (passing 99.7% of the built-in test cases of the 100 most popular crates) and flags Rust principle violations in real-world Rust projects that use FFI or inline assembly. We discovered 8 previously unknown bugs in such crates in our experiments.}
}


@inproceedings{DBLP:conf/ccs/LiuDJWWHWS25,
	author = {Yuwei Liu and
                  Junquan Deng and
                  Xiangkun Jia and
                  Yanhao Wang and
                  Minghua Wang and
                  Lin Huang and
                  Tao Wei and
                  Purui Su},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {PromeFuzz: {A} Knowledge-Driven Approach to Fuzzing Harness Generation
                  with Large Language Models},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {1559--1573},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765222},
	doi = {10.1145/3719027.3765222},
	timestamp = {Fri, 26 Dec 2025 20:53:02 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/LiuDJWWHWS25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {API-level fuzzing has become increasingly important for discovering subtle bugs in modern software, yet generating effective fuzzing harnesses remains a complex and error-prone task. Existing approaches often rely on limited consumer code or shallow program analysis, which fail to capture deep API semantics and interdependencies, resulting in poor coverage and high false positive rates. Recent methods incorporating Large Language Models (LLMs) have improved harness generation by leveraging pretrained knowledge, but they still struggle with hallucinations and lack domain-specific understanding. To address the challenges, we present P rome F uzz,  a knowledge-driven framework for automatic fuzzing harness generation using LLMs. P rome F uzz  constructs a structured knowledge base by combining code metadata, API documentation, and real-world call correlations to enhance the semantic accuracy and coverage of generated harnesses. It further integrates retrieval-augmented generation and a dedicated sanitizer module to refine harness quality and triage crashes. We evaluate P rome F uzz  on 22 open-source projects, demonstrating significant improvements over state-of-the-art tools. Specifically, P rome F uzz  achieves 1.50×, 3.88×, 1.91× and 1.40× higher branch coverage than 3 LLM-based baselines (PromptFuzz, CKGFuzzer and OSS-Fuzz-Gen) and manually crafted harnesses (OSS-Fuzz), respectively. It also discovers more unique crashes with 89.7% precision and uncovers 25 previously unknown vulnerabilities (21 confirmed by the developer and 3 assigned with CVE IDs).}
}


@inproceedings{DBLP:conf/ccs/0001WALR0Z25,
	author = {Meng Shen and
                  Jinhe Wu and
                  Junyu Ai and
                  Qi Li and
                  Chenchen Ren and
                  Ke Xu and
                  Liehuang Zhu},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Swallow: {A} Transfer-Robust Website Fingerprinting Attack via Consistent
                  Feature Learning},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {1574--1588},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744795},
	doi = {10.1145/3719027.3744795},
	timestamp = {Fri, 26 Dec 2025 20:53:02 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/0001WALR0Z25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Website fingerprinting (WF) attacks on Tor networks can analyze traffic patterns to identify the websites Tor users are visiting, and thus pose a significant threat to user privacy. In a real-world environment, Tor users face diverse network conditions and can also employ WF defenses, raising new challenges to launch WF attacks. The state-of-the-art (SOTA) WF attacks either rely on a strong assumption that WF classifiers are trained and deployed under the same network condition, or suffer from significant performance degradation against WF defenses. In this paper, we propose Swallow, a transfer-robust WF attack that can quickly transfer to new network conditions while maintaining robustness against various WF defenses. Specifically, we propose a novel trace representation named Consistent Interaction Feature (CIF), which aligns traffic distributions across different network conditions to capture consistent features. Then we design three data augmentation algorithms to simulate potential variations under various network conditions. We extensively evaluate Swallow using ten datasets, including both self-collected and public datasets. The closed- and open-world evaluation results demonstrate that Swallow significantly outperforms the SOTA attacks. In particular, with only 5 labeled instances per website for model fine-tuning, Swallow achieves an average improvement in accuracy of 17.50% over the SOTA WF attacks.}
}


@inproceedings{DBLP:conf/ccs/HeXWZ0C025,
	author = {Xiaoyu He and
                  Xiaohui Xie and
                  Xin Wang and
                  Lei Zhang and
                  Kun Xie and
                  Lin Chen and
                  Yong Cui},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {FlowSentry: Accelerating NetFlow-based DDoS Detection},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {1589--1603},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744800},
	doi = {10.1145/3719027.3744800},
	timestamp = {Fri, 26 Dec 2025 20:53:02 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/HeXWZ0C025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Distributed Denial of Service (DDoS) attacks threaten the stability of online services by overwhelming them with excessive traffic. NetFlow-based DDoS detection systems are widely adopted by Internet Service Providers (ISPs) in upstream multi-point detection scenarios to provide robust detection for volumetric DDoS attacks. However, these systems face inherent delays, as NetFlow detection is non-instantaneous—routers aggregate and summarize flow records over a period before reporting, which impacts timely detection. Existing research primarily focuses on optimizing the NetFlow reporting mechanism at the router side. Unfortunately, the need for either software or hardware upgrades for routers would incur a high deployment cost, which is impractical for ISPs in the short term. In this paper, we propose FlowSentry, a novel NetFlow detection framework to accelerate DDoS attack identification at the server side. The system operates on a dual-layer filtering paradigm to handle the high-frequency NetFlow records, incorporating two core technologies: ADWindow and STAnalyzer. ADWindow is a sketch-based sliding window mechanism designed to retain possibly anomalous flow information, filtering out benign flows to reduce the computational overhead. STAnalyzer leverages the cross-router traffic correlation to efficiently infer abnormal growth patterns of potential malicious traffic based on partially reported flow records, thus significantly reducing the detection delay. Our extensive experiments in simulated backbone network environments demonstrate that FlowSentry achieves better detection accuracy while reducing the detection delay by up to 65.63% compared to existing methods.}
}


@inproceedings{DBLP:conf/ccs/Miao0WWHWHLJC25,
	author = {Keji Miao and
                  Jie Yuan and
                  Xinghai Wei and
                  Xingwu Wang and
                  Dongqi Han and
                  Haiguang Wang and
                  Runshan Hu and
                  Xiaoyong Li and
                  Zitong Jin and
                  Wenqi Chen},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {1BIT: Persistent Path Validation with Customized Noise Signal Characteristics},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {1604--1618},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744819},
	doi = {10.1145/3719027.3744819},
	timestamp = {Fri, 26 Dec 2025 20:53:02 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/Miao0WWHWHLJC25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Path-aware networks have garnered significant attention as an emerging research area. It allows network senders to actively select or influence transmission paths to meet specific requirements, which necessitates the support of path validation mechanisms. Supported by the path-aware networking research group under the Internet Engineering Task Force (IETF), path validation plays a crucial role in enhancing end hosts' control over packet forwarding. However, existing methods face trade-offs among security, protocol header overhead, and computational cost, forming a ''trilemma.'' Drawing inspiration from persistent validation in zero-trust architecture, we propose the 1BIT protocol. This protocol reduces protocol header overhead by more than 57% while providing robust data flow security. The packet demand for path fault detection is reduced by more than 72%, and fault locations can be precisely identified. By employing hash algorithms and few binary operations, the 1BIT protocol achieves high throughput and supports routers capable of adapting to high-speed, multi-interface environments. On a 16-core CPU, the 1BIT protocol can handle throughput exceeding 100 Gbps. This lightweight and efficient solution introduces anomaly signal detection techniques into the field of path validation. Benefiting from in-depth research on anomaly signal detection, this technology offers a richer set of solutions for path validation and lays the foundation for future research and implementation in areas such as multi-path validation and path privacy protection.}
}


@inproceedings{DBLP:conf/ccs/LiZXMQL0ZDLZF25,
	author = {Xiang Li and
                  Mingming Zhang and
                  Zuyao Xu and
                  Fasheng Miao and
                  Yuqi Qiu and
                  Baojun Liu and
                  Jia Zhang and
                  Xiaofeng Zheng and
                  Haixin Duan and
                  Zheli Liu and
                  Yunhai Zhang and
                  Dunqiu Fan},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {RebirthDay Attack: Reviving {DNS} Cache Poisoning with the Birthday
                  Paradox},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {1619--1633},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744832},
	doi = {10.1145/3719027.3744832},
	timestamp = {Fri, 26 Dec 2025 20:53:02 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/LiZXMQL0ZDLZF25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {DNS cache poisoning is a persistent game of attack and defense, posing an enduring challenge for the DNS community. Significant efforts have been made to uncover, detect, and mitigate vulnerabilities that increase the risk of cache poisoning. However, no work has systematically revisited whether the original cache poisoning attack based on the Birthday Paradox remains effective. In this work, we introduce RebirthDay, a novel DNS cache poisoning attack targeting recursive resolvers and forwarders, reviving the classic DNS Birthday attack that no longer works since 2002. RebirthDay exploits newly uncovered, protocol-compliant vulnerabilities in DNS extension implementations to bypass the query aggregation mechanism intended to prevent DNS Birthday attacks that has not been well understood. We uncovered that 18 out of 22 mainstream DNS software are vulnerable due to weaknesses in the processing of a DNS extension (i.e., ECS option), specifically lacking or incorrectly implemented ECS coherence checks when handling DNS queries and responses, demonstrating the widespread susceptibility to RebirthDay. These flaws could be exploited to circumvent the query aggregation mechanism and launch RebirthDay attacks. Through comprehensive evaluation, we showed that RebirthDay attacks are highly practical and can have significant real-world impact, affecting 16 router vendors, 14 public DNS services, and 365K (15%) open DNS resolvers. We have reported the identified vulnerabilities to affected vendors and discussed mitigation solutions with them. To date, we have received acknowledgments from 8 vendors, including BIND, Unbound, PowerDNS, and Quad9, and have been assigned 50 CVE-ids. Our study emphasizes the need for greater attention to the importance of ECS verification and DNS extension implementations, revealing new security risks introduced by them.}
}


@inproceedings{DBLP:conf/ccs/0070LMGZF025,
	author = {Hui Li and
                  Haotian Li and
                  Chi Ma and
                  Jingjing Guan and
                  Junchi Zeng and
                  Haonan Feng and
                  Ziming Zhao},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {5G-RNAKA : {A} Random Number-based Authentication and Key Agreement
                  Protocol for 5G Systems},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {1634--1648},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744844},
	doi = {10.1145/3719027.3744844},
	timestamp = {Fri, 26 Dec 2025 20:53:02 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/0070LMGZF025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The 5G-AKA protocol, defined by 3GPP for authentication and key agreement in 5G networks, remains vulnerable to linkability, synchronization failure, and Sequence Number ( SQN ) exposure attacks. These issues threaten user privacy and service availability. Existing improvements often retain these flaws or cause high overhead due to continued use of the legacy  SQN  mechanism from 3G. In this paper, we propose 5G-RNAKA, a secure and efficient AKA protocol for 5G systems. Unlike 5G-AKA, 5G-RNAKA eliminates  SQN  counters and instead utilizes random numbers generated by the Universal Subscriber Identity Module (USIM) in 5G User Equipment (UE) for session identification. This random number is embedded in the reply message from the service network (SN) to prevent replay attacks against the UE. Additionally, by removing the  SQN  mechanism, 5G-RNAKA enhances user privacy by preventing attackers from linking challenge-response sessions. It also enables the UE to authenticate the SN, effectively mitigating the risk of SN impersonation. We formally verify that 5G-RNAKA achieves its security goals of privacy, authentication, and secrecy using the state-of-the-art formal verification tool, Tamarin Prover. Our implementation and evaluation further demonstrate that 5G-RNAKA improves communication efficiency and reduces storage overhead. While primarily designed for 5G, 5G-RNAKA's features align with emerging trends in 6G authentication, suggesting its potential for adaptation to future 6G architectures.}
}


@inproceedings{DBLP:conf/ccs/Xu0DL25,
	author = {Xuening Xu and
                  Chenglong Fu and
                  Xiaojiang Du and
                  Bo Luo},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Discovering and Exploiting IoT Device Hidden Attributes: {A} New Vulnerability
                  in Smart Homes},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {1649--1663},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744847},
	doi = {10.1145/3719027.3744847},
	timestamp = {Fri, 26 Dec 2025 20:53:02 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/Xu0DL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the growing popularity and pervasive adoption of smart home Internet of Things (IoT) platforms, IoT security and privacy issues are gaining more attention. In this work, we reveal a new vulnerability inherent in most smart home IoT automation platforms and systems but previously unnoticed by the security community: the  hidden attributes,  i.e., attributes that are configurable by knowledgeable attackers through IoT APIs to effectively change device behaviors, but these attributes are not manageable or observable by users. An IoT device with compromised hidden attributes may behave differently from user expectations and cause severe security and safety consequences (e.g., burglary or fire). We present the root causes of the vulnerability and develop an approach to systematically discover hidden attributes. We evaluate a total of 31 commodity IoT devices of various types from 16 manufacturers and identify hidden attributes in all of them. Furthermore, we select several IoT devices with security and safety-critical hidden attributes and demonstrate the end-to-end hidden attribute attack on two popular IoT platforms: Samsung SmartThings and Amazon Alexa. In addition, we develop a tool that can automatically patch edge drivers and fix the hidden attribute issue. The source code of the auto-patching tool can be found in the https://anonymous.4open.science/r/SmartThings-Edge-Driver-Auto-Patching-49CE/README.md Anonymous GitHub.}
}


@inproceedings{DBLP:conf/ccs/YangL0LLFW25,
	author = {Luming Yang and
                  Lin Liu and
                  Junjie Huang and
                  Zhuotao Liu and
                  Shiyu Liang and
                  Shaojing Fu and
                  Yongjun Wang},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {MM4flow: {A} Pre-trained Multi-modal Model for Versatile Network Traffic
                  Analysis},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {1664--1678},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744804},
	doi = {10.1145/3719027.3744804},
	timestamp = {Fri, 26 Dec 2025 20:53:02 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/YangL0LLFW25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Network traffic analysis is a critical research area, playing an essential role in enhancing network security and ensuring high-quality network services. Existing methods, which primarily rely on a single modality, face two significant limitations. First, while existing approaches may achieve strong performance in specific tasks, they often lack sufficient adaptability for diverse tasks. Second, existing pre-trained models are only trained with GB-scale traffic, with which increases the risk of over-fitting and limiting the models' overall performance. To address these challenges, we propose MM4flow, a pre-trained multi-modal model designed for versatile network traffic analysis. We divide network flows into two modalities: raw byte streams and transmission patterns, which encapsulate the content and behavior information, respectively. MM4flow is composed of two key stages: uni-modal pre-training and multi-modal fine-tuning. We develop an efficient data collection scheme enabling TB-scale traffic pre-training. Leveraging a real-world traffic that exceeds 70 TB, MM4flow conducts uni-modal pre-training on each modality with a modified BERT architecture tailored for network flows. For specific downstream tasks, we introduce a modal fusion module based on cross-attention mechanisms. The fusion module facilitates effective integration of multi-modal information, enabling MM4flow to fully utilize both content and behavior cues during fine-tuning with minimal labeled dataset. We evaluate MM4flow on six public datasets covering six various tasks. Extensive experiments demonstrate that MM4flow achieves superior accuracy than baselines. Especially, compared to existing pre-trained models, MM4flow achieves an 84% improvement in accuracy for website identification under encrypted tunnels. Moreover, the pre-trained MM4flow significantly reduces the reliance on high-quality labeled training data for downstream tasks.}
}


@inproceedings{DBLP:conf/ccs/QiXZM25,
	author = {Tianyu Qi and
                  Lei Xue and
                  Yufeng Zhan and
                  Xiaobo Ma},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Sylva: Tailoring Personalized Adversarial Defense in Pre-trained Models
                  via Collaborative Fine-tuning},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {1679--1693},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744805},
	doi = {10.1145/3719027.3744805},
	timestamp = {Fri, 26 Dec 2025 20:53:02 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/QiXZM25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The growing adoption of large pre-trained models in edge computing has made deploying model inference on mobile clients both practical and popular. These devices are inherently vulnerable to direct adversarial attacks, which pose a substantial threat to the robustness and security of deployed models. Federated adversarial training (FAT) has emerged as an effective solution to enhance model robustness while preserving client privacy. However, FAT frequently produces a generalized global model, which struggles to address the diverse and heterogeneous data distributions across clients, resulting in insufficiently personalized performance, while also encountering substantial communication challenges during the training process. In this paper, we propose  Sylva,  a personalized collaborative adversarial training framework designed to deliver customized defense models for each client through a two-phase process. In Phase 1,  Sylva  employs LoRA for local adversarial fine-tuning, enabling clients to personalize model robustness while drastically reducing communication costs by uploading only LoRA parameters during federated aggregation. In Phase 2, a game-based layer selection strategy is introduced to enhance accuracy on benign data, further refining the personalized model. This approach ensures that each client receives a tailored defense model that balances robustness and accuracy effectively. Extensive experiments on benchmark datasets demonstrate that  Sylva  can achieve up to 50× improvements in communication efficiency compared to state-of-the-art algorithms, while achieving up to 29.5% and 50.4% enhancements in adversarial robustness and benign accuracy, respectively.}
}


@inproceedings{DBLP:conf/ccs/ChenCLLH25,
	author = {Changsheng Chen and
                  Wenyu Chen and
                  Yinyin Lin and
                  Bin Li and
                  Jiwu Huang},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Unmask Tampering: Efficient Document Tampering Localization under
                  Recapturing Attacks with Real Distortion Knowledge},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {1694--1708},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744809},
	doi = {10.1145/3719027.3744809},
	timestamp = {Fri, 26 Dec 2025 20:53:02 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/ChenCLLH25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Document tampering localization (DTL) aims to detect tampering traces and ensure the integrity of document images. However, recapturing attacks (  i.e.,  printing and scanning the altered document images) can effectively conceal tampering traces due to distortions such as halftoning, blurring, and noise. Compounding this challenge, the collection of real recaptured document samples is both time-consuming and resource-intensive. It is important to investigate an efficient method that adapt the existing DTL models to unmask the threat from recapturing attack. In this work, we tackle these challenges by first proposing a Real Halftone-based Document Synthesis (RHSyn) method to generate realistic recaptured document images. RHSyn exploits reference halftone patterns with a novel table look-up operation, which incorporates real-world distortions from printers and scanners to produce high-fidelity synthetic data. To improve DTL performance, we introduce a Masked Parameter-Efficient Fine-Tuning (M-PEFT) technique to facilitate extracting distinctive forensic features from text and background regions under recapturing attacks. In the experiment, we gather two extensive testing datasets comprising over 6,600 real recaptured document images from 9 printers and 7 scanners. Experimental results under recapturing attacks demonstrate that the performances of the existing DTL models are significantly improved with RHSyn-generated data via M-PEFT. Specifically, our approach achieves an average F1-Score of 0.611 across three test datasets, increased by 0.496 compared to models without fine-tuning, demonstrating its capacity to effectively counter the threat of recapturing attacks.}
}


@inproceedings{DBLP:conf/ccs/LvSW0ZC0025,
	author = {Peizhuo Lv and
                  Mengjie Sun and
                  Hao Wang and
                  XiaoFeng Wang and
                  Shengzhi Zhang and
                  Yuxuan Chen and
                  Kai Chen and
                  Limin Sun},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {{RAG-WM:} An Efficient Black-Box Watermarking Approach for Retrieval-Augmented
                  Generation of Large Language Models},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {1709--1723},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744813},
	doi = {10.1145/3719027.3744813},
	timestamp = {Fri, 26 Dec 2025 20:53:02 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/LvSW0ZC0025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent years, tremendous success has been witnessed in Retrieval-Augmented Generation (RAG), widely used to enhance Large Language Models (LLMs) in domain-specific, knowledge-intensive, and privacy-sensitive tasks. However, attackers may steal those valuable RAGs and deploy or commercialize them, making it essential to detect Intellectual Property (IP) infringement. Most existing ownership protection solutions, such as watermarks, are designed for relational databases and texts. They cannot be directly applied to RAGs because relational database watermarks require white-box access to detect IP infringement, which is unrealistic for the knowledge base in RAGs. Meanwhile, post-processing by the adversary's deployed LLMs typically destructs text watermark information. To address those problems, we propose a novel black-box ''knowledge watermark'' approach, named RAG-WM, to detect IP infringement of RAGs. RAG-WM uses a multi-LLM interaction framework, comprising a Watermark Generator, Shadow LLM & RAG, and Watermark Discriminator, to create watermark texts based on watermark entity-relationship tuples and inject them into the target RAG. We evaluate RAG-WM across three domain-specific and two privacy-sensitive tasks on four benchmark LLMs. Experimental results show that RAG-WM effectively detects the stolen RAGs in various deployed LLMs. Furthermore, RAG-WM is robust against paraphrasing, unrelated content removal, knowledge insertion, and knowledge expansion attacks. Lastly, RAG-WM can also evade watermark detection approaches, highlighting its promising application in detecting IP infringement of RAG systems.}
}


@inproceedings{DBLP:conf/ccs/WangZCBKY25,
	author = {Zhiqi Wang and
                  Chengyu Zhang and
                  Yuetian Chen and
                  Nathalie Baracaldo and
                  Swanand Ravindra Kadhe and
                  Lei Yu},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Membership Inference Attacks as Privacy Tools: Reliability, Disparity
                  and Ensemble},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {1724--1738},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744818},
	doi = {10.1145/3719027.3744818},
	timestamp = {Fri, 26 Dec 2025 20:53:02 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/WangZCBKY25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Membership inference attacks (MIAs) pose a significant threat to the privacy of machine learning models and are widely used as tools for privacy assessment, auditing, and machine unlearning. While prior MIA research has primarily focused on performance metrics such as AUC, accuracy, and TPR@low FPR—either by developing new methods to enhance these metrics or using them to evaluate privacy solutions—we found that it overlooks the disparities among different attacks. These disparities, both between distinct attack methods and between multiple instantiations of the same method, have crucial implications for the reliability and completeness of MIAs as privacy evaluation tools. In this paper, we systematically investigate these disparities through a novel framework based on coverage and stability analysis. Extensive experiments reveal significant disparities in MIAs, their potential causes, and their broader implications for privacy evaluation. To address these challenges, we propose an ensemble framework with three distinct strategies to harness the strengths of state-of-the-art MIAs while accounting for their disparities. This framework not only enables the construction of more powerful attacks but also provides a more robust and comprehensive methodology for privacy evaluation.}
}


@inproceedings{DBLP:conf/ccs/Luo0X25,
	author = {Xinjian Luo and
                  Ting Yu and
                  Xiaokui Xiao},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Prompt Inference Attack on Distributed Large Language Model Inference
                  Frameworks},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {1739--1753},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744820},
	doi = {10.1145/3719027.3744820},
	timestamp = {Sun, 07 Dec 2025 22:09:43 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/Luo0X25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The inference process of modern large language models (LLMs) demands prohibitive computational resources, rendering them infeasible for deployment on consumer-grade devices. To address this limitation, recent studies propose distributed LLM inference frameworks, which employ split learning principles to enable collaborative LLM inference on resource-constrained hardware. However, distributing LLM layers across participants requires the transmission of intermediate outputs, which may introduce privacy risks to the original input prompts --- a critical issue that has yet to be thoroughly explored in the literature. In this paper, we rigorously examine the privacy vulnerabilities of distributed LLM inference frameworks by designing and evaluating three prompt inference attacks aimed at reconstructing input prompts from intermediate LLM outputs. These attacks are developed under various query and data constraints to reflect diverse real-world LLM service scenarios. Specifically, the first attack assumes an unlimited query budget and access to an auxiliary dataset sharing the same distribution as the target prompts. The second attack also leverages unlimited queries but uses an auxiliary dataset with a distribution differing from the target prompts. The third attack operates under the most restrictive scenario, with limited query budgets and no auxiliary dataset available. We evaluate these attacks on a range of LLMs, including state-of-the-art models such as Llama-3.2 and Phi-3.5, as well as widely-used models like GPT-2 and BERT for comparative analysis. Our experiments show that the first two attacks achieve reconstruction accuracies exceeding 90%, while the third achieves accuracies typically above 50%, even under stringent constraints. These findings highlight substantial privacy risks in distributed LLM inference frameworks, issuing a strong alert on their deployment in real-world applications. Additionally, our analysis uncovers distinct distributional properties of intermediate embeddings across LLM layers, providing valuable insights into the LLM inference process and the development of effective defense mechanisms for distributed LLM frameworks.}
}


@inproceedings{DBLP:conf/ccs/PollmannT25,
	author = {Daniel P{\"{o}}llmann and
                  Tianxin Tang},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Differentially Private Access in Encrypted Search: Achieving Privacy
                  at a Small Cost?},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {1754--1768},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765038},
	doi = {10.1145/3719027.3765038},
	timestamp = {Sun, 07 Dec 2025 22:09:43 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/PollmannT25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Encrypted search focuses on protecting sensitive data in outsourced environments while enabling private queries. Although standard encrypted search algorithms are efficient, they often leak some information about the queries and data. One such leakage is the access pattern on the outsourced storage. Recent leakage-abuse attacks have exploited this seemingly harmless leakage to successfully recover both queries and data, shifting research priorities towards finding the right balance between privacy and performance. While some proposals leverage oblivious RAM or other oblivious data structures to hide the access pattern, they typically incur significant bandwidth costs. In response, researchers have developed new schemes that ensure access leakage satisfies  differential privacy (DP).  Yet the security implications of these new guarantees remain unclear. Especially, compared with conventional differential privacy, the application and threat model are significantly different. To understand these implications, we investigate two concrete instances of (encrypted) range-query schemes (appeared in SODA '19 and CCS '22) that achieve differentially private access. We analyze their security guarantees using inference attacks to recover queries and data on real-world datasets. Our findings raise a critical concern that ensuring access leakage is differentially private either falls short of providing strong security for the queries and data, diverging from the initial goals, or offers only weak security but at a high efficiency/correctness cost. As part of our analysis, we also propose a generic security definition for DP access, and identify two general techniques for leakage mitigation,  bucketization  and  partitioning,  that may be of independent interest.}
}


@inproceedings{DBLP:conf/ccs/ChakrabartiMMS25,
	author = {Anirban Chakrabarti and
                  Monosij Maitra and
                  Arup Mondal and
                  Kushaz Sehgal},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Silent Threshold Traitor Tracing {\&} Enhancing Mempool Privacy},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {1769--1783},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765099},
	doi = {10.1145/3719027.3765099},
	timestamp = {Fri, 26 Dec 2025 20:53:02 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/ChakrabartiMMS25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The rising commerciality of cryptocurrencies and blockchains in DeFi applications raises the importance of implementing robust methods to protect its regular users against parties with enormous amounts of resources that allows them to balefully influence the market through various Maximal Extractable Value (MEV) strategies. There are typical situations in such scenarios where an end-user may want to hide its transaction details till it has been executed. Ensuring the privacy of pending mempool transactions thus becomes an important goal. To this end, various decentralized versions of threshold encryption (TE) systems have been recently shown particularly effective. In this work we aim to enhance the privacy of such mempool transactions' through a new primitive that we call  silent threshold traitor-tracing  (ST 3 ). In addition to providing a thresholdized decryption facility through a quorum of some  T  parties, ST 3  enables  public  tracing of (at least one) member from such a  malicious  quorum in TE systems (thereby adding accountability to TE), but  without  the presence of any trusted authority. For mempool transactions, such a tracing functionality allows to trace member(s) of a malicious decryption committee who are in-charge of validating pending mempool transactions together. Compared to recent works in this space on silent TE (STE) by Garg et al. (CRYPTO 2024) and threshold traitor-tracing (T 3 ) by Boneh et al. (CRYPTO 2024), ST 3  achieves the best of both worlds: It is endowed with a  silent  setup (like STE) and also allows  public  tracing in a malicious decryption committee ( unlike  T 3 ). Our work resolves two important problems left open by Boneh et al. (CRYPTO 2024). We present two constructions of ST 3 . The first one is a generic compiler whereas the second one is built from the notion of a  distributed predicate encryption with pooled decryption  (DPEPD) -- a primitive we define and build from bilinear pairings, proving its security in the GGM. DPEPD may be of independent interest with applications beyond ST 3 . Our techniques are inspired from two recent works: one is STE (as above) and the other one is a concurrent work of Branco et al. (ASIACRYPT 2024) that builds traitor-tracing (TT) schemes without a trusted authority. Our second ST 3  scheme achieves a  transparent  setup -- a property that is deemed largely beneficial for any practical deployment. Further, both our schemes have sublinear ciphertext sizes  O (√L), where  L  is the number of users in the system at any time. We also benchmark a prototype of the second ST 3  scheme in Go to demonstrate its application in encrypted mempools. Our results showcase the practicality of our schemes: For L= 256 parties with a threshold  T  = ⌊ 2L/3⌋ = 170, encryption, partial decryption, decryption aggregation and tracing algorithms take 166.8 ms, 15.8 ms, 589 ms and 9195 ms respectively with a ciphertext size of 12.57 KB.}
}


@inproceedings{DBLP:conf/ccs/GaoNBT25,
	author = {Jiahui Gao and
                  Son Nguyen and
                  Marina Blanton and
                  Ni Trieu},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {{PULSE:} Parallel Private Set Union for Large-Scale Entities},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {1784--1798},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765108},
	doi = {10.1145/3719027.3765108},
	timestamp = {Fri, 26 Dec 2025 20:53:02 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/GaoNBT25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Multi-party private set union (mPSU) allows multiple parties to compute the union of their private input sets without revealing any additional information. Existing efficient mPSU protocols can be categorized into symmetric key encryption (SKE)-based and public key encryption (PKE)-based approaches. However, neither type of mPSU protocol scales efficiently to a large number of parties, as they fail to fully utilize available computational resources, leaving participants idle during various stages of the protocol execution. This work examines the limitation of existing protocols and proposes a unified framework for designing efficient mPSU protocols. We then introduce an efficient Parallel mPSU for Large-Scale Entities (PULSE) that enables parallel computation, allowing all parties/entities to perform computations without idle time, leading to significant efficiency improvements, particularly as the number of parties increases. Our protocol is based on PKE and secure even when up to  n -1 semi-honest parties are corrupted. We implemented PULSE and compared it to state-of-the-art mPSU protocols under different settings, showing a speedup of 1.91 to 3.57X for  n =8 parties for various set sizes.}
}


@inproceedings{DBLP:conf/ccs/BandarupalliJKL25,
	author = {Akhil Bandarupalli and
                  Xiaoyu Ji and
                  Aniket Kate and
                  Chen{-}Da Liu{-}Zhang and
                  Daniel P{\"{o}}llmann and
                  Yifan Song},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Velox: Scalable Fair Asynchronous {MPC} from Lightweight Cryptography},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {1799--1813},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765114},
	doi = {10.1145/3719027.3765114},
	timestamp = {Fri, 26 Dec 2025 20:53:02 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/BandarupalliJKL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Multi-party computation (MPC) enables a set of mutually  n  distrusting parties to compute any function on their private inputs. Mainly, MPC facilitates agreement on the function's output while preserving the secrecy of honest inputs, even against a subset of  t  parties controlled by an adversary. With applications spanning from anonymous broadcast to private auctions, MPC is considered a cornerstone of distributed cryptography, and significant research efforts have been aimed at making MPC practical in the last decade. However, most libraries either make strong assumptions like the network being bounded synchronous, or incur high computation overhead from the extensive use of expensive public-key operations that prevent them from scaling beyond a few dozen parties. This work presents  Velox,  an asynchronous MPC protocol that offers fairness against an optimal adversary corrupting up to  t  <  n over 3 parties. Velox significantly enhances practicality by leveraging lightweight cryptographic primitives - such as symmetric-key encryption and hash functions - which are 2-3 orders of magnitude faster than public-key operations, resulting in substantial computational efficiency. Moreover, Velox is highly communication-efficient, with linear amortized communication relative to circuit size and only  O  ( n 3 ) field elements of additive overhead. Concretely, Velox requires just 9.33 field elements per party per multiplication gate, more than 10X reduction compared to the state of the art. Moreover, Velox also offers Post-Quantum Security as lightweight cryptographic primitives retain their security against a quantum adversary. We implement Velox comprehensively, covering both offline and online phases, and evaluate its performance on a geographically distributed testbed through a real-world application: anonymous broadcast. Our implementation securely shuffles a batch of  k =256 messages in 4 seconds with n=16 parties and 18 seconds with  n =64 parties, a 36X and 28.6X reduction in latency compared to the prior best work. At scale with  n 112 parties, Velox is able to shuffle the same batch of messages in under 50 seconds from end to end, illustrating its effectiveness and scalability. Overall, our work removes significant barriers faced by prior asynchronous MPC solutions, making asynchronous MPC practical and efficient for large-scale deployments involving 100s of parties.}
}


@inproceedings{DBLP:conf/ccs/AdeiOSV25,
	author = {David Adei and
                  Chris Orsini and
                  Alessandra Scafuro and
                  Tanner Verber},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {How to Recover a Cryptographic Secret From the Cloud},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {1814--1828},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765127},
	doi = {10.1145/3719027.3765127},
	timestamp = {Fri, 26 Dec 2025 20:53:02 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/AdeiOSV25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Clouds have replaced most local backup systems as they offer strong availability and reliability guarantees. Clouds, however, are not (and should not be) used as backup for cryptographic secrets. Cryptographic secrets might control financial assets (e.g., crypto wallets), hence, storing such secrets on the cloud corresponds to sharing ownership of the financial assets with the cloud, and makes the cloud a more attractive target for insider attacks. Can we have the best of the two worlds, where a user, Alice, can conveniently store a copy of her cryptographic secrets on the cloud and she is the only one who can recover them? Can she do so even when she loses her devices and forgets all credentials, while at the same time retaining full ownership of her secrets? In this paper, we provide a cloud-based secret-recovery mechanism using trusted execution environments (TEE) where confidentiality is always guaranteed when Alice has not lost her credentials, even in the presence of a malicious cloud fitted with a TEE. If Alice loses all her credentials, she can still recover her secrets (in most circumstances). This is in contrast with all previous work that relies on the assumption that Alice remembers some authentication secret. We prove our system secure in the Universally Composable framework. Further, we implement our protocols and evaluate their performance.}
}


@inproceedings{DBLP:conf/ccs/ZhouZXTFN00J25,
	author = {Tian Zhou and
                  Fangyu Zheng and
                  Zhuoyu Xie and
                  Wenxu Tang and
                  Guang Fan and
                  Yijing Ning and
                  Yi Bian and
                  Jingqiang Lin and
                  Jiwu Jing},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {ML-Cube: Accelerating Module-Lattice-Based Cryptography using Machine
                  Learning Accelerators with a Memory-Less Design},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {1829--1843},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765130},
	doi = {10.1145/3719027.3765130},
	timestamp = {Fri, 26 Dec 2025 20:53:03 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/ZhouZXTFN00J25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The rapid advancement of AI technologies has led to a dramatic surge in computational demands, driving significant breakthroughs in ML accelerators. The powerful performance of these accelerators has attracted the attention of cryptography researchers, and recent studies have begun to explore their use in accelerating cryptographic operations. However, treating these accelerators as black boxes leads to high latency, and strict concurrency requirements, which hinder their practical deployment. In this paper, we go beyond the black-box treatment of ML accelerators and introduce ML-Cube (ML 3 ), a novel memory-less framework that leverages ML accelerators to implement module-lattice-based PQC, FIPS 203 ML-KEM, and FIPS 204 ML-DSA. The performance benefits of ML-Cube arise from our thorough analysis of ML accelerator internals. Rather than treating the accelerators as black boxes, we dissect their operating mechanisms and design tailored mathematical transformations for cryptographic acceleration. This enables memory-less (I)NTT and polynomial multiplication that minimizes external memory dependencies and reduces latency. We further address the high latency and excessive parallelism demands of traditional SIMT-based implementations by fully parallelizing both ML-KEM and ML-DSA schemes. Our experiments show that our Tensor Core-based (I)NTT achieves a 2.03x--3.56x speedup over a highly-optimized CUDA-core implementation. Moreover, our memory-less polynomial multiplication attains a 10x speedup, and the full ML-KEM reaches up to a 3.58x speedup with only less than one-tenth of the latency compared with SOTA approach (CHES '24). Additionally, our enhanced ML-DSA implementation offers a 30% to 55% throughput improvement over the previous SOTA methods (TDSC '24) under the server-oriented model. Importantly, by confining core computations within registers, our approach inherently mitigates memory disclosure and cache-based side-channel attacks, thereby enhancing overall security.}
}


@inproceedings{DBLP:conf/ccs/CornelissenB25,
	author = {Eric Cornelissen and
                  Musard Balliu},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {NodeShield: Runtime Enforcement of Security-Enhanced SBOMs for Node.js},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {1844--1858},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765136},
	doi = {10.1145/3719027.3765136},
	timestamp = {Sun, 07 Dec 2025 22:09:41 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/CornelissenB25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The software supply chain is an increasingly common attack vector for malicious actors. The Node.js ecosystem has been subject to a wide array of attacks, likely due to its size and prevalence. To counter such attacks, the research community and practitioners have proposed a range of static and dynamic mechanisms, including process- and language-level sandboxing, permission systems, and taint tracking. Drawing on valuable insight from these works, this paper studies a runtime protection mechanism for (the supply chain of) Node.js applications with the ambitious goals of compatibility, automation, minimal overhead, and policy conciseness. Specifically, we design, implement and evaluate NodeShield, a protection mechanism for Node.js that enforces an application's dependency hierarchy and controls access to system resources at runtime. We leverage the up-and-coming SBOM standard as the source of truth for the dependency hierarchy of the application, thus preventing components from stealthily abusing undeclared components. We propose to enhance the SBOM with a notion of capabilities that represents a set of related system resources a component may access. Our proposed SBOM extension, the Capability Bill of Materials or CBOM, records the required capabilities of each component, providing valuable insight into the potential privileged behavior. NodeShield enforces the SBOM and CBOM at runtime via code outlining (as opposed to inlining) with no modifications to the original code or Node.js runtime, thus preventing unexpected, potentially malicious behavior. Our evaluation shows that NodeShield can prevent over 98% out of 67 known supply chain attacks while incurring minimal overhead on servers at less than 1ms per request. We achieve this while maintaining broad compatibility with vanilla Node.js and a concise policy language that consists of at most 7 entries per dependency.}
}


@inproceedings{DBLP:conf/ccs/GautamYSSR25,
	author = {Anuj Gautam and
                  Tarun Kumar Yadav and
                  Garrett Smith and
                  Kent E. Seamons and
                  Scott Ruoti},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Passwords and {FIDO2} Are Meant To Be Secret: {A} Practical Secure
                  Authentication Channel for Web Browsers},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {1859--1873},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765195},
	doi = {10.1145/3719027.3765195},
	timestamp = {Fri, 26 Dec 2025 20:53:03 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/GautamYSSR25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Password managers provide significant security benefits to users. However, malicious client-side scripts and browser extensions can steal passwords after the manager has autofilled them into the web page. In this paper, we extend prior work by Stock and Johns, showing how password autofill can be hardened to prevent these local attacks. We implement our design in the Firefox browser and conduct experiments demonstrating that our defense successfully protects passwords from XSS attacks and malicious extensions. We also show that our implementation is compatible with 97% of the Alexa top 1000 websites. Next, we generalize our design, creating a second defense that prevents recently discovered local attacks against the FIDO2 protocols. We implement this second defense into Firefox, demonstrating that it protects the FIDO2 protocol against XSS attacks and malicious extensions. This defense is compatible with all websites, though it does require a small change (2-3 lines) to web servers implementing FIDO2.}
}


@inproceedings{DBLP:conf/ccs/ZhangLL025,
	author = {Qiyi Zhang and
                  Fengyu Liu and
                  Zihan Lin and
                  Yuan Zhang},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Be Aware of What You Let Pass: Demystifying URL-based Authentication
                  Bypass Vulnerability in Java Web Applications},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {1874--1888},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765199},
	doi = {10.1145/3719027.3765199},
	timestamp = {Fri, 26 Dec 2025 20:53:03 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/ZhangLL025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {URL-based authentication provides a centralized and flexible way to safeguard sensitive resources in Java web applications by enforcing authentication checks based on URL paths. However, inconsistencies in handling flexible routing features (e.g., removing /./) between URL routing and authentication can be exploited to bypass authentication checks, resulting in URL-based Authentication Bypass Vulnerabilities (UABVulns). These vulnerabilities allow attackers to access sensitive resources without authentication, leading to serious security breaches. In this paper, we conduct the first in-depth study of 53 real-world UABVulns in Java web applications. Our study uncovers the root causes of UABVulns and identifies three key findings regarding URL routing, authentication, and sanitization. Guided by these findings, we design and implement UABScan, a static analysis tool that detects UABVulns by matching routing and authentication inconsistencies through pattern-based analysis. We evaluate UABScan on 529 popular Java web applications and successfully report 94 UABVulns across 72 applications, including 35 verified high-risk 0-days. Through manual investigation, UABScan achieves a recall of 87.50% and a precision of 80.00%, and significantly outperforms the state-of-the-art tool. To date, 31 CVE IDs have been assigned.}
}


@inproceedings{DBLP:conf/ccs/ZafarSDK025,
	author = {Ahsan Zafar and
                  Junhua Su and
                  Sohom Datta and
                  Alexandros Kapravelos and
                  Anupam Das},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Same Script, Different Behavior: Characterizing Divergent JavaScript
                  Execution Across Different Device Platforms},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {1889--1903},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765202},
	doi = {10.1145/3719027.3765202},
	timestamp = {Sun, 07 Dec 2025 22:09:45 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/ZafarSDK025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {JavaScript drives dynamic content across modern web platforms, yet differences in browser engines, hardware, and APIs create distinct execution environments on mobile and desktop devices. This divergence raises important concerns about platform-specific tracking, but its scope and impact remain underexplored. In this paper, we present a hybrid analysis of JavaScript execution across mobile and desktop to uncover behavioral differences in how identical code operates. By combining static analysis of script structure with dynamic tracing of runtime behavior, we identify execution path divergences tied to the user's device. Our study shows that 20.6% of scripts on the top 10K Tranco-ranked websites exhibit platform-specific execution. Our tracing algorithm pinpoints the sources of divergence for 92.8% of conditional Web API calls, with 76% involving known fingerprinting APIs and 6% relying on lesser-known but platform-revealing interfaces. We further categorize divergent paths, finding asymmetric tracking patterns: desktop flows are dominated by fingerprinting and bot detection, while mobile flows focus more on behavioral profiling.}
}


@inproceedings{DBLP:conf/ccs/KoscinskiNOFM25,
	author = {Viktoria Koscinski and
                  Mark Nelson and
                  Ahmet Okutan and
                  Robert Falso and
                  Mehdi Mirakhorli},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Conflicting Scores, Confusing Signals: An Empirical Study of Vulnerability
                  Scoring Systems},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {1904--1918},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765210},
	doi = {10.1145/3719027.3765210},
	timestamp = {Thu, 01 Jan 2026 19:11:52 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/KoscinskiNOFM25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Accurately assessing software vulnerabilities is essential for effective prioritization and remediation. While various scoring systems exist to support this task, their differing goals, methodologies and outputs often lead to inconsistent prioritization decisions. This work provides the first large-scale, outcome-linked empirical comparison of four publicly available vulnerability scoring systems: the Common Vulnerability Scoring System (CVSS), the Stakeholder-Specific Vulnerability Categorization (SSVC), the Exploit Prediction Scoring System (EPSS), and the Exploitability Index. We use a dataset of 600 real-world vulnerabilities derived from four months of Microsoft's Patch Tuesday disclosures to investigate the relationships between these scores, evaluate how they support vulnerability management task, how these scores categorize vulnerabilities across triage tiers, and assess their ability to capture the real-world exploitation risk. Our findings reveal significant disparities in how scoring systems rank the same vulnerabilities, with implications for organizations relying on these metrics to make data-driven, risk-based decisions. We provide insights into the alignment and divergence of these systems, highlighting the need for more transparent and consistent exploitability, risk, and severity assessments.}
}


@inproceedings{DBLP:conf/ccs/LachnitK25,
	author = {Simon Lachnit and
                  Ghassan Karame},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {On Hyperparameters and Backdoor-Resistance in Horizontal Federated
                  Learning},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {1919--1933},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765211},
	doi = {10.1145/3719027.3765211},
	timestamp = {Fri, 26 Dec 2025 20:53:03 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/LachnitK25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Horizontal Federated Learning (HFL) is particularly vulnerable to backdoor attacks as adversaries can easily manipulate both the training data and processes to execute sophisticated attacks. In this work, we study the impact of training hyperparameters on the effectiveness of backdoor attacks and defenses in HFL. More specifically, we show both analytically and by means of measurements that the choice of hyperparameters by benign clients does not only influence model accuracy  but also significantly impacts backdoor attack success.  This stands in sharp contrast with the multitude of contributions in the area of HFL security, which often rely on custom ad-hoc hyperparameter choices for benign clients---leading to more pronounced backdoor attack strength and diminished impact of defenses. Our results indicate that properly tuning benign clients' hyperparameters---such as learning rate, batch size, and number of local epochs---can significantly curb the effectiveness of backdoor attacks,  regardless of the malicious clients' settings.  We support this claim with an extensive robustness evaluation of state-of-the-art attack-defense combinations, showing that carefully chosen hyperparameters yield across-the-board improvements in robustness without sacrificing main task accuracy. For example, we show that the 50%-lifespan of the strong A3FL attack can be reduced by 98.6%, respectively---all without using any defense and while incurring only a 2.9 percentage points drop in clean task accuracy.}
}


@inproceedings{DBLP:conf/ccs/0013DGYT25,
	author = {Xiaowei Chen and
                  Verena Distler and
                  Chloe Gordon and
                  Yaxing Yao and
                  Ziwen Teuber},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Empowering Parents to Support Children's Online Security and Privacy:
                  Findings from a Randomized Controlled Trial},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {1934--1948},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765214},
	doi = {10.1145/3719027.3765214},
	timestamp = {Fri, 26 Dec 2025 20:53:03 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/0013DGYT25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the ubiquitous computing society, parenting ''digital natives'' presents unprecedented challenges. Parents often rely on online resources to support and guide their children in security and privacy ( S&P ) related topics. However, the abundance of online resources makes it challenging for parents to find high-quality and relevant resources that align with their S&P needs. Further, the longitudinal development of parental competence and coping strategies in S&P topics remains largely unexplored. We conducted a formative study with 210 U.S. parents of children (M age  = 11.73 years,  SD  = 3.15) to investigate the challenges parents face in educating children about online S&P topics and to inform the design of a remote intervention program (six short videos). In the main study, we evaluated this intervention's efficacy using a 14-week longitudinal randomized controlled trial, which consisted of 201 U.S. parents, with 113 assigned to the control group and 88 to the intervention group. We found that short videos significantly enhanced parents' security awareness and their conversation strategies. Notably, parents who initially exhibited lower levels of these measurements benefited the most from the intervention. Moreover, short videos were effective in enhancing parents' self-efficacy in protecting their children from online risks. This study provides valuable insights into various challenges parents face and respective coping strategies that could be implemented to address S&P concerns in family settings. The design and evaluation of the intervention program serve as a foundation for future S&P researchers and educational stakeholders.}
}


@inproceedings{DBLP:conf/ccs/DorazahiMAR25,
	author = {Mah Jan Dorazahi and
                  Deepthi Mungara and
                  Yasemin Acar and
                  Harshini Sri Ramulu},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Security and Privacy Perceptions of Pakistani Facebook Matrimony Group
                  Users},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {1949--1963},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765221},
	doi = {10.1145/3719027.3765221},
	timestamp = {Fri, 26 Dec 2025 20:53:03 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/DorazahiMAR25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In Pakistan, where dating apps are subject to censorship, Facebook matrimony groups---also referred to as marriage groups---serve as alternative virtual spaces for members to search for potential life partners. To participate in these groups, members often share sensitive personal information such as photos, addresses, and phone numbers, which exposes them to risks such as fraud, blackmail, and identity theft. To better protect users of Facebook matrimony groups, we need to understand aspects related to user safety, such as how users perceive risks, what influences their trust in sharing personal information, and how they navigate security and privacy concerns when seeking potential partners online. In this study, through 23 semi-structured interviews, we explore how Pakistani users of Facebook matrimony groups perceive and navigate risks of sharing personal information, and how cultural norms and expectations influence their behavior in these groups. We find elevated privacy concerns among participants, leading them to share limited personal information and creating mistrust among potential partners. Many also expressed concerns about the authenticity of profiles and major security risks, such as identity theft, harassment, and social judgment. Our work highlights the challenges of safely navigating Facebook matrimony groups in Pakistan and offers recommendations for such as implementing stronger identity verification by group admins, enforcing stricter cybersecurity laws, clear platform guidelines to ensure accountability, and technical feature enhancements---including restricting screenshots, picture downloads, and implementing anonymous chats---to protect user data and build trust.}
}


@inproceedings{DBLP:conf/ccs/GuoYYCS025,
	author = {Zihui Guo and
                  Miaomiao Yuan and
                  Yanqi Yang and
                  Liwei Chen and
                  Gang Shi and
                  Dan Meng},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {DiveFuzz: Enhancing {CPU} Fuzzing via Diverse Instruction Construction},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {1964--1978},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765167},
	doi = {10.1145/3719027.3765167},
	timestamp = {Fri, 26 Dec 2025 20:53:03 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/GuoYYCS025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Comprehensive exploration of the CPU architectural states in fuzzing is akin to generating diverse test cases, which include a reasonable distribution of opcode and diversity in instruction execution results (typically measured through write-back data). However, our analysis of state-of-the-art CPU fuzzers reveals that they exhibit high repetition in write-back data and an imbalanced distribution of opcodes during fuzzing. This paper presents DiveFuzz, which diversifies write-back data by finely controlling the operands of instructions at runtime, coupled with correlated contextual semantics, to generate instruction streams with diverse write-back data and semantic associations. Furthermore, DiveFuzz introduces a novel mutator that monitors the fuzzing process to dynamically adjust opcode distribution and accurately eliminate false positives. Our evaluations show that DiveFuzz significantly increases the diversity of instruction write-back data and achieves a more balanced opcode distribution compared to state-of-the-art fuzzers. Across five common coverage metrics, DiveFuzz achieves coverage 204× faster than DifuzzRTL and 114× faster than Cascade. We evaluated DiveFuzz on four well-known open-source RISC-V CPUs—XiangShan, CVA6, Rocket, and NutShell—uncovering 26 new bugs, 15 of which have CVE identifiers.}
}


@inproceedings{DBLP:conf/ccs/WangHCL025,
	author = {Penghao Wang and
                  Shuo Huai and
                  Yetong Cao and
                  Chao Liu and
                  Jun Luo},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Threat from Windshield: Vehicle Windows as Involuntary Attack Sources
                  on Automotive Voice Assistants},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {1979--1993},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765171},
	doi = {10.1145/3719027.3765171},
	timestamp = {Fri, 26 Dec 2025 20:53:03 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/WangHCL025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As automotive voice assistants (AVAs) become increasingly cen- tral to modern vehicles, their vulnerability to attacks exploiting inaudible sounds should raise security concerns. However, such concerns are often deemed low priority, because it is widely be- lieved that an attacker to AVAs should be strategically positioned inside the concerned vehicle for two main reasons: i) inaudible signals can barely penetrate vehicle hulls and ii) a line-of-sight (LoS) path is needed between the attacker (sound source) and the AVA's microphone. In this paper, we disprove this common belief by proposing ShieldSpear to launch AVA attacks outside vehicle hulls. ShieldSpear exploits a tiny piezo-element placed on the exterior of the windshield to convert it into both a speaker and microphone. While this setting naturally brings the attacking sound source into a vehicle, strategically placing this compactly integrated element may further yield i) covertness (blended into stickers), ii) LoS path to AVA's microphones, and iii) real-time attacking capability dur- ing vehicle motion. To maintain sufficient volume while evading detection, we design novel hardware and signal carriers for deliver- ing attack (voice) commands. Moreover, ShieldSpear leverages the windshield-converted microphone to acquire drivers' voiceprint so as to accurately emulate it in the faked commands. Extensive experiments involving five mainstream vehicles have demonstrated the effectiveness of ShieldSpear by a 90.9% end-to-end success rate in injecting faked voice commands into AVAs.}
}


@inproceedings{DBLP:conf/ccs/KunduNKOGV25,
	author = {Suparna Kundu and
                  Quinten Norga and
                  Angshuman Karmakar and
                  Uttam Kumar Ojha and
                  Anindya Ganguly and
                  Ingrid Verbauwhede},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {mUOV: Masking the Unbalanced Oil and Vinegar Digital Signature Scheme
                  at First- and Higher-Order},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {1994--2008},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765188},
	doi = {10.1145/3719027.3765188},
	timestamp = {Fri, 26 Dec 2025 20:53:03 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/KunduNKOGV25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the recent search for additional post-quantum designs, multivariate quadratic equations (MQE) based designs have been receiving attention due to their small signature sizes. Unbalanced Oil and Vinegar (UOV) is an MQE-based digital signature (DS) scheme proposed over two decades ago. Although the mathematical security of UOV has been thoroughly analyzed, several practical side-channel attacks (SCA) have been shown on UOV based DS schemes. In this work, we perform a thorough analysis to identify the variables in UOV based DS schemes that can be exploited with passive SCA, specifically differential power attacks (DPA). Secondly, we introduce masking as a countermeasure to protect the sensitive components of UOV based schemes. We propose efficient masked gadgets for all the critical operations, including the masked dot-product and matrix-vector multiplication. We show that our gadgets are secure in the  t -probing model through formal proofs, mechanically verified using the  maskVerif  tool. We implemented and demonstrated the practical feasibility of our arbitrary-order masking algorithms for UOV-Ip and UOV-III. We show that the masked signature generation of UOV-Ip performs up to 62% better than ML-DSA-44 and 99% better than Falcon-512. In addition, the security of our implementation is practically validated using the test vector leakage assessment (TVLA) methodology.}
}


@inproceedings{DBLP:conf/ccs/HallyburtonP25,
	author = {R. Spencer Hallyburton and
                  Miroslav Pajic},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Security-Aware Sensor Fusion with {MATE:} the Multi-Agent Trust Estimator},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {2009--2023},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765193},
	doi = {10.1145/3719027.3765193},
	timestamp = {Fri, 26 Dec 2025 20:53:03 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/HallyburtonP25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Sensor fusion in multi-agent systems, including smart cities, often lacks security awareness and is vulnerable to attacks. We propose a security-aware sensor fusion framework that estimates and incorporates probabilistic trust with uncertainty to defend against compromised insider agents. Trust is modeled as a hidden Markov process and updated via Bayesian inference using novel trust pseudomeasurements (PSMs), which map discrepancies between expected and observed sensor data into trust evidence. Trust estimates reweight agent contributions during fusion and identify corrupted information, mitigating the influence of compromised nodes. Our system includes a dynamic field-of-view estimator using LiDAR ray tracing, novel logic for PSM generation, and efficient Bayesian updates with conjugate priors. Evaluated in adversarial scenarios, our method significantly reduces fusion error and accurately detects compromised agents. These results show trust-guided fusion enables resilient situational awareness under attack, making it suitable for adversarial cyber-physical environments.}
}


@inproceedings{DBLP:conf/ccs/Li0LYZJ25,
	author = {Shijia Li and
                  Jiang Ming and
                  Lanqing Liu and
                  Longwei Yang and
                  Ni Zhang and
                  Chunfu Jia},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Adversarially Robust Assembly Language Model for Packed Executables
                  Detection},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {2024--2038},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765157},
	doi = {10.1145/3719027.3765157},
	timestamp = {Fri, 26 Dec 2025 20:53:03 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/Li0LYZJ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Detecting packed executables is a critical component of large-scale malware analysis and antivirus engine workflows, as it identifies samples that warrant computationally intensive dynamic unpacking to reveal concealed malicious behavior. Traditionally, packer detection techniques have relied on empirical features, such as high entropy or specific binary patterns. However, these empirical, feature-based methods are increasingly vulnerable to evasion by adversarial samples or unknown packers (e.g., low-entropy packers). Furthermore, the dependence on expert-crafted features poses challenges in sustaining and evolving these methods over time. In this paper, we examine the limitations of existing packer detection methods and propose  Pack-ALM , a novel deep-learning-based approach for detecting packed executables. Inspired by the linguistic concept of distinguishing between real and pseudo words, we reformulate packer detection as a task of differentiating between legitimate and pseudo instructions. To achieve this, we preprocess native data and packed data into pseudo instructions and design a pre-trained assembly language model that recognizes features indicative of packed data. We evaluate Pack-ALM against leading industrial packer detection tools and state-of-the-art assembly language models. Extensive experiments on over 37,000 samples demonstrate that Pack-ALM effectively identifies packed binaries, including samples created with adversarial or previously unseen packing techniques. Moreover, Pack-ALM outperforms traditional entropy-based methods and advanced assembly language models in both detection accuracy and adversarial robustness.}
}


@inproceedings{DBLP:conf/ccs/ElAtaliGNA25,
	author = {Hossam ElAtali and
                  Merve G{\"{u}}lmez and
                  Thomas Nyman and
                  N. Asokan},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {{BLACKOUT:} Data-Oblivious Computation with Blinded Capabilities},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {2039--2053},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765169},
	doi = {10.1145/3719027.3765169},
	timestamp = {Fri, 26 Dec 2025 20:53:03 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/ElAtaliGNA25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Lack of memory-safety and exposure to side channels are two prominent, persistent challenges for the secure implementation of software. Memory-safe programming languages promise to significantly reduce the prevalence of memory-safety bugs, but make it more difficult to implement side-channel-resistant code. We aim to address both memory-safety and side-channel resistance by augmenting memory-safe hardware with the ability for data-oblivious programming. We describe an extension to the CHERI capability architecture to provide  blinded capabilities  that allow data-oblivious computation to be carried out by userspace tasks. We also present BLACKOUT, our realization of blinded capabilities on a FPGA softcore based on the speculative out-of-order CHERI-Toooba processor and extend the CHERI-enabled Clang/LLVM compiler and the CheriBSD operating system with support for blinded capabilities. BLACKOUT makes writing side-channel-resistant code easier by making non-data-oblivious operations via blinded capabilities explicitly fault. Through rigorous evaluation we show that BLACKOUT ensures memory operated on through blinded capabilities is securely allocated, used, and reclaimed and demonstrate that, in benchmarks comparable to those used by previous work, BLACKOUT imposes only a small performance degradation (1.5% geometric mean) compared to the baseline CHERI-Toooba processor.}
}


@inproceedings{DBLP:conf/ccs/Liu0TZLGP025,
	author = {Haoyi Liu and
                  Feng Dong and
                  Yunpeng Tian and
                  Mu Zhang and
                  Xuefeng Li and
                  Fangming Gu and
                  Zhiniang Peng and
                  Haoyu Wang},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Needle in a Haystack: Automated and Scalable Vulnerability Hunting
                  in the Windows {ALPC} Sea},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {2054--2068},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765180},
	doi = {10.1145/3719027.3765180},
	timestamp = {Fri, 26 Dec 2025 20:53:03 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/Liu0TZLGP025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Windows services utilizing Remote Procedure Call (RPC) and Component Object Model (COM) technology over the underlying Advanced Local Procedure Call (ALPC) transport present a significant attack surface. However, previous research often focused on known vulnerability patterns or required time-consuming reverse engineering, which hinders scalable vulnerability discovery. We developed a tool designed to automate and scale the fuzzing of ALPC communications. It employs a record-and-replay based strategy, capturing live system-wide ALPC traffic and replaying mutated payloads directly at the ALPC layer, thereby overcoming the scalability barrier posed by the manual preparation required with conventional methods. Furthermore, it integrates dedicated detection techniques to identify information leakage vulnerabilities that crash-centric fuzzers often miss. After evaluating various versions of Windows operating systems, we discovered 12 vulnerabilities confirmed by Microsoft, 10 of which have already been assigned CVE numbers.}
}


@inproceedings{DBLP:conf/ccs/Trampert0R025,
	author = {Leon Trampert and
                  Daniel Weber and
                  Christian Rossow and
                  Michael Schwarz},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Styled to Steal: The Overlooked Attack Surface in Email Clients},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {2069--2083},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765189},
	doi = {10.1145/3719027.3765189},
	timestamp = {Fri, 26 Dec 2025 20:53:03 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/Trampert0R025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Email is still a widely used communication medium, particularly in professional contexts. Standards such as OpenPGP and S/MIME offer encryption while maintaining compatibility with existing infrastructure. Within the end-to-end encryption threat model, email servers are untrusted, which creates opportunities for attackers to inject malicious HTML or CSS into encrypted emails---either live during email transport, or by re-sending leaked emails. In this paper, we show that isolation mechanisms in widely used email client software remain inadequate. We present a novel scriptless attack that extracts arbitrary plaintext from encrypted emails using only CSS without requiring JavaScript. Once the email is opened, three benign-looking CSS features — container queries, lazy-loaded web fonts, and contextual font ligatures — map each character of the ciphertext-carried plaintext to a unique network request to the attacker's server. This attack technique can incrementally reconstruct the entire plaintext in a single rendering pass, with no JavaScript, no visual artifacts, and, depending on the configuration, even without any user interaction. The technique differs considerably from prior work: it achieves complete plaintext recovery without script execution, evades state-of-the-art sanitizers such as DOMPurify, and succeeds across multiple browser engines. We demonstrate the severity of this threat on Mozilla Thunderbird and KMail, with end-to-end attacks successfully exfiltrating PGP-encrypted text from an email rendered in the latest version of the respective clients. Furthermore, we show that our technique affects code integrity tools and sanitization techniques reused in software stacks, including Meta's Code Verify. Our findings led to practical mitigations in Thunderbird, as well as a revision of Meta's threat model to include CSS. These results underline the need for robust content isolation in email client software and challenge the assumption that existing mitigations fully prevent encrypted content leakage.}
}


@inproceedings{DBLP:conf/ccs/0001SHC0L0Z25,
	author = {Zihao Li and
                  Zhiyuan Sun and
                  Zheyuan He and
                  Jinzhao Chu and
                  Hao Zhou and
                  Xiapu Luo and
                  Ting Chen and
                  Yinqian Zhang},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Denial of Sequencing Attacks in Ethereum Layer 2 Rollups},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {2084--2098},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765100},
	doi = {10.1145/3719027.3765100},
	timestamp = {Fri, 26 Dec 2025 20:53:03 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/0001SHC0L0Z25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Layer 2 rollups offer promising solutions to address Ethereum's scalability issues. However, the centralized nature of the sequencer in these rollups makes them vulnerable to denial of service attacks, in which adversaries overwhelm the sequencer with invalid transactions that cannot be included in blocks, thereby exhausting its computational resources for transaction processing. To mitigate such threat, layer 2 rollups implement the legality check mechanism to filter out invalid transactions before they reach the sequencer. In this work, we unveil a novel denial of sequencing attack that disrupts the liveness of layer 2 rollups at zero cost by bypassing the legality check. Specifically, our attack enables an adversary to craft malicious invalid transactions that bypass the legality check but are ultimately discarded by the sequencer after execution. As a result, the adversary can exhaust the sequencer's computational resources without incurring any fees. To construct such malicious transactions, we propose two approaches: a side-channel based approach and an incomplete check based approach, both of which rely on underlying vulnerabilities in rollups. Additionally, we investigate two widely used rollups, i.e., Arbitrum and Polygon zkEVM, and uncover four unknown vulnerabilities within them, which can be exploited to launch our attack using the two proposed approaches. Through extensive experiments conducted in a local environment, we demonstrate that all our attack variants, each exploiting distinct vulnerabilities, lead to severe attack effects at zero cost. Moreover, we discuss three feasible mitigations against our attack. At the time of writing, both the vulnerabilities and our attack have been acknowledged by the respective official teams, who have awarded us bug bounties to highlight the severity of our findings.}
}


@inproceedings{DBLP:conf/ccs/LiuLPHL0L00Q25,
	author = {Yizhong Liu and
                  Andi Liu and
                  Zhuocheng Pan and
                  Yuxuan Hu and
                  Jianwei Liu and
                  Song Bian and
                  Yuan Lu and
                  Zhenyu Guan and
                  Dawei Li and
                  Meikang Qiu},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Realizing Corrupted-Shard Tolerance: {A} Sharding Blockchain with
                  Preserving Global Resilience},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {2099--2113},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765132},
	doi = {10.1145/3719027.3765132},
	timestamp = {Fri, 26 Dec 2025 20:53:03 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/LiuLPHL0L00Q25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Blockchain sharding is a promising approach to enhancing scalability by partitioning the network into smaller, parallel shards. However, existing sharding blockchains that rely on Byzantine fault tolerance protocols require large shard sizes to meet strict security thresholds, limiting scalability, while relaxing security parameters can lead to liveness and safety violations. In this work, we present Camael, a secure sharding blockchain that achieves corrupted-shard tolerance through effective detection and processing mechanisms for both liveness and safety violations. Specifically, fake liveness violations forged by malicious nodes are accurately detected via a two-phase reporting and confirmation mechanism, while concealed safety violations are efficiently identified using a lightweight snapshot mechanism. Furthermore, a state determination process ensures overall system consistency. Malicious nodes are precisely identified through a conviction mechanism, which enables the replacement of the targeted nodes and the reconfiguration of the shards. Notably, Camael ensures security while preserving a global fault tolerance of 1/3 and tolerating corrupted shards, with each shard accommodating up to 2/3 malicious nodes. Extensive experiments conducted on 2000 AWS EC2 nodes across 4 regions demonstrate that Camael improves throughput by 3.56 times compared to the baseline (Kronos, NDSS'25), achieving a throughput of 109.3 ktx/sec, while the violation processing requires only 1.64 sec.}
}


@inproceedings{DBLP:conf/ccs/NgMMCBL25,
	author = {Lucien K. L. Ng and
                  Pedro Moreno{-}Sanchez and
                  Mohsen Minaei and
                  Panagiotis Chatzigiannis and
                  Adithya Bhat and
                  Duc Viet Le},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Lite-PoT: Practical Powers-of-Tau Setup Ceremony},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {2114--2128},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765182},
	doi = {10.1145/3719027.3765182},
	timestamp = {Fri, 26 Dec 2025 20:53:03 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/NgMMCBL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Zero-Knowledge Succinct Non-Interactive Argument of Knowledge (zk-SNARK) schemes have gained significant adoption in privacy-preserving applications, in decentralized systems (e.g., blockchain), and in verifiable computation due to their efficiency. However, the most efficient zk-SNARKs often rely on a one-time trusted setup to generate public parameters, often known as the ''Powers of Tau'' (PoT) string. The leakage of the secret parameter τ in the string would allow attackers to generate false proofs, compromising the soundness of all zk-SNARK systems built on it. Prior proposals for decentralized setup ceremonies have utilized blockchain-based smart contracts to allow any party to contribute randomness to τ while also preventing censorship of contributions. For a  d -degree PoT string generated using randomness from  m  contributors, these solutions require a total of  O ( md ) on-chain operations (i.e., in terms of both storage and cryptographic operations). These operations primarily consist of costly group operations, particularly scalar multiplication on pairing curves, which discourage participation and limit the impact of decentralization. In this work, we present Lite-PoT, which includes two key protocols designed to reduce participation costs: ( i ) a fraud-proof protocol to reduce the number of expensive on-chain cryptographic group operations to O(1) per contributor. Our experimental results show that (with one transaction per update) our protocol enables decentralized ceremonies for PoT strings up to a 2 15 -degree (limited by Ethereum's 30M block gas limit), a ≈16× improvement over existing on-chain solutions; ( ii ) a proof aggregation technique that batches m randomness contributions into one on-chain update with only  O ( d ) on-chain operations, independent of  m . This significantly reduces the monetary cost of on-chain updates by  m -fold via amortization.}
}


@inproceedings{DBLP:conf/ccs/CaprettoCAM025,
	author = {Margarita Capretto and
                  Mart{\'{\i}}n Ceresa and
                  Antonio Fern{\'{a}}ndez Anta and
                  Pedro Moreno{-}Sanchez and
                  C{\'{e}}sar S{\'{a}}nchez},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {A Secure Sequencer and Data Availability Committee for Rollups},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {2129--2143},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765187},
	doi = {10.1145/3719027.3765187},
	timestamp = {Sun, 07 Dec 2025 22:09:40 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/CaprettoCAM025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Blockchains face a scalability limitation, partly due to the throughput limitations of consensus protocols, especially when aiming to obtain a high degree of decentralization. Layer 2 Rollups (L2s) are a faster alternative to conventional blockchains. L2s perform most computations offchain using minimally blockchains (L1) under-the-hood to guarantee correctness. A sequencer is a service that receives offchain L2 transaction requests, batches these transactions, and commits compressed or hashed batches to L1. Using hashing needs less L1 space—which is beneficial for gas cost—but requires a data availability committee (DAC) service to translate hashes into their corresponding batches of transaction requests. The behavior of sequencers and DACs influence the evolution of the L2 blockchain, presenting a potential security threat and delaying L2 adoption. We propose in this paper fraud-proof mechanisms, arbitrated by L1 contracts, to detect and generate evidence of dishonest behavior of the sequencer and DAC. We study how these fraud-proofs limit the power of adversaries that control different number of sequencer and DACs members, and provide incentives for their honest behavior. We designed these fraud-proof mechanisms as two player games. Unlike the generic fraud-proofs in current L2s (designed to guarantee the correct execution of transactions), our fraud-proofs are over pre-determined algorithms that verify the properties that determine the correctness of the DAC. Arbitrating over concrete algorithms makes our fraud-proofs more efficient, easier to understand, and simpler to prove correct. We provide as an artifact a mechanization in LEAN4 of our fraud-proof games, including (1) the verified strategies that honest players should play to win all games as well as (2) mechanisms to detect dishonest claims.}
}


@inproceedings{DBLP:conf/ccs/00030CW25,
	author = {Jie Fu and
                  Yuan Hong and
                  Zhili Chen and
                  Wendy Hui Wang},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Safeguarding Graph Neural Networks against Topology Inference Attacks},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {2144--2158},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765173},
	doi = {10.1145/3719027.3765173},
	timestamp = {Fri, 26 Dec 2025 20:53:03 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/00030CW25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graph Neural Networks (GNNs) have emerged as powerful models for learning from graph-structured data. However, their widespread adoption has raised serious privacy concerns. While prior research has primarily focused on edge-level privacy, a critical yet underexplored threat lies in  topology privacy  — the confidentiality of the graph's overall structure. In this work, we present a comprehensive study on topology privacy risks in GNNs, revealing their vulnerability to graph-level inference attacks. To this end, we propose a suite of  Topology Inference Attacks  (TIAs) that can reconstruct the structure of a target training graph using only black-box access to a GNN model. Our findings show that GNNs are highly susceptible to these attacks, and that existing edge-level differential privacy mechanisms are insufficient as they either fail to mitigate the risk or severely compromise model accuracy. To address this challenge, we introduce  Private Graph Reconstruction  (PGR), a novel defense framework designed to protect topology privacy while maintaining model accuracy. PGR is formulated as a bi-level optimization problem, where a synthetic training graph is iteratively generated using meta-gradients, and the GNN model is concurrently updated based on the evolving graph. Extensive experiments demonstrate that PGR significantly reduces topology leakage with minimal impact on model accuracy. Our code and full paper are available at https://github.com/JeffffffFu/PGR.}
}


@inproceedings{DBLP:conf/ccs/DingXSDF25,
	author = {Ruyi Ding and
                  Tianhong Xu and
                  Xinyi Shen and
                  Aidong Adam Ding and
                  Yunsi Fei},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {MoEcho: Exploiting Side-Channel Attacks to Compromise User Privacy
                  in Mixture-of-Experts LLMs},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {2159--2173},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765174},
	doi = {10.1145/3719027.3765174},
	timestamp = {Fri, 26 Dec 2025 20:53:03 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/DingXSDF25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The transformer architecture has become a cornerstone of modern AI, fueling remarkable progress across applications in natural language processing, computer vision, and multi-modal learning. As these models continue to scale explosively for performance, implementation efficiency remains a critical challenge. Mixture-of-Experts (MoE) architectures, selectively activating specialized subnetworks (experts), offer a unique balance between model accuracy and computational cost. However, the adaptive routing in MoE architectures—where input tokens are dynamically directed to specialized experts based on their semantic meaning—inadvertently opens up a new attack surface for privacy breaches. These input-dependent activation patterns leave distinctive temporal and spatial traces in hardware execution, which adversaries could exploit to deduce sensitive user data. In this work, we propose  MoEcho  (MoE-Echo), discovering a side-channel analysis-based attack surface that compromises user privacy on MoE-based systems. Specifically, in MoEcho, we introduce  four novel architectural side-channels  on different computing platforms, including  Cache Occupancy Channels  and  Pageout+Reload  on CPUs, and  Performance Counter  and  TLB Evict+Reload  on GPUs, respectively. Exploiting these vulnerabilities, we propose  four attacks  that effectively breach user privacy in large-language models (LLMs) and vision-language models (VLMs) based on MoE architectures:  Prompt Inference Attack, Response Reconstruction Attack, Visual Inference Attack, and Visual Reconstruction Attack . We evaluate MoEcho on four open-source MoE-based models at different scales, with a specific focus on the DeepSeek architecture. Our end-to-end experiments on both CPU- and GPU-deployed MoE models demonstrate a 99.8% success rate in inferring the patient's private inputs in healthcare records and 92.8% in reconstructing LLM responses. MoEcho is the first run-time architecture-level security analysis of the popular MoE structure common in modern transformers, highlighting a serious security and privacy threat and calling for effective and timely safeguards when harnessing MoE-based models for developing efficient large-scale AI services.}
}


@inproceedings{DBLP:conf/ccs/LeeFWC25,
	author = {De Zhang Lee and
                  Han Fang and
                  Hanyi Wang and
                  Ee{-}Chien Chang},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Removal Attack and Defense on AI-generated Content Latent-based Watermarking},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {2174--2188},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765175},
	doi = {10.1145/3719027.3765175},
	timestamp = {Mon, 24 Nov 2025 15:33:09 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/LeeFWC25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Digital watermarks can be embedded into AI-generated content (AIGC) by initializing the generation process with starting points sampled from a secret distribution. When combined with pseudorandom error-correcting codes, such watermarked outputs can remain indistinguishable from unwatermarked objects, while maintaining robustness under whitenoise. In this paper, we go beyond indistinguishability and investigate security under removal attacks. We demonstrate that indistinguishability alone does not necessarily guarantee resistance to adversarial removal. Specifically, we propose a novel attack that exploits boundary information leaked by the locations of watermarked objects. This attack significantly reduces the distortion required to remove watermarks—by up to a factor of 15 × compared to a baseline whitenoise attack under certain settings. To mitigate such attacks, we introduce a defense mechanism that applies a secret transformation to hide the boundary, and prove that the secret transformation effectively rendering any attacker's perturbations equivalent to those of a naïve whitenoise adversary. Our empirical evaluations, conducted on multiple versions of Stable Diffusion, validate the effectiveness of both the attack and the proposed defense, highlighting the importance of addressing boundary leakage in latent-based watermarking schemes.}
}


@inproceedings{DBLP:conf/ccs/OygenblikVASTS25,
	author = {David Oygenblik and
                  Abhinav Vemulapalli and
                  Animesh Agrawal and
                  Debopam Sanyal and
                  Alexey Tumanov and
                  Brendan Saltaformaggio},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {VillainNet: Targeted Poisoning Attacks Against SuperNets Along the
                  Accuracy-Latency Pareto Frontier},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {2189--2203},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765185},
	doi = {10.1145/3719027.3765185},
	timestamp = {Fri, 26 Dec 2025 20:53:03 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/OygenblikVASTS25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {State-of-the-art (SOTA) weight-shared SuperNets dynamically activate subnetworks at runtime, enabling robust adaptive inference under varying deployment conditions. However, we find that adversaries can take advantage of the unique training and inference paradigms of SuperNets to selectively implant backdoors that activate only within specific subnetworks, remaining dormant across billions of other subnetworks. We present VillainNet (VNET), a novel poisoning methodology that restricts backdoor activation to attacker-chosen subnetworks, tailored either to specific operational scenarios (e.g., specific vehicle speeds or weather conditions) or to specific subnetwork configurations. VNET's core innovation is a novel, distance-aware optimization process that leverages architectural and computational similarity metrics between subnetworks to ensure that backdoor activation does not occur across non-target subnetworks. This forces defenders to confront a dramatically expanded search space for backdoor detection. We show that across two SOTA SuperNets, trained on the CIFAR10 and GTSRB datasets, VNET can achieve attack success rates comparable to traditional poisoning approaches (approximately 99%), while significantly lowering the chances of attack detection, thereby stealthily hiding the attack. Consequently, defenders face increased computational burdens, requiring on average 66 (and up to 250 for highly targeted attacks) sampled subnetworks to detect the attack, implying a roughly 66-fold increase in compute cost required to test the SuperNet for backdoors.}
}


@inproceedings{DBLP:conf/ccs/DangZL25,
	author = {Chengrui Dang and
                  Xv Zhou and
                  Bei Liang},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Efficient Fuzzy {PSI} Based on Prefix Representation},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {2204--2218},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765203},
	doi = {10.1145/3719027.3765203},
	timestamp = {Fri, 26 Dec 2025 20:53:03 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/DangZL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Fuzzy PSI is a variant of PSI, which on input a set of points from the receiver and sender respectively, allows the receiver to learn which of the sender's points lie within a threshold distance δ under a specific distance metric. Baarsen and Pu (EUROCRYPT'24) first proposed efficient fuzzy PSI protocols for general  L p  distances (where  p ∈[1, ∞]) in  d -dimensional space, achieving communication complexity linear in the input size, δ, and 2 d d . However, they leave open the question of whether the prefix technique of Chakraborti et al. (USENIX Security'23) can further reduce the communication complexity of their fuzzy PSI protocols in both low and high dimensions. In this work, we thoroughly explore using the prefix technique to reduce the complexity of fuzzy PSI. First, we propose fuzzy matching protocols for  L∞  and  L p  distances, where the communication complexity is improved from  O (δ  d ) to  O (log δ,  d ) for  L ∞ , and from  O ((δ p ) to O((log δ) d p ) for  L p  distance. By applying our fuzzy matching protocol in conjunction with spatial hashing, we propose fuzzy PSI protocols for low-dimensional space. For high-dimensional space, we present the first fuzzy PSI protocols achieving communication and computation complexity that scales logarithmically in δ and linearly in dimension  d  and input set sizes. We implement our fuzzy PSI protocols and compare them with state-of-the-art protocols. Experimental results demonstrate that our protocols achieve superior performance for large δ: for input size  N =2 8 ,  d  = 5, and δ = 256, our protocol requires 10--36X less running time and 3--4.5X lower communication than existing protocols.}
}


@inproceedings{DBLP:conf/ccs/0001GKP25,
	author = {Yiping Ma and
                  Yue Guo and
                  Harish Karthikeyan and
                  Antigoni Polychroniadou},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Armadillo: Robust Single-Server Secure Aggregation for Federated Learning
                  with Input Validation},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {2219--2233},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765216},
	doi = {10.1145/3719027.3765216},
	timestamp = {Fri, 26 Dec 2025 20:53:03 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/0001GKP25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper presents a secure aggregation system Armadillo that has disruptive resistance against adversarial clients, such that any coalition of malicious clients can affect the aggregation result only by misreporting their private inputs in a pre-defined legitimate range. Armadillo is designed for federated learning setting, where a single powerful server interacts with many weak clients iteratively to train models on client's private data. While a few prior works consider disruption resistance under such setting, for an aggregation on  n  clients they either require high cost per client (Chowdhury et al. CCS '22) or concretely many rounds that is logarithmic in  n  (Bell et al. USENIX Security '23). Although disruption resistance can be achieved generically with zero-knowledge proof techniques (which we also use in this paper), we realize an efficient system with two new designs: 1) a simple two-layer secure aggregation protocol that requires only simple arithmetic computation; 2) an agreement protocol that removes the effect of malicious clients from the aggregation with low round complexity. With these techniques, Armadillo runs in 3 rounds per aggregation (our round complexity is independent of  n ) with computationally lightweight server and clients.}
}


@inproceedings{DBLP:conf/ccs/MendaBHLR25,
	author = {Sanketh Menda and
                  Mihir Bellare and
                  Viet Tung Hoang and
                  Julia Len and
                  Thomas Ristenpart},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {The {OCH} Authenticated Encryption Scheme},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {2234--2248},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765224},
	doi = {10.1145/3719027.3765224},
	timestamp = {Fri, 26 Dec 2025 20:53:03 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/MendaBHLR25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We specify OCH, the first authenticated encryption with associated data scheme built to provide 128-bit multi-user AE security, 128-bit context commitment security, and 256-bit nonces with optional nonce privacy. It therefore addresses pressing limitations of currently widely-deployed schemes. We construct and formally analyze the security of OCH in a modular fashion, with transforms that are of broader applicability. On Intel Raptor Lake CPUs, OCH using the Areion permutation family has a peak encryption speed of 0.62 cycles per byte (cpb), not far off from AES128-GCM (0.38cpb) and outperforming both ChaCha20/Poly1305 (1.63cpb) and TurboSHAKE128-Wrap (3.52cpb).}
}


@inproceedings{DBLP:conf/ccs/DoernerHIM25,
	author = {Jack Doerner and
                  Iftach Haitner and
                  Yuval Ishai and
                  Nikolaos Makriyannis},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {From {OT} to {OLE} with Subquadratic Communication},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {2249--2263},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765225},
	doi = {10.1145/3719027.3765225},
	timestamp = {Fri, 26 Dec 2025 20:53:03 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/DoernerHIM25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Oblivious Linear Evaluation (OLE) is an algebraic generalization of oblivious transfer (OT) that forms a critical part of a growing number of applications. An OLE protocol over a modulus  q  enables the  receiver  party to securely evaluate a line  a ⋅  X + b  chosen by the  sender  party on a secret point  x ∈ ℤ q . Motivated by the big efficiency gap between OLE and OT and by fast OT extension techniques, we revisit the question of  reducing  OLE to OT, aiming to improve the communication cost of known reductions. We start by observing that the Chinese Remainder Theorem (CRT) can be combined with a prior protocol of Gilboa (Crypto '99) to reduce its communication cost from  O (ℓ 2 ) to Õ(ℓ) bits, for ℓ=log  q . Unfortunately, whereas Gilboa's protocol is secure against a semi-honest sender and a malicious receiver, a direct application of the CRT technique is only semi-honest secure (it is insecure against malicious receivers). Thus, we employ number-theoretic techniques to protect our CRT-based protocol against malicious receivers, while still retaining a concrete advantage over Gilboa's protocol (e.g., 10.2X less communication for ℓ=256). Furthermore, we obtain a fully malicious OLE-to-OT reduction by applying either information-theoretic techniques with moderate overhead, or RSA-based cryptographic techniques with very low overhead. We demonstrate the usefulness of our results in the context of OLE applications, including a post-quantum oblivious pseudorandom function (OPRF) and distributed signatures. In particular, assuming pre-existing random OT correlations, we can use our malicious-receiver OLE protocol to realize (a single instance of) the power-residue based OPRF candidate with security against a malicious client and a semi-honest server using only 1.14 KB of communication, a 16X improvement over the best previous protocol in this setting. Using our RSA-based fully malicious OLE protocol, we achieve a 5X communication improvement over previous OT and EC-based distributed ECDSA protocols. Compared to other ECDSA protocols (including ones that use Paillier and class groups), the communication gains are more modest, but come at only a fraction of the computational cost as we avoid all expensive group operations.}
}


@inproceedings{DBLP:conf/ccs/PerezRL25,
	author = {Carolina Ortega P{\'{e}}rez and
                  Thomas Ristenpart and
                  Julia Len},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Interoperable Symmetric Message Franking},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {2264--2278},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744864},
	doi = {10.1145/3719027.3744864},
	timestamp = {Fri, 26 Dec 2025 20:53:03 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/PerezRL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The recent Digital Markets Act (DMA), a regulation passed by the European Union in 2022, requires messaging applications with large user bases to support interoperable end-to-end encrypted (E2EE) communication. This raises numerous questions about how to adapt cryptographic protocols to this setting in a way that preserves security and privacy. This question is not only limited to the main messaging protocols, but also extends to protocols for abuse mitigation such as the symmetric message franking protocol first proposed by Facebook. The latter uses symmetric cryptography to enable reporting abusive E2EE messages in a way that allows the platform to cryptographically verify the report's veracity. In this paper, we initiate a formal treatment of interoperable symmetric message franking (IMF). We focus on a server-to-server messaging flow, where messages are routed sequentially through the sender's and recipient's service providers, but allow the recipient to dynamically choose who to send a report to. We formalize the security definitions for IMF including adapting the sender and recipient binding definitions into various reportability and unforgeability definitions that take into account one of the service providers misbehaving. We also prove relations among these new definitions. Finally, we detail an IMF construction that satisfies the security definitions, and include a discussion of users' identity privacy goals and deployment considerations.}
}


@inproceedings{DBLP:conf/ccs/LiWZ0LY25,
	author = {Lichun Li and
                  Zecheng Wu and
                  Yuan Zhao and
                  Zhihao Li and
                  Wen{-}jie Lu and
                  Shan Yin},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Gibbon: Faster Secure Two-party Training of Gradient Boosting Decision
                  Tree},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {2279--2293},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744866},
	doi = {10.1145/3719027.3744866},
	timestamp = {Fri, 26 Dec 2025 20:53:03 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/LiWZ0LY25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Gradient Boosting Decision Tree (GBDT) and its variants are widely used in industry. They have achieved remarkable success in numerous machine learning competitions and practical applications. Secure Multi-Party Computation (MPC) allows multiple data owners to compute a function jointly while keeping their input private. In this work, we present Gibbon, a secure two-party GBDT training framework on a vertically split dataset, where two data owners each hold different features of the same data samples. Compared with the state-of-the-art Squirrel (USENIX'Sec 2023), for most parameter settings, Gibbon achieves 2×-4× reduction in running time and 2×-3× reduction in communication. Gibbon achieves its impressive performance through a series of innovative co-designs of the GBDT algorithms and advanced cryptography. Specifically, 1) we optimize the GBDT algorithm to eliminate the majority of MPC-unfriendly inversion operations. 2) We propose a novel protocol to evaluate the MPC-unfriendly sigmoid function, demonstrating 13× communication reduction compared to Squirrel's sigmoid protocol. 3) Using RLWE-based and MLWE-based homomorphic encryption, we propose a highly efficient binary matrix multiplication protocol tailored for GBDT training. Our empirical results show that our protocol is about two orders of magnitude faster than Squirrel's.}
}


@inproceedings{DBLP:conf/ccs/TruongMS0P25,
	author = {Kien Tuong Truong and
                  Simon{-}Philipp Merz and
                  Matteo Scarlata and
                  Felix G{\"{u}}nther and
                  Kenneth G. Paterson},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Breaking and Fixing Content-Defined Chunking},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {2294--2308},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744870},
	doi = {10.1145/3719027.3744870},
	timestamp = {Sun, 07 Dec 2025 22:09:45 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/TruongMS0P25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Content-defined chunking (CDC) algorithms split streams of data into smaller blocks, called chunks, in a way that preserves chunk boundaries when the data is partially changed. CDC is ubiquitous in applications that deduplicate data such as backup solutions, software patching systems, and file hosting platforms. Much like compression, CDC can introduce leakage when combined with encryption: fingerprinting attacks can exploit chunk length patterns to infer information about the data. To address these risks, many systems---mainly in the cloud backup setting---have developed bespoke mitigations by mixing a cryptographic key into the chunking process. We study these keyed CDC (KCDC) schemes ''in the wild'', presenting efficient key recovery attacks against five different KCDC schemes, deployed in the backup solutions Borg, Bupstash, Duplicacy, Restic, and Tarsnap. Our attacks are in a realistic threat model that relies only on weak known- or chosen-plaintext capabilities. This shows, in particular, that they fail to protect against fingerprinting attacks. To demonstrate practical exploitability, we also present ''end-to-end'' attacks on three complete encrypted backup applications, namely Borg, Restic and Tarsnap. These build on our attacks on the underlying KCDC schemes. In an effort to tackle these problems, we introduce the first formal treatment for KCDC schemes and propose a provably secure construction that fulfills a strong notion of security. We benchmark our construction against existing (broken) approaches, showing that it has competitive performance. In doing so, we take a step towards making real-world systems that rely on KCDC more resilient to attacks.}
}


@inproceedings{DBLP:conf/ccs/WangHSLC0025,
	author = {Ruida Wang and
                  Jincheol Ha and
                  Xuan Shen and
                  Xianhui Lu and
                  Chunling Chen and
                  Kunpeng Wang and
                  Jooyoung Lee},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Refined {TFHE} Leveled Homomorphic Evaluation and Its Application},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {2309--2323},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744873},
	doi = {10.1145/3719027.3744873},
	timestamp = {Fri, 26 Dec 2025 20:53:03 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/WangHSLC0025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {TFHE is a fully homomorphic encryption scheme over the torus that supports fast bootstrapping. Its primary evaluation mechanism is based on gate bootstrapping and programmable bootstrapping (PBS), which computes functions while simultaneously refreshing noise. PBS-based evaluation is user-friendly and efficient for small circuits; however, the number of bootstrapping operations increases exponentially with the circuit depth. To address the challenge of efficiently evaluating large-scale circuits, Chillotti et al. introduced a leveled homomorphic evaluation (LHE) mode at Asiacrypt 2017. This mode decouples circuit evaluation from bootstrapping, resulting in a speedup of hundreds of times over PBS-based methods. However, the remaining circuit bootstrapping (CBS) becomes a performance bottleneck, even though its frequency is linear with the circuit depth. In this paper, we refine the LHE mode by mitigating the high cost of CBS. First, we patch the NTT-based CBS algorithm proposed by Wang et al. [WWL+, Eurocrypt 2024], accelerating their algorithm by up to 2.6×. Then, observing the suboptimal parallelism and high complexity of modular reduction in NTT under CBS parameters, we extend WWL+ to an FFT-based algorithm by redesigning the pre-processing method and introducing a split FFT technique. This achieves the fastest CBS implementation with the smallest key size, outperforming the open-source WWL+ implementation by up to 12.1× (resp. 5.12× compared to our patched algorithm), and surpassing TFHEpp [MBM+, USENIX 2021] by 3.42× with a key size reduction of 33.2×. Furthermore, we proposed an improved integer input LHE mode by extending our CBS algorithm to support higher precision and combining it with additional optimizations such as multi-bit extraction. Compared to the previous integer input LHE mode proposed by Bergerat et al. [BBB+, JoC 2023], our approach is up to 10.7× faster with a key size reduction of up to 4.4×. To demonstrate the practicality of our improved LHE mode, we apply it to AES transciphering and general homomorphic look-up table (LUT) evaluation. For AES evaluation, our method is 4.8× faster and reduces the key size by 31.3× compared to the state-of-the-art method, Thunderbird [WLW+, TCHES 2024]. For LUT evaluation, we compare our results with the recent work of Trama et al. [TCBS, ePrint 2024/1201], which constructs a general 8-bit processor of TFHE. Our method not only achieves faster 8-to-8 LUT evaluation but also improves the efficiency of most heavy 8-bit bivariate instructions by up to 21× and the 16-bit sigmoid function by more than 26×.}
}


@inproceedings{DBLP:conf/ccs/BhattacharyyaBF25,
	author = {Rishiraj Bhattacharyya and
                  Jan Bormet and
                  Sebastian Faust and
                  Pratyay Mukherjee and
                  Hussien Othman},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {CCA-Secure Traceable Threshold (ID-based) Encryption and Application},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {2324--2338},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744876},
	doi = {10.1145/3719027.3744876},
	timestamp = {Fri, 26 Dec 2025 20:53:03 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/BhattacharyyaBF25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A recent work by Boneh, Partap, and Rotem [Crypto'24] introduced the concept of traceable threshold encryption, in that if  t  or more parties collude to construct a decryption box, which performs decryptions, then at least one party's identity can be traced by making a few black-box queries to the box. This has important applications, e.g., in blockchain mempool privacy, where collusion yields high financial gain through MEVs without any consequence -- the possibility of tracing discourages collusion. Nevertheless, their definitions leave room for exploitation as they only achieve CPA security and do not consider inconsistency in decryption via different participating sets. This paper proposes stronger definitions of traceable threshold encryption, which supports CCA-security and consistency. Our main approach considers identity-based variants of traceable encryption (which we also define). It converts that to a CCA-secure construction, adapting two generic transformations, first using a one-time signature and then a fingerprinting code. We put forward two efficient instantiations of our identity-based scheme with different merits: our first construction is based on Boneh-Franklin IBE [Crypto'01] and has constant size ciphertexts but quadratic size public keys -- this is proven secure based on XDH and BDDH. Our second construction is based on Boneh-Boyen IBE [Eurocrypt'04]. It supports both constant-size ciphertexts and constant-size public keys -- this is proven secure based on a variant of the uber assumption over bilinear pairings. Our concrete analysis shows that the first construction's ciphertext is much (~6x) smaller than the second construction. Finally, we extend the definitions to support consistency and achieve it by adjoining an efficient, non-interactive proof of correct encryption.}
}


@inproceedings{DBLP:conf/ccs/ZyskindZLP25,
	author = {Guy Zyskind and
                  Doron Zarchy and
                  Max Leibovich and
                  Chris Peikert},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {High-Throughput Universally Composable Threshold {FHE} Decryption},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {2339--2353},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744884},
	doi = {10.1145/3719027.3744884},
	timestamp = {Fri, 26 Dec 2025 20:53:03 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/ZyskindZLP25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Threshold Fully Homomorphic Encryption (FHE) enables arbitrary computation on encrypted data, while distributing the decryption capability across multiple parties. A primary application of interest is low-communication multi-party computation (MPC), which benefits from a fast and secure threshold FHE decryption protocol. Several works have addressed this problem, but all existing solutions rely on ''noise flooding'' for security. This incurs significant overhead and necessitates large parameters in practice, making it unsuitable for many real-world deployments. Some constructions have somewhat better efficiency, but at the cost of weaker, non-simulation-based security definitions, which limits their usability and composability. In this work, we propose a novel threshold FHE decryption protocol that avoids ''noise flooding'' altogether, and provides strong simulation-based security. Rather than masking the underlying ciphertext noise, our technique securely removes it via an efficient MPC rounding procedure. The cost of this MPC is mitigated by an offline/online design that preprocesses special gates for secure comparisons in the offline phase, and has low communication and computation in the online phase. This approach is of independent interest, and should also benefit other MPC protocols (e.g., secure machine learning) that make heavy use of non-linear comparison operations. We prove our protocol secure in the Universal Composability (UC) framework, and it can be generally instantiated for a variety of adversary models (e.g., security-with-abort against a dishonest majority, or guaranteed output delivery with honest majority). Compared to the state of the art, our protocol offers significant gains both in the adversary model (i.e., dishonest vs. honest majority) and practical performance: empirically, our online phase obtains approximately 20,000× better throughput, and up to a 37× improvement in latency.}
}


@inproceedings{DBLP:conf/ccs/Xu0H25,
	author = {Shuangqing Xu and
                  Yifeng Zheng and
                  Zhongyun Hua},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Harnessing Sparsification in Federated Learning: {A} Secure, Efficient,
                  and Differentially Private Realization},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {2354--2368},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765044},
	doi = {10.1145/3719027.3765044},
	timestamp = {Fri, 26 Dec 2025 20:53:03 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/Xu0H25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated learning (FL) enables multiple clients to jointly train a model by sharing only gradient updates for aggregation instead of raw data. Due to the transmission of very high-dimensional gradient updates from many clients, FL is known to suffer from a communication bottleneck. Meanwhile, the gradients shared by clients as well as the trained model may also be exploited for inferring private local datasets, making privacy still a critical concern in FL. We present Clover, a novel system framework for communication-efficient, secure, and differentially private FL. To tackle the communication bottleneck in FL,  Clover  follows a standard and commonly used approach---top- k  gradient sparsification, where each client sparsifies its gradient update such that only  k  largest gradients (measured by magnitude) are preserved for aggregation.  Clover  provides a tailored mechanism built out of a trending distributed trust setting involving three servers, which allows to efficiently aggregate multiple sparse vectors (top- k  sparsified gradient updates) into a dense vector while hiding the values and indices of non-zero elements in each sparse vector. This mechanism outperforms a baseline built on the general distributed ORAM technique by several orders of magnitude in server-side communication and runtime, with also smaller client communication cost. We further integrate this mechanism with a lightweight distributed noise generation mechanism to offer differential privacy (DP) guarantees on the trained model. To harden  Clover  with security against a malicious server, we devise a series of lightweight mechanisms for integrity checks on the server-side computation. Extensive experiments show that  Clover  can achieve utility comparable to vanilla FL with central DP and no use of top- k  sparsification. Meanwhile, achieving malicious security introduces negligible overhead in client-server communication, and only modest overhead in server-side communication and runtime, compared to the semi-honest security counterpart.}
}


@inproceedings{DBLP:conf/ccs/Fang025,
	author = {Juanru Fang and
                  Ke Yi},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Counting Subgraphs under Shuffle Differential Privacy},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {2369--2383},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765047},
	doi = {10.1145/3719027.3765047},
	timestamp = {Sun, 07 Dec 2025 22:09:41 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/Fang025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {To understand the complex structures and relationships in graph data while safeguarding personal privacy, subgraph counting under differential privacy (DP) has received a lot of attention recently. The problem is particularly important in a distributed setting, where each node holds only its local neighboring information and the analyst is untrusted. In the literature, two DP models are tailored for this scenario, known as local DP and shuffle DP, whereas the latter is equipped with a trusted shuffler that random shuffles the messages before handing them to the analyst. Since the shuffler introduces no additional privacy risk, any local DP protocol automatically satisfies shuffle DP, and the key question is whether shuffle DP can offer any improvement, especially for utility. While positive results have been obtained for a number of basic problems, such as basic counting, frequency estimation, and distinct count, it still remains elusive if this is the case for any graph problem. In this paper, we advance the understanding of this question by presenting new shuffle DP protocols for counting various subgraphs, including triangles, 4-cycles, and 3-hop paths, which improve upon the existing local DP and shuffle DP protocols, both asymptotically and concretely.}
}


@inproceedings{DBLP:conf/ccs/ChaudhuriC25,
	author = {Syomantak Chaudhuri and
                  Thomas A. Courtade},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Managing Correlations in Data and Privacy Demand},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {2384--2398},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765048},
	doi = {10.1145/3719027.3765048},
	timestamp = {Fri, 26 Dec 2025 20:53:03 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/ChaudhuriC25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Previous works in the differential privacy literature that allow users to choose their privacy levels typically operate under the heterogeneous differential privacy (HDP) framework with the simplifying assumption that user data and privacy levels are not correlated. Firstly, we demonstrate that the standard HDP framework falls short when user data and privacy demands are allowed to be correlated. Secondly, to address this shortcoming, we propose an alternate framework, Add-remove Heterogeneous Differential Privacy (AHDP), that jointly accounts for user data and privacy preference. We show that AHDP is robust to possible correlations between data and privacy. Thirdly, we formalize the guarantees of the proposed AHDP framework through an operational hypothesis testing perspective. The hypothesis testing setup may be of independent interest in analyzing other privacy frameworks as well. Fourthly, we show that there exists non-trivial AHDP mechanisms that notably do not require prior knowledge of the data-privacy correlations. We propose some such mechanisms and apply them to core statistical tasks such as mean estimation, frequency estimation, and linear regression. The proposed mechanisms are simple to implement with minimal assumptions and modeling requirements, making them attractive for real-world use. Finally, we empirically evaluate proposed AHDP mechanisms, highlighting their trade-offs using LLM-generated synthetic datasets, which we release for future research.}
}


@inproceedings{DBLP:conf/ccs/TodtMS25,
	author = {Julian Todt and
                  Felix Morsbach and
                  Thorsten Strufe},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {BFId: Identity Inference Attacks Utilizing Beamforming Feedback Information},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {2399--2413},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765062},
	doi = {10.1145/3719027.3765062},
	timestamp = {Fri, 26 Dec 2025 20:53:03 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/TodtMS25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Beamforming, as introduced in WiFi 5, requires clients to broadcast observations of their channel characteristics. This introduces a new information source for WiFi sensing with privacy threats that have not been explored, so far. With WiFi networks being ubiquitous in our everyday lives, the impact of unknown privacy threats is likely severe. To investigate this concern, we introduce BFId, the first identity inference attack using BFI-based sensing and evaluate its efficacy on a novel dataset containing WiFi recordings of 197 individuals. We show that we can infer the identity of individuals with very high accuracy, across different walking styles and perspectives, even with large sample sizes.}
}


@inproceedings{DBLP:conf/ccs/0002L25,
	author = {Yuntao Du and
                  Ninghui Li},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Systematic Assessment of Tabular Data Synthesis},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {2414--2428},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765067},
	doi = {10.1145/3719027.3765067},
	timestamp = {Sun, 07 Dec 2025 22:09:39 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/0002L25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Data synthesis has been advocated as an important approach for utilizing data while protecting data privacy. In recent years, a plethora of tabular data synthesis algorithms (i.e., synthesizers) have been proposed. Some synthesizers satisfy Differential Privacy, while others aim to provide privacy in a heuristic fashion. A comprehensive understanding of the strengths and weaknesses of these synthesizers remains elusive due to drawbacks in evaluation metrics and missing head-to-head comparisons of newly developed synthesizers that take advantage of diffusion models and large language models with state-of-the-art statistical synthesizers. In this paper, we present a systematic evaluation framework for assessing tabular data synthesis algorithms. Specifically, we examine and critique existing evaluation metrics, and introduce a set of new metrics in terms of fidelity, privacy, and utility to address their limitations. We conducted extensive evaluations of 8 different types of synthesizers on 12 real-world datasets and identified some interesting findings, which offer new directions for privacy-preserving data synthesis.}
}


@inproceedings{DBLP:conf/ccs/Nie00CYCL25,
	author = {Hao Nie and
                  Wei Wang and
                  Peng Xu and
                  Wei Chen and
                  Laurence T. Yang and
                  Mauro Conti and
                  Kaitai Liang},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Peekaboo, {I} See Your Queries: Passive Attacks Against {DSSE} Via
                  Intermittent Observations},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {2429--2443},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765075},
	doi = {10.1145/3719027.3765075},
	timestamp = {Fri, 26 Dec 2025 20:53:03 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/Nie00CYCL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Dynamic Searchable Symmetric Encryption (DSSE) allows secure searches over a dynamic encrypted database but suffers from inherent information leakage. Existing passive attacks against DSSE rely on persistent leakage monitoring to infer leakage patterns, whereas this work targets intermittent observation - a more practical threat model. We propose Peekaboo - a new universal attack framework - and the core design relies on inferring the search pattern and further combining it with auxiliary knowledge and other leakage. We instantiate Peekaboo over the SOTA attacks, Sap (USENIX' 21) and Jigsaw (USENIX' 24), to derive their ''+'' variants (Sap+ and Jigsaw+). Extensive experiments demonstrate that our design achieves >0.9 adjusted rand index for search pattern recovery and ∼90% query accuracy vs. FMA's ∼30% (CCS' 23). Peekaboo's accuracy scales with observation rounds and the number of observed queries but also it resists SOTA countermeasures, with >40% accuracy against file size padding and >80% against obfuscation.}
}


@inproceedings{DBLP:conf/ccs/Bouma-SimsLC25,
	author = {Elijah Robert Bouma{-}Sims and
                  Mandy Lanyon and
                  Lorrie Faith Cranor},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {'Is this a scam?': The Nature and Quality of Reddit Discussion about
                  Scams},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {2444--2458},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765030},
	doi = {10.1145/3719027.3765030},
	timestamp = {Sun, 07 Dec 2025 22:09:40 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/Bouma-SimsLC25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {People often use social media platforms to seek advice about scams like ecommerce fraud or phishing; however, little research has investigated the nature of such discussion. We conducted a multi-stage thematic analysis of 1,525 posts made to four communities focused on scam discussion on Reddit, primarily from /r/Scams. We found that posters use Reddit to identify scams, discuss the strategies employed by scammers, and obtain advice on coping with victimization. The scams discussed are primarily mediated by the internet or related technologies. Users in the communities we studied especially provide informational support and reassurance to victims, although some comments reinforce victim-blaming attitudes. We also observed qualitative differences in the types of support sought and given based on the community, with the board /r/Sextortion especially being used for emotional support. We conclude that Reddit's scam discussion communities serve as a valuable resource for scam prevention and remediation. Additionally, we discuss the potential for future research and law enforcement engagement on Reddit.}
}


@inproceedings{DBLP:conf/ccs/SchmidtSW25,
	author = {David Schmidt and
                  Sebastian Schrittwieser and
                  Edgar R. Weippl},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Leaky Apps: Large-scale Analysis of Secrets Distributed in Android
                  and iOS Apps},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {2459--2473},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765033},
	doi = {10.1145/3719027.3765033},
	timestamp = {Fri, 26 Dec 2025 20:53:03 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/SchmidtSW25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Mobile apps store various types of secrets to support their functionalities. These include API keys, and cryptographic material to authenticate users and access backend services. Once distributed, attackers can reverse-engineer the apps, and these secrets become accessible, posing risks such as data leaks, and service abuse. In this paper, we conduct a large-scale analysis of 10,331 Android and iOS apps to study how secrets are embedded in mobile apps. Our methodology involves extracting and validating credentials from app bundles and comparing the types and frequency of embedded secrets across Android and iOS to identify systematic differences between the two ecosystems. To assess temporal dynamics, we re-analyze apps released in 2023 after their updates in 2024. Our findings show that apps not only leak secrets required for functionality but also unintentionally include sensitive information like markdown documentation, and dependency management files. We discovered 416 functional credentials across 65 services, including 13 Git credentials that grant access to 218 public and 2,440 private repositories. Our analysis reveals that iOS apps are more likely to expose secrets, although information leaks exist in both Android and iOS apps. Finally, we show that even if developers remove embedded credentials in later versions, they frequently forget to revoke them, leaving the credentials exploitable.}
}


@inproceedings{DBLP:conf/ccs/MaLEKA0JW025,
	author = {Zheyuan Ma and
                  Gaoxiang Liu and
                  Alex Eastman and
                  Kai Kaufman and
                  Md. Armanuzzaman and
                  Xi Tan and
                  Katherine Jesse and
                  Robert J. Walls and
                  Ziming Zhao},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {'We just did not have that on the embedded system': Insights and Challenges
                  for Securing Microcontroller Systems from the Embedded {CTF} Competitions},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {2474--2488},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765039},
	doi = {10.1145/3719027.3765039},
	timestamp = {Fri, 26 Dec 2025 20:53:03 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/MaLEKA0JW025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Microcontroller systems are integral to our daily lives, powering mission-critical applications such as vehicles, medical devices, and industrial control systems. Therefore, it is essential to investigate and outline the challenges encountered in developing secure microcontroller systems. While previous research has focused solely on microcontroller firmware analysis to identify and characterize vulnerabilities, our study uniquely leverages data from the 2023 and 2024 MITRE eCTF team submissions and post-competition interviews. This approach allows us to dissect the entire lifecycle of secure microcontroller system development from both technical and perceptual perspectives, providing deeper insights into how these vulnerabilities emerge in the first place. Through the lens of eCTF, we identify fundamental conceptual and practical challenges in securing microcontroller systems. Conceptually, it is difficult to adapt from a microprocessor system to a microcontroller system, and participants are not wholly aware of the unique attacks against microcontrollers. Practically, security-enhancing tools, such as the memory-safe language Rust, lack adequate support on microcontrollers. Additionally, poor-quality entropy sources weaken cryptography and secret generation. Our findings articulate specific research, developmental, and educational deficiencies, leading to targeted recommendations for researchers, developers, vendors, and educators to enhance the security of microcontroller systems.}
}


@inproceedings{DBLP:conf/ccs/WiedemeierKFZPC25,
	author = {Joshua Wiedemeier and
                  Simon Klancher and
                  Joel Flores and
                  Max Zheng and
                  Jaehyun Park and
                  Sang Kil Cha and
                  Kangkook Jee},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Walking The Last Mile: Studying Decompiler Output Correction in Practice},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {2489--2503},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765040},
	doi = {10.1145/3719027.3765040},
	timestamp = {Fri, 26 Dec 2025 20:53:03 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/WiedemeierKFZPC25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The increasing prevalence of Python has spurred interest in decompiling Python PYC bytecode. This work presents the first large-scale study on human-assisted Python decompilation  in the wild , leveraging extensive data from pylingual.io, spanning 181,646 PYC binaries, 9,003 user-submitted patches, and 393 accuracy-verified patches. We investigate how reverse engineers respond to inaccurate decompilation and identify factors influencing their efforts to achieve accurate decompilation. We complement this unprecedented observational data with a controlled user study that isolates the technical difficulty of patching imperfect Python decompilations. By contrasting real-world patching behavior with that of the controlled setting, we discover that reversers' decision to repair a decompilation result is more strongly driven by the semantic content of the program ( e.g. , malware binaries or malicious tools) than by the technical difficulty of the patch. That is, a reverser's motivation is more important than their expertise. Our study reveals common patterns observed in the patching process, including how users approached the patching task, the types of errors they encountered, and the strategies they employed to resolve them. We also examine the strengths and limitations of assistive tools in the pursuit of perfect decompilation. Our findings offer unique insights into the practical dynamics of human-decompiler interaction, providing actionable recommendations for integrating human intelligence into the decompilation workflow and demonstrating the research potential of reliable decompilation accuracy verification.}
}


@inproceedings{DBLP:conf/ccs/Zhao0GVFM25,
	author = {Yunze Zhao and
                  Wentao Guo and
                  Harrison Goldstein and
                  Daniel Votipka and
                  Kelsey R. Fulton and
                  Michelle L. Mazurek},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {A Qualitative Analysis of Fuzzer Usability and Challenges},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {2504--2518},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765055},
	doi = {10.1145/3719027.3765055},
	timestamp = {Fri, 26 Dec 2025 20:53:03 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/Zhao0GVFM25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Fuzzing is a widely adopted technique for uncovering software vulnerabilities by generating random or mutated test inputs to trigger unexpected behavior. However, little is known about how developers actually use fuzzing tools in practice, the challenges they face, and where current tools fall short. This study investigates the human side of fuzzing via 18 semi-structured interviews with fuzzing users across diverse domains. These interviews explore participants' workflows, frustrations, and expectations around fuzzing, revealing critical usability gaps and design opportunities. Our results can inform the next generation of fuzzing tools to improve user experience, reduce manual effort, and enable more effective integration of fuzzing into real-world workflows.}
}


@inproceedings{DBLP:conf/ccs/NeilMWAR25,
	author = {Lorenzo Neil and
                  Deepthi Mungara and
                  Laurie A. Williams and
                  Yasemin Acar and
                  Bradley Reaves},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {It Should Be Easy but... New Users' Experiences and Challenges with
                  Secret Management Tools},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {2519--2533},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765065},
	doi = {10.1145/3719027.3765065},
	timestamp = {Fri, 26 Dec 2025 20:53:03 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/NeilMWAR25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Software developers face risks of leaking their software secrets, such as API keys or passwords, which can result in significant harm. Secret management tools (SMTs), such as HashiCorp Vault Secrets or Infisical, are highly recommended by industry, academia, and security guidelines to manage secrets securely. SMTs are designed to help developers secure their secrets in a central location, yet secrets leaks are still commonplace, and developers report difficulty in learning how to setup and use SMTs. While SMTs typically come with publicly available help resources (e.g., tool documentation and interfaces), it is unclear if these actually help developers learn to effectively use SMTs. Without usable help resources that onboards developers, quick adoption and effective use of SMTs may be unrealistic. In a qualitative two-step study, we observed 21 new users in person while they used SMTs to perform two secret management tasks: secret storage and access, then secret injection. We interviewed participants after each task to identify their challenges and experiences using SMTs, with the assistance of help resources. While our study sample is narrow, it serves as a reasonable proxy for new developers who are likely to adopt SMTs early in their careers. We found that even in a laboratory setting where new users found tool functionality and interface flexibility helpful, they still experienced increased difficulty to effectively use SMTs to securely remediate a hard-coded secret when they felt tool documentation was insufficient. Insufficient tool documentation motivated participants to deviate from official tool documentation to access secondary sources or attempt workaround methods. Specific challenges reported by participants were tool documentation content quality, navigation difficulties with both tool documentation and web interfaces for finding helpful content, and supportive tool features. We explain how these challenges negatively affect participant experiences adopting SMTs, and suggest recommendations on tool documentation and interfaces for SMT developers. If developers cannot simply and quickly manage secrets securely, secret leakage will continue to be commonplace.}
}


@inproceedings{DBLP:conf/ccs/HajiabadiMR25,
	author = {Ali Hajiabadi and
                  Michele Marazzi and
                  Kaveh Razavi},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {CHaRM: Checkpointed and Hashed Counters for Flexible and Efficient
                  Rowhammer Mitigation},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {2534--2548},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765021},
	doi = {10.1145/3719027.3765021},
	timestamp = {Sun, 07 Dec 2025 22:09:41 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/HajiabadiMR25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Despite efforts by DRAM vendors to mitigate Rowhammer, it is still a potent attack vector. CPU vendors are reluctant to deploy deterministic mitigations against Rowhammer due to the high cost that needs to be paid for the most vulnerable DRAM device, even though an average DRAM device is considerably less vulnerable. The main reason for this high cost is the need to track an increasing number of aggressor rows with the worsening Rowhammer threshold. Our proposed in-CPU mitigation, called CHaRM, breaks this dependency by efficiently mapping a large number of rows to a fixed number of hashed counters. Since multiple rows are now mapped to a limited number of counters, collisions can occur. To avoid excessive mitigative refreshes upon collisions, CHaRM deploys a checkpointing mechanism that saves the state of rows evicted from the table. When a row is activated again, CHaRM restores its checkpointed value and resumes tracking. Our evaluation shows that CHaRM incurs negligible slowdown, below 1% across all Rowhammer thresholds, while improving area, power, and energy by 3.8x, 4.4x, and 8.2x, respectively, for Rowhammer threshold of 1K compared to the state of the art.}
}


@inproceedings{DBLP:conf/ccs/Lin00WB25,
	author = {Hai Lin and
                  Chenglong Li and
                  Jiahai Yang and
                  Zhiliang Wang and
                  Jiaqi Bai},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {ZVDetector: State-Guided Vulnerability Detection System for Zigbee
                  Devices},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {2549--2563},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765035},
	doi = {10.1145/3719027.3765035},
	timestamp = {Fri, 26 Dec 2025 20:53:03 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/Lin00WB25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Nowadays, Zigbee devices are widely used in smart home, smart agriculture and other industries. However, there are many vulnerabilities in Zigbee devices that could compromise their normal functionality. Existing research either analyzes firmware or fuzzes devices through Zigbee networks to discover potential vulnerabilities. However, they overlook the impact of device state and protocol state on firmware or explore only a limited state space. Thus, they fail to identify many vulnerabilities caused by hidden states within each of the two states, especially vulnerabilities triggered by the combination of these two states. In this paper, we design a state-guided fuzzing system, named ZVDetector, aimed at uncovering firmware vulnerabilities caused by hidden and combined states. Specifically, we design two state-aware modules that explore richer unknown protocol state transitions based on message relationships and gain a more complete understanding of the intrinsic device state attributes. We develop a fuzzing algorithm that incorporates message semantics awareness and correlation state analysis. By integrating the perceived state information, it can explore the combined state space more efficiently. We validate the performance of ZVDetector on 10 Zigbee devices and find 25 vulnerabilities (19 zero-day). Our experiments also demonstrate the ability to explore more device state attributes and discover more message relationships related to unknown protocol states.}
}


@inproceedings{DBLP:conf/ccs/ThomasTM025,
	author = {Fabian Thomas and
                  Michael Torres and
                  Daniel Moghimi and
                  Michael Schwarz},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {ExfilState: Automated Discovery of Timer-Free Cache Side Channels
                  on {ARM} CPUs},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {2564--2578},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765061},
	doi = {10.1145/3719027.3765061},
	timestamp = {Sun, 07 Dec 2025 22:09:44 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/ThomasTM025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Microarchitectural attacks and reverse-engineering efforts rely on inferring the cache state of cache lines. While high-resolution timers traditionally enable this, such timers are increasingly restricted or unavailable to unprivileged users on modern ARM64 systems. We introduce a fuzzing-based methodology to automatically discover instruction sequences that leak cache state into architectural state—without timing measurements. Our proof-of-concept,  ExfilState,  uses differential testing, F-score ranking, and covert-channel verification to identify architectural side channels on ARM64 CPUs. Across 160 devices with 37 microarchitectures—including smartphones, laptops, and cloud servers-- ExfilState  uncovers 5 undocumented side channels, 2 of which are reliably and widely exploitable. We demonstrate their practical impact with a timer-free Spectre variant, a cache-based AES key-recovery attack, and a novel defense mechanism that aborts sensitive algorithms on eviction of victim cache lines. Our findings show that architectural side channels are both real and exploitable, even in environments without timers, broadening the attack surface on modern ARM64 platforms.}
}


@inproceedings{DBLP:conf/ccs/KovatsSCR25,
	author = {Tobias Kovats and
                  Flavien Solt and
                  Katharina Ceesay{-}Seitz and
                  Kaveh Razavi},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {MileSan: Detecting Exploitable Microarchitectural Leakage via Differential
                  Hardware-Software Taint Tracking},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {2579--2593},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765066},
	doi = {10.1145/3719027.3765066},
	timestamp = {Fri, 26 Dec 2025 20:53:03 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/KovatsSCR25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Microarchitectural performance optimizations introduce information flows inside CPU implementations that exceed those defined by the Instruction Set Architecture (ISA). Microarchitectural vulnerabilities, such as constant-time violations and various classes of transient execution attacks, are subsets of these excessive information flows. We observe that an  exploitable microarchitectural leakage  is an excessive information flow that can affect the time it takes for the CPU to execute a particular instruction, creating a timing covert channel. We design MileSan, the first RTL sanitizer that is capable of detecting exploitable microarchitectural leakage by checking for the architecturally-observable differences between architectural and microarchitectural information flows. For a given program and CPU implementation, MileSan computes architectural flows using software taint tracking and microarchitectural flows using RTL taint tracking. Evaluating the exploitability of proof of concepts generated by previous microarchitectural fuzzers, we find cases that are in fact not exploitable and discover the particular microarchitectural components that enable exploitation for the rest. In addition to assessing exploitability, MileSan enables the generation of random test programs with strictly-defined architectural information flows of secret data using a novel technique called taint-aware in-situ simulation. Leveraging this capability, we build RandOS, a new microarchitectural fuzzer that generates random programs traversing different privilege levels and address spaces, akin to  random operating systems . Evaluation using five RISC-V CPUs shows that RandOS not only detects known exploitable vulnerabilities 4.5x faster than the state of the art, but also discovers 19 new constant-time violations and transient execution vulnerabilities in well-tested CPUs, such as BOOM, CVA6 and OpenC910.}
}


@inproceedings{DBLP:conf/ccs/GuoCCL0W25,
	author = {Yitong Guo and
                  Hongbo Chen and
                  Haobin Hiroki Chen and
                  Yukui Luo and
                  XiaoFeng Wang and
                  Chenghong Wang},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {{BOLT:} Bandwidth-Optimized Lightning-Fast Oblivious Map powered by
                  Secure {HBM} Accelerators},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {2594--2608},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765069},
	doi = {10.1145/3719027.3765069},
	timestamp = {Fri, 26 Dec 2025 20:53:03 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/GuoCCL0W25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {While Trusted Execution Environments provide a strong foundation for secure cloud computing, they remain vulnerable to access pattern leakages. Oblivious Maps (OMAPs) mitigate this by fully hiding access patterns but suffer from high overhead due to randomized remapping and worst-case padding. We argue these costs are not fundamental. Modern accelerators featuring High-Bandwidth Memory (HBM) offer a new opportunity: Vaswani et al. [ OSDI '18 ] point out that eavesdropping on HBM is difficult—even for physical attackers—as its memory channels are sealed together with processor cores inside the same physical package. Later, Hunt et al. [ NSDI '20 ] show that, with proper isolation, HBM can be turned into an unobservable region where both data and memory traces are hidden. This motivates a rethink of OMAP design with HBM-backed solutions to finally overcome their traditional performance limits. Building on these insights, we present BOLT, a Bandwidth Optimized, Lightning-fasT OMAP accelerator that, for the first time, achieves  O (1)+ O (log 2 log 2 N ) bandwidth overhead. BOLT introduces three key innovations: (i) a new OMAP algorithm that leverages isolated HBM as an unobservable cache to accelerate oblivious access to large host memory; (ii) a self-hosted architecture that offloads execution and memory control from the host to mitigate CPU-side leakage; and (iii) tailored algorithm-architecture co-designs that maximize resource efficiency. We implement a prototype BOLT on a Xilinx U55C FPGA. Evaluations show that BOLT achieves up to 279X and 480X speedups in initialization and query time, respectively, over state-of-the-art OMAPs, which includes an industry implementation from Facebook.}
}


@inproceedings{DBLP:conf/ccs/Lei00LL0L25,
	author = {Chongqing Lei and
                  Zhen Ling and
                  Xiangyu Xu and
                  Shaofeng Li and
                  Guangchi Liu and
                  Kai Dong and
                  Junzhou Luo},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {FlexEmu: Towards Flexible {MCU} Peripheral Emulation},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {2609--2623},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765086},
	doi = {10.1145/3719027.3765086},
	timestamp = {Fri, 26 Dec 2025 20:53:03 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/Lei00LL0L25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Microcontroller units (MCUs) are widely used in embedded devices due to their low power consumption and cost-effectiveness. MCU firmware controls these devices and is vital to the security of embedded systems. However, performing dynamic security analyses for MCU firmware has remained challenging due to the lack of usable execution environments -- existing dynamic analyses cannot run on physical devices (e.g., insufficient computational resources), while building emulators is costly due to the massive amount of heterogeneous hardware, especially peripherals. Recent advances in automated peripheral emulation have made MCU emulation more scalable. However, these efforts only support limited peripherals and are hard to extend because they require ad-hoc adaptations. Our work is based on the insight that MCU peripherals can be modeled in a two-fold manner. At the structural level, peripherals have diverse implementations. But we can use a limited set of primitives to abstract peripherals because their hardware implementations are based on common hardware concepts. These primitives are abstract and can be instantiated with peripheral-specific implementation details to accommodate diverse peripheral implementations. At the semantic level, peripherals have diverse functionalities. However, we can use a single unified semantic model to describe the same kind of peripherals because they exhibit similar functionalities. Primitives serve as basic building blocks, allowing flexible semantic model construction. Building on this, we propose FlexEmu, a flexible MCU peripheral emulation framework. Once semantic models are created, FlexEmu automatically extracts peripheral-specific details to instantiate models and generate emulators accordingly. We have successfully applied FlexEmu to model 12 kinds of MCU peripherals. Our evaluation on 90 firmware samples across 15 different MCU platforms shows that the automatically generated emulators can faithfully replicate hardware behaviors and achieve a 98.48% unit test passing rate, outperforming state-of-the-art approaches. To demonstrate the implications of FlexEmu on firmware security, we use the generated emulators to fuzz three popular RTOSes and uncover 10 previously unknown bugs.}
}


@inproceedings{DBLP:conf/ccs/ZhaoSHH25,
	author = {Rui Zhao and
                  Muhammad Shoaib and
                  Viet Tung Hoang and
                  Wajih Ul Hassan},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Rethinking Tamper-Evident Logging: {A} High-Performance, Co-Designed
                  Auditing System},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {2624--2638},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765024},
	doi = {10.1145/3719027.3765024},
	timestamp = {Fri, 26 Dec 2025 20:53:03 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/ZhaoSHH25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Existing tamper-evident logging systems suffer from high overhead and severe data loss in high-load settings, yet only provide coarse-grained tamper detection. Moreover, installing such systems requires recompiling kernel code. To address these challenges, we present Nitro, a high-performance, tamper-evident audit logging system that supports fine-grained detection of log tampering. Even better, our system avoids kernel recompilation by using the eBPF technology. To formally justify the security of N itro , we provide a new definitional framework for logging systems, and give a practical cryptographic construction meeting this new goal. Unlike prior work that focus only on the cryptographic processing, we codesign the cryptographic part with the pre- and post-processing of the logs to exploit all system-level optimizations. Our evaluations demonstrate N itro 's superior performance, achieving 10X-25X improvements in high-stress conditions and 2X-10X in real-world scenarios while maintaining near-zero data loss. We also provide an advanced variant, N itro -R that introduces in-kernel log reduction techniques to reduce runtime overhead even further.}
}


@inproceedings{DBLP:conf/ccs/BarsBSH25,
	author = {Nils Bars and
                  Lukas Bernhard and
                  Moritz Schloegel and
                  Thorsten Holz},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Empirical Security Analysis of Software-based Fault Isolation through
                  Controlled Fault Injection},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {2639--2652},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765027},
	doi = {10.1145/3719027.3765027},
	timestamp = {Fri, 26 Dec 2025 20:53:03 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/BarsBSH25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We use browsers daily to access all sorts of information. Because browsers routinely process scripts, media, and executable code from unknown sources, they form a critical security boundary between users and adversaries. A common attack vector is JavaScript, which powers complex web interactions but exposes a large attack surface due to the sheer complexity of modern JavaScript engines. To mitigate these threats, modern engines increasingly adopt software-based fault isolation (SFI). A prominent example is Google's  V8 heap sandbox,  which represents the most widely deployed SFI mechanism, protecting billions of users across all Chromium-based browsers and countless applications built on Node.js and Electron. The heap sandbox splits the address space into two parts: one part containing trusted, security-sensitive metadata, and a sandboxed heap containing memory accessible to untrusted code. On a technical level, the sandbox enforces isolation by removing raw pointers and using translation tables to resolve references to trusted objects. Consequently, an attacker cannot corrupt trusted data even with full control of the sandboxed data, unless there is a bug in how code handles data from the sandboxed heap. Despite their widespread use, such SFI mechanisms have seen surprisingly little security testing. In this work, we propose a new testing technique that faithfully models the security boundary of modern SFI implementations. Following the SFI threat model, we assume a powerful attacker who fully controls the sandbox's memory. We implement this by instrumenting memory loads originating in the trusted domain and accessing untrusted, attacker-controlled sandbox memory. We then inject faults into the loaded data, aiming to trigger memory corruption in the  trusted domain  that processes this untrusted input. We implement our approach in a tool called SbxBrk and evaluate it on the V8 heap sandbox. In a comprehensive evaluation, we identify 19 security bugs in V8 that enable an attacker to bypass the sandbox.}
}


@inproceedings{DBLP:conf/ccs/0002G0VJL25,
	author = {Shixuan Zhao and
                  Zhongshu Gu and
                  Salman Ahmed and
                  Enriquillo Valdez and
                  Hani Jamjoom and
                  Zhiqiang Lin},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {{GPU} Travelling: Efficient Confidential Collaborative Training with
                  TEE-Enabled GPUs},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {2653--2667},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765029},
	doi = {10.1145/3719027.3765029},
	timestamp = {Thu, 01 Jan 2026 19:11:51 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/0002G0VJL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Confidential collaborative machine learning (ML) enables multiple mutually distrusted data holders to jointly train an ML model while preserving the confidentiality of their private datasets due to regulatory or competitive reasons. However, existing works need frequent data and model exchanges during training via slower conventional links. They face increasing challenges due to the exponentially growing sizes of models and datasets in modern training workloads like large language models (LLMs), resulting in prohibitively high communication costs. In this paper, we propose a novel mechanism called GPU Travelling that leverages recently emerged confidential GPUs. With our rigorous design, the GPU can securely travel to the specific data holder to load the dataset directly into the GPU's protected memory and then return for training, eliminating the need for data transmission while ensuring confidentiality up to a data-centre level. We developed a prototype using Intel TDX and NVIDIA H100 and evaluated its performance on llm.c, a CUDA-based LLM training project, and demonstrated the performance and feasibility while maintaining strong security guarantees. The results showed at least 4x speed improvement when transmitting a 512 MiB dataset chunk versus conventional transmission.}
}


@inproceedings{DBLP:conf/ccs/KreyssigHRB25,
	author = {Bruno Kreyssig and
                  Sabine Houy and
                  Timoth{\'{e}}e Riom and
                  Alexandre Bartel},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Sleeping Giants - Activating Dormant Java Deserialization Gadget Chains
                  through Stealthy Code Changes},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {2668--2682},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765031},
	doi = {10.1145/3719027.3765031},
	timestamp = {Fri, 26 Dec 2025 20:53:03 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/KreyssigHRB25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Java deserialization gadget chains are a well-researched critical software weakness. The vast majority of known gadget chains rely on gadgets from software dependencies. Furthermore, it has been shown that small code changes in dependencies have enabled these gadget chains. This makes gadget chain detection a purely reactive endeavor. Even if one dependency's deployment pipeline employs gadget chain detection, a gadget chain can still result from gadgets in other dependencies. In this work, we assess how likely small code changes are to enable a gadget chain. These changes could either be accidental or intentional as part of a supply chain attack. Specifically, we show that class serializability is a strongly fluctuating property over a dependency's evolution. Then, we investigate three change patterns by which an attacker could stealthily introduce gadgets into a dependency. We apply these patterns to 533 dependencies and run three state-of-the-art gadget chain detectors both on the original and the modified dependencies. The tools detect that applying the modification patterns can activate/inject gadget chains in 26.08% of the dependencies we selected. Finally, we verify the newly detected chains. As such, we identify dormant gadget chains in 53 dependencies that could be added through minor code modifications. This both shows that Java deserialization gadget chains are a broad liability to software and proves dormant gadget chains as a lucrative supply chain attack vector.}
}


@inproceedings{DBLP:conf/ccs/Cao0SZ025,
	author = {Sheng Cao and
                  Hao Zhou and
                  Songzhou Shi and
                  Yanjie Zhao and
                  Haoyu Wang},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Parcel Mismatch Demystified: Addressing a Decade-Old Security Challenge
                  in Android},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {2683--2698},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765034},
	doi = {10.1145/3719027.3765034},
	timestamp = {Fri, 26 Dec 2025 20:53:03 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/Cao0SZ025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Parcel Mismatch vulnerabilities in Android's Inter-Process Communication (IPC) mechanism have been a persistent security challenge for over a decade, leading to numerous privilege escalation exploits. While Google has implemented various mitigation strategies, culminating in the Lazy Bundle mechanism in Android 13, there has been no systematic analysis of these vulnerabilities and mitigations. To fill the gap, in this paper, we conduct the first comprehensive study of Parcel Mismatch vulnerabilities, proposing P arcel T aint , a new static analysis approach for detecting these issues. We develop precise models for tracking Intent and Bundle transformations across processes, enabling the discovery of new attack vectors. We reveal 10 previously unknown high-severity vulnerabilities, and 5 of them have been assigned with CVEs, including new ways to bypass existing mitigations and new attack chains in system services. All of them have been confirmed. We find that Parcel Mismatch remains a significant security concern, particularly for Android versions prior to 13 and for Original Equipment Manufacturers (OEMs) implementing custom system components. Based on our findings, Google has revised its security strategy to address core vulnerability patterns rather than relying solely on system-level mitigations. The study provides crucial insights for improving Android's IPC security and highlights the importance of systematic analysis in addressing long-standing security challenges.}
}


@inproceedings{DBLP:conf/ccs/MetzgerMNNW025,
	author = {Paul Metzger and
                  A. Theodore Markettos and
                  Edward Tomasz Napierala and
                  Matthew Naylor and
                  Robert N. M. Watson and
                  Timothy M. Jones},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Deprivileging Low-Level {GPU} Drivers Efficiently with User-Space
                  Processes and {CHERI} Compartments},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {2699--2713},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765036},
	doi = {10.1145/3719027.3765036},
	timestamp = {Fri, 26 Dec 2025 20:53:03 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/MetzgerMNNW025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Device drivers are a prominent source of operating system bugs and vulnerabilities, due to market pressures on hardware vendors and access to privileged system resources. OSes increasingly deprivilege drivers by moving them out of the kernel into user space, but this is widely understood to come with significant overhead. The perfect storm concerns GPU drivers, which are very large, complex and yet highly performance-sensitive. For performance reasons, large parts of these drivers run with full kernel privileges on major OSes. We deprivilege a GPU driver by moving it to user space. To avoid context-switching latency we run interrupt handlers inside eBPF sandboxes. Additionally, we take away the ability of the GPU driver to manage its own page tables and move this into an OS-vendor-vetted component. We create two variants. Firstly, a microkernel-inspired implementation which runs the driver in a standard Unix process. Secondly, we move the driver into a CHERI compartment. CHERI allows isolation of distrusting code in sandboxes without needing MMU-based separation. Compartments safely coexist within an address space, but efficiently share data by passing CHERI capabilities between each other, and incur reduced context-switching costs. To do this we use 'co-located processes', an existing framework which allows us to run graphics drivers and their applications as separate OS processes in a shared address space. Microkernel-like user-space drivers are still often believed to have high overheads, yet our Unix process-based implementation increases execution time on average by only 7.9% (geometric mean of the benchmark suite; max. 48.2%, min. 0.1%) for GPGPU and by 5.5% (max. 12.6%, min. -0.2%) for graphics workloads, while providing major security benefits. Despite these low costs, isolating processes with CHERI compartments, instead of address spaces, reduces average overheads to 6% (max. 36.6%, min. -0.2%) and 5% (max. 11.2%, min. 0.01%) respectively.}
}


@inproceedings{DBLP:conf/ccs/ChaliasosFL25,
	author = {Stefanos Chaliasos and
                  Denis Firsov and
                  Benjamin Livshits},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Towards a Formal Foundation for Blockchain {ZK} Rollups},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {2714--2728},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765115},
	doi = {10.1145/3719027.3765115},
	timestamp = {Fri, 26 Dec 2025 20:53:03 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/ChaliasosFL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Blockchains like Bitcoin and Ethereum have revolutionized digital transactions, yet scalability issues persist. Layer 2 solutions, such as validity proof Rollups (ZK-Rollups), aim to address these challenges by processing transactions off-chain and validating them on the main chain. However, concerns remain about security and censorship resistance, particularly regarding centralized control in Layer 2 and inadequate mechanisms for enforcing these properties through Layer 1 smart contracts. In their current form, L2s are susceptible to multisig attacks that can lead to total user funds loss. This work presents a formal analysis using the Alloy specification language to examine and design key Layer 2 functionalities, including forced transaction queues, safe blacklisting, and upgradeability. Through this analysis, we identify pitfalls in existing designs and introduce an enhanced model that has been model-checked to be correct. Finally, we propose a complete end-to-end methodology to analyze rollups' security and censorship resistance based on manually translating Alloy properties to property-based testing invariants, setting new standards.}
}


@inproceedings{DBLP:conf/ccs/BhargavanHKSS25,
	author = {Karthikeyan Bhargavan and
                  Lasse Letager Hansen and
                  Franziskus Kiefer and
                  Jonas Schneider{-}Bensch and
                  Bas Spitters},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Formal Security and Functional Verification of Cryptographic Protocol
                  Implementations in Rust},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {2729--2743},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765213},
	doi = {10.1145/3719027.3765213},
	timestamp = {Fri, 26 Dec 2025 20:53:03 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/BhargavanHKSS25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We present an effective methodology for the formal verification of practical cryptographic protocol implementations written in Rust. Within a single proof framework, we show how to develop machine-checked proofs of diverse properties like runtime safety, parsing correctness, and cryptographic protocol security. All analysis tasks are driven by the software developer who writes annotations in the Rust source code and chooses a backend prover for each task, ranging from a generic proof assistant like F* to dedicated crypto-oriented provers like ProVerif and SSProve Our main contribution is a demonstration of this methodology on Bert13, a portable, post-quantum implementation of TLS 1.3 written in Rust and verified both for security and functional correctness. To our knowledge, this is the first security verification result for a protocol implementation written in Rust, and the first verified post-quantum TLS 1.3 library.}
}


@inproceedings{DBLP:conf/ccs/RamananandroEMS25,
	author = {Tahina Ramananandro and
                  Gabriel Ebner and
                  Guido Mart{\'{\i}}nez and
                  Nikhil Swamy},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Secure Parsing and Serializing with Separation Logic Applied to CBOR,
                  CDDL, and {COSE}},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {2744--2758},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765120},
	doi = {10.1145/3719027.3765120},
	timestamp = {Fri, 26 Dec 2025 20:53:03 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/RamananandroEMS25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Incorrect handling of security-critical data formats, particularly in low-level languages, are the root cause of many security vulnerabilities. Provably correct parsing and serialization tools that target languages like C can help. Towards this end, we present PulseParse, a library of verified parser and serializer combinators for non-malleable binary formats. Specifications and proofs in PulseParse are in separation logic, offering a more abstract and compositional interface, with full support for data validation, parsing, and serialization. PulseParse also supports a class of recursive formats---with a focus on security and handling adversarial inputs, we show how to parse such formats with only a constant amount of stack space. We use PulseParse at scale by providing the first formalization of CBOR, a recursive, binary data format standard, with growing adoption in various other industrial standards. We prove that the deterministic fragment of CBOR is non-malleable and provide EverCBOR, a verified library in both C and Rust to validate, parse, and serialize CBOR objects implemented using PulseParse. Next, we provide the first formalization of CDDL, a schema definition language for CBOR. We identify well-formedness conditions on CDDL definitions to ensure that they yield unambiguous, non-malleable formats, and implement EverCDDL, a tool that checks the well-formedness of a CDDL definition and produces verified parsers and serializers for it. To evaluate our work, we use EverCDDL to generate verified parsers and serializers for various security-critical applications. Notably, we build a formally verified implementation of COSE signing, a standard for cryptographically signed objects. We also use our toolchain to generate verified code for other standards specified in CDDL, including DICE Protection Environment, a secure boot protocol standard. We conclude that PulseParse offers a powerful new foundation on which to build verified, secure data formatting tools for a range of applications.}
}


@inproceedings{DBLP:conf/ccs/Linker0CB25,
	author = {Felix Linker and
                  Christoph Sprenger and
                  Cas Cremers and
                  David A. Basin},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Looping for Good: Cyclic Proofs for Security Protocols},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {2759--2773},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765131},
	doi = {10.1145/3719027.3765131},
	timestamp = {Fri, 26 Dec 2025 20:53:03 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/Linker0CB25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Security protocols often involve loops, such as for ratcheting or for manipulating inductively-defined data structures. However, the automated analysis of security protocols has struggled to keep up with these features. The state-of-the-art often necessitates working with abstractions of such data structures or relies heavily on auxiliary, user-defined lemmas. In this work, we advance the state-of-the-art in symbolic protocol verification by adapting cyclic induction proof systems to the security protocol domain. We introduce reasoning rules for the Tamarin prover for cyclic proofs, enabling new, compact proofs, and we prove their soundness. Moreover, we implement new, simple, and effective proof search strategies that leverage these rules. With these additions, Tamarin can prove many lemmas that previously required, often complex, auxiliary lemmas. We showcase our approach on fourteen case studies, ranging from toy examples to a detailed model of the Signal protocol. Our work opens an exciting new research area where automatic induction helps scale security protocol verification, as we provide a fundamentally new and general induction mechanism.}
}


@inproceedings{DBLP:conf/ccs/HenzingerKT25,
	author = {Thomas A. Henzinger and
                  Mahyar Karimi and
                  K. S. Thejaswini},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Privacy-Preserving Runtime Verification},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {2774--2787},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765137},
	doi = {10.1145/3719027.3765137},
	timestamp = {Fri, 26 Dec 2025 20:53:03 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/HenzingerKT25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Runtime verification offers scalable solutions to improve the safety and reliability of systems. However, systems that require verification or monitoring by a third party to ensure compliance with a specification might contain sensitive information, causing privacy concerns when usual runtime verification approaches are used. Privacy is compromised if protected information about the system, or sensitive data that is processed by the system, is revealed. In addition, revealing the specification being monitored may undermine the essence of third-party verification. In this work, we propose two novel protocols for the privacy-preserving runtime verification of systems against formal sequential specifications. In our first protocol, the monitor verifies whether the system satisfies the specification without learning anything else, though both parties are aware of the specification. Our second protocol ensures that the system remains oblivious to the monitored specification, while the monitor learns only whether the system satisfies the specification and nothing more. Our protocols adapt and improve existing techniques used in cryptography, and more specifically, multi-party computation. The sequential specification defines the observation step of the monitor, whose granularity depends on the situation (e.g., banks may be monitored on a daily basis). Our protocols exchange a single message per observation step, after an initialisation phase. This design minimises communication overhead, enabling relatively lightweight privacy-preserving monitoring. We implement our approach for monitoring specifications described by register automata and evaluate it experimentally.}
}


@inproceedings{DBLP:conf/ccs/SunSWZ0W25,
	author = {Huan Sun and
                  David San{\'{a}}n and
                  Jingyi Wang and
                  Yongwang Zhao and
                  Jun Sun and
                  Wenhai Wang},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Generalized Security-Preserving Refinement for Concurrent Systems},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {2789--2803},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765138},
	doi = {10.1145/3719027.3765138},
	timestamp = {Sun, 07 Dec 2025 22:09:44 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/SunSWZ0W25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Ensuring compliance with Information Flow Security (IFS) is known to be challenging, especially for concurrent systems with large codebases such as multicore operating system (OS) kernels. Refinement, which verifies that an implementation preserves certain properties of a more abstract specification, is promising for tackling such challenges. However, in terms of refinement-based verification of security properties, existing techniques are still restricted to sequential systems or lack the expressiveness needed to capture complex security policies for concurrent systems. In this work, we present a generalized security-preserving refinement technique, particularly for verifying the IFS of concurrent systems governed by potentially complex security policies. We formalize the IFS properties for concurrent systems and present a refinement-based compositional approach to prove that the generalized security properties (e.g., intransitive noninterference) are preserved between implementation and abstraction. The key intuition enabling such reasoning, compared to previous refinement work, is to establish a step-mapping relation between the implementation and the abstraction, which is sufficient to ensure that every paired step (in the abstraction and the implementation, respectively) is either permitted or prohibited by the security policy. We apply our approach to verify two non-trivial case studies against a collection of security policies. Our proofs are fully mechanized in Isabelle/HOL, during which we identified that two covert channels previously reported in the ARINC 653 single-core standard also exist in the ARINC 653 multicore standard. We subsequently proved the correctness of the revised mechanism, showcasing the effectiveness of our approach.}
}


@inproceedings{DBLP:conf/ccs/LiuWWWA025,
	author = {Gaoyang Liu and
                  Xijie Wang and
                  Zixiong Wang and
                  Chen Wang and
                  Ahmed M. Abdelmoniem and
                  Desheng Wang},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Prototype Surgery: Tailoring Neural Prototypes via Soft Labels for
                  Efficient Machine Unlearning},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {2804--2817},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744827},
	doi = {10.1145/3719027.3744827},
	timestamp = {Fri, 26 Dec 2025 20:53:03 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/LiuWWWA025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The rapid advancements and widespread application of deep neural networks (DNNs), coupled with their reliance on sensitive and private data, have sparked growing concerns regarding data privacy and the ''right to be forgotten''. To address these concerns, machine unlearning has been proposed to efficiently eliminate the influence of specific training data from trained DNNs. However, existing machine unlearning methods struggle with the large number of parameters in trained DNNs, which lead to slow execution and high memory consumption, making them impractical for large-scale models. In this paper, we shift our focus to the small set of weights in the final classification layer of DNNs, which are defined as as ''prototypes'' for different classes. Our key observation is that the prototype associated with the unlearned training data undergoes a significant shift, whereas prototypes of unrelated classes exhibit only minor changes when comparing the prototypes of original and retrained models. Based on this observation, we propose a novel machine unlearning approach that efficiently achieves machine unlearning by directly adjusting the prototypes of DNNs. We first introduce Naive Prototype Surgery (Naive PS), a fast and simplified method that uses a closed-form solution to approximate unlearning effect by directly adjusting the prototype associated with the unlearned data. Next, we propose Prototype Surgery (PS), which incorporates soft label information to fine-tune the prototypes of all classes, to achieve a more effective unlearning. Both methods achieve data unlearning by only modifying the prototypes in the DNNs, thus avoiding the challenges posed by the large number of model parameters. Extensive experiments on four datasets demonstrate that our methods significantly accelerate the unlearning process while achieving comparable results to five existing methods in terms of both unlearning performance and privacy guarantee.}
}


@inproceedings{DBLP:conf/ccs/QiTZ0YZG025,
	author = {Peigui Qi and
                  Kunsheng Tang and
                  Wenbo Zhou and
                  Weiming Zhang and
                  Nenghai Yu and
                  Tianwei Zhang and
                  Qing Guo and
                  Jie Zhang},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {SafeGuider: Robust and Practical Content Safety Control for Text-to-Image
                  Models},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {2818--2832},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744835},
	doi = {10.1145/3719027.3744835},
	timestamp = {Fri, 26 Dec 2025 20:53:03 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/QiTZ0YZG025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Text-to-image models have shown remarkable capabilities in generating high-quality images from natural language descriptions. However, these models are highly vulnerable to adversarial prompts, which can bypass safety measures and produce harmful content. Despite various defensive strategies, achieving robustness against attacks while maintaining practical utility in real-world applications remains a significant challenge. To address this issue, we first conduct an empirical study of the text encoder in the Stable Diffusion (SD) model, which is a widely used and representative text-to-image model. Our findings reveal that the [EOS] token acts as a semantic aggregator, exhibiting distinct distributional patterns between benign and adversarial prompts in its embedding space. Building on this insight, we introduce  SafeGuider,  a two-step framework designed for robust safety control without compromising generation quality.  SafeGuider  combines an embedding-level recognition model with a safety-aware feature erasure beam search algorithm. This integration enables the framework to maintain high-quality image generation for benign prompts while ensuring robust defense against both in-domain and out-of-domain attacks.  SafeGuider  demonstrates exceptional effectiveness in minimizing attack success rates, achieving a maximum rate of only 5.48% across various attack scenarios. Moreover, instead of refusing to generate or producing black images for unsafe prompts,  SafeGuider  generates safe and meaningful images, enhancing its practical utility. In addition,  SafeGuider  is not limited to the SD model and can be effectively applied to other text-to-image models, such as the Flux model, demonstrating its versatility and adaptability across different architectures. We hope that  SafeGuider  can shed some light on the practical deployment of secure text-to-image systems.}
}


@inproceedings{DBLP:conf/ccs/ChenZMC0025,
	author = {Sizhe Chen and
                  Arman Zharmagambetov and
                  Saeed Mahloujifar and
                  Kamalika Chaudhuri and
                  David A. Wagner and
                  Chuan Guo},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {SecAlign: Defending Against Prompt Injection with Preference Optimization},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {2833--2847},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744836},
	doi = {10.1145/3719027.3744836},
	timestamp = {Fri, 26 Dec 2025 20:53:03 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/ChenZMC0025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Large language models (LLMs) are becoming increasingly prevalent in modern software systems, interfacing between the user and the Internet to assist with tasks that require advanced language understanding. To accomplish these tasks, the LLM often uses external data sources such as user documents, web retrieval, results from API calls, etc. This opens up new avenues for attackers to manipulate the LLM via prompt injection. Adversarial prompts can be injected into external data sources to override the system's intended instruction and instead execute a malicious instruction. To mitigate this vulnerability, we propose a new defense called SecAlign based on the technique of preference optimization. Our defense first constructs a preference dataset with prompt-injected inputs, secure outputs (ones that respond to the legitimate instruction), and insecure outputs (ones that respond to the injection). We then perform preference optimization on this dataset to teach the LLM to prefer the secure output over the insecure one. This provides the first known method that reduces the success rates of various prompt injections to <10%, even against attacks much more sophisticated than ones seen during training. This indicates our defense generalizes well against unknown and yet-to-come attacks. Also, SecAlign models are still practical with similar utility to the one before defensive training in our evaluations. Our code is here.}
}


@inproceedings{DBLP:conf/ccs/WuBHS0Z25,
	author = {Stanley Wu and
                  Ronik Bhaskar and
                  Anna Yoo Jeong Ha and
                  Shawn Shan and
                  Haitao Zheng and
                  Ben Y. Zhao},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {On the Feasibility of Poisoning Text-to-Image {AI} Models via Adversarial
                  Mislabeling},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {2848--2862},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744845},
	doi = {10.1145/3719027.3744845},
	timestamp = {Fri, 26 Dec 2025 20:53:03 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/WuBHS0Z25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Today's text-to-image generative models are trained on millions of images sourced from the Internet, each paired with a detailed caption produced by Vision-Language Models (VLMs). This part of the training pipeline is critical for supplying the models with large volumes of high-quality image-caption pairs during training. However, recent work suggests that VLMs are vulnerable to stealthy adversarial attacks, where adversarial perturbations are added to images to mislead the VLMs into producing incorrect captions. In this paper, we explore the feasibility of adversarial mislabeling attacks on VLMs as a mechanism to poisoning training pipelines for text-to-image models. Our experiments demonstrate that VLMs are highly vulnerable to adversarial perturbations, allowing attackers to produce benign-looking images that are consistently miscaptioned by the VLM models. This has the effect of injecting strong ''dirty-label'' poison samples into the training pipeline for text-to-image models, successfully altering their behavior with a small number of poisoned samples. We find that while potential defenses can be effective, they can be targeted and circumvented by adaptive attackers. This suggests a cat-and-mouse game that is likely to reduce the quality of training data and increase the cost of text-to-image model development. Finally, we demonstrate the real-world effectiveness of these attacks, achieving high attack success (over 73%) even in black-box scenarios against commercial VLMs (Google Vertex AI and Microsoft Azure).}
}


@inproceedings{DBLP:conf/ccs/Xu0KP25,
	author = {Xiaoyun Xu and
                  Zhuoran Liu and
                  Stefanos Koffas and
                  Stjepan Picek},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Towards Backdoor Stealthiness in Model Parameter Space},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {2863--2876},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744846},
	doi = {10.1145/3719027.3744846},
	timestamp = {Fri, 26 Dec 2025 20:53:03 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/Xu0KP25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Backdoor attacks maliciously inject covert functionality into machine learning models, which has been considered a security threat. The stealthiness of backdoor attacks is a critical research direction, focusing on adversaries' efforts to enhance the resistance of backdoor attacks against defense mechanisms. Recent research on backdoor stealthiness focuses mainly on indistinguishable triggers in input space and inseparable backdoor representations in feature space, aiming to circumvent backdoor defenses that examine these respective spaces. However, existing backdoor attacks are typically designed to resist a specific type of backdoor defense without considering the diverse range of defense mechanisms. Based on this observation, we pose a natural question:  Are current backdoor attacks truly a real-world threat when facing diverse practical defenses? To answer this question, we examine 12 common backdoor attacks that focus on input-space or feature-space stealthiness and 17 diverse representative defenses. Surprisingly, we reveal a critical blind spot that backdoor attacks designed to be stealthy in input and feature spaces can be mitigated by examining backdoored models in parameter space. To investigate the underlying causes behind this common vulnerability, we study the characteristics of backdoor attacks in the parameter space. Notably, we find that input- and feature-space attacks introduce prominent backdoor-related neurons in parameter space, which are not thoroughly considered by current backdoor attacks. Taking comprehensive stealthiness into account, we propose a novel supply-chain attack called Grond. Grond limits the parameter changes by a simple yet effective module, Adversarial Backdoor Injection (ABI), which adaptively increases the parameter-space stealthiness during the backdoor injection. Extensive experiments demonstrate that Grond outperforms all 12 backdoor attacks against state-of-the-art (including adaptive) defenses on CIFAR-10, GTSRB, and a subset of ImageNet. In addition, we show that ABI consistently improves the effectiveness of common backdoor attacks. Our code is publicly available.}
}


@inproceedings{DBLP:conf/ccs/LeeKSC25,
	author = {De Zhang Lee and
                  Aashish Kolluri and
                  Prateek Saxena and
                  Ee{-}Chien Chang},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {A Practical and Secure Byzantine Robust Aggregator},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {2877--2891},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744851},
	doi = {10.1145/3719027.3744851},
	timestamp = {Fri, 26 Dec 2025 20:53:03 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/LeeKSC25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In machine learning security, one is often faced with the problem of removing outliers from a given set of high-dimensional vectors when computing their average. For example, many variants of data poisoning attacks produce gradient vectors during training that are outliers in the distribution of clean gradients, which bias the computed average used to derive the ML model. Filtering them out before averaging serves as a generic defense strategy. Byzantine robust aggregation is an algorithmic primitive which computes a robust average of vectors, in the presence of an ε fraction of vectors which may have been arbitrarily and adaptively corrupted, such that the resulting bias in the final average is provably bounded. In this paper, we give the first robust aggregator that runs in quasi-linear time in the size of input vectors and provably has near-optimal bias bounds. Our algorithm also does not assume any knowledge of the distribution of clean vectors, nor does it require pre-computing any filtering thresholds from it. This makes it practical to use directly in standard neural network training procedures. We empirically confirm its expected runtime efficiency and its effectiveness in nullifying 10 different ML poisoning attacks.}
}


@inproceedings{DBLP:conf/ccs/Yu0WD025,
	author = {Wenxuan Yu and
                  Minghui Xu and
                  Bing Wu and
                  Sisi Duan and
                  Xiuzhen Cheng},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {{AD-MPC:} Asynchronous Dynamic {MPC} with Guaranteed Output Delivery},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {2892--2906},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765166},
	doi = {10.1145/3719027.3765166},
	timestamp = {Fri, 26 Dec 2025 20:53:03 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/Yu0WD025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {MPC-as-a-Service (MPCaaS) systems enable clients to outsource privacy-preserving computations to distributed servers, offering flexibility by adapting and configuring MPC protocols to meet diverse security requirements. However, traditional MPC protocols rely on a fixed set of servers for the entire computation process, limiting scalability. Dynamic MPC (DMPC) addresses this limitation by permitting participants to join or leave during the computation. Nevertheless, existing DMPC protocols assume synchronous networks, which can lead to failures under unbounded network delays. In this paper, we present AD-MPC, the first asynchronous dynamic MPC protocol. Our protocol ensures guaranteed output delivery under optimal resilience (( n  = 3 t  + 1)). To achieve this, we introduce two critical components: an asynchronous dynamic preprocessing protocol that facilitates the on-demand generation of Beaver triples for secure multiplication, and an asynchronous transfer protocol that maintains consistency during party hand-offs. These components collectively ensure computation correctness and transfer consistency across participants. We implement AD-MPC and evaluate its performance across up to 20 geographically distributed nodes. Experimental results demonstrate that the protocol not only offers strong security guarantees in dynamic and asynchronous network environments but also achieves performance comparable to state-of-the-art DMPC protocols.}
}


@inproceedings{DBLP:conf/ccs/0004WF25,
	author = {Zeyu Liu and
                  Yunhao Wang and
                  Ben Fisch},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {{IND-CPA-D} of Relaxed Functional Bootstrapping: {A} New Attack, {A}
                  General Fix, and {A} Stronger Model},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {2907--2921},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765170},
	doi = {10.1145/3719027.3765170},
	timestamp = {Fri, 26 Dec 2025 20:53:03 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/0004WF25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Fully homomorphic encryption (FHE) is a powerful and widely used primitive in lots of real-world applications. Recently, Li and Micciancio [Eurocrypt'21] introduced IND-CPA-D security, which strengthens the standard IND-CPA security by allowing the attacker to access a decryption oracle for honestly generated ciphertexts. Recently, Jung et al. [CCS'24] and Checri et al. [Crypto'24] have shown that even exact FHE schemes like FHEW/TFHE/BGV/BFV may still not be IND-CPA-D secure, by exploiting the bootstrapping failure. However, such attacks can be mitigated by setting negligible bootstrapping failure probability. On the other hand, Liu and Wang [Asiacrypt'24] proposed relaxed functional bootstrapping, which has orders of magnitude performance improvement and furthermore allows a free function evaluation during bootstrapping. These efficiency advantages make it a competitive choice in many applications. In this work, we show that the underlying secret key could be recovered within 10 minutes against all existing relaxed functional bootstrapping constructions, and even within 1 minute for some of them. Moreover, our attack works even with a negligible bootstrapping failure probability. Additionally, we propose a general fix that mitigates all the existing modulus-switching-error-based attacks in the IND-CPA-D model. This is achieved by constructing a new modulus switching procedure with essentially no overhead. Lastly, we show that IND-CPA-D may not be sufficient even for passive adversary model. Thus, we extend this model to IND-CPA-D with randomness (IND-CPA-DR).}
}


@inproceedings{DBLP:conf/ccs/HanffLO25,
	author = {Konrad Hanff and
                  Anja Lehmann and
                  Cavit {\"{O}}zbay},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Security Analysis of Privately Verifiable Privacy Pass},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {2922--2936},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765172},
	doi = {10.1145/3719027.3765172},
	timestamp = {Fri, 26 Dec 2025 20:53:03 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/HanffLO25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Privacy Pass is an anonymous authentication protocol which was initially designed by Davidson et al. (PETS'18) to reduce the number of CAPTCHAs that TOR users must solve. It issues single-use authentication tokens with anonymous and unlinkable redemption guarantees. The issuer and verifier of the protocol share a symmetric key, and tokens are privately verifiable. The protocol has sparked interest from both academia and industry, which led to an Internet Engineering Task Force (IETF) standard. While Davidson et al. formally analyzed the original protocol, the IETF standard introduces several changes to their protocol. Thus, the standardized version's formal security remains unexamined. We fill this gap by analyzing the IETF standard's privately verifiable Privacy Pass protocol. In particular, there are two main discrepancies between the analyzed and standardized version: First, the IETF version introduces a redemption context, that can be used for blindly embedding a validity period into the Privacy Pass tokens. We show that this variant has significant differences to public metadata extension that has been proposed for the same purpose in the literature. Redemption context offers better privacy and security than public metadata. We capture both stronger guarantees through game-based security definitions and show that the currently considered one-more unforgeability notion for Privacy Pass is insufficient when a redemption context is used. Thus, we propose a new property, targeted context unforgeability, and prove its incomparability to one-more unforgeability. Second, Davidson et al. focused on a concrete Diffie-Hellman based construction, whereas the IETF version is built generically from a verifiable oblivious pseudorandom function (VOPRF). Further, the analyzed protocol omitted the full redemption phase needed to prevent double-spending. We prove that the generic IETF construction satisfies the desired security and privacy guarantees covering the full life-cycle of tokens. Our analysis relies on natural security properties of VOPRFs, providing compatibility with any secure VOPRF instantiation. This enables crypto agility, e.g., allowing to switch to efficient quantum-safe VOPRFs when they become available.}
}


@inproceedings{DBLP:conf/ccs/Lyu0ZD25,
	author = {Yingjie Lyu and
                  Zengpeng Li and
                  Hong{-}Sheng Zhou and
                  Xudong Deng},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Threshold {ECDSA} in Two Rounds},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {2937--2950},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765176},
	doi = {10.1145/3719027.3765176},
	timestamp = {Fri, 26 Dec 2025 20:53:03 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/Lyu0ZD25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We propose the first two-round multi-party signing protocol for the Elliptic Curve Digital Signature Algorithm (ECDSA) in the threshold-optimal setting, reducing the number of rounds by one compared to the state of the art (Doerner et al., S&P '24). We also resolve the security issue of presigning pointed out by Groth and Shoup (Eurocrypt '22), evading a security loss that increases with the number of pre-released, unused presignatures, for the first time among threshold-optimal schemes. Our construction builds on Non-Interactive Multiplication (NIM), a notion proposed by Boyle et al. (PKC '25), which allows parties to evaluate multiplications on secret-shared values in one round. In particular, we use the construction of Abram et al. (Eurocrypt '24) instantiated with class groups. The setup is minimal and transparent, consisting of only two class-group generators. The signing protocol is efficient in bandwidth, with a message size of 1.9 KiB at 128-bit security, and has competitive computational performance.}
}


@inproceedings{DBLP:conf/ccs/DeoJLCB25,
	author = {Amit Deo and
                  Marc Joye and
                  Beno{\^{\i}}t Libert and
                  Benjamin R. Curtis and
                  Mayeul de Bellabre},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Fast Homomorphic Evaluation of LWR-based PRFs},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {2951--2965},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765177},
	doi = {10.1145/3719027.3765177},
	timestamp = {Fri, 26 Dec 2025 20:53:03 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/DeoJLCB25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Certain applications of fully homomorphic encryption (such as transciphering, universal thresholdizers, and PIR) require randomness while operating over encrypted data. This randomness has to be obliviously generated in the encrypted domain and remain encrypted throughout the computation. Moreover, it should be guaranteed that independent-looking random coins can be obliviously generated for different computations. In this work, we consider the homomorphic evaluation of pseudorandom functions (PRFs) with a focus on practical lattice-based candidates. In the homomorphic PRF evaluation setting, given a fully homomorphic encryption of the PRF secret key s, it should be possible to homomorphically compute encryptions of PRF evaluations {PRF s ( x i } M over i =1 for public inputs { x i . } M over i over=1 We consider this problem for PRF families based on the hardness of the Learning-With-Rounding (LWR) problem introduced by Banerjee, Peikert, and Rosen (EUROCRYPT 2012). We build on a random oracle variant of a PRF construction suggested by Banerjee  et al. , and demonstrate that it can be evaluated using only two sequential programmable bootstraps in the TFHE homomorphic encryption scheme. We also describe several modifications of this PRF---which we prove as secure as the original function---that support homomorphic evaluations using only one programmable bootstrap per slot. Numerical experiments were conducted using practically relevant FHE parameter sets from the TFHE-rs library. Our benchmarks show that a throughput of about 1000 encrypted pseudorandom bits per second (resp. 900 encrypted pseudorandom bits per second) can be achieved on an AWS hpc7a.96xlarge machine (resp. on a standard laptop with an Apple M2 chip), on a single thread. The PRF evaluation keys in our experiments have sizes roughly 40% and 60% of a bootstrapping key.}
}


@inproceedings{DBLP:conf/ccs/GuimaraesP25,
	author = {Antonio Guimar{\~{a}}es and
                  Hilder V. L. Pereira},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Fast Amortized Bootstrapping with Small Keys and Polynomial Noise
                  Overhead},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {2967--2981},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765181},
	doi = {10.1145/3719027.3765181},
	timestamp = {Sun, 07 Dec 2025 22:09:41 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/GuimaraesP25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Most homomorphic encryption (FHE) schemes exploit a technique called single-instruction multiple-data (SIMD) to process several messages in parallel. However, they base their security in somehow strong assumptions, such as the hardness of approximate lattice problems with  superpolynomial  approximation factor. On the other extreme of the spectrum, there are lightweight FHE schemes that have much faster bootstrapping but no SIMD capabilities. On the positive side, the security of these schemes is based on lattice problems with (low-degree) polynomial approximation factor only, which is a much weaker security assumption. Aiming the best of those two options, Micciancio and Sorrell (ICALP'18) proposed a new  amortized  bootstrapping that can process many messages at once, yielding sublinear time complexity per message, and allowing one to construct FHE based on lattice problems with polynomial approximation factor. Some subsequent works on this line achieve near-optimal asymptotic performance, nevertheless, concrete efficiency remains mostly an open problem. The only existing implementation to date (GPV23, Asiacrypt 2023) requires keys of up to a hundred gigabytes while only providing gains for relatively large messages. In this paper, we introduce a new method for amortized bootstrapping where the number of homomorphic operations required per message is  O ( h ) and the noise overhead is  O (√ h  λlogλ), where  h  is the Hamming weight of the LWE secret key and λ is the security parameter. This allows us to use much smaller parameters and to obtain faster running time. Our method is based on a new efficient homomorphic evaluation of sparse polynomial multiplication. We bootstrap 2 to 8-bit messages in 1.46 ms to 28.5 ms, respectively. Compared to TFHE-rs, this represents a performance improvement of 2.5 to 38.7 times while requiring bootstrapping keys up to 47.5 times smaller.}
}


@inproceedings{DBLP:conf/ccs/KirchnerTJN25,
	author = {Robin Kirchner and
                  Chris Tsoukaladelis and
                  Martin Johns and
                  Nick Nikiforakis},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {The Power to Never Be Wrong: Evasions and Anachronistic Attacks Against
                  Web Archives},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {2982--2996},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765051},
	doi = {10.1145/3719027.3765051},
	timestamp = {Fri, 26 Dec 2025 20:53:03 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/KirchnerTJN25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Web is subject to link rot, where links break as webpages are updated or deleted. Web archiving services, such as the Wayback Machine, have emerged as a key solution to address link rot by archiving web content and preserving the look and feel of websites over time. These services offer critical functionality to users, serving as a historical baseline for an ever-changing Web. Implicit in everyone's use of these services is that they are capable of providing an accurate record of the past and can, therefore, provide reliable ground truth for comparing the past to the present. In this paper, we demonstrate that this implicit assumption does not necessarily hold. To this end, we propose two new threat models against web archiving services in which attackers can exert control over how their websites are archived. Evasive adversaries can distinguish crawlers operated by web archiving services from regular users, selectively denying or altering the content delivered to the former. Anachronistic adversaries can not only identify archive crawlers but also deliver content that enables them to retain control over archived snapshots. By abusing fundamental access-control mechanisms of the Web, these attackers can effectively alter the past as recorded by web archiving services. We found that all web archives we investigated suffer from one or more of these issues, challenging our current reliance on them.}
}


@inproceedings{DBLP:conf/ccs/0004HK25,
	author = {Woonghee Lee and
                  Junbeom Hur and
                  Hyunsoo Kwon},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Deep Dive into In-app Browsers: Uncovering Hidden Pitfalls in Certificate
                  Validation},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {2997--3011},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765215},
	doi = {10.1145/3719027.3765215},
	timestamp = {Fri, 26 Dec 2025 20:53:04 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/0004HK25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {While providing a seamless user experience by enabling web access within the app, in-app browsers raise security concerns, particularly in certificate validation, which can leave users vulnerable to Man-In-The-Middle (MITM) or phishing attacks unless appropriately implemented.In this paper, we systematically evaluated the certificate validation mechanisms of in-app browsers, also known as WebView, focusing on how effectively they comply with X.509 certificate standards and support advanced certificate extensions related to revocation and Certificate Transparency (CT). To ensure reproducibility and enable platform-specific trust anchor control which is particularly challenging on Android 14 and later, we developed a unified framework called  FAITH  using physical devices for iOS and Android emulators. Using FAITH and 115 crafted certificate chains—including 87 non-compliant chains and 28 designed to test advanced certificate extensions—we tested 20 popular Android and iOS apps, as well as desktop and mobile browsers. Android WebView apps accepted 77.0% of non-compliant chains and all non-compliant intermediate CA certificate tests, significantly higher than mainstream browsers and iOS apps. We identified the root cause in Android WebView's reliance on the system-level certificate validation handler, which performs minimal checks and lacks support for extensions such as OCSP Must-Staple and Precertificate. Additionally, we found that cached intermediate CA certificates are reused during validation in Android WebView, which exposes the process to unintended bypass of certificate checks. To demonstrate its real-world impact, we constructed a detailed CA caching attack scenario, and disclosed it to responsible vendors including Google. The reported bug was subsequently acknowledged as a valid security vulnerability. Finally, we conclude by providing recommendations to improve WebView's certificate validation behavior.}
}


@inproceedings{DBLP:conf/ccs/Xie0ZHZWX0X25,
	author = {Ruotian Xie and
                  Kun Xie and
                  Pengcheng Zhao and
                  Jiajun He and
                  Xin Zeng and
                  Jigang Wen and
                  Yong Xie and
                  Wei Liang and
                  Gaogang Xie},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {GAPDiS: Gradient-Assisted Perturbation Design via Sequence Editing
                  for Website Fingerprinting Defense},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {3012--3026},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765084},
	doi = {10.1145/3719027.3765084},
	timestamp = {Fri, 26 Dec 2025 20:53:04 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/Xie0ZHZWX0X25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As deep learning-based website fingerprinting (WF) attacks become increasingly accurate, user privacy faces mounting risks. Existing defenses struggle with the discrete nature of packet direction sequences, rendering gradient-based optimization infeasible and leading to inefficient, heuristic-based perturbation solutions. We propose a novel defense framework that bridges this gap by introducing gradient---aligned offset vectors and a cosine similarity---based reward to evaluate and select perturbation candidates aligned with the gradient direction. We further design a parallel reward computation algorithm to improve efficiency and integrate it into GAPDiS, a universal perturbation generation method that combines gradient guidance with improved tabu search for global optimization. For practical deployment, GAPDiS supports both PT bridge and P4 switch implementations. Experiments on the AWF dataset show that GAPDiS reduces the classification accuracy of WF models from over 98% to below 7% with only 2.56% bandwidth overhead---achieving a 68.1% improvement over state-of-the-art methods.}
}


@inproceedings{DBLP:conf/ccs/SoFN25,
	author = {Johnny So and
                  Michael Ferdman and
                  Nick Nikiforakis},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {What Gets Measured Gets Managed: Mitigating Supply Chain Attacks with
                  a Link Integrity Management System},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {3027--3041},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765094},
	doi = {10.1145/3719027.3765094},
	timestamp = {Fri, 26 Dec 2025 20:53:04 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/SoFN25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The web continues to grow, but dependency-monitoring tools and standards for resource integrity lag behind. Currently, there exists no robust method to verify the integrity of web resources, much less in a generalizable yet performant manner, and supply chains remain one of the most targeted parts of the attack surface of web applications. In this paper, we present the design of LiMS, a transparent system to bootstrap link integrity guarantees in web browsing sessions with minimal overhead. At its core, LiMS uses a set of customizable integrity policies to declare the (un)expected properties of resources, verifies these policies, and enforces them for website visitors. We discuss how basic integrity policies can serve as building blocks for a comprehensive set of integrity policies, while providing guarantees that would be sufficient to defend against recent supply chain attacks detailed by security industry reports. Finally, we evaluate our open-sourced prototype by simulating deployments on a representative sample of 450 domains that are diverse in ranking and category. We find that our proposal offers the ability to bootstrap marked security improvements with an overall overhead of hundreds of milliseconds on initial page loads, and negligible overhead on reloads, regardless of network speeds. In addition, from examining archived data for the sample sites, we find that several of the proposed policy building blocks suit their dependency usage patterns, and would incur minimal administrative overhead.}
}


@inproceedings{DBLP:conf/ccs/DrescherMK0BJP25,
	author = {Jan Drescher and
                  Sepehr Mirzaei and
                  Soheil Khodayari and
                  David Klein and
                  Thomas Barber and
                  Martin Johns and
                  Giancarlo Pellegrino},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {In the {DOM} We Trust: Exploring the Hidden Dangers of Reading from
                  the {DOM} on the Web},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {3042--3056},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765117},
	doi = {10.1145/3719027.3765117},
	timestamp = {Fri, 26 Dec 2025 20:53:04 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/DrescherMK0BJP25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The DOM tree is a central part of modern web development, enabling JavaScript to interact with page content and structure. Only a few prior studies have studied its trustworthiness, despite its widespread use in guiding program logic and security decisions. Most notably, script gadgets have shown how this trust can be exploited by triggering the execution of benign JavaScript fragments with seemingly harmless markup injections. In this paper, we show that script gadgets are only the tip of the iceberg. Seemingly-benign markup injections can trigger the execution of fragments - that we call DOM gadgets - that, unlike script gadgets, do not necessarily result in a cross-site scripting vulnerability. Instead, they can result in a broader set of attacks, such as browser request hijacking attacks, cross-site request forgery attacks, and user interface manipulations. In this paper, we introduce an automated approach that combines static and dynamic analysis to detect  DOM gadgets , tracing flows from the DOM to security-sensitive sinks, and assessing the presence of validation or sanitization checks. We conduct a large-scale web crawl across the top 15k domains and identify 2.6 million DOM-to-sink data flows that could lead to DOM gadget exploitation. We complement this by automatically detecting markup injection vulnerabilities, finding 657 DOM gadgets on 37 sites with the markup injection vulnerability required to exploit the DOM gadget. We further analyze these flows to assess the presence and effectiveness of security checks, revealing that 10% of DOM gadget flows receive no validation or sanitization checks. Our results indicate that DOM-based input trust is both widespread and underprotected. Our work highlights the scale and diversity of DOM gadget vulnerabilities in the wild, motivating a rethink of the DOM's role in web application trust boundaries and offering tools to aid in their identification and mitigation.}
}


@inproceedings{DBLP:conf/ccs/RautenstrauchNR25,
	author = {Jannis Rautenstrauch and
                  Trung Tin Nguyen and
                  Karthik Ramakrishnan and
                  Ben Stock},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Head(er)s Up! Detecting Security Header Inconsistencies in Browsers},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {3057--3070},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765119},
	doi = {10.1145/3719027.3765119},
	timestamp = {Sun, 07 Dec 2025 22:09:44 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/RautenstrauchNR25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the modern Web, security headers are of the utmost importance for websites to provide protection against various attacks, such as Cross-Site Scripting, Clickjacking, and Cross-Site Leaks. As each security header uses a different syntax and has unique processing rules, correctly implementing them is a complex task for both browser and website developers. Inconsistency in browser behavior related to security headers harms websites as their security depends on their users' browsers. At the same time, compatibility issues may deter developers from deploying such headers in the first place. In this work, we performed a differential evaluation of the security header parsing and enforcement behavior in desktop and mobile browsers to uncover problematic browser differences. We systematically ran 177,146 tests covering 16 security-relevant headers multiple times in 16 browser configurations covering over 97% of the browser engine market share. We identified 5,606 (3.16%) tests that behave inconsistently across browsers. Our subsequent analysis revealed 42 root causes, highlighting the prevalence of implementation issues. 31 of these root causes were yet unknown and resulted in 36 bug reports against the affected browsers and specifications. Many of our reports have already resulted in fixes improving web consistency and users' security. To foster open science and enable browser vendors to continuously test their security header implementations, we open-source our test framework.}
}


@inproceedings{DBLP:conf/ccs/LiWW025,
	author = {Zongjie Li and
                  Daoyuan Wu and
                  Shuai Wang and
                  Zhendong Su},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Differentiation-Based Extraction of Proprietary Data from Fine-Tuned
                  LLMs},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {3071--3085},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744856},
	doi = {10.1145/3719027.3744856},
	timestamp = {Sun, 07 Dec 2025 22:09:42 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/LiWW025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The increasing demand for domain-specific and human-aligned Large Language Models (LLMs) has led to the widespread adoption of Supervised Fine-Tuning (SFT) techniques. SFT datasets often comprise valuable instruction-response pairs, making them highly valuable targets for potential extraction. This paper studies this critical research problem for the first time. We start by formally defining and formulating the problem, then explore various attack goals, types, and variants based on the unique properties of SFT data in real-world scenarios. Based on our analysis of extraction behaviors of direct extraction, we develop a novel extraction method specifically designed for SFT models, called Differentiated Data Extraction (DDE), which exploits the confidence levels of fine-tuned models and their behavioral differences from pre-trained base models. Through extensive experiments across multiple domains and scenarios, we demonstrate the feasibility of SFT data extraction using DDE. Our results show that DDE consistently outperforms existing extraction baselines in all attack settings. To counter this new attack, we propose a defense mechanism that mitigates DDE attacks with minimal impact on model performance. Overall, our research reveals hidden data leak risks in fine-tuned LLMs and provides insights for developing more secure models.}
}


@inproceedings{DBLP:conf/ccs/XuD0Z25,
	author = {Binyan Xu and
                  Xilin Dai and
                  Di Tang and
                  Kehuan Zhang},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {One Surrogate to Fool Them All: Universal, Transferable, and Targeted
                  Adversarial Attacks with {CLIP}},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {3087--3101},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744859},
	doi = {10.1145/3719027.3744859},
	timestamp = {Fri, 26 Dec 2025 20:53:04 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/XuD0Z25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Deep Neural Networks (DNNs) have achieved widespread success yet remain prone to adversarial attacks. Typically, such attacks either involve frequent queries to the target model or rely on surrogate models closely mirroring the target model --- often trained with subsets of the target model's training data --- to achieve high attack success rates through transferability. However, in realistic scenarios where training data is inaccessible and excessive queries can raise alarms, crafting adversarial examples becomes more challenging. In this paper, we present  UnivIntruder , a novel attack framework that relies solely on a single, publicly available CLIP model and publicly available datasets. By using textual concepts, UnivIntruder generates universal, transferable, and targeted adversarial perturbations that mislead DNNs into misclassifying inputs into adversary-specified classes defined by textual concepts. Our extensive experiments show that our approach achieves an Attack Success Rate (ASR) of up to 85% on ImageNet and over 99% on CIFAR-10, significantly outperforming existing transfer-based methods. Additionally, we reveal real-world vulnerabilities, showing that even without querying target models,  UnivIntruder  compromises image search engines like  Google  and  Baidu  with ASR rates up to 84%, and vision language models like GPT-4 and Claude-3.5 with ASR rates up to 80%. These findings underscore the practicality of our attack in scenarios where traditional avenues are blocked, highlighting the need to reevaluate security paradigms in AI applications.}
}


@inproceedings{DBLP:conf/ccs/FanZ00000Z25,
	author = {Wenshu Fan and
                  Minxing Zhang and
                  Hongwei Li and
                  Wenbo Jiang and
                  Hanxiao Chen and
                  Xiangyu Yue and
                  Michael Backes and
                  Xiao Zhang},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {DivTrackee versus DynTracker: Promoting Diversity in Anti-Facial Recognition
                  against Dynamic {FR} Strategy},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {3102--3116},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744867},
	doi = {10.1145/3719027.3744867},
	timestamp = {Fri, 26 Dec 2025 20:53:04 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/FanZ00000Z25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The widespread adoption of facial recognition (FR) models raises serious concerns about their potential misuse, motivating the development of anti-facial recognition (AFR) to protect user facial privacy. In this paper, we argue that the static FR strategy, predominantly adopted in prior literature for evaluating AFR efficacy, cannot faithfully characterize the actual capabilities of determined trackers who aim to track a specific target identity. In particular, we introduce DynTracker, a dynamic FR strategy where the model's gallery database is iteratively updated with newly recognized target identity images. Surprisingly, such a simple approach renders all the existing AFR protections ineffective. To mitigate the privacy threats posed by DynTracker, we advocate for explicitly promoting diversity in the AFR-protected images. We hypothesize that the lack of diversity is the primary cause of the failure of existing AFR methods. Specifically, we develop DivTrackee, a novel method for crafting diverse AFR protections that builds upon a text-guided image generation framework and diversity-promoting adversarial losses. Through comprehensive experiments on various image benchmarks and feature extractors, we demonstrate DynTracker's strength in breaking existing AFR methods and the superiority of DivTrackee in preventing user facial images from being identified by dynamic FR strategies. We believe our work can act as an important initial step towards developing more effective AFR methods for protecting user facial privacy against determined trackers.}
}


@inproceedings{DBLP:conf/ccs/ChangLP00025,
	author = {Jiamin Chang and
                  Haoyang Li and
                  Hammond Pearce and
                  Ruoxi Sun and
                  Bo Li and
                  Minhui Xue},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {What's Pulling the Strings? Evaluating Integrity and Attribution in
                  {AI} Training and Inference through Concept Shift},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {3117--3131},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744868},
	doi = {10.1145/3719027.3744868},
	timestamp = {Fri, 26 Dec 2025 20:53:04 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/ChangLP00025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The growing adoption of artificial intelligence (AI) has amplified concerns about trustworthiness, including integrity, privacy, robustness, and bias. To assess and attribute these threats, we propose ConceptLens, a generic framework that leverages pre-trained multimodal models to identify the root causes of integrity threats by analyzing Concept Shift in probing samples. ConceptLens demonstrates strong detection performance for vanilla data poisoning attacks and uncovers vulnerabilities to bias injection, such as the generation of covert advertisements through malicious concept shifts. It identifies privacy risks in unaltered but high-risk samples, filters them before training, and provides insights into model weaknesses arising from incomplete or imbalanced training data. Additionally, at the model level, it attributes concepts that the target model is overly dependent on, identifies misleading concepts, and explains how disrupting key concepts negatively impacts the model. It uncovers sociological biases in generative content, revealing disparities across sociological contexts. ConceptLens reveals how otherwise safe training and inference data can be unintentionally and easily exploited to undermine safety alignment.}
}


@inproceedings{DBLP:conf/ccs/MahmoodMRVASM025,
	author = {Kaleel Mahmood and
                  Caleb Manicke and
                  Ethan Rathbun and
                  Aayushi Verma and
                  Sohaib Ahmad and
                  Nicholas Stamatakis and
                  Laurent Michel and
                  Benjamin Fuller},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Busting the Paper Ballot: Voting Meets Adversarial Machine Learning},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {3132--3146},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744882},
	doi = {10.1145/3719027.3744882},
	timestamp = {Fri, 26 Dec 2025 20:53:04 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/MahmoodMRVASM025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We show the security risk associated with using machine learning classifiers in United States election tabulators. The central classification task in election tabulation is deciding whether a  mark  does or does not appear on a  bubble  associated to an alternative in a contest on the ballot. Barretto et al. (E-Vote-ID 2021) reported that convolutional neural networks are a viable option in this field, as they outperform simple feature-based classifiers. Our contributions to election security can be divided into four parts. To demonstrate and analyze the hypothetical vulnerability of machine learning models on election tabulators, we first introduce four new ballot datasets. Second, we train and test a variety of different models on our new datasets. These models include support vector machines, convolutional neural networks (a basic CNN, VGG and ResNet), and vision transformers (Twins and CaiT). Third, using our new datasets and trained models, we demonstrate that traditional white box attacks are ineffective in the voting domain due to gradient masking. Our analyses further reveal that gradient masking is a product of numerical instability. We use a modified difference of logits ratio loss to overcome this issue (Croce and Hein, ICML 2020). Fourth, in the physical world, we conduct attacks with the adversarial examples generated using our new methods. In traditional adversarial machine learning, a high (50% or greater) attack success rate is ideal. However, for certain elections, even a 5% attack success rate can flip the outcome of a race. We show such an impact is possible in the physical domain. We thoroughly discuss attack realism, and the challenges and practicality associated with printing and scanning ballot adversarial examples.}
}


@inproceedings{DBLP:conf/ccs/Yang0XCZ0025,
	author = {Yanxin Yang and
                  Ming Hu and
                  Xiaofei Xie and
                  Yue Cao and
                  Pengyu Zhang and
                  Yihao Huang and
                  Mingsong Chen},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {FilterFL: Knowledge Filtering-based Data-Free Backdoor Defense for
                  Federated Learning},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {3147--3161},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744883},
	doi = {10.1145/3719027.3744883},
	timestamp = {Fri, 26 Dec 2025 20:53:04 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/Yang0XCZ0025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Due to the lack of data auditing techniques for untrusted clients, Federated Learning (FL) is vulnerable to backdoor attacks. Although various methods have been proposed to protect FL against backdoor attacks, they still exhibit poor defense performance in extreme data heterogeneity scenarios. Worse still, these methods strongly rely on additional datasets, violating the privacy protection requirements of FL. To overcome the above shortcomings, this paper proposes a novel data-free backdoor defense approach for FL, named FilterFL, which strives to prevent uploaded client models with backdoor knowledge from participating in the aggregation operation in each FL communication round. Based on our knowledge extraction and backdoor filtering schemes using two well-designed Conditional Generative Adversarial Networks (CGANs), FilterFL extracts incremental knowledge learned by a newly updated global model and filters its backdoor components, which can be used to generate one sample that reflects backdoor knowledge for each category. If an uploaded local model can confidently classify a generated sample into its target category, the knowledge contributed by the model will be excluded from the aggregation. In this way, FilterFL can effectively defend against backdoor attacks without using any additional auxiliary data. Comprehensive experiments on well-known datasets demonstrate that, compared with state-of-the-art methods, our approach achieves the best defense performance within various data heterogeneity scenarios.}
}


@inproceedings{DBLP:conf/ccs/RamuluSRRKA25,
	author = {Harshini Sri Ramulu and
                  Helen Schmitt and
                  Bogdan Rerich and
                  Rachel Gonzalez Rodriguez and
                  Tadayoshi Kohno and
                  Yasemin Acar},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Ethics in Computer Security Research: {A} Data-Driven Assessment of
                  the Past, the Present, and the Possible Future},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {3162--3176},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765071},
	doi = {10.1145/3719027.3765071},
	timestamp = {Fri, 26 Dec 2025 20:53:04 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/RamuluSRRKA25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Ethical questions are discussed regularly in computer security. Still, researchers in computer security lack clear guidance on how to make, document, and assess ethical decisions in research when what is morally right or acceptable is not clear-cut. In this work, we give an overview of the discussion of ethical implications in current published work in computer security by reviewing all 1154 publications at top 4 security conferences published in 2024, finding inconsistent levels of ethics reporting with a strong focus of reporting institutional or ethics board approval, human subjects protection, and responsible disclosure, and a lack of discussion of balancing harms and benefits. We further report on the results of a semi-structured interview study with 24 computer security and privacy researchers (among whom were also: reviewers, ethics committee members, and/or program chairs) and their ethical decision-making both as authors and during peer review, finding a strong desire for ethical research, but a lack of consistency in considered values, ethical frameworks (if articulated), decision-making, and outcomes. We present an overview of the current state of the discussion of ethics and current de-facto standards in computer security research, contributing suggestions to improve the state of ethics in computer security research.}
}


@inproceedings{DBLP:conf/ccs/XianTLKZS25,
	author = {Lu Xian and
                  Van Hong Tran and
                  Lauren Lee and
                  Meera Kumar and
                  Yichen Zhang and
                  Florian Schaub},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Layered, Overlapping, and Inconsistent: {A} Large-Scale Analysis of
                  the Multiple Privacy Policies and Controls of {U.S.} Banks},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {3177--3191},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765072},
	doi = {10.1145/3719027.3765072},
	timestamp = {Fri, 26 Dec 2025 20:53:04 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/XianTLKZS25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Privacy policies are often complex. An exception is the two-page standardized notice that U.S. financial institutions must provide under the Gramm-Leach-Bliley Act (GLBA). However, banks now operate websites, mobile apps, and other services that involve complex data sharing practices that require additional privacy notices and do-not-sell opt-outs. We conducted a large-scale analysis of how U.S. banks implement privacy policies and controls in response to GLBA; other federal privacy policy requirements; and the California Consumer Privacy Act (CCPA), a key example for U.S. state privacy laws. We focused on the disclosure and control of a set of especially privacy-invasive practices: third-party data sharing for marketing-related purposes. We collected privacy policies for the 2,067 largest U.S. banks, 45.2% of which provided multiple policies. Across disclosures and controls for the  same  bank, we identified frequent, concerning inconsistencies---53.8% of banks with multiple privacy policies indicated in GLBA notices that they do not share with third parties but disclosed sharing in other policies. This multiplicity of policies, with the inconsistencies it causes, may create consumer confusion and undermine the transparency goals of the very laws that require them. Our findings call into question whether current policy requirements, such as the GLBA notice, are achieving their intended goals in today's online banking landscape. We discuss potential avenues for reforming and harmonizing privacy policies and control requirements across federal and state laws.}
}


@inproceedings{DBLP:conf/ccs/PonticelloSAK25,
	author = {Alexander Ponticello and
                  Filipo Sharevski and
                  Simon Anell and
                  Katharina Krombholz},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {How Blind and Low-Vision Users Manage Their Passwords},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {3192--3205},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765081},
	doi = {10.1145/3719027.3765081},
	timestamp = {Fri, 26 Dec 2025 20:53:04 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/PonticelloSAK25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Managing passwords securely and conveniently is still an open problem for many users. Existing research has examined users' password management strategies and identified pain points, such as security concerns, leading to insecure practices. We investigate how Blind and Low-Vision (BLV) users tackle this problem and how password managers can assist them. This paper presents the results of a qualitative interview study with N = 33 BLV participants. We found that all participants utilize password managers to some extent, which they perceive as fairly accessible. However, the adoption is mainly driven by the convenience of storing and retrieving passwords. The security advantages -- generating strong, random passwords -- were avoided mainly due to the absence of  practical  accessibility. Password managers do not adhere to BLV users' underlying needs for agency, which stem from experiences with inaccessible software and vendors who deprioritize accessibility issues. Underutilization of password managers leads BLV users to adopt insecure practices, such as reusing predictable passwords or resorting to 'security through obscurity' by writing important credentials in braille. We conclude our analysis by discussing the need to implement practical accessibility and usability improvements for password managers as a way of establishing trust and secure practices while maintaining BLV users' agency.}
}


@inproceedings{DBLP:conf/ccs/YuldoshkhujaevJ25,
	author = {Shakhzod Yuldoshkhujaev and
                  Mijin Jeon and
                  Doowon Kim and
                  Nick Nikiforakis and
                  Hyungjoon Koo},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {A Decade-long Landscape of Advanced Persistent Threats: Longitudinal
                  Analysis and Global Trends},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {3206--3220},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765085},
	doi = {10.1145/3719027.3765085},
	timestamp = {Sun, 07 Dec 2025 22:09:45 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/YuldoshkhujaevJ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {An advanced persistent threat (APT) refers to a covert and long-term cyberattack, typically conducted by state-sponsored actors, targeting critical sectors and often remaining undetected for long periods. In response, collective intelligence from around the globe collaborates to identify and trace surreptitious activities, generating substantial documentation on APT campaigns publicly available on the web. While a multitude of prior works predominantly focus on specific aspects of APT cases, such as detection, evaluation, cyber threat intelligence, and dataset creation, limited attention has been devoted to revisiting and investigating these scattered dossiers in a longitudinal manner. The objective of our study lies in filling the gap by offering a macro perspective, connecting key insights and global trends in the past APT attacks. We systematically analyze six reliable sources--- three focused on technical reports and another three on threat actors--- examining 1,509 APT dossiers ( i.e.,  totaling 24,215 pages) spanning from 2014 to 2023 (a decade), and identifying 603 unique APT groups in the world. To efficiently unearth relevant information, we employ a hybrid methodology that combines rule-based information retrieval with large-language-model-based search techniques. Our longitudinal analysis reveals shifts in threat actor activities, global attack vectors, changes in targeted sectors, and the relationships between cyberattacks and significant events, such as elections or wars, which provides insights into historical patterns in APT evolution. Over the past decade, 154 countries have been affected, primarily using malicious documents and spear phishing as the dominant initial infiltration vectors, and a noticeable decline in zero-day exploitation since 2016. Furthermore, we present our findings through interactive visualization tools, such as an APT map or a flow diagram, to facilitate intuitive understanding of the global patterns and trends in APT activities.}
}


@inproceedings{DBLP:conf/ccs/Qu000Z025,
	author = {Yiting Qu and
                  Xinyue Shen and
                  Yixin Wu and
                  Michael Backes and
                  Savvas Zannettou and
                  Yang Zhang},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {UnsafeBench: Benchmarking Image Safety Classifiers on Real-World and
                  AI-Generated Images},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {3221--3235},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765088},
	doi = {10.1145/3719027.3765088},
	timestamp = {Fri, 26 Dec 2025 20:53:04 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/Qu000Z025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the advent of text-to-image models and concerns about their misuse, developers are increasingly relying on image safety classifiers to moderate their generated unsafe images. Yet, the performance of current image safety classifiers remains unknown for both real-world and AI-generated images. In this work, we propose  UnsafeBench , a benchmarking framework that evaluates the effectiveness and robustness of image safety classifiers, with a particular focus on the impact of AI-generated images on their performance. First, we curate a large dataset of 10K real-world and AI-generated images that are annotated as safe or unsafe based on a set of 11 unsafe categories of images (sexual, violent, hateful, etc.). Then, we evaluate the effectiveness and robustness of five popular image safety classifiers, as well as three classifiers that are powered by general-purpose visual language models. Our assessment indicates that existing image safety classifiers are not comprehensive and effective enough to mitigate the multifaceted problem of unsafe images. Also, there exists a distribution shift between real-world and AI-generated images in image qualities, styles, and layouts, leading to degraded effectiveness and robustness. Motivated by these findings, we build a comprehensive image moderation tool called  PerspectiveVision , which improves the effectiveness and robustness of existing classifiers, especially on AI-generated images. UnsafeBench and PerspectiveVision can aid the research community in better understanding the landscape of image safety classification in the era of generative AI.}
}


@inproceedings{DBLP:conf/ccs/GanevAMC25,
	author = {Georgi Ganev and
                  Meenatchi Sundaram Muthu Selva Annamalai and
                  Sofiane Mahiou and
                  Emiliano De Cristofaro},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {The Importance of Being Discrete: Measuring the Impact of Discretization
                  in End-to-End Differentially Private Synthetic Data},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {3236--3250},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765091},
	doi = {10.1145/3719027.3765091},
	timestamp = {Fri, 26 Dec 2025 20:53:04 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/GanevAMC25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Differentially Private (DP) generative marginal models are often used in the wild to release synthetic tabular datasets in lieu of sensitive data while providing formal privacy guarantees. These models approximate low-dimensional marginals or query workloads; crucially, they require the training data to be pre-discretized, i.e., continuous values need to first be partitioned into bins. However, as the range of values (or their domain) is often inferred directly from the training data, with the number of bins and bin edges typically defined arbitrarily, this approach can ultimately break end-to-end DP guarantees and may not always yield optimal utility. In this paper, we present an extensive measurement study of four discretization strategies in the context of DP marginal generative models. More precisely, we design DP versions of three discretizers (uniform, quantile, and k-means) and reimplement the PrivTree algorithm. We find that optimizing both the choice of discretizer and bin count can improve utility, on average, by almost 30% across six DP marginal models, compared to the default strategy and number of bins, with PrivTree being the best-performing discretizer in the majority of cases. We demonstrate that, while DP generative models with non-private discretization remain vulnerable to membership inference attacks, applying DP during discretization effectively mitigates this risk. Finally, we improve on an existing approach for automatically selecting the optimal number of bins, and achieve high utility while reducing both privacy budget consumption and computational overhead.}
}


@inproceedings{DBLP:conf/ccs/LouH000TL025,
	author = {Yang Lou and
                  Haibo Hu and
                  Qun Song and
                  Qian Xu and
                  Yi Zhu and
                  Rui Tan and
                  Wei{-}Bin Lee and
                  Jianping Wang},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Asymmetry Vulnerability and Physical Attacks on Online Map Construction
                  for Autonomous Driving},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {3251--3265},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765092},
	doi = {10.1145/3719027.3765092},
	timestamp = {Fri, 26 Dec 2025 20:53:04 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/LouH000TL025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {High-definition (HD) maps provide precise environmental information essential for prediction and planning in autonomous driving (AD) systems. Due to the high cost of labeling and maintenance, recent research has turned to online HD map construction using onboard sensor data, offering wider coverage and more timely updates for autonomous vehicles (AVs). However, the robustness of online map construction under adversarial conditions remains underexplored. In this paper, we present a systematic vulnerability analysis of online map construction models, which reveals that these models exhibit an inherent bias toward predicting symmetric road structures. In asymmetric scenes like forks or merges, this bias often causes the model to mistakenly predict a straight boundary that mirrors the opposite side. We demonstrate that this vulnerability persists in the real-world and can be reliably triggered by obstruction or targeted interference. Leveraging this vulnerability, we propose a novel two-stage attack framework capable of manipulating online constructed maps. First, our method identifies vulnerable asymmetric scenes along the victim AV's potential route. Then, we optimize the location and pattern of camera-blinding attacks and adversarial patch attacks. Evaluations on a public AD dataset demonstrate that our attacks can degrade mapping accuracy by up to 9.9% in average precision, render up to 44% of targeted routes unreachable, and increase unsafe planned trajectory rates—colliding with real-world road boundaries—by up to 27%. These attacks are also validated on a real-world testbed vehicle. We further analyze root causes of the symmetry bias, attributing them to training data imbalance, model architecture, and map element representation. Based on these findings, we propose asymmetric data fine-tuning as a targeted defense, which significantly improves model robustness. To the best of our knowledge, this study presents the first vulnerability assessment of online map construction models and introduces the first digital and physical attack against them.}
}


@inproceedings{DBLP:conf/ccs/0004GWFSKP25,
	author = {Alan Wang and
                  Pranav Gopalkrishnan and
                  Yingchen Wang and
                  Christopher W. Fletcher and
                  Hovav Shacham and
                  David Kohlbrenner and
                  Riccardo Paccagnella},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Pixnapping: Bringing Pixel Stealing out of the Stone Age},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {3266--3280},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765093},
	doi = {10.1145/3719027.3765093},
	timestamp = {Fri, 26 Dec 2025 20:53:04 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/0004GWFSKP25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Pixel stealing attacks enable malicious websites to leak sensitive content displayed in victim websites. The idea, introduced by Stone in 2013, is to embed victim websites in iframes and use SVG filters to compute on, and create side channels as a function of, those websites' pixels. Fortunately, despite the danger, pixel stealing attacks are all but mitigated today thanks to websites and web browsers heavily restricting iframes and cross-origin cookie sharing. This paper introduces a pixel stealing framework targeting Android devices that bypasses all browser mitigations and can even steal secrets from non-browser apps. Our key observation is that Android APIs enable an attacker to create an analog to Stone-style attacks outside of the browser. Specifically, a malicious app can force victim pixels into the rendering pipeline via Android  intents  and compute on those victim pixels using a stack of semi-transparent Android  activities . Crucially, our framework enables stealing secrets only stored locally (e.g., 2FA codes and Google Maps Timeline), which have never before been in reach of pixel stealing attacks. We instantiate our pixel stealing framework on Google and Samsung phones---which differ in both hardware and graphical software. On the Google phones, we additionally provide evidence that the pixel color-dependent timing measured in our attack is due to GPU graphical data compression. We demonstrate end-to-end attacks that steal pixels from both browser and non-browser victims, including accounts.google.com, gmail.com, Google Maps, Google Messages, and Venmo. Finally, we demonstrate an end-to-end attack capable of stealthily stealing security-critical and  ephemeral  2FA codes from Google Authenticator in under 30 seconds.}
}


@inproceedings{DBLP:conf/ccs/HuangS25,
	author = {Long Huang and
                  Kang G. Shin},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {HW-Spy: Handwriting Inference by Tracing Pen-Tail Movements},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {3281--3295},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765109},
	doi = {10.1145/3719027.3765109},
	timestamp = {Fri, 26 Dec 2025 20:53:04 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/HuangS25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {While keyboard typing has been the most common way of inputting texts, handwriting still plays an important role in generating, inputting, or recording information like filling out essential/private forms. Considerable research has been done to identify and demonstrate the risk of keystroke-inference attacks. However, little has been done on handwriting inference despite its high risk of leaking sensitive information. To assess this under-explored risk of information leakage, we present a novel handwriting-inference attack, called HW-Spy, by tracing the victim's pen-tail movements when both the pen tip and the writing surface are outside the view of the attacker's camera, which usually happens when the victim is multitasking during an online meeting, when the victim's writing scene (in a public space) is recorded by a remote camera, or when the victim's writing behaviors are captured by the surveillance camera in a bank/dealership/realty office. In particular, we apply image segmentation to the recorded video frames of the victim's writing activities and extract the victim's pen-tail movements as a 2D coordinate sequence. We then identify the stroke-associated movements from the recorded pen's in-air video frames using a 1D U-Net model trained for stroke mask prediction and segment the characters based on the thus-derived motion features. The pen-tail's coordinate segments are then fed into a Long Short-Term Memory (LSTM) network to reconstruct the actual handwriting, which is processed further by a transformer-based model to infer the hand-written content. Our extensive experimentation shows HW-Spy to achieve an accuracy, up to 84.2%, of personalized handwriting inference and a comparable accuracy, up to 79.5%, of non-personalized handwriting inference.}
}


@inproceedings{DBLP:conf/ccs/SchwartzYCZ25,
	author = {Hadleigh Schwartz and
                  Xiaofeng Yan and
                  Charles J. Carver and
                  Xia Zhou},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Combating Falsification of Speech Videos with Live Optical Signatures},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {3296--3310},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765112},
	doi = {10.1145/3719027.3765112},
	timestamp = {Fri, 26 Dec 2025 20:53:04 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/SchwartzYCZ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {High-profile speech videos are prime targets for falsification, owing to their accessibility and influence. This work proposes VeriLight, a low-overhead and unobtrusive system for protecting speech videos from visual manipulations of speaker identity and lip and facial motion. Unlike the predominant purely digital falsification detection methods, VeriLight creates dynamic physical signatures at the event site and embeds them into all video recordings via imperceptible modulated light. These physical signatures encode semantically-meaningful features unique to the speech event, including the speaker's identity and facial motion, and are cryptographically-secured to prevent spoofing. The signatures can be extracted from any video downstream and validated against the portrayed speech content to check its integrity. Key elements of VeriLight include (1) a framework for generating extremely compact (i.e., 150-bit), pose-invariant speech video features, based on locality-sensitive hashing; and (2) an optical modulation scheme that embeds >200 bps into video while remaining imperceptible both in video and live. Experiments on extensive video datasets show VeriLight achieves AUCs ≥ 0.99 and a true positive rate of 100% in detecting falsified videos. Further, VeriLight is highly robust across recording conditions, video post-processing techniques, and white-box adversarial attacks on its feature extraction methods. A demonstration of VeriLight is available at https://mobilex.cs.columbia.edu/verilight.}
}


@inproceedings{DBLP:conf/ccs/WangZJ0025,
	author = {Jinwen Wang and
                  Hongchao Zhang and
                  Chuanrui Jiang and
                  Andrew Clark and
                  Ning Zhang},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {ConTest: Taming the Cyber-physical Input Space in Fuzz Testing with
                  Control Theory},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {3311--3325},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765129},
	doi = {10.1145/3719027.3765129},
	timestamp = {Fri, 26 Dec 2025 20:53:04 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/WangZJ0025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the proliferation of Cyber-Physical Systems (CPSs) in daily life, the security of these systems is becoming an pressing problem. Fuzz testing has recently gained attention as a promising approach for automatically detecting vulnerabilities, however, the prohibitively large search space of physical and cyber inputs remains an open research challenge. To address this gap, the paper draws on control theory, leveraging physics-informed control models to guide exploration of the input space. We design and develop ConTest, a fuzzing tool that leverages Lyapunov functions of the control model for both detection and mutation to efficiently search through the parameter space with a provable guarantee on the effectiveness of bug-finding effectiveness under bounded dynamic model errors. We implemented a prototype of ConTest and deployed it to detect spatial and temporal input validation bugs in two representative robotic vehicle (RV) platforms, ArduPilot and PX4. A total of 253 input validation bugs were found, 58 of them being zero-day bugs, and 54 of them were acknowledged by the vendors.}
}


@inproceedings{DBLP:conf/ccs/ThomasAH000025,
	author = {Fabian Thomas and
                  Eric Garc{\'{\i}}a Arribas and
                  Lorenz Hetterich and
                  Daniel Weber and
                  Lukas Gerlach and
                  Ruiyi Zhang and
                  Michael Schwarz},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {RISCover: Automatic Discovery of User-exploitable Architectural Security
                  Vulnerabilities in Closed-Source {RISC-V} CPUs},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {3326--3340},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765141},
	doi = {10.1145/3719027.3765141},
	timestamp = {Sun, 07 Dec 2025 22:09:44 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/ThomasAH000025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The open and extensible RISC-V instruction set has enabled many new CPU vendors and implementations, but most commercial CPUs are closed-source, significantly hindering vulnerability analysis—especially for bugs exploitable from unprivileged user space. We present RISCover, a user-space framework for detecting architectural vulnerabilities in closed-source RISC-V CPUs. It compares instruction-sequence behavior across CPUs, identifying deviations without source code, hardware changes, or models, and achieving orders-of-magnitude speedups over RTL-based methods. Unlike prior work, RISCover runs user code on Linux directly on real hardware, exposing vulnerabilities exploitable by unprivileged attackers. Evaluated on 8 off-the-shelf CPUs from 3 different vendors, it uncovers 4 previously unknown vulnerabilities. Notably, GhostWrite lets unprivileged code write chosen bytes to physical memory, enabling arbitrary data leakage and full machine-mode execution, while 3 unprivileged ''halt-and-catch-fire'' bugs halt CPUs and misaligned zero-stores silently corrupt data. Our results highlight the pressing need for post-silicon fuzzing techniques. RISCover complements existing RTL-level fuzzers by enabling rapid and automated security analysis of closed-source CPUs.}
}


@inproceedings{DBLP:conf/ccs/KellasC00SDK0Y25,
	author = {Andreas D. Kellas and
                  Neophytos Christou and
                  Wenxin Jiang and
                  Penghui Li and
                  Laurent Simon and
                  Yaniv David and
                  Vasileios P. Kemerlis and
                  James C. Davis and
                  Junfeng Yang},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {PickleBall: Secure Deserialization of Pickle-based Machine Learning
                  Models},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {3341--3355},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765037},
	doi = {10.1145/3719027.3765037},
	timestamp = {Fri, 26 Dec 2025 20:53:04 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/KellasC00SDK0Y25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Machine learning model repositories, such as the Hugging Face Model Hub, facilitate model exchanges. However, bad actors can deliver malware through compromised models. Existing defenses, such as safer model formats, restrictive (but inflexible) loading policies, and model scanners, have shortcomings: 44.9% of popular models on Hugging Face still use the insecure pickle format, 15% of these cannot be loaded by restrictive loading policies, and model scanners have both false positives and false negatives. Pickle remains the  de facto  standard for model exchange, and the ML community lacks a tool that offers transparent safe loading. We present P ickle B all  to help machine learning engineers load pickle-based models safely. PickleBall statically analyzes the source code of machine learning libraries and computes custom policies that specify a safe load-time behavior for benign models. It then dynamically enforces these policies during load time as a drop-in replacement for the pickle module. P ickle B all  generates policies that correctly load 79.8% of benign pickle-based models in our dataset, while rejecting all (100%) malicious examples in the same dataset. In comparison, evaluated model scanners fail to identify known malicious models, and the state-of-the-art loader loads 22% fewer benign models than P ickle B all . P ickle B all  removes the threat of arbitrary function invocation from malicious pickle-based models, raising the bar for attackers as they have to depend on code reuse techniques.}
}


@inproceedings{DBLP:conf/ccs/LinWQCM25,
	author = {Bo Lin and
                  Shangwen Wang and
                  Yihao Qin and
                  Liqian Chen and
                  Xiaoguang Mao},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Give LLMs a Security Course: Securing Retrieval-Augmented Code Generation
                  via Knowledge Injection},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {3356--3370},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765049},
	doi = {10.1145/3719027.3765049},
	timestamp = {Fri, 26 Dec 2025 20:53:04 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/LinWQCM25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Retrieval-Augmented Code Generation (RACG) leverages external knowledge to enhance Large Language Models (LLMs) in code synthesis, improving the functional correctness of the generated code. However, existing RACG systems largely overlook security, leading to substantial risks. Especially, the poisoning of malicious code into knowledge bases can mislead LLMs, resulting in the generation of insecure outputs, which poses a critical threat in modern software development. To address this, we propose a security-hardening framework for RACG systems, CodeGuarder, that shifts the paradigm from retrieving only functional code examples to incorporating both functional code and security knowledge. Our framework constructs a security knowledge base by analyzing real-world vulnerabilities from the ReposVul dataset. For each code generation query, a retriever decomposes the query into fine-grained sub-tasks and fetches relevant security knowledge. To prioritize critical security guidance, we introduce a re-ranking and filtering mechanism by leveraging the LLMs' susceptibility to different vulnerability types. This filtered security knowledge is seamlessly integrated into the generation prompt. Our evaluation shows CodeGuarder significantly improves code security rates across various LLMs, achieving average improvements of 20.12% in standard RACG, and 31.53% and 21.91% under two distinct poisoning scenarios without compromising functional correctness. Furthermore, CodeGuarder demonstrates strong generalization, enhancing security even when the targeted language's security knowledge is lacking. This work presents CodeGuarder as a pivotal advancement towards building secure and trustworthy RACG systems.}
}


@inproceedings{DBLP:conf/ccs/Xie0WFLP25,
	author = {Mengfei Xie and
                  Yan Lin and
                  Hongtao Wu and
                  Jianming Fu and
                  Chenke Luo and
                  Guojun Peng},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Beyond Tag Collision: Cluster-based Memory Management for Tag-based
                  Sanitizers},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {3371--3385},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765059},
	doi = {10.1145/3719027.3765059},
	timestamp = {Sun, 07 Dec 2025 22:09:45 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/Xie0WFLP25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Tag-based sanitizers attach a small ''key'' to each pointer and a matching ''lock'' tag to its target memory object, enabling runtime verification of pointer-object consistency and helping developers to detect potential memory violations. However, the limited tag encoding space challenges existing studies in assigning distinct tags to memory objects across temporal and spatial dimensions, leading to potential tag collisions. Such limitations reduce the probabilistic protection capabilities of sanitizers and make them vulnerable to sophisticated tag probing attacks. In this paper, we present ClusterTag, a novel cluster-based memory allocator aimed at simultaneously mitigating tag collisions in both temporal and spatial dimensions. The core design of ClusterTag effectively balances the significant mismatch between tag encoding space and memory objects: it divides memory objects into multiple independent clusters, thereby limiting tag collisions to finite chunks within each cluster. To mitigate tag collisions across clusters, we design a cluster-grained heap randomization scheme. This approach introduces random address intervals between clusters and further breaks the entropy limitation of the tag space. ClusterTag has been implemented as an independent memory allocator that seamlessly integrates with tag-based sanitizers such as HWASan, and maintains comparable performance overhead (within 1%) at various randomization densities. Security evaluations on the Juliet dataset indicate that ClusterTag exhibits deterministic results across 500 repeated tests (5,652 reported and 1,530 missed), while the existing three types of tag assignment strategies all exhibit probabilistic false negatives due to tag collisions. Quantitative analysis across three tag collision distance metrics-minimum, average, and unpredictability-demonstrates that ClusterTag achieves balanced improvements across all three, whereas prior tag assignment schemes (random, staggered, fixed) show significant trade-offs in at least one metric.}
}


@inproceedings{DBLP:conf/ccs/HuangLCWLWW25,
	author = {Haohui Huang and
                  Yue Liu and
                  Yuxi Cheng and
                  Haiyang Wei and
                  Jiamu Liu and
                  Yu Wang and
                  Linzhang Wang},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Recover Function Signature from Combined Constraints},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {3386--3400},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765089},
	doi = {10.1145/3719027.3765089},
	timestamp = {Fri, 26 Dec 2025 20:53:04 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/HuangLCWLWW25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recovering function signatures is a cornerstone of binary program analysis, yet it remains a challenging task. Existing methods either rely on disassembly-based constraints, which struggle with cross-architecture compatibility and scalability, or adopt learning-based approaches that are resource-intensive and often inaccurate. In this paper, we present CDA, a novel decompilation-based method for recovering function signatures that combines the strengths of multiple decompilers while mitigating their limitations. The core idea behind CDA is leveraging probabilistic constraints to estimate the likelihood of each function signature recovery result produced by decompilers, guided by inference rules specifically designed to address the limitations of decompilers. Based on these probabilities, CDA selects the recovery results with the highest likelihood as the final outcomes. We extensively evaluate CDA across five tasks --- variadic function/position detection, parameter identification, return value detection, and parameter type recovery --- comparing it against state-of-the-art tools, including IDA, Ghidra, Binary Ninja, and TYGR. Experimental results show that CDA outperforms baseline tools across multiple architectures (x64, x86, AArch64, Arm, and Mips) and optimization levels (O0-O3), highlighting its robustness and reliability in diverse compilation environments.}
}


@inproceedings{DBLP:conf/ccs/YangLSLL25,
	author = {Nanzi Yang and
                  Xingyu Liu and
                  Wenbo Shen and
                  Jinku Li and
                  Kangjie Lu},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Dangers Behind Access Control: Understanding and Exploiting Implicit
                  Permissions in Kubernetes},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {3401--3415},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765106},
	doi = {10.1145/3719027.3765106},
	timestamp = {Fri, 26 Dec 2025 20:53:04 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/YangLSLL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As the de-facto standard for container orchestration, Kubernetes is extensively adopted by numerous companies and cloud vendors, making its security critical. In this paper, we define a new attack surface called  implicit permission:  The execution of explicitly granted permissions in Kubernetes dynamically leads to implicit operations on other resources, enabling new permissions beyond the explicitly granted ones. Such implicit permissions create security vulnerabilities that attackers can exploit to compromise an entire cluster. Automatically identifying implicit permissions is challenging due to implicit relation reasoning and dynamic behaviors across diverse components of Kubernetes. To address that, we devise a systematic approach that combines static analysis techniques with the advanced capabilities of the large language model (LLM, e.g., GPT-4.5). Initially, we develop a static analysis to identify all Kubernetes resources. Building on this, we use static analysis to identify all explicit permissions for each resource. Finally, by combining the semantic reasoning capabilities of LLMs with the pattern-based precision of static analysis, we reason about what explicit permissions may dynamically lead to implicit permissions through complex interactions and uncover 593 implicit permissions derived from explicit permissions. We use the implicit permission references as insights to identify potential risks of CNCF projects and applications provided by the top four cloud vendors. With responsible disclosure, we obtain five new CVEs, six acknowledgments of cloud vendors, and a bounty awarded by Google. These acknowledgments underlie the practical impact of our attack.}
}


@inproceedings{DBLP:conf/ccs/Zhang0HLZGLX0025,
	author = {Shiyang Zhang and
                  Chenggang Wu and
                  Chengxuan Hou and
                  Jinglin Lv and
                  Yinqian Zhang and
                  Qianyu Guo and
                  Yuanming Lai and
                  Mengyao Xie and
                  Yan Kang and
                  Zhe Wang},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Tide: An Efficient Kernel-level Isolation Execution Environment on
                  AArch64 via Dynamically Adjusting Output Address Size},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {3416--3430},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765111},
	doi = {10.1145/3719027.3765111},
	timestamp = {Fri, 26 Dec 2025 20:53:04 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/Zhang0HLZGLX0025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {To enforce the privilege separation in the kernel, kernel-level isolated execution environment (IEE) has become a recent research trend because it can protect critical resources and monitors. Our research found that to isolate the IEE memory, all existing IEEs must act as a reference monitor to isolate page tables and validate their updates, bringing a significant performance overhead. Hence, we propose Tide, a new kernel-level IEE based on the output address size hardware feature on AArch64, which could offload such checks to the hardware. However, it still faces the flexibility and security challenges. To address them, Tide presents using the stage-2 translation to expand the physical address range to flexibly map the IEE memory and perform extra access controls on the physical memory; it designs a novel gate to enter (sneak) into the IEE securely by disabling translation temporarily, and ensures it can only be executed at the fixed locations. The experimental results show that Tide is performant than all existing IEEs on protecting critical kernel structures and security tools.}
}


@inproceedings{DBLP:conf/ccs/Lewis-PyeNRZ25,
	author = {Andrew Lewis{-}Pye and
                  Joachim Neu and
                  Tim Roughgarden and
                  Luca Zanolini},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Accountable Liveness},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {3431--3445},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765032},
	doi = {10.1145/3719027.3765032},
	timestamp = {Fri, 26 Dec 2025 20:53:04 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/Lewis-PyeNRZ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Safety and liveness are the two classical security properties of consensus protocols. Recent works have strengthened safety with  accountability : should any safety violation occur, a sizable fraction of adversary nodes can be proven to be protocol violators. This paper studies to what extent analogous accountability guarantees are achievable for  liveness.  To reveal the full complexity of this question, we introduce an interpolation between the classical synchronous and partially-synchronous models that we call the  x-partially-synchronous network model  in which, intuitively, at most an  x  fraction of the time steps in any sufficiently long interval are asynchronous (and, as with a partially-synchronous network, all time steps are synchronous following the passage of an unknown ''global stablization time''). We prove a precise characterization of the parameter regime in which accountable liveness is achievable: if and only if  x  < 1/2 and ƒ <  n /2, where  n  denotes the number of nodes and ƒ the number of nodes controlled by an adversary. We further refine the problem statement and our analysis by parameterizing by the number of violating nodes identified following a liveness violation, and provide evidence that the guarantees achieved by our protocol are near-optimal (as a function of  x  and ƒ). Our results provide rigorous foundations for liveness-accountability heuristics such as the ''inactivity leaks'' employed in Ethereum.}
}


@inproceedings{DBLP:conf/ccs/CaoG25,
	author = {Shu{-}Jie Cao and
                  Dongning Guo},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {How to Beat Nakamoto in the Race},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {3446--3460},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765058},
	doi = {10.1145/3719027.3765058},
	timestamp = {Fri, 26 Dec 2025 20:53:04 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/CaoG25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper studies proof-of-work Nakamoto consensus protocols under bounded network delays, settling two long-standing questions in blockchain security: What is the most effective attack on block safety under a given block confirmation latency? And what is the resulting probability of safety violation? A Markov decision process (MDP) framework is introduced to precisely characterize the system state (including the blocktree and timings of all blocks mined), the adversary's potential actions, and the state transitions due to the adversarial action and the random block arrival processes. An optimal attack, called  bait-and-switch,  is proposed and proved to maximize the adversary's chance of violating block safety by ''beating Nakamoto in the race''. The exact probability of this violation is calculated for any given confirmation depth using Markov chain analysis, offering fresh insights into the interplay of network delay, confirmation rules, and blockchain security.}
}


@inproceedings{DBLP:conf/ccs/SunYH25,
	author = {Yucheng Sun and
                  Haifeng Yu and
                  Ruomu Hou},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Committee Selection with Non-Proportional Weights},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {3461--3475},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765074},
	doi = {10.1145/3719027.3765074},
	timestamp = {Fri, 26 Dec 2025 20:53:04 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/SunYH25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Committees  are extensively used in the designs of various Proof-of-Stake (PoS) blockchains. A committee is simply a randomly selected subset of the parties/nodes in the system. Ideally, the committee should i) be as small as possible, and ii) properly represent the entire system, in terms of the corruption ratio. Existing committee selection schemes all follow the principle of  proportionality,  which says that a committee member should neither over-represent nor under-represent the stake it holds. In this work, highly surprisingly, we discover that proportionality actually leads to sub-optimal designs. Namely, better security and smaller committee size can be achieved when parties over-represent/under-represent their stakes. We then explore such  non-proportional designs,  and show that they can help to reduce error by many orders of magnitude, under realistic settings and real-world stake distributions of 6 major cryptocurrencies.}
}


@inproceedings{DBLP:conf/ccs/ZurE25,
	author = {Roi Bar Zur and
                  Ittay Eyal},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Elastic Restaking Networks: United we fall, (partially) divided we
                  stand},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {3476--3489},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765077},
	doi = {10.1145/3719027.3765077},
	timestamp = {Fri, 26 Dec 2025 20:53:04 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/ZurE25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Many blockchain-based decentralized services require their validators (operators) to deposit stake (collateral), which is forfeited (slashed) if they misbehave. Restaking networks let validators secure multiple services by reusing stake. These networks have quickly gained traction, leveraging over 20 billion in stake. However, restaking introduces a new attack vector where validators can coordinate to misbehave across multiple services simultaneously, extracting digital assets while forfeiting their stake only once. Previous work focused either on preventing coordinated misbehavior or on protecting services if all other services are Byzantine and might unjustly cause slashing due to bugs or malice. The first model overlooks how a single Byzantine service can collapse the network, while the second ignores shared-stake benefits. To bridge the gap, we analyze the system as a strategic game of coordinated misbehavior, when a given fraction of the services are Byzantine. We introduce elastic restaking networks, where validators can allocate portions of their stake that may cumulatively exceed their total stake, and when allocations are lost, the remaining stake stretches to cover remaining allocations. We show that elastic networks exhibit superior robustness compared to previous approaches, and demonstrate a synergistic effect where an elastic restaking network enhances its blockchain's security, contrary to community concerns of an opposite effect in existing networks. We then design incentives for tuning validators' allocations. Our elastic restaking system and incentive design have immediate practical implications for deployed restaking networks.}
}


@inproceedings{DBLP:conf/ccs/00080L0Z00F25,
	author = {Shan Wang and
                  Ming Yang and
                  Yu Liu and
                  Yue Zhang and
                  Shuaiqing Zhang and
                  Zhen Ling and
                  Jiannong Cao and
                  Xinwen Fu},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Time Tells All: Deanonymization of Blockchain {RPC} Users with Zero
                  Transaction Fee},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {3490--3504},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765082},
	doi = {10.1145/3719027.3765082},
	timestamp = {Fri, 26 Dec 2025 20:53:04 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/00080L0Z00F25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Remote Procedure Call (RPC) services have become a primary gateway for users to access public blockchains. While they offer significant convenience, RPC services also introduce critical privacy challenges that remain insufficiently examined. Existing deanonymization attacks either do not apply to blockchain RPC users or incur costs like transaction fees assuming an active network eavesdropper. In this paper, we propose a novel deanonymization attack that can link an IP address of a RPC user to this user's blockchain pseudonym. Our analysis reveals a temporal correlation between the timestamps of transaction confirmations recorded on the public ledger and those of TCP packets sent by the victim when querying transaction status. We assume a strong passive adversary with access to network infrastructure, capable of monitoring traffic at network border routers or Internet exchange points. By monitoring network traffic and analyzing public ledgers, the attacker can link the IP address of the TCP packet to the pseudonym of the transaction initiator by exploiting the temporal correlation. This deanonymization attack incurs zero transaction fee. We mathematically model and analyze the attack method, perform large-scale measurements of blockchain ledgers, and conduct real-world attacks to validate the attack. Our attack achieves a high success rate of over 95% against normal RPC users on various blockchain networks, including Ethereum, Bitcoin and Solana.}
}


@inproceedings{DBLP:conf/ccs/KelkarGPBW25,
	author = {Mahimna Kelkar and
                  Aadityan Ganesh and
                  Aditi Partap and
                  Joseph Bonneau and
                  S. Matthew Weinberg},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Breaking Omert{\`{a}}: On Threshold Cryptography, Smart Collusion,
                  and Whistleblowing},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {3505--3519},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765087},
	doi = {10.1145/3719027.3765087},
	timestamp = {Fri, 26 Dec 2025 20:53:04 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/KelkarGPBW25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cryptographic protocols often make honesty assumptions---e.g., fewer than  t  out of  n  participants are adversarial. In practice, these assumptions can be hard to ensure, particularly given monetary incentives for participants to collude and deviate from the protocol. In this work, we explore combining techniques from cryptography and mechanism design to discourage collusion. We formalize protocols in which colluders submit a cryptographic proof to  whistleblow  against their co-conspirators, revealing the dishonest behavior publicly. We provide general results on the cryptographic feasibility, and show how whistleblowing fits a number of applications including secret sharing, randomness beacons, and anonymous credentials. We also introduce  smart collusion  --- a new model for players to collude. Analogous to blockchain smart contracts, smart collusion allows colluding parties to arbitrarily coordinate and impose penalties on defectors (e.g., those that blow the whistle). We show that unconditional security is impossible against smart colluders even when whistleblowing is anonymous and can identify all colluding players. On the positive side, we construct a whistleblowing protocol that requires only a small deposit and can protect against smart collusion even with roughly  t  times larger deposit.}
}


@inproceedings{DBLP:conf/ccs/ZhangJAYM00S025,
	author = {Tianfang Zhang and
                  Qiufan Ji and
                  Md Mojibur Rahman Redoy Akanda and
                  Zhengkun Ye and
                  Ahmed Tanvir Mahdad and
                  Cong Shi and
                  Yan Wang and
                  Nitesh Saxena and
                  Yingying Chen},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Harnessing Vital Sign Vibration Harmonics for Effortless and Inbuilt
                  {XR} User Authentication},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {3520--3534},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765060},
	doi = {10.1145/3719027.3765060},
	timestamp = {Fri, 26 Dec 2025 20:53:04 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/ZhangJAYM00S025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Extended Reality (XR) headsets are increasingly serving as repositories for substantial volumes of sensitive data and gateways to web applications. This transition highlights the need for convenient and secure user authentication solutions. Traditional password/PIN-based schemes are ill-suited to the XR's gesture- and voice-based interfaces and are prone to shoulder-surfing attacks. Some recent XR systems incorporate two-factor authentication, but it requires additional operations on a second device (e.g., a smartphone or wearable). In this work, we introduce the first effortless and inbuilt XR user authentication system by leveraging the harmonics of vibrations excited by users' vital signs. The system is transparent to users (no efforts during enrollment and authentication) and requires no additional hardware. The key idea is that vital signs (i.e., breathing and heart beating) naturally generate low-frequency mechanical vibrations, causing human skull to vibrate and produces harmonic signals. When the harmonics pass the human head, they carry rich biometrics associated with the wearer's skull structure and soft tissues, which can be captured by the XR motion sensors. Instead of directly utilizing the vibrations, we extract more reliable biometrics from the ratios among different harmonic frequencies, which capture wearers' unique head and facial attenuation properties and are non-volatile when the periodicity and amplitude of vital signs fluctuate. We further design an adaptive filter to mitigate the body motion distortions in common XR interactions. By adopting advanced deep learning models with the attention mechanism, our system realizes effective and robust authentication across XR scenarios. Evaluations across 10 months, with 52 users and two popular XR headsets, show that our system can accurately authenticate users with over 95% true positive rates and rejects unauthorized users with over 98% true negative rates under various XR scenarios, with biometrics remaining consistent over long-term periods.}
}


@inproceedings{DBLP:conf/ccs/HuCZ025,
	author = {Haitao Hu and
                  Peng Chen and
                  Yanpeng Zhao and
                  Yuqi Chen},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {AgentSentinel: An End-to-End and Real-Time Security Defense Framework
                  for Computer-Use Agents},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {3535--3549},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765064},
	doi = {10.1145/3719027.3765064},
	timestamp = {Fri, 26 Dec 2025 20:53:04 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/HuCZ025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Large Language Models (LLMs) have been increasingly integrated into computer-use agents, which can autonomously operate tools on a user's computer to accomplish complex tasks. However, due to the inherently unstable and unpredictable nature of LLM outputs, they may issue unintended tool commands or incorrect inputs, leading to potentially harmful operations. Unlike traditional security risks stemming from insecure user prompts, tool execution results from LLM-driven decisions introduce new and unique security challenges. These vulnerabilities span across all components of a computer-use agent. To mitigate these risks, we propose AgentSentinel, an end-to-end, real-time defense framework designed to mitigate potential security threats on a user's computer. AgentSentinel intercepts all sensitive operations within agent-related services and halts execution until a comprehensive security audit is completed. Our security auditing mechanism introduces a novel inspection process that correlates the current task context with system traces generated during task execution. To thoroughly evaluate AgentSentinel, we present BadComputerUse, a benchmark consisting of 60 diverse attack scenarios across six attack categories. The benchmark demonstrates a 87% average attack success rate on four state-of-the-art LLMs. Our evaluation shows that AgentSentinel achieves an average defense success rate of 79.6%, significantly outperforming all baseline defenses.}
}


@inproceedings{DBLP:conf/ccs/GanG25,
	author = {Andrew Gan and
                  Zahra Ghodsi},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Sentry: Authenticating Machine Learning Artifacts on the Fly},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {3550--3563},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765070},
	doi = {10.1145/3719027.3765070},
	timestamp = {Fri, 26 Dec 2025 20:53:04 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/GanG25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Machine learning systems increasingly rely on open-source artifacts such as datasets and models that are created or hosted by other parties. The reliance on external datasets and pre-trained models exposes the system to supply chain attacks where an artifact can be poisoned before it is delivered to the end-user. Such attacks are possible due to the lack of any authenticity verification in existing machine learning systems. Incorporating cryptographic solutions such as hashing and signing can mitigate the risk of supply chain attacks. However, existing frameworks for integrity verification based on cryptographic techniques can incur significant overhead when applied to state-of-the-art machine learning artifacts due to their scale, and are not compatible with GPU platforms. In this paper, we develop Sentry, a novel GPU-based framework that verifies the authenticity of machine learning artifacts by implementing cryptographic signing and verification for datasets and models. Sentry ties developer identities to signatures and performs authentication on the fly as artifacts are loaded on GPU memory, making it compatible with GPU data movement solutions such as NVIDIA GPUDirect that bypass the CPU. Sentry incorporates GPU acceleration of cryptographic hash constructions such as Merkle tree and lattice hashing, implementing memory optimizations and resource partitioning schemes for a high throughput performance. Our evaluations show that Sentry is a practical solution to bring authenticity to machine learning systems, achieving orders of magnitude speedup over a CPU-based baseline.}
}


@inproceedings{DBLP:conf/ccs/QingYD0LL00025,
	author = {Yuqi Qing and
                  Qilei Yin and
                  Xinhao Deng and
                  Xiaoli Zhang and
                  Peiyang Li and
                  Zhuotao Liu and
                  Kun Sun and
                  Ke Xu and
                  Qi Li},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Training Robust Classifiers for Classifying Encrypted Traffic under
                  Dynamic Network Conditions},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {3564--3578},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765073},
	doi = {10.1145/3719027.3765073},
	timestamp = {Fri, 26 Dec 2025 20:53:04 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/QingYD0LL00025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Most existing DL-based encrypted traffic classification methods suffer performance degradation in real-world deployments due to dynamic network conditions,  e.g. , network environment changes and traffic obfuscation. Dynamic network conditions cause encrypted traffic to exhibit distinct feature patterns during training and testing phases. To address this issue, we propose  MetaTraffic,  a novel and general DL training framework built upon meta-learning that enhances the performance of supervised DL models designed for encrypted traffic classification against dynamic network conditions. Our key observation is that the traffic of the same network behaviors share the same semantic features even under different network conditions, which can be considered as stable feature representations. Therefore,  MetaTraffic  helps DL models learn stable feature representations by minimizing the discrepancies in how the models represent traffic features under different network conditions, thereby achieving robust classification under dynamic network conditions. We implement  MetaTraffic  based on meta-learning with three innovative facilitate modules to enhance its performance. We evaluate  MetaTraffic  using three public datasets and three new large-scale encrypted traffic datasets that cover multiple types of network conditions. Experimental results show that, under dynamic multiple types of network conditions, our framework improves the accuracy of DL models by 8.94% and the F1-Macro score by 12.55%, while existing robust training methods decrease the accuracy by 28.85% and the F1-Macro score by 33.52%.}
}


@inproceedings{DBLP:conf/ccs/ImgrundER25,
	author = {Erik Imgrund and
                  Thorsten Eisenhofer and
                  Konrad Rieck},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Adversarial Observations in Weather Forecasting},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {3579--3590},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765076},
	doi = {10.1145/3719027.3765076},
	timestamp = {Fri, 26 Dec 2025 20:53:04 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/ImgrundER25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {AI-based systems, such as Google's GenCast, have recently redefined the state of the art in weather forecasting, offering more accurate and timely predictions of both everyday weather and extreme events. While these systems are on the verge of replacing traditional meteorological methods, they also introduce new vulnerabilities into the forecasting process. In this paper, we investigate this threat and present a novel attack on autoregressive diffusion models, such as those used in GenCast, capable of manipulating weather forecasts and fabricating extreme events, including hurricanes, heat waves, and intense rainfall. The attack introduces subtle perturbations into weather observations that are statistically indistinguishable from natural noise and change less than 0.1% of the measurements—comparable to tampering with data from a single meteorological satellite. As modern forecasting integrates data from nearly one hundred satellites and many other sources operated by different countries, our findings highlight a critical security risk with the potential to cause large-scale disruptions and undermine public trust in weather forecasting.}
}


@inproceedings{DBLP:conf/ccs/XuXXW0025,
	author = {Shuo Xu and
                  Jiming Xu and
                  Pengfei Xue and
                  Xinyao Wang and
                  Lei Ju and
                  Wei Zhang},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Co-Prime: {A} Co-design Framework for Privacy Preserving Machine Learning
                  on {FPGA}},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {3591--3604},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765090},
	doi = {10.1145/3719027.3765090},
	timestamp = {Fri, 26 Dec 2025 20:53:04 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/XuXXW0025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In enormous privacy-sensitive machine learning application domains with collaborative data acquisition from multiple participants, secure multi-party computation (MPC) becomes a promising solution for privacy-preserving machine learning (PPML). Secret sharing protocols is a prevalent MPC strategy, where frequent data distribution and recombination are applied to uphold the confidentiality of participants' data. A key challenge for practical deployment of secret sharing protocols in PPML is the massive and unbalanced computation and communication workloads occurred in various linear and non-linear stages of machine learning. The imbalance could be further amplified when powerful hardware accelerators are designed to reduce the computation latency. In this work, we propose Co-Prime, an FPGA-based 3PC framework for efficient PPML without assistance from a secure third party. Co-Prime integrates protocol and hardware co-optimizations to mitigate the communication bottlenecks in secret sharing schemes. Particularly, Co-Prime proposes a novel protocol conversion technique that seamlessly converts data formats to adaptively adopt preferred protocols in various stages of PPML. Accelerator-friendly MPC primitives and system-level design space exploration schemes are designed to achieve latency hiding through overlapping computation and network communication. Finally, it enables direct interaction with data streams via network communication modules on FPGAs to further reduce the network communication overhead. Experimental results demonstrate significant performance improvements over existing privacy-preserving machine learning frameworks, with 2-18x speedup in inference latency across various LAN/WAN environments and neural network models.}
}


@inproceedings{DBLP:conf/ccs/ShuklaD0AMRC25,
	author = {Amey Shukla and
                  Luke Demarest and
                  Benjamin Fuller and
                  Sohaib Ahmad and
                  Caleb Manicke and
                  Alexander Russell and
                  Sixia Chen},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Fuzzy Extractors are Practical: Cryptographic Strength Key Derivation
                  from the Iris},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {3605--3619},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765098},
	doi = {10.1145/3719027.3765098},
	timestamp = {Fri, 26 Dec 2025 20:53:04 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/ShuklaD0AMRC25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Despite decades of effort, a persistent chasm has existed between the theory and practice of device-level biometric authentication. Theoretical constructions can, in principle, provide biometric authentication with cryptographically secure public enrollment data. However, concrete implementations of these techniques have failed to provide security with real-world parameters. The result is that deployed authentication algorithms rely on data that overtly leaks private information about the biometric; thus systems rely on externalized security measures such as trusted execution environments. We close this chasm . We introduce a key derivation system with 105 bits of entropy and a 92% true accept rate (TAR) for the iris. Our system advances 1) the feature extraction from the iris and 2) the fuzzy extractor used to derive keys. The fuzzy extractor builds on sample-then-lock (Canetti et al., Journal of Cryptology 2021). We (1) Introduce a new sampling method with a better trade-off between TAR and entropy when features have different quality, (2) Correct Canetti et al.'s main security proof, showing the minimum of min-entropy over subsets is the relevant security measure, and (3) Tighten Canetti et al.'s concrete analysis, nearly doubling security under reasonable assumptions. Our final feature extractor incorporates ideas from the new sampling method to produce features optimized for the sample-then-lock construction. The only statistical assumption needed to show security of our system is necessary: the accuracy of min-entropy estimation. At 105 bits, our quantitative level of security is well above prior work. Simhadri et al. (ISC, 2019) report 32 bits on the iris, but they have a bug in their analysis that reduces their strength. Zhang et al.'s (ePrint 2021/1559) system achieves 45 bits on the face but assumes independence between biometrics and the used error-correcting code, an assumption that cannot be easily verified.}
}


@inproceedings{DBLP:conf/ccs/BoldyrevaMT25,
	author = {Alexandra Boldyreva and
                  Deep Inder Mohan and
                  Tianxin Tang},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {May the Force \emph{Not} Be With You: Brute-Force Resistant Biometric
                  Authentication and Key Reconstruction},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {3620--3634},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744886},
	doi = {10.1145/3719027.3744886},
	timestamp = {Fri, 26 Dec 2025 20:53:04 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/BoldyrevaMT25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The use of biometric-based security protocols is on the steep rise. As biometrics become more popular, we witness more attacks. For example, recent BrutePrint/InfinityGauntlet attacks showed how to brute-force fingerprints stored on an Android phone in about 40 minutes. The attacks are possible because biometrics, like passwords, do not have high entropy. But unlike passwords, brute-force attacks are much more damaging for biometrics, because one cannot easily change biometrics in case of compromise. In this work, we propose a novel provably secure Brute-Force Resistant Biometrics (BFRB) protocol for biometric-based authentication and key reconstruction that protects against brute-force attacks even when the server storing biometric-related data is compromised. Our protocol utilizes a verifiable partially oblivious pseudorandom function, an authenticated encryption scheme, a pseudorandom function, and a hash. We formally define security for a BFRB protocol and reduce the security of our protocol to the security of the building blocks. We implement the protocol and study its performance for the ND-0405 iris dataset.}
}


@inproceedings{DBLP:conf/ccs/SunL00WW25,
	author = {Yunqing Sun and
                  Hanlin Liu and
                  Kang Yang and
                  Yu Yu and
                  Xiao Wang and
                  Chenkai Weng},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Committed Vector Oblivious Linear Evaluation and Its Applications},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {3635--3648},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744887},
	doi = {10.1145/3719027.3744887},
	timestamp = {Fri, 26 Dec 2025 20:53:04 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/SunL00WW25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We introduce the notion of committed vector oblivious linear evaluation (C-VOLE), which allows a party holding a pre-committed vector to generate VOLE correlations with multiple parties on the committed value. It is a unifying tool that can be found useful in zero-knowledge proofs (ZKPs) of committed values, actively secure multi-party computation, private set intersection (PSI), etc. To achieve the best efficiency, we design a tailored commitment scheme and matching C-VOLE protocols, both based on the learning parity with noise assumption. In particular, exploiting the structures of the carefully designed LPN-based commitment minimizes the cost of ensuring consistency between the committed vector and VOLE correlation. As a result, we achieve an 28× improvement over the protocol proposed in prior work (Usenix 2021) that uses ZKP to prove the correct opening of the commitment. We also apply C-VOLE to design a PSI protocol that allows one server to run PSI repeatedly with multiple clients while ensuring that the same set is used across all executions. Compared with the state-of-the-art PSI (CCS 2024) with similar security requirements, our protocol reduces the communication overhead by a factor of 35×.}
}


@inproceedings{DBLP:conf/ccs/Yu0FC0C25,
	author = {Jiping Yu and
                  Kun Chen and
                  Xiaoyu Fan and
                  Yunyi Chen and
                  Xiaowei Zhu and
                  Wenguang Chen},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Lodia: Towards Optimal Sparse Matrix-Vector Multiplication for Batched
                  Fully Homomorphic Encryption},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {3649--3663},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765025},
	doi = {10.1145/3719027.3765025},
	timestamp = {Tue, 20 Jan 2026 14:46:52 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/Yu0FC0C25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Encrypted matrix-vector multiplication is a fundamental component of a variety of applications that involve data privacy concerns. Current algorithms utilizing fully homomorphic encryption (FHE) generally use  batching  to enhance computational efficiency while neglecting the  sparsity  of the matrices, a characteristic that exists naturally in many practical situations. Alternatively, porting plaintext algorithms that skip zero elements to address sparsity may fail to utilize batching and introduce additional privacy concerns. We propose Lodia, an efficient outsourced sparse matrix-vector multiplication (SpMV) algorithm for batched FHE schemes without sacrificing privacy. It only requires Θ(( n + m )log( n + m )/ s ) FHE operations, where  n  is the number of rows/columns, m is the number of non-zero elements of the matrix, and  s  is the batch size of the FHE scheme. This is optimal for  m =Ω( n ) and  m = O ( n ρ ) for some ρ< 2 (i.e.,  an ≤ m ≤ bn ρ asymptotically), covering most practical cases. To our knowledge, no method has been published with better than Θ( n 2 / s ) FHE operations, suitable for any sparse matrix, and without privacy concerns. Lodia utilizes a novel  low-diagonal decomposition , which decomposes a sparse matrix into a series of special matrices named low-diagonal matrices. Based on a conventional method encoding the matrix in diagonal order, each low-diagonal matrix can be efficiently multiplied by a vector. This results in an efficient SpMV method suitable for any sparse matrix. Experiments show that Lodia practically achieves a speedup of up to 96× compared to baselines that ignore matrix sparsity, and up to 3.6× compared to implementations even with fewer security guarantees. This is the first SpMV solution on encrypted data that can process a substantial matrix with over 8 million rows/columns and 125 million non-zero elements.}
}


@inproceedings{DBLP:conf/ccs/Kondi025,
	author = {Yashvanth Kondi and
                  Divya Ravi},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Separating Broadcast from Cheater Identification},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {3664--3677},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765041},
	doi = {10.1145/3719027.3765041},
	timestamp = {Fri, 26 Dec 2025 20:53:04 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/Kondi025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Secure Multiparty Computation (MPC) protocols that achieve Identifiable Abort (IA) guarantee honest parties that if they are denied output, they will be notified of the identity of at least one corrupt party. Cheater identification provides recourse in the event of a protocol failure, and in some settings---such as key management---can even be desired over Guaranteed Output Delivery. However, unlike the weaker security with abort setting, IA protocols make integral use of a broadcast channel. In this work, we call attention to the fact that instantiating the broadcast channel itself---commonly overlooked in prior works on IA---may be the most complex and expensive component in deployments. For instance in ECDSA key management, broadcast would clearly dominate the cost of the secure computation (i.e. threshold signing). We therefore initiate a deeper investigation into the relationship between cheater identification and broadcast. As prior work has shown that the traditional notion of IA implies broadcast, we show that this connection can be circumvented: we allow honest parties to differ in which cheaters they identify, however with the ability to prove claims of cheating to any external auditor. We construct an honest majority threshold ECDSA signing protocol that offers our new notion of Provable Identifiable Selective Abort (PISA) without a traditional broadcast channel. This enables an efficient and easily deployable cheater identification mechanism for distributed key management. Our benchmarks show that with a signing threshold  t =10, the computational burden of the worst case execution path is under 500ms on standard hardware. Furthermore, we generalize our methodology: we show that any MPC protocol that achieves IA with  r  broadcasts can be compiled to one that achieves PISA with 2( r +1) point to point rounds.}
}


@inproceedings{DBLP:conf/ccs/ChenY0F0C25,
	author = {Yunyi Chen and
                  Jiping Yu and
                  Kun Chen and
                  Xiaoyu Fan and
                  Xiaowei Zhu and
                  Wenguang Chen},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Correlation-Aware Secure Sorting and Permutation for Iterative Two-Party
                  Graph Analysis},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {3679--3693},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765050},
	doi = {10.1145/3719027.3765050},
	timestamp = {Tue, 20 Jan 2026 14:46:52 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/ChenY0F0C25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Secure multi-party computation techniques enable in-depth analysis on joint graphs that inherently encompass comprehensive topology information and extended attributes, while preserving data privacy. In the two-party setting, existing approaches suffer from inefficiencies due to redundant secure sorting or costly secure shuffling operations required for secure message passing. Some works improve efficiency by relaxing security assumptions, either through differential privacy or by introducing helper parties. We present PETAL, a high-performance parallel framework for private iterative two-party graph analysis based on garbled circuits, ensuring simulation-based security under the semi-honest adversary assumption. Exploiting the iterative nature of graph analysis, we propose a novel two-party secret permutation protocol to replace secret sorting for data reordering after the first iteration, significantly improving performance. The protocol leverages correlations between permutations across iterations to reuse intermediate results, achieving linear communication after an initial setup. For the initial reordering, we design a two-party secret sorting protocol with low asymptotic complexity and small constant factors. On 2M-sized graphs, evaluations show PETAL achieves on average a 4.6× speedup and 55% less communication across four real-world applications, over the advanced version of the GraphSC framework by Araki et al.}
}


@inproceedings{DBLP:conf/ccs/RatliffBM25,
	author = {Zachary Ratliff and
                  Nicol{\'{a}}s Berrios and
                  James Mickens},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Timing Attacks on Differential Privacy are Practical},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {3694--3707},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765146},
	doi = {10.1145/3719027.3765146},
	timestamp = {Fri, 26 Dec 2025 20:53:04 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/RatliffBM25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Differential privacy (DP) has become a standard approach for computing privacy-preserving statistics. However, in interactive settings, the observable  runtime  of DP queries can inadvertently leak sensitive information, violating privacy guarantees. Prior work has shown that timing side channels can undermine DP in specific settings. In this work, we show that popular libraries for implementing differential privacy, including diffprivlib, OpenDP, and PyDP, frequently introduce such timing side channels, leading to measurable privacy degradation. Our analysis reveals timing vulnerabilities not only within commonly used DP mechanisms (e.g., private sums, counts, means, and selection) but also in commonly used pre-processing steps such as filtering and sorting. We show that these seemingly innocuous operations frequently exhibit runtimes that are sensitive not only to the presence of an individual's data in the input but also to the ordering of the input data. Several of the discovered timing side channels arise from programs whose runtimes depend on the  size  of the input dataset. The distinction between whether the dataset size is considered private or public information corresponds to  bounded  versus  unbounded  DP. We show that mechanisms satisfying  unbounded  DP with respect to their output distributions often trivially reveal their input size through their runtime distributions. We give several examples of practical attacks that can be used to re-identify individuals in a dataset given such a timing side channel. Finally, we propose an empirical auditing technique for detecting timing side-channel vulnerabilities in DP implementations. Our auditing algorithm provides a lower bound on privacy loss when both the program's output and runtime are observable to an adversary. Using our auditing framework, we are able to quantify conservative bounds on the privacy leakage of these mechanisms when runtimes are observable to an adversary.}
}


@inproceedings{DBLP:conf/ccs/WeissG25,
	author = {Jonathan Weiss and
                  Yossi Gilad},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {SlicedPIR: Offloading Heavyweight Work with {NTT}},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {3708--3722},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765154},
	doi = {10.1145/3719027.3765154},
	timestamp = {Fri, 26 Dec 2025 20:53:04 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/WeissG25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We present SlicedPIR, a distributed Private Information Retrieval (PIR) protocol. SlicedPIR efficiently alleviates the server's compute bottleneck by offloading its load across multiple untrusted client machines. In contrast to prior work, SlicedPIR induces only a modest network overhead when the server offloads its work. It achieves those communication savings by exploiting the polynomial encoding of homomorphic encryption schemes typically used in PIR protocols. This encoding lets the server make novel use of the Number Theoretic Transform (NTT) to distribute points on the polynomials as ''slices'' of its data rather than the polynomials themselves. Using NTT allows the clients to process recursive PIR queries on their slices and return a succinct result to the server. The server efficiently verifies the clients' results by leveraging the Schwartz-Zippel lemma, which we adapt to the PIR use case. We show how to integrate SlicedPIR into a private messaging system, where clients write messages to the server's database and then use PIR to secretly query for messages from their friends. We implement a prototype of SlicedPIR and run experiments to show that it scales well with the number of clients and database size. Concretely, SlicedPIR achieves better performance and cuts network usage by over 95% compared to the state-of-the-art.}
}


@inproceedings{DBLP:conf/ccs/BahramiCB25,
	author = {Pouneh Nikkhah Bahrami and
                  Dylan Cutler and
                  Igor Bilogrevic},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Byte by Byte: Unmasking Browser Fingerprinting at the Function Level
                  using {V8} Bytecode Transformers},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {3723--3736},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765158},
	doi = {10.1145/3719027.3765158},
	timestamp = {Fri, 26 Dec 2025 20:53:04 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/BahramiCB25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Browser fingerprinting enables persistent cross-site user tracking via subtle techniques that often evade conventional defenses or cause website breakage when script-level blocking countermeasures are applied. Addressing these challenges requires detection methods offering both function-level precision to minimize breakage and inherent robustness against code obfuscation and URL manipulation. We introduce ByteDefender, the first system leveraging V8 engine bytecode to detect fingerprinting operations specifically at the JavaScript function level. A Transformer-based classifier, trained offline on bytecode sequences, accurately identifies functions exhibiting fingerprinting behavior. We develop and evaluate lightweight signatures derived from this model to enable low-overhead, on-device matching against function bytecode during compilation but prior to execution, which only adds a 4% (average) latency to the page load time. This mechanism facilitates targeted, real-time prevention of fingerprinting function execution, thereby preserving legitimate script functionality. Operating directly on bytecode ensures inherent resilience against common code obfuscation and URL-based evasion. Our evaluation on the top 100k websites demonstrates high detection accuracy at both function- and script-level, with substantial improvements over state-of-the-art AST-based methods, particularly in robustness against obfuscation. ByteDefender offers a practical framework for effective, precise, and robust fingerprinting mitigation.}
}


@inproceedings{DBLP:conf/ccs/000125,
	author = {Ji Guan},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Optimal Mechanisms for Quantum Local Differential Privacy},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {3737--3749},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765178},
	doi = {10.1145/3719027.3765178},
	timestamp = {Fri, 26 Dec 2025 20:53:04 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/000125.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Centralized differential privacy has been successfully applied to quantum computing and information processing to protect privacy and avoid leaks in the connections between neighboring quantum states. Consequently, quantum local differential privacy (QLDP) has been newly proposed to preserve quantum data privacy akin to the classical scenario where all states are viewed as neighboring states. However, the exploration of the QLDP framework is still in its early stages, primarily conceptual, which poses challenges for its practical implementation in safeguarding quantum state privacy. This paper delves into optimal QLDP mechanisms to balance privacy and utility to enhance the practical use of the QLDP framework. QLDP utilizes a parameter ε to manage privacy leaks and ensure the privacy of individual quantum states. The optimization of the QLDP value ε, denoted as ε^*, for any quantum mechanism is addressed as an optimization problem. The introduction of quantum noise is shown to provide privacy protections similar to classical scenarios, with quantum depolarizing noise identified as the optimal unital privatization mechanism within the QLDP framework. Unital mechanisms represent a diverse set of quantum mechanisms that encompass frequently employed quantum noise types. Quantum depolarizing noise optimizes both fidelity and trace distance utilities, which are crucial metrics in the field of quantum computation and information, and can be viewed as a quantum counterpart to classical randomized response methods. The study further explores the trade-off between utility and privacy across different quantum noise mechanisms, including unital and non-unital quantum noise mechanisms, through both analytical and numerically experimental approaches. This highlights the optimization of quantum depolarizing noise in the QLDP framework.}
}


@inproceedings{DBLP:conf/ccs/TrummovaSHF25,
	author = {Ivana Trummov{\'{a}} and
                  Juliane Schm{\"{u}}ser and
                  Nicolas Huaman and
                  Sascha Fahl},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Competing for Attention: An Interview Study with Participants of Cryptography
                  Competitions},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {3750--3764},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765201},
	doi = {10.1145/3719027.3765201},
	timestamp = {Fri, 26 Dec 2025 20:53:04 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/TrummovaSHF25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cryptography competitions often contribute to the development and standardization of new cryptography. They help select primitives and algorithms that solve specific cryptographic problems securely and efficiently from a list of candidate submissions. Over the last decades, several competitions held by NIST and other research and regulatory organizations resulted in standards for, e.g., symmetric and asymmetric encryption, hashing, digital signatures, and, most recently, quantum secure cryptography. However, while these competitions fostered much technical research on the submitted schemes, little is currently known about the human aspects of cryptography competition processes, how they shape the competition results, and their perceived impact on cryptography security. To investigate human aspects of cryptography competitions, we interviewed 20 experienced cryptography competition participants on their experiences, their assessment of the competitions' impact and what it depended on, and suggestions to improve future competitions. We find that competitions bring attention to a cryptography area, providing research focus and motivation and establishing trust in schemes through community scrutiny and collaboration. Our participants highlighted the criticality of transparency, fairness, and trustworthiness of the competition organizer, emphasizing a need for clear and open communication. Based on these findings, we suggest strategies for future competitions to maximize engagement and provide transparent, trustworthy processes and results. We recommend stronger moderation of social conduct on official channels to ensure fairness and prevent putting off potential contributors. We also find substantial involvement and feedback collection from industry is critical. Transparent organization and evaluation elevate the competition and foster secure and well-adopted standards.}
}


@inproceedings{DBLP:conf/ccs/MoonYJK25,
	author = {Jungho Moon and
                  Dongwoo Yoo and
                  Xiaoqian Jiang and
                  Miran Kim},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {{THOR:} Secure Transformer Inference with Homomorphic Encryption},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {3765--3779},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765150},
	doi = {10.1145/3719027.3765150},
	timestamp = {Fri, 26 Dec 2025 20:53:04 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/MoonYJK25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As large language models are increasingly deployed in cloud environments, privacy concerns have become a significant issue. To address this challenge, we present THOR, a non-interactive framework for secure transformer inference using homomorphic encryption. We first propose efficient matrix multiplication algorithms based on diagonal-major encoding and compact ciphertext packing. We extend these basic algorithms to support plaintext-ciphertext matrix multiplication (PC-MM) using parallel submatrix computation and ciphertext-ciphertext multiplication (CC-MM) with a baby-step giant-step strategy. We also design efficient evaluation strategies for non-linear functions such as softmax, LayerNorm, GELU, and Tanh, by integrating advanced approximation techniques with adaptive iterative methods. Our matrix multiplication algorithms outperform state-of-the-art methods, achieving up to 5.3X speedup in PC-MM for ℝ  768 X 768  X ℝ 768X128  over BOLT (Pang et al., IEEE S&P 2024) and 9.7X in CC-MM for 12X (ℝ 64X128  X ℝ 128X128 ) over Powerformer (Park et al., Preprint). THOR enables secure inference on the BERT-base model with 128 tokens in 10 minutes on a single GPU, while maintaining comparable accuracy on GLUE tasks.}
}


@inproceedings{DBLP:conf/ccs/Shrestha0KLNW25,
	author = {Nibesh Shrestha and
                  Qianyu Yu and
                  Aniket Kate and
                  Giuliano Losa and
                  Kartik Nayak and
                  Xuechao Wang},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Optimistic, Signature-Free Reliable Broadcast and Its Applications},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {3780--3794},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765220},
	doi = {10.1145/3719027.3765220},
	timestamp = {Fri, 26 Dec 2025 20:53:04 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/Shrestha0KLNW25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Reliable broadcast (RBC) is a key primitive in fault-tolerant distributed systems, and improving its efficiency can benefit a wide range of applications. This work focuses on signature-free RBC protocols, which are particularly attractive due to their computational efficiency. Existing protocols in this setting incur an optimal 3 steps to reach a decision while tolerating up to ƒ <  n /3 Byzantine faults, where  n  is the number of parties. In this work, we propose an optimistic RBC protocol that maintains the ƒ <  n /3 fault tolerance but achieves termination in just 2 steps under certain optimistic conditions—when at least ⌉ n +2 ƒ-2 over -2 ⌈ non-broadcaster parties behave honestly. We also prove a matching lower bound on the number of honest parties required for 2-step termination. We show that our latency-reduction technique generalizes beyond RBC and applies to other primitives such as asynchronous verifiable secret sharing (AVSS) and asynchronous verifiable information dispersal (AVID), enabling them to complete in 2 steps under similar optimistic conditions. To highlight the practical impact of our RBC protocol, we integrate it into a new signature-free, post-quantum secure DAG-based Byzantine fault-tolerant (BFT) consensus protocol. Under optimistic conditions, this protocol achieves a commit latency of 3 steps—matching the performance of the best signature-based protocols. Our experimental evaluation shows that our protocol significantly outperforms existing post-quantum secure and signature-based protocols, even on machines with limited CPU resources. In contrast, signature-based protocols require high CPU capacity to achieve comparable performance.}
}


@inproceedings{DBLP:conf/ccs/0010S0QZD25,
	author = {Yu Jin and
                  Minghong Sun and
                  Dongsheng Wang and
                  Pengfei Qiu and
                  Yinqian Zhang and
                  Shuwen Deng},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {GhostCache: Timer- and Counter-Free Cache Attacks Exploiting Weak
                  Coherence on {RISC-V} and {ARM} Chips},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {3795--3809},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744833},
	doi = {10.1145/3719027.3744833},
	timestamp = {Fri, 26 Dec 2025 20:53:04 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/0010S0QZD25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Microarchitectural side-channel attacks, which have become increasingly prevalent, often rely on high-resolution timers. Emerging processor architectures have sought to mitigate these vulnerabilities by restricting access to fine-grained timers. In this work, we verify the widespread existence of weak coherence in L1 cache on multiple RISC chips, exploit it to bypass this type of mitigation and propose GhostCache, which constructs timer-free and counter-free instruction cache attacks. It introduces two novel and widely applied attack primitives, Modify+Recall and Call+ModifyCall, which are applicable to both RISC-V and ARM architectures and affect 6 commercial and 3 open-source large RISC processors. To the best of our knowledge, we present the first demonstration of timer-free and counter-free cache attacks on RISC-V processors. We also identify undisclosed features, such as the next-three-line prefetching mechanism and direct forwarding of evicted instructions from data cache to instruction cache. Furthermore, we develop four types of covert channels, achieving up to 1.68 MB/s with a 0.01% error rate. For side-channel attacks, GhostCache enables three types of timer-free real-world attacks. The first is an end-to-end website fingerprinting attack, achieving 92.02% accuracy across 100 website classes. The second is a set of kernel leakage attacks, including the discovery of a new Spectre disclosure gadget via a function pointer to leak arbitrary kernel data at 92.91% accuracy. We also launched an attack to reconstruct cryptographic keys. Lastly, we propose potential countermeasures to address these vulnerabilities in both RISC-V and ARM architectures.}
}


@inproceedings{DBLP:conf/ccs/SchluterWS25,
	author = {Benedict Schl{\"{u}}ter and
                  Christoph Wech and
                  Shweta Shinde},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Heracles: Chosen Plaintext Attack on {AMD} {SEV-SNP}},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {3810--3824},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765209},
	doi = {10.1145/3719027.3765209},
	timestamp = {Fri, 26 Dec 2025 20:53:04 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/SchluterWS25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Confidential computing needs hardware support that stops privileged software from learning secrets of a guest virtual machine. AMD offers such hardware support in the form of SEV-SNP to create confidential virtual machines, such that hardware encrypts all the VM memory. Specifically, SEV-SNP uses the XEX encryption mode with address-dependent tweak values such that the same plaintext at different memory addresses yields different ciphertexts. H eracles  makes three observations: the hypervisor can move encrypted guest pages in DRAM using three APIs; when it moves the guest pages to a new DRAM address, pages are re-encrypted; re-encryption is deterministic. By re-encrypting guest data at precisely chosen DRAM locations, we can create a chosen plaintext oracle allowing us to leak guest memory at block granularity. We build four primitives that leverage the victim's access patterns to amplify H eracles 's impact to not only leak data at block but at byte granularity. In our case studies, we leak kernel memory, crypto keys, and user passwords, as well as demonstrate web session hijacking.}
}


@inproceedings{DBLP:conf/ccs/ZhangLZM25,
	author = {Yan Zhang and
                  Zihao Liu and
                  Yi Zhu and
                  Chenglin Miao},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Towards Real-Time Defense against Object-Based LiDAR Attacks in Autonomous
                  Driving},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {3825--3839},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765227},
	doi = {10.1145/3719027.3765227},
	timestamp = {Sun, 07 Dec 2025 22:09:46 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/ZhangLZM25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {LiDAR (Light Detection and Ranging)-based object detection is a cornerstone of autonomous vehicle perception systems. Modern LiDAR perception relies heavily on deep neural networks (DNNs), which enable accurate object detection by learning geometric features from 3D point clouds. However, recent studies have shown that these systems are vulnerable to object-based adversarial attacks, where physical adversarial objects are strategically placed in the environment to manipulate LiDAR point clouds and mislead detection models. These attacks are practical, stealthy, and require no specialized hardware, posing a serious threat to the safety and reliability of AVs. Despite these risks, existing defense methods suffer from significant limitations, including high computational overhead, limited generalizability and effectiveness, and the inability to operate in real time. In this paper, we propose the first real-time defense mechanism against object-based LiDAR attacks in autonomous driving. Our solution is both detection model-agnostic and attack-agnostic, requiring no prior knowledge of the number, shape, size, or placement of adversarial objects. Positioned between the sensing and perception modules of the AV pipeline, the defense processes LiDAR point clouds in real time and employs a novel generative model that enables efficient and effective identification and removal of adversarial points from suspicious regions. Extensive experiments in both simulated and real-world environments demonstrate that our approach achieves high attack detection rates with minimal latency. This work offers a practical and robust defense solution to a growing security threat in autonomous driving.}
}


@inproceedings{DBLP:conf/ccs/SchluterS25,
	author = {Benedict Schl{\"{u}}ter and
                  Shweta Shinde},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {RMPocalypse: How a Catch-22 Breaks {AMD} {SEV-SNP}},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {3840--3854},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765233},
	doi = {10.1145/3719027.3765233},
	timestamp = {Fri, 26 Dec 2025 20:53:04 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/SchluterS25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {AMD SEV-SNP offers confidential computing in form of confidential VMs, such that the untrusted hypervisor cannot tamper with its confidentiality and integrity. SEV-SNP, the latest addition, ensures integrity via the Reverse Map Table (RMP) that stops the hypervisor from tampering guest page mappings. AMD uses RMP entries to protect the rest of the RMP, thus causing a Catch-22 during the RMP setup phase. To address this, SEV-SNP relies on AMD's Platform Security Processor (PSP), that resides next to the x86 cores executing SEV-SNP VMs, to perform the RMP initialization. During initialization, only PSP should be able to alter the RMP memory. All other memory accesses must be fenced, especially from the x86 cores. We present RMP ocalypse,  a novel attack that shows a critical gap in the security of RMP initialization, wherein the x86 cores maliciously control parts of the initial RMP state. Our analysis shows that the vulnerability arises due to the complex, but insufficient, interplay of multiple hardware components and distributed access controls. To show the impact of our finding, we exploit this gap to break confidentiality and integrity guarantees of SEV-SNP. We demonstrate RMP ocalypse  by enabling debug on production-mode CVMs, faking attestation, VMSA state replay, and code injection.}
}


@inproceedings{DBLP:conf/ccs/ZhouHW0W0025,
	author = {Ming Zhou and
                  Xupu Hu and
                  Zhihao Wang and
                  Haining Wang and
                  Hui Wen and
                  Limin Sun and
                  Peng Zhang},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Dynamic Vulnerability Patching for Heterogeneous Embedded Systems
                  Using Stack Frame Reconstruction},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {3855--3869},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765200},
	doi = {10.1145/3719027.3765200},
	timestamp = {Fri, 26 Dec 2025 20:53:04 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/ZhouHW0W0025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Existing dynamic vulnerability patching techniques are not well-suited for embedded devices, especially mission-critical ones such as medical equipment, as they have limited computational power and memory but uninterrupted service requirements. Those devices often lack sufficient idle memory for dynamic patching, and the diverse architectures of embedded systems further complicate the creation of patch triggers that are compatible across various system kernels and hardware platforms. To address these challenges, we propose a hot patching framework called StackPatch that facilitates patch development based on stack frame reconstruction. StackPatch introduces different triggering strategies to update programs stored in memory units. We leverage the exception-handling mechanisms commonly available in embedded processors to enhance StackPatch's adaptability across different processor architectures for control flow redirection. We evaluated StackPatch on embedded devices featuring three major microcontroller (MCU) architectures: ARM, RISC-V, and Xtensa. In the experiments, we used StackPatch to successfully fix 102 publicly disclosed vulnerabilities in real-time operating systems (RTOSes). We applied patching to medical devices, soft programmable logic controllers (PLCs), and network services, with StackPatch consistently completing each vulnerability remediation in less than 260 MCU clock cycles.}
}


@inproceedings{DBLP:conf/ccs/LinZYCWG025,
	author = {Minghao Lin and
                  Jiaxun Zhu and
                  Tingting Yin and
                  Zechao Cai and
                  Guanxing Wen and
                  Yanan Guo and
                  Mengyuan Li},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Chekhov's Gun: Uncovering Hidden Risks in macOS Application-Sandboxed
                  PID-Domain Services},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {3870--3884},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765205},
	doi = {10.1145/3719027.3765205},
	timestamp = {Fri, 26 Dec 2025 20:53:04 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/LinZYCWG025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {macOS delegates many high-privilege operations to dedicated PID-domain services, which applications can register and communicate with through inter-process communication (IPC). This architecture improves userland stability and security but also introduces attractive attack surfaces for adversaries. In this paper, we systematically analyze PID-domain services and uncover an overlooked attack vector: PID-domain services that are restricted to an Application Sandbox identical to the calling application can still be exploited due to subtle entitlement differences. To fully understand this attack surface, we reverse-engineered the implementation of the entitlement mechanism for the Application Sandbox in macOS. Based on these insights, we designed an entitlement-guided taint analysis framework to automatically detect vulnerable PID-domain services within this attack surface. Using our detection tool, we identified 19 confirmed zero-day vulnerabilities in the latest macOS 15.2, with 7 assigned CVE identifiers.}
}


@inproceedings{DBLP:conf/ccs/Pitigalaarachchi25,
	author = {Pansilu Pitigalaarachchi and
                  Xuhua Ding},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {A System Framework to Symbolically Explore Intel {TDX} Module Execution},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {3885--3899},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765212},
	doi = {10.1145/3719027.3765212},
	timestamp = {Fri, 26 Dec 2025 20:53:04 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/Pitigalaarachchi25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We present TDXplorer, the first dynamic symbolic analysis system for Intel's TDX Module, the software trusted computing base of TDX. Without using TDX hardware, an analyzer function on top of TDXplorer can not only apply dynamic analysis to control and instrument the TDX Module's execution, but also carry out symbolic execution for path exploration as well as security and functionality reasoning. The two types of analysis are seamlessly integrated in a way that symbolic execution is conducted directly upon the TDX Module's binary code and runtime states, which are shaped by using dynamic analysis techniques. We implement TDXplorer on Linux and measure its performance and correctness against executions on a TDX platform. Our case studies on symbolic modeling of secure EPT creation and KeyHole region management demonstrate that TDXplorer is a versatile and capable tool supporting various analysis tasks.}
}


@inproceedings{DBLP:conf/ccs/KimPOKY25,
	author = {Dong{-}uk Kim and
                  JunYoung Park and
                  Sanghak Oh and
                  Hyoungshick Kim and
                  Insu Yun},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Windows plays Jenga: Uncovering Design Weaknesses in Windows File
                  System Security},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {3900--3914},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765217},
	doi = {10.1145/3719027.3765217},
	timestamp = {Fri, 26 Dec 2025 20:53:04 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/KimPOKY25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {File systems are essential components of modern operating systems, with Windows being one of the most dominant platforms. Recently, a series of attacks have exploited the Windows file system to trigger serious security threats such as privilege escalation. Over the past several years, dozens of such attacks have been reported and even exploited in the wild. However, Microsoft has consistently addressed these issues with targeted patches rather than fundamental redesigns — resembling a precarious game of Jenga where security measures are stacked upon an unstable foundation. In this paper, we present a five-step comprehensive analysis of the Windows file system's design weaknesses. First, we analyze how Windows differs from another operating system, Linux. Second, we investigated how these discrepancies lead to security vulnerabilities in real-world applications and identified 13 high-impact vulnerabilities, including 11 previously unknown ones. Third, we show that current compatibility layers in modern programming languages fail to handle these discrepancies properly. Specifically, we examined compatibility layers in six programming languages and found 27 non-compliant and 9 inconsistencies, rendering these layers unreliable. Fourth, through a user study involving 21 experienced developers, we found that most were unfamiliar with OS-level file system discrepancies and rarely implemented appropriate mitigations. Finally, we analyze existing countermeasures and discuss their limitations. Our findings reveal critical yet largely obscured security risks resulting from design flaws in the Windows file system. Furthermore, we suggest that Microsoft rethink its strategy and address these fundamental weaknesses.}
}


@inproceedings{DBLP:conf/ccs/KochDSW25,
	author = {Maynard Koch and
                  Florian Dolzmann and
                  Thomas C. Schmidt and
                  Matthias W{\"{a}}hlisch},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Forward to Hell? On the Potentials of Misusing Transparent {DNS} Forwarders
                  in Reflective Amplification Attacks},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {3915--3929},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765096},
	doi = {10.1145/3719027.3765096},
	timestamp = {Fri, 26 Dec 2025 20:53:04 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/KochDSW25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The DNS infrastructure is infamous for facilitating reflective amplification attacks. Various countermeasures such as server shielding, access control, rate limiting, and protocol restrictions have been implemented. Still, the threat remains throughout the deployment of DNS servers. In this paper, we report on and evaluate the often unnoticed threat that derives from transparent DNS forwarders, a widely deployed, incompletely functional set of DNS components. Transparent DNS forwarders transfer DNS requests without rebuilding packets with correct source addresses. As such, transparent forwarders feed DNS requests into (mainly powerful and anycasted) open recursive resolvers, which thereby can be misused to participate unwillingly in distributed reflective amplification attacks. We show how transparent forwarders raise severe threats to the Internet infrastructure. They easily circumvent rate limiting and achieve an additional, scalable impact via the DNS anycast infrastructure. We empirically verify this scaling behavior up to a factor of 14. Transparent forwarders can also assist in bypassing firewall rules that protect recursive resolvers, making these shielded infrastructure entities part of the global DNS attack surface.}
}


@inproceedings{DBLP:conf/ccs/Fu0B025,
	author = {Chuanpu Fu and
                  Qi Li and
                  Elisa Bertino and
                  Ke Xu},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Training with Only 1.0 {\textperthousand} Samples: Malicious Traffic
                  Detection via Cross-Modality Feature Fusion},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {3930--3944},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765143},
	doi = {10.1145/3719027.3765143},
	timestamp = {Fri, 26 Dec 2025 20:53:04 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/Fu0B025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Machine Learning (ML) based malicious traffic detection systems can accurately recognize unseen network attacks by learning from large-scale traffic datasets. However, deploying such systems across multiple networks involves substantial efforts to construct large training datasets for each network. This paper addresses the issue of training with minimal datasets, that is, achieving accurate malicious traffic detection by learning a small portion of traffic in entirely new network environments, thereby eliminating prohibitive labor costs associated with traffic dataset construction. We develop tFusion to effectively extract information from limited datasets by treating network traffic data as multimodal data, comprising features from multiple sensory modalities of packets, flows, and hosts. In particular, we design a dedicated crossmodal attention model that fuses fine-grained per-packet sequential features with coarse-grained per-flow and per-host statistical features, to synthesize correlations among the different granularities of traffic features. Moreover, we design a topology-driven contrastive learning approach that pre- trains the models while reducing topology-related biases, which allows tFusion to achieve generic detection across various networks. We deploy tFusion in an institutional network and measure its performance over five days. tFusion requires human experts to label only 1.0 ‰ traffic, yet it achieves 99.82% accuracy when detecting various attacks. Meanwhile, it outperforms 14 existing methods by improving over 12.76% accuracy on 11 existing datasets.}
}


@inproceedings{DBLP:conf/ccs/XueHWRE25,
	author = {Diwen Xue and
                  Armin Huremagic and
                  Wayne Wang and
                  Ram Sundara Raman and
                  Roya Ensafi},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Fingerprinting Deep Packet Inspection Devices by their Ambiguities},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {3945--3959},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765145},
	doi = {10.1145/3719027.3765145},
	timestamp = {Fri, 26 Dec 2025 20:53:04 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/XueHWRE25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Users around the world face escalating network interference such as censorship, throttling, and interception, largely driven by the commoditization and growing availability of Deep Packet Inspection (DPI) devices. Once reserved for a few well-resourced nation-state actors, the ability to interfere with traffic at scale is now within reach of nearly any network operator. Despite this proliferation, our understanding of DPIs and their deployments on the Internet remains limited---being network intermediary leaves DPI unresponsive to conventional host-based scanning tools, and DPI vendors actively obscuring their products further complicates measurement efforts. In this work, we present a remote measurement framework,  dMAP  (DPI Mapper), that derives  behavioral fingerprints  for DPIs to differentiate and cluster these otherwise indistinguishable middleboxes at scale, as a first step toward active reconnaissance of DPIs on the Internet. Our key insight is that parsing and interpreting traffic as network intermediaries inherently involves  ambiguities ---from under-specified protocol behaviors to differing RFC interpretations---forcing DPI vendors into independent implementation choices that create measurable variance among DPIs. Based on differential fuzzing,  dMAP  systematically discovers, selects, and deploys specialized probes that translate DPI's internal parsing behaviors into externally observable fingerprints. Applying  dMAP  to DPI deployments globally, we demonstrate its practical feasibility, showing that even a modest set of 20-40 discriminative probes reliably differentiates a wide range of DPI implementations, including major nation-state censorship infrastructures and commercial DPI products. We discuss how our fingerprinting methodology generalizes beyond censorship to other forms of targeted interference, and we hope our work inspires further measurement efforts toward greater visibility and transparency into DPI devices deployed across the global Internet.}
}


@inproceedings{DBLP:conf/ccs/ZhangDRLHS25,
	author = {Wenyi Morty Zhang and
                  Annie Dai and
                  Keegan Ryan and
                  Dave Levin and
                  Nadia Heninger and
                  Aaron Schulman},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Don't Look Up: There Are Sensitive Internal Links in the Clear on
                  {GEO} Satellites},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {3960--3974},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765198},
	doi = {10.1145/3719027.3765198},
	timestamp = {Thu, 25 Dec 2025 12:46:54 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/ZhangDRLHS25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Geosynchronous (GEO) satellite links provide IP backhaul to remote critical infrastructure for utilities, telecom, government, military, and commercial users. To date, academic studies of GEO infrastructure have focused on a handful of satellites and specific use cases. We perform the first broad scan of IP traffic on 39 GEO satellites across 25 distinct longitudes with 411 transponders using consumer-grade equipment. We overcome the poor signal quality plaguing prior work and build the first general parser that can handle the diverse protocols in use by heterogeneous endpoints. We found 50% of GEO links contained cleartext IP traffic; while link-layer encryption has been standard practice in satellite TV for decades, IP links typically lacked encryption at both the link and network layers. This gives us a unique view into the internal network security practices of these organizations. We observed unencrypted cellular backhaul traffic from several providers including cleartext call and text contents, job scheduling and industrial control systems for utility infrastructure, military asset tracking, inventory management for global retail stores, and in-flight wifi.}
}


@inproceedings{DBLP:conf/ccs/CohenBN25,
	author = {Stav Cohen and
                  Ron Bitton and
                  Ben Nassi},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Here Comes the {AI} Worm: Preventing the Propagation of Adversarial
                  Self-Replicating Prompts Within GenAI Ecosystems},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {3975--3989},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765196},
	doi = {10.1145/3719027.3765196},
	timestamp = {Fri, 26 Dec 2025 20:53:04 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/CohenBN25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we show that when the communication between GenAI-powered applications relies on RAG-based inference, an attacker can initiate a computer worm-like chain reaction that we call RAGworm. This is done by crafting an adversarial self-replicating prompt that triggers a cascade of indirect prompt injections within the ecosystem and forces each affected application to perform malicious actions and compromise the RAG of additional applications. We evaluate the performance of the worm in creating a chain of malicious activities intended to promote content, distribute propaganda, and extract confidential user data within a GenAI ecosystem of GenAI-powered email assistants. We demonstrate that RAGworm can trigger the aforementioned malicious activities with a super-linear propagation rate, where each client compromises 20 new clients within the first 1-3 days (depending on the number of emails sent per day). In addition, we analyze how the performance of RAGworm is affected by various factors. Finally, we introduce the DonkeyRail, a guardrail intended to detect and prevent the propagation of RAGworm with minimal latency, high accuracy, and a low false-positive rate. We evaluate the guardrail's performance and show that it yields a true-positive rate of 1.0 with a false-positive rate of 0.017 while adding a negligible latency of 7.6-38.3 ms (depending on the number of documents retrieved). We also show that the guardrail is robust against out-of-distribution worms, consisting of unseen jailbreaking prompts and various worm use cases.}
}


@inproceedings{DBLP:conf/ccs/AlotaibiGM25,
	author = {Fahad Alotaibi and
                  Euan Goodbrand and
                  Sergio Maffeis},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Deep Learning from Imperfectly Labeled Malware Data},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {3990--4004},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765197},
	doi = {10.1145/3719027.3765197},
	timestamp = {Fri, 26 Dec 2025 20:53:04 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/AlotaibiGM25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Deep learning approaches have achieved remarkable performance in malware classification and detection. However, their success relies on the availability of large, accurately labeled datasets: a critical yet challenging requirement in the malware domain. In practice, most malware datasets are automatically labeled using outputs from antivirus engines, a process that often introduces significant label noise. Such imperfections can severely degrade the performance and generalizability of deep learning models. To address this challenge, we introduce SLB, a framework designed to robustly train deep learning–based malware systems while simultaneously refining dataset labels. SLB begins by partitioning the dataset into two subsets: a clean set containing samples with reliable labels, and a noisy set with samples that may be mislabeled, to which pseudo labels are assigned. As training progresses, SLB continuously monitors the model's predictions to dynamically update both sets. Specifically, samples in the noisy set that consistently receive predictions aligning with their (observed or pseudo) labels are promoted to the clean set, whereas samples in the clean set that exhibit unstable predictions are reclassified as noisy. This iterative process not only enhances model performance but also progressively corrects labeling errors. We evaluated SLB on multiple security datasets with both synthetic and real-world label noise across various deep learning architectures and ML algorithms. Experimental results show that SLB significantly improves malware detection performance and reduces overall noise. For example, on the Android binary dataset with 25% injected label noise, SLB reduced the noise to below 1.5% while increasing the macro F1 score from 74.51% to 96.03% and the accuracy score from 87.66% to 98.68%.}
}


@inproceedings{DBLP:conf/ccs/0001ZZW25,
	author = {Jian Lou and
                  Chenyang Zhang and
                  Xiaoyu Zhang and
                  Kai Wu},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {PreferCare: Preference Dataset Copyright Protection in {LLM} Alignment
                  by Watermark Injection and Verification},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4005--4019},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765223},
	doi = {10.1145/3719027.3765223},
	timestamp = {Fri, 26 Dec 2025 20:53:04 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/0001ZZW25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the urgent need to enhance the safety of LLM applications, there has been a growing focus on alignment training algorithms designed to keep large language models (LLMs) behaving in alignment with human values. Alignment training algorithms rely heavily on preference datasets, which are essential for finetuning LLMs to follow human preferences. However, generating and annotating these datasets is often costly and labor-intensive, making it critical to protect their copyright against unauthorized use. In this paper, we propose PreferCare, the first framework tailor-made for preference dataset copyright protection via watermark injection and verification. PreferCare comprises two consecutive stages: injection and verification. In the injection stage, a style transfer-based watermark signal and a bi-level watermark optimization process are designed to embed the watermark into the preference dataset. In the verification stage, we employ statistical tests to determine whether a suspect LLM has used the watermarked preference dataset without authorization. Extensive experiments on multiple popular LLMs have demonstrated that PreferCare achieves effectiveness, harmlessness, transferability, and robustness across diverse settings, and can successfully verify the watermark within 20 queries.}
}


@inproceedings{DBLP:conf/ccs/Zhu00W25,
	author = {Shenchen Zhu and
                  Kai Chen and
                  Yue Zhao and
                  Cheng'an Wei},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {{SCOPE:} Expanding Client-Side Post-Processing for Efficient Privacy-Preserving
                  Model Inference},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4020--4034},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765228},
	doi = {10.1145/3719027.3765228},
	timestamp = {Fri, 26 Dec 2025 20:53:04 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/Zhu00W25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Privacy-Preserving Inference (PPI) enables users to leverage powerful machine learning models without revealing sensitive input data. However, existing state-of-the-art solutions remain impractical due to significant computation and communication overheads. In this paper, we propose SCOPE (Secure Client-side Operation Expansion), a novel framework that significantly reduces these overheads by expanding the scope of client-side post-processing. We observe that modern HE-based inference schemes inevitably transfer masked intermediate ciphertexts to the client solely for two simple operations—element selection and rearrangement—incurring disproportionately high communication costs. To address this inefficiency, SCOPE introduces a semantic-preserving masking strategy that carefully calibrates the noise magnitude in masked ciphertexts, retaining minimal yet sufficient semantic information. By leveraging the inherent information asymmetry between server and client, this strategy enables clients to perform additional lightweight linear (e.g., normalization) and nonlinear (e.g., ReLU) operations locally, thus substantially reducing both computational and communication overhead, while still effectively protecting sensitive model parameters. Extensive experiments demonstrate that SCOPE achieves 3X speedup and 2.8X communication reduction over state-of-the-art approaches, with minimal accuracy degradation (<2.9%). Further evaluations under adaptive attack settings confirm that the controlled semantic exposure introduced by SCOPE does not increase the risk of model extraction attacks. The source code is available at https://anonymous.4open.science/r/scope-ccs25.}
}


@inproceedings{DBLP:conf/ccs/ZhangWLX0FL25,
	author = {Xinxuan Zhang and
                  Ruida Wang and
                  Zeyu Liu and
                  Binwu Xiang and
                  Yi Deng and
                  Ben Fisch and
                  Xianhui Lu},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Phalanx: An FHE-Friendly {SNARK} for Verifiable Computation on Encrypted
                  Data},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4035--4048},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765226},
	doi = {10.1145/3719027.3765226},
	timestamp = {Fri, 26 Dec 2025 20:53:04 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/ZhangWLX0FL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Verifiable Computation over encrypted data (VCoed) has two popular paradigms:  SNARK-FHE  (applying SNARKs to prove FHE operations) and  FHE-SNARK  (homomorphically evaluating SNARK proofs). For the existing works,  FHE-SNARK  has a much better efficiency compared to SNARK-FHE. In this work, we follow the line of FHE-SNARK and further improve its efficiency by designing Phalanx—an FHE-friendly SNARK that is: a) 3× lower multiplicative depth than FRI-based SNARKs; and b) Compatible with FHE SIMD operations. Based on Phalanx, we construct an FHE-SNARK scheme that has: a)  7.3× ~ 24.4×  speedup: 2.27-hour proof generation for 2 20 - gate circuits on a single core CPU and 0.68-hour when the input ciphertexts are in iNTT form (vs. 16.57 hours in the state-of-the-art); and b)  Practical verification:  61.4 MB proofs with 2.8 seconds verification (single core).}
}


@inproceedings{DBLP:conf/ccs/HwangLSS25,
	author = {Intak Hwang and
                  Hyeonbum Lee and
                  Jinyeong Seo and
                  Yongsoo Song},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Practical Zero-Knowledge {PIOP} for Maliciously Secure Multiparty
                  Homomorphic Encryption},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4049--4063},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765229},
	doi = {10.1145/3719027.3765229},
	timestamp = {Sun, 07 Dec 2025 22:09:42 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/HwangLSS25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Homomorphic encryption (HE) is a foundational technology in privacy-enhancing cryptography, enabling computation over encrypted data. Recently, generalized HE primitives designed for multi-party applications, such as multi-party HE (MPHE), have garnered significant research interest. While constructing secure multi-party protocols from MPHE in the semi-honest model is straightforward, achieving malicious security remains challenging as it requires zero-knowledge arguments of knowledge (ZKAoKs) for MPHE ciphertexts and public keys. In this work, we design practical ZKAoKs for MPHE that validate the well-formedness of public keys and ciphertexts. Specifically, we develop our ZKAoKs within the polynomial interactive oracle proof (PIOP) framework. To achieve this, we introduce novel optimization techniques that seamlessly integrate constraints for MPHE into the PIOP framework, enabling the design of PIOPs for validating all types of MPHE public keys, including relinearization and automorphism keys. To the best of our knowledge, our construction is the first ZKAoK for MPHE that validates automorphism keys. We instantiate our PIOP using a lattice-based polynomial commitment scheme (PCS). When compared with the previous state-of-the-art construction, PELTA (ACM CCS 2023), our implementation achieves a 5.4x reduction in proof size, a 111x speed-up in proof generation, and a 768x improvement in verification time for validating the encryption key. In addition to the encryption key, we provide benchmark results for all types of ZKAoKs required for MPHE, presenting the first concrete performance results in compiling passively secure MPHE-based protocols into maliciously secure ones.}
}


@inproceedings{DBLP:conf/ccs/HwangMSS25,
	author = {Intak Hwang and
                  Seonhong Min and
                  Jinyeong Seo and
                  Yongsoo Song},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Practical {TFHE} Ciphertext Sanitization for Oblivious Circuit Evaluation},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4064--4078},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765231},
	doi = {10.1145/3719027.3765231},
	timestamp = {Sun, 07 Dec 2025 22:09:42 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/HwangMSS25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Homomorphic encryption (FHE) enables the computation of arbitrary circuits over encrypted data. A widespread application of HE is oblivious circuit evaluation, where a sender evaluates its private circuit over a receiver's encrypted data, covering scenarios such as oblivious inference and oblivious PRF protocols. However, while the security of HE guarantees the receiver's privacy against the sender, the privacy of the sender's circuit is not solely derived from the security of HE. One effective solution to this problem is ciphertext sanitization, an algorithm that removes any information contained in a ciphertext except for the plaintext. Since its introduction by Ducas and Stehlé (Eurocrypt 2016), several approaches have been proposed for constructing sanitization algorithms for TFHE, but they remain highly impractical. In this work, we present a novel sanitization algorithm for TFHE ciphertexts that is practically deployable. Unlike prior methods that introduce randomization throughout the entire bootstrapping procedure or require repeated bootstrappings, our approach involves only two lightweight randomization steps at the input and output of the original TFHE bootstrapping, without modifying its core operations. As a result, our algorithm achieves sanitization with a single bootstrapping and minimal randomization, fully leveraging the fast performance of TFHE bootstrapping. In addition, we design a zero-knowledge argument of knowledge (ZKAoK) for TFHE ciphertexts and bootstrapping keys to address malicious receivers. To the best of our knowledge, this work is the first to construct a concrete ZKAoK that covers all receiver-sent materials, enabling a secure TFHE-based protocol against a malicious receiver. We provide a proof-of-concept implementation to demonstrate the practicality of our solution. Our experiments show that it takes approximately 42.17 ms to sanitize a single TFHE ciphertext, achieving up to a 31× speedup compared to the state-of-the-art method by Kluczniak (CiC 2025).}
}


@inproceedings{DBLP:conf/ccs/Dong0ZBC25,
	author = {Minglang Dong and
                  Yu Chen and
                  Cong Zhang and
                  Yujie Bai and
                  Yang Cao},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Multi-Party Private Set Operations from Predicative Zero-Sharing},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4079--4093},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765234},
	doi = {10.1145/3719027.3765234},
	timestamp = {Fri, 26 Dec 2025 20:53:04 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/Dong0ZBC25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Typical protocols in the multi-party private set operations (MPSO) setting enable m > 2 parties to perform certain secure computation on the intersection or union of their private sets, realizing a very limited range of MPSO functionalities. Most works in this field focus on just one or two specific functionalities, resulting in a large variety of isolated schemes and a lack of a unified framework in MPSO research. In this work, we present an MPSO framework, which allows m parties, each holding a set, to securely compute any set formulas (arbitrary compositions of a finite number of binary set operations, including intersection, union and difference) on their private sets. Our framework is highly versatile and can be instantiated to accommodate a broad spectrum of MPSO functionalities. To the best of our knowledge, this is the first framework to achieve such a level of flexibility and generality in MPSO, without relying on generic secure multi-party computation (MPC) techniques. Our framework exhibits favorable theoretical and practical performance. With computation and communication complexity scaling linearly with the set size n, it achieves optimal complexity that is on par with the naive solution for widely used functionalities, such as multi-party private set intersection (MPSI), MPSI with cardinality output (MPSI-card), and MPSI with cardinality and sum (MPSI-card-sum), for the first time in the standard semi-honest model. Furthermore, the instantiations of our framework, which primarily rely on symmetric-key techniques, provide efficient protocols for MPSI, MPSI-card, MPSI-card-sum, and multi-party private set union (MPSU), with online performance that either surpasses or matches the state of the art in standard semi-honest model. At the technical core of our framework is a newly introduced primitive called predicative zero-sharing. This primitive captures the universality of a number of MPC protocols and is composable. We believe it may be of independent interest.}
}


@inproceedings{DBLP:conf/ccs/ShiWFDKLCDZM25,
	author = {Guiming Shi and
                  Yuchen Wei and
                  Shengyu Fan and
                  Xianglong Deng and
                  Liang Kong and
                  Xianbin Li and
                  Jingwei Cai and
                  Shuwen Deng and
                  Mingzhe Zhang and
                  Kaisheng Ma},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {{WPC:} Weight Plaintext Compression for {CNN} Inference based on {RNS-CKKS}},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4094--4108},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765022},
	doi = {10.1145/3719027.3765022},
	timestamp = {Fri, 26 Dec 2025 20:53:05 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/ShiWFDKLCDZM25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Convolutional neural network (CNN) inference based on RNS-CKKS enables secure processing on encrypted data but introduces significant weight size overhead. Weight plaintext, weight in RNS-CKKS format, can reach tens to hundreds of gigabytes. Existing compression methods either add high computational cost or yield low compression rates. In this work, we propose WPC, Weight Plaintext Compression, to compress weight plaintext for RNS-CKKS-based CNN inference. We observe that the transformation from the weight in CNN models to the weight plaintext in RNS-CKKS format involves an operation akin to the Discrete Fourier Transform, which shifts data between the time and frequency domains while retaining redundant information from periodic and discrete data. Based on this observation, we first introduce the Periodic Transmit Theorem, which states that periodic patterns can be preserved during the transformation process, thereby enabling compression. We then propose Channel Innermost Packing Scheme and Rotation Padding to rearrange the weight data into periodic patterns for compression. Results show that WPC achieves 1.25 to 2.18 times speedup on an A100 GPU and 46.08 to 139.11 times compression rate.}
}


@inproceedings{DBLP:conf/ccs/ChenG0CLCZ0L25,
	author = {Zhuo Chen and
                  Yuyang Gong and
                  Jiawei Liu and
                  Miaokun Chen and
                  Haotan Liu and
                  Qikai Cheng and
                  Fan Zhang and
                  Wei Lu and
                  Xiaozhong Liu},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {FlippedRAG: Black-Box Opinion Manipulation Adversarial Attacks to
                  Retrieval-Augmented Generation Models},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4109--4123},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765023},
	doi = {10.1145/3719027.3765023},
	timestamp = {Fri, 26 Dec 2025 20:53:05 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/ChenG0CLCZ0L25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Retrieval-Augmented Generation (RAG) enriches LLMs by dynamically retrieving external knowledge, reducing hallucinations and satisfying real-time information needs. While existing research mainly targets RAG's performance and efficiency, emerging studies highlight critical security concerns. Yet, current adversarial approaches remain limited, mostly addressing white-box scenarios or heuristic black-box attacks without fully investigating vulnerabilities in the retrieval phase. Additionally, prior works mainly focus on factoid Q&A tasks, their attacks lack complexity and can be easily corrected by advanced LLMs. In this paper, we investigate a more realistic and critical threat scenario: adversarial attacks intended for opinion manipulation against black-box RAG models, particularly on controversial topics. Specifically, we propose FlippedRAG, a transfer-based adversarial attack against black-box RAG-like systems. We first demonstrate that the underlying retriever of a black-box RAG can be reverse-engineered and approximated by enumerating critical queries, candidates, and answers, enabling us to train a surrogate retriever. Leveraging the surrogate retriever, we further craft target poisoning triggers, altering vary few documents to effectively manipulate both retrieval and subsequent generation, transferring the attack to the original black-box RAG model. Extensive empirical results show that FlippedRAG substantially outperforms baseline methods, improving the average attack success rate by 16.7%. Across four diverse domains, FlippedRAG achieves on average a 50% directional shift in the opinion polarity of RAG-generated responses, ultimately causing a notable 20% shift in user cognition. Furthermore, we actively evaluate the performance of several potential defensive measures, concluding that existing mitigation strategies remain insufficient against such sophisticated manipulation attacks. These results highlight an urgent need for developing innovative defensive solutions to ensure the security and trustworthiness of RAG systems.}
}


@inproceedings{DBLP:conf/ccs/0001XSF0SZ25,
	author = {Ke Cheng and
                  Yuheng Xia and
                  Anxiao Song and
                  Jiaxuan Fu and
                  Wenjie Qu and
                  Yulong Shen and
                  Jiaheng Zhang},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Mosformer: Maliciously Secure Three-Party Inference Framework for
                  Large Transformers},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4124--4138},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765028},
	doi = {10.1145/3719027.3765028},
	timestamp = {Fri, 26 Dec 2025 20:53:05 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/0001XSF0SZ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Transformer-based models like BERT and GPT have achieved state-of-the-art performance across a wide range of AI tasks but raise serious privacy concerns when deployed as cloud inference services. To address this, secure multi-party computation (MPC) is commonly employed, encrypting both user inputs and model parameters to enable inference without revealing any private information. However, existing MPC-based secure transformer inference protocols are predominantly designed under the semi-honest security model. Extending these protocols to support malicious security remains a significant challenge, primarily due to the substantial overhead introduced by securely evaluating complex non-linear functions required for adversarial resilience. We introduce Mosformer, the first maliciously secure three-party (3PC) inference framework that efficiently supports large transformers such as BERT and GPT. We first design constant-round comparison and lookup table protocols with malicious security, leveraging verifiable distributed point functions (VDPFs). Building on these, we develop a suite of 3PC protocols for efficient and secure evaluation of complex non-linear functions in transformers. Together with optimized modulus conversion, our approach substantially reduces the overhead of secure transformer inference while preserving model accuracy. Experimental results on the vanilla transformer block show that Mosformer achieves up to a 5.3× speedup and a 4.3× reduction in communication over prior maliciously secure protocols. Despite offering stronger security guarantees, Mosformer achieves comparable or even superior online performance to state-of-the-art semi-honest 2PC and 3PC frameworks, including BOLT (Oakland 2024), BumbleBee (NDSS 2025), SHAFT (NDSS 2025), and Ditto (ICML 2024), on full-scale models such as BERT and GPT-2.}
}


@inproceedings{DBLP:conf/ccs/0005L0025,
	author = {Chen Gong and
                  Kecen Li and
                  Zinan Lin and
                  Tianhao Wang},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {DPImageBench: {A} Unified Benchmark for Differentially Private Image
                  Synthesis},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4139--4153},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765045},
	doi = {10.1145/3719027.3765045},
	timestamp = {Fri, 26 Dec 2025 20:53:05 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/0005L0025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Differentially private (DP) image synthesis aims to generate artificial images that retain the properties of a sensitive image dataset while protecting the privacy of individual images within the dataset. Despite recent advancements, we find that inconsistent--and sometimes flawed--evaluation protocols have been applied across studies. This not only impedes the understanding of current methods but also hinders future advancements in the field. To address the issue, this paper introduces DPImageBench, with thoughtful design across several dimensions: (1) Methods. We study twelve prominent methods and systematically characterize each based on model architecture, pretraining strategy, and privacy mechanism. (2) Evaluation. We include nine datasets and seven metrics to thoroughly assess these methods. Notably, we find that the common practice of selecting downstream classifiers based on the highest accuracy on sensitive test sets not only violates DP but also overestimates the utility. DPImageBench corrects for it. (3) Platform. Despite the wide variety of methods and evaluation protocols, DPImageBench provides a standardized interface that accommodates current and future implementations within a unified framework. With DPImageBench, we have several noteworthy findings. For example, contrary to the common wisdom that pretraining on public image datasets is usually beneficial, we find that the distributional similarity between pretraining and sensitive images significantly impacts the performance of the synthetic images and does not always yield improvements. The source code is available.}
}


@inproceedings{DBLP:conf/ccs/YuanMG025,
	author = {Xiaoyong (Brian) Yuan and
                  Xiaolong Ma and
                  Linke Guo and
                  Lan Zhang},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {What Lurks Within? Concept Auditing for Shared Diffusion Models at
                  Scale},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4154--4168},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765052},
	doi = {10.1145/3719027.3765052},
	timestamp = {Mon, 24 Nov 2025 15:33:09 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/YuanMG025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Diffusion models (DMs) have revolutionized text-to-image generation, enabling the creation of highly realistic and customized images from text prompts. With the rise of parameter-efficient fine-tuning (PEFT) techniques like LoRA, users can now customize powerful pre-trained models using minimal computational resources. However, the widespread sharing of fine-tuned DMs on open platforms raises growing ethical and legal concerns, as these models may inadvertently or deliberately generate sensitive or unauthorized content, such as copyrighted material, private individuals, or harmful content. Despite increasing regulatory attention on generative AI, there are currently no practical tools for systematically auditing these models before deployment. In this paper, we address the problem of concept auditing: determining whether a fine-tuned DM has learned to generate a specific target concept. Existing approaches typically rely on prompt-based input crafting and output-based image classification but they suffer from critical limitations, including prompt uncertainty, concept drift, and poor scalability. To overcome these challenges, we introduce Prompt-Agnostic Image-Free Auditing (PAIA), a novel, model-centric concept auditing framework. By treating the DM as the object of inspection, PAIA enables direct analysis of internal model behavior, bypassing the need for optimized prompts or generated images. It integrates two key components: a prompt-agnostic strategy that mitigates prompt sensitivity by analyzing model behavior during late-stage denoising, and an image-free detection method based on conditional calibrated error, which compares the internal dynamics of a fine-tuned model against its base version. Our auditing setting assumes internal access to DMs, but does not require access to proprietary fine-tuning data or user prompts, an assumption aligned with how hosted platforms audit uploaded models. We evaluate PAIA on 320 controlled models trained with curated concept datasets and 771 real-world community models sourced from a public DM sharing platform, covering a wide range of concepts including celebrities, cartoon characters, videogame entities, and movie references. Evaluation results show that PAIA achieves over 90% detection accuracy while reducing auditing time by 18 - 40x compared to existing baselines, and remains robust under adaptive attacks. To our knowledge, PAIA is the first scalable and practical solution for pre-deployment concept auditing of diffusion models, providing a practical foundation for safer and more transparent diffusion model sharing.}
}


@inproceedings{DBLP:conf/ccs/Ma00025,
	author = {Jianan Ma and
                  Jingyi Wang and
                  Qi Xuan and
                  Zhen Wang},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Provable Repair of Deep Neural Network Defects by Preimage Synthesis
                  and Property Refinement},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4169--4183},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765057},
	doi = {10.1145/3719027.3765057},
	timestamp = {Sun, 07 Dec 2025 22:09:43 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/Ma00025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {It is known that deep neural networks may exhibit dangerous behaviors under various security threats (e.g., backdoor attacks, adversarial attacks and safety property violation) and there exists an ongoing arms race between attackers and defenders. In this work, we propose a complementary perspective to utilize recent progress on ''neural network repair'' to mitigate these security threats and repair various kinds of neural network defects (arising from different security threats) within a unified framework, offering a potential silver bullet solution to real-world scenarios. To substantially push the boundary of existing repair techniques (suffering from limitations such as lack of guarantees, limited scalability, considerable overhead, etc) in addressing more practical contexts, we propose ProRepair, a novel provable neural network repair framework driven by formal preimage synthesis and property refinement. The key intuitions are: (i) synthesizing a precise proxy box to characterize the feature space preimage, which can derive a bounded distance term sufficient to guide the subsequent repair step towards the correct outputs, and (ii) performing property refinement to enable surgical corrections and scale to more complex tasks. We evaluate ProRepair across four security threats repair tasks on six benchmarks and the results demonstrate it outperforms existing methods in effectiveness, efficiency and scalability. For point-wise repair, ProRepair corrects models while preserving performance and achieving significantly improved generalization, with a speed-up of 5× to 2000× over existing provable approaches. In region-wise repair, ProRepair successfully repairs all 36 safety property violation instances (compared to 8 by the best existing method), and can handle 18× higher dimensional spaces.}
}


@inproceedings{DBLP:conf/ccs/GaoMD0G25,
	author = {Xinyu Gao and
                  Xiangtao Meng and
                  Yingkai Dong and
                  Zheng Li and
                  Shanqing Guo},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {\emph{DCMI: } {A} Differential Calibration Membership Inference Attack
                  Against Retrieval-Augmented Generation},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4184--4198},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765103},
	doi = {10.1145/3719027.3765103},
	timestamp = {Fri, 26 Dec 2025 20:53:05 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/GaoMD0G25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {While Retrieval-Augmented Generation (RAG) effectively reduces hallucinations by integrating external knowledge bases, it introduces vulnerabilities to membership inference attacks (MIAs), particularly in systems handling sensitive data. Existing MIAs targeting RAG's external databases often rely on model responses but ignore the interference of  non-member-retrieved documents  on RAG outputs, limiting their effectiveness. To address this, we propose DCMI, a differential calibration MIA that mitigates the negative impact of  non-member-retrieved documents . Specifically,  DCMI  leverages the sensitivity gap between  member  and  non-member retrieved documents  under query perturbation. It generates perturbed queries for calibration to isolate the contribution of  member-retrieved documents  while minimizing the interference from  non-member-retrieved documents . Experiments under progressively relaxed assumptions show that  DCMI  consistently outperforms baselines—for example, achieving 97.42% AUC and 94.35% Accuracy against the RAG system with Flan-T5, exceeding the MBA baseline by over 40%. Furthermore, on real-world RAG platforms such as Dify and MaxKB,  DCMI  maintains a 10%-20% advantage over the baseline. These results highlight significant privacy risks in RAG systems and emphasize the need for stronger protection mechanisms. We appeal to the community's consideration of deeper investigations, like ours, against the data leakage risks in rapidly evolving RAG systems.}
}


@inproceedings{DBLP:conf/ccs/KangKC25,
	author = {Yujin Kang and
                  Eunsun Kim and
                  Yoon{-}Sik Cho},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Can Personal Health Information Be Secured in LLM? Privacy Attack
                  and Defense in the Medical Domain},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4199--4213},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765105},
	doi = {10.1145/3719027.3765105},
	timestamp = {Sun, 07 Dec 2025 22:09:42 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/KangKC25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recent advancements have shown that Large Language Models (LLMs) possess significant versatility, making them suitable for applications in many areas. Several studies have shown how general-purpose LLMs can be adapted to domain-specific tasks. However, these domain-adapted LLMs can be exposed to greater privacy risks, which are especially exacerbated in the medical field. In this paper, we present the study investigating the susceptibility of LLMs to leaking sensitive health information. We conduct prompt-based attacks on LLMs trained with medical datasets, showing that medical LLMs can inadvertently disclose confidential patient data. To contribute towards mitigating privacy risks in the medical domain, we implement red teaming defense strategies to make LLMs robust against malicious attacks. For this medical red teaming approach, we develop and publicly release MediRed, a dataset of 1,000 red team attacks. By leveraging this dataset to enhance our defense mechanisms, we achieve up to 56% improvement in privacy protection compared to base models. Our code and dataset are available at https://github.com/yujinKang32/Private_Med_LLM.git}
}


@inproceedings{DBLP:conf/ccs/Xiao0SD25,
	author = {Hanshen Xiao and
                  Jun Wan and
                  Elaine Shi and
                  Srinivas Devadas},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {One-Sided Bounded Noise: Theory, Optimization Algorithms and Applications},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4214--4228},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765110},
	doi = {10.1145/3719027.3765110},
	timestamp = {Fri, 26 Dec 2025 20:53:05 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/Xiao0SD25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We investigate the optimal trade-off between utility and privacy using one-sided perturbation. Unlike conventional privacy-preserving statistical releases, randomization for obfuscating side-channel information is often constrained by infrastructure limitations. In practical scenarios, these constraints may only allow positive and bounded perturbations. For example, extending processing time or sending and storing dummy messages/data is typically feasible. However, implementing modifications in the opposite direction is challenging due to restrictions imposed by hardware capacity, communication protocols, and data management systems. In this paper, we establish the foundation of the positive noise mechanism within three semantic privacy frameworks: Differential Privacy (DP), Maximal Leakage (MaxL), and Probably Approximately Correct (PAC) Privacy. We then present a series of results that characterize or approximate the optimal one-sided noise distribution, subject to a second-moment budget and a bounded maximal magnitude. Building on this theoretical foundation, we develop efficient tools to solve the underlying optimization problems. Through experiments conducted in various scenarios, we demonstrate that existing techniques, such as Truncated Biased Laplace noise, are often suboptimal and result in excessive performance degradation. For instance, in an anonymous communication system with a 250K message budget, our optimized DP noise mechanism achieves a 21× reduction in dummy messages and an 18× reduction in dummy message latency overhead compared to traditional methods.}
}


@inproceedings{DBLP:conf/ccs/BekosPKP25,
	author = {Paschalis Bekos and
                  Panagiotis Papadopoulos and
                  Nicolas Kourtellis and
                  Michalis Polychronakis},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {PIIxel Leaks: Passive Identification of Personally Identifiable Information
                  Leakage through Meta Pixel},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4229--4243},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765113},
	doi = {10.1145/3719027.3765113},
	timestamp = {Fri, 26 Dec 2025 20:53:05 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/BekosPKP25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Web pixels are one of the predominant techniques for tracking conversions and user behavior on the Web. The integration of Meta Pixel (the most widely used tracking pixel) into a website enables Meta to collect sensitive information about the website's visitors and match it with their Facebook or Instagram profiles. In addition to detailed navigation history, Meta Pixel also collects personally identifiable information (PII) entered by visitors in online forms present on the website, such as emails and phone numbers. In this paper, we present a scalable and comprehensive approach for measuring PII leakage through Meta Pixel by  passively  inspecting its core components, without the need to interact with the dynamic elements of a website. This is possible by statically identifying and analyzing the configuration profile of a Meta Pixel instance and extracting the information it is set up to collect. By developing a hybrid crawling approach (static and headless), we analyzed the top-1M most popular websites and found that  12.2%  of them leak at least one instance of PII to Meta. We also found that in addition to email addresses and phone numbers, Meta Pixel also tracks PII such as age, gender, and geographical information, which can be used to not only reveal the identity of a user, but also their demographic characteristics. Finally, we assess the ability of Meta Pixel to track the browsing journey of a user by recording the sequence of full URLs visited across sub-pages.}
}


@inproceedings{DBLP:conf/ccs/InyangsonRJFM25,
	author = {David Inyangson and
                  Sarah Radway and
                  Tushar M. Jois and
                  Nelly Fazio and
                  James Mickens},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Amigo: Secure Group Mesh Messaging in Realistic Protest Settings},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4244--4258},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765133},
	doi = {10.1145/3719027.3765133},
	timestamp = {Fri, 26 Dec 2025 20:53:05 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/InyangsonRJFM25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {During large-scale protests, a repressive government will often disable the Internet to thwart communication between protesters. Smartphone mesh networks, which route messages over short-range, possibly ephemeral, radio connections between nearby phones, allow protesters to communicate without relying on centralized Internet infrastructure. Unfortunately, prior work on providing secure communication in Internet shutdown settings fails to adequately consider protester needs. Previous attempts fail to support efficient  private group  communication (a crucial requirement for protests), and evaluate their solutions in network environments which fail to accurately capture link churn, physical spectrum contention, and the mobility models found in realistic protest settings. In this paper, we introduce Amigo, a novel mesh messaging system which supports group communication through a decentralized approach to continuous key agreement, and forwards messages using a novel routing protocol. Amigo is uniquely designed to handle the challenges of ad-hoc routing scenarios, where dynamic network topologies and node mobility make achieving key agreement nontrivial. Our extensive simulations reveal the poor scalability of prior approaches, the benefits of Amigo's protest-specific optimizations, and the challenges that still must be solved to scale secure mesh networks to protests with thousands of participants.}
}


@inproceedings{DBLP:conf/ccs/ChhillarRSK25,
	author = {Somiya Chhillar and
                  Mary K. Righi and
                  Rebecca E. Sutter and
                  Evgenios M. Kornaropoulos},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Exposing Privacy Risks in Anonymizing Clinical Data: Combinatorial
                  Refinement Attacks on \emph{k}-Anonymity Without Auxiliary Information},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4259--4273},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765139},
	doi = {10.1145/3719027.3765139},
	timestamp = {Fri, 26 Dec 2025 20:53:05 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/ChhillarRSK25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Despite longstanding criticism from the privacy community, k-anonymity remains a widely used standard for data anonymization, mainly due to its simplicity, regulatory alignment, and preservation of data utility. However, non-experts often defend k-anonymity on the grounds that, in the absence of auxiliary information, no known attacks can compromise its protections. In this work, we refute this claim by introducing  Combinatorial Refinement Attacks  (CRA), a new class of privacy attacks targeting k-anonymized datasets produced using local recoding. This is the first method that does not rely on external auxiliary information or assumptions about the underlying data distribution. CRA leverages the utility-optimizing behavior of local recoding anonymization of ARX, which is a widely used open-source software for anonymizing data in clinical settings, to formulate a linear program that significantly reduces the space of plausible sensitive values. To validate our findings, we partnered with a network of free community health clinics, an environment where (1) auxiliary information is indeed hard to find due to the population they serve and (2) open-source k-anonymity solutions are attractive due to regulatory obligations and limited resources. Our results on real-world clinical microdata reveal that even in the absence of external information, established anonymization frameworks do not deliver the promised level of privacy, raising critical privacy concerns.}
}


@inproceedings{DBLP:conf/ccs/SiLC0W25,
	author = {Janice Jianing Si and
                  Xin Lin and
                  Haorui Cui and
                  Xiaobo Zhou and
                  Kanye Ye Wang},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Digital Safety for Children with Intellectual Disabilities When Using
                  Mobile Devices from Parents' and Teachers' Perspectives},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4274--4288},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765101},
	doi = {10.1145/3719027.3765101},
	timestamp = {Fri, 26 Dec 2025 20:53:05 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/SiLC0W25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As mobile devices become increasingly integrated into children's daily lives, digital safety has emerged as a pressing concern, particularly for children with intellectual disabilities (ID), who are more vulnerable due to their cognitive and behavioral challenges. Despite their heightened risk, little research has addressed the unique digital safety issues these children face. To bridge this gap, we conducted semi-structured interviews with parents and special education teachers who are key figures for overseeing the digital access and safety of children with ID. Our findings highlight four primary concerns: imitation of harmful behaviors, accidental misoperation of devices, risks from fraud, and exposure to cyberbullying. To address these, parents and teachers largely rely on proactive educational strategies supported by technical controls and device restrictions. We conclude by emphasizing the need to adapt special education practices to the evolving digital landscape and propose inclusive safety strategies applicable to other at-risk user groups.}
}


@inproceedings{DBLP:conf/ccs/SimhadriXFZ25,
	author = {Vamsi Shankar Simhadri and
                  Yichang Xiong and
                  Habiba Farrukh and
                  Xiaokuan Zhang},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {\emph{Virtual} Reality, \emph{Real} Problems: {A} Longitudinal Security
                  Analysis of {VR} Firmware},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4289--4303},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765102},
	doi = {10.1145/3719027.3765102},
	timestamp = {Fri, 26 Dec 2025 20:53:05 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/SimhadriXFZ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Virtual Reality (VR) technology is rapidly growing in recent years. VR devices such as Meta Quest 3 utilize numerous sensors to collect users' data to provide an immersive experience. Due to the extensive data collection and the immersive nature, the security of VR devices is paramount. Leading VR devices often adopt and customize Android systems, which makes them susceptible to both Android-based vulnerabilities and new issues introduced by VR-specific customizations (e.g., system services to support continuous head and hand tracking). While prior work has extensively examined the security properties of the Android software stack, how these security properties hold for VR systems remains unexplored. In this paper, we present the first comprehensive security analysis of VR firmware. We collect over 300 versions of VR firmware from two major vendors, Quest and Pico, and perform a longitudinal analysis across the kernel layer, the system binary and library layer, and the application layer. We have identified several security issues in these VR firmware, including missing kernel-level security features, insufficient binary hardening, inconsistent permission enforcement, and inadequate SELinux policy enforcement. Based on our findings, we synthesize recommendations for VR vendors to improve security and trust for VR devices. This paper will act as an important security resource for VR developers, users, and vendors, and will also direct future advancements in secure VR ecosystem}
}


@inproceedings{DBLP:conf/ccs/NonnenkampGG025,
	author = {Julia Nonnenkamp and
                  Naman Gupta and
                  Abhimanyu Dev Gupta and
                  Rahul Chatterjee},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Hidden in Plain Bytes: Investigating Interpersonal Account Compromise
                  with Data Exports},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4304--4318},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765147},
	doi = {10.1145/3719027.3765147},
	timestamp = {Fri, 26 Dec 2025 20:53:05 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/NonnenkampGG025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {When survivors of technology-facilitated abuse (TFA) suspect someone has accessed their online accounts, they often rely on built-in account security interfaces (ASIs), such as trusted device lists within settings, to assess account compromise. However, these interfaces typically offer limited or ambiguous details about past account accesses and security-critical events. Under right of access provisions in data protection laws, users can request structured exports of their personal data from online services. In this study, we explore whether and how data exports can supplement ASIs to support compromise investigations, particularly in interpersonal threat contexts. We simulated four types of account compromise attacks across six popular platforms, analyzing the resulting data exports and ASIs. Our findings show that data exports consistently contain more granular login histories and richer device/network identifiers than interfaces. Some even link security-related actions (e.g., password changes) and other post-authentication activity to specific devices, offering forensic value for identifying compromise. We discuss usability and other practical challenges of using data exports during TFA interventions.}
}


@inproceedings{DBLP:conf/ccs/HouFD025,
	author = {Zhenduo Hou and
                  Tingwei Fan and
                  Fei Duan and
                  Ding Wang},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {How to Design Secure Honey Vault Schemes},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4319--4333},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765162},
	doi = {10.1145/3719027.3765162},
	timestamp = {Fri, 26 Dec 2025 20:53:05 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/HouFD025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Password vaults enable a user to store multiple passwords with a single master password. Honey encryption (HE) protected password vaults (called honey vaults), are promising in resisting offline master password guessing attacks. Trial-decrypted with incorrect master passwords, honey vaults are designed to yield plausible-looking decoy vaults to confuse attackers, forcing them to perform online verifications to know whether a decrypted vault is the real one. In this paper, we demonstrate how to design secure honey vault schemes in a principled approach. We first identify three major types of vulnerabilities, and propose three critical design criteria based on rigorous theories, with each aiming to address one type of vulnerability. These criteria are: (1) Employing an accurate password probability model (PPM) in the natural language encoder (NLE, a key component of a honey vault) to resist distribution-aware distinguishing attacks; (2) Employing sequence-based PPMs for unique passwords, and sufficiently concise reuse models to resist encoding attacks (USENIX SEC'19); (3) Hiding a user's real-vault-related (i.e., adaptive) PPM to resist extraction attacks (USENIX SEC'21). To meet these key criteria, we propose VaultGuard with an innovative NLE and HE-Adaptive to honey-encrypt a user's real vault and the adaptive PPM, respectively. Our NLE eliminates the first and second vulnerabilities, while HE-Adaptive addresses the third. Security evaluations on real-world data reveal that our VaultGuard can significantly enhance honey vault security, forcing attackers to perform 1.10∼3.98 times online verifications. We also provide an efficient proof-of-concept VaultGuard implementation on the client side. We believe this work provides general principles and actionable guidelines for designing secure honey vault schemes.}
}


@inproceedings{DBLP:conf/ccs/TolsdorfLI25,
	author = {Jan Tolsdorf and
                  David Langer and
                  Luigi Lo Iacono},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Phishing Susceptibility and the (In-)Effectiveness of Common Anti-Phishing
                  Interventions in a Large University Hospital},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4334--4348},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765164},
	doi = {10.1145/3719027.3765164},
	timestamp = {Sun, 07 Dec 2025 22:09:45 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/TolsdorfLI25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Phishing attacks via email remain a major entry point for security and privacy breaches in hospitals. In the European Union, faced with both regulatory pressure to act and limited resources for cybersecurity, hospitals may resort to minimal-effort, off-the-shelf anti-phishing interventions such as warning banners in enterprise email systems. However, their effectiveness remains uncertain, particularly given the highly diverse workforce comprising medical, nursing, functional, administrative, IT, and other staff groups. We conducted a large-scale phishing simulation at a German university hospital, targeting 7,044 email accounts, to analyze how phishing susceptibility varies across staff groups, how email characteristics---such as timing, tone, context, and persuasive framing---influence susceptibility, and how 11 common in-situ anti-phishing interventions affect risky staff behavior. We found that susceptibility but also intervention effectiveness differed markedly across staff groups. Even a small number of phishing emails posed a substantial risk that persisted for about three days. The most effective interventions involved robust technical detection, including spam filtering and in-email phishing warnings. Friction-based measures, such as disabling links and active warning pages, showed mixed but promising effects. In contrast, display name suppression and the widely used method of generic  [EXTERNAL]  email tagging had no or inconsistent effects. Surveys revealed that some staff reacted with fear, shame, guilt, and hostility, highlighting the ethical challenges of such simulations. Our findings provide actionable guidance for phishing resilience in healthcare and similarly complex organizations.}
}


@inproceedings{DBLP:conf/ccs/YuLZH025,
	author = {Yaman Yu and
                  Yiren Liu and
                  Yuqi Zhang and
                  Yun Huang and
                  Yang Wang},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {YouthSafe: {A} Youth-Centric Safety Benchmark and Safeguard Model
                  for Large Language Models},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4349--4363},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765168},
	doi = {10.1145/3719027.3765168},
	timestamp = {Fri, 26 Dec 2025 20:53:05 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/YuLZH025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Large Language Models (LLMs) are increasingly used by teenagers and young adults in everyday life, ranging from emotional support and creative expression to educational assistance. However, their unique vulnerabilities and risk profiles remain under-examined in current safety benchmarks and moderation systems, leaving this population disproportionately exposed to harm. In this work, we present Youth AI Risk (YAIR), the first benchmark dataset designed to evaluate and improve the safety of youth–LLM interactions. YAIR consists of 12,449 annotated conversation snippets spanning 78 fine-grained risk types, grounded in a taxonomy of youth-specific harms such as grooming, boundary violation, identity confusion, and emotional overreliance. We systematically evaluate widely adopted moderation models on YAIR and find that existing approaches substantially underperform in detecting youth-centered risks, often missing contextually subtle yet developmentally harmful interactions. To address these gaps, we introduce YouthSafe, a real-time risk detection model optimized for youth–GenAI contexts. YouthSafe significantly outperforms prior systems across multiple metrics on risk detection and classification, offering a concrete step toward safer and more developmentally appropriate AI interactions for young users.}
}


@inproceedings{DBLP:conf/ccs/Ben-TovS25,
	author = {Matan Ben{-}Tov and
                  Mahmood Sharif},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {GASLITEing the Retrieval: Exploring Vulnerabilities in Dense Embedding-based
                  Search},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4364--4378},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765095},
	doi = {10.1145/3719027.3765095},
	timestamp = {Sun, 07 Dec 2025 22:09:40 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/Ben-TovS25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Dense embedding-based text retrieval—retrieval of relevant passages from corpora via deep learning encodings—has emerged as a powerful method attaining state-of-the-art search results and popularizing Retrieval Augmented Generation (RAG). Still, like other search methods, embedding-based retrieval may be susceptible to search-engine optimization (SEO) attacks, where adversaries promote malicious content by introducing adversarial passages to corpora. Prior work has shown such SEO is  feasible , mostly demonstrating attacks against retrieval-integrated systems (e.g., RAG). Yet, these consider relaxed SEO threat models (e.g., targeting single queries), use baseline attack methods, and provide small-scale retrieval evaluation, thus obscuring our comprehensive understanding of retrievers'  worst-case  behavior. This work aims to faithfully and thoroughly assess retrievers' robustness, paving a path to uncover factors related to their susceptibility to SEO. To this end, we, first, propose the GASLITE attack for generating adversarial passages, that—without relying on the corpus content or modifying the model—carry adversary-chosen information while achieving high retrieval ranking, consistently outperforming prior approaches. Second, using GASLITE, we extensively evaluate retrievers' robustness, testing nine advanced models under varied threat models, while focusing on pertinent adversaries targeting queries on a specific concept (e.g., a public figure). Amongst our findings: retrievers are highly vulnerable to SEO against concept-specific queries, even under negligible poisoning rates (e.g., ≤0.0001% of the corpus), while generalizing across different corpora and query distributions; single-query SEO is completely solved by GASLITE; adaptive attacks demonstrate bypassing common defenses; robustness to SEO attacks varies substantially between retrievers. Third, exploring the latter finding, we identify key factors that may contribute to models' susceptibility to SEO, including specific properties in the embedding space's geometry, echoing the essentiality of worst-case evaluations, and laying the basis for future defenses.}
}


@inproceedings{DBLP:conf/ccs/PengXLJWWR25,
	author = {Yiteng Peng and
                  Dongwei Xiao and
                  Zhibo Liu and
                  Zhenlan Ji and
                  Daoyuan Wu and
                  Shuai Wang and
                  Juergen Rahmel},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {The Phantom Menace in Crypto-Based PET-Hardened Deep Learning Models:
                  Invisible Configuration-Induced Attacks},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4379--4393},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765107},
	doi = {10.1145/3719027.3765107},
	timestamp = {Sun, 07 Dec 2025 22:09:43 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/PengXLJWWR25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The increasing use of deep learning (DL) models has given rise to significant privacy concerns regarding training and inference data. To address these concerns, the community has increasingly adopted crypto-based privacy-enhancing technologies (CPET) like homomorphic encryption (HE), secure multi-party computation (MPC), and zero-knowledge proofs (ZKP). The integration of CPET with DL, often referred to as CPET-DL, is commonly facilitated by specialized frameworks like CrypTen, TenSEAL, and EZKL. These frameworks offer configurable parameters to balance model accuracy and computational efficiency during privacy-preserving operations. However, these configurations, while seemingly harmless, can introduce subtle vulnerabilities. The stealthy attacks induced by misconfigurations are hard to detect because 1) the plaintext models remain vulnerability-free, and 2) existing auditing tools are hardly applicable to CPET-hardened models. This creates a paradox: tools intended to protect privacy can be undermined through configuration manipulation. We present ConPETro, the first attack on CPET-hardened models by manipulating the CPET-DL framework configurations. We show that well-crafted configurations allow attackers to create CPET-hardened models that function similarly to benign plaintext models under normal inputs, but exhibit significantly reduced robustness for malicious inputs embedded with triggers. ConPETro strategically selects triggers to maximize behavioral deviations with benign models and uses gradient consistency to guide configuration exploration, effectively finding malicious configurations that bypass standard plaintext model auditing. Evaluations across three mainstream CPET-DL frameworks (HE, MPC, and ZKP) demonstrate ConPETro's effectiveness in both semantic and non-semantic triggers. ConPETro achieves an average maximum attack success rate (ASR) of 72.27% in CPET-hardened models with non-semantic triggers; the accuracy only drops by 4%, thus maintaining stealthiness. It also achieves a maximum ASR of 94.74% with semantic triggers across three datasets. We also demonstrate that our stealthy attacks can bypass advanced defense and detection tools.}
}


@inproceedings{DBLP:conf/ccs/NasrFIAFPTTBC25,
	author = {Milad Nasr and
                  Yanick Fratantonio and
                  Luca Invernizzi and
                  Ange Albertini and
                  Loua Farah and
                  Alex Petit{-}Bianco and
                  Andreas Terzis and
                  Kurt Thomas and
                  Elie Bursztein and
                  Nicholas Carlini},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Evaluating the Robustness of a Production Malware Detection System
                  to Transferable Adversarial Attacks},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4394--4408},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765118},
	doi = {10.1145/3719027.3765118},
	timestamp = {Fri, 26 Dec 2025 20:53:05 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/NasrFIAFPTTBC25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As deep learning models become widely deployed as components within larger production systems, their individual shortcomings can create system-level vulnerabilities with real-world impact. This paper studies how adversarial attacks targeting an ML component can degrade or bypass an entire production-grade malware detection system, performing a case study analysis of Gmail's pipeline where file-type identification relies on a ML model. The malware detection pipeline in use by Gmail contains a machine learning model that routes each potential malware sample to a specialized malware classifier to improve accuracy and performance. This model, called Magika, has been open sourced. By designing adversarial examples that fool Magika, we can cause the production malware service to incorrectly route malware to an unsuitable malware detector thereby increasing our chance of evading detection. Specifically, by changing just 13 bytes of a malware sample, we can successfully evade Magika in 90% of cases and thereby allow us to send malware files over Gmail. We then turn our attention to defenses, and develop an approach to mitigate the severity of these types of attacks. For our defended production model, a highly resourced adversary requires 50 bytes to achieve just a 20% attack success rate. We implement this defense, and, thanks to a collaboration with Google engineers, it has already been deployed in production for the Gmail classifier.}
}


@inproceedings{DBLP:conf/ccs/ChaudhariHJSNO25,
	author = {Harsh Chaudhari and
                  Jamie Hayes and
                  Matthew Jagielski and
                  Ilia Shumailov and
                  Milad Nasr and
                  Alina Oprea},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Cascading Adversarial Bias from Injection to Distillation in Language
                  Models},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4409--4422},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765122},
	doi = {10.1145/3719027.3765122},
	timestamp = {Fri, 26 Dec 2025 20:53:05 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/ChaudhariHJSNO25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Model distillation has become essential for creating deployable language models, but their widespread deployment raises concerns about about their resilience to adversarial manipulation. This paper investigates how adversaries can inject subtle biases into teacher models through minimal data poisoning during training, which propagates to a smaller distilled student model and becomes significantly amplified. We identify two propagation modes: Untargeted (affecting multiple tasks) and Targeted (focusing on specific task while maintaining normal behavior elsewhere). With only 25 poisoned samples (0.25% poisoning rate), student models generate biased responses 76.9% of the time in targeted scenarios versus 69.4% in teachers, while untargeted propagation shows 5.7X-29.2X higher adversarial bias rate in students on unseen tasks. We validate across six bias types (targeted advertisement, phishing link, narrative manipulations, insecure coding practices), various distillation methods, and text/code generation modalities. Current defense mechanisms—including perplexity filtering, bias detection systems, and LLM-based autoraters—prove inadequate against these attacks. We propose practical design principles for building effective adversarial bias mitigation strategies to address this threat vector.}
}


@inproceedings{DBLP:conf/ccs/CaoLCG0C25,
	author = {Bochuan Cao and
                  Changjiang Li and
                  Yuanpu Cao and
                  Yameng Ge and
                  Ting Wang and
                  Jinghui Chen},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {You Can't Steal Nothing: Mitigating Prompt Leakages in LLMs via System
                  Vectors},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4423--4437},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765124},
	doi = {10.1145/3719027.3765124},
	timestamp = {Fri, 26 Dec 2025 20:53:05 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/CaoLCG0C25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Large language models (LLMs) have been widely adopted across various applications, leveraging customized system prompts for diverse tasks. Facing potential system prompt leakage risks, model developers have implemented strategies to prevent leakage, primarily by disabling LLMs from repeating their context when encountering known attack patterns. However, it remains vulnerable to new and unforeseen prompt-leaking techniques. In this paper, we first introduce a simple yet effective prompt leaking attack to reveal such risks. Our attack is capable of extracting system prompts from various LLM-based application, even from SOTA LLM models such as GPT-4o or Claude 3.5 Sonnet. Our findings further inspire us to search for a fundamental solution to the problems by having no system prompt in the context. To this end, we propose SysVec, a novel method that encodes system prompts as internal representation vectors rather than raw text. By doing so, SysVec minimizes the risk of unauthorized disclosure while preserving the LLM's core language capabilities. Remarkably, this approach not only enhances security but also improves the model's general instruction-following abilities. Experimental results demonstrate that SysVec effectively mitigates prompt leakage attacks, preserves the LLM's functional integrity, and helps alleviate the forgetting issue in long-context scenarios.}
}


@inproceedings{DBLP:conf/ccs/RanzatoSZ25,
	author = {Francesco Ranzato and
                  Ahmad Shakeel and
                  Marco Zanella},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Exact Robustness Certification of k-Nearest Neighbors},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4439--4453},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765140},
	doi = {10.1145/3719027.3765140},
	timestamp = {Fri, 26 Dec 2025 20:53:05 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/RanzatoSZ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Robustness guarantees are essential for deploying machine learning models in security-critical environments where adversarial attacks pose a serious threat. While extensive progress has been made in certifying (deep) neural networks, nonparametric models such as  k -Nearest Neighbors ( k -NN) have been less investigated, despite their interpretability and usage in high-assurance settings. Prior certification methods for  k -NN provide sound but incomplete guarantees, leaving many genuinely robust inputs uncertified. This work introduces a sound and complete certification framework for  k -NN classifiers, offering  exact  robustness guarantees against adversarial perturbations. Our approach combines hypercube space decomposition with a novel graph-theoretic analysis based on an adversarial proximity precedence graph, enabling full coverage of adversarial regions. Extensive evaluation on widely used datasets demonstrates that our exact methodology significantly improves certification rates over existing techniques while maintaining scalability. By closing the gap between soundness and completeness, our framework advances the security guarantees of  k -NN models and contributes to the broader goal of provably robust machine learning in adversarial settings.}
}


@inproceedings{DBLP:conf/ccs/0001DTP25,
	author = {Sangho Lee and
                  Jules Drean and
                  Yue Tan and
                  Marcus Peinado},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {IOValve: Leakage-Free {I/O} Sandbox for Large-Scale Untrusted Data
                  Processing},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4454--4468},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765121},
	doi = {10.1145/3719027.3765121},
	timestamp = {Fri, 26 Dec 2025 20:53:05 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/0001DTP25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The widespread adoption of Large Language Models (LLMs) is driving the rapidly growing demand for large-scale computations like training and fine-tuning models. In many areas, the confidentiality of the underlying data is of critical importance to their corporate or government owners. However, securing data in large-scale computations is challenging. First, its demand for enormous hardware resources typically requires outsourcing (e.g., to the public cloud). Second, the large and rapidly evolving software stack used in LLM training in conjunction with a growing incidence of supply chain attacks and software vulnerabilities makes it all but impossible for data owners to establish trust in the code that processes their highly sensitive data. Confidential computing and sandboxing are promising techniques for solving these problems. However, existing sandboxes do not address covert channels which limits their ability to protect confidential data. This paper proposes  IOValve,  a novel I/O sandbox for large-scale computations on confidential data.  IOValve  places sandbox enforcement on a programmable network device that is physically isolated from the processor hardware running the untrusted software stack. This construction allows  IOValve  to sidestep the multitude of side channels due to visible or hidden resource sharing.  IOValve  interposes on all network I/O of the sandbox and only transmits encrypted and regularized network traffic in order to prevent information leakage over the network. Our evaluation shows that  IOValve  has marginal performance overhead and supports real-world applications like LLM fine-tuning and batch inference, and molecular simulation.}
}


@inproceedings{DBLP:conf/ccs/TakekoshiMFS25,
	author = {Satoru Takekoshi and
                  Manami Mori and
                  Takaaki Fukai and
                  Takahiro Shinagawa},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {BadAML: Exploiting Legacy Firmware Interfaces to Compromise Confidential
                  Virtual Machines},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4469--4483},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765123},
	doi = {10.1145/3719027.3765123},
	timestamp = {Fri, 26 Dec 2025 20:53:05 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/TakekoshiMFS25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Confidential virtual machines (CVMs) are an emerging form of trusted execution environment that enable existing operating systems (OSs) to run securely without trusting cloud providers. To this end, CVMs employ hardware-based memory encryption for runtime confidentiality and cryptographic attestation to verify memory integrity at startup. However, we reveal a previously overlooked attack vector that allows malicious cloud providers to bypass CVM attestation and execute arbitrary code within users' CVMs regardless of specific CVM configurations. Our attack,  BadAML , exploits the Advanced Configuration and Power Interface (ACPI), a legacy yet widely adopted firmware interface for machine configuration. Specifically, BadAML leverages ACPI Machine Language (AML) to inject arbitrary binary code into the guest OS kernel without affecting CVM attestation. Because ACPI remains an essential component even in virtualized environments, BadAML constitutes a powerful and portable attack vector independent of guest OS type and CVM technology. We demonstrate proof-of-concept exploits of BadAML in both Linux and Windows CVM environments. We then analyze possible mitigation measures, discussing their effectiveness and limitations. Finally, we introduce  AML sandboxing , a practical defense that restricts memory access to safe regions under the CVM threat model; we present its design, implementation, and evaluation, demonstrating its effectiveness across 18 real-world cloud CVM instances.}
}


@inproceedings{DBLP:conf/ccs/BleySWSH25,
	author = {Moritz Bley and
                  Tobias Scharnowski and
                  Simon W{\"{o}}rner and
                  Moritz Schloegel and
                  Thorsten Holz},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Protocol-Aware Firmware Rehosting for Effective Fuzzing of Embedded
                  Network Stacks},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4484--4498},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765125},
	doi = {10.1145/3719027.3765125},
	timestamp = {Fri, 26 Dec 2025 20:53:05 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/BleySWSH25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {One of the biggest attack surfaces of embedded systems is their network interfaces, which enable communication with other devices. Unlike their general-purpose counterparts, embedded systems are designed for specialized use cases, resulting in unique and diverse communication stacks. Unfortunately, current approaches for evaluating the security of these embedded network stacks require manual effort or access to hardware, and they generally focus only on small parts of the embedded system. A promising alternative is  firmware rehosting,  which enables fuzz testing of the entire firmware by generically emulating the physical hardware. However, existing rehosting methods often struggle to meaningfully explore network stacks due to their complex, multi-layered input formats. This limits their ability to uncover deeply nested software faults. To address this problem, we introduce a novel method to automatically detect and handle the use of network protocols in firmware called P emu . By automatically deducing the available network protocols, P emu  can transparently generate valid network packets that encapsulate fuzzing data, allowing the fuzzing input to flow directly into deeper layers of the firmware logic. Our approach thus enables a deeper, more targeted, and layer-by-layer analysis of firmware components that were previously difficult or impossible to test. Our evaluation demonstrates that P emu  consistently improves the code coverage of three existing rehosting tools for embedded network stacks. Furthermore, our fuzzer rediscovered several known vulnerabilities and identified five previously unknown software faults, highlighting its effectiveness in uncovering deeply nested bugs in network-exposed code.}
}


@inproceedings{DBLP:conf/ccs/JohannesmeyerIG25,
	author = {Brian Johannesmeyer and
                  Raphael Isemann and
                  Cristiano Giuffrida and
                  Herbert Bos},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Dynamic Detection of Vulnerable {DMA} Race Conditions},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4499--4513},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765126},
	doi = {10.1145/3719027.3765126},
	timestamp = {Thu, 25 Dec 2025 12:46:54 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/JohannesmeyerIG25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The drivers of modern operating systems use Direct Memory Access (DMA) to efficiently communicate with peripheral devices. Since the memory accessed by DMA is a shared resource between driver and device, it is a possible source of race conditions. Peripheral devices are also often untrusted, so these race conditions open up a new potential attack vector against a trusted OS kernel. In this paper, we present DMAR acer , a dynamic detector called for these DMA-based race conditions in kernel code. DMAR acer  tracks memory accesses to DMA memory throughout the kernel's lifetime and analyses them for various indicators of race conditions. Additionally, upon detecting a race condition, DMAR acer  uses taint tracking to trace its impact and identify any potential vulnerabilities it may trigger, such as memory corruption or denial-of-service. We used DMAR acer  to search the drivers of the Linux kernel for DMA-based errors and find that DMA-based race conditions are a systemic issue in driver code. In total, DMAR acer  was able to detect 817 problematic memory accesses and 344 vulnerable operations in the scanned Linux kernel drivers.}
}


@inproceedings{DBLP:conf/ccs/HugenrothLMB25,
	author = {Daniel Hugenroth and
                  Mario Lins and
                  Ren{\'{e}} Mayrhofer and
                  Alastair R. Beresford},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Attestable Builds: Compiling Verifiable Binaries on Untrusted Systems
                  using Trusted Execution Environments},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4514--4528},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765128},
	doi = {10.1145/3719027.3765128},
	timestamp = {Fri, 26 Dec 2025 20:53:05 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/HugenrothLMB25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper we present attestable builds, a new paradigm to provide strong source-to-binary correspondence in software artifacts. We tackle the challenge of opaque build pipelines that disconnect the trust between source code, which can be understood and audited, and the final binary artifact which is difficult to inspect. Our system uses modern trusted execution environments (TEEs) and sandboxed build containers to provide strong guarantees that a given artifact was correctly built from a specific source code snapshot. As such it complements existing approaches like reproducible builds which typically require time-intensive modifications to existing build configurations and dependencies, and require independent parties to continuously build and verify artifacts. In comparison, an attestable build requires only minimal changes to an existing project, and offers nearly instantaneous verification of the correspondence between a given binary and the source code and build pipeline used to construct it. We evaluate it by building open-source software libraries—focusing on projects which are important to the trust chain and have proven difficult to be built deterministically. The overhead (42 seconds start-up latency and 14% increase in build duration) is small in comparison to the overall build time. Importantly, our prototype can build complex projects such as LLVM Clang without requiring any modifications to their source code and build scripts. Finally, we formally model and verify the attestable build design to demonstrate its security against well-resourced adversaries.}
}


@inproceedings{DBLP:conf/ccs/Attias0MBM25,
	author = {Vidal Attias and
                  Nicolas Bellec and
                  Gr{\'{e}}goire Menguy and
                  S{\'{e}}bastien Bardin and
                  Jean{-}Yves Marion},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Augmenting Search-based Program Synthesis with Local Inference Rules
                  to Improve Black-box Deobfuscation},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4529--4543},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765134},
	doi = {10.1145/3719027.3765134},
	timestamp = {Sun, 07 Dec 2025 22:09:40 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/Attias0MBM25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Code obfuscation aims to protect programs from reverse engineering, with applications ranging from intellectual property protection to malware hardening. Recent works on black-box analyses propose to leverage program synthesis in order to infer the semantics of highly obfuscated code blocks. Being fully  black-box,  these approaches are immune to  syntactic  complexity and can thus bypass standard obfuscation mechanisms. Yet, they are restricted by their synthesis capabilities and can only be applied to  semantically  simple code blocks. It explains why they have mainly been used on virtual machine handlers, where behaviors are usually simple enough. Applying black-box deobfuscation at scale beyond virtualization is still an open problem, notably because black-box methods cannot synthesize complex behaviors involving, for example, arbitrary constant values or affine or polynomial relations over mixed-boolean-arithmetic expressions. In this article, we show how to combine  search-based program synthesis  with  local inference rules,  resulting in a new method named  Search Modulo Inference Rules  ( Smir  that boosts search-based program synthesis while keeping its generality and flexibility. We instantiate  Smir  with inference rules for hard synthesis problems like arbitrary constant values and affine or polynomial relations over mixed boolean expressions, yielding the new black-box deobfuscation tool:  XSmir . Experiments on obfuscated codes, real-world binaries, and synthetic benchmarks demonstrate that  XSmir  significantly outperforms prior black-box deobfuscators, synthesizing overall 76% and 84% of the expressions from our real-world obfuscated and non-obfuscated benchmarks where prior works recover 63% and 55%, together with 2 to 3 times less false positive and slightly improved compression rate.}
}


@inproceedings{DBLP:conf/ccs/ChenWZX25,
	author = {Andong Chen and
                  Yangyang Wang and
                  Jia Zhang and
                  Mingwei Xu},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Right the Ship: Assessing the Legitimacy of Invalid Routes in {RPKI}},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4544--4558},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744853},
	doi = {10.1145/3719027.3744853},
	timestamp = {Fri, 26 Dec 2025 20:53:05 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/ChenWZX25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Resource Public Key Infrastructure (RPKI) aims to prevent prefix hijacking by providing secure mappings between IP prefixes and their authorized origin Autonomous Systems (ASes). In recent years, there has been notable growth in the deployment of RPKI and Route Origin Validation (ROV). Nonetheless, over 40% of the routes in the global routing table still lack the protection of RPKI. One of the critical reasons some networks are reluctant to deploy RPKI is the concern that some ROV-invalid routes may be legitimate, and filtering these routes will harm network service quality, especially affecting network connectivity. In this work, we perform a comprehensive measurement study to assess the legitimacy of ROV-invalid routes in RPKI. We evaluate the impact of filtering all ROV-invalid routes in the global routing table, presenting a view that some ROV-invalid routes are not illegitimate, defined as harmlessly ROV-invalid (h-invalid). We propose five characteristics and design a characteristics-based methodology for identifying h-invalid routes. Based on the methodology, we analyze the magnitude of h-invalid routes present on the Internet each day, revealing that over 91% of ROV-invalid results are h-invalid. Furthermore, we conclude three main reasons for h-invalid routes. Finally, with all our findings, we provide practical recommendations for network operators to help promote RPKI deployment.}
}


@inproceedings{DBLP:conf/ccs/WuZLLAD25,
	author = {Dashuai Wu and
                  Yunyi Zhang and
                  Baojun Liu and
                  Xiang Li and
                  Eihal Alowaisheq and
                  Haixin Duan},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Exploring and Analyzing Cross Layer DoS Attack Against UDP-based Services
                  on Linux},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4559--4573},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744878},
	doi = {10.1145/3719027.3744878},
	timestamp = {Fri, 26 Dec 2025 20:53:05 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/WuZLLAD25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The layered architecture of the TCP/IP protocol stack enables protocol layers to be implemented independently and flexibly. However, this layered design introduces potential security risks when shared resources are not properly managed between different layers. This paper investigates a neglected cross-layer shared resource risk, termed SocketFilled, which exploits the insecure usage of the UDP send buffer at the transport layer by the link layer, resulting in the interruption of response packets from the upper application layer. To explore the root causes of cross-layer DoS vulnerabilities resulting from the implementation of the TCP/IP protocol stack, we systematically analyzed the protocol standards of address resolution and reviewed the implementation in mainstream open-source operating systems. Moreover, we conducted a comprehensive experimental evaluation of mainstream operating systems (e.g., Linux and FreeBSD) and UDP services (e.g., DNS and QUIC). The experimental results show that the latest version of Linux and UDP service software (e.g., BIND9, PowerDNS, and Nginx) are affected, causing significant packet loss and even complete service interruption. Then, we estimated the impact range of SocketFilled in the wild and demonstrated that 17.3% of open resolvers,54.3% of authoritative servers of the Tranco Top 100K domains, and 3.8% of these well-known domains' HTTP/3 servers are potentially affected, including Bing, Amazon, and Shopee, after excluding the influence of cloud servers. We have conducted responsible disclosure by reporting the vulnerability to the Linux community. Our research highlights the effectiveness of cross-layer mechanisms in DoS attacks and calls for heightened attention to the layered complexity of protocol stack implementations within the security community.}
}


@inproceedings{DBLP:conf/ccs/FengL0W0025,
	author = {Xuewei Feng and
                  Zhaoxi Li and
                  Qi Li and
                  Ziqiang Wang and
                  Kun Sun and
                  Ke Xu},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Off-Path {TCP} Exploits: {PMTUD} Breaks {TCP} Connection Isolation
                  in {IP} Address Sharing Scenarios},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4574--4587},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744888},
	doi = {10.1145/3719027.3744888},
	timestamp = {Fri, 26 Dec 2025 20:53:05 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/FengL0W0025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Path MTU Discovery (PMTUD) and IP address sharing are integral aspects of modern Internet infrastructure. In this paper, we investigate the security vulnerabilities associated with PMTUD within the context of prevalent IP address sharing practices. We reveal that PMTUD is inadequately designed to handle IP address sharing, creating vulnerabilities that attackers can exploit to perform off-path TCP hijacking attacks. We demonstrate that by observing the path MTU value determined by a server for a public IP address (shared among multiple devices), an off-path attacker on the Internet, in collaboration with a malicious device, can infer the sequence numbers of TCP connections established by other legitimate devices sharing the same IP address. This vulnerability enables the attacker to perform off-path TCP hijacking attacks, significantly compromising the security of the affected TCP connections. Our attack involves first identifying a target TCP connection originating from the shared IP address, followed by inferring the sequence numbers of the identified connection. We thoroughly assess the impacts of our attack under various network configurations. Experimental results reveal that the attack can be executed within an average time of 220 seconds, achieving a success rate of 70%. Case studies, including SSH DoS, FTP traffic poisoning, and HTTP injection, highlight the threat it poses to various applications. Additionally, we evaluate our attack across 50 real-world networks with IP address sharing---including public Wi-Fi, VPNs, and 5G---and find 38 vulnerable. Finally, we responsibly disclose the vulnerabilities, receive recognition from organizations such as IETF, Linux, and Cisco, and propose our countermeasures.}
}


@inproceedings{DBLP:conf/ccs/HuGZZGHL25,
	author = {Junjie Hu and
                  Feng Guo and
                  Qihang Zhou and
                  Yixin Zhang and
                  Zibo Gao and
                  Yinglong Han and
                  Zhiqiang Lv},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {{SISTAR:} An Efficient DDoS Detection and Mitigation Framework Utilizing
                  Programmable Data Planes},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4589--4603},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765046},
	doi = {10.1145/3719027.3765046},
	timestamp = {Fri, 26 Dec 2025 20:53:05 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/HuGZZGHL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {DDoS attacks have become one of the most severe cybersecurity threats, especially in application-layer attacks. With the emergence of Programmable Data Planes (PDPs), it has become possible to maintain line-rate throughput while achieving high detection rates, making them crucial in addressing DDoS challenges. However, due to the complexity of DDoS attacks, detection remains resource-intensive and overall network defense effectiveness is limited. This limitation becomes particularly pronounced in clustered environments, where coordinated defense is essential. This paper presents SISTAR, an innovative framework for efficient DDoS detection and mitigation using PDP. SISTAR integrates an improved Decision Tree - Constrained Threshold Segmentation (DT-CTS) model to achieve high detection accuracy while minimizing hardware resource usage. Through distributed deployment across multiple switches, SISTAR enhances network resilience by enabling rapid detection and coordinated response to DDoS attacks. We implement a prototype of SISTAR and evaluate its performance in a realistic testbed, the experimental results show that SISTAR surpasses existing models in terms of detection accuracy and resource efficiency. When combined with its alert pushback mechanism, SISTAR can effectively reduce network resource consumption caused by DDoS attacks.}
}


@inproceedings{DBLP:conf/ccs/HeDHWZLSZXSLQ025,
	author = {Xin He and
                  Enhuan Dong and
                  Jiyuan Han and
                  Zhiliang Wang and
                  Hui Zhang and
                  Liang Liu and
                  Lianyi Sun and
                  Supei Zhang and
                  Pengfei Xue and
                  Guanglei Song and
                  Han Li and
                  Xiaowen Quan and
                  Jiahai Yang},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {ScannerGrouper: {A} Generalizable and Effective Scanning Organization
                  Identification System Toward the Open World},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4604--4618},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765053},
	doi = {10.1145/3719027.3765053},
	timestamp = {Fri, 26 Dec 2025 20:53:05 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/HeDHWZLSZXSLQ025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent years, many scanning organizations deploy large numbers of scanners to actively probe the Internet. Identifying the organizations behind these scanners is of significant value. The problem of analyzing the sources of scanners has been investigated in various studies. However, as far as we know, the problem of effectively and generally identifying scanner organizations in real-world scenarios remains unsolved. In this paper, we present ScannerGrouper, a darknet-independent system specifically designed to identify the organizations behind Internet scanners in real-world scenarios. ScannerGrouper leverages monitoring systems capable of capturing service probes, e.g., honeypots, to collect traffic for subsequent analysis. To address the robustness challenge, ScannerGrouper selects features from the payloads of the first service probes sent by scanners through statistical analysis, and aggregates the identification results from multiple service-specific classifiers. To tackle the open-world issue, ScannerGrouper customizes a state-of-the-art open-set model to our specific task, and updates the system incrementally. We conduct extensive experiments to validate ScannerGrouper effectiveness. ScannerGrouper outperforms baseline solutions in identification performance, achieving a weighted average F1-score that is 1.63 to 4.05 times higher. We also experimentally analyze the identification results of unattributed scanners, training time, the performance of possible alternative models of the core module, and the impact of hyperparameters, etc.}
}


@inproceedings{DBLP:conf/ccs/BaumerBRSS25,
	author = {Fabian B{\"{a}}umer and
                  Marcus Brinkmann and
                  Maximilian Radoy and
                  J{\"{o}}rg Schwenk and
                  Juraj Somorovsky},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {On the Security of {SSH} Client Signatures},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4619--4633},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765079},
	doi = {10.1145/3719027.3765079},
	timestamp = {Sun, 07 Dec 2025 22:09:40 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/BaumerBRSS25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Administrators and developers use SSH client keys and signatures for authentication, for example, to access internet backbone servers or to commit new code on platforms like GitHub. However, unlike servers, SSH clients cannot be measured through internet scans. We close this gap in two steps. First, we collect SSH client public keys. Such keys are regularly published by their owners on open development platforms like GitHub and GitLab. We systematize previous non-academic work by subjecting these keys to various security tests in a longitudinal study. Second, in a series of black-box lab experiments, we analyze the implementations of algorithms for SSH client signatures in 24 popular SSH clients for Linux, Windows, and macOS. We extracted 31,622,338 keys from three public sources in two scans. Compared to previous work, we see a clear tendency to abandon RSA signatures in favor of EdDSA signatures. Still, in January 2025, we found 98 broken short keys, 139 keys generated from weak randomness, and 149 keys with common or small factors—the large majority of the retrieved keys exposed no weakness. Weak randomness can not only compromise a secret key through its public key, but also through signatures. It is well-known that a bias in random nonces in ECDSA can reveal the secret key through public signatures. For the first time, we show that the use of deterministic nonces in ECDSA can also be dangerous: The private signing key of a PuTTY client can be recovered from just 58 valid signatures if ECDSA with NIST curve P-521 is used. PuTTY acknowledged our finding in CVE-2024-31497, and they subsequently replaced the nonce generation algorithm.}
}


@inproceedings{DBLP:conf/ccs/NgK25,
	author = {Lucien K. L. Ng and
                  Vladimir Kolesnikov},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Toss: Garbled {PIR} from Table-Only Stacking},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4634--4648},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744831},
	doi = {10.1145/3719027.3744831},
	timestamp = {Sun, 07 Dec 2025 22:09:43 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/NgK25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Garbled Circuits (GC) is a foundational primitive for secure two-party computation (2PC). Garbled Private Information Retrieval (GPIR) is a GC technique for looking up a public array or database (DB) on a private index unknown to either player. GPIR immediately implies GC evaluation of functions implemented as a publicly known look-up table (LUT). GPIR is costly: it can be obtained by a linear scan, adapting Garbled RAM, stacking GC branches implementing access to table elements, and, most recently, from the GC look-up table ''logrow'' (Heath et al., Eurocrypt 2024). For a database of N rows with m-bit entries, logrow's computation is approximately O(NmΚ), and its communication is O(m·(log N·Κ + N)). Logrow thus can be effectively used on tables of size up to about 2 15 . We propose  Toss, a new efficient GPIR with dramatically reduced bandwidth consumption (a scarce resource in MPC!), both asymptotically and concretely. Our communication cost is O(m(N·m·Κ)), with a small constant, sublinear in both N and the security parameter Κ. Our computation cost is O(N·m·Κ + (√(N/Κ)·m + N)·c Κ )), where c Κ  is the cost of hash evaluation. This matches or slightly improves on logrow's computational cost. In concrete terms, for a 2 20 -row LUT of 8-bit items, we improve over logrow by a factor of >31× in communication. On a laptop over a 100 Mbps channel, throughput rises from ≈10.6 lookups/s to ≈81 lookups/s (>7.5× improvement); on a 10 Mbps channel, Toss is >28× faster. Communication improvement grows with N—for N = 2 25 , m = 32, the gain exceeds 512×. Toss builds on stacked garbling (SGC) and logrow with multiple low-level optimizations, requiring reworking of their internals and interfaces. We emphasize that constructing GPIR directly from SGC incurs logarithmic computational overhead, which actually reduces throughput in typical ''laptop + LAN'' testbeds. We implement our construction and report its performance.}
}


@inproceedings{DBLP:conf/ccs/FranzeseF00JPD25,
	author = {Olive Franzese and
                  Congyu Fang and
                  Radhika Garg and
                  Xiao Wang and
                  Somesh Jha and
                  Nicolas Papernot and
                  Adam Dziedzic},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Secure Noise Sampling for Differentially Private Collaborative Learning},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4649--4663},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744834},
	doi = {10.1145/3719027.3744834},
	timestamp = {Fri, 26 Dec 2025 20:53:05 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/FranzeseF00JPD25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Differentially private stochastic gradient descent (DP-SGD) trains machine learning (ML) models with formal privacy guarantees for the training set by adding random noise to gradient updates. In collaborative learning (CL), where multiple parties jointly train a model, noise addition occurs either (i) before or (ii) during secure gradient aggregation. The first option is deployed in distributed DP methods, which require greater amounts of total noise to achieve security, resulting in degraded model utility. The second approach preserves model utility but requires a secure multiparty computation (MPC) protocol. Existing methods for MPC noise generation require tens to hundreds of seconds of runtime per noise sample because of the number of parties involved. This makes them impractical for collaborative learning, which often requires thousands or more samples of noise in each training step. We present a novel protocol for MPC noise sampling tailored to the collaborative learning setting. It works by constructing an approximation of the distribution of interest which can be efficiently sampled by a series of table lookups. Our method achieves significant runtime improvements and requires much less communication compared to previous work, especially at higher numbers of parties. It is also highly flexible -- while previous MPC sampling methods tend to be optimized for specific distributions, we prove that our method can generically sample noise from statistically close approximations of  arbitrary  discrete distributions. This makes it compatible with a wide variety of DP mechanisms. Our experiments demonstrate the efficiency and utility of our method applied to a discrete Gaussian mechanism for differentially private collaborative learning. For 16 parties, we achieve a runtime of 0.06 seconds and 11.59 MB total communication per sample, a 230× runtime improvement and 3× less communication compared to the prior state-of-the-art for sampling from discrete Gaussian distribution in MPC.}
}


@inproceedings{DBLP:conf/ccs/ChiangDDEKS25,
	author = {James Hsin{-}yu Chiang and
                  Ivan Damg{\aa}rd and
                  William R. Duro and
                  Sunniva Engan and
                  Sebastian Kolby and
                  Peter Scholl},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Post-Quantum Threshold Ring Signature Applications from VOLE-in-the-Head},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4664--4678},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744854},
	doi = {10.1145/3719027.3744854},
	timestamp = {Fri, 26 Dec 2025 20:53:05 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/ChiangDDEKS25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We propose efficient, post-quantum threshold ring signatures constructed from one-wayness of AES encryption and the VOLE-in-the-Head zero-knowledge proof system. Our scheme scales efficiently to large rings and extends the linkable ring signatures paradigm. We define and construct key-binding deterministic tags to achieve linkability. We then extend our threshold ring signatures to realize post-quantum anonymous ledger transactions in the spirit of Monero. Finally, our deterministic tags also enable succinct aggregation using approximate lower bound arguments of knowledge; this allows us to achieve succinct (approximate) multi-signatures without SNARKs. Our constructions assume symmetric key primitives only. Whilst it is common to build post-quantum signatures from the one-wayness property of AES and a post-quantum NIZK scheme, we extend this paradigm to define and construct novel security properties from AES that are useful for advanced signature applications. We introduce key-binding and pseudorandomness of functions from AES to establish linkability and anonymity of our threshold ring signatures from deterministic tags, and similarly establish binding and hiding properties of block ciphers modeled as ideal permutations to build commitments from AES, a crucial building block for our proposed post-quantum anonymous ledger scheme.}
}


@inproceedings{DBLP:conf/ccs/PiskeSTKZ25,
	author = {Lucas Piske and
                  Jaspal Singh and
                  Ni Trieu and
                  Vladimir Kolesnikov and
                  Vassilis Zikas},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Distance-Aware {OT} with Application to Fuzzy {PSI}},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4679--4691},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744857},
	doi = {10.1145/3719027.3744857},
	timestamp = {Fri, 26 Dec 2025 20:53:05 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/PiskeSTKZ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A two-party fuzzy private set intersection (PSI) protocol between Alice and Bob with input sets  A  and  B  allows Alice to learn nothing more than the points of Bob that are ''δ-close'' to its points in some metric space  dist  . More formally, Alice learns only the set {b |  dist  (a,b) ≤ δ, a ∈ A, b ∈ B} for a predefined threshold δ and distance metric  dist , while Bob learns nothing about Alice's set. Fuzzy PSI is a valuable privacy tool in scenarios where private set intersection needs to be computed over imprecise or measurement-based data, such as GPS coordinates or healthcare data. Previous approaches to fuzzy PSI rely on asymmetric cryptographic primitives, generic two-party computation (2PC) techniques like garbled circuits, or function secret sharing methods, all of which are computationally intensive and lead to poor concrete efficiency. This work introduces a new modular framework for fuzzy PSI, primarily built on efficient symmetric key primitives. Our framework reduces the design of efficient fuzzy PSI to a novel variant of oblivious transfer (OT), which we term distance-aware random OT (da-ROT). This variant enables the sender to obtain two random strings (r 0 , r 1 ), while the receiver obtains one of these values r b , depending on whether the receiver's input keyword  a  and the sender's input keyword  b  are close in some metric space i.e.,  dist  (a,b) ≤ δ. The da-ROT can be viewed as a natural extension of traditional OT, where the condition (choice bit) is known to the receiver. We propose efficient constructions for da-ROT based on standard OT techniques tailored for small domains, supporting distance metrics such as the Chebyshev norm, the Euclidean norm, and the Manhattan norm. By integrating these da-ROT constructions, our fuzzy PSI framework achieves up to a 14× reduction in communication cost and up to a 54× reduction in computation cost compared to previous state-of-the-art protocols, across input set sizes ranging from 2 8  to 2 16 . Additionally, we extend our framework to compute fuzzy PSI cardinality and fuzzy join from traditional PSI-related functionalities. All proposed protocols are secure in the semi-honest model.}
}


@inproceedings{DBLP:conf/ccs/AsharovEKL25,
	author = {Gilad Asharov and
                  Eliran Eiluz and
                  Ilan Komargodski and
                  Wei{-}Kai Lin},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {MegaBlocks: Breaking the Logarithmic I/O-Overhead Barrier for Oblivious
                  {RAM}},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4692--4706},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765159},
	doi = {10.1145/3719027.3765159},
	timestamp = {Fri, 26 Dec 2025 20:53:05 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/AsharovEKL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Oblivious RAM (ORAM) is a central cryptographic primitive that enables secure memory access while hiding access patterns. Among existing ORAM paradigms, hierarchical ORAMs were long considered impractical despite their asymptotic optimality. However, recent advancements (FutORAMa, CCS'23) demonstrate that hierarchical ORAM-based schemes can be made efficient given sufficient client-side memory. In this work, we present a new hierarchical ORAM construction that achieves practical performance without requiring large local memory. From a theoretical standpoint, we identify that there is a gap in the literature concerning the asymmetric setting, where the logical word size is asymptotically smaller than the physical memory block size. In this scenario, the best-known construction (OptORAMa, J. ACM '23,) turns every logical query into  O (log  N ) physical memory accesses (quantity known as ''I/O overhead''), whereas the lower bound of Komargodski and Lin (CRYPTO'21) implies that Ω(log  N  /log log  N ) accesses are needed. We close this gap by constructing an optimal ORAM for the asymmetric setting, achieving an I/O overhead of  O (log  N  / log log  N ). Our construction features exceptionally small constants (between 1 and 4, depending on the block size) and operates without requiring large local memory. We implement our scheme and compare it to PathORAM (CCS'13) and FutORAMa, demonstrating significant improvement. For 1TB logical memory, our construction obtains X10-X30 reduction in I/O overhead and bandwidth compared to PathORAM, and X7--X26 improvement over FutORAMa. This improvement applies when those schemes weren't designed to operate on large blocks, as in our settings, and the exact improvement depends on the physical block size and the exact local memory available.}
}


@inproceedings{DBLP:conf/ccs/LiuZJ25,
	author = {Yiting Liu and
                  Biming Zhou and
                  Haodong Jiang},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {CuKEM: {A} Concise and Unified Hybrid Key Encapsulation Mechanism},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4707--4721},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3744863},
	doi = {10.1145/3719027.3744863},
	timestamp = {Fri, 26 Dec 2025 20:53:05 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/LiuZJ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the post-quantum migration of the traditional key establishment protocol, hybrid key encapsulation mechanisms (KEMs) are recommended by standards bodies, including NIST, ETSI, and national security agencies like NCSC-UK, BSI-Germany  etc.  Recently, several hybrid KEMs with CCA security such as XOR-then-MAC, Dual-PRF and X-Wing (being standardized by IETF) are proposed based on CCA KEMs obtained by applying the complicated Fujisaki-Okamoto transform to public-key encryption (PKE) schemes. In some cryptographic protocols such as PQ-Noise and Signal, 1CCA security (similar to the CCA security except that the adversary is restricted to one single decapsulation query) is required. However, no specific scheme has been designed to specifically achieve 1CCA security (excluding the schemes that aim to achieve CCA security, as they inherently encompass 1CCA security). In this paper, we propose CuKEM, a concise and unified hybrid KEM framework directly built on PKEs. We prove that CuKEM, equipped with different modules, achieves security notions in both the random oracle model and the quantum random oracle model, including IND-CPA, IND-1CCA, and IND-CCA. Compared to the existing KEM-based designs, CuKEM is more concise because it simplifies or even eliminates certain hash operations without compromising security. The evaluation shows that CuKEM can significantly improve efficiency over current hybrid KEMs,  e.g. , the encapsulation(decapsulation) of CCA-secure CuKEM efficiency gains of up to 22.28% (16.22%) compared to X-Wing, while the 1CCA-secure CuKEM gains up to 13.97% (104.31%).}
}


@inproceedings{DBLP:conf/ccs/KirschSV25,
	author = {Tobias Kirsch and
                  Haya Schulmann and
                  Niklas Vogel},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Demo: Stopping Production Testing: {A} Graphical {RPKI} Test-Suite},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4722--4723},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3760705},
	doi = {10.1145/3719027.3760705},
	timestamp = {Fri, 26 Dec 2025 20:53:05 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/KirschSV25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Resource Public Key Infrastructure (RPKI) is increasingly protecting global BGP routing and major players are pushing for wide-scale adoption. RPKI protection relies on correct publication and validity of RPKI objects: If a prefix has no valid covering RPKI object, e.g., because the object is invalid or expired, the prefix is not protected from hijacks. At the same time, ASes that issue RPKI objects lack any feedback whether their objects are considered valid by all RPKI validation software. This lack of feedback has repeatedly led to operational issues, and problems with object validity are persistent to this day. Oftentimes, issues with objects are only detected in production, after they have caused damage to routing. A prominent example of this is an issue with Amazon objects in 2023 that left 6000 of its prefixes open to hijack in any AS using a specific RPKI validator software implementation. In this work, we present a novel RPKI toolsuite that allows for comprehensive testing of RPKI objects, enabling operators to detect issues in their object configurations before production use. For this, our tool allows parsing arbitrary DER/base64 encoded objects, editing their content and structure, and live-testing them against all current RPKI validator implementations to probe for inconsistent validation results, errors, and even vulnerabilities. Our work provides an important foundation to ensure RPKI resilience against misconfigurations and facilitates future research into RPKI security. We make our tool open-source and provide a hosted web application to enable usage by the community.}
}


@inproceedings{DBLP:conf/ccs/Pilgun25,
	author = {Aleksandr Pilgun},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Demo: Reverse Engineering Android Apps with Code Coverage},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4725--4727},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3762169},
	doi = {10.1145/3719027.3762169},
	timestamp = {Sun, 07 Dec 2025 22:09:43 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/Pilgun25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Reverse engineering Android apps remains a critical and labor-intensive task, particularly for analyzing novel malware. Analysts typically begin with decompiled Java code using tools like JaDX and often must correlate it with runtime information gathered from dynamic analysis. In this work, we present JaDX-ACVTool, a plugin that bridges this gap by integrating code coverage information from ACVTool directly into JaDX-GUI. Our approach highlights Java methods executed during analysis, enabling security analysts to quickly identify and navigate runtime-relevant code paths. Plugin repository:  https://github.com/pilgun/jadx-acvtool}
}


@inproceedings{DBLP:conf/ccs/ZhangMA25,
	author = {Haoying Zhang and
                  Abhishek K. Mishra and
                  H{\'{e}}ber Hwang Arcolezi},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Demo: Exploring Utility and Attackability Trade-offs in Local Differential
                  Privacy},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4728--4730},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3760706},
	doi = {10.1145/3719027.3760706},
	timestamp = {Fri, 26 Dec 2025 20:53:05 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/ZhangMA25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Local Differential Privacy (LDP) provides strong, formal privacy guarantees without requiring a trusted curator, making it a promising approach for privacy-preserving data collection and analysis. However, despite extensive research, practitioners may struggle to understand how to tune LDP parameters and anticipate the impact on data utility and attack risks for their specific scenarios. To address this gap, we demonstrate LDP-Toolbox, the first interactive, web-based toolbox (implemented in Python) that enables practical, analytical visualization of trade-offs between privacy loss (ε), utility loss, and vulnerability to attacks. The toolbox supports exploration of these trade-offs using real-world datasets from different domains; in this demonstration, we focus on discrete personal attributes and location-based scenarios. By providing intuitive, visual insights, LDP-Toolbox lowers the barrier to deploying LDP in real applications and helps bridge the gap between theoretical guarantees and practical adoption. The toolbox is open-source on PyPI (https://pypi.org/project/ldp-toolbox) and a video is available on our GitHub repository (https://github.com/hharcolezi/ldp-toolbox).}
}


@inproceedings{DBLP:conf/ccs/TianL0L0SW025,
	author = {Renrui Tian and
                  Yahui Li and
                  Han Zhang and
                  Xinzhe Liu and
                  Xia Yin and
                  Xingang Shi and
                  Zhiliang Wang and
                  Jilong Wang},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Poster: {ERIS:} Evaluating {ROV} via ICMPv6 Rate Limiting Side Channels},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4731--4733},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3760707},
	doi = {10.1145/3719027.3760707},
	timestamp = {Fri, 26 Dec 2025 20:53:05 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/TianL0L0SW025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Resource Public Key Infrastructure (RPKI) plays a crucial role in securing BGP against prefix hijacking by enabling Route Origin Validation (ROV). However, the limited adoption of ROV in the real world undermines the effectiveness of RPKI. Hence, measuring ROV deployment in practice is essential for assessing the impact of RPKI. Existing measurement efforts either suffer from limited coverage and accuracy due to reliance on control-plane data, or require controlled IP prefixes or large-scale deployment of vantage points. Furthermore, most studies focused on IPv4, leaving ROV status in IPv6 largely underexplored. To bridge this gap, we propose  ERIS,  the first measurement framework to evaluate ROV in IPv6 by leveraging ICMPv6 rate limiting side channels.  ERIS  does not require controlled prefixes or distributed vantage points, enabling scalable and accurate ROV measurements from a single vantage point.}
}


@inproceedings{DBLP:conf/ccs/RyuSL25,
	author = {Nayeon Ryu and
                  Heeyeong Suh and
                  Seyoung Lee},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Poster: Longitudinal Analysis of Romance Scam Infrastructure Evolution:
                  Evidence of Strategic Legitimization},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4734--4736},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3760708},
	doi = {10.1145/3719027.3760708},
	timestamp = {Tue, 09 Dec 2025 08:06:19 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/RyuSL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Romance scams represent a cybercrime category causing more than 650 million in reported losses annually, with limited systematic longitudinal analysis. We present a 12-year infrastructure evolution study analyzing 11,674 romance scammer profiles from ScamDigger (2012-2024). Using IP geolocation and ASN classification, we identify a marked inflection in 2019. Contrary to expected technological advancement, we observe strategic migration toward legitimate infrastructure: Traditional ISP usage increased substantially while proxy usage declined from an average of 90.6% (pre-2019) to 53.1% (post-2019), corresponding to a 37.5 percentage-point decrease. Analysis reveals systematic geographic specialization with operational bases in West African Traditional ISPs (Nigeria: 94.2%, Ghana: 94.6%) and deceptive infrastructure in Western cloud services (US: 53.1%, Germany: 59.9%). ASN diversity contracted 31.3%, indicating ecosystem consolidation. These findings suggest ongoing industrialization through legitimacy exploitation, motivating adjustments to detection methodologies.}
}


@inproceedings{DBLP:conf/ccs/MaSHZ25,
	author = {Zijing Ma and
                  Leming Shen and
                  Xinyu Huang and
                  Yuanqing Zheng},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Poster: \emph{LLMalware}: An LLM-Powered Robust and Efficient Android
                  Malware Detection Framework},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4737--4739},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3760709},
	doi = {10.1145/3719027.3760709},
	timestamp = {Fri, 26 Dec 2025 20:53:05 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/MaSHZ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Android malware pose severe threats to the mobile application ecosystem. Although well-trained malware detection models can initially achieve satisfactory performance, they struggle with unseen Android apps constantly emerging over time, which is known as the concept drift problem. Previous methods frequently collect and label new apps to update the aging models. This process, however, necessitates domain knowledge and incurs prohibitive retraining overhead. To address this problem, this paper presents  LLMalware , which integrates three novel technical components. First, we propose  full-spectrum automated feature extraction , which automatically extracts diverse malware features from various detection models. Next, we develop  cohesive feature fusion , which combines these features to build effective representations for robust malware detection. Lastly, we devise  agile knowledge update  to enable efficient online malware detection via an LLM-based automated agent and a dynamically maintained malware knowledge base. Extensive experiments demonstrate  LLMalware  can mitigate concept drift with an average improvement of approximately 10% in F1-score over state-of-the-art baselines.}
}


@inproceedings{DBLP:conf/ccs/0043DCYX25,
	author = {Hao Zhou and
                  Hua Dai and
                  Siqi Cai and
                  Geng Yang and
                  Yang Xiang},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Poster: Adaptive Gradient Clipping with Personalized Differential
                  Privacy for Heterogeneous Federated Learning},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4740--4742},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3760710},
	doi = {10.1145/3719027.3760710},
	timestamp = {Fri, 26 Dec 2025 20:53:05 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/0043DCYX25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We present GC-DP, a novel federated learning framework that enables personalized differential privacy by adaptively adjusting gradient clipping thresholds. Unlike traditional DP methods that apply a fixed clipping bound, GC-DP uses a proxy dataset to learn client-specific mappings from privacy budgets (ε) to optimal clipping thresholds (C^*), while also allowing each client to adjust its local clipping bound in real time based on the  l 2  norm of its local gradient. This dual adaptivity significantly improves the balance between privacy protection and model utility in heterogeneous FL settings.}
}


@inproceedings{DBLP:conf/ccs/IshizueR025,
	author = {Tetsu Ishizue and
                  Sara Rampazzi and
                  Takeshi Sugawara},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Poster: Recapture Detection Using Disparity Map Obtained from Dual-Pixel
                  Image Sensors},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4743--4745},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3760711},
	doi = {10.1145/3719027.3760711},
	timestamp = {Fri, 26 Dec 2025 20:53:05 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/IshizueR025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recapturing computer monitors with a camera is a common threat to cryptographic techniques designed to verify the origin of images and prevent AI-generated deepfakes. Although depth information can help distinguish a real-world scene from a flat computer monitor, incorporating additional depth sensors is often cost-prohibitive. To address this challenge, we explore the use of dual-pixel (DP) image sensors commonly found in still and smartphone cameras for fast autofocus, as a means to extract depth information for distinguishing real scenes from recaptured ones, without requiring additional hardware. Our signal processing pipeline is composed of (i) a stereo matching algorithm to obtain a disparity map using a pair of images generated from a DP image sensor and (ii) plane fitting to evaluate the flatness of the scene. Our proof-of-concept evaluation on a real-world DP image dataset demonstrates that the proposed method detects recaptured images at 100% accuracy. Similarly, it successfully distinguishes real-world scenes from recaptured deepfake images with >98% accuracy.}
}


@inproceedings{DBLP:conf/ccs/Sun0LL25,
	author = {Chengbin Sun and
                  Hailong Sun and
                  Guancheng Li and
                  Jiashuo Liang},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Poster: Black-box Attacks on Multimodal Large Language Models through
                  Adversarial {ICC} Profiles},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4746--4748},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3760712},
	doi = {10.1145/3719027.3760712},
	timestamp = {Fri, 26 Dec 2025 20:53:05 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/Sun0LL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Despite their remarkable performance on vision-language tasks, multimodal large language models (MLLMs) remain vulnerable to adversarial examples. However, most existing attacks rely on gradient-based pixel perturbations and require white-box access to model parameters. In this paper, we propose ICCAdv, a novel black-box attack that requires no access to model parameters or gradients. The core idea of ICCAdv is to exploit the discrepancy between human and model perception of images during input processing. This discrepancy arises from the color management process, as human observers perceive rendered images based on ICC profile transformations, whereas most MLLMs circumvent this process and operate directly on raw RGB values. By embedding adversarial ICC profiles into image files, ICCAdv manipulates the perceived color semantics of MLLMs while preserving the natural visual appearance for human observers. Preliminary experiments indicate that ICCAdv can effectively attack state-of-the-art MLLMs while maintaining a natural visual appearance to human observers.}
}


@inproceedings{DBLP:conf/ccs/SanchezL25,
	author = {Gustavo S{\'{a}}nchez and
                  Adam Lundqvist},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Poster: Towards Intelligent Assurance for Autonomous {AI} Pentesters:
                  Concurrent Compliance Auditing and Self-Augmentation via Execution
                  Trace Analysis},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4749--4751},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3760713},
	doi = {10.1145/3719027.3760713},
	timestamp = {Mon, 15 Dec 2025 13:00:51 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/SanchezL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As Artificial Intelligence (AI) increasingly powers autonomous offensive security tools (i.e., AI Pentesters); ensuring their operational integrity, regulatory compliance (e.g., under the EU AI Act), and ethical conduct becomes critical, particularly when direct human oversight is limited or absent. To address these challenges, we propose an Intelligent Assurance System (IAS) that provides continuous oversight and accountability for fully autonomous AI Pentesters. The IAS is designed to enhance trustworthiness by monitoring execution traces, enforcing compliance, delivering real-time feedback, and facilitating self-improvement while being resource-efficient.}
}


@inproceedings{DBLP:conf/ccs/GiesenSD25,
	author = {Jens{-}Rene Giesen and
                  Christian Scholz and
                  Lucas Davi},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Poster: Code HarvETHter: Corpus-Driven Decompilation of Ethereum Smart
                  Contracts},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4752--4754},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3760714},
	doi = {10.1145/3719027.3760714},
	timestamp = {Sun, 07 Dec 2025 22:09:41 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/GiesenSD25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This poster introduces HarvETHter, a smart contract decompiler for EVM-based platforms such as Ethereum, Binance, and Polygon. We present the corpus completeness hypothesis, which we investigate through HarvETHter. Relying on our hypothesis, HarvETHter sources knowledge of the Ethereum blockchain and leverages it to decompile smart contracts to Solidity source code.}
}


@inproceedings{DBLP:conf/ccs/SchulmannV25,
	author = {Haya Schulmann and
                  Niklas Vogel},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Poster: We must talk about {RPKI} Repositories},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4755--4757},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3760715},
	doi = {10.1145/3719027.3760715},
	timestamp = {Fri, 26 Dec 2025 20:53:05 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/SchulmannV25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Resource Public Key Infrastructure (RPKI) increasingly protects global routing against attacks. RPKI protection builds on the security and availability of RPKI objects, which are stored in public RPKI repositories. Despite their critical role, not much is known about the technical specifics of these repositories. Which implementations do they use? Is the software maintained and secure? Which vulnerabilities persist? Answering these questions is essential to evaluate security and resilience of current RPKI architecture. In this work, we develop the first methods for fingerprinting RPKI repositories based on RPKI specification, using undefined implementation-specifics like arbitrary element order or naming conventions as fingerprinting metrics. We evaluate our methodology on all current production RPKI repositories and identify 7 different deployed implementations. We find implementations diversity, especially for large providers, but also identify that most repositories (56%) use the same software, Krill. Fingerprinting shows that most deployed software (71%) is vulnerable to attacks, and 4 repositories use software deprecated over 7 years ago. Our work is not only an important step towards a complete view of RPKI ecosystem security, but it also shows that specification analysis serves as a powerful basis for fingerprinting.}
}


@inproceedings{DBLP:conf/ccs/ChaeCKJOK25,
	author = {Sangjun Chae and
                  Jangseop Choi and
                  Taeyang Kim and
                  Eun Jung and
                  Sanghak Oh and
                  Hyoungshick Kim},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Poster: Insecure Coding Habits Die Hard. Can {PEFT} Really Turn LLMs
                  into Secure Coders?},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4758--4760},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3760716},
	doi = {10.1145/3719027.3760716},
	timestamp = {Fri, 26 Dec 2025 20:53:05 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/ChaeCKJOK25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Large language models (LLMs) have advanced automated code generation but often produce code with critical security flaws, including buffer overflows, memory leaks, and unsafe file handling. While prior work emphasizes post-hoc vulnerability detection, we introduce a framework for secure-by-construction code generation via parameter-efficient fine-tuning (PEFT). We construct a secure training dataset by automatically fixing 7 high-impact vulnerability types in 37,540 C code samples from CodeNet, achieving 95.36% CWE reduction. We then apply prompt and prefix tuning to four open-source models (CodeGen-16B/6B-multi and StarCoder2-7B/3B), updating fewer than 1% of the parameters. On the LLMSecEval benchmark, our approach increases secure code generations from 20 to 36 for StarCoder2-3B and from 10 to 27 for CodeGen-6B. These results demonstrate that PEFT can substantially improve code security without full model retraining.}
}


@inproceedings{DBLP:conf/ccs/LuKLS25,
	author = {Andrew Lu and
                  Mashrafi Kajol and
                  Wei Lu and
                  Dean Sullivan},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Poster: PainNOVA: Privacy-Aware Voice-Based Pain-Level Detection},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4761--4763},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3760717},
	doi = {10.1145/3719027.3760717},
	timestamp = {Fri, 26 Dec 2025 20:53:05 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/LuKLS25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Pain-level detection is vital to determine proper medical treatment. Existing self-reporting, behavioral, and image-based pain detection methods typically lead to high costs for professional staff and clinical equipment and also have a high risk of leaking sensitive information, which could be exploited by adversaries to learn gender, age group, and underlying health conditions. To address these challenges, we propose a privacy-aware voice-based pain-level detection framework, which extracts frequency-domain characteristics from audio files, removes the gender-sensitive features from the identified characteristics, and trains a convolutional neural network (CNN) to perform 3-level pain classification. Our preliminary analysis and experiments based on a commonly adopted database (TAME Pain dataset) indicate that log-Mel spectrogram and zero-crossing rate are two promising voice features for effective pain-level classification. We further extend our study to a nonverbal dataset, VIVAE (Variably Intense Vocalizations of Affect and Emotion Corpus), and confirm that the identified voice features are applicable to both verbal and nonverbal patients for pain classification.}
}


@inproceedings{DBLP:conf/ccs/TsengHCS25,
	author = {Yi{-}Fan Tseng and
                  Jheng{-}Jia Huang and
                  Guan{-}Yu Chen and
                  Ting{-}Hsiang Su},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Poster: Public Key Encryption with Exclusionary Subset Keyword Search
                  from Lattices},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4764--4766},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3760718},
	doi = {10.1145/3719027.3760718},
	timestamp = {Fri, 26 Dec 2025 20:53:05 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/TsengHCS25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper introduces a novel public-key searchable encryption (PKSE) scheme that supports a new search pattern:  exclusionary subset search,  which cannot be trivially realized from the current PKSE schemes. This pattern enables users to retrieve ciphertexts that do not contain a specific subset of keywords, offering a more intuitive and efficient approach in scenarios where excluding a limited set of keywords is crucial. Besides, our scheme is built over lattices, and support constant-size trapdoors, which take advantages against the existing lattice-based constructions.}
}


@inproceedings{DBLP:conf/ccs/MieschSV25,
	author = {Katharina Miesch and
                  Haya Schulmann and
                  Niklas Vogel},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Poster: The Rocky Road Towards {RPKI} Algorithm Agility},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4767--4769},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3760719},
	doi = {10.1145/3719027.3760719},
	timestamp = {Fri, 26 Dec 2025 20:53:05 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/MieschSV25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Resource Public Key Infrastructure (RPKI) already protects around 50% of announced BGP prefixes, and around 28% of systems enforce RPKI validity in routing. RPKI binds ownership of prefixes to public keys inside certificates, which are signed by the respective issuer. For signatures and keys, RPKI currently exclusively supports RSA-2048, forbidding other algorithms and key sizes. In this work, we practically show that RPKI efficiency could significantly benefit from algorithm agility, allowing for smaller more efficient algorithms like Elliptic Curve Cryptography (ECC). We further illustrate that current plans for shifting algorithms, which will eventually become necessary to shift towards quantum-secure algorithms, are infeasible due to bandwidth limitations, validation overhead, and issues with patch management. From our observations, we derive a new agility procedure that uses separate repository versions additional to two separate trees (a mixed tree and a legacy tree) to enable incremental deployment of a new algorithm. In contrast to existing approaches, our procedure provides benefits also for early adopters, facilitating deployment.}
}


@inproceedings{DBLP:conf/ccs/LengZZS25,
	author = {Xue Leng and
                  Hai Zhang and
                  Tiantian Zhu and
                  Jianguo Sun},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Poster: Leveraging Large Language Models to Effectively and Efficiently
                  Identify Vulnerability Patches for WordPress Plugins},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4770--4772},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3760720},
	doi = {10.1145/3719027.3760720},
	timestamp = {Fri, 26 Dec 2025 20:53:05 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/LengZZS25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Vulnerability patches are essential for managing vulnerabilities in Open-source software (OSS). However, accurately identifying them remains difficult. Existing methods mainly rely on rule-based matching and are not well-suited to ecosystems like WordPress plugins, due to the lack of a unified development standard. In contrast, methods that combine vulnerability descriptions with code changes demonstrate greater potential. However, current prediction models lack deep semantic understanding and thus cannot fully understand the meaning behind the changes. To address this issue, we propose LLM4Patch, a method that leverages the strong semantic understanding ability of Large Language Models (LLMs) to identify security patches. It takes a range of commits and the related vulnerability information as input. The LLM then identifies which commit is the security patch and generates a detailed report to help developers make quick and accurate decisions. We implemented a prototype system in Python and tested it with Deepseek-R1. The results show that the system achieved a recall of 90.7% and a precision of 100%. These results indicate that LLMs have strong potential in identifying vulnerability patches and are worth further research and development.}
}


@inproceedings{DBLP:conf/ccs/MirditaSW25,
	author = {Donika Mirdita and
                  Haya Schulmann and
                  Michael Waidner},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Poster: Exploring the Landscape of {RPKI} Relying Parties},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4773--4775},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3760721},
	doi = {10.1145/3719027.3760721},
	timestamp = {Fri, 26 Dec 2025 20:53:05 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/MirditaSW25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Resource Public Key Infrastructure (RPKI) is the most successful routing defense mechanism currently deployed throughout critical Internet infrastructures around the world. According to recent works, RPKI deployment boasts over 55% global prefix resource coverage, and at least 27% global protocol enforcement; all this success over a short period of time. In this work, we investigate for the first time deployment trends of the Relying Party (RP), the RPKI component responsible for collecting and enforcing RPKI on routers. We map RP locations, deployment parameters, vulnerability distributions, and describe the evolution of deployment trends over two measurement periods three years apart. Through this exploratory analysis, we map global patterns and the preferred deployment configurations by network operators. We observe how within three years, RP traffic increased by 45%, while 89% of traffic stems from one software type. Our measurements show a strong preference by operators to self-host, coupled with inadequate rates of RP vulnerability mitigation.}
}


@inproceedings{DBLP:conf/ccs/WongHGYLLC25,
	author = {Guo{-}Wei Wong and
                  Yi{-}Ting Huang and
                  Ying{-}Ren Guo and
                  Ming{-}Chuan Yang and
                  Shou{-}De Lin and
                  Wang{-}Chien Lee and
                  Meng Chang Chen},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Poster: When Logs Misbehave: Retrieving Known APTs from Noisy Graphs},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4776--4778},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3760722},
	doi = {10.1145/3719027.3760722},
	timestamp = {Fri, 26 Dec 2025 20:53:05 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/WongHGYLLC25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The task of retrieving known Advanced Persistent Threat (APT) campaigns from system activity graphs, where nodes represent MITRE ATT&CK techniques and edges encode temporal or resource-level relationships, requires reasoning over structures. In operational settings, these target graphs are often noisy due to incomplete detection, technique misclassification, and benign-induced structural artifacts. To address this issue, we formulate the task as approximate subgraph matching between a known APT query graph and a noisy, partially observed technique graph. In this poster, we introduce a preliminary embedding-based retrieval method, aiming to promote it as a robust and practical framework for retrieving known APTs in real-world environments.}
}


@inproceedings{DBLP:conf/ccs/RamuluRRRWFKSA25,
	author = {Harshini Sri Ramulu and
                  Anna Lena Rotthaler and
                  Jost Rossel and
                  Rachel Gonzalez Rodriguez and
                  Dominik Wermke and
                  Sascha Fahl and
                  Tadayoshi Kohno and
                  Juraj Somorovsky and
                  Yasemin Acar},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Poster: Computer Security Researchers' Experiences with Vulnerability
                  Disclosures},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4779--4781},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3760723},
	doi = {10.1145/3719027.3760723},
	timestamp = {Fri, 26 Dec 2025 20:53:05 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/RamuluRRRWFKSA25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Vulnerability disclosures are necessary to improve the security of our digital ecosystem. However, they can also be challenging for researchers: it may be hard to find out who the affected parties even are, or how to contact them. Researchers may be ignored or face adversity when disclosing vulnerabilities. We investigate researchers' experiences with vulnerability disclosures, extract best practices, and make recommendations for researchers, institutions that employ them, industry, and regulators to enable effective vulnerability disclosures.}
}


@inproceedings{DBLP:conf/ccs/HwangKK25,
	author = {Eunbee Hwang and
                  Hyunsoo Kim and
                  Ted Taekyoung Kwon},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Poster: Reconsidering DNS-Based Domain Verification: Privacy and Overhead
                  Implications},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4782--4784},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3760724},
	doi = {10.1145/3719027.3760724},
	timestamp = {Fri, 26 Dec 2025 20:53:05 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/HwangKK25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Domain verification (DV) using DNS TXT records has become an essential mechanism for proving domain ownership across various online services. However, this practice inadvertently discloses sensitive business relations, increases DNS response sizes, and burdens DNS resolver infrastructures. Our measurement of over 2.5 million DNS TXT records highlights the prevalence of bloated TXT records. This work serves as a preliminary problem statement motivating privacy-preserving and efficient DV mechanisms.}
}


@inproceedings{DBLP:conf/ccs/MalaviyaB0L25,
	author = {Shubham Malaviya and
                  Anuj Bagad and
                  Manish Shukla and
                  Sachin Lodha},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Poster: Impulse in the Clickstream: Behavioral Insights from Browsing
                  History},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4785--4787},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3760725},
	doi = {10.1145/3719027.3760725},
	timestamp = {Fri, 26 Dec 2025 20:53:05 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/MalaviyaB0L25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Phishing attacks often exploit user impulsivity, leading to reflexive clicks on malicious links without proper evaluation. While prior research has explored phishing awareness, there remains a gap in understanding impulsive clicking behavior. In this study, we present a novel approach to characterize clicking impulsivity using browser history data. Our session-level analysis reveals that user's impulsive clicking behavior is situational and context dependent. Our findings offer actionable insights for adaptive security interventions based on real-time user behavior.}
}


@inproceedings{DBLP:conf/ccs/LengSZLS25,
	author = {Xue Leng and
                  Kaiwen Shen and
                  Chengxuan Zhu and
                  Xing Li and
                  Jianguo Sun},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Poster: An Obfuscation Framework for Mitigating Topology Probing Attacks
                  in Cloud-Native Systems},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4788--4790},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3760726},
	doi = {10.1145/3719027.3760726},
	timestamp = {Fri, 26 Dec 2025 20:53:05 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/LengSZLS25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In cloud-native systems, microservices communicate with each other through remote calls. This communication side channel contains various information that can be leveraged to carry out topology probing attacks, DDoS attacks, etc. To defend against these attacks, researchers conducted work on critical path analysis and topology obfuscation. However, these works can not be applied to cloud-native scenarios because of limited flexibility and the long calculation time. In this paper, we propose  MeshGuard , a novel obfuscation framework for mitigating topology probing attacks in cloud-native systems. Specifically, we construct a service-level dynamic labyrinth to achieve adaptive topology obfuscation. To avoid leaking traffic patterns when obfuscating topology, we disguise obfuscated traffic with tailored parameters. Finally, we design a tag-based obfuscation mechanism to avoid affecting normal microservices. The preliminary results show that MeshGuard can effectively protect the critical path and services with acceptable resource overhead.}
}


@inproceedings{DBLP:conf/ccs/ZhouGT0X25,
	author = {Junwei Zhou and
                  Yuyang Gao and
                  Cheng Tan and
                  Yanchao Yang and
                  Jianwen Xiang},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Poster: GLog: Self-Evolving Log Anomaly Type Prediction via Instruction-Tuned
                  {LLM} and Clustering},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4791--4793},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3760727},
	doi = {10.1145/3719027.3760727},
	timestamp = {Fri, 26 Dec 2025 20:53:05 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/ZhouGT0X25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Log anomaly detection is critical for maintaining system reliability and observability in complex cloud and microservice environments. However, existing methods often remain limited to binary classification, struggle to adapt to dynamic log patterns, and suffer from semantic loss due to log parsing. To address these challenges, we propose GLog, an end-to-end framework that enables dynamic anomaly type prediction without requiring manual type labels. GLog first fine-tunes instruction-tuned large language models using normal/abnormal labels to achieve high-accuracy anomaly detection on raw, unparsed log sequences. It then clusters the detected anomalies to automatically generate pseudo anomaly type labels and descriptions, which are further used for second-stage fine-tuning, enabling the model to predict specific anomaly types with interpretable outputs. By leveraging full log semantics and dynamically updating its anomaly type repository, GLog reduces manual annotation costs and adapts to evolving system behaviors in large-scale environments.}
}


@inproceedings{DBLP:conf/ccs/ThakurA25,
	author = {Animesh Thakur and
                  Mikael Asplund},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Poster: {PQ} Noise Explorer},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4794--4796},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3760728},
	doi = {10.1145/3719027.3760728},
	timestamp = {Sun, 07 Dec 2025 22:09:44 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/ThakurA25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We present a PQ Noise Explorer, a Rust repository for designing, formally verifying, and implementing arbitrary PQ Noise patterns. PQ Noise Explorer can validate any PQ Noise pattern and translate it into a model for automated verification and also a software implementation written in Rust.}
}


@inproceedings{DBLP:conf/ccs/LengZLTSC25,
	author = {Xue Leng and
                  Fengming Zhu and
                  Xing Li and
                  Ye Tian and
                  Jianguo Sun and
                  Yan Chen},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Poster: Obfuscating Function Activity States to Enhance Privacy in
                  Serverless Applications},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4797--4799},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3760729},
	doi = {10.1145/3719027.3760729},
	timestamp = {Thu, 01 Jan 2026 19:11:53 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/LengZLTSC25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Serverless computing, also known as Function-as-a-Service (FaaS), is widely used in modern applications. Function instances share the underlying physical infrastructure, which makes co-location attacks possible and leads to the leakage of sensitive information such as function activity states. Existing work has respective limitations in serverless scenarios because of incomplete detection coverage, long training time, and intrusion into the function's runtime environment. In this paper, we propose FaaSGuard, an obfuscation framework to protect function activity states in network side-channels and enhance privacy in serverless applications. To be specific, we design an adaptive obfuscation strategy selection mechanism to make FaaSGuard flexible. We design a traffic camouflage method to make obfuscated traffic indistinguishable from normal traffic, making FaaSGuard invisible. In order not to affect normal traffic, we propose a tag-based obfuscation mechanism to identify obfuscated packets. The preliminary evaluation results show that FaaSGuard can conceal function activity states with negligible resource overhead.}
}


@inproceedings{DBLP:conf/ccs/NazKW25,
	author = {Muqaddas Naz and
                  Muhammad Taimoor Khan and
                  Muhammad Waqas},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Poster: Model-driven Privacy Analysis of Messaging Platforms},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4800--4802},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3760730},
	doi = {10.1145/3719027.3760730},
	timestamp = {Fri, 26 Dec 2025 20:53:05 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/NazKW25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Analyzing privacy breaches in Internet-based messaging applications is challenging due to overlapping and sometimes conflicting requirements such as confidentiality, anonymity, unlinkability, and user consent. Existing static analysis techniques typically target isolated aspects of privacy, limiting their scope. In this work, we introduce a static analysis framework based on a composite privacy model that captures the interdependencies among these requirements. This unified model enables the systematic identification of technical privacy violations and their associated legal implications, such as infringements of data protection laws and digital rights. We apply our framework to Ejabberd, a real-time communication server used in messaging platforms like WhatsApp. Our analysis focuses on confidentiality and consent-driven privacy concerns, including the right to be informed and the right to erasure. The results highlight the effectiveness of our approach in bridging technical analysis with legal accountability.}
}


@inproceedings{DBLP:conf/ccs/WeiW25,
	author = {Kai Wei and
                  Guangjing Wang},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Poster: Agentic Shell Honeypot Using Structured Logging},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4803--4805},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3760731},
	doi = {10.1145/3719027.3760731},
	timestamp = {Fri, 26 Dec 2025 20:53:05 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/WeiW25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A shell honeypot emulates a command-line interface to record the behaviors of attackers. Traditional honeypots, however, rely on static, rule-based responses that fail to capture the complexity of real-world multi-turn adversarial interactions. Recent efforts have introduced large language model (LLM) driven honeypots. However, existing LLM-based shell honeypots still fall short of realism due to vulnerabilities such as prompt injection, state inconsistency, and response latency. In this work, we present HoneyAgents, an agent-based honeypot system designed to address the aforementioned limitations. HoneyAgents introduces three key innovations: (i) a role-delegate architecture with strategic and response agents that jointly cope with prompt injection; (ii) a structured logging mechanism that achieves long-term memory for interaction state alignment; (iii) a hierarchical planning design within multi-agent cooperation to generate exploitable shell responses within a dynamic interaction time. The evaluation shows that HoneyAgents improves robustness, realism, and efficiency, making LLM-powered honeypots more viable for real-world security operations.}
}


@inproceedings{DBLP:conf/ccs/ShibaI25,
	author = {Rentaro Shiba and
                  Tetsu Iwata},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Poster: An Improved Quantum Attack on the Two-round Even-Mansour Cipher
                  with Independent Permutations and Keys},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4806--4808},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3760732},
	doi = {10.1145/3719027.3760732},
	timestamp = {Fri, 26 Dec 2025 20:53:05 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/ShibaI25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this study, we propose a quantum attack on the two-round iterated Even-Mansour cipher, which consists of two independent permutations and three independent subkeys. Our attack is in the Q1 model, where an adversary makes classical online queries and quantum offline queries. The complexity of our attack is  O (2 n /2 ), where  n  is the block size, while the best known attack for this variant is  O (2 3 n /5 ). Thus, our method significantly improves the computational complexity compared to existing quantum attacks.}
}


@inproceedings{DBLP:conf/ccs/Chalkias25,
	author = {Kostas Kryptos Chalkias},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Poster: Post-Quantum Readiness in EdDSA Chains},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4809--4811},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3760734},
	doi = {10.1145/3719027.3760734},
	timestamp = {Sun, 07 Dec 2025 22:09:40 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/Chalkias25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The impending threat posed by large-scale quantum computers necessitates a reevaluation of signature schemes deployed in blockchain protocols. In particular, blockchains relying on ECDSA, such as Bitcoin and Ethereum, exhibit inherent vulnerabilities due to on-chain public key exposure and the lack of post-quantum security guarantees. While several post-quantum transition proposals have been introduced, including hybrid constructions and zero-knowledge based key migration protocols, these approaches often fail to protect inactive (sleeping) accounts or require address changes, violating core immutability and usability assumptions. In this work, we observe that blockchains employing EdDSA with RFC 8032-compliant key derivation (e.g., Sui, Solana, Near) possess an underexplored structural advantage. Specifically, EdDSA's hash-based deterministic secret generation enables zero-knowledge proofs of private key ownership without revealing the corresponding public key. We demonstrate how Post-Quantum NIZKs can be constructed to prove knowledge of the seed used in EdDSA key derivation, enabling post-quantum-secure transaction authorization without altering addresses or disclosing elliptic curve data. By post-quantum readiness, we mean that with a single user action all future signatures can be made post-quantum secure, even if past transactions used classical elliptic curve cryptography. This allows even users who have previously exposed their public key to seamlessly enter the post-quantum era without transferring assets or changing their account address. This mechanism affords a quantum-resilient path that preserves backward compatibility, supports account abstraction, and critically secures dormant accounts that would otherwise be compromised under quantum adversaries.}
}


@inproceedings{DBLP:conf/ccs/Ishizuka25,
	author = {Keita Ishizuka},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Poster: Reducing Hull Dimensions for Efficient Permutation Recovery
                  in Code-Based Cryptography},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4812--4814},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3760735},
	doi = {10.1145/3719027.3760735},
	timestamp = {Sun, 07 Dec 2025 22:09:42 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/Ishizuka25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The permutation equivalence problem (PEP) for linear codes is fundamental to both coding theory and modern cryptography. The support splitting algorithm (SSA) is the most effective practical approach, with efficiency critically dependent on hull dimensions. SSA requires hulls that remain invariant under coordinate permutations, but can use alternative inner products to potentially reduce hull dimensions. We provide a complete characterization: permutation-invariant hulls correspond precisely to bilinear forms with structure matrices of the form  aI + bJ . We prove that these alternative hulls can reduce dimensions by at most one, and establish conditions for when reduction occurs. While this bound limits the impact on cryptographic security, the improvement translates to a factor  q  speedup in enumeration complexity -- significant for code classification and cryptanalysis refinement. Our results apply to schemes like LESS and SPECK, where accurate complexity assessment is crucial for parameter selection.}
}


@inproceedings{DBLP:conf/ccs/WongTHGJWC25,
	author = {Kai{-}Xian Wong and
                  Chan{-}Jien Tan and
                  Yi{-}Ting Huang and
                  Ying{-}Ren Guo and
                  Yu{-}Zih Jheng and
                  Guo{-}Wei Wong and
                  Meng Chang Chen},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Poster: LogCraft: Crafting CVE-Aware Synthetic Worlds (Logs)},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4815--4817},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3760736},
	doi = {10.1145/3719027.3760736},
	timestamp = {Fri, 26 Dec 2025 20:53:05 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/WongTHGJWC25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The generation of realistic, labeled audit logs is critical for evaluating the effectiveness of cybersecurity detection systems, yet existing datasets often lack diversity, scalability, and support for real-world vulnerabilities. While SAGA provides a solid foundation by addressing many of these challenges, this work further extends its capabilities in two key directions. First, we expand the coverage of attack behaviors by simulating additional lateral movement techniques and introducing a semi-automated process for generating labeled log templates. Second, we enable CVE-based log synthesis by incorporating vulnerability information into the attack modeling process. These enhancements improve the fidelity, automation, and extensibility of synthetic log generation, supporting more effective training and evaluation of threat detection models.}
}


@inproceedings{DBLP:conf/ccs/WuCW25,
	author = {Min{-}Chieh Wu and
                  Jui{-}An Chang and
                  Yu{-}Sung Wu},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Poster: High-Fidelity and Contextual User Activity Memory Forensics},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4818--4820},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3760737},
	doi = {10.1145/3719027.3760737},
	timestamp = {Fri, 26 Dec 2025 20:53:05 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/WuCW25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Retrieving application user activities from a memory dump has traditionally been a labor-intensive process, due to both the sheer volume of memory data and the complexity of opaque data structures. We introduce RAM-Weaver, a system that enables contextual querying of user activities from application memory dump files. RAM-Weaver distills essential information from raw dumps and leverages large language models (LLMs) to navigate opaque data structures and support interactive queries. This distillation process can reduce the data volume by up to 99.9% and improve the signal-to-noise ratio by nearly 37 dB, making it feasible to run on smaller, offline models. When combined with full-scale, cloud-hosted models, RAM-Weaver can retrieve user activity data with exceptionally high accuracy.}
}


@inproceedings{DBLP:conf/ccs/0002ZWXTY25,
	author = {Junwei Zhou and
                  Ying Zhu and
                  Linhao Wang and
                  Jianwen Xiang and
                  Cheng Tan and
                  Yanchao Yang},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Poster: LogCADA: Cross-System Log Anomaly Detection based on Two-Stage
                  Multi-Source Domain Adaptation},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4821--4823},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3760738},
	doi = {10.1145/3719027.3760738},
	timestamp = {Fri, 26 Dec 2025 20:53:05 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/0002ZWXTY25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Deep learning-based log anomaly detection demands extensive labeled data, posing significant challenges for emerging systems with limited logs. Transfer learning mitigates this issue by leveraging knowledge from data-rich source domains, enabling effective adaptation to data-scarce target domains. The challenge in recent cross-domain research lies in the joint optimization of knowledge transfer efficacy and model generalization capability. To address these limitations, we propose LogCADA, a novel logarithmic anomaly detection framework based on transfer learning, which can obtain effective common features through double-layer adversarial training, and distinguish common features and unique features between different domains through multi-source domain contrast alignment to achieve better knowledge transfer.The results demonstrate that our method can be adapted from dual source to single target domain and effectively overcome the inherent limitations of traditional cross-domain anomaly detection methods, yielding significant practical value for real-world log analysis scenarios.}
}


@inproceedings{DBLP:conf/ccs/CeliPENP25,
	author = {Sof{\'{\i}}a Celi and
                  Rafa{\"{e}}l del Pino and
                  Thomas Espitau and
                  Guilhem Niot and
                  Thomas Prest},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Poster: Efficient Threshold {ML-DSA} up to 6 Parties},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4824--4826},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3760739},
	doi = {10.1145/3719027.3760739},
	timestamp = {Mon, 24 Nov 2025 15:33:09 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/CeliPENP25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Threshold signature schemes enable a group of users to collaboratively produce digital signatures without revealing any individual share. With the current NIST post-quantum standardization underway, the lack of efficient and practical threshold variants of standardized schemes hinders adoption. We introduce the first threshold signature scheme compatible with the ML-DSA standard (Module-Lattice-based Digital Signature Algorithm), supporting up to 6 parties, while retaining efficient signing. Our work uses advanced short secret sharing techniques and optimized rejection sampling to balance communication and correctness in distributed settings. We implement our construction in Go and benchmark it in local, LAN, and WAN deployments. Results show that our threshold ML-DSA is both practical and compatible with real-world applications such as multi-device cryptocurrency wallets, threshold TLS, and Tor's directory authorities.}
}


@inproceedings{DBLP:conf/ccs/ChoK25,
	author = {Yena Cho and
                  Hyoungshick Kim},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Poster: Scalable Privacy-Preserving Linear Regression Training via
                  Homomorphic Encryption},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4827--4829},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3760740},
	doi = {10.1145/3719027.3760740},
	timestamp = {Sun, 07 Dec 2025 22:09:41 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/ChoK25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Linear regression is a fundamental model in data analysis, but training it over encrypted data remains expensive due to the overhead of homomorphic encryption (HE). We present PP-LR, an end-to-end CKKS-based training protocol for linear regression that supports encrypted gradient descent with feature-level parallelism and conditional bootstrapping. Compared to a standard HE implementation, it trains up to 15.7 times faster while maintaining accuracy within 0.2% of plaintext models on four real-world datasets.}
}


@inproceedings{DBLP:conf/ccs/StirewaltG25,
	author = {Tashi Stirewalt and
                  Assefaw Hadish Gebremedhin},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Poster: Adversarial Habituation Attack: {A} Psychological Extension
                  and Re-framing of Boiling Frog Attack},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4830--4832},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3760741},
	doi = {10.1145/3719027.3760741},
	timestamp = {Thu, 25 Dec 2025 12:46:54 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/StirewaltG25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As machine learning models play an increasingly vital role in threat detection systems, they are facing greater risks from sophisticated adversarial machine learning (AML) attacks. Intrusion detection systems (IDS) that depend on anomaly detection can be misled by attacks that gradually evolve. These include attacks metaphorically referred to as ''boiling frog'' attacks, where an attacker subtly modifies the model's behavior through incremental changes designed to normalize anomalous patterns. This short paper introduces the Adversarial Habituation Attack (AHA), a psychological reframing and expansion of the ''boiling frog'' concept. AHA draws on well-established concepts in psychological research, including Habituation (diminished response), Sensitization (heightened response), Creeping Normality, and Alert Fatigue (the ''cry wolf'' effect). By establishing a common terminology and framework, AHA links cognitive habituation with AML. We demonstrate an AHA attack in a virtual network of Ubuntu machines protected by a centralized Variational Autoencoder (VAE)-based Suricata Network IDS. Our findings suggest that leveraging psychological insights—for example, by introducing variability to counteract habituation—can enhance understanding of the elements of AHA and inspire the development of more robust defenses in security domains that deal with concept drift-related vulnerabilities.}
}


@inproceedings{DBLP:conf/ccs/LiQADCZ25,
	author = {Lin Li and
                  Youyang Qu and
                  Jiayang Ao and
                  Ming Ding and
                  Chao Chen and
                  Jun Zhang},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Poster: The Art of Deception: Crafting Chimera Images for Covert and
                  Robust Semantic Poisoning Attacks},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4833--4835},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3760742},
	doi = {10.1145/3719027.3760742},
	timestamp = {Fri, 26 Dec 2025 20:53:05 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/LiQADCZ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the exponential surge in media data volumes and their growing intrinsic value, the landscape has become increasingly susceptible to persistent and strategically designed data poisoning attacks targeting these valuable assets. In this work, we propose a novel approach leveraging generative AI techniques to craft covert and robust poisonous data samples, referred to as  Chimera  Images. These images seamlessly blend visual features from two target classes to generate hybrid objects that preserve appearance fidelity. These ''normal'' samples with correct labels can subtly distort the model's decision boundary without raising suspicion. Extensive experimental results on CIFAR-10 and Flowers datasets demonstrate that the proposed method i) reduces the accuracy of the targeted class, ii) maintains the performance of other classes, and iii) exhibits immunity to state-of-the-art defence strategies. We also explore the usage of generative AI content detection as a defence mechanism, demonstrating that the recently discovered snapshot technique is ineffective against the AI-generated poisonous  Chimera  samples.}
}


@inproceedings{DBLP:conf/ccs/SteeleAM25,
	author = {Lucy Steele and
                  Fahad Alotaibi and
                  Sergio Maffeis},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Poster: Randomness Unmasked: Towards Reproducible and Fair Evaluation
                  of Shift-Aware Deep Learning {NIDS}},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4836--4838},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3760743},
	doi = {10.1145/3719027.3760743},
	timestamp = {Sun, 07 Dec 2025 22:09:44 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/SteeleAM25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Deep learning techniques are increasingly being incorporated into NIDS. However, the evaluation of such deep learning models often assumes static data distributions and overlooks the effects of randomness and environmental variation. As a result, the reported performance may not reflect the NIDS behaviour during real-world deployment. This paper investigates the impact of stochastic and environmental factors on the evaluation of deep learning models for NIDS, with a focus on shift-aware models that detect and adapt to data shift, representing state-of-the-art systems for long-term deployment. We examine two baselines under controlled variations to analyse the impact of each factor on the reproducibility and fairness of the results, revealing that the F 1  score can vary largely due to these, even minor, variations. All of the explored factors affect the reproducibility of the results, and some can significantly skew performance. Based on our findings, we provide practical recommendations to support reproducible and fair evaluations of deep learning-based NIDS systems.}
}


@inproceedings{DBLP:conf/ccs/Jin025,
	author = {Gyujeong Jin and
                  Seyoung Lee},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Poster: Inferring On-Screen Keyboard Input via Gamepad-based Mouse
                  Movement Traces},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4839--4841},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3760744},
	doi = {10.1145/3719027.3760744},
	timestamp = {Fri, 26 Dec 2025 20:53:05 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/Jin025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {On-screen keyboards operated via directional input devices—such as remote controls, D-pads, or game controllers—are widely used in smart TVs, kiosks, and accessibility-focused systems. Although these systems appear secure due to limited interaction bandwidth and the absence of direct screen access, we demonstrate that the sequence of directional movements and confirmation clicks can be exploited to infer sensitive input such as passwords. We propose a novel side-channel attack that reconstructs cursor trajectories from direction-click logs, simulates all possible starting positions, and ranks candidate passwords based on geometric and semantic scoring. Our evaluation over 1000 randomly generated passwords shows that the correct password appears in the top-5 candidates in 100% of cases and ranks first in 85.8% of them. We also investigate practical mitigation techniques—such as temporal jitter and randomized directional noise—and demonstrate that these defenses reduce the attack success rate to 18.2%. This study highlights a previously underexplored threat surface in GUI-based systems using directional input and calls for renewed attention to input privacy in constrained environments.}
}


@inproceedings{DBLP:conf/ccs/TianQDLTZ25,
	author = {Yicun Tian and
                  Youyang Qu and
                  Ming Ding and
                  Shigang Liu and
                  Pei{-}Wei Tsai and
                  Jun Zhang},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Poster: Decoding Social Engineering: {A} Multi-Level Framework for
                  Tactic Generation, Annotation, and Evaluation},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4842--4844},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3760745},
	doi = {10.1145/3719027.3760745},
	timestamp = {Fri, 26 Dec 2025 20:53:05 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/TianQDLTZ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Phishing emails increasingly embed complex social engineering (SE) tactics to manipulate recipients and increase success rates. However, existing organizational training simulations and detection systems seldom incorporate tactic complexity or reveal how such tactics are linguistically embedded. To address this, we develop methods for generating, annotating, and evaluating SE tactics across three complexity levels in phishing emails. A reliably annotated dataset is constructed via a generate–cross-verify–highlight pipeline, which ensures semantic alignment between labels and embedded SE tactics. These trigger segments are subsequently clustered and synthesized into fine-grained patterns that characterize how each SE tactic manifests at Level 1 (easily), Level 2 (moderately), and Level 3 (deeply). These patterns underpin a multi-level SE framework, validated through LLM-based detection experiments. Detection accuracy declines with increasing tactic complexity, confirming the framework's stratification capability and its utility in training, simulation, and tactic-aware detection design.}
}


@inproceedings{DBLP:conf/ccs/Roy25,
	author = {Rupshali Roy},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Addressing Vulnerabilities and Opacities in Quantum Service Providers},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4845--4847},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765564},
	doi = {10.1145/3719027.3765564},
	timestamp = {Fri, 26 Dec 2025 20:53:05 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/Roy25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {There is a steady growth in research and demand for real quan- tum hardware in the Noisy Intermediate-Scale Quantum (NISQ) era of quantum computing. This prompts many third-party cloud providers to set up quantum hardware as a service that includes a wide range of qubit technologies and architectures to maximize performance at minimal cost. Quantum circuits submitted to these services are the fruits of the efforts invested by the designers. But these third-party cloud compilers (who offer more efficient alter- natives to established compilers) can make user circuits/programs vulnerable to various security breaches. Communication channels for transmitting quantum information also need to be developed such that there is end to end encryption. There is little to no visibil- ity on where the execution of the circuit is actually taking place. The success of the user program is highly reliant on the backend that was used for execution. Besides, the third-party provider and/or tools (e.g., hardware mapper and allocator) may be untrustworthy and execute the quantum circuits on less efficient and more error- prone hardware to conserve resources and maximize profit. These vulnerabilities in the quantum system could leak confidential data, cause loss of intellectual property rights of designers, cause loss of access control, corrupt user programs et cetera. Thus, it is imper- ative to identify these security vulnerabilities and create defense strategies to protect quantum programs, thus helping to maintain the integrity of quantum information across the software stack. My thesis aims to help address these vulnerabilities and opacities and address them.}
}


@inproceedings{DBLP:conf/ccs/Santra25,
	author = {Monika Santra},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {AI-Augmented Static Analysis: Bridging Heuristics and Completeness
                  for Practical Reverse Engineering},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4848--4850},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765565},
	doi = {10.1145/3719027.3765565},
	timestamp = {Sun, 07 Dec 2025 22:09:44 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/Santra25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Reverse engineering poses significant challenges for several reasons, including the presence of interleaved code and data, the absence of names, types, and stack frames, aggressive compiler optimizations, and a range of obfuscation techniques. Traditional static analysis methods and existing tools have sought to mitigate the impact of these missing critical elements through various heuristic-based strategies. However, recent advancements in artificial intelligence (AI) have shown promise in tackling these challenges by uncovering complex hidden patterns from incomplete or low-level representations, particularly in predicting high-level semantic constructs that may be lost during compilation. Despite these advancements, AI-only solutions frequently struggle to deliver the completeness and reliability necessary for security-critical binary analysis. To address this shortcoming, we aim to establish an innovative synergy between AI and static analysis—leveraging AI to replace brittle heuristics for enhanced generalization while using static analysis to reinforce AI with a best-effort approach to completeness, thereby meeting the rigorous demands of security applications. In this thesis, we will concentrate on three essential tasks in reverse engineering that are notably underserved in both academic research and existing tools: instruction boundary identification, function boundary identification, and Control Flow Graph (CFG) construction, more specifically for indirect call targets. Our goal is to develop a novel integration of AI and static analysis, creating an end-to-end disassembly framework.}
}


@inproceedings{DBLP:conf/ccs/Lu25,
	author = {Hongyi Lu},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Hardware-assisted Memory Isolation},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4851--4853},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765566},
	doi = {10.1145/3719027.3765566},
	timestamp = {Sun, 07 Dec 2025 22:09:43 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/Lu25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Modern computing systems increasingly rely on hardware-assisted memory isolation to secure critical data and execution contexts without the overhead of purely software-based mechanisms. While features like Intel MPK, Arm POE, and RISC-V PMP offer promising support, they often suffer from a limited number of available isolation domains and primarily focus on CPU memory, leaving interactions with peripheral devices unprotected. In this dissertation, we partially address these challenges by presenting  Moat,  a lightweight hardware-assisted isolation framework that combines MPK with the existing MMU to achieve effectively unlimited isolation domains, demonstrated in securing eBPF programs with minimal overhead. Beyond proposing new solutions, we also uncover a critical vulnerability in current GPU trusted execution environments (TEEs) through  Mole,  an attack that exploits under-documented microcontroller units inside GPUs to bypass the isolation of GPU TEEs and access protected memory. Our research aims to develop new hardware primitives that are flexible, lightweight and able to deliver protection across CPUs and peripherals to meet the demands of secure, large-scale systems.}
}


@inproceedings{DBLP:conf/ccs/Erlacher25,
	author = {Leonardo Erlacher},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {{S2S-SED:} {A} Speech-to-Speech Approach for Detection of Social Engineering
                  Attacks in Audio Conversations},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4854--4856},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765567},
	doi = {10.1145/3719027.3765567},
	timestamp = {Sun, 07 Dec 2025 22:09:41 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/Erlacher25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Voice-based social engineering attacks are becoming increasingly sophisticated, driven by advances in generative speech synthesis, neural voice cloning, and psychologically adaptive manipulation strategies. While large language models (LLMs) have demonstrated substantial capabilities in textual deception detection, their reliance on transcribed input omits essential prosodic and interactional cues -- such as stress, urgency, or conversational dynamics—that are critical for identifying manipulative intent in spoken interactions. This constitutes a fundamental limitation in current LLM-based approaches to voice fraud detection. This doctoral research aims to investigate and develop S2S-SED, a novel speech-to-speech framework for the detection of social engineering attacks in audio conversations. Unlike transcription-dependent pipelines, the envisioned architecture processes raw audio input directly by encoding continuous speech into latent representations that implicitly preserve prosodic patterns, emotional tone, and semantic content. These embeddings are fed into a unified inference model capable of assessing conversational dynamics—such as stress, urgency, and turntaking -- without relying on intermediate text or auxiliary subsystems. Building upon recent advancements in audio language mod- eling, the project envisions the construction of a domain-specific, annotated Dataset of voice-based social engineering scenarios. This dataset will serve as the foundation for training and evaluating an audio-native LLM tailored to deception detection. The research addresses a critical gap at the intersection of speech processing, AI-driven security, and human-machine communication, and aims to lay the groundwork for next-generation methods in voice threat mitigation.}
}


@inproceedings{DBLP:conf/ccs/Gegenhuber25,
	author = {Gabriel K. Gegenhuber},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Security and Privacy Measurements in Cellular Networks: Novel Approaches
                  in a Global Roaming Context},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4857--4859},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765568},
	doi = {10.1145/3719027.3765568},
	timestamp = {Sun, 07 Dec 2025 22:09:41 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/Gegenhuber25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cellular networks serve as the backbone of global communication, providing critical access to telephony and the Internet, often in regions lacking alternatives. However, the growing complexity of these networks, driven by architectural innovations (e.g., Voice over IP, eSIMs) and commercial dynamics (e.g., roaming, virtual operators, zero-rating) remains poorly understood due to the lack of open, scalable, and geographically diverse measurement tools. Moreover, access to mobile networks today is no longer limited to the traditional radio interface. Technologies like Voice-over-WiFi (VoWiFi) offer alternative connectivity paths via third-party Internet infrastructure, extending operator reach into environments with limited cellular coverage. Similarly, over-the-top (OTT) messaging services such as WhatsApp and Signal have become central to modern communication, accounting for a substantial share of global messaging and voice traffic while bypassing traditional operator-controlled channels entirely. In this work, we evaluate existing methods for large-scale cellular network measurements and introduce novel techniques to tackle the growing challenges of transparency, scalability, and diversity across networks and geographies. By open-sourcing our measurement tools, we aim to lower the entry barrier for independent research and foster a more inclusive and democratized ecosystem for investigating cellular network behavior and global communication.}
}


@inproceedings{DBLP:conf/ccs/Loop25,
	author = {Jennifer Vander Loop},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Postmortem Voice Cloning: Individuals Perspectives of Ownership and
                  Deceptive Harms},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4860--4862},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765569},
	doi = {10.1145/3719027.3765569},
	timestamp = {Sun, 07 Dec 2025 22:09:43 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/Loop25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {increasingly realistic, making it possible to replicate a person's voice with just a few seconds of audio. Cloned voices are already being used in impersonation scams, including family emergency schemes where callers use cloned voices to pose as relatives in distress to solicit money. Postmortem voice cloning introduces new opportunities for misuse, allowing bad actors to impersonate deceased individuals or emotionally manipulate surviving family members. My dissertation research examines the risks that individuals associate with voice cloning. Using a mixed-methods approach that incorporates surveys and participant interviews, I will also explore assumptions about voice privacy and expectations regarding regulation and prevention of unauthorized use. I will use thematic analysis that is guided by an established voice cloning harm taxonomy. The goal of my research is to understand the perspectives of individuals to inform safeguards, legal protections, and platform responsibilities surrounding the unauthorized use of a person's voice after their death.}
}


@inproceedings{DBLP:conf/ccs/Frick25,
	author = {Raphael Antonius Frick},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Towards Explainable and Robust Deepfake Detection and Attribution:
                  Enhancing Multimedia Forensics for the Next Generation of Synthetic
                  Media},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4863--4865},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765570},
	doi = {10.1145/3719027.3765570},
	timestamp = {Fri, 26 Dec 2025 20:53:05 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/Frick25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The rise of generative AI has enabled the creation of synthetic audio, images, and videos that are virtually indistinguishable from authentic media, presenting new threats to digital trust, privacy, and security. While deepfake detection has advanced, most solutions focus on binary classification performed by data-driven approaches, which are insufficient for attribution and explainability required in high-stakes scenarios. This dissertation aims to develop robust, generalizable, and explainable forensic frameworks that (1) not only detect AI-generated media but also attribute attacks to specific models or methods, (2) provide interpretable evidence for forensic and legal contexts, and (3) are resilient to adversarial manipulations. Our approach integrates data-driven and model-based techniques, leverages external data, and builds on extensive prior work in multimedia forensics. In this paper, we present key challenges, objectives and early findings that support the advancement of trustworthy AI and strengthen digital media security.}
}


@inproceedings{DBLP:conf/ccs/Tan25,
	author = {Gefei Tan},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Scalable Cryptography for Trustworthy Machine Learning in the {LLM}
                  Era},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4866--4868},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765571},
	doi = {10.1145/3719027.3765571},
	timestamp = {Fri, 26 Dec 2025 20:53:05 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/Tan25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Modern cryptographic tools such as multi-party computation (MPC) and zero-knowledge proofs (ZKPs) offer strong, provable security guarantees—but these generic protocols remain impractical for production-scale machine learning (ML), especially in the era of large language models (LLMs). This thesis proposal advances the central claim that cryptographic protocols co-designed with the structure of specific ML subtasks can achieve practical efficiency without compromising privacy or verifiability. To validate this vision, this proposal develops three interconnected research thrusts: (1)  Confidential Outsourced Training.  Customized MPC protocols shift expensive cryptographic steps to local computations, enabling secure training of large models in untrusted clouds by resource-constrained data owners. (2)  Scalable MPC Primitives for Large Datasets.  Provably secure building blocks—such as oblivious shuffles, private joins, and sparse linear algebra routines—bridge the performance gap in privacy-preserving data pipelines at scale. (3)  Verifiable ML without Retraining.  Rather than proving each training step, a new proof-of-optimality framework certifies that a trained or fine-tuned model (e.g., LoRA adapters) satisfies desired properties, enabling efficient, auditable deployment without re-executing training. Together, these efforts aim to close the long-standing gap between privacy and efficiency, demonstrating that strong cryptographic guarantees and modern ML workflows can be reconciled through principled, application-aware design.}
}


@inproceedings{DBLP:conf/ccs/Xu25,
	author = {Jie Xu},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Turning Uncertainty into Efficiency: Toward Practical, Quantum-Resistant
                  Verifiable Privacy Tools},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4869--4871},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765572},
	doi = {10.1145/3719027.3765572},
	timestamp = {Fri, 26 Dec 2025 20:53:05 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/Xu25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Verifiable Random Functions (VRFs) and Oblivious Pseudorandom Functions (OPRFs) are essential cryptographic primitives in privacy-preserving applications such as anonymous authentication, private set intersection (PSI), and decentralized identity. Existing constructions, however, rely on number-theoretic assumptions that are vulnerable to quantum attacks. This PhD research project focuses on constructing efficient and practical VRFs and OPRFs from lattice-based assumptions to ensure post-quantum security. A key obstacle in these constructions is the overhead of zero-knowledge proofs (ZKPs), particularly range proofs, which are costly in terms of size and prover complexity. To address this, we investigate probabilistic techniques that relax exact correctness. In particular, we explore approximate range proofs and algebraic transformations, such as using automorphisms in polynomial rings to simulate inner product arguments via polynomial multiplication. These methods enable more efficient and scalable lattice-based constructions of VRFs, including group and context-bound variants, as well as OPRFs. The goal is to make these primitives practical for deployment in post-quantum privacy-preserving systems.}
}


@inproceedings{DBLP:conf/ccs/Olszewski25,
	author = {Daniel Olszewski},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {On Defining Reproducible Outcomes for the Computer Security Community},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4872--4874},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765573},
	doi = {10.1145/3719027.3765573},
	timestamp = {Fri, 26 Dec 2025 20:53:06 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/Olszewski25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Reproducibility is crucial to the advancement of science; it strengthens confidence in seemingly contradictory results and expands the boundaries of known discoveries. Computer Security has the natural benefit of creating artifacts that should facilitate computational reproducibility, the ability for others to use someone else's code and data to independently recreate results, in a relatively straightforward fashion. While the Security community has recently increased its attention on reproducibility, whether the current approach to increasing reproducible research is effective remains an open question. In this dissertation, we measure the impact of current approaches to reproducible research, construct frameworks and tools to increase reproducible outcomes, and analyze the approach we have taken. The goal of this dissertation is to provide tools for security researchers that simplify and increase the reproducibility of research.}
}


@inproceedings{DBLP:conf/ccs/Fu25,
	author = {Qishuang Fu},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Towards Explainable and Effective Anti-Money Laundering for Cryptocurrency},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4875--4877},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765574},
	doi = {10.1145/3719027.3765574},
	timestamp = {Fri, 26 Dec 2025 20:53:06 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/Fu25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cryptocurrency money laundering poses a serious threat to the security and compliance of decentralized financial systems. While various detection methods have been proposed, existing approaches either lack explainability or struggle to effectively handle privacy coins. This dissertation proposes two research directions aimed at enhancing the explainability and effectiveness of anti-money laundering (AML) techniques. The first direction proposes an explainable AML framework for non-privacy coins by incorporating transaction semantic parsing and large language model-based classification. The second direction explores a novel method for tracking illicit fund flows involving privacy coins such as Monero, focusing on improving de-anonymization accuracy and identifying cross-chain laundering paths. Preliminary results on the first direction demonstrate the feasibility of a semantic-aware module and the potential of a fine-tuned large language model in detecting complex laundering behaviors.}
}


@inproceedings{DBLP:conf/ccs/Kundu25,
	author = {Suparna Kundu},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Towards Solving Real-world Problems of Post-quantum Cryptography},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4878--4880},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765575},
	doi = {10.1145/3719027.3765575},
	timestamp = {Sun, 07 Dec 2025 22:09:42 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/Kundu25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Public-key cryptography is indispensable in maintaining the security and integrity of digital data. The most widely used current public-key cryptography is based on the integer factorization problem and the elliptic-curve discrete logarithm problem, which are vulnerable against an adversary with large-scale quantum computers. Fortunately, post-quantum cryptography (PQC) can provide security against both classical and quantum adversaries. Due to rapid advancement in quantum computer development, the transition from classical public-key cryptography to PQC has become imperative. A watershed moment in this transition is the recent publication of a set of PQC schemes by the National Institute of Standards and Technology (NIST). Although it is a significant step, the research and development in PQC is quite immature compared to several decades-old classical public-key cryptographic schemes. Therefore, several open problems, such as physical attack analysis and their countermeasures, application-specific modifications, lightweight implementations for resource-constrained devices, integration into different secure protocols, etc., need to be addressed before the widespread deployment of PQC in real-world applications. This dissertation aims to address some of these problems in order to bridge the gap between the theory and practice of PQC.}
}


@inproceedings{DBLP:conf/ccs/Gehrke25,
	author = {Lukas Gehrke},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Dissertation Research Description: The Potential of SBOMs to Increase
                  Software Supply Chain Security},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4881--4883},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765576},
	doi = {10.1145/3719027.3765576},
	timestamp = {Fri, 26 Dec 2025 20:53:06 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/Gehrke25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Software supply chain security is an essential area of cybersecurity, as shown by attacks such as the XZ Utils incident in 2024. Software Bills of Materials (SBOMs) were introduced to keep track of the supply chain of a software artifact. They have been brought to widespread attention in 2021 through US Executive Order 14028. The EU will make SBOMs mandatory by 2027 with their Cyber Resilience Act from 2024. In contrast to these demands for SBOMs through legislation, practitioners struggle to make real use of them. Multiple recent studies have concluded that adoption of SBOMs and their integration into security processes are facing various challenges. At the same time, accuracy and correctness problems of SBOMs generated by wide-spread tools have been shown. Based on this situation, the dissertation research is dedicated to the research question: What benefit do SBOMs provide and what further benefit can they potentially provide for supply chain security?  In order to answer, this research description introduces four intended contributions: (1) First, all knowledge about the history of SBOMs and related concepts in Computer Science is systematized. (2) Second, an  SBOM usage model  that provides an abstract view on the software supply chain as well as actors involved in it is developed. The goal of the model is to give a theoretical foundation for making practical use of SBOMs. (3) Third, with  BOM2VULN  an analysis of current tools that map vulnerabilities to SBOMs is conducted, potentially including the introduction of a new tool for this task. The goal is to provide security engineers with a means of quickly finding vulnerabilities and assessing their relevance. (4) Lastly, the  SBOM Nutri Score  is proposed including an evaluation. The score helps practitioners to evaluate the software supply chain risk of third party code they use or intend to use.}
}


@inproceedings{DBLP:conf/ccs/Ghosh25,
	author = {Tanusree Ghosh},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {Exploring the Janus Face of Synthetic Images: From Privacy-secure
                  Biometrics Applications to Deepfake Detection for Misinformation-Free
                  Social Networks},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4884--4886},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3765577},
	doi = {10.1145/3719027.3765577},
	timestamp = {Sun, 07 Dec 2025 22:09:41 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/Ghosh25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The rise of generative AI presents a profound duality, or a ''Janus Face,'' for digital society. On one hand, its ability to synthesize hyper-realistic faces offers a powerful solution to long-standing privacy and data scarcity challenges in biometric systems---a promising but underexplored application. On the other hand, this same technology is weaponized to create 'deepfakes' that fuel misinformation campaigns on Online Social Networks (OSNs), posing a significant threat to digital integrity. However, countering this threat is hampered by critical failures in existing deepfake detectors. They are often: (i)  Brittle in the Wild:  They prove vulnerable to the compression and post-processing artifacts introduced by OSNs. (ii)  Poorly Generalizable:  They fail to detect forgeries from new or unseen generative models. (iii)  Computationally Inefficient:  Many state-of-the-art models are too parameter-heavy for practical deployment on resource-constrained devices. This dissertation confronts this duality by addressing both sides of the coin. First, it examines the ''substitutability'' of synthetic face data, demonstrating that biometric classifiers (e.g., Age, Gender etc.) trained on AI-generated faces can match or even exceed the generalization performance of those trained on real face data. Second, to counter the malicious use of this technology, this dissertation develops a framework of deepfake detectors designed to be robust, generalizable, and efficient by construction. My work introduces novel, lightweight feature sets on different cues (e.g., colour cue-based Relative Chrominance Difference, Gradient features, Depth cues etc.) that are inherently resilient to OSN transformations and improve generalization to unseen forgeries. Preliminary results confirm state-of-the-art performance, achieving high accuracy in challenging real-world scenarios with a significant reduction in model complexity.}
}


@inproceedings{DBLP:conf/ccs/DurakLS25,
	author = {F. Bet{\"{u}}l Durak and
                  Fengjun Li and
                  Sophie Stephenson},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {{ACM} {CCS} Young Scholars Development Program},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4887--4888},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3767675},
	doi = {10.1145/3719027.3767675},
	timestamp = {Fri, 26 Dec 2025 20:53:06 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/DurakLS25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this short document, we introduce The ACM CCS Young Scholars Development Program (YSDP); a new initiative aiming at supporting early-career researchers within the computer security community. YSDP is created and organized by dedicated chairs. The program promotes collaboration, communication, and professional growth through structured events such as talks, panels, and breakout technical discussions sessions. It emphasizes skill-building and networking, with a focus on integrating young scholars into the broader academic ecosystem. In this report, we detail the planning, selection, and execution of the program, and highlight its role in shaping a stronger research environment.}
}


@inproceedings{DBLP:conf/ccs/PintorJ025,
	author = {Maura Pintor and
                  Matthew Jagielski and
                  Ruoxi Jia},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {AISec '25: 18th {ACM} Workshop on Artificial Intelligence and Security},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4889--4891},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3767658},
	doi = {10.1145/3719027.3767658},
	timestamp = {Fri, 26 Dec 2025 20:53:06 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/PintorJ025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The use of Artificial Intelligence (AI) and Machine Learning (ML) has been the center of the most outstanding advancements in the last years. The ability to analyze considerable streams of data in real time makes these technologies the most promising tool in many domains, including cybersecurity. As an outstanding example, ML can be used for identifying malware because of its ability to detect patterns otherwise difficult to see for humans and hardcoded rules. However, the use of AI and ML in security-relevant domains raised rightful concerns about their trustworthiness and robustness, especially when facing adaptive attackers. Additionally, privacy threats are now emerging as a crucial aspect and need proper testing and possibly mitigation to prevent data stealing and leakage of sensitive information. AISec provides a venue for presenting and discussing new developments in the intersection of security and privacy with AI and ML.}
}


@inproceedings{DBLP:conf/ccs/FawazM25,
	author = {Kassem Fawaz and
                  Daisuke Mashima},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {CPSIoTSec'25: The 7th Joint Workshop on {CPS} {\&} IoT Security
                  and Privacy},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4892--4893},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3767659},
	doi = {10.1145/3719027.3767659},
	timestamp = {Fri, 26 Dec 2025 20:53:06 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/FawazM25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The 7th Joint Workshop on CPS & IoT Security and Privacy is set to take place in Taipei, Taiwan, on October 17, 2025, in conjunction with the ACM Conference on Computer and Communications Security (CCS'25). This workshop marks the amalgamation of two workshops held in 2019: one focused on the security and privacy of cyber-physical systems, while the other one centered on the security and privacy of IoT. The primary objective of this workshop is to create a collaborative forum that brings together academia, industry experts, and governmental entities, encouraging them to contribute cutting-edge research, share demonstrations or hands-on experiences, and engage in discussions. This year, our call for contributions encompassed a broad spectrum, including full research papers, work-in-progress submissions, and one-page abstracts. The workshop program includes nine full/short papers on the security and privacy of CPS/IoT, alongside one demo paper that presents a virtual cybersecurity testbed. Furthermore, the workshop will feature one distinguished keynote presentation by Prof. Daniel Xiapu Luo, a world-renowned expert in CPS security. The talk will offer deep insights on automotive cybersecurity. The complete CPSIoTSec'25 workshop proceedings are available at https://doi.org/10.1145/3733801}
}


@inproceedings{DBLP:conf/ccs/Blanc0Z25,
	author = {Gregory Blanc and
                  Takeshi Takahashi and
                  Zonghua Zhang},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {{ARTMAN} '25: Third Workshop on Recent Advances in Resilient and Trustworthy
                  MAchine learning-driveN systems},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4894--4895},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3767660},
	doi = {10.1145/3719027.3767660},
	timestamp = {Fri, 26 Dec 2025 20:53:06 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/Blanc0Z25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The ARTMAN workshop aims to bring together academic researchers and industry practitioners from diverse domains, primarily security & privacy and machine learning, but also various application fields, to collaboratively explore and discuss resilient and trustworthy machine learning-powered applications and systems. This workshop focuses on AI/ML application domains and welcomes contributions on both foundational and applied aspects of ML across various industries, including transportation, aerospace, healthcare, energy, and finance, among others, showcasing AI-driven advances in performance and efficiency. This workshop also seeks contributions on the application of reliable and secure AI/ML algorithms, especially knowledge-informed approaches, to improve resilience and trust, particularly in human-machine partnerships and interactions within such scenarios.}
}


@inproceedings{DBLP:conf/ccs/CafaroC0K25,
	author = {Massimo Cafaro and
                  Eric Chan{-}Tin and
                  Jerry Chou and
                  Jinoh Kim},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {{WATCH} '25: First Workshop on Analytics, Telemetry, and Cybersecurity
                  for {HPCC}},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4896--4897},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3767661},
	doi = {10.1145/3719027.3767661},
	timestamp = {Fri, 26 Dec 2025 20:53:06 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/CafaroC0K25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Workshop on Analytics, Telemetry, and Cybersecurity for High-Performance Computing and Communications (HPCC) is newly launched and takes place in Taipei, Taiwan, on October 17, 2025, in conjunction with the ACM Conference on Computer and Communications Security (CCS'25). As its title suggests, the workshop centers on strengthening resilience and security in HPCC applications and infrastructures by leveraging leading technologies, including data-driven methodologies and machine intelligence techniques. The primary objective of this workshop is to provide a dedicated platform for researchers, practitioners, and industry experts to engage in discussions on cutting-edge topics in analytics, telemetry, and cybersecurity for HPCC. This year's call for contributions welcomes both full research papers and work-in-progress submissions, resulting in the acceptance of five full-length research papers. In addition, the workshop features a distinguished keynote presentation by Dr. Hsu-Chun Hsiao, Associate Professor in the Department of Computer Science and Information Engineering and the Graduate Institute of Networking and Multimedia at National Taiwan University. The WATCH'25 complete workshop proceedings can be found at: https://dl.acm.org/citation.cfm?id=3733826.}
}


@inproceedings{DBLP:conf/ccs/YelgundhalliHRD25,
	author = {Aditya Sirish A Yelgundhalli and
                  Behnaz Hassanshahi and
                  Dennis Roellke and
                  Drew Davidson and
                  Kathleen Moriarty and
                  Lorenzo De Carli and
                  Marcela S. Melara and
                  Santiago Torres{-}Arias and
                  Sarah Evans and
                  Yuchen Zhang},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {{SCORED} '25: Workshop on Software Supply Chain Offensive Research
                  and Ecosystem Defenses},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4898--4899},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3767662},
	doi = {10.1145/3719027.3767662},
	timestamp = {Fri, 26 Dec 2025 20:53:06 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/YelgundhalliHRD25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Attacks on the software supply chain have shed light on the fragility and importance of ensuring the security and integrity of this vital ecosystem. Addressing the technical and social challenges to building trustworthy software (including AI applications) requires innovative solutions and an interdisciplinary approach. The Workshop on Software Supply Chain Offensive Research and Ecosystem Defenses (SCORED) is the leading venue for academics, industry practitioners, and policymakers to present and discuss security vulnerabilities, novel defenses against attacks, deployment experiences, adoption requirements and best practices in the software supply chain. The complete SCORED '25 workshop proceedings are available at: https://doi.org/10.1145/3733827}
}


@inproceedings{DBLP:conf/ccs/0001LYD25,
	author = {Tianshi Li and
                  Toby Jia{-}Jun Li and
                  Yaxing Yao and
                  Sauvik Das},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {{HAIPS} '25: First {ACM} {CCS} Workshop on Human-Centered {AI} Privacy
                  and Security},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4900--4901},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3767663},
	doi = {10.1145/3719027.3767663},
	timestamp = {Fri, 26 Dec 2025 20:53:06 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/0001LYD25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recent advances in AI/ML create novel and pressing privacy and security challenges—ranging from using generative AI to create harmful content, to the generation of insecure code by AI coding assistants; from oversharing information with ChatGPT to unexpected privacy leaks by LLM agents. At the same time, AI offers new opportunities to address long-standing end-user privacy and security concerns and empower practitioners to adopt better security and privacy practices. In the inaugural workshop of HAIPS'25, we aim to help build and strengthen a community of people enthusiastic about privacy and security issues related to AI from a human-centered perspective, and foster cross-disciplinary research agendas that effectively engage with the human element when addressing these issues. The HAIPS'25 complete workshop proceedings can be found at: https://dl.acm.org/citation.cfm?id=3733816}
}


@inproceedings{DBLP:conf/ccs/000125a,
	author = {Jianying Zhou},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {{WPES} '25: 24th Workshop on Privacy in the Electronic Society},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4902--4903},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3767664},
	doi = {10.1145/3719027.3767664},
	timestamp = {Fri, 26 Dec 2025 20:53:06 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/000125a.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The need for privacy-aware policies, regulations, and techniques has been widely recognized. This workshop discusses the problems of privacy in the global interconnected societies and possible solutions. The 2025 Workshop, held in conjunction with the ACM CCS conference, is the 24th in a yearly forum for papers on all the different aspects of privacy in today's electronic society.}
}


@inproceedings{DBLP:conf/ccs/BasqueB25,
	author = {Zion Leonahenahe Basque and
                  Ati Priya Bajaj},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {{SURE} '25: The 1st {ACM} Workshop on Software Understanding and Reverse
                  Engineering},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4904--4905},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3767665},
	doi = {10.1145/3719027.3767665},
	timestamp = {Fri, 26 Dec 2025 20:53:06 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/BasqueB25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The 1st ACM Workshop on Software Understanding and Reverse Engineering (SURE), co-located with CCS 2025, addressed the growing gap between rapid software creation and our ability to analyze and reason about code. The program features a keynote, paper sessions, posters, and a roundtable on challenges in reverse engineering. SURE received 15 submissions and accepted nine papers (60% acceptance rate). By bringing together researchers and practitioners, the workshop established a new venue for defining the field and fostering collaboration. Beyond its program, SURE contributed to shaping the emerging research community around software understanding. The workshop collected diverse approaches, highlighted shared challenges, and began articulating clearer definitions of what constitutes work in software understanding and reverse engineering. By consolidating knowledge and promoting discussion across traditional and exploratory topics, SURE laid the groundwork for a stronger, more coherent research agenda in this critical area. The SURE '25 complete workshop proceedings can be found at: https://dl.acm.org/citation.cfm?id=3733822.}
}


@inproceedings{DBLP:conf/ccs/BardinIM25,
	author = {S{\'{e}}bastien Bardin and
                  Michele Ianni and
                  Hyungon Moon},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {CheckMATE '25: Research on Offensive and Defensive Techniques in the
                  Context of Man At The End {(MATE)} Attacks},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4906--4907},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3767666},
	doi = {10.1145/3719027.3767666},
	timestamp = {Fri, 26 Dec 2025 20:53:06 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/BardinIM25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Man-At-The-End (MATE) attackers operate with full access to software or hardware targets and can observe, analyze, and modify running systems to extract secrets or alter behavior. CheckMATE explores both offensive and defensive research in this space: measurement studies and tooling that expose realistic attack techniques, alongside defenses such as obfuscation, tamper-resistance, watermarking, white-box cryptography, and hardware-assisted protections. This workshop collects rigorous, reproducible research aimed at bridging academic advances and industry practice. The CheckMATE '25 complete workshop proceedings can be found at: https://dl.acm.org/citation.cfm?id=3733817}
}


@inproceedings{DBLP:conf/ccs/0001B25,
	author = {Paolo Palmieri and
                  Shivam Bhasin},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {{CCSW} '25: Cloud Computing Security Workshop},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4908--4909},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3767667},
	doi = {10.1145/3719027.3767667},
	timestamp = {Fri, 26 Dec 2025 20:53:06 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/0001B25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The 16th Cloud Computing Security Workshop (CCSW '25), co-located with the ACM Conference on Computer and Communications Security (CCS '25), was held in Taipei on October 17, 2025. It featured six full papers on various aspects of security and privacy of cloud environments, including recent advances in security testing and intrusion detection enabled by artificial intelligence, advanced cryptography for the outsourcing of data and computation, and secure coding and networking. The program was enriched by two distinguished keynote speakers: Dr. Tianwei Zhang and Dr. Matthias Kannwischer. The complete CCSW '25 workshop proceedings can be found at: https://dl.acm.org/citation.cfm?id=3733812}
}


@inproceedings{DBLP:conf/ccs/RazaS25,
	author = {Muhammad Taqi Raza and
                  Jakub Szefer},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {QSec '25: Workshop on Quantum Security and Privacy},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4910--4911},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3767668},
	doi = {10.1145/3719027.3767668},
	timestamp = {Fri, 26 Dec 2025 20:53:06 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/RazaS25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Quantum Security and Privacy (QSec) Workshop aims to establish a focused venue dedicated to examining both the novel threats introduced by quantum technologies and the security of quantum systems themselves. By bringing together experts from traditional security domains such as post-quantum cryptography and network security, as well as from quantum computing research including quantum key distribution and quantum architectures, QSec provides a forum to expose emerging quantum-era threats by analyzing how adversaries with quantum or quantum-enhanced capabilities can undermine both classical and quantum systems. It further seeks to showcase innovative defenses by presenting hybrid cryptographic schemes, quantum-native protocols such as QKD, and hardware-level protections. In addition, the workshop aims to bridge disparate communities by fostering collaboration among researchers in cryptography, networking, architecture, and quantum information science. Finally, QSec aspires to chart a roadmap for future research by using keynotes, technical sessions, and blue-sky discussions to identify long-term challenges and research directions. The complete QSec’25 workshop proceedings can be found at: https://dl.acm.org/citation.cfm?id=3733825}
}


@inproceedings{DBLP:conf/ccs/KunduYN25,
	author = {Ashish Kundu and
                  Attila A. Yavuz and
                  Cristina Nita{-}Rotaru},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {QRSec 2025: {ACM} {CCS} First Workshop on Quantum-Resistant Cryptography
                  and Security},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4912--4913},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3767669},
	doi = {10.1145/3719027.3767669},
	timestamp = {Fri, 26 Dec 2025 20:53:06 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/KunduYN25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Quantum computing poses transformative opportunities and challenges, with cryptography at the forefront of its impact. The ACM CCS Workshop on Quantum-Resistant Cryptography and Security (QRSec 2025) provides a forum for researchers, practitioners, and industry leaders to explore advances in post-quantum cryptography (PQC) and its integration into secure systems. Building on the momentum of the NIST PQC standardization process and the release of the first standards in 2024, QRSec 2025 highlights theoretical foundations, algorithm design, engineering, and deployment strategies alongside emerging topics such as machine learning for cryptanalysis, quantum-resistant networks, blockchain, IoT, and cloud security. The program features keynotes from leading experts, technical paper sessions, and interactive panels bridging academia, industry, and government. By fostering dialogue across these communities, QRSec 2025 aims to advance the state of the art in quantum-resistant security and chart practical paths for migration and compliance in the post-quantum era.}
}


@inproceedings{DBLP:conf/ccs/Lam0W0XC0YBW25,
	author = {Kwok{-}Yan Lam and
                  Xiaoning Liu and
                  Derui Wang and
                  Bo Li and
                  Wenyuan Xu and
                  Jieshan Chen and
                  Minhui Xue and
                  Xingliang Yuan and
                  Guangdong Bai and
                  Shuo Wang},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {{LAMPS} '25: {ACM} {CCS} Workshop on Large {AI} Systems and Models
                  with Privacy and Security Analysis},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4914--4915},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3767670},
	doi = {10.1145/3719027.3767670},
	timestamp = {Fri, 26 Dec 2025 20:53:06 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/Lam0W0XC0YBW25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With large AI systems and models (LAMs) playing an ever-growing role across diverse applications, their impact on the privacy and cybersecurity of critical infrastructure has become a pressing concern. The LAMPS workshop is dedicated to tackling these emerging challenges, promoting dialogue on cutting-edge developments and ethical issues in safeguarding LAMs within critical infrastructure contexts. Bringing together leading experts from around the world, this workshop will delve into the complex privacy and cybersecurity risks posed by LAMs in critical sectors. Attendees will explore innovative solutions, exchange best practices, and contribute to shaping the future research agenda, emphasizing the crucial balance between advancing AI technologies and securing critical digital and physical infrastructures.}
}


@inproceedings{DBLP:conf/ccs/ChungZZ25,
	author = {Hao Chung and
                  Yajin Zhou and
                  Liyi Zhou},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {DeFi '25: 5th {ACM} Workshop on Decentralized Finance and Security},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4916--4917},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3767671},
	doi = {10.1145/3719027.3767671},
	timestamp = {Fri, 26 Dec 2025 20:53:06 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/ChungZZ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Decentralized Finance (DeFi) has undergone significant expansion, evolving from a niche market into a complex alternative financial ecosystem. This burgeoning landscape now encompasses a diverse array of financial services, including decentralized exchanges, lending and borrowing platforms, stablecoins, derivatives, yield optimization services, prediction markets, and privacy-enhancing technologies such as token mixers. While the total value locked in DeFi protocols—estimated at approximately 77 billion USD—underscores its increasing significance, it simultaneously highlights the critical necessity for robust security measures. This workshop aims to address the pressing security challenges in the maturing DeFi space by convening leading experts from the fields of cryptography, game theory, economics, and cybersecurity. Our primary objective is to foster interdisciplinary dialogue and showcase cutting-edge research that rigorously examines the current state of DeFi security and charts a comprehensive path forward. The anticipated outcomes include a prioritized research agenda, new collaborative initiatives bridging theoretical advancements with practical implementations, and a strategic roadmap for enhancing security in the rapidly evolving DeFi ecosystem. This year's program features a keynote talk by Prof. Vassilis Zikas, two invited talks by the winners of the Best DeFi Paper Award (theoretical research track and applied research track), and four presentations of accepted original papers, showcasing both fundamental advances and real-world applications.}
}


@inproceedings{DBLP:conf/ccs/BichhawatH25,
	author = {Abhishek Bichhawat and
                  Jana Hofmann},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {The 20th Workshop on Programming Languages and Analysis for Security
                  {(PLAS} 2025)},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4918--4919},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3767672},
	doi = {10.1145/3719027.3767672},
	timestamp = {Fri, 26 Dec 2025 20:53:06 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/BichhawatH25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {PLAS provides a forum for exploring and evaluating the use of programming language and program analysis techniques for promoting security in the complete range of software systems, from compilers to machine-learned models and smart contracts. The workshop encourages proposals of new, speculative ideas, evaluations of new or known techniques in practical settings, and discussions of emerging threats and problems. It also host position papers that are radical, forward-looking, and lead to lively and insightful discussions influential to the future research at the intersection of programming languages and security. This year will mark the 20th edition of PLAS, which was first held in 2007 in San Diego. The workshop will host 2 keynote talks, by Limin Jia and Jan Reineke, and 5 paper presentations.}
}


@inproceedings{DBLP:conf/ccs/Sun025,
	author = {Ruimin Sun and
                  Mu Zhang},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {RICSS'25: 3rd International Workshop on Re-design Industrial Control
                  Systems with Security},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4920--4921},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3767673},
	doi = {10.1145/3719027.3767673},
	timestamp = {Sun, 07 Dec 2025 22:09:44 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/Sun025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Industrial Control System (ICS) and its software touches every aspect of the critical infrastructure used by our industry, academia, and government. Back in the days, these systems and software were not designed with security in mind. With the ever expanding inter- connectivity of ICS environments and new threats, practitioners are stuck on a patchwork of security. While certain proprietary ICS software manufacturers have started to provide security solutions, free and open source ICS software is often less known. The goal of the workshop is twofold: we want to collect ideas on redesigning (parts of) the ICS ecosystem so that security is built-in by design; we also invite contributions on designing, incorporating, and maintaining secure open-source ICS software.}
}


@inproceedings{DBLP:conf/ccs/WooTAMWVF25,
	author = {Simon S. Woo and
                  Shahroz Tariq and
                  Sharif Abuadbba and
                  Kristen Moore and
                  Tim Walita and
                  Bimal Viswanath and
                  Mario Fritz},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {3D-Sec '25: The 1st {ACM} Workshop on Deepfake, Deception, and Disinformation
                  Security},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4922--4923},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3767674},
	doi = {10.1145/3719027.3767674},
	timestamp = {Fri, 26 Dec 2025 20:53:06 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/WooTAMWVF25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The rise of deepfakes, AI-generated misinformation, and synthetic personas has introduced unprecedented challenges to digital security. These technologies are increasingly weaponised for political manipulation, financial fraud, social engineering, and cyber warfare. With the rapid evolution of Generative AI, Large Language Models (LLMs), and adversarial machine learning, malicious actors now possess tools to fabricate convincing narratives, generate realistic fake media, and orchestrate large-scale influence campaigns. The 3D-Sec: Deepfake, Deception, and Disinformation Security Workshop at ACM CCS 2025 seeks to confront these emerging threats by fostering dialogue and innovation in detection, attribution, forensic analysis, and mitigation strategies. This workshop brings together experts from academia, industry, and government to explore the security implications of AI-driven deception and to develop robust frameworks for safeguarding digital ecosystems against synthetic media and automated disinformation. The official 3D-Sec workshop webpage is available at: https://sites.google.com/view/3d-sec2025, providing comprehensive information on the program, speakers, and accepted papers. The peer-reviewed proceedings of 3D-Sec have been published and can be accessed via the ACM Digital Library at: https://dl.acm.org/citation.cfm?id=3733813.}
}


@inproceedings{DBLP:conf/ccs/Xing025,
	author = {Luyi Xing and
                  Yue Xiao},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {SaTS '25: The 3rd {ACM} Workshop on Security and Privacy of AI-Empowered
                  Mobile Super Apps},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4924--4925},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3768538},
	doi = {10.1145/3719027.3768538},
	timestamp = {Fri, 26 Dec 2025 20:53:06 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/Xing025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Mobile super apps, which bundle multiple mini-apps into a single platform, have become central to the consumer-facing digital ecosystem. Services such as WeChat, Alipay, Grab, and TikTok integrate payments, messaging, commerce, and entertainment, while at the same time collecting and processing large volumes of sensitive personal data. This concentration of functionality creates unprecedented opportunities to businesses and online services but also raises significant security and privacy risks. Meanwhile, a growing trend is the integration of large language models (LLMs) into mobile apps, transforming them into LLM-driven agentic systems. These systems are capable of orchestrating mini-apps and other mobile apps, interacting with external services, and carrying out privileged tasks on behalf of users. While this enables powerful new applications, it also expands the attack surface and introduces new forms of data exposure, misuse of privileges, and adversarial manipulation. The workshop seeks contributions including but not limited secure architectural design, permission frameworks, threat modeling, privacy-preserving methods, and case studies of real-world deployments in order to build a foundation for safer and more trustworthy LLM-empowered super apps and more generally mobile apps.}
}


@inproceedings{DBLP:conf/ccs/BergamaschiPR25,
	author = {Fl{\'{a}}vio Bergamaschi and
                  Yuriy Polyakov and
                  Kurt Rohloff},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {{WAHC} 2025: 13th Workshop on Encrypted Computing {\&} Applied
                  Homomorphic Cryptography},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4926--4927},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3769095},
	doi = {10.1145/3719027.3769095},
	timestamp = {Fri, 26 Dec 2025 20:53:06 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/BergamaschiPR25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Secure computation is becoming a key feature of future information systems. Distributed network applications and cloud architectures are at danger because lots of personal consumer data is aggregated in all kinds of formats and for various purposes. Industry and consumer electronics companies are facing massive threats like theft of intellectual property and industrial espionage. Public infrastructure has to be secured against sabotage and manipulation. A possible solution is encrypted computing: Data can be processed on remote, possibly insecure resources, while program code and data is encrypted all the time. This allows to outsource the computation of confidential information independently from the trustworthiness or the security level of the remote system. The technologies and techniques discussed in this workshop are a key to extend the range of applications that can be securely outsourced. The goal of the 13th Workshop on Encrypted Computing & Applied Homomorphic Cryptography (WAHC '25) is to bring together researchers and practitioners from industry to present, discuss and to share the latest progress in the field. We want to exchange ideas that address real-world problems with practical approaches and solutions. The complete WAHC '25 workshop proceedings can be found at https://dl.acm.org/citation.cfm?id=3733811.}
}


@inproceedings{DBLP:conf/ccs/ChenR25,
	author = {Jyh{-}Cheng Chen and
                  K. K. Ramakrishnan},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {free5GC '25: The 1st free5GC World Forum},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4928--4929},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3769096},
	doi = {10.1145/3719027.3769096},
	timestamp = {Fri, 26 Dec 2025 20:53:06 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/ChenR25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The 1st free5GC World Forum brings together researchers, industry professionals, and open-source contributors to explore the challenges and recent advancements in 5G core networks, with a particular focus on security and the transformative role of free5GC, the leading open-source 5G Standalone (SA) core network. free5GC, a project hosted by the Linux Foundation, is a fully 3GPP-compliant, open-source 5G core network platform. It empowers researchers, developers, and businesses to drive innovation in 5G systems by providing a robust prototyping environment for next-generation connectivity solutions. Recent notable architectures, such as L25GC+, which aims to significantly reduce control plane latency while maintaining 3GPP compliance, exemplify how free5GC facilitates the development and testing of cutting-edge ideas on a production-grade 5G core. The forum offers a unique opportunity for participants to share insights, present innovations, and shape the future direction of free5GC and next-generation mobile networks. The complete free5GC '25 workshop proceedings can be found at: https://dl.acm.org/citation.cfm?id=3733814}
}


@inproceedings{DBLP:conf/ccs/HofFK25,
	author = {Hans{-}Joachim Hof and
                  Mario Fritz and
                  Christoph Krau{\ss}},
	editor = {Chun{-}Ying Huang and
                  Jyh{-}Cheng Chen and
                  Shiuh{-}Pyng Shieh and
                  David Lie and
                  V{\'{e}}ronique Cortier},
	title = {{CSCS} '25 - Cyber Security in CarS Workshop},
	booktitle = {Proceedings of the 2025 {ACM} {SIGSAC} Conference on Computer and
                  Communications Security, {CCS} 2025, Taipei, Taiwan, October 13-17,
                  2025},
	pages = {4930--4931},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3719027.3769666},
	doi = {10.1145/3719027.3769666},
	timestamp = {Fri, 26 Dec 2025 20:53:06 +0100},
	biburl = {https://dblp.org/rec/conf/ccs/HofFK25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The second Cyber Security in Cars Workshop (CSCS'25) takes place in Taipei, Taiwan, on October 17, 2025, in conjunction with the ACM Conference on Computer and Communications Security (CCS'25). CSCS is the successor of the yearly ACM Computer Science in Cars Symposium, which ran from 2017 to 2023. CSCS'25 aims to bring together researchers, practitioners, developers, and anyone interested in solving the myriad of complex problems of cyber security in modern vehicles. The conference offers a common platform to discuss new developments in vehicle technology and its applications. In addition to presenting current research contributions, the conference offers the opportunity for networking, joint brainstorming on current challenges, and the development of new solutions.}
}
