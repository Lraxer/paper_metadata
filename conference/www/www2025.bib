@inproceedings{DBLP:conf/www/Schmidhuber25,
	author = {J{\"{u}}rgen Schmidhuber},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Falling Walls, WWW, Modern AI, and the Future of the Universe},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {1},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714541},
	doi = {10.1145/3696410.3714541},
	timestamp = {Wed, 23 Apr 2025 16:35:50 +0200},
	biburl = {https://dblp.org/rec/conf/www/Schmidhuber25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Around 1990, the Berlin Wall came down, the WWW was born at CERN, mobile phones became popular, self-driving cars appeared in traffic, and modern AI based on very deep artificial neural networks emerged, including the principles behind the G, P, and T in ChatGPT. I place these events in the history of the universe since the Big Bang, and discuss what's next: not just AI behind the screen in the virtual world, but real AI for real robots in the real world, connected through a WWW of machines. Intelligent (but not necessarily super-intelligent) robots that can learn to operate the tools and machines operated by humans can also build (and repair when needed) more of their own kind. This will culminate in life-like, self-replicating and self-improving machine civilisations, which represent the ultimate form of upscaling, and will shape the long-term future of the entire cosmos. The wonderful short-term side effect is that our AI will continue to make people's lives longer, healthier and easier.}
}


@inproceedings{DBLP:conf/www/Leskovec25,
	author = {Jure Leskovec},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {From Retrieval to Reasoning: Advancing {AI} Agents for Knowledge Discovery
                  and Collaboration},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {2},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714542},
	doi = {10.1145/3696410.3714542},
	timestamp = {Thu, 01 May 2025 20:27:23 +0200},
	biburl = {https://dblp.org/rec/conf/www/Leskovec25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The web is the world's largest knowledge repository, yet as AI systems become increasingly integrated into our digital infrastructure, the ability to retrieve, reason, and collaborate effectively has become paramount. Large Language Models (LLMs) are evolving from passive responders to active knowledge agents that can retrieve complex information, validate hypotheses, and optimize interactions over multiple turns. In this talk, I will explore the frontiers of AI-driven knowledge retrieval and reasoning, drawing from recent research on knowledge graphs, semi-structured retrieval, adaptive tool use, and multi-turn AI collaboration. I will also discuss how agentic frameworks enable rigorous, automated hypothesis validation through sequential falsifications. Together, these advancements push beyond traditional search and QA systems, unlocking new capabilities for knowledge discovery, scientific research, and human-AI collaboration. Finally, I will highlight key challenges and opportunities in building AI systems that are not just accurate, but also interactive, explainable, and aligned with human needs.}
}


@inproceedings{DBLP:conf/www/Gao25,
	author = {Wen Gao},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Peng Cheng Cloud Brain and Mind Series of Large Model},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {3},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714543},
	doi = {10.1145/3696410.3714543},
	timestamp = {Tue, 13 May 2025 07:31:04 +0200},
	biburl = {https://dblp.org/rec/conf/www/Gao25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As a revolutionary pre-training model, ChatGPT has already had a huge impact on global economic. It is the strong foundation of computing power that enables large models to continuously improve in the process of understanding massive data, resulting in breakthrough innovations. Based on the Peng Cheng Cloud Brain II E-level intelligent computing platform, Peng Cheng Laboratory is training PCL Mind Series of Large Model. Mind is the first fully autonomous, controllable, safe, open-source pre-training foundation model in China, where the performance of the 200 billion parameter base model reaches the international advanced, and the output content conforms to the Chinese core values. Peng Cheng Laboratory is opening up PCL Mind cooperation and work with external partners to continuously build a large model open-source consortium for domestic large model ecosystem. The next generation-Peng Cheng Cloud Brain III will break through key technologies such as high computing power chips, large-scale networking communication, high-performance software stacks, and large-scale parallel training, and support 10,000 chip-level parallel training of trillion-level parameter AI.}
}


@inproceedings{DBLP:conf/www/Liu25,
	author = {Yan Liu},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {The {AI} Revolution in Time Series: Challenges and Opportunites},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {4},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714965},
	doi = {10.1145/3696410.3714965},
	timestamp = {Tue, 13 May 2025 07:31:04 +0200},
	biburl = {https://dblp.org/rec/conf/www/Liu25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recent advancements in deep learning and artificial intelligence have driven significant progress in time series modeling and analysis. On one hand, researchers seek breakthroughs in performance on classical tasks such as forecasting, anomaly detection, classification, etc. On the other hand, it is intriguing to explore the potential for answering more complex inference and reasoning tasks from time series. In this keynote, I will examine the pathways toward foundation models for time series and discuss future research directions in this rapidly evolving field. The remarkable success of foundation models in natural language processing - exemplified by Generative Pre-trained Transformers (GPT) - suggests their potential to revolutionize time series analysis. I will introduce our recent efforts along this direction, including TEMPO, a novel framework designed to learn effective time series representations by leveraging two key inductive biases: one is explicit decomposition of trend, seasonal, and residual components, and the second is prompt-based distribution adaptation for diverse time series types. Beyond representation learning, practical applications demands advanced reasoning capabilities with multi-step time series inference task, requiring both compositional reasoning and computational precision. To tackle this challenge, I will discuss TS-reasoner, a program-aided inference agent that integrates large language models (LLMs) with structured execution pipelines, in-context learning, and self-correction mechanisms. I will discuss a new benchmark dataset and evaluation framework to systematically assess multi-step time series reasoning. By bridging deep learning advances with structured reasoning, I will highlight the next frontier in time series research, i.e., developing foundation models that enhance forecasting performance, generative models, and reasoning capabilities from time series across diverse applications.}
}


@inproceedings{DBLP:conf/www/000125,
	author = {Jon Whittle},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {{AI} for Science: The Next Big Opportunity},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {5},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714966},
	doi = {10.1145/3696410.3714966},
	timestamp = {Fri, 09 May 2025 20:28:07 +0200},
	biburl = {https://dblp.org/rec/conf/www/000125.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In 2024, Demis Hassabis and John Jumper won the Nobel Prize for Chemistry for developing an AI model to predict the shape of every protein known to mankind. Chair of the Nobel Committee, Heiner Linke, described the AI system as the achievement of a ''50-year-old dream'' that solved a notoriously difficult problem eluding scientists since the 1970s. This AI system, AlphaFold, has ushered in a golden age of AI for science - the development of AI techniques for accelerating scientific discovery. We are currently amid the largest surge in the application and development of AI for scientific research in history. Scholarly publications, patents, education, training, research activity and investment are increasing at unprecedented rates. AI may help scientists address humanity's greatest challenges such as climate change, pollution, resource scarcity and infectious diseases. In this talk, I will cover the state of practice in AI for science. I'll discuss some of the successes already achieved as well as challenges for applying AI to science in the future. And I'll highlight some of the work at CSIRO, Australia's national science agency, which contains over 1000 AI experts developing novel AI solutions to long-standing scientific problems.}
}


@inproceedings{DBLP:conf/www/AhmetajBHHJGMMM25,
	author = {Shqiponja Ahmetaj and
                  Iovka Boneva and
                  Jan Hidders and
                  Katja Hose and
                  Maxime Jakubowski and
                  Jos{\'{e}} Emilio Labra Gayo and
                  Wim Martens and
                  Fabio Mogavero and
                  Filip Murlak and
                  Cem Okulmus and
                  Axel Polleres and
                  Ognjen Savkovic and
                  Mantas Simkus and
                  Dominik Tomaszuk},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Common Foundations for SHACL, ShEx, and PG-Schema},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {8--21},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714694},
	doi = {10.1145/3696410.3714694},
	timestamp = {Fri, 09 May 2025 20:28:07 +0200},
	biburl = {https://dblp.org/rec/conf/www/AhmetajBHHJGMMM25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graphs have emerged as a foundation for a variety of applications, including capturing factual knowledge, semantic data integration, social networks, and informing machine learning algorithms. Formalising properties of the data and ensuring data quality requires describing  schemas  of such graphs. Driven by diverse applications, the Semantic Web and database communities developed not only different graph data models-RDF and property graphs-but also different  graph schema languages -SHACL, ShEx, and PG-Schema. Each language has its unique approach to defining constraints and validating graph data, leaving potential users in the dark about their commonalities and differences. In this paper, we provide concise formal definitions of the  core components  of these languages, employ a uniform framework to facilitate a comprehensive comparison between them, and identify a common set of functionalities, shedding light on both overlapping and distinctive features.}
}


@inproceedings{DBLP:conf/www/YangCS25,
	author = {Hui Yang and
                  Jiaoyan Chen and
                  Uli Sattler},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {TransBox: \emph{EL}\({}^{\mbox{++}}\)-closed Ontology Embedding},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {22--34},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714672},
	doi = {10.1145/3696410.3714672},
	timestamp = {Fri, 09 May 2025 20:28:07 +0200},
	biburl = {https://dblp.org/rec/conf/www/YangCS25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {OWL (Web Ontology Language) ontologies, which are able to represent both relational and type facts as standard knowledge graphs and complex domain knowledge in Description Logic (DL) axioms, are widely adopted in domains such as healthcare and bioinformatics. Inspired by the success of knowledge graph embeddings, embedding OWL ontologies has gained significant attention in recent years. Current methods primarily focus on learning embeddings for atomic concepts and roles, enabling the evaluation based on normalized axioms through specially designed score functions. However, they often neglect the embedding of complex concepts, making it difficult to infer with more intricate axioms. This limitation reduces their effectiveness in advanced reasoning tasks, such as Ontology Learning and ontology-mediated Query Answering. In this paper, we propose  EL ++ -closed ontology embeddings which are able to represent any logical expressions in DL  EL ++  via composition. Furthermore, we develop TransBox, an effective  EL ++  -closed ontology embedding method that can handle many-to-one, one-to-many and many-to-many relations. Our extensive experiments demonstrate that TransBox often achieves state-of-the-art performance across various real-world datasets for predicting complex axioms.}
}


@inproceedings{DBLP:conf/www/Nguyen0SH025,
	author = {Chau D. M. Nguyen and
                  Tim French and
                  Michael Stewart and
                  Melinda Hodkiewicz and
                  Wei Liu},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Spherical Embeddings for Atomic Relation Projection Reaching Complex
                  Logical Query Answering},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {35--46},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714747},
	doi = {10.1145/3696410.3714747},
	timestamp = {Fri, 09 May 2025 20:28:07 +0200},
	biburl = {https://dblp.org/rec/conf/www/Nguyen0SH025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Projecting knowledge graph queries into an embedding space using geometric models (points, boxes and spheres) can help to answer queries for large incomplete knowledge graphs. In this work, we propose a symbolic learning-free approach using fuzzy logic to address the shape-closure problem that restricted geometric-based embedding models to only a few shapes (e.g. ConE) for answering complex logical queries. The use of symbolic approach facilitates non-closure geometric models (e.g. point, box) to handle logical operators (including negation). This enabled our newly proposed spherical embeddings (SpherE) in this work to use a polar coordinate system to effectively represent hierarchical relation. Results show that the SpherE model can answer existential positive first-order logic and negation queries. We show that SpherE significantly outperforms the point and box embeddings approaches while generating semantically meaningful hierarchy-aware embeddings.}
}


@inproceedings{DBLP:conf/www/PhamMNSM25,
	author = {Thi Hoang Thi Pham and
                  Gabriela Montoya and
                  Brice N{\'{e}}delec and
                  Hala Skaf{-}Molli and
                  Pascal Molli},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Passage: Ensuring Completeness and Responsiveness of Public {SPARQL}
                  Endpoints with {SPARQL} Continuation Queries},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {47--58},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714757},
	doi = {10.1145/3696410.3714757},
	timestamp = {Fri, 09 May 2025 20:28:07 +0200},
	biburl = {https://dblp.org/rec/conf/www/PhamMNSM25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Being able to query online public knowledge graphs such as Wikidata or DBpedia is extremely valuable. However, these queries can be interrupted due to the fair use policies enforced by SPARQL endpoint providers, leading to incomplete results. While these policies help maintain the responsiveness of public SPARQL endpoints, they compromise the completeness of query results, which limits the feasibility of various downstream tasks. Ideally, we should not have to choose between completeness and responsiveness. To address this issue, we introduce and formalize the concept of  SPARQL continuation queries . When a SPARQL endpoint interrupts a query, it returns partial results along with a SPARQL continuation query to retrieve the remaining results. If the continuation query is also interrupted, the process repeats, generating further continuation queries until the complete results are obtained. In our experimentation, we show that our continuation server PASSAGE ensures completeness and responsiveness while delivering high performance.}
}


@inproceedings{DBLP:conf/www/Fuentes-Sepulveda25,
	author = {Jos{\'{e}} Fuentes{-}Sep{\'{u}}lveda and
                  Adri{\'{a}}n G{\'{o}}mez{-}Brand{\'{o}}n and
                  Aidan Hogan and
                  Ayleen Irribarra{-}Cort{\'{e}}s and
                  Gonzalo Navarro and
                  Juan L. Reutter},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Worst-Case-Optimal Joins on Graphs with Topological Relations},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {59--71},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714695},
	doi = {10.1145/3696410.3714695},
	timestamp = {Fri, 09 May 2025 20:28:07 +0200},
	biburl = {https://dblp.org/rec/conf/www/Fuentes-Sepulveda25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Spatial data play an important role in many applications built over knowledge graphs, and are frequently referenced in queries posed to public query services, such as that of Wikidata. Querying for spatial data presents a significant challenge, as topological relations such as  adjacent  or  contains  imply inferred information, such as through the transitivity of the containment relation. However, despite all the recent advances in querying knowledge graphs, we still lack techniques specifically tailored for topological information. Applications looking to incorporate topological relations must either materialize the inferred relations, incurring high space and maintenance overheads, or query them with less efficient recursive algorithms, incurring high runtime overheads. In this paper we address the problem of leveraging topological information in knowledge graphs by designing efficient algorithms to process these queries. Our solution involves building a specific index that stores the topological information in a convenient compact form, and includes specialized algorithms that infer every possible relation from the basic topological facts in the graph. We show that, while using essentially the same space required to solve standard graph pattern queries, we can incorporate topological predicates, accounting for all the inferred information, all within worst-case-optimal time. We implement our scheme and show experimentally that it outperforms baseline solutions by a notable margin.}
}


@inproceedings{DBLP:conf/www/KoYKK25,
	author = {Youmin Ko and
                  Hyemin Yang and
                  Taeuk Kim and
                  Hyunjoon Kim},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Subgraph-Aware Training of Language Models for Knowledge Graph Completion
                  Using Structure-Aware Contrastive Learning},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {72--85},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714946},
	doi = {10.1145/3696410.3714946},
	timestamp = {Fri, 09 May 2025 20:28:07 +0200},
	biburl = {https://dblp.org/rec/conf/www/KoYKK25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Fine-tuning pre-trained language models (PLMs) has recently shown a potential to improve knowledge graph completion (KGC). However, most PLM-based methods focus solely on encoding textual information, neglecting the long-tailed nature of knowledge graphs and their various topological structures, e.g., subgraphs, shortest paths, and degrees. We claim that this is a major obstacle to achieving higher accuracy of PLMs for KGC. To this end, we propose a Subgraph-Aware Training framework for KGC (SATKGC) with two ideas: (i) subgraph-aware mini-batching to encourage hard negative sampling and to mitigate an imbalance in the frequency of entity occurrences during training, and (ii) new contrastive learning to focus more on harder in-batch negative triples and harder positive triples in terms of the structural properties of the knowledge graph. To the best of our knowledge, this is the first study to comprehensively incorporate the structural inductive bias of the knowledge graph into fine-tuning PLMs. Extensive experiments on three KGC benchmarks demonstrate the superiority of SATKGC. Our code is available.https://github.com/meaningful96/SATKGC}
}


@inproceedings{DBLP:conf/www/LiWZFC025,
	author = {Zhao Li and
                  Xin Wang and
                  Jun Zhao and
                  Feng Feng and
                  Zirui Chen and
                  Jianxin Li},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {HySAE: An Efficient Semantic-Enhanced Representation Learning Model
                  for Knowledge Hypergraph Link Prediction},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {86--97},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714549},
	doi = {10.1145/3696410.3714549},
	timestamp = {Fri, 09 May 2025 20:28:07 +0200},
	biburl = {https://dblp.org/rec/conf/www/LiWZFC025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Representation learning technique is an effective link prediction paradigm to alleviate the incompleteness of knowledge hypergraphs. However, the n-ary complex semantic information inherent in knowledge hypergraphs causes existing methods to face the dual limitations of weak effectiveness and low efficiency. In this paper, we propose a novel knowledge hypergraph representation learning model, HySAE, which can achieve a satisfactory trade-off between effectiveness and efficiency. Concretely, HySAE builds an efficient semantic-enhanced  3D scalable end-to-end embedding architecture  to sufficiently capture knowledge hypergraph  n -ary complex semantic information with fewer parameters, which can significantly reduce the computational cost of the model. In particular, we also design an efficient position-aware entity role semantic embedding way and two enhanced semantic learning strategies to further improve the effectiveness and scalability of our proposed method. Extensive experimental results on all datasets demonstrate that HySAE consistently outperforms state-of-the-art baselines, with an average improvement of 9.15%, a maximum improvement of 39.44%, an average 10.39x faster, and 75.79% fewer parameters.}
}


@inproceedings{DBLP:conf/www/LiuZLYPY25,
	author = {Ben Liu and
                  Jihai Zhang and
                  Fangquan Lin and
                  Cheng Yang and
                  Min Peng and
                  Wotao Yin},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {SymAgent: {A} Neural-Symbolic Self-Learning Agent Framework for Complex
                  Reasoning over Knowledge Graphs},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {98--108},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714768},
	doi = {10.1145/3696410.3714768},
	timestamp = {Sun, 15 Jun 2025 16:48:59 +0200},
	biburl = {https://dblp.org/rec/conf/www/LiuZLYPY25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recent advancements have highlighted that Large Language Models (LLMs) are prone to hallucinations when solving complex reasoning problems, leading to erroneous results. To tackle this issue, researchers incorporate Knowledge Graphs (KGs) to improve the reasoning ability of LLMs. However, existing methods face two limitations: 1) they typically assume that all answers to the questions are contained in KGs, neglecting the incompleteness issue of KGs, and 2) they treat the KG as a static repository and overlook the implicit logical reasoning structures inherent in KGs. In this paper, we introduce SymAgent, an innovative neural-symbolic agent framework that achieves collaborative augmentation between KGs and LLMs. We conceptualize KGs as dynamic environments and transform complex reasoning tasks into a multi-step interactive process, enabling KGs to participate deeply in the reasoning process. SymAgent consists of two modules: Agent-Planner and Agent-Executor. The Agent-Planner leverages LLM's inductive reasoning capability to extract symbolic rules from KGs, guiding efficient question decomposition. The Agent-Executor autonomously invokes predefined action tools to integrate information from KGs and external documents, addressing the issues of KG incompleteness. Furthermore, we design a self-learning framework comprising online exploration and offline iterative policy updating phases, enabling the agent to automatically synthesize reasoning trajectories and improve performance. Experimental results demonstrate that SymAgent with weak LLM backbones (i.e., 7B series) yields better or comparable performance compared to various strong baselines. Further analysis reveals that our agent can identify missing triples, facilitating automatic KG updates.}
}


@inproceedings{DBLP:conf/www/YangYJGYLY25,
	author = {Shundong Yang and
                  Jing Yang and
                  Xiaowen Jiang and
                  Yuan Gao and
                  Laurence T. Yang and
                  Ruikun Luo and
                  Jieming Yang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Towards Multimodal Inductive Learning: Adaptively Embedding {MMKG}
                  via Prototypes},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {109--118},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714781},
	doi = {10.1145/3696410.3714781},
	timestamp = {Wed, 23 Apr 2025 16:35:50 +0200},
	biburl = {https://dblp.org/rec/conf/www/YangYJGYLY25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Multimodal Knowledge Graphs (MMKG) models integrate multimodal contexts to improve link prediction performance. All existing MMKG models follow the transductive setting with a fixed predefined set, meaning that all the entities, relations, and multimodal information in the test graph are observed during training. This hinders their generalization to real-world MMKG with unseen entities and relations. Intuitively, a MMKG model trained on DBpedia cannot infer on Freebase. To address above limitations, we make the first attempt towards inductive learning for MMKG and propose a multimodal <u> Ind </u>uctive <u> MMKG </u> model ( IndMKG ) that is <u> universal </u> and  transferable  to any MMKG. Distinct from existing transductive methods, our model does not rely on specific trained embeddings; instead, IndMKG generates adaptive embeddings conditioned on any new MMKG via multimodal prototypes. Specifically, we construct class-adaptive prototypes to appropriately characterize the multimodal feature distribution of the given graph and equip IndMKG with robust adaptability to multimodal information across MMKGs. In addition, IndMKG learns non-specific structural embeddings based on meta relations. Such strategies tackle the challenge of notable multimodal feature discrepancies in cross-graph induction and allow the pre-trained IndMKG model to effectively zero-shot generalize to any MMKG. The strong performance in both inductive and transductive settings, across more than 20+ different scenarios, confirms the effectiveness and robustness of IndMKG. Our code is released at https://github.com/MMKGer/IndMKG/.}
}


@inproceedings{DBLP:conf/www/LiuGWZBSC025,
	author = {Zhiqiang Liu and
                  Chengtao Gan and
                  Junjie Wang and
                  Yichi Zhang and
                  Zhongpu Bo and
                  Mengshu Sun and
                  Huajun Chen and
                  Wen Zhang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {OntoTune: Ontology-Driven Self-training for Aligning Large Language
                  Models},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {119--133},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714816},
	doi = {10.1145/3696410.3714816},
	timestamp = {Fri, 09 May 2025 20:28:07 +0200},
	biburl = {https://dblp.org/rec/conf/www/LiuGWZBSC025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Existing domain-specific Large Language Models (LLMs) are typically developed by fine-tuning general-purposed LLMs with large-scale domain-specific corpora. However, training on large-scale corpora often fails to effectively organize domain knowledge of LLMs, leading to fragmented understanding. Inspired by how humans connect concepts and organize knowledge through mind maps, we aim to emulate this approach by using  ontology  with hierarchical conceptual knowledge to reorganize LLM's domain knowledge. From this perspective, we propose an ontology-driven self-training framework called  OntoTune , which aims to align LLMs with ontology through in-context learning, enabling the generation of responses guided by the ontology. We leverage in-context learning to identify whether the LLM has acquired the specific concept's ontology knowledge, and select the entries not yet mastered by LLM as the training set to further align the LLM with ontology. Compared to existing domain LLMs based on newly collected large-scale domain-specific corpora, our OntoTune, which relies on the existing, long-term developed ontology and LLM itself, significantly reduces data maintenance costs and offers improved generalization ability. We conduct our study in the medical domain to evaluate the effectiveness of OntoTune, utilizing a standardized medical ontology, SNOMED CT as our ontology source. Experimental results demonstrate that OntoTune achieves state-of-the-art performance in both in-ontology task hypernym discovery and out-of-ontology task medical domain QA. Moreover, compared to the latest direct ontology injection method TaxoLLaMA, our OntoTune better preserves original knowledge of LLM. The code and data are available at https://github.com/zjukg/OntoTune.}
}


@inproceedings{DBLP:conf/www/FengG0HYX0SZS25,
	author = {Yu Feng and
                  Yangli{-}ao Geng and
                  Yifan Zhu and
                  Zongfu Han and
                  Xie Yu and
                  Kaiwen Xue and
                  Haoran Luo and
                  Mengyang Sun and
                  Guangwei Zhang and
                  Meina Song},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {{PM-MOE:} Mixture of Experts on Private Model Parameters for Personalized
                  Federated Learning},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {134--146},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714561},
	doi = {10.1145/3696410.3714561},
	timestamp = {Tue, 10 Jun 2025 14:16:06 +0200},
	biburl = {https://dblp.org/rec/conf/www/FengG0HYX0SZS25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated learning (FL) has gained widespread attention for its privacy-preserving and collaborative learning capabilities. Due to significant statistical heterogeneity, traditional FL struggles to generalize a shared model across diverse data domains. Personalized federated learning addresses this issue by dividing the model into a globally shared part and a locally private part, with the local model correcting representation biases introduced by the global model. Nevertheless, locally converged parameters more accurately capture domain-specific knowledge, and current methods overlook the potential benefits of these parameters. To address these limitations, we propose PM-MoE architecture. This architecture integrates a mixture of personalized modules and an energy-based personalized modules denoising, enabling each client to select beneficial personalized parameters from other clients. We applied the PM-MoE architecture to nine recent model-split-based personalized federated learning algorithms, achieving performance improvements with minimal additional training. Extensive experiments on six widely adopted datasets and two heterogeneity settings validate the effectiveness of our approach. The source code is available at https://github.com/dannis97500/PM-MOE.}
}


@inproceedings{DBLP:conf/www/0001L000L25,
	author = {Jiale Zhang and
                  Haoxuan Li and
                  Di Wu and
                  Xiaobing Sun and
                  Qinghua Lu and
                  Guodong Long},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Beyond Dataset Watermarking: Model-Level Copyright Protection for
                  Code Summarization Models},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {147--157},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714641},
	doi = {10.1145/3696410.3714641},
	timestamp = {Fri, 09 May 2025 20:28:07 +0200},
	biburl = {https://dblp.org/rec/conf/www/0001L000L25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Code Summarization Model (CSM) has been widely used in code production, such as online and web programming for PHP and Javascript. CSMs are essential tools in code production, enhancing software development efficiency and driving innovation in automated code analysis. However, CSMs face risks of exploitation by unauthorized users, particularly in an online environment where CSMs can be easily shared and disseminated. To address these risks, digital watermarks offer a promising solution by embedding imperceptible signatures within the models to assert copyright ownership and track unauthorized usage. Traditional watermarking for CSM copyright protection faces two main challenges: 1) dataset watermarking methods require separate design of triggers and watermark features based on the characteristics of different programming languages, which not only increases the computation complexity but also leads to a lack of generalization, 2) existing watermarks based on code style transformation are easily identifiable by automated detection, demonstrating poor concealment. To tackle these issues, we propose ModMark, a novel model-level digital watermark embedding method. Specifically, by fine-tuning the tokenizer, ModMark achieves cross-language generalization while reducing the complexity of watermark design. Moreover, we employ noise injection techniques to effectively prevent trigger detection. Experimental results show that our method can achieve 100% watermark verification rate across various programming languages' CSMs, and the concealment and effectiveness of ModMark can also be guaranteed. Our codes and datasets are available at https://github.com/Ocreatedin/ModMark.}
}


@inproceedings{DBLP:conf/www/ChenYZ000HMZ25,
	author = {Yibin Chen and
                  Yifu Yuan and
                  Zeyu Zhang and
                  Yan Zheng and
                  Jinyi Liu and
                  Fei Ni and
                  Jianye Hao and
                  Hangyu Mao and
                  Fuzheng Zhang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {SheetAgent: Towards a Generalist Agent for Spreadsheet Reasoning and
                  Manipulation via Large Language Models},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {158--177},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714962},
	doi = {10.1145/3696410.3714962},
	timestamp = {Fri, 09 May 2025 20:28:07 +0200},
	biburl = {https://dblp.org/rec/conf/www/ChenYZ000HMZ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Spreadsheets are ubiquitous across the World Wide Web, playing a critical role in enhancing work efficiency across various domains. Large language model (LLM) has been recently attempted for automatic spreadsheet manipulation but has not yet been investigated in complicated and realistic tasks where reasoning challenges exist (e.g., long horizon manipulation with multi-step reasoning and ambiguous requirements). To bridge the gap with the real-world requirements, we introduce  SheetRM , a benchmark featuring long-horizon and multi-category tasks with reasoning-dependent manipulation caused by real-life challenges. To mitigate the above challenges, we further propose  SheetAgent , a novel autonomous agent that utilizes the power of LLMs. SheetAgent consists of three collaborative modules:  Planner, Informer,  and  Retriever,  achieving both advanced reasoning and accurate manipulation over spreadsheets without human interaction through iterative task reasoning and reflection. Extensive experiments demonstrate that SheetAgent delivers 20--40% pass rate improvements on multiple benchmarks over baselines, achieving enhanced precision in spreadsheet manipulation and demonstrating superior table reasoning abilities. More details and visualizations are available at the https://sheetagent.github.io/. The datasets and source code are available at https://anonymous.4open.science/r/SheetAgent.}
}


@inproceedings{DBLP:conf/www/NazariRN25,
	author = {Amir Behrad Khorram Nazari and
                  Davood Rafiei and
                  Mario A. Nascimento},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {MixedSAND: Semantic Annotation of Mixed-unit Numeric Data},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {178--187},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714701},
	doi = {10.1145/3696410.3714701},
	timestamp = {Fri, 09 May 2025 20:28:07 +0200},
	biburl = {https://dblp.org/rec/conf/www/NazariRN25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Quantitative information about entities constitutes a significant portion of tabular data in open sources and data lakes. Such tables often lack consistent labeling and proper schema, posing significant challenges for querying and integration. This paper studies the problem of numerical column annotation in scenarios where quantitative data may be gathered from different sources and unit consistency is a concern. For instance, weight measurements may vary between entities, expressed in kilograms for some and pounds for others, with no accompanying unit information. We investigate the conditions for effectively annotating mixed-unit numeric data, introduce a benchmark for such an annotation task, and propose an algorithm that reliably detects semantic types (e.g., height) and links them to the corresponding types present in a knowledge graph. Our evaluation on a diverse set of columns with mixed units and varying levels of annotation difficulty shows that our method significantly outperforms strong baselines such as GPT-4o-mini and SAND in terms of accuracy, excelling in both detecting mixed units and annotating them with appropriate semantic labels.}
}


@inproceedings{DBLP:conf/www/LuoWMJLZ25,
	author = {Jiamin Luo and
                  Jingjing Wang and
                  Junxiao Ma and
                  Yujie Jin and
                  Shoushan Li and
                  Guodong Zhou},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Omni-SILA: Towards Omni-scene Driven Visual Sentiment Identifying,
                  Locating and Attributing in Videos},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {188--197},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714642},
	doi = {10.1145/3696410.3714642},
	timestamp = {Fri, 09 May 2025 20:28:07 +0200},
	biburl = {https://dblp.org/rec/conf/www/LuoWMJLZ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Prior studies on Visual Sentiment Understanding (VSU) primarily rely on the explicit scene information (e.g., facial expression) to judge visual sentiments, which largely ignore implicit scene information (e.g., human action, objection relation and visual background), while such information is critical for precisely discovering visual sentiments. Motivated by this, this paper proposes a new  Omni -scene driven visual  S entiment  I dentifying,  L ocating and  A ttributing in videos (Omni-SILA) task, aiming to interactively and precisely identify, locate and attribute visual sentiments through both explicit and implicit scene information. Furthermore, this paper believes that this Omni-SILA task faces two key challenges: modeling scene and highlighting implicit scene beyond explicit. To this end, this paper proposes an Implicit-enhanced Causal MoE (ICM) approach for addressing the Omni-SILA task. Specifically, a Scene-Balanced MoE (SBM) and an Implicit-Enhanced Causal (IEC) blocks are tailored to model scene information and highlight the implicit scene information beyond explicit, respectively. Extensive experimental results on our constructed explicit and implicit Omni-SILA datasets demonstrate the great advantage of the proposed ICM approach over advanced Video-LLMs.}
}


@inproceedings{DBLP:conf/www/Cai00Z00C25,
	author = {Hongru Cai and
                  Yongqi Li and
                  Wenjie Wang and
                  Fengbin Zhu and
                  Xiaoyu Shen and
                  Wenjie Li and
                  Tat{-}Seng Chua},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Large Language Models Empowered Personalized Web Agents},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {198--215},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714842},
	doi = {10.1145/3696410.3714842},
	timestamp = {Fri, 09 May 2025 20:28:07 +0200},
	biburl = {https://dblp.org/rec/conf/www/Cai00Z00C25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Web agents have emerged as a promising direction to automate Web task completion based on user instructions, significantly enhancing user experience. Recently, Web agents have evolved from traditional agents to Large Language Models (LLMs)-based Web agents. Despite their success, existing LLM-based Web agents overlook the importance of personalized data ( e.g. , user profiles and historical Web behaviors) in assisting the understanding of users' personalized instructions and executing customized actions. To overcome the limitation, we first formulate the task of LLM-empowered personalized Web agents, which integrate personalized data and user instructions to personalize instruction comprehension and action execution. To address the absence of a comprehensive evaluation benchmark, we construct a  Personal ized  W eb  A gent Benchmark (PersonalWAB), featuring user instructions, personalized user data, Web functions, and two evaluation paradigms across three personalized Web tasks. Moreover, we propose a  P ersonalized  U ser  M emory-enhanced  A lignment (PUMA) framework to adapt LLMs to the personalized Web agent task. PUMA utilizes a memory bank with a task-specific retrieval strategy to filter relevant historical Web behaviors. Based on the behaviors, PUMA then aligns LLMs for personalized action execution through fine-tuning and direct preference optimization. Extensive experiments validate the superiority of PUMA over existing Web agents on PersonalWAB.}
}


@inproceedings{DBLP:conf/www/0005ZL00HZ0SD0Z25,
	author = {Jun Yin and
                  Zhengxin Zeng and
                  Mingzheng Li and
                  Hao Yan and
                  Chaozhuo Li and
                  Weihao Han and
                  Jianjin Zhang and
                  Ruochen Liu and
                  Hao Sun and
                  Weiwei Deng and
                  Feng Sun and
                  Qi Zhang and
                  Shirui Pan and
                  Senzhang Wang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Unleash LLMs Potential for Sequential Recommendation by Coordinating
                  Dual Dynamic Index Mechanism},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {216--227},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714866},
	doi = {10.1145/3696410.3714866},
	timestamp = {Fri, 09 May 2025 20:28:07 +0200},
	biburl = {https://dblp.org/rec/conf/www/0005ZL00HZ0SD0Z25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Owing to the unprecedented capability in semantic understanding and logical reasoning, large language models (LLMs) have shown fantastic potential in developing next-generation sequential recommender systems (RSs). However, existing LLM-based sequential RSs mostly separate index generation from sequential recommendation, leading to insufficient integration between semantic information and collaborative information. On the other hand, the neglect of user-related information hinders LLM-based sequential RSs from exploiting high-order user-item interaction patterns. In this paper, we propose the End-to-End Dual Dynamic ( ED 2 ) recommender, the first LLM-based sequential RS which adopts dual dynamic index mechanism, targeting resolving the above limitations simultaneously. The dual dynamic index mechanism can not only assembly index generation and sequential recommendation into a unified LLM-backbone pipeline, but also make it practical for LLM-based sequential recommender to take advantage of user-related information. Specifically, to facilitate the LLM comprehension ability to dual dynamic index, we propose a multigrained token regulator which constructs alignment supervision based on LLMs semantic knowledge across multiple representation granularities. Moreover, the associated user collection data and a series of novel instruction tuning tasks are specially customized to capture the high-order user-item interaction patterns. Extensive experiments on three public datasets demonstrate the superiority of ED 2 , achieving an average improvement of 19.62% in Hit-Rate and 21.11% in NDCG.}
}


@inproceedings{DBLP:conf/www/Gao00LL0WGT25,
	author = {Jingtong Gao and
                  Bo Chen and
                  Xiangyu Zhao and
                  Weiwen Liu and
                  Xiangyang Li and
                  Yichao Wang and
                  Wanyu Wang and
                  Huifeng Guo and
                  Ruiming Tang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {LLM4Rerank: LLM-based Auto-Reranking Framework for Recommendations},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {228--239},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714922},
	doi = {10.1145/3696410.3714922},
	timestamp = {Fri, 09 May 2025 20:28:07 +0200},
	biburl = {https://dblp.org/rec/conf/www/Gao00LL0WGT25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Reranking is significant for recommender systems due to its pivotal role in refining recommendation results. Numerous reranking models have emerged to meet diverse reranking requirements in practical applications, which not only prioritize accuracy but also consider additional aspects such as diversity and fairness. However, most of the existing models struggle to strike a harmonious balance between these diverse aspects at the model level. Additionally, the scalability and personalization of these models are often limited by their complexity and a lack of attention to the varying importance of different aspects in diverse reranking scenarios. To address these issues, we propose LLM4Rerank, a comprehensive LLM-based reranking framework designed to bridge the gap between various reranking aspects while ensuring scalability and personalized performance. Specifically, we abstract different aspects into distinct nodes and construct a fully connected graph for LLM to automatically consider aspects like accuracy, diversity, fairness, and more, all in a coherent Chain-of-Thought (CoT) process. To further enhance personalization during reranking, we facilitate a customizable input mechanism that allows fine-tuning of LLM's focus on different aspects according to specific reranking needs. Experimental results on three widely used public datasets demonstrate that LLM4Rerank outperforms existing state-of-the-art reranking models across multiple aspects.}
}


@inproceedings{DBLP:conf/www/LiZLCRKL25,
	author = {Yuhan Li and
                  Xinni Zhang and
                  Linhao Luo and
                  Heng Chang and
                  Yuxiang Ren and
                  Irwin King and
                  Jia Li},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {G-Refer: Graph Retrieval-Augmented Large Language Model for Explainable
                  Recommendation},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {240--251},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714727},
	doi = {10.1145/3696410.3714727},
	timestamp = {Fri, 09 May 2025 20:28:07 +0200},
	biburl = {https://dblp.org/rec/conf/www/LiZLCRKL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Explainable recommendation has demonstrated significant advantages in informing users about the logic behind recommendations, thereby increasing system transparency, effectiveness, and trustworthiness. To provide personalized and interpretable explanations, existing works often combine the generation capabilities of large language models (LLMs) with collaborative filtering (CF) information. CF information extracted from the user-item interaction graph captures the user behaviors and preferences, which is crucial for providing informative explanations. However, due to the complexity of graph structure, effectively extracting the CF information from graphs still remains a challenge. Moreover, existing methods often struggle with the integration of extracted CF information with LLMs due to its implicit representation and the modality gap between graph structures and natural language explanations. To address these challenges, we propose  G-Refer , a framework using Graph Retrieval-augmented large language models (LLMs) for explainable recommendation. Specifically, we first employ a hybrid graph retrieval mechanism to retrieve explicit CF signals from both structural and semantic perspectives. The retrieved CF information is explicitly formulated as human-understandable text by the proposed graph translation and accounts for the explanations generated by LLMs. To bridge the modality gap, we introduce knowledge pruning and retrieval-augmented fine-tuning to enhance the ability of LLMs to process and utilize the retrieved CF information to generate explanations. Extensive experiments show that G-Refer achieves superior performance compared with existing methods in both explainability and stability. Codes and data are available at https://github.com/Yuhan1i/G-Refer.}
}


@inproceedings{DBLP:conf/www/Wang0S025,
	author = {Shuyao Wang and
                  Zhi Zheng and
                  Yongduo Sui and
                  Hui Xiong},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Unleashing the Power of Large Language Model for Denoising Recommendation},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {252--263},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714758},
	doi = {10.1145/3696410.3714758},
	timestamp = {Fri, 09 May 2025 20:28:07 +0200},
	biburl = {https://dblp.org/rec/conf/www/Wang0S025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recommender systems are crucial for personalizing user experiences but often depend on implicit feedback data, which can be noisy and misleading. Existing denoising studies involve incorporating auxiliary information or learning strategies from interaction data. However, they struggle with the inherent limitations of external knowledge and interaction data, as well as the non-universality of certain predefined assumptions, hindering accurate noise identification. Recently, large language models (LLMs) have gained attention for their extensive world knowledge and reasoning abilities, yet their potential in enhancing denoising in recommendations remains underexplored. In this paper, we introduce LLaRD, a framework leveraging LLMs to improve denoising in recommender systems, thereby boosting overall recommendation performance. Specifically, LLaRD generates denoising-related knowledge by first enriching semantic insights from observational data via LLMs and inferring user-item preference knowledge. It then employs a novel Chain-of-Thought (CoT) technique over user-item interaction graphs to reveal relation knowledge for denoising. Finally, it applies the Information Bottleneck (IB) principle to align LLM-generated denoising knowledge with recommendation targets, filtering out noise and irrelevant LLM knowledge. Empirical results demonstrate LLaRD's effectiveness in enhancing denoising and recommendation accuracy.}
}


@inproceedings{DBLP:conf/www/Xu0ZTYF025,
	author = {Yiyan Xu and
                  Wenjie Wang and
                  Yang Zhang and
                  Biao Tang and
                  Peng Yan and
                  Fuli Feng and
                  Xiangnan He},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Personalized Image Generation with Large Multimodal Models},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {264--274},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714843},
	doi = {10.1145/3696410.3714843},
	timestamp = {Fri, 09 May 2025 20:28:07 +0200},
	biburl = {https://dblp.org/rec/conf/www/Xu0ZTYF025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Personalized content filtering, such as recommender systems, has become a critical infrastructure to alleviate information overload. However, these systems merely filter existing content and are constrained by its limited diversity, making it difficult to meet users' varied content needs. To address this limitation, personalized content generation has emerged as a promising direction with broad applications. Nevertheless, most existing research focuses on personalized text generation, with relatively little attention given to personalized image generation. The limited work in personalized image generation faces challenges in accurately capturing users' visual preferences and needs from noisy user-interacted images and complex multimodal instructions. Worse still, there is a lack of supervised data for training personalized image generation models. To overcome the challenges, we propose a  P ersonalized  I mage  Ge nerati on  Framework  named Pigeon, which adopts exceptional large multimodal models with three dedicated modules to capture users' visual preferences and needs from noisy user history and multimodal instructions. To alleviate the data scarcity, we introduce a two-stage preference alignment scheme, comprising masked preference reconstruction and pairwise preference alignment, to align Pigeon with the personalized image generation task. We apply Pigeon to personalized sticker and movie poster generation, where extensive quantitative results and human evaluation highlight its superiority over various generative baselines.}
}


@inproceedings{DBLP:conf/www/ZhouLRZXCRHCLKW25,
	author = {Peilin Zhou and
                  Chao Liu and
                  Jing Ren and
                  Xinfeng Zhou and
                  Yueqi Xie and
                  Meng Cao and
                  Zhongtao Rao and
                  You{-}Liang Huang and
                  Dading Chong and
                  Junling Liu and
                  Jae Boum Kim and
                  Shoujin Wang and
                  Raymond Chi{-}Wing Wong and
                  Sunghun Kim},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {When Large Vision Language Models Meet Multimodal Sequential Recommendation:
                  An Empirical Study},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {275--292},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714764},
	doi = {10.1145/3696410.3714764},
	timestamp = {Thu, 12 Jun 2025 14:52:51 +0200},
	biburl = {https://dblp.org/rec/conf/www/ZhouLRZXCRHCLKW25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As multimedia content continues to grow on the web, the integration of visual and textual data has become a crucial challenge for web applications, particularly in recommendation systems. Large Vision Language Models (LVLMs) have demonstrated considerable potential in addressing this challenge across various tasks that require such multimodal integration. However, their application in multimodal sequential recommendation (MSR) has not been extensively studied. To bridge this gap, we introduce  MSRBench,  the first comprehensive benchmark designed to systematically evaluate different LVLM integration strategies in web-based recommendation scenarios. We benchmark three state-of-the-art LVLMs, i.e., GPT-4 Vision, GPT-4o, and Claude-3-Opus, on the next item prediction task using the constructed Amazon Review Plus dataset, which includes additional item descriptions generated by LVLMs. Our evaluation examines five integration strategies: using LVLMs as  recommender, item enhancer, reranker,  and various combinations of these roles. The benchmark results reveal that 1) using LVLMs as rerankers is the most effective strategy, significantly outperforming others that rely on LVLMs to directly generate recommendations or only enhance items; 2) GPT-4o consistently achieves the best performance across most scenarios, particularly when employed as a reranker; 3) the computational inefficiency of LVLMs presents a major barrier to their widespread adoption in real-time multimodal recommendation systems. Our code and datasets are available at https://github.com/PALIN2018/MSRBench.}
}


@inproceedings{DBLP:conf/www/CheeWGMZ25,
	author = {Heng Er Metilda Chee and
                  Jiayin Wang and
                  Zhiqiang Guo and
                  Weizhi Ma and
                  Min Zhang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {PerSRV: Personalized Sticker Retrieval with Vision-Language Model},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {293--303},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714772},
	doi = {10.1145/3696410.3714772},
	timestamp = {Fri, 09 May 2025 20:28:07 +0200},
	biburl = {https://dblp.org/rec/conf/www/CheeWGMZ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Instant Messaging is a popular mean for daily communication, allowing users to send text and stickers. As the saying goes, ''a picture is worth a thousand words'', so developing an effective sticker retrieval technique is crucial for enhancing user experience. However, existing sticker retrieval methods rely on labeled data to interpret stickers, and general-purpose Vision-Language Models (VLMs) often struggle to capture the unique semantics of stickers. Additionally, relevant-based sticker retrieval methods lack personalization, creating a gap between diverse user expectations and retrieval results. To address these, we propose the Personalized Sticker Retrieval with Vision-Language Model framework, namely PerSRV, structured into offline calculations and online processing modules. The online retrieval part follows the paradigm of relevant recall and personalized ranking, supported by the offline pre-calculation parts, which are sticker semantic understanding, utility evaluation and personalization modules. Firstly, for sticker-level semantic understanding, we supervised fine-tuned LLaVA-1.5-7B to generate human-like sticker semantics, complemented by textual content extracted from figures and historical interaction queries. Secondly, we investigate three crowd-sourcing metrics for sticker utility evaluation. Thirdly, we cluster style centroids based on users' historical interactions to achieve personal preference modeling. Finally, we evaluate our proposed PerSRV method on a public sticker retrieval dataset from WeChat, containing 543,098 candidates and 12,568 interactions. Experimental results show that PerSRV significantly outperforms existing methods in multi-modal sticker retrieval. Additionally, our supervised fine-tuned VLM delivers notable improvements in sticker semantic understandings. The code and fine-tuned LLaVA model for sticker understanding are publicly available.}
}


@inproceedings{DBLP:conf/www/WangXHSZW25,
	author = {Yihan Wang and
                  Fei Xiong and
                  Zhexin Han and
                  Qi Song and
                  Kaiqiao Zhan and
                  Ben Wang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Unleashing the Potential of Two-Tower Models: Diffusion-Based Cross-Interaction
                  for Large-Scale Matching},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {304--312},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714829},
	doi = {10.1145/3696410.3714829},
	timestamp = {Fri, 09 May 2025 20:28:07 +0200},
	biburl = {https://dblp.org/rec/conf/www/WangXHSZW25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Two-tower models are widely adopted in the industrial-scale matching stage across a broad range of application domains, such as content recommendations, advertisement systems, and search engines. This model efficiently handles large-scale candidate item screening by separating user and item representations. However, the decoupling network also leads to a neglect of potential information interaction between the user and item representations. Current state-of-the-art (SOTA) approaches include adding a shallow fully connected layer(i.e., COLD), which is limited by performance and can only be used in the ranking stage. For performance considerations, another approach attempts to capture historical positive interaction information from the other tower by regarding them as the input features(i.e., DAT). Later research showed that the gains achieved by this method are still limited because of lacking the guidance on the next user intent. To address the aforementioned challenges, we propose a "cross-interaction decoupling architecture" within our matching paradigm. This user-tower architecture leverages a diffusion module to reconstruct the next positive intention representation and employs a mixed-attention module to facilitate comprehensive cross-interaction. During the next positive intention generation, we further enhance the accuracy of its reconstruction by explicitly extracting the temporal drift within user behavior sequences. Experiments on two real-world datasets and one industrial dataset demonstrate that our method outperforms the SOTA two-tower models significantly, and our diffusion approach outperforms other generative models in reconstructing item representations.}
}


@inproceedings{DBLP:conf/www/HuR0WZK025,
	author = {Songwen Hu and
                  Ryan A. Rossi and
                  Tong Yu and
                  Junda Wu and
                  Handong Zhao and
                  Sungchul Kim and
                  Shuai Li},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Interactive Visualization Recommendation with Hier-SUCB},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {313--321},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714697},
	doi = {10.1145/3696410.3714697},
	timestamp = {Fri, 09 May 2025 20:28:07 +0200},
	biburl = {https://dblp.org/rec/conf/www/HuR0WZK025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Visualization recommendation aims to enable rapid visual analysis of massive datasets. In real-world scenarios, it is essential to quickly gather and comprehend user preferences to cover users from diverse backgrounds, including varying skill levels and analytical tasks. Previous approaches to personalized visualization recommendations are non-interactive and rely on initial user data for new users. As a result, these models cannot effectively explore options or adapt to real-time feedback. To address this limitation, we propose an interactive personalized visualization recommendation (PVisRec) system that learns on user feedback from previous interactions. For more interactive and accurate recommendations, we propose Hier-SUCB, a contextual combinatorial semi-bandit in the PVisRec setting. Theoretically, we show an improved overall regret bound with the same rank of time but an improved rank of action space. We further demonstrate the effectiveness of Hier-SUCB through extensive experiments where it is comparable to offline methods and outperforms other bandit algorithms in the setting of visualization recommendation.}
}


@inproceedings{DBLP:conf/www/ZhangSYLX25,
	author = {Huanyu Zhang and
                  Xiaoxuan Shen and
                  Baolin Yi and
                  Jianfang Liu and
                  Yinao Xie},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {A Plug-in Critiquing Approach for Knowledge Graph Recommendation Systems
                  via Representative Sampling},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {322--333},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714808},
	doi = {10.1145/3696410.3714808},
	timestamp = {Fri, 09 May 2025 20:28:07 +0200},
	biburl = {https://dblp.org/rec/conf/www/ZhangSYLX25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Incorporating a critiquing component into recommender applications facilitates the enhancement of user perception. Typically, critique-able recommender systems adapt the model parameters and update the recommendation list in real-time through the analysis of user critiquing keyphrases in the inference phase. The current critiquing methods necessitate the designation of a dedicated recommendation model to estimate user relevance to the critiquing keyphrase during the training phase preceding the recommendations update. This paradigm restricts the applicable scenarios and reduces the potential for keyphrase exploitation. Furthermore, these approaches ignore the issue of catastrophic forgetting caused by continuous modification of model parameters in multi-step critiquing. Thus, we present a general  R epresentative  I tems  S ampling Framework for  C ritiquing on Knowledge Graph Recommendation  (RISC) implemented as a plug-in, which offers a new paradigm for critiquing in mainstream recommendation scenarios. RISC leverages the knowledge graph to sample important representative items as a hinge to expand and convey information from user critiquing, indirectly estimating the relevance of the user to the critiquing keyphrase. Consequently, the necessity for specialized user-keyphrase correlation modules is eliminated with respect to a variety of knowledge graph recommendation models. Moreover, we propose a Weight Experience Replay (WER) approach based on KG to mitigate catastrophic forgetting by reinforcing the user's prior preferences during the inference phase. Our extensive experimental findings on three real-world datasets and three knowledge graph recommendation methods illustrate that RISC with WER can be effectively integrated into knowledge graph recommendation models to efficiently utilize user critiquing for refining recommendations and mitigate catastrophic forgetting.}
}


@inproceedings{DBLP:conf/www/ZhaoYLL0ZG025,
	author = {Chu Zhao and
                  Enneng Yang and
                  Yuliang Liang and
                  Pengxiang Lan and
                  Yuting Liu and
                  Jianzhe Zhao and
                  Guibing Guo and
                  Xingwei Wang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Graph Representation Learning via Causal Diffusion for Out-of-Distribution
                  Recommendation},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {334--346},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714849},
	doi = {10.1145/3696410.3714849},
	timestamp = {Fri, 09 May 2025 20:28:07 +0200},
	biburl = {https://dblp.org/rec/conf/www/ZhaoYLL0ZG025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graph Neural Networks (GNNs)-based recommendation algorithms typically assume that training and testing data are drawn from independent and identically distributed (IID) spaces. However, this assumption often fails in the presence of out-of-distribution (OOD) data, resulting in significant performance degradation. In this study, we construct a Structural Causal Model (SCM) to analyze interaction data, revealing that environmental confounders (e.g., the COVID-19 pandemic) lead to unstable correlations in GNN-based models, thus impairing their generalization to OOD data. To address this issue, we propose a novel approach, graph representation learning via causal diffusion ( CausalDiffRec ) for OOD recommendation. This method enhances the model's generalization on OOD data by eliminating environmental confounding factors and learning invariant graph representations. Specifically, we use backdoor adjustment and variational inference to infer the real environmental distribution, thereby eliminating the impact of environmental confounders. This inferred distribution is then used as prior knowledge to guide the representation learning in the reverse phase of the diffusion process to learn the invariant representation. In addition,we provide a theoretical derivation that proves optimizing the objective function of CausalDiffRec can encourage the model to learn environment-invariant graph representations, thereby achieving excellent generalization performance in recommendations under distribution shifts. Our extensive experiments validate the effectiveness of CausalDiffRec in improving the generalization of OOD data, and the average improvement is up to 10.69% on Food, 18.83% on KuaiRec, 22.41% on Yelp2018, and 11.65% on Douban datasets.}
}


@inproceedings{DBLP:conf/www/Li025,
	author = {Anchen Li and
                  Bo Yang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Dual Graph Denoising Model for Social Recommendation},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {347--356},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714874},
	doi = {10.1145/3696410.3714874},
	timestamp = {Fri, 09 May 2025 20:28:07 +0200},
	biburl = {https://dblp.org/rec/conf/www/Li025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graph-based social recommender systems utilize user-item interaction graphs and user-user social graphs to model user preferences. However, their performance can be limited by redundant and noisy information in these two graphs. Although several recommender studies on data denoising exist, most either rely on heuristic assumptions, which limit their adaptability, or use a single model that combines denoising and recommendation, potentially imposing substantial demands on the model capacity. To address these issues, we propose a dual Graph Denoising Social Recommender (GDSR), which consists of two steps: graph denoising and user preference prediction. First, we design a denoising module which exploits a dual diffusion model to alleviate noises in the interaction and social graphs by performing multi-step noise diffusion and removal. We develop three kinds of conditions to guide our dual graph diffusion paradigm and propose a cross-domain signal guidance mechanism to enhance the structure of denoised graphs. Second, we devise a recommender module that employs a dual graph learning structure on denoised graphs to generate recommendations. Moreover, we use additional supervision signals from the diffusion-enhanced data augmentation to introduce a graph contrastive learning task, enhancing the recommender module's representation quality and robustness. Experiment results show the effectiveness of our GDSR.}
}


@inproceedings{DBLP:conf/www/WuLCLCNJJS025,
	author = {Xinyi Wu and
                  Donald Loveland and
                  Runjin Chen and
                  Yozen Liu and
                  Xin Chen and
                  Leonardo Neves and
                  Ali Jadbabaie and
                  Mingxuan Ju and
                  Neil Shah and
                  Tong Zhao},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {GraphHash: Graph Clustering Enables Parameter Efficiency in Recommender
                  Systems},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {357--369},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714910},
	doi = {10.1145/3696410.3714910},
	timestamp = {Fri, 11 Jul 2025 18:29:43 +0200},
	biburl = {https://dblp.org/rec/conf/www/WuLCLCNJJS025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Deep recommender systems rely heavily on large embedding tables to handle high-cardinality categorical features such as user/item identifiers, and face significant memory constraints at scale. To tackle this challenge, hashing techniques are often employed to map multiple entities to the same embedding and thus reduce the size of the embedding tables. Concurrently, graph-based collaborative signals have emerged as powerful tools in recommender systems, yet their potential for optimizing embedding table reduction remains unexplored. This paper introduces GraphHash, the first graph-based approach that leverages modularity-based bipartite graph clustering on user-item interaction graphs to reduce embedding table sizes. We demonstrate that the modularity objective has a theoretical connection to message-passing, which provides a foundation for our method. By employing fast clustering algorithms, GraphHash serves as a computationally efficient proxy for message-passing during preprocessing and a plug-and-play graph-based alternative to traditional ID hashing. Extensive experiments show that GraphHash substantially outperforms diverse hashing baselines on both retrieval and click-through-rate prediction tasks. In particular, GraphHash achieves on average a 101.52% improvement in recall when reducing the embedding table size by more than 75%, highlighting the value of graph-based collaborative information for model reduction. Our code is available at https://github.com/snap-research/GraphHash.}
}


@inproceedings{DBLP:conf/www/Sun0DZO25,
	author = {Youchen Sun and
                  Zhu Sun and
                  Yingpeng Du and
                  Jie Zhang and
                  Yew Soon Ong},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Model-Agnostic Social Network Refinement with Diffusion Models for
                  Robust Social Recommendation},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {370--378},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714683},
	doi = {10.1145/3696410.3714683},
	timestamp = {Fri, 09 May 2025 20:28:07 +0200},
	biburl = {https://dblp.org/rec/conf/www/Sun0DZO25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Social recommendations (SRs) aim to enhance preference modeling by integrating social networks. However, their effectiveness is mainly constrained by two factors: the noisy social connections that may not reflect shared interests, and the limited number of social connections for most users, which hampers the system's ability to fully leverage social influence. Therefore, it is essential to perform social network refinement by removing noisy connections and adding meaningful ones for robust SRs. Inspired by the denoising capability of generative diffusion models, we propose a Model-Agnostic Social Network Refinement framework with Diffusion Models for Robust Social Recommendation (ARD-SR). Specifically, in the forward process, we corrupt the social network by progressively adding position-specific Gaussian noise calibrated to the user preference similarity, better simulating how the social network responds to noise perturbations. The reverse process learns to denoise, guided by each user's neighborhood preferences from the SR backbone, generating a tailored social network aligned with each user's preference for establishing connections. For effective learning, we design a curriculum-based training mechanism that progressively introduces challenging samples characterized by high sparsity or high noise levels. Finally, ARD-SR and the SR backbone are alternately trained, ensuring a continuous mutual enhancement between the social network refinement and the backbone's user representation learning. To further enhance the quality of the refined social network, (1) we introduce a preference-guided flip operation during inference to improve the input quality; and (2) we modify social connections based on the exponential weighted moving average of ARD-SR's predictions across epochs to reduce fluctuations. Experiments on three datasets show that ARD-SR significantly improves SR performance across multiple SR backbones. The code is released at https://github.com/sunyc123r/ARD-SR.}
}


@inproceedings{DBLP:conf/www/Wang00LH0X25,
	author = {Xiaobei Wang and
                  Shuchang Liu and
                  Qingpeng Cai and
                  Xiang Li and
                  Lantao Hu and
                  Han Li and
                  Guangming Xie},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Value Function Decomposition in Markov Recommendation Process},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {379--390},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714807},
	doi = {10.1145/3696410.3714807},
	timestamp = {Fri, 09 May 2025 20:28:07 +0200},
	biburl = {https://dblp.org/rec/conf/www/Wang00LH0X25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recent advances in recommender systems have shown that user-system interaction essentially formulates long-term optimization problems, and online reinforcement learning can be adopted to improve recommendation performance. The general solution framework incorporates a value function that estimates the user's expected cumulative rewards in the future and guides the training of the recommendation policy. To avoid local maxima, the policy may explore potential high-quality actions during inference to increase the chance of finding better future rewards. To accommodate the stepwise recommendation process, one widely adopted approach to learning the value function is learning from the difference between the values of two consecutive states of a user. However, we argue that this paradigm involves a challenge of Mixing Random Factors: there exist two random factors from the stochastic policy and the uncertain user environment, but they are not separately modeled in the standard temporal difference (TD) learning, which may result in a suboptimal estimation of the long-term rewards and less effective action exploration. As a solution, we show that these two factors can be separately approximated by decomposing the original temporal difference loss. The disentangled learning framework can achieve a more accurate estimation with faster learning and improved robustness against action exploration. As an empirical verification of our proposed method, we conduct offline experiments with simulated online environments built on the basis of public datasets.}
}


@inproceedings{DBLP:conf/www/Xue00H0G025,
	author = {Zhenghai Xue and
                  Qingpeng Cai and
                  Bin Yang and
                  Lantao Hu and
                  Peng Jiang and
                  Kun Gai and
                  Bo An},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {{AURO:} Reinforcement Learning for Adaptive User Retention Optimization
                  in Recommender Systems},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {391--401},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714956},
	doi = {10.1145/3696410.3714956},
	timestamp = {Fri, 09 May 2025 20:28:07 +0200},
	biburl = {https://dblp.org/rec/conf/www/Xue00H0G025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The field of Reinforcement Learning (RL) has garnered increasing attention for its ability of optimizing user retention in recommender systems. A primary obstacle in this optimization process is the environment non-stationarity stemming from the continual and complex evolution of user behavior patterns over time, such as variations in interaction rates and retention propensities. These changes pose significant challenges to existing RL algorithms for recommendations, leading to issues with dynamics and reward distribution shifts. This paper introduces a novel approach called  A daptive  U ser  R etention  O ptimization (AURO) to address this challenge. To navigate the recommendation policy in non-stationary environments, AURO introduces an state abstraction module in the policy network. The module is trained with a new value-based loss function, aligning its output with the estimated performance of the current policy. As the policy performance of RL is sensitive to environment drifts, the loss function enables the state abstraction to be reflective of environment changes and notify the recommendation policy to adapt accordingly. Additionally, the non-stationarity of the environment introduces the problem of implicit cold start, where the recommendation policy continuously interacts with users displaying novel behavior patterns. AURO encourages exploration guarded by performance-based rejection sampling to maintain a stable recommendation quality in the cost-sensitive online environment. Extensive empirical analysis are conducted in a user retention simulator, the MovieLens dataset, and a live short-video recommendation platform, demonstrating AURO's superior performance against all evaluated baseline algorithms. Code is available at https://github.com/AIDefender/AURO}
}


@inproceedings{DBLP:conf/www/0001C025,
	author = {Siyu Wang and
                  Xiaocong Chen and
                  Lina Yao},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Policy-Guided Causal State Representation for Offline Reinforcement
                  Learning Recommendation},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {402--412},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714562},
	doi = {10.1145/3696410.3714562},
	timestamp = {Fri, 09 May 2025 20:28:07 +0200},
	biburl = {https://dblp.org/rec/conf/www/0001C025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In offline reinforcement learning-based recommender systems (RLRS), learning effective state representations is crucial for capturing user preferences that directly impact long-term rewards. However, raw state representations often contain high-dimensional, noisy information and components that are not causally relevant to the reward. Additionally, missing transitions in offline data make it challenging to accurately identify features that are most relevant to user satisfaction. To address these challenges, we propose Policy-Guided Causal Representation (PGCR), a novel two-stage framework for causal feature selection and state representation learning in offline RLRS. In the first stage, we learn a causal feature selection policy that generates modified states by isolating and retaining only the causally relevant components (CRCs) while altering irrelevant components. This policy is guided by a reward function based on the Wasserstein distance, which measures the causal effect of state components on the reward and encourages the preservation of CRCs that directly influence user interests. In the second stage, we train an encoder to learn compact state representations by minimizing the mean squared error (MSE) loss between the latent representations of the original and modified states, ensuring that the representations focus on CRCs. We provide a theoretical analysis proving the identifiability of causal effects from interventions, validating the ability of PGCR to isolate critical state components for decision-making. Extensive experiments demonstrate that PGCR significantly improves recommendation performance, confirming its effectiveness for offline RL-based recommender systems.}
}


@inproceedings{DBLP:conf/www/WangLL0LCC25,
	author = {Haolin Wang and
                  Lin Liu and
                  Jiuyong Li and
                  Ziqi Xu and
                  Jixue Liu and
                  Zehong Cao and
                  Debo Cheng},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Off-policy Evaluation for Multiple Actions in the Presence of Unobserved
                  Confounders},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {413--424},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714924},
	doi = {10.1145/3696410.3714924},
	timestamp = {Fri, 09 May 2025 20:28:07 +0200},
	biburl = {https://dblp.org/rec/conf/www/WangLL0LCC25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Off-policy evaluation (OPE) is a crucial problem in reinforcement learning (RL), where the goal is to estimate the long-term cumulative reward of a target policy using historical data generated by a potentially different behaviour policy. In many real-world applications, such as precision medicine and recommendation systems, unobserved confounders may influence the action, reward, and state transition dynamics, which leads to biased estimates if not properly addressed. While existing methods for handling unobserved confounders in OPE focus on single-action settings, they are less effective in multi-action scenarios commonly found in practical applications, where an agent can take multiple actions simultaneously. In this paper, we propose a novel auxiliary variable-aided method for OPE in multi-action settings with unobserved confounders. Our approach overcomes the limitations of traditional auxiliary variable methods for multi-action scenarios by requiring only a single auxiliary variable, relaxing the need for as many auxiliary variables as the actions. Through theoretical analysis, we prove that our method provides an unbiased estimation of the target policy value. Empirical evaluations demonstrate that our estimator achieves better performance compared to existing baseline methods, highlighting its effectiveness and reliability in addressing unobserved confounders in multi-action OPE settings.}
}


@inproceedings{DBLP:conf/www/Mao0LLLH25,
	author = {Wenyu Mao and
                  Shuchang Liu and
                  Haoyang Liu and
                  Haozhe Liu and
                  Xiang Li and
                  Lantao Hu},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Distinguished Quantized Guidance for Diffusion-based Sequence Recommendation},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {425--435},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714955},
	doi = {10.1145/3696410.3714955},
	timestamp = {Tue, 13 May 2025 07:31:05 +0200},
	biburl = {https://dblp.org/rec/conf/www/Mao0LLLH25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Diffusion models (DMs) have emerged as promising approaches for sequential recommendation due to their strong ability to model data distributions and generate high-quality items. Existing work typically adds noise to the next item and progressively denoises it guided by the user's interaction sequence, generating items that closely align with user interests. However, we identify two key issues in this paradigm. First, the sequences are often heterogeneous in length and content, exhibiting noise due to stochastic user behaviors. Using such sequences as guidance may hinder DMs from accurately understanding user interests. Second, DMs are prone to data bias and tend to generate only the popular items that dominate the training dataset, thus failing to meet the personalized needs of different users. To address these issues, we propose Distinguished Quantized Guidance for Diffusion-based Sequence Recommendation (DiQDiff), which aims to extract robust guidance to understand user interests and generate distinguished items for personalized user interests within DMs. To extract robust guidance, DiQDiff introduces Semantic Vector Quantization (SVQ) to quantize sequences into semantic vectors (e.g., collaborative signals and category interests) using a codebook, which can enrich the guidance to better understand user interests. To generate distinguished items, DiQDiff personalizes the generation through Contrastive Discrepancy Maximization (CDM), which maximizes the distance between denoising trajectories using contrastive loss to prevent biased generation for different users. Extensive experiments are conducted to compare DiQDiff with multiple baseline models across four widely-used datasets. The superior recommendation performance of DiQDiff against leading approaches demonstrates its effectiveness in sequential recommendation tasks.}
}


@inproceedings{DBLP:conf/www/LovelandWZKSJ25,
	author = {Donald Loveland and
                  Xinyi Wu and
                  Tong Zhao and
                  Danai Koutra and
                  Neil Shah and
                  Mingxuan Ju},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Understanding and Scaling Collaborative Filtering Optimization from
                  the Perspective of Matrix Rank},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {436--449},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714904},
	doi = {10.1145/3696410.3714904},
	timestamp = {Fri, 11 Jul 2025 18:29:43 +0200},
	biburl = {https://dblp.org/rec/conf/www/LovelandWZKSJ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Collaborative Filtering (CF) methods dominate real-world recommender systems given their ability to learn high-quality, sparse ID-embedding tables that effectively capture user preferences. These tables scale linearly with the number of users and items, and are trained to ensure high similarity between embeddings of interacted user-item pairs, while maintaining low similarity for non-interacted pairs. Despite their high performance, encouraging dispersion for non-interacted pairs necessitates expensive regularization (e.g., negative sampling), hurting runtime and scalability. Existing research tends to address these challenges by simplifying the learning process, either by reducing model complexity or sampling data, trading performance for runtime. In this work, we move beyond model-level modifications and study the properties of the embedding tables under different learning strategies. Through theoretical analysis, we find that the singular values of the embedding tables are intrinsically linked to different CF loss functions. These findings are empirically validated on real-world datasets, demonstrating the practical benefits of higher stable rank -- a continuous version of matrix rank which encodes the distribution of singular values. Based on these insights, we propose an efficient warm-start strategy that regularizes the stable rank of the user and item embeddings. We show that stable rank regularization during early training phases can promote higher-quality embeddings, resulting in training speed improvements of up to 65.9%. Additionally, stable rank regularization can act as a proxy for negative sampling, allowing for performance gains of up to 21.2% over loss functions with small negative sampling ratios. Overall, our analysis unifies current CF methods under a new perspective -- their optimization of stable rank -- motivating a flexible regularization method that is easy to implement, yet effective at enhancing CF systems.}
}


@inproceedings{DBLP:conf/www/WangXWL025,
	author = {Cheng Wang and
                  Wenchao Xu and
                  Haozhao Wang and
                  Wei Liu and
                  Ruixuan Li},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Privacy-Friendly Cross-Domain Recommendation via Distilling User-irrelevant
                  Information},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {450--461},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714580},
	doi = {10.1145/3696410.3714580},
	timestamp = {Fri, 09 May 2025 20:28:07 +0200},
	biburl = {https://dblp.org/rec/conf/www/WangXWL025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Privacy-preserving Cross-Domain Recommendation (CDR) has been extensively studied to address the cold-start problem using auxiliary source domains while simultaneously protecting sensitive information. However, existing privacy-preserving CDR methods rely heavily on transferring sensitive user embeddings or behaviour logs, which leads to adopt privacy methods to distort the data patterns before transferring it to the target domain. The distorted information can compromise overall performance during the knowledge transfer process. To overcome these challenges, our approach differs from existing privacy-preserving methods that focus on safeguarding user-sensitive information. Instead, we concentrate on distilling transferable knowledge from insensitive item embeddings, which we refer to as  prototypes.  Specifically, we propose a conditional model inversion mechanism to accurately distill prototypes for individual users. We have designed a new data format and corresponding learning paradigm for distilling transferable prototypes from traditional recommendation models using model inversion. These prototypes facilitate bridging the domain shift between distinct source and target domains in a privacy-friendly manner. Additionally, they enable the identification of top-k users in the target domain to substitute for cold-start users prediction. We conduct extensive experiments across large real-world datasets, and the results substantiate the effectiveness of PFCDR https://github.com/walcheng/PFCDR.}
}


@inproceedings{DBLP:conf/www/XingMDHZZ25,
	author = {Haibo Xing and
                  Kanefumi Matsuyama and
                  Hao Deng and
                  Jinxin Hu and
                  Yu Zhang and
                  Xiaoyi Zeng},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {{ESANS:} Effective and Semantic-Aware Negative Sampling for Large-Scale
                  Retrieval Systems},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {462--471},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714600},
	doi = {10.1145/3696410.3714600},
	timestamp = {Fri, 09 May 2025 20:28:07 +0200},
	biburl = {https://dblp.org/rec/conf/www/XingMDHZZ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Industrial recommendation systems typically involve a two-stage process: retrieval and ranking, which aims to match users with millions of items. In the retrieval stage, classic embedding-based retrieval (EBR) methods depend on effective negative sampling techniques to enhance both performance and efficiency. However, existing techniques often suffer from false negatives, high cost for ensuring sampling quality and semantic information deficiency. To address these limitations, we propose Effective and Semantic-Aware Negative Sampling (ESANS), which integrates two key components: Effective Dense Interpolation Strategy (EDIS) and Multimodal Semantic-Aware Clustering (MSAC). EDIS generates virtual samples within the low-dimensional embedding space to improve the diversity and density of the sampling distribution while minimizing computational costs. MSAC refines the negative sampling distribution by hierarchically clustering item representations based on multimodal information (visual, textual, behavioral), ensuring semantic consistency and reducing false negatives. Extensive offline and online experiments demonstrate the superior efficiency and performance of ESANS.}
}


@inproceedings{DBLP:conf/www/QinL0025,
	author = {Jiarui Qin and
                  Weiwen Liu and
                  Weinan Zhang and
                  Yong Yu},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {{D2K:} Turning Historical Data into Retrievable Knowledge for Recommender
                  Systems},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {472--482},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714664},
	doi = {10.1145/3696410.3714664},
	timestamp = {Fri, 09 May 2025 20:28:07 +0200},
	biburl = {https://dblp.org/rec/conf/www/QinL0025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A vast amount of user behavior data is constantly accumulating on today's large recommendation platforms, recording users' various interests and tastes. Preserving knowledge from the old data while new data continually arrives is a vital problem for recommender systems. Existing approaches generally seek to save the knowledge implicitly in the model parameters. However, such a parameter-centric approach lacks scalability and flexibility---the capacity is hard to scale, and the knowledge is inflexible to utilize. Hence, in this work, we propose a framework that turns massive user behavior <u>d</u>ata <u>to</u> retrievable <u>k</u>nowledge (D2K). It is a  data-centric  approach that is model-agnostic and easy to scale up. Different from only storing unary knowledge such as the user-side or item-side information, D2K propose to store  ternary knowledge  for recommendation, which is determined by the complete recommendation factors---user, item, and context. The knowledge retrieved by target samples can be directly used to enhance the performance of any recommendation algorithms. Specifically, we introduce a Transformer-based knowledge encoder to transform the old data into knowledge with the user-item-context cross features. A personalized knowledge adaptation unit is devised to effectively exploit the information from the knowledge base by adapting the retrieved knowledge to the target samples. Extensive experiments demonstrate the superiority of the proposed method.}
}


@inproceedings{DBLP:conf/www/HuangQLF0025,
	author = {Junjie Huang and
                  Jiarui Qin and
                  Jianghao Lin and
                  Ziming Feng and
                  Weinan Zhang and
                  Yong Yu},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Unleashing the Potential of Multi-Channel Fusion in Retrieval for
                  Personalized Recommendations},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {483--494},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714753},
	doi = {10.1145/3696410.3714753},
	timestamp = {Fri, 09 May 2025 20:28:07 +0200},
	biburl = {https://dblp.org/rec/conf/www/HuangQLF0025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recommender systems (RS) are pivotal in managing information overload in modern digital services. A key challenge in RS is efficiently processing vast item pools to deliver highly personalized recommendations under strict latency constraints. Multi-stage cascade ranking addresses this by employing computationally efficient retrieval methods to cover diverse user interests, followed by more precise ranking models to refine the results. In the retrieval stage, multi-channel retrieval is often used to generate distinct item subsets from different candidate generators, leveraging the complementary strengths of these methods to maximize coverage. However, forwarding all retrieved items overwhelms downstream rankers, necessitating truncation. Despite advancements in individual retrieval methods,  multi-channel fusion , the process of efficiently merging multi-channel retrieval results, remains underexplored.  We are the first to identify and systematically investigate multi-channel fusion in the retrieval stage.  Current industry practices often rely on heuristic approaches and manual designs, which often lead to suboptimal performance. Moreover, traditional gradient-based methods like SGD are unsuitable for this task due to the non-differentiable nature of the selection process. In this paper, we explore advanced channel fusion strategies by assigning systematically optimized weights to each channel. We utilize black-box optimization techniques, including the Cross Entropy Method and Bayesian Optimization for global weight optimization, alongside policy gradient-based approaches for personalized merging. Our methods enhance both personalization and flexibility, achieving significant performance improvements across multiple datasets and yielding substantial gains in real-world deployments, offering a scalable solution for optimizing multi-channel fusion in retrieval.}
}


@inproceedings{DBLP:conf/www/TalukderGH25,
	author = {Niloy Talukder and
                  Croix Gyurek and
                  Mohammad Al Hasan},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Node2binary: Compact Graph Node Embeddings using Binary Vectors},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {495--505},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714938},
	doi = {10.1145/3696410.3714938},
	timestamp = {Fri, 09 May 2025 20:28:07 +0200},
	biburl = {https://dblp.org/rec/conf/www/TalukderGH25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the adoption of deep learning models to low-power, small-memory edge devices, energy consumption and storage usage of such models have become a key concern. The problem exacerbates even further with ever-growing data and equally-matched bulkier models. This concern is particularly pronounced for graph data due to its quadratic storage, irregular (non-grid) geometry, and very large size. Typical graph data, such as road networks, infrastructure networks, and social networks, easily exceeds millions of nodes, and several gigabytes of storage is needed just to store the node embedding vectors, let alone the model parameters. In recent years, the memory issue has been addressed by moving away from memory-intensive double precision floating-point arithmetic towards single-precision or even half-precision, often by trading-off marginally small performance. Along this effort, we propose Node2Binary, which embeds graph nodes in as few as 128 binary bits, thereby reducing the memory footprint of vertex embedding vectors by several orders of magnitude. N ode 2 Binary . leverages a fast community detection algorithm to convert the given graph into a hierarchical partition tree and then find embeddings of graph vertices in binary space by solving a combinatorial optimization (CO) task over the tree edges. CO is NP-hard, but N ode 2 Binary  uses an innovative combination of discrete gradient descent and randomization to solve this task effectively and efficiently. Extensive experiments over four real-world graphs show that N ode 2 Binary  achieves competitive performance compared to the state-of-the art graph embedding methods in both node classification and link prediction tasks.}
}


@inproceedings{DBLP:conf/www/GkartziosPT25,
	author = {Christos Gkartzios and
                  Evaggelia Pitoura and
                  Panayiotis Tsaparas},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Fair Network Communities through Group Modularity},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {506--517},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714625},
	doi = {10.1145/3696410.3714625},
	timestamp = {Fri, 09 May 2025 20:28:07 +0200},
	biburl = {https://dblp.org/rec/conf/www/GkartziosPT25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Communities in networks are groups of nodes that are more densely connected to each other than to the rest of the network, forming clusters with strong internal relationships. When nodes have sensitive attributes, such as demographic groups in social networks, a key question is whether nodes in each group are equally well-connected within each community. We model connectivity fairness using group modularity, an adaptation of modularity that accounts for group structures. We introduce two versions of group modularity, each grounded on a different null model, and propose fairness-aware community detection algorithms. Finally, we provide experimental results on real and synthetic networks, evaluating both the connectivity fairness of community structures in networks and the performance of our fairness-aware algorithms.}
}


@inproceedings{DBLP:conf/www/HuiZTR25,
	author = {Yunming Hui and
                  Inez Maria Zwetsloot and
                  Simon Trimborn and
                  Stevan Rudinac},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Domain-Informed Negative Sampling Strategies for Dynamic Graph Embedding
                  in Meme Stock-Related Social Networks},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {518--529},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714650},
	doi = {10.1145/3696410.3714650},
	timestamp = {Fri, 09 May 2025 20:28:07 +0200},
	biburl = {https://dblp.org/rec/conf/www/HuiZTR25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Social network platforms like Reddit are increasingly impacting real-world economics. Meme stocks are a recent phenomena where price movements are driven by retail investors organizing themselves via social networks. To study the impact of social networks on meme stocks, the first step is to analyze these networks. Going forward, predicting meme stocks' returns would require to predict dynamic interactions first. This is different from conventional link prediction, frequently applied in e.g. recommendation systems. For this task, it is essential to predict more complex interaction dynamics, such as the exact timing. These are crucial for linking the network to meme stock price movements. Dynamic graph embedding (DGE) has recently emerged as a promising approach for modeling dynamic graph-structured data. However, current negative sampling strategies, an important component of DGE, are designed for conventional dynamic link prediction and do not capture the specific patterns present in meme stock-related social networks. This limits the training and evaluation of DGE models in such social networks. To overcome this drawback, we propose novel negative sampling strategies based on the analysis of real meme stock-related social networks and financial knowledge. Our experiments show that the proposed negative sampling strategies can better evaluate and train DGE models targeted at meme stock-related social networks compared to existing baselines.}
}


@inproceedings{DBLP:conf/www/LiJZSG25,
	author = {Hao Li and
                  Hao Jiang and
                  Yuke Zheng and
                  Hao Sun and
                  Wenying Gong},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {UniGO: {A} Unified Graph Neural Network for Modeling Opinion Dynamics
                  on Graphs},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {530--540},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714636},
	doi = {10.1145/3696410.3714636},
	timestamp = {Wed, 09 Jul 2025 09:51:40 +0200},
	biburl = {https://dblp.org/rec/conf/www/LiJZSG25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Polarization and fragmentation in social media amplify user biases, making it increasingly important to understand the evolution of opinions. Opinion dynamics provide interpretability for studying opinion evolution, yet incorporating these insights into predictive models remains challenging. This challenge arises due to the inherent complexity of the diversity of opinion fusion rules and the difficulty in capturing equilibrium states while avoiding over-smoothing. This paper constructs a unified opinion dynamics model to integrate different opinion fusion rules and generates corresponding synthetic datasets. To fully leverage the advantages of unified opinion dynamics, we introduces UniGO, a framework for modeling opinion evolution on graphs. Using a coarsen-refine mechanism, UniGO efficiently models opinion dynamics through a graph neural network, mitigating over-smoothing while preserving equilibrium phenomena. UniGO leverages pretraining on synthetic datasets, which enhances its ability to generalize to real-world scenarios, providing a viable paradigm for applications of opinion dynamics. Experimental results on both synthetic and real-world datasets demonstrate UniGO's effectiveness in capturing complex opinion formation processes and predicting future evolution. The pretrained model also shows strong generalization capability, validating the benefits of using synthetic data to boost real-world performance.}
}


@inproceedings{DBLP:conf/www/CinusMLF25,
	author = {Federico Cinus and
                  Marco Minici and
                  Luca Luceri and
                  Emilio Ferrara},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Exposing Cross-Platform Coordinated Inauthentic Activity in the Run-Up
                  to the 2024 {U.S.} Election},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {541--559},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714698},
	doi = {10.1145/3696410.3714698},
	timestamp = {Fri, 09 May 2025 20:28:07 +0200},
	biburl = {https://dblp.org/rec/conf/www/CinusMLF25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Coordinated information operations remain a persistent challenge on social media, despite platform efforts to curb them. While previous research has primarily focused on identifying these operations within individual platforms, this study shows that coordination frequently transcends platform boundaries. Leveraging newly collected data of online conversations related to the 2024 U.S. Election across 𝕏 (formerly, Twitter), Facebook, and Telegram, we construct similarity networks to detect coordinated communities exhibiting suspicious sharing behaviors within and across platforms. Proposing an advanced coordination detection model, we reveal evidence of potential foreign interference, with Russian-affiliated media being systematically promoted across Telegram and 𝕏. Our analysis also uncovers substantial intra- and cross-platform coordinated inauthentic activity, driving the spread of highly partisan, low-credibility, and conspiratorial content. These findings highlight the urgent need for regulatory measures that extend beyond individual platforms to effectively address the growing challenge of cross-platform coordinated influence campaigns.}
}


@inproceedings{DBLP:conf/www/NettasingheRJPL25,
	author = {Buddhika Nettasinghe and
                  Ashwin Rao and
                  Bohan Jiang and
                  Allon G. Percus and
                  Kristina Lerman},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {In-Group Love, Out-Group Hate: {A} Framework to Measure Affective
                  Polarization via Contentious Online Discussions},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {560--575},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714935},
	doi = {10.1145/3696410.3714935},
	timestamp = {Fri, 09 May 2025 20:28:07 +0200},
	biburl = {https://dblp.org/rec/conf/www/NettasingheRJPL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Affective polarization, the emotional divide between ideological groups marked by in-group love and out-group hate, has intensified in the United States, driving contentious issues like masking and lockdowns during the COVID-19 pandemic. Despite its societal impact, existing models of opinion change fail to account for emotional dynamics nor offer methods to quantify affective polarization robustly and in real-time. In this paper, we introduce a discrete choice model that captures decision-making within affectively polarized social networks and propose a statistical inference method estimate key parameters---in-group love and out-group hate---from social media data. Through empirical validation from online discussions about the COVID-19 pandemic, we demonstrate that our approach accurately captures real-world polarization dynamics and explains the rapid emergence of a partisan gap in attitudes towards masking and lockdowns. This framework allows for tracking affective polarization across contentious issues has broad implications for fostering constructive online dialogues in digital spaces.}
}


@inproceedings{DBLP:conf/www/YuanSR25,
	author = {Lanqin Yuan and
                  Philipp J. Schneider and
                  Marian{-}Andrei Rizoiu},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Behavioral Homophily in Social Media via Inverse Reinforcement Learning:
                  {A} Reddit Case Study},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {576--589},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714618},
	doi = {10.1145/3696410.3714618},
	timestamp = {Fri, 09 May 2025 20:28:07 +0200},
	biburl = {https://dblp.org/rec/conf/www/YuanSR25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Online communities play a critical role in shaping societal discourse and influencing collective behavior in the real world. The tendency for people to connect with others who share similar characteristics and views, known as homophily, plays a key role in the formation of echo chambers which further amplify polarization and division. Existing works examining homophily in online communities traditionally infer it using content- or adjacency-based approaches, such as constructing explicit interaction networks or performing topic analysis. These methods fall short for platforms where interaction networks cannot be easily constructed and fail to capture the complex nature of user interactions across the platform. This work introduces a novel approach for quantifying user homophily. We first use an Inverse Reinforcement Learning (IRL) framework to infer users' policies, then use these policies as a measure of behavioral homophily. We apply our method to Reddit, conducting a case study across 5.9 million interactions over six years, demonstrating how this approach uncovers distinct behavioral patterns and user roles that vary across different communities. We further validate our behavioral homophily measure against traditional content-based homophily, offering a powerful method for analyzing social media dynamics and their broader societal implications. We find, among others, that users can behave very similarly (high behavioral homophily) when discussing entirely different topics like soccer vs e-sports (low topical homophily), and that there is an entire class of users on Reddit whose purpose seems to be to disagree with others.}
}


@inproceedings{DBLP:conf/www/LentiAMM25,
	author = {Jacopo Lenti and
                  Luca Maria Aiello and
                  Corrado Monti and
                  Gianmarco De Francisci Morales},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Causal Modeling of Climate Activism on Reddit},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {590--600},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714684},
	doi = {10.1145/3696410.3714684},
	timestamp = {Fri, 09 May 2025 20:28:07 +0200},
	biburl = {https://dblp.org/rec/conf/www/LentiAMM25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Climate activism is crucial in stimulating collective societal and behavioral change towards sustainable practices through political pressure. Although multiple factors contribute to the participation in activism, their complex relationships and the scarcity of data on their interactions have restricted most prior research to studying them in isolation, thus preventing the development of a quantitative, causal understanding of why people approach activism. In this work, we develop a comprehensive causal model of how and why Reddit users engage with activist communities driving mass climate protests (mainly the 2019 Earth Strike, Fridays for Future, and Extinction Rebellion). Our framework, based on Stochastic Variational Inference applied to Bayesian Networks, learns the causal pathways over multiple time periods. Distinct from previous studies, our approach uses large-scale and fine-grained longitudinal data (2016 to 2022) to jointly model the roles of sociodemographic makeup, experience of extreme weather events, exposure to climate-related news, and social influence through online interactions. We find that among users interested in climate change, participation in online activist communities is indeed influenced by direct interactions with activists and largely by recent exposure to media coverage of climate protests. Among people aware of climate change, left-leaning people from lower socioeconomic backgrounds are particularly represented in online activist groups. Our findings offer empirical validation for theories of media influence and critical mass, and lay the foundations to inform interventions and future studies to foster public participation in collective action.}
}


@inproceedings{DBLP:conf/www/KimA25,
	author = {Rachel M. Kim and
                  Ashton Anderson},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {The Agenda-Setting Function of Social Media},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {601--613},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714750},
	doi = {10.1145/3696410.3714750},
	timestamp = {Thu, 01 May 2025 20:27:23 +0200},
	biburl = {https://dblp.org/rec/conf/www/KimA25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As people increasingly use social media as a primary news source, it becomes critical to understand how online platforms affect peoples' experience of the news. Through the media effects of agenda-setting and framing, different news sources can vary in their influence on public opinion regarding which issues people consider important and how particular aspects of these issues should be interpreted. However, little is known about how issues and frames shift and segregate across partisan lines as traditional news on social media gets filtered by the selective exposure effects of social media. In this study, we investigate the issues and frames invoked in news article shares across Reddit over 16 years and measure their traditional media and social media partisanship. We measure the change between  production  (news articles posted on Reddit) and  consumption  (news articles posted on Reddit, weighted by their score). We find that issues are shared in a co-partisan manner across traditional media and social media lines. Issues are also more polarized in social media than traditional media and more polarized in consumption than production. We find that frames across several issues are also subject to co-partisan sharing behavior. In contrast to the significant polarization of news outlets on Reddit in 2016, issues and frames do not polarize more over time. Finally, looking at case studies of frames within specific issues, we disaggregate the shift from production to consumption by distinguishing between issues where the frames polarize and issues that simply receive less exposure on one side of the political spectrum. Our results give insight into broader phenomena like political polarization by highlighting the dimensions of precisely what polarizes and how polarization occurs. Overall, our study showcases the importance of understanding how social media distorts the perception of the news via its agenda-setting and framing functions.}
}


@inproceedings{DBLP:conf/www/LvXFZLL025,
	author = {Fengmao Lv and
                  Mengting Xiong and
                  Junlin Fang and
                  Lingli Zhang and
                  Tianze Luo and
                  Weichao Liang and
                  Tianrui Li},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {MSTI-Plus: Introducing Non-Sarcasm Reference Materials to Enhance
                  Multimodal Sarcasm Target Identification},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {614--624},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714570},
	doi = {10.1145/3696410.3714570},
	timestamp = {Fri, 09 May 2025 20:28:07 +0200},
	biburl = {https://dblp.org/rec/conf/www/LvXFZLL025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Sarcasm is a subtle expression that indicates the incongruity between literal meanings and factual opinions. For multimodal posts in social medias which consist of both images and texts, sarcasm expressions are even more widespread. Recent works have paid attentions to Multimodal Sarcasm Target Identification (MSTI), which focuses on detecting aspect terms of mockery or ridicule as sarcasm targets. However, the current MSTI benchmark only contains annotations on fine-grained sarcasm targets within sarcastic samples. In practice, it will be featured by two major limitations. First, there lack annotations on non-sarcasm aspects to inform deep models to perceive the semantic difference between sarcasm targets and non-sarcasm aspects. As a result, deep models will tend to incorrectly recognize non-sarcasm aspects as sarcasm targets. Second, there lack non-sarcasm samples to inform deep models to perceive the inherent semantics of sarcasm intentions. Due to the subtle characteristic of sarcasm expressions, models trained with only fine-grained supervision signals cannot thoroughly understand the sarcasm semantics, making the fine-grained task of sarcasm target identification restricted. Motivated by these limitations, this work reconstructs a more comprehensive MSTI benchmark by introducing both fine-grained non-sarcasm aspect annotations for existing sarcasm samples and non-sarcastic samples as non-sarcasm references to enable deep models to clearly perceive the mentioned information during training. Based on the multi-granularity (i.e., both aspect-level and sample-level) non-sarcasm information introduced into this new benchmark, this work further proposes a pluggable Semantics-aware Sarcasm Target Identification mechanism to enhance sarcasm target identification by modeling the overall semantics of sarcasm intentions via an auxiliary sample-level sarcasm recognition task. By modeling the overall semantics of sarcasm intention, deep models can obtain a more comprehensive understanding on sarcasm semantics, leading to improved performance on fine-grained sarcasm target identification. Extensive experiments are conducted to validate our contribution. Both the dataset and code are available at https://github.com/tiggers23/MSTI-Plus.}
}


@inproceedings{DBLP:conf/www/LiangWFYWL25,
	author = {Tao Liang and
                  Siying Wu and
                  Junfeng Fang and
                  Guowu Yang and
                  Wenya Wang and
                  Fengmao Lv},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Damage Analysis via Bidirectional Multi-Task Cascaded Multimodal Fusion},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {625--636},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714609},
	doi = {10.1145/3696410.3714609},
	timestamp = {Fri, 09 May 2025 20:28:07 +0200},
	biburl = {https://dblp.org/rec/conf/www/LiangWFYWL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Damage analysis in social media platforms such as Twitter is a comprehensive problem which involves different subtasks for mining damage-related information from tweets (  e.g.,  informativeness, humanitarian categories and severity assessment). The comprehensive information obtained by damage analysis enables to identify breaking events around the world in real-time and hence provides aids in emergency responses. Recently, with the rapid development of web technologies, multimodal damage analysis has received increasing attentions due to users' preference of posting multimodal information in social media. Multimodal damage analysis leverages the associated image modality to improve the identification of damage-related information in social media. However, existing works on multimodal damage analysis address each damage-related subtask individually and do not consider their joint training mechanism. In this work, we propose the Bidirectional Multi-task Cascaded multimodal Fusion (BiMCF) approach towards joint multimodal damage analysis. To this end, we introduce the cascaded multimodal fusion framework to separately integrate effective visual and text information for each task, considering that different tasks attend to different information. To exploit the interactions across tasks, bidirectional propagation of the attended image-text interactive information is implemented between tasks, which can lead to enhanced multimodal fusion. Comprehensive experiments are conducted to validate the effectiveness of the proposed approach. Code is available at https://github.com/tiggers23/BiMCF.}
}


@inproceedings{DBLP:conf/www/MazharSSRVK0A25,
	author = {Abdullah Mazhar and
                  Zuhair Hasan Shaik and
                  Aseem Srivastava and
                  Polly Ruhnke and
                  Lavanya Vaddavalli and
                  Sri Keshav Katragadda and
                  Shweta Yadav and
                  Md. Shad Akhtar},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Figurative-cum-Commonsense Knowledge Infusion for Multimodal Mental
                  Health Meme Classification},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {637--648},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714778},
	doi = {10.1145/3696410.3714778},
	timestamp = {Fri, 09 May 2025 20:28:07 +0200},
	biburl = {https://dblp.org/rec/conf/www/MazharSSRVK0A25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The expression of mental health symptoms through non-traditional means, such as memes, has gained remarkable attention over the past few years, with users often highlighting their mental health struggles through figurative intricacies within memes. While humans rely on commonsense knowledge to interpret these complex expressions, current Multimodal Language Models (MLMs) struggle to capture these figurative aspects inherent in memes. To address this gap, we introduce a novel dataset, AxiOM, derived from the GAD anxiety questionnaire, which categorizes memes into six fine-grained anxiety symptoms. Next, we propose a commonsense and domain-enriched framework, M3H, to enhance MLMs' ability to interpret figurative language and commonsense knowledge. The overarching goal remains to first understand and then classify the mental health symptoms expressed in memes. We benchmark M3H against 6 competitive baselines (with 20 variations), demonstrating improvements in both quantitative and qualitative metrics, including a detailed human evaluation. We observe a clear improvement of 4.20% and 4.66% on weighted-F1 metric. To assess the generalizability, we perform extensive experiments on a public dataset,  RESTORE,  for depressive symptom identification, presenting an ablation study that highlights the contribution of each module. Our findings reveal limitations in existing models and the advantage of employing commonsense to enhance figurative understanding.}
}


@inproceedings{DBLP:conf/www/QiaoWCK25,
	author = {Tingrui Qiao and
                  Caroline Walker and
                  Chris Cunningham and
                  Yun Sing Koh},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Thematic-LM: {A} LLM-based Multi-agent System for Large-scale Thematic
                  Analysis},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {649--658},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714595},
	doi = {10.1145/3696410.3714595},
	timestamp = {Fri, 09 May 2025 20:28:07 +0200},
	biburl = {https://dblp.org/rec/conf/www/QiaoWCK25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Thematic analysis (TA) is a widely used qualitative method for identifying underlying meanings within unstructured text. However, TA requires manual processes, which become increasingly labour-intensive and time-consuming as datasets grow. While large language models (LLMs) have been introduced to assist with TA on small-scale datasets, three key limitations hinder their effectiveness. First, current approaches often depend on interactions between an LLM agent and a human coder, a process that becomes challenging with larger datasets. Second, with feedback from the human coder, the LLM tends to mirror the human coder, which provides a narrower viewpoint of the data. Third, existing methods follow a sequential process, where codes are generated for individual samples without recalling previous codes and associated data, reducing the ability to analyse data holistically. To address these limitations, we propose Thematic-LM, an LLM-based multi-agent system for large-scale computational thematic analysis. Thematic-LM assigns specialised tasks to each agent, such as coding, aggregating codes, and maintaining and updating the codebook. We assign coder agents different identity perspectives to simulate the subjective nature of TA, fostering a more diverse interpretation of the data. We applied Thematic-LM to the Dreaddit dataset and the Reddit climate change dataset to analyse themes related to social media stress and online opinions on climate change. We evaluate the resulting themes based on trustworthiness principles in qualitative research. Our study reveals insights such as assigning different identities to coder agents promotes divergence in codes and themes.}
}


@inproceedings{DBLP:conf/www/ZhangQMG0HJ25,
	author = {Limiao Zhang and
                  Xinyang Qi and
                  Haiping Ma and
                  Jie Gao and
                  Xingyi Zhang and
                  Yanqing Hu and
                  Yaochu Jin},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Spatial-Temporal Analysis of Collective Emotional Resonance in China
                  During Global Health Crisis},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {659--672},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714913},
	doi = {10.1145/3696410.3714913},
	timestamp = {Tue, 13 May 2025 07:31:04 +0200},
	biburl = {https://dblp.org/rec/conf/www/ZhangQMG0HJ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The 21st century has already witnessed so many outbreaks with pandemic potential, including SARS (2002), H1N1 (2009), MERS (2012), Ebola (2014), Zika virus (2015), and the COVID-19 pandemic (2019). Using 60 million geotagged Sina Weibo tweets covering over 20 million active accounts, we investigate the collective emotional dynamics on social media in the most recent global pandemic, i.e., COVID-19. This research features two highlights: (1) It focuses on the Chinese population located in the initial epicenter of the pandemic. (2) It examines the initial year after the pandemic outbreak, a critical period where emotions were most intense due to the uncertainty and rapid developments related to the crisis. Using cross-disciplinary methods, we reveal a positive connection between online emotional resonance and geographic proximity, demonstrating a direct mapping between virtual network distances and physical spatial embedding. We propose a percolation-based index to measure the nationwide emotional resonance level with which we illustrate the significant economic impact of the global health issue. Finally, we identify a leader-follower pattern in emotional resonance fluctuations based on time-lag emotion correlations, revealing that less active regions play a crucial role in leading and responding to emotional changes. In the face of long COVID and emerging global health crises, our analysis elucidates how collective emotional resonance evolves, providing potential directions for online opinion interventions during global shocks.}
}


@inproceedings{DBLP:conf/www/HanL0C25,
	author = {Yongxuan Han and
                  Shengzhong Liu and
                  Fan Wu and
                  Guihai Chen},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {{ABO:} Abandon Bayer Filter for Adaptive Edge Offloading in Responsive
                  Augmented Reality},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {673--684},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714856},
	doi = {10.1145/3696410.3714856},
	timestamp = {Fri, 09 May 2025 20:28:07 +0200},
	biburl = {https://dblp.org/rec/conf/www/HanL0C25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Bayer-patterned color filter array (CFA) has been the go-to solution for color image sensors. In augmented reality (AR), although color interpolation (i.e.,  demosaicing ) of pre-demosaic RAW images facilitates a user-friendly rendering, it creates no benefits in offloaded DNN analytics but increases the image channels by 3x inducing higher transmission overheads. The potential optimization in frame preprocessing of DNN offloading is yet to be investigated. To that end, we propose ABO, an adaptive RAW frame offloading framework that parallelizes demosaicing with DNN computation. Its contributions are three-fold: First, we design a configurable tile-wise RAW image neural codec to compress frame sizes while sustaining downstream DNN accuracy under bandwidth constraints. Second, based on content-aware tiles-in-frame selection and runtime bandwidth estimation, a dynamic transmission controller adaptively calibrates codec configurations to maximize the DNN accuracy. Third, we further optimize the system pipelining to achieve lower end-to-end frame processing latency and higher throughput. Through extensive evaluations on a prototype platform, ABO consistently achieves 40% more frame processing throughput and 30% less end-to-end latency while improving the DNN accuracy by up to 15% than SOTA baselines. It also exhibits improved robustness against dim lighting and motion blur situations.}
}


@inproceedings{DBLP:conf/www/BiswasKM00V25,
	author = {Sayan Biswas and
                  Anne{-}Marie Kermarrec and
                  Alexis Marouani and
                  Rafael Pires and
                  Rishi Sharma and
                  Martijn de Vos},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Boosting Asynchronous Decentralized Learning with Model Fragmentation},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {685--696},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714872},
	doi = {10.1145/3696410.3714872},
	timestamp = {Thu, 01 May 2025 20:27:22 +0200},
	biburl = {https://dblp.org/rec/conf/www/BiswasKM00V25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Decentralized learning (DL) is an emerging technique that allows nodes on the web to collaboratively train machine learning models without sharing raw data. Dealing with stragglers, i.e., nodes with slower compute or communication than others, is a key challenge in DL. We present DivShare, a novel asynchronous DL algorithm that achieves fast model convergence in the presence of communication stragglers. DivShare achieves this by having nodes fragment their models into parameter subsets and send, in parallel to computation, each subset to a random sample of other nodes instead of sequentially exchanging full models. The transfer of smaller fragments allows more efficient usage of the collective bandwidth and enables nodes with slow network links to quickly contribute with at least some of their model parameters. By theoretically proving the convergence of DivShare, we provide, to the best of our knowledge, the first formal proof of convergence for a DL algorithm that accounts for the effects of asynchronous communication with delays. We experimentally evaluate DivShare against two state-of-the-art DL baselines, AD-PSGD and Swift, and with two standard datasets, CIFAR-10 and MovieLens. We find that DivShare with communication stragglers lowers time-to-accuracy by up to 3.9x compared to AD-PSGD on the CIFAR-10 dataset. Compared to baselines, DivShare also achieves up to 19.4% better accuracy and 9.5% lower test loss on the CIFAR-10 and MovieLens datasets, respectively.}
}


@inproceedings{DBLP:conf/www/Xie0025,
	author = {Yongzheng Xie and
                  Hongyu Zhang and
                  Muhammad Ali Babar},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Multivariate Time Series Anomaly Detection by Capturing Coarse-Grained
                  Intra- and Inter-Variate Dependencies},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {697--705},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714941},
	doi = {10.1145/3696410.3714941},
	timestamp = {Fri, 09 May 2025 20:28:07 +0200},
	biburl = {https://dblp.org/rec/conf/www/Xie0025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Multivariate time series anomaly detection is essential for failure management in web application operations, as it directly influences the effectiveness and timeliness of implementing remedial or preventive measures. This task is often framed as a semi-supervised learning problem, where only normal data are available for model training, primarily due to the labor-intensive nature of data labeling and the scarcity of anomalous data. Existing semi-supervised methods often detect anomalies by capturing intra-variate temporal dependencies and/or inter-variate relationships to learn normal patterns, flagging timestamps that deviate from these patterns as anomalies. However, these approaches often fail to capture salient intra-variate temporal and inter-variate dependencies in time series due to their focus on excessively fine granularity, leading to suboptimal performance. In this study, we introduce MtsCID, a novel semi-supervised multivariate time series anomaly detection method. MtsCID employs a dual network architecture: one network operates on the attention maps of multi-scale intra-variate patches for coarse-grained temporal dependency learning, while the other works on variates to capture coarse-grained inter-variate relationships through convolution and interaction with sinusoidal prototypes. This design enhances the ability to capture the patterns from both intra-variate temporal dependencies and inter-variate relationships, resulting in improved performance. Extensive experiments across seven widely used datasets demonstrate that MtsCID achieves performance comparable or superior to state-of-the-art benchmark methods.}
}


@inproceedings{DBLP:conf/www/SongLZYXL25,
	author = {Mingxuan Song and
                  Pengze Li and
                  Bohan Zhou and
                  Shenglin Yin and
                  Zhen Xiao and
                  Jieyi Long},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {{AERO:} Enhancing Sharding Blockchain via Deep Reinforcement Learning
                  for Account Migration},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {706--716},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714926},
	doi = {10.1145/3696410.3714926},
	timestamp = {Fri, 09 May 2025 20:28:07 +0200},
	biburl = {https://dblp.org/rec/conf/www/SongLZYXL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Sharding blockchain networks face significant scalability challenges due to high frequencies of cross-shard transactions and uneven workload distributions among shards. To address these scalability issues, account migration offers a promising solution. However, existing migration solutions struggle with the high computational overhead and insufficient capture of complex transaction patterns. We propose AERO, a deep reinforcement learning framework to facilitate efficient account migration in sharding blockchains. AERO employs a prefix-based grouping strategy to enable group-level migration decisions and capture complex transaction patterns and relationships between accounts. We also implement a sharding blockchain system called AEROChain, which integrates AERO and aligns with the blockchain decentralization principle. Extensive evaluation with real Ethereum transaction data demonstrates that AERO improves the system throughput by 31.77% compared to existing solutions, effectively reducing cross-shard transactions and balancing shard workloads.}
}


@inproceedings{DBLP:conf/www/Cao0B0LL25,
	author = {Yinfeng Cao and
                  Jiannong Cao and
                  Dongbin Bai and
                  Long Wen and
                  Yang Liu and
                  Ruidong Li},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {{MAP} the Blockchain World: {A} Trustless and Scalable Blockchain
                  Interoperability Protocol for Cross-chain Applications},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {717--726},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714867},
	doi = {10.1145/3696410.3714867},
	timestamp = {Fri, 09 May 2025 20:28:07 +0200},
	biburl = {https://dblp.org/rec/conf/www/Cao0B0LL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Blockchain interoperability protocols enable cross-chain asset transfers or data retrievals between isolated chains, which are considered as one of the core infrastructure for Web 3.0. However, existing protocols either face severe scalability issues due to high on-chain and off-chain cost, or suffer from trust concerns because of centralized architecture. In this paper, we propose MAP, a trustless blockchain interoperability protocol that relays cross-chain transactions across heterogeneous chains with high scalability. First, within MAP, we develop a novel  cross-chain relay  architecture, which integrates a unified relay chain and on-chain light clients of source chains, allowing the trustworthy retrieval and verification of heterogeneous cross-chain transactions. Furthermore, we reduce cross-chain verification cost by incorporating an optimized on-chain light client scheme that adaptively decouples signature verification overheads from inefficient smart contract execution and offloads them to off-chain provers. For experiments, we conduct the first large-scale evaluation on existing blockchain interoperability protocols. With MAP, the required number of on-chain light clients is reduced from O(N 2 ) to  O(N) , with decreasing on-chain cost 35% and 25% off-chain cost when verifying cross-chain transactions. To demonstrate the effectiveness, we deployed MAP in the real world. By 2025, we have supported over six popular public chains, 50 cross-chain applications and relayed over 200K cross-chain transactions worth over 640 million USD. Based on the deployment records, we construct the first real-world cross-chain dataset to further advance blockchain interoperability research.}
}


@inproceedings{DBLP:conf/www/PandeyVAZSZ25,
	author = {Ayush Pandey and
                  Matteo Varvello and
                  Syed Ishtiaque Ahmed and
                  Shurui Zhou and
                  Lakshmi Subramanian and
                  Yasir Zaki},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {{MAML:} Towards a Faster Web in Developing Regions},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {727--739},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714584},
	doi = {10.1145/3696410.3714584},
	timestamp = {Fri, 09 May 2025 20:28:07 +0200},
	biburl = {https://dblp.org/rec/conf/www/PandeyVAZSZ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The web experience in developing regions remains subpar, primarily due to the growing complexity of modern webpages and insufficient optimization by content providers. Users in these regions typically rely on low-end devices and limited bandwidth, which results in a poor user experience as they download and parse webpages bloated with excessive third-party CSS and JavaScript (JS). To address these challenges, we introduce the Mobile Application Markup Language (MAML), a flat layout-based web specification language that reduces computational and data transmission demands, while replacing the excessive bloat from JS with a new scripting language centered on essential (and popular) web functionalities. Last but not least, MAML is backward compatible as it can be transpiled to minimal HTML/JavaScript/CSS and thus work with legacy browsers. We benchmark MAML in terms of page load times and sizes, using a translator which can automatically port any webpage to MAML. When compared to the popular Google AMP, across 100 testing webpages, MAML offers webpage speedups by tens of seconds under challenging network conditions thanks to its significant size reductions. Next, we run a competition involving 25 university students porting 50 of the above webpages to MAML using a web-based editor we developed. This experiment verifies that, with little developer effort, MAML is quite effective in maintaining the visual and functional correctness of the originating webpages.}
}


@inproceedings{DBLP:conf/www/ZhangWLLLLL025,
	author = {Qi Zhang and
                  Qian Wu and
                  Zeqi Lai and
                  Jihao Li and
                  Hewu Li and
                  Yuyu Liu and
                  Yuanjie Li and
                  Jun Liu},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Spache: Accelerating Ubiquitous Web Browsing via Schedule-Driven Space
                  Caching},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {740--750},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714789},
	doi = {10.1145/3696410.3714789},
	timestamp = {Fri, 18 Jul 2025 10:39:50 +0200},
	biburl = {https://dblp.org/rec/conf/www/ZhangWLLLLL025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we perform a systematic study to explore a pivotal problem facing the web community:  is current distributed web cache ready for future satellite Internet?  First, through a worldwide performance measurement based on the RIPE Atlas platform and Starlink, the largest low-earth orbit (LEO) satellite network (LSN) today, we identify that the uneven deployment of current distributed cache servers, inter-ISP meandering routes and the last-mile congestion on LEO links jointly prevent existing terrestrial web cache from providing low-latency web access for users in emerging LSNs. Second, we propose S pache , a novel web caching system which addresses the limitations of existing ground-only cache by exploiting a bold idea: integrating web cache into LEO satellites to achieve ubiquitous and low-latency web services. Specifically, S pache  leverages a key feature of LSNs called  communication schedule  to efficiently prefetch web contents on satellites, and adopts a schedule-driven partitioning strategy to avoid cache pollution involved by LEO mobility. Finally, we implement a prototype of S pache , and evaluate it based on real-world HTTP traces and data-driven LSN simulation. Extensive evaluations demonstrate that as compared to existing distributed caching solutions, S pache  can improve cache hit ratio by 19.8% on average, reduce latency by up to 17.7%, and maintains consistently low web browsing latency for global LSN users.}
}


@inproceedings{DBLP:conf/www/HanBATY025,
	author = {Yudong Han and
                  Weichen Bi and
                  Ruibo An and
                  Deyu Tian and
                  Qi Yang and
                  Yun Ma},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {{GL2GPU:} Accelerating WebGL Applications via Dynamic {API} Translation
                  to WebGPU},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {751--762},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714785},
	doi = {10.1145/3696410.3714785},
	timestamp = {Fri, 09 May 2025 20:28:07 +0200},
	biburl = {https://dblp.org/rec/conf/www/HanBATY025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {WebGL has long been the prevalent API for GPU-accelerated graphics in web browsers, boosting 2D/3D graphical web applications. Despite widespread adoption, WebGL's programming model hinders its rendering performance on modern GPU hardware. To this end, WebGPU has been proposed as the next-generation API of GPU-accelerated processing in web browsers, exhibiting higher performance than WebGL. However, considering the complex logic of WebGL applications and the still-evolving WebGPU specification, statically migrating existing WebGL applications to WebGPU from source code is labor-intensive. To address this issue, we propose GL2GPU, an intermediate layer that dynamically translates WebGL to WebGPU at JavaScript runtime to improve rendering performance. GL2GPU addresses the inconsistencies between the WebGL and WebGPU programming models by emulating WebGL rendering states and leverages performance optimization mechanisms introduced by WebGPU to reduce the overhead of dynamic translation. Evaluation of three representative WebGL benchmarks shows that GL2GPU significantly enhances end-to-end rendering performance while maintaining visual consistency, achieving an average frame time reduction of 45.05% across different devices and operating systems.}
}


@inproceedings{DBLP:conf/www/GanLZWYGLL25,
	author = {Xinbiao Gan and
                  Tiejun Li and
                  Qiang Zhang and
                  Guang Wu and
                  Bo Yang and
                  Chunye Gong and
                  Jie Liu and
                  Kai Lu},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {GraphCSR: {A} Space and Time-Efficient Sparse Matrix Representation
                  for Web-scale Graph Processing},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {763--771},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714833},
	doi = {10.1145/3696410.3714833},
	timestamp = {Fri, 09 May 2025 20:28:08 +0200},
	biburl = {https://dblp.org/rec/conf/www/GanLZWYGLL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graph data processing is essential for web-scale applications, including social networks, recommendation systems, and web of things (WoT) systems, where large, sparsely connected graphs dominate. Traditional sparse matrix storage formats like compressed sparse row (CSR) face significant memory and performance bottlenecks in distributed, federated, and edge-based computing environments, which are increasingly central to the web. To address this challenge, we propose  GraphCSR , a novel storage format that clusters vertices with identical edge degrees and stores only the starting index of each group. This approach minimizes memory overhead and facilitates batch memory access while enhancing overall performance, making it particularly suitable for federated systems and resource-constrained edge nodes. Our experiments across various graph operations and large datasets show that  GraphCSR  achieves considerable memory savings and performance gains of large-scale, distributed graph processing. When deployed  GraphCSR  on two production-grade supercomputers, demonstrating its potential for scaling web and WoT graph processing in large-scale distributed computing systems.}
}


@inproceedings{DBLP:conf/www/Tran0YN0Y25,
	author = {Hung Vinh Tran and
                  Tong Chen and
                  Guanhua Ye and
                  Quoc Viet Hung Nguyen and
                  Kai Zheng and
                  Hongzhi Yin},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {On-device Content-based Recommendation with Single-shot Embedding
                  Pruning: {A} Cooperative Game Perspective},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {772--785},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714921},
	doi = {10.1145/3696410.3714921},
	timestamp = {Fri, 09 May 2025 20:28:08 +0200},
	biburl = {https://dblp.org/rec/conf/www/Tran0YN0Y25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Content-based Recommender Systems (CRSs) play a crucial role in shaping user experiences in e-commerce, online advertising, and personalized recommendations. However, due to the vast amount of categorical features, the embedding tables used in CRS models pose a significant storage bottleneck for real-world deployment, especially on resource-constrained devices. To address this problem, various embedding pruning methods have been proposed, but most existing ones require expensive retraining steps for each target parameter budget, leading to enormous computation costs. In reality, this computation cost is a major hurdle in real-world applications with diverse storage requirements, such as federated learning and streaming settings. In this paper, we propose  Sha pley  V alue-guided  E mbedding  R eduction (Shaver) as our response. With Shaver, we view the problem from a cooperative game perspective, and quantify each embedding parameter's contribution with Shapley values to facilitate contribution-based parameter pruning. To address the inherently high computation costs of Shapley values, we propose an efficient and unbiased method to estimate Shapley values of a CRS's embedding parameters. Moreover, in the pruning stage, we put forward a field-aware codebook to mitigate the information loss in the traditional zero-out treatment. Through extensive experiments on three real-world datasets, Shaver has demonstrated competitive performance with lightweight recommendation models across various parameter budgets. The source code is available at https://github.com/chenxing1999/shaver.}
}


@inproceedings{DBLP:conf/www/GanLWZSYLL25,
	author = {Xinbiao Gan and
                  Tiejun Li and
                  Liang Wu and
                  Qiang Zhang and
                  Lingyun Song and
                  Bo Yang and
                  Jie Liu and
                  Kai Lu},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {GraphCom: Communication Hierarchy-aware Graph Engine for Distributed
                  Model Training},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {786--795},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714741},
	doi = {10.1145/3696410.3714741},
	timestamp = {Fri, 09 May 2025 20:28:08 +0200},
	biburl = {https://dblp.org/rec/conf/www/GanLWZSYLL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Efficient processing of large-scale graphs with billions to trillions of edges is essential for training graph-based large language models (LLMs) in web-scale systems. The increasing complexity and size of these models create significant communication challenges due to the extensive message exchanges required across distributed nodes. Current graph engines struggle to effectively scale across hundreds of computing nodes because they often overlook variations in communication costs within the interconnection hierarchy. This paper presents GraphCom, a communication-efficient message graph engine for graph processing on supercomputers. Our key idea is to leverage the network topology information to perform communication hierarchy-aware message aggregation, where messages are (i) gathered to the responsible nodes (referred to as monitors) in the source domains, (ii) transferred between monitors, and (iii) scattered to the target nodes in the target domains. GraphCom's aggregation is more aggressive in that each source domain (instead of the source node). We have implemented GraphCom on top of MPI. We demonstrate GraphCom's effectiveness with synthetic benchmarks and real-world graphs, utilizing up to 79,024 nodes and over 1.2 million processor cores, demonstrating that GraphCom surpasses leading graph- parallel systems and state-of-the-art counterparts in both throughput and scalability. Moreover, we have deployed GraphCom on a production supercomputer, where it consistently outperforms the top solutions on the Graph500 list. These results highlight the potential GraphCom has to significantly improve the efficiency of distributed large-scale graph-based LLM training by optimizing communication between distributed systems, making it an invaluable graph engine for distributed training tasks on web-scale graphs.}
}


@inproceedings{DBLP:conf/www/LiaoL025,
	author = {Jinzhi Liao and
                  Zenghua Liao and
                  Xiang Zhao},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {{PSSD:} Making Large Language Models Self-denial via Human Psyche
                  Structure},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {796--806},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714715},
	doi = {10.1145/3696410.3714715},
	timestamp = {Fri, 09 May 2025 20:28:08 +0200},
	biburl = {https://dblp.org/rec/conf/www/LiaoL025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The enhance of accuracy in reasoning results of LLMs arouses the community's interests, wherein pioneering studies investigate post-hoc strategies to rectify potential mistakes. Despite extensive efforts, they are all stuck in a state of resource competition demand ing significant time and computing expenses. The cause of the situation lies in the failure of identifying the fundamental feature of the solutions in this line, coined as the self-denial of LLMs. In other words, LLMs should confidently determine the potential existence of mistakes and carefully execute the targeted correction. As the whole procedure conducts within LLMs, supporting and persuasive references are hard to acquire, while the absence of specific steps towards refining hidden mistakes persists even when errors are acknowledged. In response to the challenges, we present PSSD, which refers to and implements the human psyche structure such that three distinct and interconnected roles contribute to human reasoning. Specifically, PSSD leverages the recent multi-agent paradigm, and is further enhanced with three innovatively conceived roles: (1) the intuition-based id role that provides initial attempts based on benign LLMs; (2) the rule-driven superego role that summarizes rules to regulate the above attempts, and returns specific key points as guidance; and (3) the script-centric ego role that absorbs all procedural information to generate executable script for the final answer prediction. Extensive experiments demonstrate that the proposed design not only better enhance reasoning capabilities, but also seamlessly integrate with current models, leading to superior performance.}
}


@inproceedings{DBLP:conf/www/0003SYLZ25,
	author = {Yongqiang Huang and
                  Zerui Shao and
                  Ziyuan Yang and
                  Zexin Lu and
                  Yi Zhang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {FedRIR: Rethinking Information Representation in Federated Learning},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {807--816},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714612},
	doi = {10.1145/3696410.3714612},
	timestamp = {Tue, 13 May 2025 07:31:04 +0200},
	biburl = {https://dblp.org/rec/conf/www/0003SYLZ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Mobile and Web-of-Things (WoT) devices at the network edge generate vast amounts of data for machine learning applications, yet privacy concerns hinder centralized model training. Federated Learning (FL) allows clients (devices) to collaboratively train a shared model coordinated by a central server without transferring private data. However, inherent statistical heterogeneity among clients presents challenges, often leading to a dilemma between clients' need for personalized local models and the server's goal of building a generalized global model. Existing FL methods typically prioritize either global generalization or local personalization, resulting in a trade-off between these objectives and limiting the full potential of diverse client data. To address this challenge, we propose a novel framework that enhances both global generalization and local personalization by  R ethinking  I nformation  R epresentation in the  Fed erated learning process ( FedRIR ). Specifically, we introduce Masked Client-Specific Learning (MCSL), which isolates and extracts fine-grained client-specific features tailored to each client's unique data characteristics, thereby enhancing personalization. Meanwhile, the Information Distillation Module (IDM) refines global shared features by filtering out redundant client-specific information, resulting in a purer and more robust global representation that enhances generalization. By integrating refined global features with isolated client-specific features, we construct enriched representations that effectively capture both global patterns and local nuances, thereby improving the performance of downstream tasks on the client. Extensive experiments on diverse datasets demonstrate that FedRIR significantly outperforms state-of-the-art FL methods, achieving up to a 3.93% improvement in accuracy while ensuring robustness and stability in heterogeneous environments. The code is publicly available at https://github.com/Deep-Imaging-Group/FedRIR.}
}


@inproceedings{DBLP:conf/www/Wang0DCHC0025,
	author = {Kaibin Wang and
                  Qiang He and
                  Zeqian Dong and
                  Rui Chen and
                  Chuan He and
                  Caslon Chua and
                  Feifei Chen and
                  Yun Yang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Maverick: Personalized Edge-Assisted Federated Learning with Contrastive
                  Training},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {817--828},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714884},
	doi = {10.1145/3696410.3714884},
	timestamp = {Fri, 09 May 2025 20:28:08 +0200},
	biburl = {https://dblp.org/rec/conf/www/Wang0DCHC0025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In an edge-assisted federated learning (FL) system, edge servers aggregate the local models from the clients within their coverage areas to produce intermediate models for the production of the global model. This significantly reduces the communication overhead incurred during the FL process. To accelerate model convergence, FedEdge, the state-of-the-art edge-assisted FL system, trains clients' models in local federations when they wait for the global model in each training round. However, our investigation reveals that it drives the global model towards clients with excessive local training, causing model drifts that undermine model performance for other clients. To tackle this problem, this paper presents Maverick, a new edge-assisted FL system that mitigates model drifts by training personalized local models for clients through contrastive local training. It introduces a model-contrastive loss to facilitate personalized local federated training by driving clients' local models away from the global model and close to their corresponding intermediate models. In addition, Maverick includes anomalous models in contrastive local training as negative samples to accelerate the convergence of clients' local models. Extensive experiments are conducted on three widely-used models trained on three datasets to comprehensively evaluate the performance of Maverick. Compared to state-of-the-art edge-assisted FL systems, Maverick accelerates model convergence by up to 16.2x and improves model accuracy by up to 12.7%.}
}


@inproceedings{DBLP:conf/www/Cheng00YL025,
	author = {Ke Cheng and
                  Zhi Wang and
                  Wen Hu and
                  Tiannuo Yang and
                  Jianguo Li and
                  Sheng Zhang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {{SCOOT:} SLO-Oriented Performance Tuning for {LLM} Inference Engines},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {829--839},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714930},
	doi = {10.1145/3696410.3714930},
	timestamp = {Fri, 09 May 2025 20:28:08 +0200},
	biburl = {https://dblp.org/rec/conf/www/Cheng00YL025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As large language models (LLMs) are gaining increasing popularity across a wide range of web applications, it is of great importance to optimize service-level objectives (SLOs) for LLM inference services to enhance user satisfaction and improve the competitiveness of cloud vendors. In this paper, we observe that adjusting the parameters of LLM inference engines can improve service performance, and the optimal parameter configurations of different services are different. Therefore, we propose SCOOT, an automatic performance tuning system to optimize SLOs for each LLM inference service by tuning the parameters of the inference engine. SCOOT jointly exploits single-objective and multiple-objective Bayesian optimization (BO) techniques to handle various optimization objectives via exploration and exploitation. Moreover, SCOOT prunes the search space with known constraints and adopts a random forest to learn hidden constraints during the tuning process to mitigate invalid exploration. To improve the tuning efficiency, SCOOT utilizes the parallel suggestion to accelerate the tuning process. Extensive experiments demonstrate that SCOOT considerably outperforms existing tuning techniques in SLO optimization while greatly improving the tuning efficiency. Moreover, SCOOT is universally applicable to various LLM inference engines including vLLM and TensorRT-LLM. Currently, SCOOT has already been implemented in the production environment at Ant Group.}
}


@inproceedings{DBLP:conf/www/WangGHLZX25,
	author = {Hao Wang and
                  Shangwei Guo and
                  Jialing He and
                  Hangcheng Liu and
                  Tianwei Zhang and
                  Tao Xiang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Model Supply Chain Poisoning: Backdooring Pre-trained Models via Embedding
                  Indistinguishability},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {840--851},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714624},
	doi = {10.1145/3696410.3714624},
	timestamp = {Fri, 09 May 2025 20:28:08 +0200},
	biburl = {https://dblp.org/rec/conf/www/WangGHLZX25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Pre-trained models (PTMs) are widely adopted across various downstream tasks in the machine learning supply chain. Adopting untrustworthy PTMs introduces significant security risks, where adversaries can poison the model supply chain by embedding hidden malicious behaviors (backdoors) into PTMs. However, existing backdoor attacks to PTMs can only achieve partially task-agnostic and the embedded backdoors are easily erased during the fine-tuning process. This makes it challenging for the backdoors to persist and propagate through the supply chain. In this paper, we propose a novel and severer backdoor attack, TransTroj, which enables the backdoors embedded in PTMs to efficiently transfer in the model supply chain. In particular, we first formalize this attack as an indistinguishability problem between poisoned and clean samples in the embedding space. We decompose embedding indistinguishability into pre- and post-indistinguishability, representing the similarity of the poisoned and reference embeddings before and after the attack. Then, we propose a two-stage optimization that separately optimizes triggers and victim PTMs to achieve embedding indistinguishability. We evaluate TransTroj on four PTMs and six downstream tasks. Experimental results show that our method significantly outperforms SOTA task-agnostic backdoor attacks -- achieving nearly 100% attack success rate on most downstream tasks -- and demonstrates robustness under various system settings. Our findings underscore the urgent need to secure the model supply chain against such transferable backdoor attacks. The code is available at https://github.com/haowang-cqu/TransTroj}
}


@inproceedings{DBLP:conf/www/LiSW025,
	author = {Ken Li and
                  Bin Shi and
                  Jiazhe Wei and
                  Bo Dong},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {{NI-GDBA:} Non-Intrusive Distributed Backdoor Attack Based on Adaptive
                  Perturbation on Federated Graph Learning},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {852--862},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714630},
	doi = {10.1145/3696410.3714630},
	timestamp = {Fri, 09 May 2025 20:28:08 +0200},
	biburl = {https://dblp.org/rec/conf/www/LiSW025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated Graph Learning (FedGL) is an emerging Federated Learning (FL) framework that learns the graph data from various clients to train better Graph Neural Networks(GNNs) model. Owing to concerns regarding the security of such framework, numerous studies have attempted to execute backdoor attacks on FedGL, with a particular focus on distributed backdoor attacks. However, all existing methods posting distributed backdoor attack on FedGL only focus on injecting distributed backdoor triggers into the training data of each malicious client, which will cause model performance degradation on original task and is not always effective when confronted with robust federated learning defense algorithms, leading to low success rate of attack. What's more, the backdoor signals introduced by the malicious clients may be smoothed out by other clean signals from the honest clients, which potentially undermining the performance of the attack. To address the above significant shortcomings, we propose a non-intrusive graph distributed backdoor attack(NI-GDBA) that does not require backdoor triggers to be injected in the training data. Our attack trains an adaptive perturbation trigger generator model for each malicious client to learn the natural backdoor from the GNN model downloading from the server with the malicious client's local data. In contrast to traditional distributed backdoor attacks on FedGL via trigger injection in training data, our attack on different datasets such as Molecules and Bioinformatics have higher attack success rate, stronger persistence and stealth, and has no negative impact on the performance of the global GNN model. We also explore the robustness of NI-GDBA under different defense strategies, and based on our extensive experimental studies, we show that our attack method is robust to current federated learning defense methods, thus it is necessary to consider non-intrusive distributed backdoor attacks on FedGL as a novel threat that requires custom defenses. Code is available at: https://github.com/kiyotakali/NI-GDBA}
}


@inproceedings{DBLP:conf/www/XueWYMQT025,
	author = {Yanni Xue and
                  Jiakai Wang and
                  Zixin Yin and
                  Yuqing Ma and
                  Haotong Qin and
                  Renshuai Tao and
                  Xianglong Liu},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Dual Intention Escape: Penetrating and Toxic Jailbreak Attack against
                  Large Language Models},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {863--871},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714654},
	doi = {10.1145/3696410.3714654},
	timestamp = {Fri, 09 May 2025 20:28:08 +0200},
	biburl = {https://dblp.org/rec/conf/www/XueWYMQT025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recently, the jailbreak attack, which generates adversarial prompts to bypass safety measures and mislead large language models (LLMs) to output harmful answers, has attracted extensive interest due to its potential to reveal the vulnerabilities of LLMs. However, ignoring the exploitation of the characteristics in intention understanding, existing studies could only generate prompts with weak attacking ability, failing to evade defenses (e.g., sensitive word detect) and causing malice(e.g., harmful outputs). Motivated by the mechanism in the psychology of human misjudgment, we propose a dual intention escape (DIE) jailbreak attack framework to generate more stealthy and toxic prompts to deceive LLMs to output harmful content. For stealthiness, inspired by the anchoring effect, we designed the Intention-anchored Malicious Concealment(IMC) module that hides the harmful intention behind a generated anchor intention by the recursive decomposition block and contrary intention nesting block. Since the anchor intention will be received first, the LLMs might pay less attention to the harmful intention and enter response status. For toxicity, we propose the Intention-reinforced Malicious Inducement (IMI) module based on the availability bias mechanism in a progressive malicious prompting approach. Due to the ongoing emergence of statements correlated to harmful intentions, the output content of LLMs will be closer to these more accessible intentions, i.e., more toxic. We conducted extensive experiments under black-box settings, supporting that DIE could achieve 100% ASR-R and 92.9% ASR-G against GPT3.5-turbo.}
}


@inproceedings{DBLP:conf/www/MaiHCPL0D025,
	author = {Wuyuao Mai and
                  Geng Hong and
                  Pei Chen and
                  Xudong Pan and
                  Baojun Liu and
                  Yuan Zhang and
                  Haixin Duan and
                  Min Yang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {You Can't Eat Your Cake and Have It Too: The Performance Degradation
                  of LLMs with Jailbreak Defense},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {872--883},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714632},
	doi = {10.1145/3696410.3714632},
	timestamp = {Fri, 09 May 2025 20:28:08 +0200},
	biburl = {https://dblp.org/rec/conf/www/MaiHCPL0D025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the rise of generative large language models (LLMs) like LLaMA and ChatGPT, these models have significantly transformed daily life and work by providing advanced insights. However, as jailbreak attacks continue to circumvent built-in safety mechanisms, exploiting carefully crafted scenarios or tokens, the safety risks of LLMs have come into focus. While numerous defense strategies-such as prompt detection, modification, and model fine-tuning-have been proposed to counter these attacks, a critical question arises: do these defenses compromise the utility and usability of LLMs for legitimate users? Existing research predominantly focuses on the effectiveness of defense strategies without thoroughly examining their impact on performance, leaving a gap in understanding the trade-offs between LLM safety and performance. Our research addresses this gap by conducting a comprehensive study on the utility degradation, safety elevation, and exaggerated-safety escalation of LLMs with jailbreak defense strategies. We propose  USEBench , a novel benchmark designed to evaluate these aspects, along with  USEIndex , a comprehensive metric for assessing overall model performance. Through experiments on seven state-of-the-art LLMs, we found that mainstream jailbreak defenses fail to ensure both safety and performance simultaneously. Although model-finetuning performs the best overall, their effectiveness varies across LLMs. Furthermore, vertical comparisons reveal that developers commonly prioritize performance over safety when iterating or fine-tuning their LLMs.}
}


@inproceedings{DBLP:conf/www/ChenDLF0G0025,
	author = {Ruonan Chen and
                  Ye Dong and
                  Yizhong Liu and
                  Tingyu Fan and
                  Dawei Li and
                  Zhenyu Guan and
                  Jianwei Liu and
                  Jianying Zhou},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {FLock: Robust and Privacy-Preserving Federated Learning based on Practical
                  Blockchain State Channels},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {884--895},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714666},
	doi = {10.1145/3696410.3714666},
	timestamp = {Fri, 09 May 2025 20:28:08 +0200},
	biburl = {https://dblp.org/rec/conf/www/ChenDLF0G0025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated Learning  (FL) is a distributed machine learning paradigm that allows multiple clients to train models collaboratively without sharing local data. Numerous works have explored security and privacy protection in FL, as well as its integration with blockchain technology. However, existing FL works still face critical issues. i) It is difficult to achieving  poisoning robustness  and  data privacy  while ensuring high  model accuracy.  Malicious clients can launch  poisoning attacks  that degrade the global model. Besides, aggregators can infer private data from the gradients, causing  privacy leakages.  Existing privacy-preserving poisoning defense FL solutions suffer from decreased model accuracy and high computational overhead. ii) Blockchain-assisted FL records iterative gradient updates on-chain to prevent model tampering, yet existing schemes are not compatible with practical blockchains and incur high costs for maintaining the gradients on-chain. Besides, incentives are overlooked, where unfair reward distribution hinders the sustainable development of the FL community. In this work, we propose FLock, a robust and privacy-preserving FL scheme based on practical blockchain state channels. First, we propose a lightweight secure  Multi-party Computation  (MPC)-friendly robust aggregation method through quantization, median, and Hamming distance, which could resist poisoning attacks against up to <50% malicious clients. Besides, we propose communication-efficient Shamir's secret sharing-based MPC protocols to protect data privacy with high model accuracy. Second, we utilize blockchain off-chain state channels to achieve immutable model records and incentive distribution. FLock achieves cost-effective compatibility with practical cryptocurrency platforms, e.g. Ethereum, along with fair incentives, by merging the secure aggregation into a multi-party state channel. In addition, a pipelined  Byzantine Fault-Tolerant  (BFT) consensus is integrated where each aggregator can reconstruct the final aggregated results. Lastly, we implement FLock and the evaluation results demonstrate that FLock enhances robustness and privacy, while maintaining efficiency and high model accuracy. Even with 25 aggregators and 100 clients, FLock can complete one secure aggregation for ResNet in 2 minutes over a WAN. FLock successfully implements secure aggregation with such a large number of aggregators, thereby enhancing the fault tolerance of the aggregation.}
}


@inproceedings{DBLP:conf/www/FangWG25,
	author = {Minghong Fang and
                  Xilong Wang and
                  Neil Zhenqiang Gong},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Provably Robust Federated Reinforcement Learning},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {896--909},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714728},
	doi = {10.1145/3696410.3714728},
	timestamp = {Fri, 09 May 2025 20:28:08 +0200},
	biburl = {https://dblp.org/rec/conf/www/FangWG25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated reinforcement learning (FRL) allows agents to jointly learn a global decision-making policy under the guidance of a central server. While FRL has advantages, its decentralized design makes it prone to poisoning attacks. To mitigate this, Byzantine-robust aggregation techniques tailored for FRL have been introduced. Yet, in our work, we reveal that these current Byzantine-robust techniques are not immune to our newly introduced Normalized attack. Distinct from previous attacks that targeted enlarging the distance of policy updates before and after an attack, our Normalized attack emphasizes on maximizing the angle of deviation between these updates. To counter these threats, we develop an ensemble FRL approach that is provably secure against both known and our newly proposed attacks. Our ensemble method involves training multiple global policies, where each is learnt by a group of agents using any foundational aggregation rule. These well-trained global policies then individually predict the action for a specific test state. The ultimate action is chosen based on a majority vote for discrete action systems or the geometric median for continuous ones. Our experimental results across different settings show that the Normalized attack can greatly disrupt non-ensemble Byzantine-robust methods, and our ensemble approach offers substantial resistance against poisoning attacks.}
}


@inproceedings{DBLP:conf/www/RenC0S0TL25,
	author = {Jie Ren and
                  Kangrui Chen and
                  Chen Chen and
                  Vikash Sehwag and
                  Yue Xing and
                  Jiliang Tang and
                  Lingjuan Lyu},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Self-Comparison for Dataset-Level Membership Inference in Large (Vision-)Language
                  Model},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {910--920},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714703},
	doi = {10.1145/3696410.3714703},
	timestamp = {Fri, 09 May 2025 20:28:08 +0200},
	biburl = {https://dblp.org/rec/conf/www/RenC0S0TL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Large Language Models (LLMs) and Vision-Language Models (VLMs) have made significant advancements in a wide range of natural language processing and vision-language tasks. Access to large web-scale datasets has been a key factor in their success. However, concerns have been raised about the unauthorized use of copyrighted materials and potential copyright infringement. Existing methods, such as sample-level Membership Inference Attacks (MIA) and distribution-based dataset, inference distinguish member and non-member data by leveraging the common observation that models tend to memorize and show greater confidence in member data. Nevertheless, these methods face challenges when applied to LLMs and VLMs, such as the requirement for ground-truth member data or non-member data that shares the same distribution as the test data. In this paper, we propose a novel dataset-level membership inference method based on Self-Comparison. We find that a member prefix followed by a non-member suffix (paraphrased from a member suffix) can further trigger the model's memorization on training data. Instead of directly comparing member and non-member data, we introduce paraphrasing to the second half of the sequence and evaluate how the likelihood changes before and after paraphrasing. Unlike prior approaches, our method does not require access to ground-truth member data or non-member data in identical distribution, making it more practical. Extensive experiments demonstrate that our proposed method outperforms traditional MIA and dataset inference techniques across various datasets and models, including GPT-4o.}
}


@inproceedings{DBLP:conf/www/WangL0Z025,
	author = {Runze Wang and
                  Jiahao Liu and
                  Miao Hu and
                  Yipeng Zhou and
                  Di Wu},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Local Differentially Private Release of Infinite Streams With Temporal
                  Relevance},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {921--930},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714619},
	doi = {10.1145/3696410.3714619},
	timestamp = {Mon, 16 Jun 2025 15:29:08 +0200},
	biburl = {https://dblp.org/rec/conf/www/WangL0Z025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The data stream generated by users on web applications is often collected using a local differential privacy (LDP) approach to ensure privacy. This approach offers rigorous theoretical guarantees and low computational overhead, albeit at the expense of data utility. Data utility encompasses both the value of individual data points and the temporal relevance that exists between them, but existing studies primarily focus on enhancing the former utility while neglecting the latter. Furthermore, the collected data often requires cleaning, and we have demonstrated through a case study that data stream lacking time relevance poses a significant risk to users' privacy during the cleaning process. In this paper, for the first time we present an online LDP publishing mechanism while preserving the inherent temporal relevance for the infinite stream, called the Sampling Period Perturbation Algorithm (SPPA). Specifically, we model the temporal relevance between data points as the Fourier interpolation function, resulting in a computational complexity reduction from O(n 2 ) to O(n log n) when compared with the conventional Markov approach in the offline setting. To strike a better balance between privacy and utility, we add noise to the sampling period due to its minimal impact on sensitivity, which is analyzed by our novel concepts of (ε,τ)-temporal indistinguishability and (ε,w,τ)-event LDP. Through extensive experiments, SPPA exhibits superior performance in terms of both data utility and privacy preservation compared to the state-of-the-art baselines. In particular, when ε=1, compared with the state-of-the-art baseline, SPPA diminishes the MSE by up to 64.2%, and raises the event monitoring efficiency by up to 21.4%.}
}


@inproceedings{DBLP:conf/www/0012WYY0Y25,
	author = {He Zhang and
                  Bang Wu and
                  Xiangwen Yang and
                  Xingliang Yuan and
                  Xiaoning Liu and
                  Xun Yi},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Dynamic Graph Unlearning: {A} General and Efficient Post-Processing
                  Method via Gradient Transformation},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {931--944},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714911},
	doi = {10.1145/3696410.3714911},
	timestamp = {Fri, 09 May 2025 20:28:08 +0200},
	biburl = {https://dblp.org/rec/conf/www/0012WYY0Y25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Dynamic graph neural networks (DGNNs) have emerged and been widely deployed in various web applications (e.g., Reddit) to serve users (e.g., personalized content delivery) due to their remarkable ability to learn from complex and dynamic user interaction data. Despite benefiting from high-quality services, users have raised privacy concerns, such as misuse of personal data (e.g., dynamic user-user/item interaction) for model training, requiring DGNNs to "forget" their data to meet AI governance laws (e.g., the "right to be forgotten" in GDPR). However, current static graph unlearning studies cannot  unlearn dynamic graph elements  and exhibit limitations such as the model-specific design or reliance on pre-processing, which disenable their practicability in dynamic graph unlearning. To this end, we study the dynamic graph unlearning for the first time and propose an  effective, efficient, general,  and  post-processing  method to implement DGNN unlearning. Specifically, we first formulate dynamic graph unlearning in the context of continuous-time dynamic graphs, and then propose a method called Gradient Transformation that directly maps the unlearning request to the desired parameter update. Comprehensive evaluations on six real-world datasets and state-of-the-art DGNN backbones demonstrate its effectiveness (e.g., limited drop or obvious improvement in utility) and efficiency (e.g., 7.23× speed-up) advantages. Additionally, our method has the potential to handle future unlearning requests with significant performance gains (e.g., 32.59× speed-up).}
}


@inproceedings{DBLP:conf/www/LeeLK0K25,
	author = {Kiho Lee and
                  Kyungchan Lim and
                  Hyoungshick Kim and
                  Yonghwi Kwon and
                  Doowon Kim},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {7 Days Later: Analyzing Phishing-Site Lifespan After Detected},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {945--956},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714678},
	doi = {10.1145/3696410.3714678},
	timestamp = {Thu, 01 May 2025 20:27:23 +0200},
	biburl = {https://dblp.org/rec/conf/www/LeeLK0K25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Phishing attacks continue to be a major threat to internet users, causing data breaches, financial losses, and identity theft. This study provides an in-depth analysis of the lifespan and evolution of phishing websites, focusing on their survival strategies and evasion techniques. We analyze 286,237 unique phishing URLs over five months using a custom web crawler based on Puppeteer and Chromium. Our crawler runs on a 30-minute cycle, systematically checking the operational status of phishing websites by collecting their HTTP status codes, screenshots, HTML, and HTTP data. Temporal and survival analyses, along with statistical tests, are used to examine phishing website lifecycles, evolution, and evasion tactics. Our findings show that the average lifespan of phishing websites is 54 hours (2.25 days) with a median of 5.46 hours, indicating rapid takedown of many sites while a subset remains active longer. Interestingly, logistic-themed phishing websites (e.g., USPS) operate within a compressed timeframe (1.76 hours) compared to other brands (e.g., Facebook). We further analyze detection effectiveness using Google Safe Browsing (GSB). We find that GSB detects only 18.4% of phishing websites, taking an average of 4.5 days. Notably, 83.93% of phishing sites are already taken down before GSB detection, meaning GSB requires more prompt detection. Moreover, 16.07% of phishing sites persist beyond this point, surviving for an additional 7.2 days on average, resulting in an average total lifespan of approximately 12 days. We reveal that DNS resolution error is the main cause (67%) of phishing website takedowns. Finally, we uncover that phishing sites with extensive visual changes (more than 100 times) exhibit a median lifespan of 17 days, compared to 1.93 hours for those with minimal modifications. These results highlight the dynamic nature of phishing attacks, the challenges in detection and prevention, and the need for more rapid and comprehensive countermeasures against evolving phishing tactics.}
}


@inproceedings{DBLP:conf/www/LimLJ0KK25,
	author = {Kyungchan Lim and
                  Kiho Lee and
                  Fujiao Ji and
                  Yonghwi Kwon and
                  Hyoungshick Kim and
                  Doowon Kim},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {What's in Phishers: {A} Longitudinal Study of Security Configurations
                  in Phishing Websites and Kits},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {957--968},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714710},
	doi = {10.1145/3696410.3714710},
	timestamp = {Thu, 01 May 2025 20:27:24 +0200},
	biburl = {https://dblp.org/rec/conf/www/LimLJ0KK25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Phishing attacks pose a significant threat to Internet users. Understanding the security posture of phishing infrastructure is crucial for developing effective defense strategies, as it helps identify potential weaknesses that attackers might exploit. Despite extensive research, there may still be a gap in fully understanding these security weaknesses. To address this important issue, this paper presents a longitudinal study of security configurations and vulnerabilities in phishing websites and associated kits. We focus on two main areas: (1) analyzing the security configurations of phishing websites and servers, particularly HTTP headers and application-level security, and (2) examining the prevalence and types of vulnerabilities in phishing kits. We analyze data from 906,731 distinct phishing websites collected over 2.5 years, covering HTML headers, client-side resources, and phishing kits. Our findings suggest that phishing websites often employ weak security configurations, with 88.8% of the 13,344 collected phishing kits containing at least one potential vulnerability, and 12.5% containing backdoor vulnerabilities. These vulnerabilities present an opportunity for defenders to shift from passive defense to active disruption of phishing operations. Our research proposes a new approach to leverage weaknesses in phishing infrastructure, allowing defenders to take proactive actions to disable phishing sites earlier and reduce their effectiveness.}
}


@inproceedings{DBLP:conf/www/GhoshSUHC25,
	author = {Medhasree Ghosh and
                  Swapnil Srivastava and
                  Apoorva Upadhyaya and
                  Raju Halder and
                  Joydeep Chandra},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {{CATALOG:} Exploiting Joint Temporal Dependencies for Enhanced Phishing
                  Detection on Ethereum},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {969--977},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714903},
	doi = {10.1145/3696410.3714903},
	timestamp = {Fri, 09 May 2025 20:28:08 +0200},
	biburl = {https://dblp.org/rec/conf/www/GhoshSUHC25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Phishing scams on Ethereum have expanded with the surge of the platform, posing substantial challenges due to the sheer similarity in user behaviours and sparse temporal instances. Current methods often fail to tackle these concerns and overlook the temporal sequence of transactions, resulting in suboptimal performance. In this paper, we aim to address these gaps by focusing on the alignment of two aspects: (1) User-specific local temporal behavior, and (2) Divergences from global activity patterns of the network. Hence, we introduce  CATALOG  (CApturing joint TemporAl dependencies from LOcal and Global user behaviour), a novel representation learning model that jointly captures the local and global user behviours and their correlations by leveraging a dual cross-attention mechanism paired with a bi-directional Masked Language Modelling (MLM) transformer. Our proposed model simultaneously learns from local behavioral shifts, global market trends, and contextually enriched embeddings, effectively distinguishing phishing from non-phishing users while addressing existing research gaps. Extensive experiments on real-world Ethereum transaction data show that our framework improves phishing detection by 7-8% in the F1-Score along with demonstrating the generalization to Ethereum versions 1.0 and 2.0.}
}


@inproceedings{DBLP:conf/www/Shi0CS00LY25,
	author = {Zewei Shi and
                  Ruoxi Sun and
                  Jieshan Chen and
                  Jiamou Sun and
                  Minhui Xue and
                  Yansong Gao and
                  Feng Liu and
                  Xingliang Yuan},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {50 Shades of Deceptive Patterns: {A} Unified Taxonomy, Multimodal
                  Detection, and Security Implications},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {978--989},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714593},
	doi = {10.1145/3696410.3714593},
	timestamp = {Fri, 09 May 2025 20:28:08 +0200},
	biburl = {https://dblp.org/rec/conf/www/Shi0CS00LY25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Deceptive patterns (DPs) are user interface designs deliberately crafted to manipulate users into unintended decisions, often by exploiting cognitive biases for the benefit of companies or services. While numerous studies have explored ways to identify these deceptive patterns, many existing solutions require significant human intervention and struggle to keep pace with the evolving nature of deceptive designs. To address these challenges, we expanded the deceptive pattern taxonomy from security and privacy perspectives, refining its categories and scope. We created a comprehensive dataset of deceptive patterns by integrating existing small-scale datasets with new samples, resulting in 6,725 images and 10,421 DP instances from mobile apps and websites. We then developed DPGuard, a novel automatic tool leveraging commercial multimodal large language models (MLLMs) for deceptive pattern detection. Experimental results show that DPGuard outperforms state-of-the-art methods. An extensive empirical evaluation on 2,000 popular mobile apps and websites reveals that 25.7% of mobile apps and 49.0% websites feature at least one deceptive pattern instance. Through 4 unexplored case studies that inform security implications, we highlight the critical importance of the unified taxonomy in addressing the growing challenges of Internet deception.}
}


@inproceedings{DBLP:conf/www/TsaiMZZ025,
	author = {Elisa Tsai and
                  Neal Mangaokar and
                  Boyuan Zheng and
                  Haizhong Zheng and
                  Atul Prakash},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Harmful Terms and Where to Find Them: Measuring and Modeling Unfavorable
                  Financial Terms and Conditions in Shopping Websites at Scale},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {990--1003},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714573},
	doi = {10.1145/3696410.3714573},
	timestamp = {Fri, 09 May 2025 20:28:08 +0200},
	biburl = {https://dblp.org/rec/conf/www/TsaiMZZ025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Terms and conditions for online shopping websites often contain terms that can have significant financial consequences for customers. Despite their impact, there is currently no comprehensive understanding of the types and potential risks associated with unfavorable financial terms. Furthermore, there are no publicly available detection systems or datasets to systematically identify or mitigate these terms. In this paper, we take the first steps toward solving this problem with three key contributions. First,  we introduce  TermMiner,  an automated data collection and topic modeling pipeline to understand the landscape of unfavorable financial terms.  Second,  we create  ShopTC-100K,  a dataset of terms and conditions from shopping websites in the Tranco top 100K list, comprising 1.8 million terms from 8,251 websites. Consequently, we develop a taxonomy of 22 types from 4 categories of unfavorable financial terms---spanning purchase, post-purchase, account termination, and legal aspects.  Third,  we build  TermLens,  an automated detector that uses Large Language Models (LLMs) to identify unfavorable financial terms. Fine-tuned on an annotated dataset,  TermLens  achieves an F1 score of 94.6% and a false positive rate of 2.3% using GPT-4o. When applied to shopping websites from the Tranco top 100K, we find that 42.06% of these sites contain at least one unfavorable financial term, with such terms being more prevalent on less popular websites. Case studies further highlight the financial risks and customer dissatisfaction associated with unfavorable financial terms, as well as the limitations of existing ecosystem defenses.}
}


@inproceedings{DBLP:conf/www/WangMSY25,
	author = {Jiaxin Wang and
                  Qian'ang Mao and
                  Hongliang Sun and
                  Jiaqi Yan},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Gamblers or Delegatees: Identifying Hidden Participant Roles in Crypto
                  Casinos},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {1004--1015},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714689},
	doi = {10.1145/3696410.3714689},
	timestamp = {Fri, 09 May 2025 20:28:08 +0200},
	biburl = {https://dblp.org/rec/conf/www/WangMSY25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the development of blockchain technology, crypto gambling has gained popularity due to its high level of anonymity. However, similar to traditional casinos, crypto casinos are controlled by a few internal  Delegatees , making it impossible for them to achieve complete transparency and fairness. These delegatees are hidden among  gamblers  and are difficult to identify and distinguish in anonymous and large-scale blockchain transaction networks. This paper proposes an unsupervised dual-stage role identification method to adaptively identify key roles and hidden delegatees in label-sparse crypto casinos. Specifically, inspired by voting-style transaction patterns, we propose a novel voting influence metric for key node identification. This metric is based on one-dimensional structural entropy to capture global dissemination capability. Subsequently, we develop a multi-view graph neural network framework enhanced with two-dimensional global structural entropy minimization and self-supervised contrastive learning to improve the robustness and interpretability of hidden role partitioning. Experiments on real-world cases of the most mainstream blockchains-Ethereum, TRON, and Arbitrum-demonstrate that our proposed method effectively reveals distinct role compositions and collusion patterns, distinguishing between gamblers and delegatees. Our results achieve a higher match with identities confirmed by judicial authorities than existing methods, indicating the effectiveness and generalizability of our approach in enhancing security and regulation oversight.}
}


@inproceedings{DBLP:conf/www/HuynhDHCST0V25,
	author = {Phuong Duy Huynh and
                  Son Hoang Dau and
                  Nicholas Huppert and
                  Joshua Cervenjak and
                  Hoonie Sun and
                  Hong Yen Tran and
                  Xiaodong Li and
                  Emanuele Viterbo},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Serial Scammers and Attack of the Clones: How Scammers Coordinate
                  Multiple Rug Pulls on Decentralized Exchanges},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {1016--1033},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714919},
	doi = {10.1145/3696410.3714919},
	timestamp = {Fri, 09 May 2025 20:28:08 +0200},
	biburl = {https://dblp.org/rec/conf/www/HuynhDHCST0V25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We explored the ubiquitous phenomenon of  serial scammers,  each of whom deployed dozens to thousands of addresses to conduct a series of  similar  Rug Pulls on popular decentralized exchanges. We first constructed two datasets of around 384,000 scammer addresses behind all one-day Simple Rug Pulls on Uniswap (Ethereum) and Pancakeswap (BSC), and identified distinctive  scam patterns  including  star, chain,  and  major (scam-funding) flow.  These patterns, which collectively cover about 40% of all scammer addresses in our datasets, reveal typical ways scammers run multiple Rug Pulls and organize the money flow among different addresses. We then studied the more general concept of  scam cluster,  which comprises scammer addresses linked together via direct ETH/BNB transfers or behind the same scam pools. We found that scam token contracts are highly similar within each cluster (average similarities >70%) and dissimilar across different clusters (average similarities <30%), corroborating our view that each cluster belongs to the same scammer/scam organization. Lastly, we analyze the scam profit of individual scam pools and clusters, employing a novel  cluster-aware profit formula  that takes into account the important role of  wash traders.  The analysis shows that the existing formula inflates the profit by at least 35% on Uniswap and 24% on Pancakeswap.}
}


@inproceedings{DBLP:conf/www/MuzammilPLRN25,
	author = {Muhammad Muzammil and
                  Abisheka Pitumpe and
                  Xigao Li and
                  Amir Rahmati and
                  Nick Nikiforakis},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {The Poorest Man in Babylon: {A} Longitudinal Study of Cryptocurrency
                  Investment Scams},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {1034--1045},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714588},
	doi = {10.1145/3696410.3714588},
	timestamp = {Fri, 09 May 2025 20:28:08 +0200},
	biburl = {https://dblp.org/rec/conf/www/MuzammilPLRN25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Governments and regulatory bodies have recognized investment scams as a prevalent form of cryptocurrency fraud. These scams typically use professional-looking websites to lure unsuspecting victims with promises of unrealistically high returns. In this paper, we introduce Crimson, a distributed system designed to continuously detect cryptocurrency investment scam websites as they are created in the wild. During the first 8 months of 2024, Crimson processed approximately 6 billion domain names and classified 43,572 unique cryptocurrency investment scam websites in real-time. Beyond detection, we provide insights into the design and infrastructure of these websites that can help users recognize scam patterns and assist hosting providers in detecting and blocking such sites. Furthermore, we investigate the inclusion of our detected scam websites in block-lists used by popular web browsers and applications, finding that the vast majority of these websites were absent. On the financial side, by analyzing the transactions incoming to scammer wallets on 6.7% of the sites detected by Crimson, we observe an estimated lower bound of 2.04M USD in losses due to cryptocurrency investment scams.}
}


@inproceedings{DBLP:conf/www/SangFYWZJY25,
	author = {Anyuan Sang and
                  Xuezheng Fan and
                  Li Yang and
                  Yuchen Wang and
                  Lu Zhou and
                  Junbo Jia and
                  Huipeng Yang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {{STGAN:} Detecting Host Threats via Fusion of Spatial-Temporal Features
                  in Host Provenance Graphs},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {1046--1057},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714925},
	doi = {10.1145/3696410.3714925},
	timestamp = {Tue, 13 May 2025 07:31:05 +0200},
	biburl = {https://dblp.org/rec/conf/www/SangFYWZJY25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As the complexity and frequency of cyberattacks, such as Advanced Persistent Threats (APTs) and ransomware, continue to escalate, traditional anomaly detection methods have proven inadequate in addressing these sophisticated, multi-faceted threats. Recently, Host Provenance Graphs (HPGs) have played a crucial role in analyzing system-level interactions, detecting anomalous behaviors, and tracing attack chains. However, existing provenance-based detection methods primarily rely on single-dimensional feature analysis, which fails to capture the dynamic and multi-dimensional patterns of modern APT attacks, resulting in insufficient detection performance. To overcome this limitation, we introduce STGAN, a model that integrates spatial-temporal graphs into host provenance graph modeling. STGAN applies temporal and spatial encoding to dynamic provenance graphs to extract temporal, spatial, and semantic features, constructing a comprehensive feature representation. This representation is further fused and enhanced using a multi-head self-attention mechanism, followed by anomaly detection. Through extensive evaluations on three widely-used provenance graph datasets, we demonstrate that our approach consistently outperforms current state-of-the-art techniques in terms of detection performance. Additionally, we contribute to the research community by releasing our datasets and code, facilitating further exploration and validation.}
}


@inproceedings{DBLP:conf/www/ZhangZWLS0Y25,
	author = {Tianyu Zhang and
                  Han Zhang and
                  Yunze Wei and
                  Yahui Li and
                  Xingang Shi and
                  Jilong Wang and
                  Xia Yin},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {{ACME++:} {A} Secure Authorization Mechanism for {ACME} Clients in
                  the Web {PKI} Ecosystem},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {1058--1067},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714763},
	doi = {10.1145/3696410.3714763},
	timestamp = {Fri, 09 May 2025 20:28:08 +0200},
	biburl = {https://dblp.org/rec/conf/www/ZhangZWLS0Y25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Automatic Certificate Management Environment (ACME) protocol automates the issuance and renewal of secure socket layer certificates, simplifying the management of large-scale certificate deployments. To reduce the load on Certificate Authority (CA) servers, ACME employs a caching mechanism that stores domain validation (DV) results for 30 days. However, this mechanism allows attackers to reuse previously authorized results, potentially bypassing the DV process. In this paper, we introduce the ACME  Authz  Cache Attack, whereby an attacker can obtain fraudulent certificates without domain control. We demonstrate that even the prominent CA, Let's Encrypt, is vulnerable to this attack. To mitigate this, we propose ACME++, an enhanced protocol that binds the client's IP address and a unique identifier to the ACME account, ensuring secure authorization for each new client and effectively preventing the ACME  Authz  Cache Attack. Our implementation of ACME++ shows that it introduces little overhead to the CA server.}
}


@inproceedings{DBLP:conf/www/Meng000Q025,
	author = {Wenwen Meng and
                  Chuan Ma and
                  Ming Ding and
                  Chunpeng Ge and
                  Yuwen Qian and
                  Tao Xiang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Beyond Single Tabs: {A} Transformative Few-Shot Approach to Multi-Tab
                  Website Fingerprinting Attacks},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {1068--1077},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714811},
	doi = {10.1145/3696410.3714811},
	timestamp = {Fri, 09 May 2025 20:28:08 +0200},
	biburl = {https://dblp.org/rec/conf/www/Meng000Q025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Website Fingerprinting (WF) attacks allow passive eavesdroppers to deduce the websites a user visits by analyzing encrypted traffic, threatening user privacy. While current WF attacks achieve high accuracy, they typically assume single-tab browsing, which is unrealistic as users often open multiple tabs, creating mixed traffic. Existing multi-tab WF approaches require large datasets and frequent retraining due to evolving website content, limiting their practicality. In this paper, we introduce Few-shot Multi-tab Website Fingerprinting (FMWF), a novel approach designed to address the limitations of existing multi-tab WF attacks. FMWF directly tackles the challenges of mixed, overlapping traffic traces generated from multi-tab browsing, leveraging two key innovations: (1) an advanced data augmentation technique that synthesizes realistic multi-tab traffic sequences from easily collected single-tab traces, thereby dramatically reducing the need for large-scale real-world traffic data; and (2) a powerful fine-tuning algorithm based on transfer learning that adapts pre-trained models to new, multi-tab environments with minimal additional data. This two-stage framework enables FMWF to capture the complex effectively, overlapping traffic patterns inherent in multi-tab browsing while maintaining a high level of flexibility and significantly lowering computational and data collection burdens. Our experiments, conducted using real traffic traces collected from three widely-used browsers-Microsoft Edge, Google Chrome, and Tor Browser-highlight the superior performance of FMWF in both closed-world and open-world scenarios. Notably, FMWF achieves a minimum 12.3% improvement in accuracy compared to ARES (SP'23) [7], TMWF (CCS'23) [13], and BAPM (ACSAC'21) [10] in the open-world scenario. The code with related datasets is available at https://github.com/WW-Meng/FMWF.}
}


@inproceedings{DBLP:conf/www/ChengZLSDD025,
	author = {Yifei Cheng and
                  Yujia Zhu and
                  Baiyang Li and
                  Peishuai Sun and
                  Yong Ding and
                  Xinhao Deng and
                  Qingyun Liu},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {{HOLMES} {\&} {WATSON:} {A} Robust and Lightweight {HTTPS} Website
                  Fingerprinting through {HTTP} Version Parallelism},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {1078--1092},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714578},
	doi = {10.1145/3696410.3714578},
	timestamp = {Fri, 09 May 2025 20:28:08 +0200},
	biburl = {https://dblp.org/rec/conf/www/ChengZLSDD025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Website Fingerprinting (WF) is a traffic analysis technique that aims to identify websites visited by users through the analysis of encrypted traffic patterns. Existing approaches often exhibit limited robustness against network variability and concept drift, resulting in significant performance degradation under real-world HTTPS conditions. Moreover, these methods typically require large-scale training datasets and substantial computational resources, which further increases the complexity of deployment. In this paper, we propose HOLMES, a novel approach that exploits HTTP version parallelism to extract enhanced application-layer features. These features, including the number of web resources transmitting in various HTTP versions, expose up to 4.28 bits of information-surpassing 98% of previously reported features and demonstrate increased stability across varying network conditions. Complementary to this, we introduce WATSON, a lightweight classification method based on lazy learning, which substantially reduces the dependency on large training datasets. To further enhance the identification accuracy, we incorporate two fingerprint-specific distance metrics that ensure high intra-class similarity. Our experimental evaluation demonstrates that HOLMES & WATSON significantly enhance both robustness and efficiency, achieving an average accuracy of 87.7% with only a single sample per website, marking an improvement of over 15% compared to state-of-the-art methods.}
}


@inproceedings{DBLP:conf/www/TrampertH0SR025,
	author = {Leon Trampert and
                  Lorenz Hetterich and
                  Lukas Gerlach and
                  Mona Schappert and
                  Christian Rossow and
                  Michael Schwarz},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Peripheral Instinct: How External Devices Breach Browser Sandboxes},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {1093--1104},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714637},
	doi = {10.1145/3696410.3714637},
	timestamp = {Fri, 09 May 2025 20:28:08 +0200},
	biburl = {https://dblp.org/rec/conf/www/TrampertH0SR025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Browser APIs such as WebHID, WebUSB, Web Serial, and Web MIDI enable web applications to interact directly with external devices. The support of such APIs in Chromium-based browsers, such as Chrome and Edge, radically changes the threat model for peripherals and increases the attack surface. In the past, devices could assume a trusted host, i.e., the operating system. Now, the host is a potentially malicious website and cannot be trusted. We show how this changed threat model leads to security and privacy problems, up to a complete compromise of the operating system. While the API specifications list initial security considerations, they shift the responsibility to (unprepared) device vendors. We systematically analyze the security implications of external devices exposed by such new APIs. By reverse-engineering peripheral devices of several popular widespread vendors, we show that many vendors allow controlling devices via Web APIs up to reprogramming or even fully replacing the firmware. Consequently, web attackers can reprogram devices with malicious payloads and custom firmware without requiring any physical interaction. To demonstrate the security implications, we build several full-chain exploits, leading to arbitrary code execution on the victim system, circumventing the browser sandbox. Our research shows that browser security should not rely on the secure implementation of third-party hardware.}
}


@inproceedings{DBLP:conf/www/CalzavaraCF25,
	author = {Stefano Calzavara and
                  Samuele Casarin and
                  Riccardo Focardi},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Dynamic Security Analysis of JavaScript: Are We There Yet?},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {1105--1115},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714614},
	doi = {10.1145/3696410.3714614},
	timestamp = {Fri, 09 May 2025 20:28:08 +0200},
	biburl = {https://dblp.org/rec/conf/www/CalzavaraCF25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we systematically evaluate the effectiveness of existing tools for the dynamic security analysis of client-side JavaScript, focusing in particular on information flow control. Each tool is evaluated in terms of: (i)  compatibility,  i.e., the ability to process and analyze existing scripts without breaking; (ii)  transparency,  i.e., the ability to preserve the original script semantics when security enforcement is not necessary; (iii)  coverage,  i.e., the effectiveness in terms of number of detected information flows; (iv)  performance,  i.e., the computational overhead introduced by the analysis. Our investigation shows that most of the existing analysis tools are incompatible with the modern Web and the compatibility issues affecting them are not easily fixed. Moreover, transparency issues abound and make us question analysis correctness. This is also confirmed by our coverage evaluation, showing that some tools are unable to detect any information flow on real-world websites, while the remaining tools report significantly different outputs. Finally, we observe that the computational overhead of analysis tools may be significant and can exceed 30x. In the end, out of all the evaluated tools, just one of them (Project Foxhound) is effective enough for practical adoption at scale.}
}


@inproceedings{DBLP:conf/www/AkandaMS25,
	author = {Md Mojibur Rahman Redoy Akanda and
                  Ahmed Tanvir Mahdad and
                  Nitesh Saxena},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Broken Access: On the Challenges of Screen Reader Assisted Two-Factor
                  and Passwordless Authentication},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {1116--1128},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714579},
	doi = {10.1145/3696410.3714579},
	timestamp = {Thu, 01 May 2025 20:27:21 +0200},
	biburl = {https://dblp.org/rec/conf/www/AkandaMS25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In today's technology-driven world, web services have opened up new opportunities for blind and visually impaired people to interact independently. Securing interactions with these services is crucial; however, currently deployed methods of web authentication mainly concentrate on sighted users, overlooking the specific needs of the blind and visually impaired community. In this paper, we address this critical gap by investigating the security and accessibility aspects of these web authentication methods when adopted by blind and visually impaired users. We model web authentication for such users as screen reader assisted authentication and introduce an evaluation framework called Authentication Workflows Accessibility Review and Evaluation (AWARE). Using AWARE, we then systematically assessed popular PC-based and smartphone-based screen readers against different types of deployed web authentication methods, including variants of 2FA and passwordless schemes, to simulate real-world scenarios for blind and visually impaired individuals. We analyzed these screen reader assisted authentication interactions with authentication methods in three settings: using a terminal (PC) with screen readers, a combination of the terminal (PC) and smartphone with screen readers, and smartphones with integrated screen readers. The results of our study underscore significant weaknesses in all of our observed screen reader assisted authentication scenarios for real-life authentication methods. These weaknesses, encompassing specific accessibility issues caused by imprecise screen reader instructions, highlight vulnerability concerning observed scenarios for both real-world and research literature based attacks, including phishing, concurrency, fatigue, cross-service, and shoulder surfing. Broadly, our AWARE framework can be used by authentication system designers as a precursor to user studies which are typically time-consuming and tedious to perform, independently allowing to unfold security and accessibility problems early which designers can address prior to full-fledged user testing of more isolated issues.}
}


@inproceedings{DBLP:conf/www/HeHZWW25,
	author = {Dongxiao He and
                  Yongqi Huang and
                  Jitao Zhao and
                  Xiaobao Wang and
                  Zhen Wang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Str-GCL: Structural Commonsense Driven Graph Contrastive Learning},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {1129--1141},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714900},
	doi = {10.1145/3696410.3714900},
	timestamp = {Fri, 09 May 2025 20:28:08 +0200},
	biburl = {https://dblp.org/rec/conf/www/HeHZWW25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graph Contrastive Learning (GCL) is a widely adopted approach in self-supervised graph representation learning, applying contrastive objectives to produce effective representations. However, current GCL methods primarily focus on capturing implicit semantic relationships, often overlooking the structural commonsense embedded within the graph's structure and attributes, which contains underlying knowledge crucial for effective representation learning. Due to the lack of explicit information and clear guidance in general graph, identifying and integrating such structural commonsense in GCL poses a significant challenge. To address this gap, we propose a novel framework called Structural Commonsense Unveiling in Graph Contrastive Learning (Str-GCL). Str-GCL leverages first-order logic rules to represent structural commonsense and explicitly integrates them into the GCL framework. It introduces topological and attribute-based rules without altering the original graph and employs a representation alignment mechanism to guide the encoder in effectively capturing this commonsense. To the best of our knowledge, this is the first attempt to directly incorporate structural commonsense into GCL. Extensive experiments demonstrate that Str-GCL outperforms existing GCL methods, providing a new perspective on leveraging structural commonsense in graph representation learning.}
}


@inproceedings{DBLP:conf/www/YuGZFZ25,
	author = {Xingtong Yu and
                  Zechuan Gong and
                  Chang Zhou and
                  Yuan Fang and
                  Hui Zhang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {{SAMGPT:} Text-free Graph Foundation Model for Multi-domain Pre-training
                  and Cross-domain Adaptation},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {1142--1153},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714828},
	doi = {10.1145/3696410.3714828},
	timestamp = {Tue, 13 May 2025 07:31:04 +0200},
	biburl = {https://dblp.org/rec/conf/www/YuGZFZ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graphs are able to model interconnected entities in many online services, supporting a wide range of applications on the Web. This raises an important question: How can we train a graph foundational model on multiple source domains and adapt to an unseen target domain? A major obstacle is that graphs from different domains often exhibit divergent characteristics. Some studies leverage large language models to align multiple domains based on textual descriptions associated with the graphs, limiting their applicability to text-attributed graphs. For text-free graphs, a few recent works attempt to align different feature distributions across domains, while generally neglecting structural differences. In this work, we propose a novel Structure Alignment framework for text-free Multi-domain Graph Pre-Training and cross-domain adaptation (SAMGPT). It is designed to learn multi-domain knowledge from graphs originating in multiple source domains, which can then be adapted to address applications in an unseen target domain. Specifically, we introduce a set of  structure tokens  to harmonize structure-based aggregation across source domains during the pre-training phase. Next, for cross-domain adaptation, we design dual prompts, namely,  holistic prompts  and  specific prompts , which adapt unified multi-domain structural knowledge and fine-grained, domain-specific information, respectively, to a target domain. Finally, we conduct comprehensive experiments on seven public datasets to evaluate and analyze the effectiveness of SAMGPT.}
}


@inproceedings{DBLP:conf/www/0008HZW0Y25,
	author = {Li Sun and
                  Zhenhao Huang and
                  Suyang Zhou and
                  Qiqi Wan and
                  Hao Peng and
                  Philip S. Yu},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {RiemannGFM: Learning a Graph Foundation Model from Riemannian Geometry},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {1154--1165},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714952},
	doi = {10.1145/3696410.3714952},
	timestamp = {Fri, 23 May 2025 17:14:58 +0200},
	biburl = {https://dblp.org/rec/conf/www/0008HZW0Y25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The foundation model has heralded a new era in artificial intelligence, pretraining a single model to offer cross-domain transferability on different datasets. Graph neural networks excel at learning graph data, the omnipresent non-Euclidean structure, but often lack the generalization capacity. Hence,  graph foundation model  is drawing increasing attention, and recent efforts have been made to leverage Large Language Models. On the one hand, existing studies primarily focus on text-attributed graphs, while a wider range of real graphs do not contain fruitful textual attributes. On the other hand, the sequential graph description tailored for the Large Language Model neglects the structural complexity, which is a predominant characteristic of the graph. Such limitations motivate an important question:  Can we go beyond Large Language Models, and pretrain a universal model to learn the structural knowledge for any graph?  The answer in the language or vision domain is a shared vocabulary. We observe the fact that there also exist shared substructures underlying graph domain, and thereby open a new opportunity of graph foundation model with structural vocabulary. The key innovation is the discovery of a simple yet effective structural vocabulary of trees and cycles, and we explore its inherent connection to Riemannian geometry. Herein, we present a universal pretraining model, RiemannGFM. Concretely, we first construct a novel product bundle to incorporate the diverse geometries of the vocabulary. Then, on this constructed space, we stack Riemannian layers where the structural vocabulary, regard- less of specific graph, is learned in Riemannian manifold offering cross-domain transferability. Extensive experiments show the effectiveness of RiemannGFM on a diversity of real graphs.}
}


@inproceedings{DBLP:conf/www/NiFDZWZ25,
	author = {Zhibin Ni and
                  Pan Fan and
                  Shengzhuo Dai and
                  Bo Zhang and
                  Hai Wan and
                  Xibin Zhao},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {{FG-CIBGC:} {A} Unified Framework for Fine-Grained and Class-Incremental
                  Behavior Graph Classification},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {1166--1181},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714960},
	doi = {10.1145/3696410.3714960},
	timestamp = {Fri, 09 May 2025 20:28:08 +0200},
	biburl = {https://dblp.org/rec/conf/www/NiFDZWZ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Learning-based Behavior Graph Classification (BGC) is widely used in Internet infrastructure for partitioning and identifying similar behavior graphs, yet its real-world application faces notable challenges. The challenges are: (i) fine-grained emerging behavior graphs, and (ii) incremental model adaptations. To tackle these issues, we propose to (i) mine semantics in multi-source logs using Large Language Models (LLMs) under In-Context Learning (ICL), and (ii) bridge the gap between Out-Of-Distribution (OOD) detection and class-incremental graph learning. Based on these ideas, we develop the first unified framework termed as  F ine- G rained and  C lass- I ncremental  B ehavior  G raph  C lassification ( FG-CIBGC  ). It consists of two novel modules, i.e., gPartition and gAdapt, that are used for partitioning fine-grained graphs and performing unknown class detection and adaptation, respectively. To validate FG-CIBGC, we introduce a new benchmark, including a 4,992-graph, 32-class dataset from 8 attack scenarios and a novel Edge Intersection over Union (EIoU) metric. Extensive experiments show FG-CIBGC outperforms baselines on fine-grained class-incremental BGC task and generates behavior graphs which enhance downstream tasks.}
}


@inproceedings{DBLP:conf/www/GuoW0J25,
	author = {Wenxuan Guo and
                  Runzhong Wang and
                  Yanyan Xu and
                  Yaohui Jin},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Unified and Generalizable Reinforcement Learning for Facility Location
                  Problems on Graphs},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {1182--1195},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714812},
	doi = {10.1145/3696410.3714812},
	timestamp = {Fri, 09 May 2025 20:28:08 +0200},
	biburl = {https://dblp.org/rec/conf/www/GuoW0J25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Facility location problems on graphs are ubiquitous in the real world and hold significant importance, yet their resolution is often impeded by NP-hardness. MIP solvers can find the optimal solutions but fail to handle large instances, while algorithm efficiency has a higher priority in cases of emergency. Recently, machine learning methods have been proposed to tackle such classical problems with fast inference, but they are limited to the myopic constructive pattern and only consider simple cases in Euclidean space. This paper introduces a unified and generalizable approach to tackle facility location problems on weighted graphs with deep reinforcement learning, demonstrating a keen awareness of complex graph structures. Striking a harmonious balance between solution quality and running time, our method stands out with superior efficiency and steady performance. Our model trained on small graphs is highly scalable and consistently generates high-quality solutions, achieving a speedup of more than 2000 times to Gurobi on instances with 1000 nodes. The experiments on Shanghai road networks further demonstrate its practical value in solving real-world problems. The source codes are available at https://github.com/AryaGuo/PPO-swap.}
}


@inproceedings{DBLP:conf/www/Yang0XLZK25,
	author = {Jinluan Yang and
                  Zhengyu Chen and
                  Teng Xiao and
                  Yong Lin and
                  Wenqiao Zhang and
                  Kun Kuang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Leveraging Invariant Principle for Heterophilic Graph Structure Distribution
                  Shifts},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {1196--1204},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714749},
	doi = {10.1145/3696410.3714749},
	timestamp = {Fri, 09 May 2025 20:28:08 +0200},
	biburl = {https://dblp.org/rec/conf/www/Yang0XLZK25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Heterophilic Graph Neural Networks (HGNNs) have shown promising results for semi-supervised learning tasks on graphs. Notably, most real-world heterophilic graphs are composed of a mixture of nodes with different neighbor patterns, exhibiting local node-level homophilic and heterophilic structures. However, existing works are only devoted to designing better unified HGNN backbones for node classification tasks on heterophilic and homophilic graphs simultaneously, and their analyses of HGNN performance concerning nodes are only based on the determined data distribution without exploring the effect caused by the difference of structural pattern between training and testing nodes. How to learn invariant node representations on heterophilic graphs to handle this structure difference or distribution shifts remains unexplored. In this paper, we first discuss the limitations of previous graph-based invariant learning methods in addressing the heterophilic graph structure distribution shifts from the perspective of data augmentation. Then, we propose  HEI , a framework capable of generating invariant node representations through incorporating  H eterophily information, the node's estimated neighbor pattern, to infer latent  E nvironments without augmentation, which are then used for  I nvariant prediction. We provide detailed theoretical guarantees to clarify the reasonability of HEI. Extensive experiments on various benchmarks and backbones can also demonstrate the effectiveness and robustness of our method compared with existing state-of-the-art baselines.}
}


@inproceedings{DBLP:conf/www/LiuL25,
	author = {Fan Liu and
                  Hao Liu},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Subgraph Federated Unlearning},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {1205--1215},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714821},
	doi = {10.1145/3696410.3714821},
	timestamp = {Tue, 13 May 2025 07:31:05 +0200},
	biburl = {https://dblp.org/rec/conf/www/LiuL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Subgraph federated learning aims to collaboratively train a global model over distributed subgraphs stored in multiple local clients with strict privacy constraints, which is crucial to a wide range of applications such as healthcare, recommendation systems, and financial crime detection. With the increasing emphasis on the "right to be forgotten," the issue of machine unlearning of subgraph federated models has gained significant importance. However, existing federated unlearning approaches largely focused on unstructured data, overlooking the impact of structural dependency and cross-client interferences in graph-based data. To this end, in this paper, we propose ReGEnUnlearn, a subgraph federated unlearning framework for efficient and comprehensive unlearning of multiple target clients. Specifically, we first propose the  Reinforced Federated Policy Sampler  (RFPS) to learn optimal sampling strategies that minimize the interference among cross-client subgraphs. By interacting with the federated graph sampling environment, the agent learns to selectively forget an optimal subgraph of target clients, thus preserving the global model utility. Moreover, we propose the  Parameter-free Graph Prompt Knowledge Distillation  (PGPKD) module, which retains the unique graph knowledge contributed by the target clients, thereby facilitating comprehensive unlearning via a tailored gradient ascent objective. Extensive experiments in various federated settings demonstrate ReGEnUnlearn\'s superiority over existing federated unlearning methods, offering a speedup of 3.6× to 9× compared to traditional retraining while maintaining model utility within a range of 100%-102%.}
}


@inproceedings{DBLP:conf/www/LiuYL25,
	author = {Zhengyang Liu and
                  Hang Yu and
                  Xiangfeng Luo},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Federated Graph Anomaly Detection via Disentangled Representation
                  Learning},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {1216--1224},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714567},
	doi = {10.1145/3696410.3714567},
	timestamp = {Fri, 09 May 2025 20:28:08 +0200},
	biburl = {https://dblp.org/rec/conf/www/LiuYL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graph anomaly detection plays a crucial role in identifying nodes that deviate significantly from normal patterns within a graph, with applications spanning various domains such as detection of authorship fraud and rumor propagation. Traditional methods primarily focus on aggregating information from neighboring nodes and reconstructing the central node based on these aggregated features. The anomaly degree is then calculated by comparing the reconstructed features with the original ones. Despite their effectiveness, these methods face limitations due to the constraints of device performance and the need to protect user privacy. In reality, graph data is often partitioned and distributed across different local clients, which leads to isolated client subgraphs. This partitioning results in incomplete feature aggregation, as the connections between subgraphs are missing, ultimately reducing the performance of anomaly detection models. To overcome these challenges, a federated graph anomaly detection approach based on disentangled representation learning is proposed. This method separates node features into two distinct components: intrinsic features and subgraph style features. By identifying outliers within the subgraph style features, a set of pseudo-nodes is generated and shared across the entire graph. These pseudo-nodes simulate connections between otherwise isolated subgraphs, which enables more comprehensive aggregation of intrinsic features from neighboring nodes. In addition, conditional variational autoencoders (CVAE) are employed alongside contrastive learning strategies to alleviate class imbalance and achieve effective feature disentanglement. These techniques help ensure that anomalous nodes are detected more accurately despite the inherent challenges of federated graph systems. Extensive experiments conducted on six diverse datasets provide compelling evidence of the proposed method's superior performance in federated graph anomaly detection, highlighting its ability to effectively handle incomplete graph structures while maintaining data privacy.}
}


@inproceedings{DBLP:conf/www/00020SCY025,
	author = {Xiangyu Dong and
                  Xingyi Zhang and
                  Yanni Sun and
                  Lei Chen and
                  Mingxuan Yuan and
                  Sibo Wang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {SmoothGNN: Smoothing-aware {GNN} for Unsupervised Node Anomaly Detection},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {1225--1236},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714615},
	doi = {10.1145/3696410.3714615},
	timestamp = {Tue, 13 May 2025 07:31:04 +0200},
	biburl = {https://dblp.org/rec/conf/www/00020SCY025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The smoothing issue in graph learning leads to indistinguishable node representations, posing significant challenges for graph-related tasks. However, our experiments reveal that this problem can uncover underlying properties of node anomaly detection (NAD) that previous research has missed. We introduce Individual Smoothing Patterns (ISP) and Neighborhood Smoothing Patterns (NSP), which indicate that the representations of anomalous nodes are harder to smooth than those of normal ones. In addition, we explore the theoretical implications of these patterns, demonstrating the potential benefits of ISP and NSP for NAD tasks. Motivated by these findings, we propose SmoothGNN, a novel unsupervised NAD framework. First, we design a learning component to explicitly capture ISP for detecting node anomalies. Second, we design a spectral graph neural network to implicitly learn ISP to enhance detection. Third, we design an effective coefficient based on our findings that NSP can serve as coefficients for node representations, aiding in the identification of anomalous nodes. Furthermore, we devise a novel anomaly measure to calculate loss functions and anomalous scores for nodes, reflecting the properties of NAD using ISP and NSP. Extensive experiments on 9 real datasets show that SmoothGNN outperforms the best rival by an average of 14.66% in AUC and 7.28% in Average Precision, with 75x running time speedup, validating the effectiveness and efficiency of our framework. Our code is available at https://github.com/xydong127/SmoothGNN.}
}


@inproceedings{DBLP:conf/www/DingLJWHA25,
	author = {Yuanhao Ding and
                  Yang Liu and
                  Yugang Ji and
                  Weigao Wen and
                  Qing He and
                  Xiang Ao},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {{SPEAR:} {A} Structure-Preserving Manipulation Method for Graph Backdoor
                  Attacks},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {1237--1247},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714665},
	doi = {10.1145/3696410.3714665},
	timestamp = {Fri, 09 May 2025 20:28:08 +0200},
	biburl = {https://dblp.org/rec/conf/www/DingLJWHA25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graph Neural Networks (GNNs) are vulnerable to backdoor attacks, where adversaries implant malicious triggers to manipulate model predictions. Existing graph backdoor attacks are susceptible to defense mechanisms or robust classifiers because they rely on subgraph injection or structural perturbations, e.g., creating additional edges to attach backdoor triggers to the original graph. To enhance the stealthiness of graph backdoors, we propose SPEAR, a novel structure-preserving graph backdoor attack that avoids modifying the graph's topology. SPEAR operates within a limited attack budget by selectively perturbing node attributes while ensuring the triggers exert significant influence through a global importance-driven feature selection strategy. Additionally, a neighborhood-aware trigger generator is employed to underpin a high attack success rate by utilizing semantic information from the neighborhood. SPEAR amplifies effectiveness and stealthiness by combining subtle yet impactful attribute manipulation with a refined trigger generation mechanism. Extensive experiments demonstrate that SPEAR achieves state-of-the-art effectiveness in bypassing defenses on real-world datasets, establishing it as a potent and stealthy backdoor attack for graph-based tasks. Code is available at https://github.com/yhDing/SPEAR.}
}


@inproceedings{DBLP:conf/www/GongSMS25,
	author = {Zheng Gong and
                  Shuheng Shen and
                  Changhua Meng and
                  Ying Sun},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Exploring Hypergraph Condensation via Variational Hyperedge Generation
                  and Multi-Aspectual Amelioration},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {1248--1260},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714914},
	doi = {10.1145/3696410.3714914},
	timestamp = {Tue, 13 May 2025 07:31:05 +0200},
	biburl = {https://dblp.org/rec/conf/www/GongSMS25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Hypergraph neural networks (HyperGNNs) show promise in modeling online networks with high-order correlations. Despite notable progress, training these models on large-scale raw hypergraphs entails substantial computational and storage costs, thereby increasing the need of hypergraph size reduction. However, existing size reduction methods primarily capture pairwise association pattern within conventional graphs, making them challenging to adapt to hypergraphs with high-order correlations. To fill this gap, we introduce a novel hypergraph condensation framework, HG-Cond, designed to distill large-scale hypergraphs into compact, synthetic versions while maintaining comparable HyperGNN performance. Within this framework, we develop a Neural Hyperedge Linker to capture the high-order connectivity pattern through variational inference, achieving linear complexity with respect to the number of nodes. Moreover, We propose a multi-aspectual amelioration strategy including a Gradient-Parameter Synergistic Matching objective to holistically refine synthetic hypergraphs by coordinating improvements in node attributes, high-order connectivity, and label distributions. Extensive experiments demonstrate the efficacy of HG-Cond in hypergraph condensation, notably outperforming the original test accuracy on the 20News dataset while concurrently reducing the hypergraph size to a mere 5% of its initial scale. Furthermore, the condensed hypergraphs demonstrate robust cross-architectural generalizability and potential for expediting neural architecture search.}
}


@inproceedings{DBLP:conf/www/ChoeKKSF25,
	author = {Minyoung Choe and
                  Jihoon Ko and
                  Taehyung Kwon and
                  Kijung Shin and
                  Christos Faloutsos},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Kronecker Generative Models for Power-Law Patterns in Real-World Hypergraphs},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {1261--1272},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714893},
	doi = {10.1145/3696410.3714893},
	timestamp = {Fri, 09 May 2025 20:28:08 +0200},
	biburl = {https://dblp.org/rec/conf/www/ChoeKKSF25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Do real-world hypergraphs obey any patterns? Are power laws fundamental in hypergraphs as they are in real-world graphs? What generator can reproduce these patterns? A hypergraph is a generalization of a conventional graph, and it consists of nodes and hyperedges, with each hyperedge joining any number of nodes. Hypergraphs are adept at representing group interactions where two or more entities interact simultaneously, such as collaborative research and group discussions. In a wide range of real-world hypergraphs, we discover power-law or log-logistic distributions in eight structural properties. To simulate these observed patterns, we introduce HyRec, a tractable and realistic generative model leveraging the Kronecker product. We mathematically demonstrate that HyRec accurately reproduces both the patterns we observed and typical evolutionary trends found in real-world hypergraphs. To fit the parameters of HyRec to large-scale hypergraphs, we design SingFit, a fast and space-efficient algorithm successfully applied to eleven real-world hypergraphs with up to one million nodes and hyperedges. This paper makes the following contributions: (a) Discoveries: we identify multiple patterns that real-world hypergraphs obey, (b) Model: we propose HyRec, a tractable and realistic model capable of reproducing real-world hypergraphs efficiently (spec., with fewer than 1,000 parameters) with the support of SingFit, and (c) Proofs: we prove that HyRec adheres to these patterns.}
}


@inproceedings{DBLP:conf/www/WangAT25,
	author = {Yifan Wang and
                  Gonzalo R. Arce and
                  Guangmo Tong},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Generalization Performance of Hypergraph Neural Networks},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {1273--1291},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714586},
	doi = {10.1145/3696410.3714586},
	timestamp = {Fri, 09 May 2025 20:28:08 +0200},
	biburl = {https://dblp.org/rec/conf/www/WangAT25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Hypergraph neural networks have been promising tools for handling learning tasks involving higher-order data, with notable applications in web graphs, such as modeling multi-way hyperlink structures and complex user interactions. Yet, their generalization abilities in theory are less clear to us. In this paper, we seek to develop margin-based generalization bounds for four representative classes of hypergraph neural networks, including convolutional-based methods (UniGCN), set-based aggregation (AllDeepSets), invariant and equivariant transformations (M-IGN), and tensor-based approaches (T-MPHN). Through the PAC-Bayes framework, our results reveal the manner in which hypergraph structure and spectral norms of the learned weights can affect the generalization bounds, where the key technical challenge lies in developing new perturbation analysis for hypergraph neural networks, which offers a rigorous understanding of how variations in the model's weights and hypergraph structure impact its generalization behavior. Our empirical study examines the relationship between the practical performance and theoretical bounds of the models over synthetic and real-world datasets. One of our primary observations is the strong correlation between the theoretical bounds and empirical loss, with statistically significant consistency in most cases.}
}


@inproceedings{DBLP:conf/www/0002ZLWXFJLX25,
	author = {Zhenhua Huang and
                  Wenhao Zhou and
                  Yufeng Li and
                  Xiuyang Wu and
                  Chengpei Xu and
                  Junfeng Fang and
                  Zhaohong Jia and
                  Linyuan L{\"{u}} and
                  Feng Xia},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {{SEHG:} Bridging Interpretability and Prediction in Self-Explainable
                  Heterogeneous Graph Neural Networks},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {1292--1304},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714661},
	doi = {10.1145/3696410.3714661},
	timestamp = {Fri, 09 May 2025 20:28:08 +0200},
	biburl = {https://dblp.org/rec/conf/www/0002ZLWXFJLX25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Heterogeneous Graph Neural Networks (HGNNs) are extensively applied in modeling web-based applications that involve heterogeneous graph structures. Explanation models for HGNNs aim to address their ''black box'' nature. Enhancing the interpretability of HGNNs leads to a better understanding and can potentially improve predictive performance. However, existing post-hoc HGNN explanation methods cannot impact the HGNN's predictions. Self-explainable homogeneous models also perform poorly on heterogeneous graphs. To address these challenges, we present a Self-Explainable Heterogeneous Graph Neural Network (SEHG), a novel architecture that integrates explanation generation into the learning process of HGNN through two alternative stages. The first stage focuses on producing high-quality explanations while providing predictions alongside. The second stage enhances prediction accuracy by a contrastive learning strategy. Unlike the current methods that rely on manually defined metapaths for structural explanations, SEHG generates important structure and feature explanations by learnable heterogeneous masks. To ensure high-quality and sparsity explanation, these masks are regulated by a uniquely designed range-based penalty during training. Moreover, we introduce HetBA, a collection of synthetic heterogeneous datasets designed to quantify and visualize explanations or heterogeneous graphs. Extensive experiments demonstrate the effectiveness of SEHG, which surpasses strong baselines in real-world node classification tasks by notable margins of up to 3.91%. SEHG also achieves state-of-the-art performance on synthetic datasets with improvement of up to 9.44%, and records the highest fidelity scores in explanation tasks, improving by up to 46.57%. To our knowledge, SEHG is a pioneering self-explainable HGNN framework that achieves state-of-the-art performance on both heterogeneous graph explanation and prediction tasks.}
}


@inproceedings{DBLP:conf/www/01280YH25,
	author = {Xin Wang and
                  Jiawei Jiang and
                  Xiao Yan and
                  Qiang Huang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {{TESA:} {A} Trajectory and Semantic-aware Dynamic Heterogeneous Graph
                  Neural Network},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {1305--1315},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714918},
	doi = {10.1145/3696410.3714918},
	timestamp = {Fri, 09 May 2025 20:28:08 +0200},
	biburl = {https://dblp.org/rec/conf/www/01280YH25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Dynamic graph neural networks (DGNNs) are designed to capture the dynamic evolution of graph node interactions. However, existing DGNNs mainly consider homogeneous graphs, neglecting the rich heterogeneity in node and edge types, which is prevalent for real-world graphs and essential for modeling complex dynamic interactions. In this work, we propose the  T raj E ctory and  S emantic- A ware dynamic heterogeneous graph neural network ( TeSa ), which integrates  trajectory-based evolution  and  semantic-aware aggregation  to capture both the evolving dynamics and heterogeneous semantics entailed in continuous-time dynamic heterogeneous graphs. In particular, trajectory-based evolution treats the interactions received by each node (called node trajectory) as a sequence and employs a temporal point process to learn the dynamic evolution in these interactions. Semantic-aware aggregation separates edges of different types when aggregating messages for each node from its neighbors. Edges of the same type are processed at first (i.e., intra-semantic aggregation), and then edges of different types are handled (i.e., inter-semantic fusion), to offer a comprehensive view of the heterogeneous semantics. We compare  TeSa  with 7 state-of-the-art DGNN models, and the results show that  TeSa  improves the best-performing baseline by an average of 5.11% and 5.74% in accuracy for transductive and inductive tasks.}
}


@inproceedings{DBLP:conf/www/LvXWL025,
	author = {Xiaowei Lv and
                  Xiaojia Xu and
                  Yongcai Wang and
                  Haoyu Liu and
                  Deying Li},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Coreness Maximization through Budget-Limited Edge Insertion},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {1316--1330},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714838},
	doi = {10.1145/3696410.3714838},
	timestamp = {Fri, 09 May 2025 20:28:08 +0200},
	biburl = {https://dblp.org/rec/conf/www/LvXWL025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Budget Limited Coreness Maximization (BLCM) problem aims to enhance average user engagement by activating a limited number of connections, i.e., inserting up to  b  edges to maximize the coreness gain of all vertices in a graph. Due to the cascading feature, we prove the BLCM is NP-hard, APX-hard, and not submodular, meaning greedy sequential edge insertion fails to deliver satisfactory results. As a result, solving BLCM requires combinatorial edge insertion and must face the combinatorial exploration difficulty. This paper proposes the first effective and polynomial-time approach to BLCM. It embeds local combinatorial optimization into global greedy search to boost the benefits of combinatorial optimization while restricting its complexity. Specifically, we propose efficient methods to evaluate the cascaded coreness improvements of two local combinatorial strategies, i.e., when a leader or a group of nodes increase their coreness values via local edge insertion. Note that the key difficulty lies in evaluating the cascading effects. Based on these, we propose three efficient combinatorial edge insertion strategies: (1) Leader-Centric Greedy Insertion (LCGI), (2) Group-Centric Greedy Insertion (GCGI), and (3) a Leader-Group Balance (LGB) insertion. LCGI greedily finds the most influential leader that can produce the highest coreness gain together with its followers. GCGI finds the most influential group that can promote the most coreness gain. LGB combines the two strategies to select edge combinations adaptively. We prove the low complexity of LCGI, GCGI and LGB. Experiments conducted on 13 real-world datasets highlight their practical utility and superiority over existing approaches.}
}


@inproceedings{DBLP:conf/www/SunSZ25,
	author = {Yubo Sun and
                  Haoxin Sun and
                  Zhongzhi Zhang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Scalable Algorithms for Forest-Based Centrality on Large Graphs},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {1331--1341},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714566},
	doi = {10.1145/3696410.3714566},
	timestamp = {Fri, 09 May 2025 20:28:08 +0200},
	biburl = {https://dblp.org/rec/conf/www/SunSZ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Centrality measures are essential for identifying important nodes and edges in networks. In this paper, we focus on two forest-based centrality measures on undirected graphs: forest node centrality (FNC) and forest edge centrality (FEC), which capture the influence of nodes and edges through their participation in spanning forests. Both centrality measures can be represented using entries of the forest matrix. To address the challenge of computing the two measures on large networks, we propose two scalable algorithms from different perspectives. The first algorithm IFGN combines two variance reduction techniques to approximate the entries of the forest matrix, applicable to both FNC and FEC.The second algorithm  FECE  incorporates a new physical interpretation of FEC, allowing for a better overall estimation. We provide error guarantees for both algorithms and demonstrate their efficiency and effectiveness through extensive experiments on various real-world networks.}
}


@inproceedings{DBLP:conf/www/LiK0OXJ25,
	author = {Dongyuan Li and
                  Satoshi Kosugi and
                  Ying Zhang and
                  Manabu Okumura and
                  Feng Xia and
                  Renhe Jiang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Revisiting Dynamic Graph Clustering via Matrix Factorization},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {1342--1352},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714646},
	doi = {10.1145/3696410.3714646},
	timestamp = {Fri, 09 May 2025 20:28:08 +0200},
	biburl = {https://dblp.org/rec/conf/www/LiK0OXJ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Dynamic graph clustering aims to detect and track time-varying clusters in dynamic graphs, revealing the evolutionary mechanisms of complex real-world dynamic systems. Matrix factorization-based methods are promising approaches for this task; however, these methods often struggle with scalability and can be time-consuming when applied to large-scale dynamic graphs. Moreover, they tend to lack robustness and are vulnerable to real-world noisy data. To address these issues, we make three key contributions. First, to improve scalability, we propose temporal separated matrix factorization, where a single matrix is divided into multiple smaller matrices for independent factorization, resulting in faster computation. Second, to improve robustness, we introduce bi-clustering regularization, which jointly optimizes graph embedding and clustering, thereby filtering out noisy features from the graph embeddings. Third, to further enhance effectiveness and efficiency, we propose selective embedding updating, where we update only the embeddings of dynamic nodes while the embeddings of static nodes are fixed among different timestamps. Experimental results on six synthetic and five real-world benchmarks demonstrate the scalability, robustness and effectiveness of our proposed method. Source code is available at https://github.com/Clearloveyuan/DyG-MF.}
}


@inproceedings{DBLP:conf/www/XieY025,
	author = {Kun Xie and
                  Renchi Yang and
                  Sibo Wang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Diffusion-based Graph-agnostic Clustering},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {1353--1364},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714652},
	doi = {10.1145/3696410.3714652},
	timestamp = {Fri, 09 May 2025 20:28:08 +0200},
	biburl = {https://dblp.org/rec/conf/www/XieY025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Clustering over a graph seeks to partition the nodes therein into disjoint groups such that nodes within the same cluster are tightly-knit, while those across clusters are distant from each other. In practice, graphs are often attended with rich attributes, which are termed  attributed graphs . By leveraging the complementary nature of graph topology and node attributes in such graphs,  graph neural networks  (GNNs) have obtained encouraging performance in graph clustering. However, existing GNN-based approaches strongly rely on the  homophilic  assumption of the input graph, and thus, largely fail on  heterophilic  graphs and others embodying numerous missing or noisy links, which are widely present in real life. To bridge this gap, this paper presents DGAC, an effective graph-agnostic solution for graph clustering. Particularly, DGAC overcomes the limitations of prior works by exploiting the high-order connectivity of nodes within not only the input graph G but also the affinity graph H underlying the attribute data. To achieve this goal, we first unify the embedding and clustering generations into a coherent framework optimizing the  Dirichlet Energy  on both G and H. Based thereon, theoretically-grounded solvers are developed for efficient constructions of the embeddings and clusters via graph diffusion operations, which aggregate features from specific neighbors, enabling the capture of high-order semantics from G or H. On top of that, DGAC includes three training loss functions that facilitate effective feature extraction and clustering. Extensive experiments, comparing DGAC against 12 baselines over 12 homophilic or heterophilic graph datasets, showcase that DGAC consistently and considerably outperforms all competitors in terms of clustering quality measured against ground truth labels.}
}


@inproceedings{DBLP:conf/www/YueLSG00LG25,
	author = {Juwei Yue and
                  Haikuo Li and
                  Jiawei Sheng and
                  Yihan Guo and
                  Xinghua Zhang and
                  Chuan Zhou and
                  Tingwen Liu and
                  Li Guo},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Graph Wave Networks},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {1365--1379},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714673},
	doi = {10.1145/3696410.3714673},
	timestamp = {Fri, 09 May 2025 20:28:08 +0200},
	biburl = {https://dblp.org/rec/conf/www/YueLSG00LG25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Dynamics modeling has been introduced as a novel paradigm in message passing (MP) of graph neural networks (GNNs). Existing methods consider MP between nodes as a heat diffusion process, and leverage heat equation to model the temporal evolution of nodes in the embedding space. However, heat equation can hardly depict the wave nature of graph signals in graph signal processing. Besides, heat equation is essentially a partial differential equation (PDE) involving a first partial derivative of time, whose numerical solution usually has low stability, and leads to inefficient model training. In this paper, we would like to depict more wave details in MP, since graph signals are essentially wave signals that can be seen as a superposition of a series of waves in the form of eigenvector. This motivates us to consider MP as a wave propagation process to capture the temporal evolution of wave signals in the space. Based on wave equation in physics, we innovatively develop a graph wave equation to leverage the wave propagation on graphs. In details, we demonstrate that the graph wave equation can be connected to traditional spectral GNNs, facilitating the design of graph wave networks (GWNs) based on various Laplacians and enhancing the performance of the spectral GNNs. Besides, the graph wave equation is particularly a PDE involving a second partial derivative of time, which has stronger stability on graphs than the heat equation that involves a first partial derivative of time. Additionally, we theoretically prove that the numerical solution derived from the graph wave equation are constantly stable, enabling to significantly enhance model efficiency while ensuring its performance. Extensive experiments show that GWNs achieve state-of-the-art and efficient performance on benchmark datasets, and exhibit outstanding performance in addressing challenging graph problems, such as over-smoothing and heterophily. Our code is available at https://github.com/YueAWu/Graph-Wave-Networks.}
}


@inproceedings{DBLP:conf/www/LiuLDLJS25,
	author = {Xiaodong Liu and
                  Xiao Lin and
                  Yiming Ding and
                  Changcheng Li and
                  Peng Jiang and
                  Weiran Shen},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Optimizing Revenue through User Coupon Recommendations in Truthful
                  Online Ad Auctions},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {1380--1388},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714594},
	doi = {10.1145/3696410.3714594},
	timestamp = {Fri, 09 May 2025 20:28:08 +0200},
	biburl = {https://dblp.org/rec/conf/www/LiuLDLJS25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Online advertising serves as the primary revenue source for numerous Internet companies, which typically sell advertising slots through auctions. Conventional online ad auctions assume constant click-through rates (CTRs) and conversion rates (CVRs) for ads during the auction process. However, this paper studies a new scenario where advertisers can offer coupons to users, thereby influencing both CTRs and CVRs and consequently, the platform's revenue. We study how to recommend user coupons to advertisers in truthful auction systems. We model the interaction between the platform and the advertisers as an extensive-form game, where advertisers first report coupon bids to the platform to receive coupon recommendations, and then participate in auctions by reporting their auction bids. Our research identifies a sufficient condition under which the advertisers' optimal strategy is to report their valuations truthfully in both the recommendation and auction stages. We construct two mechanisms based on these findings. The first mechanism is a distribution-free mechanism, which is easily implementable in industrial systems; and the second is a revenue-optimal mechanism that offers simpler implementation compared to existing work Liu et al. Both synthetic and industrial experiments show that our mechanisms improve the platform's revenue. Notably, our revenue-optimal mechanism achieves the same outcome compared to existing work by Liu et al., while offering a simpler implementation.}
}


@inproceedings{DBLP:conf/www/BanchioBLMP25,
	author = {Martino Banchio and
                  Kshipra Bhawalkar and
                  Christopher Liaw and
                  Aranyak Mehta and
                  Andr{\'{e}}s Perlroth},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Autobidding With Interdependent Values},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {1389--1397},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714700},
	doi = {10.1145/3696410.3714700},
	timestamp = {Fri, 09 May 2025 20:28:08 +0200},
	biburl = {https://dblp.org/rec/conf/www/BanchioBLMP25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we initiate the study of autobidding where the signals for each bidder can be noisy and correlated. Our first set of results showcases the failure of traditional auctions such as the second-price auction (SPA) and the first-price auction (FPA). In particular, uniform bidding is not an optimal bidding strategy for SPA and both SPA and FPA can have arbitrarily poor efficiency. To circumvent this, we propose the Contextual Second Price Auction (CSPA), a novel mechanism which mitigates the aforementioned adverse effects by leveraging multiple signals to adjust the allocation of SPA. We show that uniform bidding is an optimal bidding strategy in CSPA and we prove a tight bound on the price for anarchy for CSPA of 2, thus recovering the well-established results in the independent setting. Finally, we show that CSPA always achieves at least half the welfare of SPA; moreover this is also tight.}
}


@inproceedings{DBLP:conf/www/AggarwalFZ25,
	author = {Gagan Aggarwal and
                  Giannis Fikioris and
                  Mingfei Zhao},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {No-Regret Algorithms in non-Truthful Auctions with Budget and {ROI}
                  Constraints},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {1398--1415},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714881},
	doi = {10.1145/3696410.3714881},
	timestamp = {Fri, 09 May 2025 20:28:08 +0200},
	biburl = {https://dblp.org/rec/conf/www/AggarwalFZ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Advertisers are increasingly using automated bidding to optimize their ad campaigns on online advertising platforms. Autobidding allows an advertiser to optimize her objective subject to various constraints. In this paper, we design online autobidding algorithms to optimize value subject to ROI and budget constraints. We consider an item is being auctioned in each of  T  rounds. We focus on one buyer with budget and ROI constraints in the stochastic setting: her value and highest competing bid faced are drawn i.i.d. from some unknown (joint) distribution in each round. We design low-regret bidding algorithms that bid on behalf of this buyer. Our main result is an algorithm with full information feedback (i.e., the highest competing bid is revealed after each round) that guarantees a near-optimal ~O(√T) regret with respect to the best Lipschitz function that maps values to bids. The class of Lipschitz bidding functions is rich enough to best respond to many correlation structures between value and highest competing bid, e.g., positive or negative correlation. Our result applies to a wide range of auctions, most notably any mixture of first- and second-price auctions. In addition, our result holds for both value-maximizing buyers and quasi-linear utility-maximizing buyers. We also study the bandit setting, where one only observes whether the auction is won or not. Here, we show an Ω(T 2/3  ) regret lower bound for first-price auctions, showing a significant disparity between the full information and bandit settings. We also design an algorithm with a regret bound of ~O(T 3/4  ) when the value distribution is known and is independent of the highest competing bid.}
}


@inproceedings{DBLP:conf/www/ChengDM25,
	author = {Yukun Cheng and
                  Xiaotie Deng and
                  Yunxuan Ma},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Networked Digital Public Goods Games with Heterogeneous Players and
                  Convex Costs},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {1416--1424},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714869},
	doi = {10.1145/3696410.3714869},
	timestamp = {Fri, 09 May 2025 20:28:08 +0200},
	biburl = {https://dblp.org/rec/conf/www/ChengDM25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the digital age, resources such as open-source software and publicly accessible databases form a crucial category of digital public goods, providing extensive benefits for Internet. However, these public goods' inherent non-exclusivity and non-competitiveness frequently result in under-provision, a dilemma exacerbated by individuals' tendency to free-ride. This scenario fosters both cooperation and competition among users, leading to the public goods games. This paper investigates networked public goods games involving heterogeneous players and convex costs, focusing on the characterization of Nash Equilibrium (NE). In these games, each player can choose her effort level, representing her contributions to public goods. Network structures are employed to model the interactions among participants. Each player's utility consists of a concave value component, influenced by the collective efforts of all players, and a convex cost component, determined solely by the individual's own effort. To the best of our knowledge, this study is the first to explore the networked public goods game with convex costs. Our research begins by examining welfare solutions aimed at maximizing social welfare and ensuring the convergence of pseudo-gradient ascent dynamics. We establish the presence of NE in this model and provide an in-depth analysis of the conditions under which NE is unique. We also delve into comparative statics, an essential tool in economics, to evaluate how slight modifications in the model--interpreted as monetary redistribution--affect player utilities. In addition, we analyze a particular scenario with a predefined game structure, illustrating the practical relevance of our theoretical insights. Overall, our research enhances the broader understanding of strategic interactions and structural dynamics in networked public goods games, with significant implications for policy design in internet economic and social networks.}
}


@inproceedings{DBLP:conf/www/PanWXZ25,
	author = {Yuqi Pan and
                  Zhiwei Steven Wu and
                  Haifeng Xu and
                  Shuran Zheng},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Differentially Private Bayesian Persuasion},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {1425--1440},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714854},
	doi = {10.1145/3696410.3714854},
	timestamp = {Fri, 09 May 2025 20:28:08 +0200},
	biburl = {https://dblp.org/rec/conf/www/PanWXZ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The tension between persuasion and privacy preservation is common in real-world settings. Online platforms should protect the privacy of web users whose data they collect, even as they seek to disclose information about these data (e.g., to advertisers). Similarly, hospitals may share patient data to attract research investments with the obligation to preserve patients' privacy. To address these issues, we study Bayesian persuasion under differential privacy constraints, where the sender must design an optimal signaling scheme for persuasion while guaranteeing the privacy of each agent's private information in the database. To understand how privacy constraints affect information disclosure, we explore two perspectives within Bayesian persuasion: one views the mechanism as releasing a posterior about the private data, while the other views it as sending an action recommendation. The posterior-based formulation leads to privacy-utility tradeoffs, quantifying how the tightness of privacy constraints impacts the sender's optimal utility. For any instance in a common utility function family and a wide range of privacy levels, a significant constant gap in the sender's optimal utility can be found between any two of the three conditions: ε-differential privacy constraint, relaxation (ε,δ)-differential privacy constraint, and no privacy constraint. We further geometrically characterize optimal signaling schemes under popular privacy constraints (ε-differential privacy, (ε,δ)-differential privacy and Rényi differential privacy), which turns out to be equivalent to finding concave hulls in constrained posterior regions. Finally, we develop polynomial-time algorithms for computing optimal differentially private signaling schemes.}
}


@inproceedings{DBLP:conf/www/GuoKL25,
	author = {Yongkang Guo and
                  Yuqing Kong and
                  Jialiang Liu},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Mitigating the Participation Bias by Balancing Extreme Ratings},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {1441--1455},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714556},
	doi = {10.1145/3696410.3714556},
	timestamp = {Fri, 09 May 2025 20:28:08 +0200},
	biburl = {https://dblp.org/rec/conf/www/GuoKL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Rating aggregation plays a crucial role in various fields, such as product recommendations, hotel rankings, and teaching evaluations. However, traditional averaging methods can be affected by participation bias, where some raters do not participate in the rating process, leading to potential distortions. In this paper, we consider a robust rating aggregation task under the participation bias. We assume that raters may not reveal their ratings with a certain probability depending on their individual ratings, resulting in partially observed samples. Our goal is to minimize the expected squared loss between the aggregated ratings and the average of all underlying ratings (possibly unobserved) in the worst-case scenario. We focus on two settings based on whether the sample size (i.e. the number of raters) is known. In the first setting, where the sample size is known, we propose an aggregator, named as the Balanced Extremes Aggregator. It estimates unrevealed ratings with a balanced combination of extreme ratings. When the sample size is unknown, we derive another aggregator, the Polarizing-Averaging Aggregator, which becomes optimal as the sample size grows to infinity. Numerical results demonstrate the superiority of our proposed aggregators in mitigating participation bias, compared to simple averaging and the spectral method. Furthermore, we validate the effectiveness of our aggregators on a real-world dataset.}
}


@inproceedings{DBLP:conf/www/WangXHB025,
	author = {Qiyuan Wang and
                  Ruiling Xu and
                  Shibo He and
                  Randall Berry and
                  Meng Zhang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Unlearning Incentivizes Learning under Privacy Risk},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {1456--1467},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714740},
	doi = {10.1145/3696410.3714740},
	timestamp = {Fri, 09 May 2025 20:28:08 +0200},
	biburl = {https://dblp.org/rec/conf/www/WangXHB025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {While federated learning enables intelligent services and personalized user experiences, it raises privacy concerns due to regulatory requirements and user demands for data protection. Federated unlearning offers a potential solution to these issues. However, despite increasing demand for its practical implementation driven by  right-to-be-forgotten  regulations, the economic implications of federated unlearning on user behavior and platform profitability remain underexplored, potentially hindering its adoption. In this paper, we formulate a set of contract design problems for both unlearning-disabled and unlearning-enabled scenarios. Challenges arise when the unlearning-enabled platform jointly designs compensation for both learning and unlearning to incentivize users' sequential decisions to balance the expected revenue and unlearning cost. We first conduct a questionnaire survey that reveals that federated unlearning increases users' willingness to participate in federated learning. We then provide a necessary condition for maximizing the surplus of an unlearning-enabled platform, enabling the point-wise decomposition for the optimal contract design problem, based on which we minimize the incentive cost and maximize the surplus for the platform. Our further analysis reveals that i) the incentive effects of unlearning grow quadratically with users' privacy sensitivity, and ii) enabling unlearning may even profit more than disabling it when the training cost increases at a faster rate than the probability of privacy leakage as effort levels rise. Our numerical results show that the platform's profitability is primarily influenced by users' privacy sensitivity. When users have a relatively high privacy sensitivity, enabling unlearning can significantly improve profitability.}
}


@inproceedings{DBLP:conf/www/0001JLM25,
	author = {Serena Wang and
                  Michael I. Jordan and
                  Katrina Ligett and
                  R. Preston McAfee},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Relying on the Metrics of Evaluated Agents},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {1468--1487},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714864},
	doi = {10.1145/3696410.3714864},
	timestamp = {Fri, 09 May 2025 20:28:08 +0200},
	biburl = {https://dblp.org/rec/conf/www/0001JLM25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Online platforms and regulators face a continuing problem of designing effective evaluation metrics. While tools for collecting and processing data continue to progress, this has not addressed the problem of  unknown unknowns , or fundamental informational limitations on part of the evaluator. To guide the choice of metrics in the face of this informational problem, we turn to the evaluated agents themselves, who may have more information about how to measure their own outcomes. We model this interaction as an agency game, where we ask:  When does an agent have an incentive to reveal the observability of a metric to their evaluator?  We show that an agent will prefer to reveal metrics that differentiate the most difficult tasks from the rest, and conceal metrics that differentiate the easiest. We further show that the agent can prefer to reveal a metric *garbled* with noise over both fully concealing and fully revealing. This indicates an economic value to privacy that yields Pareto improvement for both the agent and evaluator. We demonstrate these findings on data from online rideshare platforms.}
}


@inproceedings{DBLP:conf/www/WuDL025,
	author = {Yanxuan Wu and
                  Haihan Duan and
                  Xitong Li and
                  Xiping Hu},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Navigating the Deployment Dilemma and Innovation Paradox: Open-Source
                  versus Closed-source Models},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {1488--1501},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714783},
	doi = {10.1145/3696410.3714783},
	timestamp = {Fri, 09 May 2025 20:28:08 +0200},
	biburl = {https://dblp.org/rec/conf/www/WuDL025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recent advances in Artificial Intelligence (AI) have introduced a popular paradigm in Machine Learning (ML) model development: pre-training and domain adaptation. As both closed-source developers and open-source community lead in pre-training foundation models, domain deployers face the dilemma about whether to use closed-source models via API access or to host open-source models on proprietary hardware. Using closed-source models incurs recurring costs, while hosting open-source models requires substantial hardware investments and may lead to potentially lagging advancements. This paper presents a game-theoretical model to examine the economic incentives behind the deployment choice and the impact of open-source engagement strategies on technological innovation. We find that deployers consistently opt for closed-source APIs when the open-source community engages reactively by maintaining a fixed performance ratio relative to closed-source advancements. However, open-source models can become preferable when a proactive open-source community produces high-performance models independently. Furthermore, we identify conditions under which the engagement and competitiveness of the open-source community can either foster or inhibit technological progress. These insights offer valuable implications for market regulation and the future of technology innovation.}
}


@inproceedings{DBLP:conf/www/ChenV25,
	author = {Yi Chen and
                  Ramya Korlakai Vinayak},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Query Design for Crowdsourced Clustering: Effect of Cognitive Overload
                  and Contextual Bias},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {1502--1521},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714587},
	doi = {10.1145/3696410.3714587},
	timestamp = {Fri, 09 May 2025 20:28:08 +0200},
	biburl = {https://dblp.org/rec/conf/www/ChenV25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Crowdsourced clustering leverages human input to group items into clusters. The design of tasks for crowdworkers, specifically the number of items presented per query, impacts answer quality and cognitive load. This work investigates the trade-off between query size and answer accuracy, revealing diminishing returns beyond 4-5 items per query. Crucially, we identify contextual bias in crowdworker responses - the likelihood of grouping items depends not only on their similarity but also on the other items present in the query. This structured noise contradicts assumptions made in existing noise models. Our findings underscore the need for more nuanced noise models that account for the complex interplay between items and query context in crowdsourced clustering tasks.}
}


@inproceedings{DBLP:conf/www/Papadogiannakis25,
	author = {Emmanouil Papadogiannakis and
                  Nicolas Kourtellis and
                  Panagiotis Papadopoulos and
                  Evangelos P. Markatos},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Welcome to the Dark Side: Analyzing the Revenue Flows of Fraud in
                  the Online Ad Ecosystem},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {1522--1535},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714899},
	doi = {10.1145/3696410.3714899},
	timestamp = {Fri, 09 May 2025 20:28:08 +0200},
	biburl = {https://dblp.org/rec/conf/www/Papadogiannakis25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The online advertising market has recently reached the 500 billion dollar mark. To accommodate the need to match a user with the highest bidder at a fraction of a second, it has moved towards a complex, automated and often opaque model that involves numerous agents and intermediaries. Stimulated by the lack of transparency, but also the enormous potential profits, bad actors have found ways to circumvent restrictions, and generate substantial revenue that can support websites with objectionable or even illegal content. In this work, we evaluate transparency Web standards and show how shady actors take advantage of gaps to absorb ad revenues while putting the brand safety of advertisers in danger. We collect and study a large corpus of thousands of websites and show how ad transparency standards can be abused by bad actors to obscure ad revenue flows. We show how identifier pooling can redirect ad revenues from reputable domains to notorious domains serving objectionable content, and that the phenomenon is underestimated by previous studies by a factor of 15. Finally, we publish a Web monitoring service that enhances the transparency of supply chains and business relationships between publishers and ad networks.}
}


@inproceedings{DBLP:conf/www/Zafar025,
	author = {Ahsan Zafar and
                  Anupam Das},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Assessing Compliance in Digital Advertising: {A} Deep Dive into Acceptable
                  Ads Standards},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {1536--1547},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714725},
	doi = {10.1145/3696410.3714725},
	timestamp = {Thu, 01 May 2025 20:27:29 +0200},
	biburl = {https://dblp.org/rec/conf/www/Zafar025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Online ads provide essential revenue for millions of websites but often disrupt user experience. To address this, browser extensions emerged to block intrusive ads, prompting the creation of the Acceptable Ads Standards to balance user choice and monetization. The Acceptable Ads Standards, initiated by the Acceptable Ads Committee, seek a balance between user experience and ad effectiveness, allowing certain non-intrusive ads defined by size, placement, and type limitations. This paper analyzes the compliance of digital advertisements with the Acceptable Ads standards by examining 10,000 popular domains intersecting Tranco's top 100K and the Acceptable Ads exception list. Our findings reveal that nearly 10% of these sites display non-compliant ads on landing pages, exposing design flaws in the exception list that allow publishers to bypass size and format restrictions. We propose enhancements to the exception list to better uphold user experience and ad integrity.}
}


@inproceedings{DBLP:conf/www/RampiselaRML25,
	author = {Theresia Veronika Rampisela and
                  Tuukka Ruotsalo and
                  Maria Maistro and
                  Christina Lioma},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Joint Evaluation of Fairness and Relevance in Recommender Systems
                  with Pareto Frontier},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {1548--1566},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714589},
	doi = {10.1145/3696410.3714589},
	timestamp = {Fri, 09 May 2025 20:28:08 +0200},
	biburl = {https://dblp.org/rec/conf/www/RampiselaRML25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Fairness and relevance are two important aspects of recommender systems (RSs). Typically, they are evaluated either (i) separately by individual measures of fairness and relevance, or (ii) jointly using a single measure that accounts for fairness with respect to relevance. However, approach (i) often does not provide a reliable joint estimate of the goodness of the models, as it has two different best models: one for fairness and another for relevance. Approach (ii) is also problematic because these measures tend to be ad-hoc and do not relate well to traditional relevance measures, like NDCG. Motivated by this, we present a new approach for jointly evaluating fairness and relevance in RSs: Distance to Pareto Frontier (DPFR). Given some user-item interaction data, we compute their Pareto frontier for a pair of existing relevance and fairness measures, and then use the distance from the frontier as a measure of the jointly achievable fairness and relevance. Our approach is modular and intuitive as it can be computed with existing measures. Experiments with 4 RS models, 3 re-ranking strategies, and 6 datasets show that existing metrics have inconsistent associations with our Pareto-optimal solution, making DPFR a more robust and theoretically well-founded joint measure for assessing fairness and relevance. Our code: https://github.com/theresiavr/DPFR-recsys-evaluation}
}


@inproceedings{DBLP:conf/www/ChenTXLLWWC25,
	author = {Eason Chen and
                  Xinyi Tang and
                  Zimo Xiao and
                  Chuangji Li and
                  Shizhuo Li and
                  Tingguan Wu and
                  Siyun Wang and
                  Kostas Kryptos Chalkias},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {SuiGPT {MAD:} Move {AI} Decompiler to Improve Transparency and Auditability
                  on Non-Open-Source Blockchain Smart Contract},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {1567--1576},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714790},
	doi = {10.1145/3696410.3714790},
	timestamp = {Fri, 09 May 2025 20:28:08 +0200},
	biburl = {https://dblp.org/rec/conf/www/ChenTXLLWWC25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The vision of Web3 is to improve user control over data and assets, but one challenge that complicates this vision is the prevalence of non-transparent, scam-prone applications and vulnerable smart contracts that put Web3 users at risk. While code audits are one solution to this problem, the lack of smart contracts source code on many blockchain platforms, such as Sui, hinders the ease of auditing. A promising approach to this issue is the use of a decompiler to reverse-engineer smart contract bytecode. However, existing decompilers for Sui produce code that is difficult to understand and cannot be directly recompiled. To address this, we developed the SuiGPT Move AI Decompiler (MAD), a Large Language Model (LLM)-powered web application that decompiles smart contract bytecodes on Sui into logically correct, human-readable, and re-compilable source code with prompt engineering. Our evaluation shows that MAD's output successfully passes original unit tests and achieves a 73.33% recompilation success rate on real-world smart contracts. Additionally, newer models tend to deliver improved performance, suggesting that MAD's approach will become increasingly effective as LLMs continue to advance. In a user study involving 12 developers, we found that MAD significantly reduced the auditing workload compared to using traditional decompilers. Participants found MAD's outputs comparable to the original source code, improving accessibility for understanding and auditing non-open-source smart contracts. Through qualitative interviews with these developers and Web3 projects, we further discussed the strengths and concerns of MAD. MAD has practical implications for blockchain smart contract transparency, auditing, and education. It empowers users to easily and independently review and audit non-open-source smart contracts, fostering accountability and decentralization. Moreover, MAD's methodology could potentially extend to other smart contract languages, like Solidity, further enhancing Web3 transparency.}
}


@inproceedings{DBLP:conf/www/Papadogiannakis25a,
	author = {Emmanouil Papadogiannakis and
                  Panagiotis Papadopoulos and
                  Nicolas Kourtellis and
                  Evangelos P. Markatos},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Before {\&} After: The Effect of EU's 2022 Code of Practice on
                  Disinformation},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {1577--1587},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714898},
	doi = {10.1145/3696410.3714898},
	timestamp = {Fri, 09 May 2025 20:28:08 +0200},
	biburl = {https://dblp.org/rec/conf/www/Papadogiannakis25a.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Over the past few years, the European Commission has made significant steps to reduce disinformation in cyberspace. One of those steps has been the introduction of the 2022 ''Strengthened Code of Practice on Disinformation''. Signed by leading online platforms, this Strengthened Code of Practice on Disinformation is an attempt to combat disinformation on the Web. The Code of Practice includes a variety of measures including the demonetization of disinformation, urging, for example, advertisers ''to avoid the placement of advertising next to Disinformation content''. In this work, we set out to explore what was the impact of the Code of Practice and especially to explore to what extent ad networks continue to advertise on dis-/mis-information sites. We perform a historical analysis and find that, although at a hasty glance things may seem to be improving, there is really no significant reduction in the amount of advertising relationships among popular misinformation websites and major ad networks. In fact, we show that ad networks have withdrawn mostly from unpopular misinformation websites with very few visitors, but still form relationships with highly unreliable websites that account for the majority of misinformation traffic. To make matters worse, we show that ad networks continue to place advertisements of legitimate companies next to misinformation content. We show that major ad networks place ads in almost 400 misinformation websites in our dataset.}
}


@inproceedings{DBLP:conf/www/LiC00L0Z25,
	author = {Zhiwen Li and
                  Die Chen and
                  Mingyuan Fan and
                  Cen Chen and
                  Yaliang Li and
                  Yanhao Wang and
                  Wenmeng Zhou},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Responsible Diffusion Models via Constraining Text Embeddings within
                  Safe Regions},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {1588--1601},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714912},
	doi = {10.1145/3696410.3714912},
	timestamp = {Fri, 09 May 2025 20:28:08 +0200},
	biburl = {https://dblp.org/rec/conf/www/LiC00L0Z25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The remarkable ability of diffusion models to generate high-fidelity images has led to their widespread adoption. However, concerns have also arisen regarding their potential to produce Not Safe for Work (NSFW) content and exhibit social biases, hindering their practical use in real-world applications. In response to this challenge, prior work has focused on employing security filters to identify and exclude toxic text, or alternatively, fine-tuning pre-trained diffusion models to erase sensitive concepts. Unfortunately, existing methods struggle to achieve satisfactory performance in the sense that they can have a significant impact on the normal model output while still failing to prevent the generation of harmful content in some cases. In this paper, we propose a novel self-discovery approach to identifying a semantic direction vector in the embedding space to restrict text embedding within a safe region. Our method circumvents the need for correcting individual words within the input text and steers the entire text prompt towards a safe region in the embedding space, thereby enhancing model robustness against all possibly unsafe prompts. In addition, we employ Low-Rank Adaptation (LoRA) for semantic direction vector initialization to reduce the impact on the model performance for other semantics. Furthermore, our method can also be integrated with existing methods to improve their social responsibility. Extensive experiments on benchmark datasets demonstrate that our method can effectively reduce NSFW content and mitigate social bias generated by diffusion models compared to several state-of-the-art baselines.  WARNING: This paper contains model-generated images that may be potentially offensive.}
}


@inproceedings{DBLP:conf/www/ChenLWCB25,
	author = {Baiqi Chen and
                  Jiawei Lyu and
                  Tingmin Wu and
                  Mohan Baruwal Chhetri and
                  Guangdong Bai},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Semantics-Aware Cookie Purpose Compliance},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {1602--1613},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714746},
	doi = {10.1145/3696410.3714746},
	timestamp = {Fri, 09 May 2025 20:28:08 +0200},
	biburl = {https://dblp.org/rec/conf/www/ChenLWCB25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Websites commonly display cookie banners to inform users about the use and purposes of cookies. However, they may still, whether intentionally or unintentionally (e.g., due to third-party libraries imported), mis-declare cookies that may be abused for tracking. In this work, we introduce COOVER (<u>coo</u>kie <u>v</u>alue examin<u>er</u>) to assess the non-compliance between the website-declared purpose and the semantic-intended purpose of cookies (denoted as  potential cookie purpose violation  ). We advocate that the value of the cookie is a more reliable indicator of its semantic-intended purpose compared to other features such as expiration time. COOVER decomposes the cookie value into primitive  segments  representing minimal semantic units, and fine-tunes a GPT-3.5 model to automatically interpret their value-inferred semantics. Based on the interpretation, it classifies cookies into four GDPR-defined purposes. COOVER achieves an F1 score of 95%, significantly outperforming other methods. We employ COOVER to analyze Alexa Top 1k websites to understand the  status quo  of potential cookie purpose violation on the web. Remarkably, out of 15,339 cookies across these websites, only 3.1% quality as  truly  necessary cookies, while 44.1% of websites suffer from issues of potential purpose violation.}
}


@inproceedings{DBLP:conf/www/MaHLF25,
	author = {Jiatong Ma and
                  Linmei Hu and
                  Rang Li and
                  Wenbo Fu},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {LoCal: Logical and Causal Fact-Checking with LLM-Based Multi-Agents},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {1614--1625},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714748},
	doi = {10.1145/3696410.3714748},
	timestamp = {Fri, 09 May 2025 20:28:08 +0200},
	biburl = {https://dblp.org/rec/conf/www/MaHLF25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the development of social media, people are exposed to a vast amount of unverified information, making fact-checking particularly important. Existing fact-checking methods primarily encourage breaking down claims into more easily solvable sub-tasks, and deriving final answers through reasoning with external evidence. However, these models face logical issues regarding whether and how the sub-tasks can logically be combined to form the original claims, and encounter causal errors in the reasoning process due to insufficient evidence or hallucinations from LLMs. In addition, they often suffer from a lack of interpretability. In this paper, we propose Logical and Causal fact-checking (LoCal), a novel fact-checking framework based on multiple LLM-based agents. The usage of multi-agent systems is due to their increasingly demonstrated ability to perform complex tasks in a manner similar to humans. LoCal primarily consists of a decomposing agent, multiple reasoning agents, and two evaluating agents. Specifically, the decomposing agent first utilizes the in-context learning ability of LLMs to break down complex claims into simpler sub-tasks, including fact verification tasks and question answering tasks. Afterwards, two types of reasoning agents are respectively utilized to retrieve external knowledge to address the fact verification tasks that require comparative analysis skills, and the question answering tasks that necessitate the ability of information extraction from evidence. We then combine the sub-tasks and their corresponding responses to generate a solution for evaluation. In order to enhance logical and causal consistency, two evaluating agents are respectively employed to examine whether the generated solution is logically equivalent to the original claim and determine whether the solution still holds when challenged by the counterfactual label. The evaluating agents provide confidence degrees for the solutions based on the evaluation results and iteratively correct the logical and causal errors in the reasoning process. We evaluate LoCal on two challenging datasets, and the results show that LoCal significantly outperforms all the baseline models across different settings of evidence availability. In addition, LoCal offers better interpretability by providing a structured solution along with detailed evaluating processes. We believe LoCal will provide valuable insights for future misinformation detection.}
}


@inproceedings{DBLP:conf/www/DingZ25,
	author = {Bailu Ding and
                  Jiaqi Zhai},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Retrieval with Learned Similarities},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {1626--1637},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714822},
	doi = {10.1145/3696410.3714822},
	timestamp = {Fri, 09 May 2025 20:28:08 +0200},
	biburl = {https://dblp.org/rec/conf/www/DingZ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Retrieval plays a fundamental role in recommendation systems, search, and natural language processing (NLP) by efficiently finding relevant items from a large corpus given a query. Dot products have been widely used as the similarity function in such tasks, enabled by Maximum Inner Product Search (MIPS) algorithms for efficient retrieval. However, state-of-the-art retrieval algorithms have migrated to learned similarities. These advanced approaches encompass multiple query embeddings, complex neural networks, direct item ID decoding via beam search, and hybrid solutions. Unfortunately, we lack efficient solutions for retrieval in these state-of-the-art setups. Our work addresses this gap by investigating efficient retrieval techniques with expressive learned similarity functions. We establish Mixture-of-Logits (MoL) as a universal approximator of similarity functions, demonstrate that MoL's expressiveness can be realized empirically to achieve superior performance on diverse retrieval scenarios, and propose techniques to retrieve the approximate top- k  results using MoL with tight error bounds. Through extensive experimentation, we show that MoL, enhanced by our proposed mutual information-based load balancing loss, sets new state-of-the-art results across heterogeneous scenarios, including sequential retrieval models in recommendation systems and finetuning language models for question answering; and our approximate top- k  algorithms outperform baselines by up to 66× in latency while achieving >.99 recall rate compared to exact algorithms.}
}


@inproceedings{DBLP:conf/www/0004LZ0MYSMY25,
	author = {Yiqun Chen and
                  Qi Liu and
                  Yi Zhang and
                  Weiwei Sun and
                  Xinyu Ma and
                  Wei Yang and
                  Daiting Shi and
                  Jiaxin Mao and
                  Dawei Yin},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {TourRank: Utilizing Large Language Models for Documents Ranking with
                  a Tournament-Inspired Strategy},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {1638--1652},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714863},
	doi = {10.1145/3696410.3714863},
	timestamp = {Tue, 13 May 2025 07:31:04 +0200},
	biburl = {https://dblp.org/rec/conf/www/0004LZ0MYSMY25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Large Language Models (LLMs) are increasingly employed in zero-shot documents ranking, yielding commendable results. However, several significant challenges still persist in LLMs for ranking: (1) LLMs are constrained by limited input length, precluding them from processing a large number of documents simultaneously; (2) The output document sequence is influenced by the input order of documents, resulting in inconsistent ranking outcomes; (3) Achieving a balance between cost and ranking performance is challenging. To tackle these issues, we introduce a novel documents ranking method called TourRank 1 . which is inspired by the sport tournaments, such as FIFA World Cup. Specifically, we 1) overcome the limitation in input length and reduce the ranking latency by incorporating a multi-stage grouping strategy similar to the parallel group stage of sport tournaments; 2) improve the ranking performance and robustness to input orders by using a points system to ensemble multiple ranking results. We test TourRank with different LLMs on the TREC DL datasets and the BEIR benchmark. The experimental results demonstrate that TourRank delivers state-of-the-art performance at a modest cost.}
}


@inproceedings{DBLP:conf/www/Yu25,
	author = {Weiren Yu},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {SimEdge: {A} Scalable Transitivity-Aware Graph-Theoretic Similarity
                  Model for Capturing Edge-to-Edge Relationships},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {1653--1665},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714751},
	doi = {10.1145/3696410.3714751},
	timestamp = {Thu, 01 May 2025 20:27:29 +0200},
	biburl = {https://dblp.org/rec/conf/www/Yu25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Measuring similarity based on network topology is a crucial task in the realm of web search. While many well-established similarity measures (e.g. SimRank) focus on assessing node-to-node similarity, capturing edge-to-edge relationships is equally important in many applications (e.g. link spam detection). However, existing node-to-node similarity measures from the SimRank family may violate the triangular inequality. When applied directly to assessing edge-to-edge similarity, such measures may fail to capture transitive relationships and misrepresent dissimilarity between nodes. In this paper, we propose a novel similarity measure, SimEdge, which can capture transitive relationships for assessing edge-to-edge similarity. The intuition of SimEdge revolves around a mutual reinforcement co-recursion: "two edges are assessed as similar if they are linked to similar nodes, and two nodes are assessed as similar if they are linked to similar edges." We show that SimEdge guarantees the transitivity of similarity, and enhances the accuracy of the node-to-node SimRank similarity without misrepresenting dissimilarity between nodes. For large-scale graphs, we also propose efficient techniques to compute SimEdge similarities in linear memory with guaranteed accuracy. Our empirical evaluation on various datasets validates that SimEdge is highly effective in capturing transitive edge-to-edge relationships, while offering a more reliable assessment of node-to-node similarity. Moreover, SimEdge shows superior scalability in assessing edge-to-edge similarities on large-scale graphs with billions of edges.}
}


@inproceedings{DBLP:conf/www/LuoZ0XXC25,
	author = {Pengfei Luo and
                  Jingbo Zhou and
                  Tong Xu and
                  Yuan Xia and
                  Linli Xu and
                  Enhong Chen},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {\emph{ImageScope: } Unifying Language-Guided Image Retrieval via Large
                  Multimodal Model Collective Reasoning},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {1666--1682},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714777},
	doi = {10.1145/3696410.3714777},
	timestamp = {Fri, 09 May 2025 20:28:08 +0200},
	biburl = {https://dblp.org/rec/conf/www/LuoZ0XXC25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the proliferation of images in online content, language-guided image retrieval (LGIR) has emerged as a research hotspot over the past decade, encompassing a variety of subtasks with diverse input forms. While the development of large multimodal models (LMMs) has significantly facilitated these tasks, existing approaches often address them in isolation, requiring the construction of separate systems for each task. This not only increases system complexity and maintenance costs, but also exacerbates challenges stemming from language ambiguity and complex image content, making it difficult for retrieval systems to provide accurate and reliable results. To this end, we propose  ImageScope , a training-free, three-stage framework that leverages collective reasoning to unify LGIR tasks. The key insight behind the unification lies in the compositional nature of language, which transforms diverse LGIR tasks into a generalized text-to-image retrieval process, along with the reasoning of LMMs serving as a universal verification to refine the results. To be specific, in the first stage, we improve the robustness of the framework by synthesizing search intents across varying levels of semantic granularity using chain-of-thought (CoT) reasoning. In the second and third stages, we then reflect on retrieval results by verifying predicate propositions locally, and performing pairwise evaluations globally. Experiments conducted on six LGIR datasets demonstrate that  ImageScope  outperforms competitive baselines. Comprehensive evaluations and ablation studies further confirm the effectiveness of our design.}
}


@inproceedings{DBLP:conf/www/WangZ000W0SYZL25,
	author = {Yejing Wang and
                  Chi Zhang and
                  Xiangyu Zhao and
                  Qidong Liu and
                  Maolin Wang and
                  Xuetao Wei and
                  Zitao Liu and
                  Xing Shi and
                  Xudong Yang and
                  Ling Zhong and
                  Wei Lin},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Behavior Modeling Space Reconstruction for E-Commerce Search},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {1683--1692},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714949},
	doi = {10.1145/3696410.3714949},
	timestamp = {Tue, 13 May 2025 07:31:04 +0200},
	biburl = {https://dblp.org/rec/conf/www/WangZ000W0SYZL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Delivering superior search services is crucial for enhancing customer experience and driving revenue growth in e-commerce. Conventionally, search systems model user behaviors by combining user preference and query-item relevance statically, often through a fixed logical 'and' relationship. This paper reexamines existing approaches through a unified lens using causal graphs and Venn diagrams, uncovering two prevalent yet significant issues: entangled preference and relevance effects, and a collapsed modeling space. To surmount these challenges, our research introduces a novel framework, DRP, which enhances search accuracy through two components to reconstruct the behavior modeling space. Specifically, we implement preference editing to proactively remove the relevance effect from preference predictions, yielding untainted user preferences. Additionally, we employ adaptive fusion, which dynamically adjusts fusion criteria to align with the varying patterns of relevance and preference, facilitating more nuanced and tailored behavior predictions within the reconstructed modeling space. Empirical validation on two public datasets and a proprietary e-commerce search dataset underscores the superiority of our proposed methodology, demonstrating marked improvements in performance over existing approaches. The code is available at https://github.com/Applied-Machine-Learning-Lab/DRP.}
}


@inproceedings{DBLP:conf/www/TanQL0WWWWL025,
	author = {Tao Tan and
                  Yining Qian and
                  Ang Lv and
                  Hongzhan Lin and
                  Songhao Wu and
                  Yongbo Wang and
                  Feng Wang and
                  Jingtong Wu and
                  Xin Lu and
                  Rui Yan},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {\emph{PEAR: } \emph{Position-Embedding-Agnostic Attention Re-weighting
                  Enhances Retrieval-Augmented Generation with Zero Inference Overhead}},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {1693--1702},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714795},
	doi = {10.1145/3696410.3714795},
	timestamp = {Fri, 09 May 2025 20:28:08 +0200},
	biburl = {https://dblp.org/rec/conf/www/TanQL0WWWWL025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Large language models (LLMs) enhanced with retrieval-augmented generation (RAG) have introduced a new paradigm for web search. However, the limited context awareness of LLMs degrades their performance on RAG tasks. Existing methods to enhance context awareness are often inefficient, incurring time or memory overhead during inference, and many are tailored to specific position embeddings. In this paper, we propose  P osition- E mbedding- A gnostic attention  R e-weighting  (PEAR) , which enhances the context awareness of LLMs with zero inference overhead. Specifically, on a proxy task focused on context copying, we first detect heads which suppress the models' context awareness, thereby diminishing RAG performance. To weaken the impact of these heads, we re-weight their outputs with learnable coefficients. The LLM (with frozen parameters) is optimized by adjusting these coefficients to minimize loss on the proxy task. During inference, the optimized coefficients are fixed to re-weight these heads, regardless of the specific task at hand. Our proposed PEAR offers two major advantages over previous approaches: (1) It introduces zero additional inference overhead in terms of memory usage or inference time, while outperforming competitive baselines in accuracy and efficiency across various RAG tasks. (2) It is independent of position embedding algorithms, ensuring broader applicability. Our code is available at https://github.com/TTArch/PEAR-RAG.}
}


@inproceedings{DBLP:conf/www/0004MZMXFSCGY25,
	author = {Yiqun Chen and
                  Jiaxin Mao and
                  Yi Zhang and
                  Dehong Ma and
                  Long Xia and
                  Jun Fan and
                  Daiting Shi and
                  Zhicong Cheng and
                  Simiu Gu and
                  Dawei Yin},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {{MA4DIV:} Multi-Agent Reinforcement Learning for Search Result Diversification},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {1703--1715},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714862},
	doi = {10.1145/3696410.3714862},
	timestamp = {Tue, 13 May 2025 07:31:04 +0200},
	biburl = {https://dblp.org/rec/conf/www/0004MZMXFSCGY25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Search result diversification (SRD), which aims to ensure that documents in a ranking list cover a broad range of subtopics, is a significant and widely studied problem in Information Retrieval and Web Search. Existing methods primarily utilize a paradigm of ''greedy selection'', i.e., selecting one document with the highest diversity score at a time or optimize an approximation of the objective function. These approaches tend to be inefficient and are easily trapped in a suboptimal state. To address these challenges, we introduce  M ulti- A gent reinforcement learning (MARL) for search result  DIV ersity, which called  MA4DIV . In this approach, each document is an agent and the search result diversification is modeled as a cooperative task among multiple agents. By modeling the SRD ranking problem as a cooperative MARL problem, this approach allows for directly optimizing the diversity metrics, such as α-NDCG, while achieving high training efficiency. We conducted experiments on public TREC datasets and a larger scale dataset in the industrial setting. The experiemnts show that MA4DIV achieves substantial improvements in both effectiveness and efficiency than existing baselines, especially on the industrial dataset.}
}


@inproceedings{DBLP:conf/www/SongW0DMZX25,
	author = {Xiaoshuai Song and
                  Zhengyang Wang and
                  Keqing He and
                  Guanting Dong and
                  Yutao Mou and
                  Jinxu Zhao and
                  Weiran Xu},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Assessing and Post-Processing Black Box Large Language Models for
                  Knowledge Editing},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {1716--1732},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714732},
	doi = {10.1145/3696410.3714732},
	timestamp = {Fri, 09 May 2025 20:28:08 +0200},
	biburl = {https://dblp.org/rec/conf/www/SongW0DMZX25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The rapid evolution of the Web as a key platform for information dissemination has led to the growing integration of large language models (LLMs) in Web-based applications. However, the swift changes in web content present challenges in maintaining these models' relevance and accuracy. The task of Knowledge Editing (KE) is aimed at efficiently and precisely adjusting the behavior of large language models (LLMs) to update specific knowledge while minimizing any adverse effects on other knowledge. Current research predominantly concentrates on editing white-box LLMs, neglecting a significant scenario: editing black-box LLMs, where access is limited to interfaces and only textual output is provided. In this paper, we initially officially introduce KE on black-box LLMs, followed by presenting a thorough evaluation framework. This framework operates without requiring logits and considers pre- and post-edit consistency, addressing the limitations of current evaluations that are inadequate for black-box LLMs editing and lack comprehensiveness. To address privacy leaks of editing data and style over-editing in existing approaches, we propose a new postEdit framework. postEdit incorporates a retrieval mechanism for editing knowledge and a purpose-trained editing plugin called post-editor, ensuring privacy through downstream processing and maintaining textual style consistency via fine-grained editing. Experiments and analysis conducted on two benchmarks show that postEdit surpasses all baselines and exhibits robust generalization, notably enhancing style retention by an average of +20.82%. Our code is available on github https://github.com/songxiaoshuai/postEdit.}
}


@inproceedings{DBLP:conf/www/TanDWWCW25,
	author = {Jiejun Tan and
                  Zhicheng Dou and
                  Wen Wang and
                  Mang Wang and
                  Weipeng Chen and
                  Ji{-}Rong Wen},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {HtmlRAG: {HTML} is Better Than Plain Text for Modeling Retrieved Knowledge
                  in {RAG} Systems},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {1733--1746},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714546},
	doi = {10.1145/3696410.3714546},
	timestamp = {Tue, 13 May 2025 07:31:04 +0200},
	biburl = {https://dblp.org/rec/conf/www/TanDWWCW25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Retrieval-Augmented Generation (RAG) has been shown to improve knowledge capabilities and alleviate the hallucination problem of LLMs. The Web is a major source of external knowledge used in RAG systems, and many commercial RAG systems have used Web search engines as their major retrieval systems. Typically, such RAG systems retrieve search results, download HTML sources of the results, and then extract plain texts from the HTML sources. Plain text documents or chunks are fed into the LLMs to augment the generation. However, much of the structural and semantic information inherent in HTML, such as headings and table structures, is lost during this plain-text-based RAG process. To alleviate this problem, we propose HtmlRAG, which uses HTML instead of plain text as the format of retrieved knowledge in RAG. We believe HTML is better than plain text in modeling knowledge in external documents, and most LLMs possess robust capacities to understand HTML. However, utilizing HTML presents new challenges. HTML contains additional content such as tags, JavaScript, and CSS specifications, which bring extra input tokens and noise to the RAG system. To address this issue, we propose HTML cleaning, compression, and a two-step block-tree-based pruning strategy, to shorten the HTML while minimizing the loss of information. Experiments on six QA datasets confirm the superiority of using HTML in RAG systems. Our code and datasets are available at https://github.com/plageon/HtmlRAG.}
}


@inproceedings{DBLP:conf/www/0002TZ025,
	author = {Chuang Zhao and
                  Hui Tang and
                  Jiheng Zhang and
                  Xiaomeng Li},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Unveiling Discrete Clues: Superior Healthcare Predictions for Rare
                  Diseases},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {1747--1758},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714831},
	doi = {10.1145/3696410.3714831},
	timestamp = {Fri, 09 May 2025 20:28:08 +0200},
	biburl = {https://dblp.org/rec/conf/www/0002TZ025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Accurate healthcare prediction is essential for improving patient outcomes. Existing work primarily leverages advanced frameworks like attention or graph networks to capture the intricate collaborative (CO) signals in electronic health records. However, prediction for rare diseases remains challenging due to limited co-occurrence and inadequately tailored approaches. To address this issue, this paper proposes UDC, a novel method that unveils discrete clues to bridge consistent textual knowledge and CO signals within a unified semantic space, thereby enriching the representation semantics of rare diseases. Specifically, we focus on addressing two key sub-problems: (1) acquiring distinguishable discrete encodings for precise disease representation and (2) achieving semantic alignment between textual knowledge and the CO signals at the code level. For the first sub-problem, we refine the standard vector quantized process to include condition awareness. Additionally, we develop an advanced contrastive approach in the decoding stage, leveraging synthetic and mixed-domain targets as hard negatives to enrich the perceptibility of the reconstructed representation for downstream tasks. For the second sub-problem, we introduce a novel codebook update strategy using co-teacher distillation. This approach facilitates bidirectional supervision between textual knowledge and CO signals, thereby aligning semantically equivalent information in a shared discrete latent space. Extensive experiments on three datasets demonstrate our superiority.}
}


@inproceedings{DBLP:conf/www/HeSHLSH25,
	author = {Yufei He and
                  Yuan Sui and
                  Xiaoxin He and
                  Yue Liu and
                  Yifei Sun and
                  Bryan Hooi},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {UniGraph2: Learning a Unified Embedding Space to Bind Multimodal Graphs},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {1759--1770},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714818},
	doi = {10.1145/3696410.3714818},
	timestamp = {Tue, 13 May 2025 07:31:04 +0200},
	biburl = {https://dblp.org/rec/conf/www/HeSHLSH25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Existing foundation models, such as CLIP, aim to learn a unified embedding space for multimodal data, enabling a wide range of downstream web-based applications like search, recommendation, and content classification. However, these models often overlook the inherent graph structures in multimodal datasets, where entities and their relationships are crucial. Multimodal graphs (MMGs) represent such graphs where each node is associated with features from different modalities, while the edges capture the relationships between these entities.On the other hand, existing graph foundation models primarily focus on text-attributed graphs (TAGs) and are not designed to handle the complexities of MMGs. To address these limitations, we propose UniGraph2, a novel cross-domain graph foundation model that enables general representation learning on MMGs, providing a unified embedding space. UniGraph2 employs modality-specific encoders alongside a graph neural network (GNN) to learn a unified low-dimensional embedding space that captures both the multimodal information and the underlying graph structure. We propose a new cross-domain multi-graph pre-training algorithm at scale to ensure effective transfer learning across diverse graph domains and modalities. Additionally, we adopt a Mixture of Experts (MoE) component to align features from different domains and modalities, ensuring coherent and robust embeddings that unify the information across modalities. Extensive experiments on a variety of multimodal graph tasks demonstrate that UniGraph2 significantly outperforms state-of-the-art models in tasks such as representation learning, transfer learning, and multimodal generative tasks, offering a scalable and flexible solution for learning on MMGs.}
}


@inproceedings{DBLP:conf/www/ZhengBWZH25,
	author = {Lecheng Zheng and
                  John R. Birge and
                  Haiyue Wu and
                  Yifang Zhang and
                  Jingrui He},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Cluster Aware Graph Anomaly Detection},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {1771--1782},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714575},
	doi = {10.1145/3696410.3714575},
	timestamp = {Fri, 09 May 2025 20:28:08 +0200},
	biburl = {https://dblp.org/rec/conf/www/ZhengBWZH25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graph anomaly detection has gained significant attention across various domains, particularly in critical applications like fraud detection in e-commerce platforms and insider threat detection in cybersecurity. Usually, these data are composed of multiple types (e.g., user information and transaction records for financial data), thus exhibiting view heterogeneity. However, in the era of big data, the heterogeneity of views and the lack of label information pose substantial challenges to traditional approaches. Existing unsupervised graph anomaly detection methods often struggle with high-dimensionality issues, rely on strong assumptions about graph structures or fail to handle complex multi-view graphs. To address these challenges, we propose a cluster aware multi-view graph anomaly detection method, called CARE. Our approach captures both local and global node affinities by augmenting the graph's adjacency matrix with the pseudo-label (i.e., soft membership assignments) without any strong assumption about the graph. To mitigate potential biases from the pseudo-label, we introduce a similarity-guided loss. Theoretically, we show that the proposed similarity-guided loss is a variant of contrastive learning loss, and we present how this loss alleviates the bias introduced by pseudo-label with the connection to graph spectral clustering. Experimental results on several datasets demonstrate the effectiveness and efficiency of our proposed framework. Specifically, CARE outperforms the second-best competitors by more than 39% on the Amazon dataset with respect to AUPRC and 18.7% on the YelpChi dataset with respect to AUROC. The code of our method is available at the GitHub link: https://github.com/zhenglecheng/CARE-demo.}
}


@inproceedings{DBLP:conf/www/LiLBD0P25,
	author = {Weihe Li and
                  Zukai Li and
                  Beyza B{\"{u}}t{\"{u}}n and
                  Alec F. Diallo and
                  Marco Fiore and
                  Paul Patras},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Pontus: {A} Memory-Efficient and High-Accuracy Approach for Persistence-Based
                  Item Lookup in High-Velocity Data Streams},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {1783--1794},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714670},
	doi = {10.1145/3696410.3714670},
	timestamp = {Fri, 09 May 2025 20:28:08 +0200},
	biburl = {https://dblp.org/rec/conf/www/LiLBD0P25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In today's web-scale, data-driven environments, real-time detection of persistent items that consistently recur over time is essential for maintaining system integrity, reliability, and security. Persistent items often signal critical anomalies, such as stealthy DDoS and botnet attacks in web infrastructures. Although various methods exist for identifying such items as well as for determining their frequency, they require recording every item for processing, which is impractical at very high data rates achieved by modern data streams. In this paper, we introduce Pontus, a novel approach that uses an approximate data structure ( sketch ) specifically designed for the efficient and accurate detection of persistent items. Our method not only achieves fast and precise lookup but is also flexible, allowing for minor modifications to accommodate other types of persistence-based item detection tasks, such as detecting persistent items with low frequency. We rigorously validate our approach through formal methods, offering detailed proofs of time/space complexity and error bounds to demonstrate its theoretical soundness. Our extensive trace-driven evaluations across various persistence-based tasks further demonstrate Pontus's effectiveness in significantly improving detection accuracy and enhancing processing speed compared to existing approaches. We implement Pontus in an experimental platform with industry-grade Intel Tofino switches and demonstrate the practical feasibility of our approach in a real-world memory-constrained environment.}
}


@inproceedings{DBLP:conf/www/0001ZWLY25,
	author = {Yuanmin Huang and
                  Mi Zhang and
                  Zhaoxiang Wang and
                  Wenxuan Li and
                  Min Yang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Revisiting Backdoor Attacks on Time Series Classification in the Frequency
                  Domain},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {1795--1810},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714827},
	doi = {10.1145/3696410.3714827},
	timestamp = {Fri, 09 May 2025 20:28:08 +0200},
	biburl = {https://dblp.org/rec/conf/www/0001ZWLY25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Time series classification (TSC) is a cornerstone of modern web applications, powering tasks such as financial data analysis, network traffic monitoring, and user behavior analysis. In recent years, deep neural networks (DNNs) have greatly enhanced the performance of TSC models in these critical domains. However, DNNs are vulnerable to backdoor attacks, where attackers can covertly implant triggers into models to induce malicious outcomes. Existing backdoor attacks targeting DNN-based TSC models remain elementary. In particular, early methods borrow trigger designs from computer vision, which are ineffective for time series data. More recent approaches utilize generative models for trigger generation, but at the cost of significant computational complexity. In this work, we analyze the limitations of existing attacks and introduce an enhanced method,  FreqBack . Drawing inspiration from the fact that DNN models inherently capture frequency domain features in time series data, we identify that improper perturbations in the frequency domain are the root cause of ineffective attacks. To address this, we propose to generate triggers both effectively and efficiently, guided by frequency analysis. FreqBack exhibits substantial performance across five models and eight datasets, achieving an impressive attack success rate of over 90%, while maintaining less than a 3% drop in model accuracy on clean data.}
}


@inproceedings{DBLP:conf/www/LiR0L00025,
	author = {Hao Li and
                  Yubing Ren and
                  Yanan Cao and
                  Yingjie Li and
                  Fang Fang and
                  Zheng Lin and
                  Shi Wang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Bridging the Gap: Aligning Language Model Generation with Structured
                  Information Extraction via Controllable State Transition},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {1811--1821},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714571},
	doi = {10.1145/3696410.3714571},
	timestamp = {Fri, 09 May 2025 20:28:09 +0200},
	biburl = {https://dblp.org/rec/conf/www/LiR0L00025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Large language models (LLMs) achieve superior performance in generative tasks. However, due to the natural gap between language model generation and structured information extraction in three dimensions: task type, output format, and modeling granularity, they often fall short in structured information extraction, a crucial capability for effective data utilization on the web. In this paper, we define the generation process of the language model as the controllable state transition, aligning the generation and extraction processes to ensure the integrity of the output structure and adapt to the goals of the information extraction task. Furthermore, we propose the Structure2Text decider to help the language model understand the fine-grained extraction information, which converts the structured output into natural language and makes state decisions, thereby focusing on the task-specific information kernels, and alleviating language model hallucinations and incorrect content generation. We conduct extensive experiments and detailed analyses on myriad information extraction tasks, including named entity recognition, relation extraction, and event argument extraction. Our method not only achieves significant performance improvements but also considerably enhances the model's capability to generate precise and relevant content, making the extracted content easy to parse.}
}


@inproceedings{DBLP:conf/www/ShaoHLX25,
	author = {Chenyang Shao and
                  Xinyuan Hu and
                  Yutang Lin and
                  Fengli Xu},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Division-of-Thoughts: Harnessing Hybrid Language Model Synergy for
                  Efficient On-Device Agents},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {1822--1833},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714765},
	doi = {10.1145/3696410.3714765},
	timestamp = {Fri, 09 May 2025 20:28:09 +0200},
	biburl = {https://dblp.org/rec/conf/www/ShaoHLX25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The rapid expansion of web content has made on-device AI assistants indispensable for helping users manage the increasing complexity of online tasks. The emergent reasoning ability in large language models offer a promising path for next-generation on-device AI agents. However, deploying full-scale Large Language Models (LLMs) on resource-limited local devices is challenging. In this paper, we propose <u>D</u>ivision-<u>o</u> f-<u>T</u>houghts ( DoT ), a collaborative reasoning framework leveraging the synergy between locally deployed Smaller-scale Language Models (SLMs) and cloud-based LLMs. DoT leverages a  Task Decomposer  to elicit the inherent planning abilities in language models to decompose user queries into smaller sub-tasks, which allows hybrid language models to fully exploit their respective strengths. Besides, DoT employs a  Task Scheduler  to analyze the pair-wise dependency of sub-tasks and create a dependency graph, facilitating parallel reasoning of sub-tasks and the identification of key steps. To allocate the appropriate model based on the difficulty of sub-tasks, DoT leverages a  Plug-and-Play Adapter,  which is an additional task head attached to the SLM that does not alter the SLM's parameters. To boost adapter's task allocation capability, we propose a self-reinforced training method that relies solely on task execution feedback. Extensive experiments on various benchmarks demonstrate that our DoT significantly reduces LLM costs while maintaining competitive reasoning accuracy. Specifically, DoT reduces the average reasoning time and API costs by 66.12% and 83.57%, while achieving comparable reasoning accuracy with the best baseline methods.}
}


@inproceedings{DBLP:conf/www/GuiL000CSC0Z00025,
	author = {Yi Gui and
                  Zhen Li and
                  Yao Wan and
                  Yemin Shi and
                  Hongyu Zhang and
                  Bohua Chen and
                  Yi Su and
                  Dongping Chen and
                  Siyuan Wu and
                  Xing Zhou and
                  Wenbin Jiang and
                  Hai Jin and
                  Xiangliang Zhang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {WebCode2M: {A} Real-World Dataset for Code Generation from Webpage
                  Designs},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {1834--1845},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714889},
	doi = {10.1145/3696410.3714889},
	timestamp = {Fri, 09 May 2025 20:28:09 +0200},
	biburl = {https://dblp.org/rec/conf/www/GuiL000CSC0Z00025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Automatically generating webpage code from webpage designs can significantly reduce the workload of front-end developers, and recent  Multimodal Large Language Models  (MLLMs) have shown promising potential in this area. However, our investigation reveals that most existing MLLMs are constrained by the absence of high-quality, large-scale, real-world datasets, resulting in inadequate performance in automated webpage code generation. To fill this gap, this paper introduces WebCode2M, a new dataset comprising 2.56 million instances, each containing a design image along with the corresponding webpage code and layout details. Sourced from real-world web resources, WebCode2M offers a rich and valuable dataset for webpage code generation across a variety of applications. The dataset quality is ensured by a scoring model that filters out instances with aesthetic deficiencies or other incomplete elements. To validate the effectiveness of WebCode2M, we introduce a baseline model based on the  Vision Transformer  (ViT), named WebCoder, and establish a benchmark for fair comparison. Additionally, we introduce a new metric, TreeBLEU, to measure the structural hierarchy recall. The benchmarking results demonstrate that our dataset significantly improves the ability of MLLMs to generate code from webpage designs, confirming its effectiveness and usability for future applications in front-end design tools. Finally, we highlight several practical challenges introduced by our dataset, calling for further research. The code and dataset are publicly available at our project homepage: https://webcode2m.github.io.}
}


@inproceedings{DBLP:conf/www/Gui0LZC0SCZ0025,
	author = {Yi Gui and
                  Yao Wan and
                  Zhen Li and
                  Zhongyi Zhang and
                  Dongping Chen and
                  Hongyu Zhang and
                  Yi Su and
                  Bohua Chen and
                  Xing Zhou and
                  Wenbin Jiang and
                  Xiangliang Zhang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {UICopilot: Automating {UI} Synthesis via Hierarchical Code Generation
                  from Webpage Designs},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {1846--1855},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714891},
	doi = {10.1145/3696410.3714891},
	timestamp = {Thu, 24 Apr 2025 07:52:00 +0200},
	biburl = {https://dblp.org/rec/conf/www/Gui0LZC0SCZ0025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Automating the synthesis of  User Interfaces  (UIs) plays a crucial role in enhancing productivity and accelerating the development lifecycle, reducing both development time and manual effort. Recently, the rapid development of  Multimodal Large Language Models  (MLLMs) has made it possible to generate front-end  Hypertext Markup Language  (HTML) code directly from webpage designs. However, real-world webpages encompass not only a diverse array of HTML tags but also complex stylesheets, resulting in significantly lengthy code. The lengthy code poses challenges for the performance and efficiency of MLLMs, especially in capturing the structural information of UI designs. To address these challenges, this paper proposes UICopilot, a novel approach to automating UI synthesis via hierarchical code generation from webpage designs. To validate the effectiveness of UIC opilot , we conduct experiments on a real-world dataset, i.e., WebCode2M. Experimental results demonstrate that UIC opilot  significantly outperforms existing baselines in both automatic evaluation metrics and human evaluations. Specifically, statistical analysis reveals that the majority of human annotators prefer the webpages generated by UIC opilot  over those produced by GPT-4V.}
}


@inproceedings{DBLP:conf/www/GuCDZ025,
	author = {Yuhao Gu and
                  Chunyu Chen and
                  Jiangsu Du and
                  Xiaoxi Zhang and
                  Xianwei Zhang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {{ORFA:} Exploring WebAssembly as a Turing Complete Query Language
                  for Web APIs},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {1856--1865},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714826},
	doi = {10.1145/3696410.3714826},
	timestamp = {Wed, 23 Apr 2025 16:35:50 +0200},
	biburl = {https://dblp.org/rec/conf/www/GuCDZ025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Web APIs are the primary communication form for Web services, with RESTful design being the predominant paradigm. However, RESTful APIs are typically fixed once defined, causing data under- or over-fetching as they can't meet clients' varying Web service needs. While semantic enriched API query languages like GraphQL mitigates this problem, they still face expressiveness limitations for logical operations such as indirect queries and loop traversals. To address this, we propose ORFA (One Request For All), the first in literature that employs WebAssembly (Wasm) as a Web API query language to achieve complete expressiveness of client requests. ORFA's key advantage lies in its use of Wasm's Turing completeness to allow clients to compose arbitrary operations within a single request, thus significantly eliminating redundant data transmission and boosting communication efficiency. Technically, ORFA provides a runtime for executing Wasm query programs and incorporates new module splitting strategies and a caching mechanism customized for integrating Wasm into Web API services, which can enable lightweight code transfer and fast request responses. Experimental results on a realistic testbed and popular Web applications show that ORFA effectively reduces latency by 18.4% and network traffic by 24.5% on average, compared to the state-of-the-art GraphQL.}
}


@inproceedings{DBLP:conf/www/WangFZCZL0DC25,
	author = {Xin Wang and
                  Ling Feng and
                  Huijun Zhang and
                  Lei Cao and
                  Kaisheng Zeng and
                  Qi Li and
                  Yang Ding and
                  Yi Dai and
                  David A. Clifton},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {{MISE:} Meta-knowledge Inheritance for Social Media-Based Stressor
                  Estimation},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {1866--1876},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714901},
	doi = {10.1145/3696410.3714901},
	timestamp = {Fri, 09 May 2025 20:28:09 +0200},
	biburl = {https://dblp.org/rec/conf/www/WangFZCZL0DC25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Stress haunts people in modern society, which may cause severe health issues if left unattended. With social media becoming an integral part of daily life, leveraging social media to detect stress has gained increasing attention. While the majority of the work focuses on classifying stress states and stress categories, this study introduce a new task aimed at estimating more specific stressors (like exam, writing paper, etc.) through users' posts on social media. Unfortunately, the diversity of stressors with many different classes but a few examples per class, combined with the consistent arising of new stressors over time, hinders the machine understanding of stressors. To this end, we cast the stressor estimation problem within a practical scenario few-shot learning setting, and propose a novel meta-learning based stressor estimation framework that is enhanced by a meta-knowledge inheritance mechanism. This model can not only learn generic stressor context through meta-learning, but also has a good generalization ability to estimate new stressors with little labeled data. A fundamental breakthrough in our approach lies in the inclusion of the meta-knowledge inheritance mechanism, which equips our model with the ability to prevent catastrophic forgetting when adapting to new stressors. The experimental results show that our model achieves state-of-the-art performance compared with the baselines. Additionally, we construct a social media-based stressor estimation dataset that can help train artificial intelligence models to facilitate human well-being.}
}


@inproceedings{DBLP:conf/www/WangLLCWYHS25,
	author = {Rui Wang and
                  Jiahao Lu and
                  Xincheng Lv and
                  Shuyu Chang and
                  Yansheng Wu and
                  Yuanzhi Yao and
                  Haiping Huang and
                  Guozi Sun},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Mining User Preferences from Online Reviews with the Genre-aware Personalized
                  Neural Topic Model},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {1877--1888},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714775},
	doi = {10.1145/3696410.3714775},
	timestamp = {Fri, 09 May 2025 20:28:09 +0200},
	biburl = {https://dblp.org/rec/conf/www/WangLLCWYHS25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Customer-generated reviews on e-commerce websites often contain valuable insights into users' interests in product genres and provide a rich source for mining user preferences. However, most existing neural topic models tend to generate meaningless topics that share low correlations with product genres. Furthermore, they often fail to mine user preferences and discover personalized topic profiles due to the absence of explicit user modeling. To address these limitations, we propose a novel Genre-aware Personalized neural Topic Model (GPTM), which incorporates product genre information into the topic modeling process to ensure the relevance between mined topics and product genres. Moreover, it could produce a personalized topic profile for each user by performing user preference modeling. Extensive experimental results on three publicly available Amazon review corpora validate the effectiveness of the proposed GPTM in genre-aware topic modeling. Furthermore, GPTM surpasses state-of-the-art baselines in user preference mining and generates high-quality personalized topic profiles.}
}


@inproceedings{DBLP:conf/www/BhuiyanVSZ25,
	author = {Masudul Hasan Masud Bhuiyan and
                  Matteo Varvello and
                  Cristian{-}Alexandru Staicu and
                  Yasir Zaki},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Digital Disparities: {A} Comparative Web Measurement Study Across
                  Economic Boundaries},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {1889--1900},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714647},
	doi = {10.1145/3696410.3714647},
	timestamp = {Fri, 09 May 2025 20:28:09 +0200},
	biburl = {https://dblp.org/rec/conf/www/BhuiyanVSZ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {While internet usage is slowly catching up globally, it is still unclear how the web experience differs in developing and developed countries. On the one hand, the web has a notoriously large inertia, with many webpages still relying on unencrypted HTTP, deprecated web features, or old and buggy libraries. On the other hand, developing countries are expected to leapfrog and directly adopt the newest technologies by learning from the prior mistakes of more developed countries. Anecdotal evidence suggests that webpages in developing and developed regions differ significantly. In this work, we test this hypothesis by measuring differences in web development practices across the two groups of countries, using multiple dimensions: webpages' size, complexity, security, privacy, quality, technology adoption, and accessibility. Concretely, we collect the largest dataset to date that compares web development practices across developed and developing regions -- 200,000 webpages across 20 countries -- which we aim to open source along with this publication. Our findings reveal that webpages in developing regions are generally smaller and simpler, utilizing fewer requests - an adaptation that improves the performance over slower network conditions common in these areas. However, these sites are less optimized in other critical aspects: they frequently employ inefficient image formats, include unnecessary JavaScript or CSS code, or lack responsive image designs. Notably, our security assessment shows developing regions lagging in HTTPS adoption and vulnerability mitigation, possibly due to lower awareness of best practices.}
}


@inproceedings{DBLP:conf/www/0044SKCJ025,
	author = {Yu Zhang and
                  Yanzhen Shen and
                  SeongKu Kang and
                  Xiusi Chen and
                  Bowen Jin and
                  Jiawei Han},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Chain-of-Factors Paper-Reviewer Matching},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {1901--1910},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714708},
	doi = {10.1145/3696410.3714708},
	timestamp = {Fri, 09 May 2025 20:28:09 +0200},
	biburl = {https://dblp.org/rec/conf/www/0044SKCJ025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the rapid increase in paper submissions to academic conferences, the need for automated and accurate paper-reviewer matching is more critical than ever. Previous efforts in this area have considered various factors to assess the relevance of a reviewer's expertise to a paper, such as the semantic similarity, shared topics, and citation connections between the paper and the reviewer's previous works. However, most of these studies focus on only one factor, resulting in an incomplete evaluation of the paper-reviewer relevance. To address this issue, we propose a unified model for paper-reviewer matching that jointly considers semantic, topic, and citation factors. To be specific, during training, we instruction-tune a contextualized language model shared across all factors to capture their commonalities and characteristics; during inference, we chain the three factors to enable step-by-step, coarse-to-fine search for qualified reviewers given a submission. Experiments on four datasets (one of which is newly contributed by us) spanning various fields such as machine learning, computer vision, information retrieval, and data mining consistently demonstrate the effectiveness of our proposed Chain-of-Factors model in comparison with state-of-the-art paper-reviewer matching methods and scientific pre-trained language models.}
}


@inproceedings{DBLP:conf/www/KoRK25,
	author = {Yunyong Ko and
                  Seongeun Ryu and
                  Sang{-}Wook Kim},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {{CROWN:} {A} Novel Approach to Comprehending Users' Preferences for
                  Accurate Personalized News Recommendation},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {1911--1921},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714752},
	doi = {10.1145/3696410.3714752},
	timestamp = {Thu, 01 May 2025 20:27:23 +0200},
	biburl = {https://dblp.org/rec/conf/www/KoRK25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Personalized news recommendation aims to assist users in finding news articles that align with their interests, which plays a pivotal role in mitigating users' information overload problem. Despite the breakthrough in personalized news recommendation, the following challenges have been rarely explored: (C1) Comprehending manifold intents coupled within a news article, (C2) Differentiating varying post-read preferences of news articles, and (C3) Addressing the cold-start user problem. To tackle these challenges together, we propose a novel personalized news recommendation framework (CROWN) that employs (1) category-guided intent disentanglement for (C1), (2) consistency-based news representation for (C2), and (3) GNN-enhanced hybrid user representation for (C3). Furthermore, we incorporate a category prediction into the training process of CROWN as an auxiliary task for enhancing intent disentanglement. Extensive experiments on two real-world datasets reveal that (1) CROWN outperforms twelve state-of-the-art news recommendation methods and (2) the proposed strategies significantly improve the accuracy of CROWN.}
}


@inproceedings{DBLP:conf/www/SchwartzBMES25,
	author = {Yuval Schwartz and
                  Lavi Ben{-}Shimol and
                  Dudu Mimran and
                  Yuval Elovici and
                  Asaf Shabtai},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {LLMCloudHunter: Harnessing LLMs for Automated Extraction of Detection
                  Rules from Cloud-Based {CTI}},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {1922--1941},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714798},
	doi = {10.1145/3696410.3714798},
	timestamp = {Fri, 09 May 2025 20:28:09 +0200},
	biburl = {https://dblp.org/rec/conf/www/SchwartzBMES25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As the number and sophistication of cyber attacks have increased, threat hunting has become a critical aspect of active security, enabling proactive detection and mitigation of threats before they cause significant harm. Open-source cyber threat intelligence (OSCTI) is a valuable resource for threat hunters, however, it often comes in unstructured formats that require further manual analysis. Previous studies aimed at automating OSCTI analysis are limited since (1) they failed to provide actionable outputs, (2) they did not take advantage of images present in OSCTI sources, and (3) they focused on on-premises environments, overlooking the growing importance of cloud environments. To address these gaps, we propose LLMCloudHunter, a novel framework that leverages large language models (LLMs) to automatically generate generic-signature detection rule candidates from textual and visual OSCTI data. We evaluated the quality of the rules generated by the proposed framework using 20 annotated real-world cloud threat reports. The results show that our framework achieved a precision of 83% and recall of 99% for the task of accurately extracting API calls made by the threat actor and a precision of 99% with a recall of 97% for IoCs. Additionally, 99.18% of the generated detection rule candidates were successfully compiled and converted into Splunk queries.}
}


@inproceedings{DBLP:conf/www/SunCFL0L25,
	author = {Yuxia Sun and
                  Huihong Chen and
                  Zhixiao Fu and
                  Wenjian Lv and
                  Zitao Liu and
                  Haolin Liu},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {WasmGuard: Enhancing Web Security through Robust Raw-Binary Detection
                  of WebAssembly Malware},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {1942--1950},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714696},
	doi = {10.1145/3696410.3714696},
	timestamp = {Fri, 09 May 2025 20:28:09 +0200},
	biburl = {https://dblp.org/rec/conf/www/SunCFL0L25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {WebAssembly (Wasm), a binary instruction format designed for efficient cross-platform execution, has rapidly become a foundational web standard, widely adopted in browsers, client-side, and server-side applications. However, its growing popularity has led to an increase in Wasm-targeted malware, including cryptojackers and obfuscated malicious scripts, which pose significant threats to web security. In spite of progress in deep learning based detection methods for Wasm malware, such as MINOS, these approaches face substantial performance degradation in adversarial environments. In our experiments, MINOS's detection accuracy dropped to 49.90% under adversarial attacks, revealing critical vulnerabilities. To address this, we introduce  WasmGuard , a robust malware detection framework tailored for Wasm. WasmGuard employs FGSM-based adversarial training with prior-based initialization for perturbation bytes in customized sections, coupled with a novel adversarial contrastive learning objective. Using our large-scale dataset,  WasmMal-15K  (publicly available at https://github.com/Yuxia-Sun/WasmMal GitHub), WasmGuard outperforms six competing methods, achieving up to 99.20% Robust Accuracy and 99.93% Standard Accuracy under PGD-50 adversarial attacks, while maintaining low training overhead. Additionally, we have released  WebChecker , a WasmGuard-powered browser plugin, providing real-time protection against malicious Wasm files, at https://github.com/Yuxia-Sun/WasmGuard.}
}


@inproceedings{DBLP:conf/www/Xu0P025,
	author = {Zitao Xu and
                  Xiaoqing Chen and
                  Weike Pan and
                  Zhong Ming},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Heterogeneous Graph Transfer Learning for Category-aware Cross-Domain
                  Sequential Recommendation},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {1951--1962},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714885},
	doi = {10.1145/3696410.3714885},
	timestamp = {Fri, 09 May 2025 20:28:09 +0200},
	biburl = {https://dblp.org/rec/conf/www/Xu0P025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cross-domain sequential recommendation (CDSR) is proposed to alleviate the data sparsity issue while capturing users' sequential preferences. However, most existing methods do not explore the item transition patterns across different domains and can also not be applied to a multi-domain scenario.Moreover, previous methods rely on overlapping users as bridges to transfer knowledge, which struggles to capture the complex associations across domains without sufficient overlapping users. In this paper, we introduce item attributes into CDSR, and propose a heterogeneous graph transfer learning method to address these issues.Specifically, we construct a cross-domain heterogeneous graph to allow the association of user, item, and category nodes from different domains,and enhance the flexibility of the model by enabling message propagation between more nodes through edge expansion based on the semantic similarity and co-occurrence probability.In addition, we devise meta-paths from different perspectives for nodes at item, user and category levels to guide information aggregation, which can transfer knowledge across domains and reduce the reliance on the number of overlapping users.We further design attention modules to capture users' dynamic preferences from the item sequences they have interacted with in each domain, and explore the transition patterns within category sequences which reflect users' coarse-grained preferences.Finally, we perform knowledge transfer across different domains, and predict the most likely items that users will interact with in each domain. Extensive empirical studies on three real-world datasets indicate that our HGTL significantly outperforms the state-of-the-art baselines in all cases.}
}


@inproceedings{DBLP:conf/www/ZhangFJBW025,
	author = {Tianyu Zhang and
                  Junfeng Fang and
                  Houcheng Jiang and
                  Baolong Bi and
                  Xiang Wang and
                  Xiangnan He},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Explainable and Efficient Editing for Large Language Models},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {1963--1976},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714835},
	doi = {10.1145/3696410.3714835},
	timestamp = {Fri, 09 May 2025 20:28:09 +0200},
	biburl = {https://dblp.org/rec/conf/www/ZhangFJBW025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Large Language Models (LLMs) exhibit remarkable capabilities in storing and retrieving vast amounts of factual knowledge. However, they retain outdated or incorrect information from Web corpora. Since full retraining is costly, locate-and-edit model editing methods offer a feasible alternative. Current methods typically follow a two-stage paradigm: (1) identifying critical layers that store knowledge and (2) updating their parameters to store new knowledge. However, both phases have their inherent limitations. Firstly, layer identification is independent of the knowledge being updated, ignoring the differences in knowledge storage patterns. Secondly, parameter updating suffers from high computational overhead due to gradient descent. To solve these, we propose an  E xplainable and effi C ient model  E diting method, termed  ECE . Specifically, we integrate LLM explainability into the editing process, enabling the adaptive identification of the crucial neurons. Through clustering similar knowledge, we enable batch optimization in a single gradient step, significantly reducing computational time without compromising effectiveness. Extensive experiments demonstrate that ECE can achieve superior performance, showcasing the potential of explainability-driven editing methods for LLMs. Code is available at https://github.com/tianyuzhangterry/ECE.}
}


@inproceedings{DBLP:conf/www/MaLDSY025,
	author = {Yuchao Ma and
                  Weian Li and
                  Yuejia Dou and
                  Zhiyuan Su and
                  Changyuan Yu and
                  Qi Qi},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {A Context-Aware Framework for Integrating Ad Auctions and Recommendations},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {1977--1991},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714779},
	doi = {10.1145/3696410.3714779},
	timestamp = {Fri, 09 May 2025 20:28:09 +0200},
	biburl = {https://dblp.org/rec/conf/www/MaLDSY025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recently, many e-commerce platforms have favored presenting a mixed list of ads and organic content to users. The widely-used approach separately ranks ads and organic items, then sequentially inserts ads into the list of organic items. However, this method yields sub-optimal results. Firstly, it only ensures that each generated ad and organic item list achieves local optimality, while the predetermined insertion order fails to guarantee global optimality. Secondly, this approach overlooks the mutual effect between organic items and ads, resulting in an incomplete utilization of contextual information. Besides, it cannot prevent strategic behavior by advertisers. Therefore, we propose a context-aware integrated framework to address these issues. This framework applies automated mechanism design to integrated ad auctions for the first time. Specifically, it models ads and organic items simultaneously along with their contextual information and employs a learning-based approach to prevent advertisers from engaging in strategic behavior. Afterward, the framework directly generates a mixed list, enhancing the overall performance. We also propose  T ransformer encoder-based  I ntegrated  C ontextual  Net  work (TICNet) to generate the optimal integrated contextual ad auction. Finally, we validate the effectiveness of TICNet on synthetic and real-world datasets. Our experimental results demonstrate that TICNet significantly outperforms baseline models across multiple metrics.}
}


@inproceedings{DBLP:conf/www/YuanXCZWZ25,
	author = {Meng Yuan and
                  Yutian Xiao and
                  Wei Chen and
                  Chou Zhao and
                  Deqing Wang and
                  Fuzhen Zhuang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Hyperbolic Diffusion Recommender Model},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {1992--2006},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714873},
	doi = {10.1145/3696410.3714873},
	timestamp = {Fri, 09 May 2025 20:28:09 +0200},
	biburl = {https://dblp.org/rec/conf/www/YuanXCZWZ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Diffusion models (DMs) have emerged as the new state-of-the-art family of deep generative models. To gain deeper insights into the limitations of diffusion models in recommender systems, we investigate the fundamental structural disparities between images and items. Consequently, items often exhibit distinct anisotropic and directional structures that are less prevalent in images. However, the traditional forward diffusion process continuously adds isotropic Gaussian noise, causing anisotropic signals to degrade into noise, which impairs the semantically meaningful representations in recommender systems. Inspired by the advancements in hyperbolic spaces, we propose a novel  H yperbolic D iffusion R ecommender M odel  (named HDRM). Unlike existing directional diffusion methods based on Euclidean space, the intrinsic non-Euclidean structure of hyperbolic space makes it particularly well-adapted for handling anisotropic diffusion processes. In particular, we begin by constructing a geometrically latent space grounded in hyperbolic geometry, incorporating interpretability measures to define the latent anisotropic diffusion processes. Subsequently, we propose a novel hyperbolic latent diffusion process specifically tailored for users and items. Drawing upon the natural geometric attributes of hyperbolic spaces, we restrict both radial and angular components to facilitate directional diffusion propagation, thereby ensuring the preservation of the original topological structure in user-item interaction graphs. Extensive experiments on three benchmark datasets demonstrate the effectiveness of HDRM. Our code is available at https://github.com/yuanmeng-cpu/HDRM.}
}


@inproceedings{DBLP:conf/www/RaoSJ0025,
	author = {Xuan Rao and
                  Shuo Shang and
                  Renhe Jiang and
                  Peng Han and
                  Lisi Chen},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Seed: Bridging Sequence and Diffusion Models for Road Trajectory Generation},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {2007--2017},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714951},
	doi = {10.1145/3696410.3714951},
	timestamp = {Fri, 09 May 2025 20:28:09 +0200},
	biburl = {https://dblp.org/rec/conf/www/RaoSJ0025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Road trajectory generation creates synthetic yet realistic trajectories to tackle data collection costs and privacy concerns. Existing methods generate a trajectory either segment-by-segment using sequence models or holistically in one step using diffusion models. Sequence-based models have good regularity and consistency (i.e., resemble the input trajectories) but lack diversity, while diffusion-based models enhance diversity but sacrifice regularity and consistency. To combine the merits of existing methods, we propose  Seed , by bridging  <u>se</u> quenc <u>e</u>  and  <u>d</u> iffusion models for trajectory generation. In particular, Seed adopts a  conditional diffusion structure , where a Transformer models the movement of each trajectory along the road segments, and conditioned on the Transformer's output, a diffusion model recovers the next road segment from random noise. The rationale is that the Transformer captures sequential patterns for regularity and consistency, while the diffusion model introduces diversity by recovering from noise. We use a trajectory reconstruction task to train Seed, and design a curriculum learning strategy to accelerate convergence. We compare Seed with 8 state-of-the-art trajectory generation methods on 3 datasets, and the results show that Seed improves the best-performing baseline by over 50%.}
}


@inproceedings{DBLP:conf/www/ZhaoYLZG025,
	author = {Chu Zhao and
                  Enneng Yang and
                  Yuliang Liang and
                  Jianzhe Zhao and
                  Guibing Guo and
                  Xingwei Wang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Distributionally Robust Graph Out-of-Distribution Recommendation via
                  Diffusion Model},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {2018--2031},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714848},
	doi = {10.1145/3696410.3714848},
	timestamp = {Fri, 09 May 2025 20:28:09 +0200},
	biburl = {https://dblp.org/rec/conf/www/ZhaoYLZG025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The distributionally robust optimization (DRO)-based graph neural network methods improve recommendation systems' out-of-distribution (OOD) generalization by optimizing the model's worst-case performance. However, these studies fail to consider the impact of noisy samples in the training data, which results in diminished generalization capabilities and lower accuracy. Through experimental and theoretical analysis, this paper reveals that current DRO-based graph recommendation methods assign greater weight to noise distribution, leading to model parameter learning being dominated by it. When the model overly focuses on fitting noise samples in the training data, it may learn irrelevant or meaningless features that cannot be generalized to OOD data. To address this challenge, we design a  D istributionally  R obust  G raph model for  O OD recommendation (DRGO). Specifically, our method first employs a simple and effective diffusion paradigm to alleviate the noisy effect in the latent space. Additionally, an entropy regularization term is introduced in the DRO objective function to avoid extreme sample weights in the worst-case distribution. Finally, we provide a theoretical proof of the generalization error bound of DRGO as well as a theoretical analysis of how our approach mitigates noisy sample effects, which helps to better understand the proposed framework from a theoretical perspective. We conduct extensive experiments on four datasets to evaluate the effectiveness of our framework against three typical distribution shifts, and the results demonstrate its superiority in both independently and identically distributed distributions (IID) and OOD.}
}


@inproceedings{DBLP:conf/www/0001YXLXS025,
	author = {Yunyi Zhang and
                  Ruozhen Yang and
                  Xueqiang Xu and
                  Rui Li and
                  Jinfeng Xiao and
                  Jiaming Shen and
                  Jiawei Han},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {TELEClass: Taxonomy Enrichment and LLM-Enhanced Hierarchical Text
                  Classification with Minimal Supervision},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {2032--2042},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714940},
	doi = {10.1145/3696410.3714940},
	timestamp = {Fri, 09 May 2025 20:28:09 +0200},
	biburl = {https://dblp.org/rec/conf/www/0001YXLXS025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Hierarchical text classification aims to categorize each document into a set of classes in a label taxonomy, which is a fundamental web text mining task with broad applications such as web content analysis and semantic indexing. Most earlier works focus on fully or semi-supervised methods that require a large amount of human annotated data which is costly and time-consuming to acquire. To alleviate human efforts, in this paper, we work on hierarchical text classification with a minimal amount of supervision: using the sole class name of each node as the only supervision. Recently, large language models (LLM) have shown competitive performance on various tasks through zero-shot prompting, but this method performs poorly in the hierarchical setting because it is ineffective to include the large and structured label space in a prompt. On the other hand, previous weakly-supervised hierarchical text classification methods only utilize the raw taxonomy skeleton and ignore the rich information hidden in the text corpus that can serve as additional class-indicative features. To tackle the above challenges, we propose TELEClass, <u>T</u>axonomy <u>E</u>nrichment and <u>L</u>LM-<u>E</u>nhanced weakly-supervised hierarchical text <u>Class</u>ification, which combines the general knowledge of LLMs and task-specific features mined from an unlabeled corpus. TELEClass automatically enriches the raw taxonomy with class-indicative features for better label space understanding and utilizes novel LLM-based data annotation and generation methods specifically tailored for the hierarchical setting. Experiments show that TELEClass can significantly outperform previous baselines while achieving comparable performance to zero-shot prompting of LLMs with drastically less inference cost.}
}


@inproceedings{DBLP:conf/www/Liu0ZL025,
	author = {Haibo Liu and
                  Chen Gong and
                  Zhenzhe Zheng and
                  Shengzhong Liu and
                  Fan Wu},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Enabling Real-Time Inference in Online Continual Learning via Device-Cloud
                  Collaboration},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {2043--2052},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714796},
	doi = {10.1145/3696410.3714796},
	timestamp = {Fri, 09 May 2025 20:28:09 +0200},
	biburl = {https://dblp.org/rec/conf/www/Liu0ZL025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Online continual learning (CL) is becoming a mainstream paradigm to learn incrementally from task streams without forgetting previously learned knowledge. However, the current online CL primarily focuses on learning performance, such as avoiding catastrophic forgetting, neglecting the critical demands of system performance, such as real-time inference. As a result, the performance of real-time inference in online CL degrades significantly due to frequent data distribution variations and time-consuming model adaptation. In this work, we propose ELITE, an online CL framework with device-cloud collaboration, to realize on-device real-time inference on time-varying task streams with performance guarantee. To realize on-device real-time inference in online CL, ELITE features a new design of the model zoo comprising various pre-trained models with the assistance of the cloud, and proposes a task-oriented on-device model selection to quickly retrieve the best-fit models instead of performing time-consuming model retraining. To prevent performance degradation on new tasks not available in the cloud, we introduces a latency-aware on-device model fine-tuning strategy to adapt to new tasks with an accuracy-latency trade-off, and dynamically updates the model zoo to enhance ELITE. Extensive evaluations on five real-world datasets have been conducted, and the results demonstrate that ELITE consistently outperforms the state-of-art solutions, improving the accuracy by 16.3% on average and reducing the response latency by up to 1.98 times.}
}


@inproceedings{DBLP:conf/www/Wang0BCJLLL25,
	author = {Xutong Wang and
                  Yun Feng and
                  Bingsheng Bi and
                  Yaqin Cao and
                  Ze Jin and
                  Xinyu Liu and
                  Yuling Liu and
                  Yunpeng Li},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Not All Benignware Are Alike: Enhancing Clean-Label Attacks on Malware
                  Classifiers},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {2053--2063},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714552},
	doi = {10.1145/3696410.3714552},
	timestamp = {Fri, 09 May 2025 20:28:09 +0200},
	biburl = {https://dblp.org/rec/conf/www/Wang0BCJLLL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Machine Learning (ML) based malware classifiers are vulnerable to exploitation during the training phase due to the necessity of regular retraining with samples collected from the wild. Recent studies have highlighted the efficacy of backdoor attacks in the malware domain, where attackers can manipulate the model during training by injecting samples embedded with specific triggers, causing the model to establish an association between the trigger and a designated class, thereby achieving evasion of detection. While research on backdoor attacks has been extensively explored in the field of computer vision, it has been largely overlooked in the malware domain. Unlike in the computer vision domain, the threat model in the malware domain typically restricts attackers to employing clean-label attacks (i.e., attackers do not have control over the labeling of poisoned data). However, clean-label attack methods are generally less effective compared to those that involve embedding triggers and altering sample labels to the target class (called corrupted-label attacks). To address this limitation, we propose a simple yet effective method that involves  P oisoning  M alware- S imilar  B enignware  (PMSB)  instead of random selection, thereby approximating the scenario of corrupted-label attacks and enhancing the effectiveness of clean-label attacks. Additionally, we introduce three similarity measurement methods based on feature-based distance, distribution-based distance, and contribution-based difference to select malware-similar benignware. Comprehensive evaluations across three different trigger types and three datasets demonstrate the superiority and general applicability of PMSB.}
}


@inproceedings{DBLP:conf/www/Yu0Y00T25,
	author = {Qi Yu and
                  Zhichen Zeng and
                  Yuchen Yan and
                  Lei Ying and
                  R. Srikant and
                  Hanghang Tong},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Joint Optimal Transport and Embedding for Network Alignment},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {2064--2075},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714937},
	doi = {10.1145/3696410.3714937},
	timestamp = {Fri, 09 May 2025 20:28:09 +0200},
	biburl = {https://dblp.org/rec/conf/www/Yu0Y00T25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Network alignment, which aims to find node correspondence across different networks, is the cornerstone of various downstream multi-network and Web mining tasks. Most of the embedding-based methods indirectly model cross-network node relationships by contrasting positive and negative node pairs sampled from hand-crafted strategies, which are vulnerable to graph noises and lead to potential misalignment of nodes. Another line of work based on the optimal transport (OT) theory directly models cross-network node relationships and generates noise-reduced alignments. However, OT methods heavily rely on fixed, pre-defined cost functions that prohibit end-to-end training and are hard to generalize. In this paper, we aim to unify the embedding and OT-based methods in a mutually beneficial manner and propose a joint optimal transport and embedding framework for network alignment named JOENA. For one thing (OT for embedding), through a simple yet effective transformation, the noise-reduced OT mapping serves as an adaptive sampling strategy directly modeling all cross-network node pairs for robust embedding learning. For another (embedding for OT), on top of the learned embeddings, the OT cost can be gradually trained in an end-to-end fashion, which further enhances the alignment quality. With a unified objective, the mutual benefits of both methods can be achieved by an alternating optimization schema with guaranteed convergence. Extensive experiments on real-world networks validate the effectiveness and scalability of JOENA, achieving up to 16% improvement in MRR and 20 times speedup compared with the state-of-the-art alignment methods.}
}


@inproceedings{DBLP:conf/www/0004MGZWZZY25,
	author = {Shenghao Yang and
                  Weizhi Ma and
                  Zhiqiang Guo and
                  Min Zhang and
                  Haiyang Wu and
                  Junjie Zhai and
                  Chunhui Zhang and
                  Yuekui Yang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Explainable Multi-Modality Alignment for Transferable Recommendation},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {2076--2084},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714733},
	doi = {10.1145/3696410.3714733},
	timestamp = {Fri, 09 May 2025 20:28:09 +0200},
	biburl = {https://dblp.org/rec/conf/www/0004MGZWZZY25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the development of multi-modal modeling techniques, recent sequential recommender systems enhance transferability by incorporating cross-domain universal multi-modal data, e.g., text and image. Existing methods typically adopt pairwise alignment to alleviate the gap between modalities. However, this alignment paradigm has limitations on  explainability, consistency,  and  expansibility,  resulting in suboptimal performance. This paper proposes a novel  E xplainable multi-modality  A lignment method for transferable  Rec  ommender systems, i.e.,  EARec.  Specifically, we design a two-stage framework to achieve explainable modality alignment in the source domain and recommendation based on aligned modality representations in the target domain. In the first stage, we adopt a generative task to align various modalities in parallel to a shared anchor with explainable meaning. All modalities share the same anchor to ensure consistent direction. Additionally, we treat behavior as an independent modality to integrate task-specific information into the alignment framework. In the second stage, we compose multiple item modality representation models trained in the first stage to obtain a unified model capable of understanding various modalities simultaneously, thereby providing high-quality item modality representations for recommendations in the target domain. Benefiting from the approach of parallel modality alignment followed by model composition, the framework shows flexibility in expanding new modalities. Experimental results on multiple public datasets demonstrate the superiority of EARec over baselines, and further analyses indicate the explainability and expansibility of the proposed alignment method.}
}


@inproceedings{DBLP:conf/www/ZhangXFLYLL25,
	author = {Baolei Zhang and
                  Haoran Xin and
                  Minghong Fang and
                  Zhuqing Liu and
                  Biao Yi and
                  Tong Li and
                  Zheli Liu},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Traceback of Poisoning Attacks to Retrieval-Augmented Generation},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {2085--2097},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714756},
	doi = {10.1145/3696410.3714756},
	timestamp = {Tue, 10 Jun 2025 16:57:47 +0200},
	biburl = {https://dblp.org/rec/conf/www/ZhangXFLYLL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Large language models (LLMs) integrated with retrieval-augmented generation (RAG) systems improve accuracy by leveraging external knowledge sources. However, recent research has revealed RAG's susceptibility to poisoning attacks, where the attacker injects poisoned texts into the knowledge database, leading to attacker-desired responses. Existing defenses, which predominantly focus on inference-time mitigation, have proven insufficient against sophisticated attacks. In this paper, we introduce RAGForensics, the first traceback system for RAG, designed to identify poisoned texts within the knowledge database that are responsible for the attacks. RAGForensics operates iteratively, first retrieving a subset of texts from the database and then utilizing a specially crafted prompt to guide an LLM in detecting potential poisoning texts. Empirical evaluations across multiple datasets demonstrate the effectiveness of RAGForensics against state-of-the-art poisoning attacks. This work pioneers the traceback of poisoned texts in RAG systems, providing a practical and promising defense mechanism to enhance their security.}
}


@inproceedings{DBLP:conf/www/LuoSYF025,
	author = {Jiayi Luo and
                  Qingyun Sun and
                  Haonan Yuan and
                  Xingcheng Fu and
                  Jianxin Li},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Robust Graph Learning Against Adversarial Evasion Attacks via Prior-Free
                  Diffusion-Based Structure Purification},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {2098--2110},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714815},
	doi = {10.1145/3696410.3714815},
	timestamp = {Fri, 09 May 2025 20:28:09 +0200},
	biburl = {https://dblp.org/rec/conf/www/LuoSYF025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Adversarial evasion attacks pose significant threats to graph learning, with lines of studies that have improved the robustness of Graph Neural Networks (GNNs). However, existing works rely on priors about clean graphs or attacking strategies, which are often heuristic and inconsistent. To achieve robust graph learning over different types of evasion attacks and diverse datasets, we investigate this problem from a prior-free structure purification perspective. Specifically, we propose a novel Diffusion-based Structure Purification framework named DiffSP, which creatively incorporates the graph diffusion model to learn intrinsic distributions of clean graphs and purify the perturbed structures by removing adversaries under the direction of the captured predictive patterns without relying on priors. DiffSP is divided into the forward diffusion process and the reverse denoising process, during which structure purification is achieved. To avoid valuable information loss during the forward process, we propose an LID-driven non-isotropic diffusion mechanism to selectively inject noise anisotropically. To promote semantic alignment between the clean graph and the purified graph generated during the reverse process, we reduce the generation uncertainty by the proposed graph transfer entropy guided denoising mechanism. Extensive experiments demonstrate the superior robustness of DiffSP against evasion attacks.}
}


@inproceedings{DBLP:conf/www/GaoTSJ025,
	author = {Jianling Gao and
                  Chongyang Tao and
                  Zhenchao Sun and
                  Xiya Jiang and
                  Shuai Ma},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Semi-Supervised Anomaly Detection through Denoising-Aware Contrastive
                  Distance Learning},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {2111--2119},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714626},
	doi = {10.1145/3696410.3714626},
	timestamp = {Fri, 09 May 2025 20:28:09 +0200},
	biburl = {https://dblp.org/rec/conf/www/GaoTSJ025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Semi-supervised anomaly detection (AD) has garnered growing attention due to its ability to effectively leverage limited labeled data to identify anomalies. However, current methods often impose artificial constraints on the proportion of unlabeled anomalies in the training set, thereby impeding the effective training of models for anomaly detection in real-world scenarios where several anomalies may be present in the unlabeled dataset. Additionally, existing methods often struggle to effectively exploit and model the complex relationships between data instances, which is critical for learning more discriminative features and accurate distance measures. Distance-based methods, in particular, typically rely on Euclidean distance metric, which lacks the flexibility to capture complex correlations across different data dimensions. To address the above challenges, we propose CAD, a denoising-aware <u>C</u>ontrastive distance learning framework for semi-supervised <u>AD</u>. It introduces a contrastive training objective to facilitate the learning of distinctive representations by contrasting the average distance between anomalies and unlabeled samples. To fully exploit the information from the unlabeled data meanwhile mitigate the effects of noise, we incorporate a two-stage anomaly denoising and expansion strategy to refine the dataset by identifying high-confidence samples from the unlabeled set. Furthermore, we employ a parameterized bilinear tensor distance layer to learn a customized distance metric, enabling the model to capture intricate relationships among data points. Extensive experiments on 10 real-world datasets demonstrate that CAD significantly outperforms existing semi-supervised AD models. Code available at https://github.com/CADrepo/CAD.}
}


@inproceedings{DBLP:conf/www/MaiZ025,
	author = {Sijie Mai and
                  Ying Zeng and
                  Haifeng Hu},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Learning by Comparing: Boosting Multimodal Affective Computing through
                  Ordinal Learning},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {2120--2134},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714841},
	doi = {10.1145/3696410.3714841},
	timestamp = {Fri, 09 May 2025 20:28:09 +0200},
	biburl = {https://dblp.org/rec/conf/www/MaiZ025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Previous studies on multimodal affective computing primarily focus on approximating predictions to annotated labels, often neglecting the ordinal nature of affective states. In this paper, we address this issue by exploring ordinal learning, and a Multimodal Ordinal Affective Computing (MOAC) framework is designed to enhance the understanding of the nature of affective concepts. Specifically, we propose coarse-grained label-level ordinal learning that prompts the model to  learn to compare  in the label space, encouraging higher predictive values for samples annotated with larger labels over those with smaller labels. Moreover, a regularization loss is proposed to prevent the output distributions from deviating significantly from the annotated label distributions. Fine-grained feature-level ordinal learning is then performed via the feature difference operation and the neutral embedding. The former compares samples in the feature space, calculating the difference between features of different samples to generate 'new' features for a more robust training. The latter seeks to reduce the difficulty of prediction by estimating the difference between the target multimodal representations and a neutral reference. We first demonstrate MOAC in multimodal sentiment analysis, which is a regression task that aligns well with the function of ordinal learning. Then we extend MOAC to classification tasks including multimodal humor detection and sarcasm detection to evaluate its generalizability. Experiments suggest that MOAC outperforms state-of-the-art methods.}
}


@inproceedings{DBLP:conf/www/LiuW0Z025,
	author = {Hong Liu and
                  Zhe Wang and
                  Kewen Wang and
                  Xiaowang Zhang and
                  Zhiyong Feng},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Transfer Rule Learning over Large Knowledge Graphs},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {2135--2143},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714597},
	doi = {10.1145/3696410.3714597},
	timestamp = {Fri, 09 May 2025 20:28:09 +0200},
	biburl = {https://dblp.org/rec/conf/www/LiuW0Z025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Logical rules have been widely used for expressing schema knowledge in various practical applications. It is infeasible to handcraft rules from large knowledge graphs (KGs) and thus many methods have been proposed for learning rules automatically from KGs. However, it is largely ignored how to extract rules in a (target) KG from rules that already exist in some other (source) KGs. In this paper, we propose a framework for KG rule learning based on transfer learning. A major challenge for establishing such a framework is that a suitable alignment mechanism is required for mapping certain subgraph structures between predicates in the source KG and the target KG. Hence, our framework provides a new method for predicate mapping based on graph-structural similarity. The proposed framework can be used as a standalone rule learner but more importantly, it paves a new way for enhancing the state-of-the-art rule learners for large KGs. Extensive experiments are conducted to evaluate the new approach to rule learning, which shows that rules in smaller KGs can be effectively transferred to a large KG.}
}


@inproceedings{DBLP:conf/www/WangHZHW025,
	author = {Shuzheng Wang and
                  Yue Huang and
                  Wenqin Zhang and
                  Yuming Huang and
                  Xuechao Wang and
                  Jing Tang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Private Order Flows and Builder Bidding Dynamics: The Road to Monopoly
                  in Ethereum's Block Building Market},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {2144--2157},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714754},
	doi = {10.1145/3696410.3714754},
	timestamp = {Fri, 09 May 2025 20:28:09 +0200},
	biburl = {https://dblp.org/rec/conf/www/WangHZHW025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Ethereum, as a representative of Web3, adopts a novel framework called Proposer Builder Separation (PBS) to prevent the centralization of block profits in the hands of institutional Ethereum stakers. Introducing builders to generate blocks based on public transactions, PBS aims to ensure that block profits are distributed among all stakers. Through the auction among builders, only one will win the block in each slot. Ideally, the equilibrium strategy of builders under public information would lead them to bid all block profits. However, builders are now capable of extracting profits from private order flows. In this paper, we explore the effect of PBS with private order flows. Specifically, we propose the asymmetry auction model of MEV-Boost auction. Moreover, we conduct empirical study on Ethereum blocks from January 2023 to May 2024. Our analysis indicates that private order flows contribute to 54.59% of the block value, indicating that different builders will build blocks with different valuations. Interestingly, we find that builders with more private order flows (i.e., higher block valuations) are more likely to win the block, while retain larger proportion of profits. In return, such builders will further attract more private order flows, resulting in a monopolistic market gradually. Our findings reveal that PBS in current stage is unable to balance the profit distribution, which just transits the centralization of block profits from institutional stakers to the monopolistic builder.}
}


@inproceedings{DBLP:conf/www/HuangCZWCWC025,
	author = {Xuanwen Huang and
                  Wei Chow and
                  Yize Zhu and
                  Yang Wang and
                  Ziwei Chai and
                  Chunping Wang and
                  Lei Chen and
                  Yang Yang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Enhancing Cross-domain Link Prediction via Evolution Process Modeling},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {2158--2171},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714792},
	doi = {10.1145/3696410.3714792},
	timestamp = {Thu, 01 May 2025 20:27:23 +0200},
	biburl = {https://dblp.org/rec/conf/www/HuangCZWCWC025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper proposes CrossLink, a novel framework for cross-domain link prediction. CrossLink learns the evolution pattern of a specific downstream graph and subsequently makes pattern-specific link predictions. It employs a technique called  conditioned link generation,  which integrates both evolution and structure modeling to perform evolution-specific link prediction. This conditioned link generation is carried out by a transformer-decoder architecture, enabling efficient parallel training and inference. CrossLink is trained on extensive dynamic graphs across diverse domains, encompassing 6 million dynamic edges. Extensive experiments on eight untrained graphs demonstrate that CrossLink achieves state-of-the-art performance in cross-domain link prediction. Compared to advanced baselines under the same settings, CrossLink shows an average improvement of  11.40%  in  Average Precision  across eight graphs. Impressively, it surpasses the fully supervised performance of 8 advanced baselines on 6 untrained graphs. Project Page is https://zjunet.github.io/CrossLink/}
}


@inproceedings{DBLP:conf/www/WuQYJLL0L25,
	author = {Weiheng Wu and
                  Wei Qiao and
                  Wenhao Yan and
                  Bo Jiang and
                  Yuling Liu and
                  Baoxu Liu and
                  Zhigang Lu and
                  Junrong Liu},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Brewing Vodka: Distilling Pure Knowledge for Lightweight Threat Detection
                  in Audit Logs},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {2172--2182},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714563},
	doi = {10.1145/3696410.3714563},
	timestamp = {Fri, 09 May 2025 20:28:09 +0200},
	biburl = {https://dblp.org/rec/conf/www/WuQYJLL0L25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Advanced Persistent Threats (APTs) are continuously evolving, leveraging their stealthiness and persistence to put increasing pressure on current provenance-based Intrusion Detection Systems (IDS). This evolution exposes several critical issues: (1) The dense interaction between malicious and benign nodes within provenance graphs introduces neighbor noise, hindering effective detection; (2) The complex prediction mechanisms of existing APTs detection models lead to the insufficient utilization of prior knowledge embedded in the data; (3) The high computational cost makes detection impractical. To address these challenges, we propose Vodka, a lightweight threat detection system built on a knowledge distillation framework, capable of node-level detection within audit log provenance graphs. Specifically, Vodka applies graph Laplacian regularization to reduce neighbor noise, obtaining smoothed and denoised graph signals. Subsequently, Vodka employs a teacher model based on GNNs to extract knowledge, which is then distilled into a lightweight student model. The student model is designed as a combination of a feature transformation module and a personalized PageRank random walk label propagation module, with the former capturing feature knowledge and the latter learning label and structural knowledge. After distillation, the student model benefits from the knowledge of the teacher model to perform precise threat detection. Finally, Vodka reconstructs attack paths from anomalous nodes, providing insight into the attackers' strategies. We evaluate Vodka through extensive experiments on three public datasets and compare its performance against several state-of-the-art IDS solutions. The results demonstrate that Vodka achieves outstanding detection accuracy across all scenarios.}
}


@inproceedings{DBLP:conf/www/ZhuSWLWPHT25,
	author = {Yun Zhu and
                  Haizhou Shi and
                  Xiaotang Wang and
                  Yongchao Liu and
                  Yaoke Wang and
                  Boci Peng and
                  Chuntao Hong and
                  Siliang Tang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {GraphCLIP: Enhancing Transferability in Graph Foundation Models for
                  Text-Attributed Graphs},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {2183--2197},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714801},
	doi = {10.1145/3696410.3714801},
	timestamp = {Fri, 09 May 2025 20:28:09 +0200},
	biburl = {https://dblp.org/rec/conf/www/ZhuSWLWPHT25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recently, research on Text-Attributed Graphs (TAGs) has gained significant attention due to the prevalence of free-text node features in real-world applications and the advancements in Large Language Models (LLMs) that bolster TAG methodologies. However, current TAG approaches face two primary challenges: (i)  Heavy reliance on label information  and (ii)  Limited cross-domain zero/few-shot transferability . These issues constrain the scaling of both data and model size, owing to high labor costs and scaling laws, complicating the development of graph foundation models with strong transferability. In this work, we propose the GraphCLIP framework to address these challenges by learning <u>graph</u> foundation models with strong <u>c</u>ross-domain zero/few-shot transferabi<u>li</u>ty through a self-supervised contrastive graph-summary <u>p</u>retraining method. Specifically, we generate and curate large-scale graph-summary pair data with the assistance of LLMs, and introduce a novel graph-summary pretraining method, combined with invariant learning, to enhance graph foundation models with strong cross-domain zero-shot transferability. For few-shot learning, we propose a novel graph prompt tuning technique aligned with our pretraining objective to mitigate catastrophic forgetting and minimize learning costs. Extensive experiments show the superiority of GraphCLIP in both zero-shot and few-shot settings, while evaluations across various downstream tasks confirm the versatility of GraphCLIP. Our code is available at: https://github.com/ZhuYun97/GraphCLIP.}
}


@inproceedings{DBLP:conf/www/ZhangZ25,
	author = {Yi Zhang and
                  Yiwen Zhang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {MixRec: Individual and Collective Mixing Empowers Data Augmentation
                  for Recommender Systems},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {2198--2208},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714565},
	doi = {10.1145/3696410.3714565},
	timestamp = {Mon, 05 May 2025 07:55:32 +0200},
	biburl = {https://dblp.org/rec/conf/www/ZhangZ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The core of the general recommender systems lies in learning high-quality embedding representations of users and items to investigate their positional relations in the feature space. Unfortunately, data sparsity caused by difficult-to-access interaction data severely limits the effectiveness of recommender systems. Faced with such a dilemma, various types of self-supervised learning methods have been introduced into recommender systems in an attempt to alleviate the data sparsity through distribution modeling or data augmentation. However, most data augmentation relies on elaborate manual design, which is not only not universal, but the bloated and redundant augmentation process may significantly slow down model training progress. To tackle these limitations, we propose a novel Dual Mixing-based Recommendation Framework (MixRec) to empower data augmentation as we wish. Specifically, we propose individual mixing and collective mixing, respectively. The former aims to provide a new positive sample that is unique to the target (user or item) and to make the pair-wise recommendation loss benefit from it, while the latter aims to portray a new sample that contains group properties in a batch. The two mentioned mixing mechanisms allow for data augmentation with only one parameter that does not need to be set multiple times and can be done in linear time complexity. Besides, we propose the dual-mixing contrastive learning to maximize the utilization of these new-constructed samples to enhance the consistency between pairs of positive samples. Experimental results on four real-world datasets demonstrate the advantages of MixRec in terms of effectiveness, simplicity, efficiency, and scalability.}
}


@inproceedings{DBLP:conf/www/HuangPZLC25,
	author = {Sujia Huang and
                  Yueyang Pi and
                  Tong Zhang and
                  Wenzhe Liu and
                  Zhen Cui},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Boosting Graph Convolution with Disparity-induced Structural Refinement},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {2209--2221},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714786},
	doi = {10.1145/3696410.3714786},
	timestamp = {Tue, 13 May 2025 07:31:04 +0200},
	biburl = {https://dblp.org/rec/conf/www/HuangPZLC25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graph Neural Networks (GNNs) have expressed remarkable capability in processing graph-structured data. Recent studies have found that most GNNs rely on the homophily assumption of graphs, leading to unsatisfactory performance on heterophilous graphs. While certain methods have been developed to address heterophilous links, they lack more precise estimation of high-order relationships between nodes. This could result in the aggregation of excessive interference information during message propagation, thus degrading the representation ability of learned features. In this work, we propose a Disparity-induced Structural Refinement (DSR) method that enables adaptive and selective message propagation in GNN, to enhance representation learning in heterophilous graphs. We theoretically analyze the necessity of structural refinement during message passing grounded in the derivation of error bound for node classification. To this end, we design a disparity score that combines both features and structural information at the node level, reflecting the connectivity degree of hopping neighbor nodes. Based on the disparity score, we can adjust the aggregation of neighbor nodes, thereby mitigating the impact of irrelevant information during message passing. Experimental results demonstrate that our method achieves competitive performance, mostly outperforming advanced methods on both homophilous and heterophilous datasets.}
}


@inproceedings{DBLP:conf/www/ShiGY0CCYVR25,
	author = {Zhengliang Shi and
                  Shen Gao and
                  Lingyong Yan and
                  Yue Feng and
                  Xiuyi Chen and
                  Zhumin Chen and
                  Dawei Yin and
                  Suzan Verberne and
                  Zhaochun Ren},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Tool Learning in the Wild: Empowering Language Models as Automatic
                  Tool Agents},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {2222--2237},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714825},
	doi = {10.1145/3696410.3714825},
	timestamp = {Fri, 09 May 2025 20:28:09 +0200},
	biburl = {https://dblp.org/rec/conf/www/ShiGY0CCYVR25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Augmenting large language models (LLMs) with external tools has emerged as a promising approach to extend their utility, enabling them to solve practical tasks. Previous methods manually parse tool documentation and create in-context demonstrations, transforming tools into structured formats for LLMs to use in their step-by-step reasoning. However, this manual process requires domain expertise and struggles to scale to large toolsets. Additionally, these methods rely heavily on ad-hoc inference techniques or special tokens to integrate free-form LLM generation with tool-calling actions, limiting the LLM's flexibility in handling diverse tool specifications and integrating multiple tools. In this work, we propose AutoTools, a framework that enables LLMs to automate the tool-use workflow. Specifically, the LLM automatically transforms tool documentation into callable functions, verifying syntax and runtime correctness. Then, the LLM integrates these functions into executable programs to solve practical tasks, flexibly grounding tool-use actions into its reasoning processes. Extensive experiments on existing and newly collected, more challenging benchmarks illustrate the superiority of our framework. Inspired by these promising results, we further investigate how to improve the expertise of LLMs, especially open-source LLMs with fewer parameters, within AutoTools. Thus, we propose the AutoTools-Learning approach, training the LLMs with three learning tasks on 34k instances of high-quality synthetic data, including documentation understanding, relevance learning, and function programming. Fine-grained results validate the effectiveness of our overall training approach and each individual task. Our methods are an important step towards the use of LLMs for solving real-world tasks with external tools.}
}


@inproceedings{DBLP:conf/www/HongCWXL0C25,
	author = {Yayao Hong and
                  Liyue Chen and
                  Leye Wang and
                  Xiuhuai Xie and
                  Guofeng Luo and
                  Cheng Wang and
                  Longbiao Chen},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {STKOpt: Automated Spatio-Temporal Knowledge Optimization for Traffic
                  Prediction},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {2238--2249},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714598},
	doi = {10.1145/3696410.3714598},
	timestamp = {Fri, 09 May 2025 20:28:09 +0200},
	biburl = {https://dblp.org/rec/conf/www/HongCWXL0C25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Ubiquitous sensors and mobile devices have spurred the growth of Web-of-Things (WoT) services in smart cities, making accurate spatio-temporal traffic predictions increasingly crucial. Leveraging advances in deep learning, recent Spatio-Temporal Graph Neural Networks (STGNNs) have achieved remarkable results. However, these methods address scenario-specific spatio-temporal heterogeneity by designing model architectures, often overlooking the importance of selecting optimal spatio-temporal knowledge (i.e., model inputs). In this paper, we propose an automated framework for spatio-temporal knowledge optimization to address this challenge. Our framework seamlessly integrates with downstream models, enhancing their performance across various prediction tasks. Specifically, we design a knowledge search space composed of parameters that represent scenario-specific spatio-temporal correlations within data. Additionally, we employ a bandit-based multi-fidelity algorithm for knowledge optimization to solve the constraint of limited resource. Furthermore, we adopt a meta-learner to extract transferable meta-knowledge about optimal knowledge, facilitating efficient exploration of the search space. Extensive experiments on five widely used real-world datasets demonstrate the effectiveness of our proposed framework. To the best of our knowledge, we are the first to automatically optimize spatio-temporal knowledge for spatio-temporal traffic prediction.}
}


@inproceedings{DBLP:conf/www/WangZZZSWTWHPGM25,
	author = {Zixiang Wang and
                  Yinghao Zhu and
                  Huiya Zhao and
                  Xiaochen Zheng and
                  Dehao Sui and
                  Tianlong Wang and
                  Wen Tang and
                  Yasha Wang and
                  Ewen M. Harrison and
                  Chengwei Pan and
                  Junyi Gao and
                  Liantao Ma},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {ColaCare: Enhancing Electronic Health Record Modeling through Large
                  Language Model-Driven Multi-Agent Collaboration},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {2250--2261},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714877},
	doi = {10.1145/3696410.3714877},
	timestamp = {Fri, 09 May 2025 20:28:09 +0200},
	biburl = {https://dblp.org/rec/conf/www/WangZZZSWTWHPGM25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We introduce ColaCare, a framework that enhances Electronic Health Record (EHR) modeling through multi-agent collaboration driven by Large Language Models (LLMs). Our approach seamlessly integrates domain-specific expert models with LLMs to bridge the gap between structured EHR data and text-based reasoning. Inspired by the Multidisciplinary Team (MDT) approach used in clinical settings, ColaCare employs two types of agents: DoctorAgents and a MetaAgent, which collaboratively analyze patient data. Expert models process and generate predictions from numerical EHR data, while LLM agents produce reasoning references and decision-making reports within the MDT-driven collaborative consultation framework. The MetaAgent orchestrates the discussion, facilitating consultations and evidence-based debates among DoctorAgents, simulating diverse expertise in clinical decision-making. We additionally incorporate the Merck Manual of Diagnosis and Therapy (MSD) medical guideline within a retrieval-augmented generation (RAG) module for medical evidence support, addressing the challenge of knowledge currency. Extensive experiments conducted on three EHR datasets demonstrate ColaCare's superior performance in clinical mortality outcome and readmission prediction tasks, underscoring its potential to revolutionize clinical decision support systems and advance personalized precision medicine. All code, case studies and a questionnaire are available at the project website: https://colacare.netlify.app.}
}


@inproceedings{DBLP:conf/www/ChenFDWCWLLZLZL25,
	author = {Xingye Chen and
                  Wei Feng and
                  Zhenbang Du and
                  Weizhen Wang and
                  Yanyin Chen and
                  Haohan Wang and
                  Linkai Liu and
                  Yaoyu Li and
                  Jinyuan Zhao and
                  Yu Li and
                  Zheng Zhang and
                  Jingjing Lv and
                  Junjie Shen and
                  Zhangang Lin and
                  Jingping Shao and
                  Yuanjie Shao and
                  Xinge You and
                  Changxin Gao and
                  Nong Sang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {CTR-Driven Advertising Image Generation with Multimodal Large Language
                  Models},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {2262--2275},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714836},
	doi = {10.1145/3696410.3714836},
	timestamp = {Wed, 23 Apr 2025 16:35:50 +0200},
	biburl = {https://dblp.org/rec/conf/www/ChenFDWCWLLZLZL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In web data, advertising images are crucial for capturing user attention and improving advertising effectiveness. Most existing methods generate background for products primarily focus on the aesthetic quality, which may fail to achieve satisfactory online performance. To address this limitation, we explore the use of Multimodal Large Language Models (MLLMs) for generating advertising images by optimizing for Click-Through Rate (CTR) as the primary objective. Firstly, we build targeted pre-training tasks, and leverage a large-scale e-commerce multimodal dataset to equip MLLMs with initial capabilities for advertising image generation tasks. To further improve the CTR of generated images, we propose a novel reward model to fine-tune pre-trained MLLMs through Reinforcement Learning (RL), which can jointly utilize multimodal features and accurately reflect user click preferences. Meanwhile, a product-centric preference optimization strategy is developed to ensure that the generated background content aligns with the product characteristics after fine-tuning, enhancing the overall relevance and effectiveness of the advertising images. Extensive experiments have demonstrated that our method achieves state-of-the-art performance in both online and offline metrics. Our code and pre-trained models are publicly available at: https://github.com/Chenguoz/CAIG.}
}


@inproceedings{DBLP:conf/www/XuKON25,
	author = {Ziqi Xu and
                  Sevvandi Kandanaarachchi and
                  Cheng Soon Ong and
                  Eirini Ntoutsi},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Fairness Evaluation with Item Response Theory},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {2276--2288},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714883},
	doi = {10.1145/3696410.3714883},
	timestamp = {Fri, 09 May 2025 20:28:09 +0200},
	biburl = {https://dblp.org/rec/conf/www/XuKON25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Item Response Theory (IRT) has been widely used in educational psychometrics to assess student ability, as well as the difficulty and discrimination of test questions. In this context, discrimination specifically refers to how effectively a question distinguishes between students of different ability levels, and it does not carry any connotation related to fairness. In recent years, IRT has been successfully used to evaluate the predictive performance of Machine Learning (ML) models, but this paper marks its first application in fairness evaluation. In this paper, we propose a novel Fair-IRT framework to evaluate a set of predictive models on a set of individuals, while simultaneously eliciting specific parameters, namely, the ability to make fair predictions (a feature of predictive models), as well as the discrimination and difficulty of individuals that affect the prediction results. Furthermore, we conduct a series of experiments to comprehensively understand the implications of these parameters for fairness evaluation. Detailed explanations for item characteristic curves (ICCs) are provided for particular individuals. We propose the flatness of ICCs to disentangle the unfairness between individuals and predictive models. The experiments demonstrate the effectiveness of this framework as a fairness evaluation tool. Two real-world case studies illustrate its potential application in evaluating fairness in both classification and regression tasks.}
}


@inproceedings{DBLP:conf/www/Wei0G0YH25,
	author = {Yongfu Wei and
                  Yan Lin and
                  Hongfan Gao and
                  Ronghui Xu and
                  Sean Bin Yang and
                  Jilin Hu},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Path-LLM: {A} Multi-Modal Path Representation Learning by Aligning
                  and Fusing with Large Language Models},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {2289--2298},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714744},
	doi = {10.1145/3696410.3714744},
	timestamp = {Fri, 09 May 2025 20:28:09 +0200},
	biburl = {https://dblp.org/rec/conf/www/Wei0G0YH25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The advancement of intelligent transportation systems has led to a growing demand for accurate path representations, which are essential for tasks such as travel time estimation, path ranking, and trajectory analysis. However, traditional path representation learning (PRL) methods often focus solely on single-modal road network data, overlooking important physical and regional factors that influence real-world traffic dynamics. To overcome this limitation, we introduce  Path-LLM , a multi-modal path representation learning model that integrates large language models (LLMs) into PRL. Our approach leverages LLMs to interpret both topological and textual data, enabling robust multi-modal path representations. To effectively align and merge these modalities, we propose  TPalign , a contrastive learning-based pretraining strategy that ensures alignment within the embedding space. We then present  TPfusion , a multimodal fusion module that dynamically adjusts the weight of each modality before integration. To further optimize LLM training, we introduce a  Two-stage Overlapping Curriculum Learning  (TOCL) approach, which progressively increases the complexity of the training data. Finally, we evaluate Path-LLM on three real-world datasets across traditional PRL downstream tasks, achieving up to a 61.84% improvement in path ranking performance on the Xi'an dataset. Additionally, Path-LLM demonstrates superior performance in both few-shot and zero-shot learning scenarios. Our code is available at: https://github.com/decisionintelligence/Path-LLM.}
}


@inproceedings{DBLP:conf/www/Chen0000025,
	author = {Kaiyu Chen and
                  Dong Wen and
                  Hanchen Wang and
                  Zhengyi Yang and
                  Wenjie Zhang and
                  Xuemin Lin},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Covering K-Cliques in Billion-Scale Graphs},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {2299--2308},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714897},
	doi = {10.1145/3696410.3714897},
	timestamp = {Fri, 09 May 2025 20:28:09 +0200},
	biburl = {https://dblp.org/rec/conf/www/Chen0000025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The  k -clique structure in graphs has been investigated in various real-world applications, such as community detection in complex networks, functional module discovery in biological networks, and link spam detection in web graphs. Despite extensive research on  k -clique enumeration, the large number of  k -cliques in many graphs poses a challenge for practical application and computation. To address this, we explore the  k -clique τ-cover problem, a generalization of the vertex cover problem. The problem aims to find a small set of vertices that can effectively represent all  k -cliques in the graph. We prove the NP-hardness of finding the minimum  k -clique cover. We propose a hierarchical solution that computes a small cover without enumerating  k -cliques. Extensive experiments on real-world graphs verify the efficiency and effectiveness of our solution.}
}


@inproceedings{DBLP:conf/www/CongCZ025,
	author = {Peizhuang Cong and
                  Qizhi Chen and
                  Haochen Zhao and
                  Tong Yang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {{BATON:} Enhancing Batch-wise Inference Efficiency for Large Language
                  Models via Dynamic Re-batching},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {2309--2318},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714950},
	doi = {10.1145/3696410.3714950},
	timestamp = {Fri, 09 May 2025 20:28:09 +0200},
	biburl = {https://dblp.org/rec/conf/www/CongCZ025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The advanced capabilities of Large Language Models (LLMs) have inspired the development of various interactive web services or applications, such as ChatGPT, which offer query inference services for users. Unlike traditional DNN model, the inference of LLM entails different iterations of forward computation for different queries, which result in efficiency challenges for existing run-to-completion batch-wise inference. Hence, some methods refine batch-wise inference to iteration-level by duplicating all nonlinear layers of LLM. However, this approach not only increases resource usage but also introduces idle computations to the batch due to the prefilling of newly added queries. Therefore, we propose BATON, an efficient batch-wise LLM inference scheme by dynamically adjusting processing batch, which can achieve near-zero idle computations without incurring additional resource consumption. To do so, BATON 1) shapes the vectors involved in the inference of the newly inserted query and processing batch to align dimensions and generates a new attention mask based on vector shaping to ensure inference correctness, which enables query inserting without consuming additional resource; 2) embeds prefilled Keys and Values of the new query into the KV_Cache of the processing batch by leveraging the prefilling and decoding separation mechanism, eliminating idle computations to the batch introduced by the prefilling process of the new query. Experimental results show that compared to the state-of-the-art solution Orca, BATON outperforms improves query processing by up to 1.75x.}
}


@inproceedings{DBLP:conf/www/Shi0ZX0025,
	author = {Zhenning Shi and
                  Dan Zhao and
                  Yijia Zhu and
                  Guorui Xie and
                  Qing Li and
                  Yong Jiang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Helios: Learning and Adaptation of Matching Rules for Continual In-Network
                  Malicious Traffic Detection},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {2319--2329},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714742},
	doi = {10.1145/3696410.3714742},
	timestamp = {Fri, 09 May 2025 20:28:09 +0200},
	biburl = {https://dblp.org/rec/conf/www/Shi0ZX0025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Network Intrusion Detection Systems (NIDS) are critical for web security by identifying and blocking malicious traffic. In-network NIDS leverage programmable switches for high-speed traffic processing. However, they are unable to reconcile the fine-grained classification of known classes and the identification of unseen attacks. Moreover, they lack support for incremental updates. In this paper, we propose Helios, an in-network malicious traffic detection system, for continual adaptation in attack-incremental scenarios. First, we design a novel Supervised Mixture Prototypical Learning (SMPL) method combined with clustering initialization to learn prototypes that encapsulate the knowledge, based on the weighted infinity norm distance. SMPL enables known class classification and unseen attack identification through similarity comparison between prototypes and samples. Then, we design boundary calibration and overlap refinement to transform learned prototypes into priority-guided matching rules, ensuring precise and efficient in-network deployment. Additionally, Helios supports incremental prototype learning and rule updates, achieving low-cost hardware reconfiguration. We implement Helios on a Tofino switch and evaluation on three datasets shows that Helios achieves superior performance in classifying known classes (92%+ in ACC and F1) as well as identifying unseen attacks (62% - 98% in TPR). Helios has also reduced resource consumption and reconfiguration time, demonstrating its scalability and efficiency for real-world deployment.}
}


@inproceedings{DBLP:conf/www/LvCLSLL25,
	author = {Xiangwei Lv and
                  Jingyuan Chen and
                  Mengze Li and
                  Yongduo Sui and
                  Zemin Liu and
                  Beishui Liao},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Grasp the Key Takeaways from Source Domain for Few Shot Graph Domain
                  Adaptation},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {2330--2340},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714743},
	doi = {10.1145/3696410.3714743},
	timestamp = {Tue, 13 May 2025 07:31:04 +0200},
	biburl = {https://dblp.org/rec/conf/www/LvCLSLL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graph Neural Networks (GNNs) have achieved remarkable success in node classification tasks on individual graphs. However, existing GNNs trained within a specific domain (  a.k.a.,  source domain) frequently exhibit unsatisfied performance when transferred to another domain (  a.k.a.,  target domain), due to the domain gap. To tackle this issue, Few Shot Graph Domain Adaptation (FSGDA) is introduced to the node classification task, facilitating knowledge transfer from a fully labeled source graph to a target graph with minimal annotations for each class. An intuitive solution is directly training the GNN with labeled source and target samples together. Nevertheless, there are two issues in this procedure: (1) When the annotations on the target domain used for training are extremely sparse, the GNN performance may significantly be damaged by nodes with the source-domain bias not aligning with the target-domain distribution. (2) Apart from the biased nodes, the low-value nodes among the remaining nodes impede the GNN learning for the core nodes, like the limited target training nodes. To address the above issues, we propose a new method for FSGDA, named GraphInflu, whose core idea is to grasp the key takeaways from the source domain to facilitate the adaptation process. It contains two characteristic modules, including the Supportive Node Selector and the Soft Logic-Inspired Node Reweighting. The former aims to identify the most influential set of source nodes based on their contribution to improving performance on target nodes. The latter further focuses more on the core nodes in the selected influential set, which closely align with the target nodes especially those presenting challenging predictions. Extensive experiments validate the efficacy of GraphInflu by overcoming the current state-of-the-art methods. Our code is available at https://github.com/lvXiangwei/GraphInflu.git.}
}


@inproceedings{DBLP:conf/www/Sun0DZ25,
	author = {Jintao Sun and
                  Hao Fei and
                  Gangyi Ding and
                  Zhedong Zheng},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {From Data Deluge to Data Curation: {A} Filtering-WoRA Paradigm for
                  Efficient Text-based Person Search},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {2341--2351},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714788},
	doi = {10.1145/3696410.3714788},
	timestamp = {Fri, 09 May 2025 20:28:09 +0200},
	biburl = {https://dblp.org/rec/conf/www/Sun0DZ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In text-based person search endeavors, data generation has emerged as a prevailing practice, addressing concerns over privacy preservation and the arduous task of manual annotation. Although the number of synthesized data can be infinite in theory, the scientific conundrum persists that how much generated data optimally fuels subsequent model training. We observe that only a subset of the data in these constructed datasets plays a decisive role. Therefore, we introduce a new Filtering-WoRA paradigm, which contains a filtering algorithm to identify this crucial data subset and WoRA (Weighted Low-Rank Adaptation) learning strategy for light fine-tuning. The filtering algorithm is based on the cross-modality relevance to remove the lots of coarse matching synthesis pairs. As the number of data decreases, we do not need to fine-tune the entire model. Therefore, we propose a WoRA learning strategy to efficiently update a minimal portion of model parameters. WoRA streamlines the learning process, enabling heightened efficiency in extracting knowledge from fewer, yet potent, data instances. Extensive experimentation validates the efficacy of pretraining, where our model achieves advanced and efficient retrieval performance on challenging real-world benchmarks. Notably, on the CUHK-PEDES dataset, we have achieved a competitive mAP of 67.02% while reducing model training time by 19.82%.}
}


@inproceedings{DBLP:conf/www/WeiT25,
	author = {Yiluo Wei and
                  Gareth Tyson},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Virtual Stars, Real Fans: Understanding the VTuber Ecosystem},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {2352--2365},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714803},
	doi = {10.1145/3696410.3714803},
	timestamp = {Fri, 09 May 2025 20:28:09 +0200},
	biburl = {https://dblp.org/rec/conf/www/WeiT25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Livestreaming by VTubers --- animated 2D/3D avatars controlled by real individuals --- have recently garnered substantial global followings and achieved significant monetary success. Despite prior research highlighting the importance of realism in audience engagement, VTubers deliberately conceal their identities, cultivating dedicated fan communities through virtual personas. While previous studies underscore that building a core fan community is essential to a streamer's success, we lack an understanding of the characteristics of viewers of this new type of streamer. Gaining a deeper insight into these viewers is critical for VTubers to enhance audience engagement, foster a more robust fan base, and attract a larger viewership. To address this gap, we conduct a comprehensive analysis of VTuber viewers on Bilibili, a leading livestreaming platform where nearly all VTubers in China stream. By compiling a first-of-its-kind dataset covering 2.7M livestreaming sessions, we investigate the characteristics, engagement patterns, and influence of VTuber viewers. Our research yields several valuable insights, which we then leverage to develop a tool to ''recommend'' future subscribers to VTubers. By reversing the typical approach of recommending streams to viewers, this tool assists VTubers in pinpointing potential future fans to pay more attention to, and thereby effectively growing their fan community.}
}


@inproceedings{DBLP:conf/www/Qian0ZMLD025,
	author = {Hongjin Qian and
                  Zheng Liu and
                  Peitian Zhang and
                  Kelong Mao and
                  Defu Lian and
                  Zhicheng Dou and
                  Tiejun Huang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {MemoRAG: Boosting Long Context Processing with Global Memory-Enhanced
                  Retrieval Augmentation},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {2366--2377},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714805},
	doi = {10.1145/3696410.3714805},
	timestamp = {Fri, 09 May 2025 20:28:09 +0200},
	biburl = {https://dblp.org/rec/conf/www/Qian0ZMLD025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Processing long contexts presents a significant challenge for large language models (LLMs). While recent advancements allow LLMs to handle much longer contexts than before (e.g., 32K or 128K tokens), it is computationally expensive and can still be insufficient for many applications. Retrieval-Augmented Generation (RAG) is considered a promising strategy to address this problem. However, conventional RAG methods face inherent limitations because of two underlying requirements: 1) explicitly stated queries, and 2) well-structured knowledge. These conditions, however, do not hold in general long-context processing tasks. In this work, we propose  MemoRAG , a novel RAG framework empowered by global memory-augmented retrieval. MemoRAG features a dual-system architecture. First, it employs a  light but long-range system  to create a global memory of the long context. Once a task is presented, it generates draft answers, providing useful clues for the retrieval tools to locate relevant information within the long context. Second, it leverages an expensive but expressive system, which generates the final answer based on the retrieved information. Building upon this fundamental framework, we realize the memory module in the form of KV compression, and reinforce its memorization and cluing capacity from the Generation quality's Feedback ( a.k.a.  RLGF). In our experiments, MemoRAG achieves superior performances across a variety of long-context evaluation tasks, not only complex scenarios where traditional RAG methods struggle, but also simpler ones where RAG is typically applied.}
}


@inproceedings{DBLP:conf/www/WenLTPHLH25,
	author = {Zhihua Wen and
                  Zhizhao Liu and
                  Zhiliang Tian and
                  Shilong Pan and
                  Zhen Huang and
                  Dongsheng Li and
                  Minlie Huang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Scenario-independent Uncertainty Estimation for LLM-based Question
                  Answering via Factor Analysis},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {2378--2390},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714880},
	doi = {10.1145/3696410.3714880},
	timestamp = {Tue, 13 May 2025 07:31:04 +0200},
	biburl = {https://dblp.org/rec/conf/www/WenLTPHLH25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Large language models (LLMs) demonstrate significant potential in various applications; however, they are susceptible to generating hallucinations, which can lead to the spread of online misinformation. Existing studies address hallucination detection by (1) employing reference-based methods that consult external resources for verification or (2) utilizing reference-free methods that mainly estimate answer uncertainty based on LLM's internal states. However, reference-based methods incur significant costs and can be infeasible for obtaining reliable external references. Besides, existing uncertainty estimation (UE) methods often overlook the impact of scenario backgrounds inherited from the query's lexical resources, leading to noise in UE. In almost all real-world applications, users care about the uncertainty concerning semantics or facts instead of the query's scenario information. Therefore, we argue that mitigating scenario-related noise and focusing on semantic information can yield a more desirable UE. In this paper, we introduce a plug-and-play scenario-independent framework to enhance unsupervised UE in LLMs by removing scenario-related noise and focusing on semantic information. This framework is compatible with most existing UE methods, as it leverages only the existing UE methods' outputs. Specifically, we design a scenario-specific sampling to paraphrase queries, maintaining their common semantics while diversifying the scenario distribution. Subsequently, to estimate the contribution of the common semantics, we design a factor analysis (FA) model to disentangle the UE score obtained from the given UE method into a combination of multiple latent factors, which represent the contribution of the common semantics and scenario-related noise. By solving the FA model, we decompose the impact of the most significant factor to approximate the uncertainty caused by the common semantics, thus achieving scenario-independent UE. Extensive experiments and analysis across multiple models and datasets demonstrate the effectiveness of our approach.}
}


@inproceedings{DBLP:conf/www/LuZZ25,
	author = {Zenan Lu and
                  Xiaotian Zhou and
                  Zhongzhi Zhang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Fast Estimation and Optimization of Resistance Diameter on Graphs},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {2391--2401},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714820},
	doi = {10.1145/3696410.3714820},
	timestamp = {Fri, 09 May 2025 20:28:09 +0200},
	biburl = {https://dblp.org/rec/conf/www/LuZZ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The resistance diameter of a graph is the maximum resistance distance among all pairs of nodes in the graph, which has found various applications in many scenarios. However, direct computation of resistance diameter involves the pseudoinverse of graph Laplacian, which takes cubic time and is thus infeasible for huge networks with millions of nodes. In this paper, we consider the computation and optimization problems for resistance diameter of a graph. First, we develop a nearly linear time algorithm to approximate the resistance diameter, which has a theoretically guaranteed error. Then, we propose and study an optimization problem of adding a fixed number of edges to a graph, such that the resistance diameter of the resulting graph is minimized. We show that the objective function is non-supermodular but monotone. Moreover, we propose two fast heuristic algorithms to approximately solve this problem. Finally, we conduct extensive experiments on different networks with sizes up to one million nodes, demonstrating the superiority of our algorithms in terms of efficiency and effectiveness.}
}


@inproceedings{DBLP:conf/www/WangZWX025,
	author = {Pengbo Wang and
                  Gongming Zhao and
                  Yuantao Wu and
                  Hongli Xu and
                  Haibo Wang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {X-ClusterLink: An Efficient Cross-Cluster Communication Framework
                  in Multi-Kubernetes Clusters},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {2402--2412},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714846},
	doi = {10.1145/3696410.3714846},
	timestamp = {Fri, 09 May 2025 20:28:09 +0200},
	biburl = {https://dblp.org/rec/conf/www/WangZWX025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Kubernetes is widely adopted by enterprises to enhance service availability for applications such as web services and large-scale model training, due to its advantages in managing containerized applications. As service demands increase, a single Kubernetes cluster often becomes insufficient, leading to the trend of using multiple clusters to improve service scalability. However, achieving efficient cross-cluster communication poses significant challenges due to the need for low latency, high throughput, and strong robustness. Existing methods for cross-cluster communication either employ a centralized control plane, which becomes a communication bottleneck, or use numerous service-bound proxies, leading to increased management complexity and possibly compromised robustness in cross-cluster communication. To address the above challenges, we introduce X-ClusterLink, a framework designed for efficient cross-cluster communication in multi-Kubernetes clusters. X-ClusterLink first employs broker clusters to ensure low-latency cross-cluster synchronization. Then, it aggregates multiple containerized gateways to enhance throughput and leverages eXpress Data Path (XDP) for advanced packet processing, thereby accelerating traffic forwarding. Finally, it incorporates Bucket-Based Consistent ECMP to facilitate seamless failover and enhance robustness. Experimental results demonstrate that X-ClusterLink significantly improves cross-cluster communication efficiency, increasing cross-cluster forwarding bandwidth by 3.1 × compared to existing solutions.}
}


@inproceedings{DBLP:conf/www/GuLZYGX0L25,
	author = {Zheyuan Gu and
                  Chang Liu and
                  Xiyuan Zhang and
                  Chen Yang and
                  Gaopeng Gou and
                  Gang Xiong and
                  Zhen Li and
                  Sijia Li},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {DecETT: Accurate App Fingerprinting Under Encrypted Tunnels via Dual
                  Decouple-based Semantic Enhancement},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {2413--2423},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714643},
	doi = {10.1145/3696410.3714643},
	timestamp = {Fri, 09 May 2025 20:28:09 +0200},
	biburl = {https://dblp.org/rec/conf/www/GuLZYGX0L25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Due to the growing demand for privacy protection, encrypted tunnels have become increasingly popular among mobile app users, which brings new challenges to app fingerprinting (AF)-based network management. Existing methods primarily transfer traditional AF methods to encrypted tunnels directly, ignoring the core obfuscation and re-encapsulation mechanism of encrypted tunnels, thus resulting in unsatisfactory performance. In this paper, we propose DecETT, a dual decouple-based semantic enhancement method for accurate AF under encrypted tunnels. Specifically, DecETT improves AF under encrypted tunnels from two perspectives: app-specific feature enhancement and irrelevant tunnel feature decoupling. Considering the obfuscated app-specific information in encrypted tunnel traffic, DecETT introduces TLS traffic with stronger app-specific information as a semantic anchor to guide and enhance the fingerprint generation for tunnel traffic. Furthermore, to address the app-irrelevant tunnel feature introduced by the re-encapsulation mechanism, DecETT is designed with a dual decouple-based fingerprint enhancement module, which decouples the tunnel feature and app semantic feature from tunnel traffic separately, thereby minimizing the impact of tunnel features on accurate app fingerprint extraction. Evaluation under five prevalent encrypted tunnels indicates that DecETT outperforms state-of-the-art methods in accurate AF under encrypted tunnels, and further demonstrates its superiority under tunnels with more complicated obfuscation. Project page: https://github.com/DecETT/DecETT}
}


@inproceedings{DBLP:conf/www/Shi0ZY025,
	author = {Xiaoyi Shi and
                  Lin He and
                  Jiasheng Zhou and
                  Yifan Yang and
                  Ying Liu},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Miresga: Accelerating Layer-7 Load Balancing with Programmable Switches},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {2424--2434},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714809},
	doi = {10.1145/3696410.3714809},
	timestamp = {Thu, 17 Jul 2025 16:37:43 +0200},
	biburl = {https://dblp.org/rec/conf/www/Shi0ZY025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As online cloud services expand rapidly, layer-7 load balancing has become indispensable for maintaining service availability and performance. The emergence of programmable switches with both high performance and a certain degree of flexibility has made it possible to apply programmable switches to load balancing. Nevertheless, the limited memory capacity and the relatively sluggish speed of table entry insertion and deletion of programmable switches have severely constrained their performance. To this end, we introduce Miresga, a hybrid and high-performance layer-7 load balancing system by co-designing hardware and software. The core idea of Miresga is to maximize the utilization of hardware and software resources by rationally partitioning the layer-7 load balancing task, thereby improving performance. To achieve this, Miresga offloads the elephant flows, which account for the majority of traffic, to programmable switches that excel at packet processing, and Miresga utilizes general-purpose servers with stronger computational capabilities to parse application layer protocols and apply load balancing rules. To alleviate memory pressure on the programmable switch, Miresga employs a back-end agent to handle memory-intensive tasks, working in conjunction with the programmable switch to complete the offloaded tasks. This design leverages the performance advantages of the programmable switch while avoiding bottlenecks caused by its limited memory and table insertion speed. We implement the Miresga prototype with a 3.2 Tbps Intel Tofino switch and general-purpose servers. The evaluation results show that Miresga achieves 3.9× throughput and 0.4× latency compared to software load balancing solutions. Compared to the state-of-the-art design employing programmable switches, Miresga achieves almost the same throughput and latency for delivering large objects and 5.0× throughput and 0.2× latency when transmitting small objects.}
}


@inproceedings{DBLP:conf/www/0007G0PSZ025,
	author = {Saurabh Kumar and
                  Valerio La Gatta and
                  Andrea Pugliese and
                  Andrew Pulver and
                  V. S. Subrahmanian and
                  Jiazhi Zhang and
                  Youzhi Zhang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Reinforcement-Learning Based Covert Social Influence Operations},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {2435--2449},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714729},
	doi = {10.1145/3696410.3714729},
	timestamp = {Fri, 09 May 2025 20:28:09 +0200},
	biburl = {https://dblp.org/rec/conf/www/0007G0PSZ025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {How might reinforcement-learning based covert social influence operations (CSIOs) be run, given that the CSIO agent wants to maximize influence and minimize discoverability of malicious accounts? And how successful can they be, given that both social platform bot detectors and humans might report them to the social platform? To answer these questions, we propose RL_CSIO, a methodology based on reinforcement learning (RL) for running CSIOs. We ran 4 CSIOs with IRB-approval over a period of 5 days using a panel of 225 human subjects. We explore 8 research questions based on the data collected. The results show that RL_CSIO agents successfully trade off influence and discoverability - but in ways that are nuanced and unexpected.}
}


@inproceedings{DBLP:conf/www/Li0W0025,
	author = {Jia{-}Nan Li and
                  Jian Guan and
                  Wei Wu and
                  Zhengtao Yu and
                  Rui Yan},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {2D-TPE: Two-Dimensional Positional Encoding Enhances Table Understanding
                  for Large Language Models},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {2450--2463},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714920},
	doi = {10.1145/3696410.3714920},
	timestamp = {Fri, 09 May 2025 20:28:09 +0200},
	biburl = {https://dblp.org/rec/conf/www/Li0W0025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Tables are ubiquitous across various domains for concisely representing structured information. Empowering large language models (LLMs) to reason over tabular data represents an actively explored direction. However, since typical LLMs only support one-dimensional (1D) inputs, existing methods often flatten the two-dimensional (2D) table structure into a sequence of tokens, which can severely disrupt the spatial relationships and result in an inevitable loss of vital contextual information. In this paper, we first empirically demonstrate the detrimental impact of such flattening operations on the performance of LLMs in capturing the spatial information of tables through two elaborate proxy tasks. Subsequently, we introduce a simple yet effective positional encoding method, termed "2D-TPE" (Two-Dimensional Table Positional Encoding), to address this challenge. 2D-TPE enables each attention head to dynamically select a permutation order of tokens within the context for attending to them, where each permutation represents a distinct traversal mode for the table, such as column-wise or row-wise traversal. 2D-TPE effectively mitigates the risk of losing essential spatial information while preserving computational efficiency, thus better preserving the table structure. Extensive experiments across five benchmarks demonstrate that 2D-TPE outperforms strong baselines, underscoring the importance of preserving the table structure for accurate table comprehension. Comprehensive analysis further reveals the substantially better scalability of 2D-TPE to large tables than baselines.}
}


@inproceedings{DBLP:conf/www/ZhuangDHLFJN25,
	author = {Ziyi Zhuang and
                  Hanwen Du and
                  Hui Han and
                  Youhua Li and
                  Junchen Fu and
                  Joemon M. Jose and
                  Yongxin Ni},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Bridging the Gap: Teacher-Assisted Wasserstein Knowledge Distillation
                  for Efficient Multi-Modal Recommendation},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {2464--2475},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714852},
	doi = {10.1145/3696410.3714852},
	timestamp = {Fri, 09 May 2025 20:28:09 +0200},
	biburl = {https://dblp.org/rec/conf/www/ZhuangDHLFJN25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Multi-modal recommender systems (MMRecs) leverage diverse modalities to deliver personalized recommendations, yet they often struggle with efficiency due to the large size of modality encoders and the complexity of fusing high-dimensional features. To address the efficiency issue, a promising solution is to compress a cumbersome MMRec into a lightweight ID-based Multi-\xa0 Layer Perceptron-based Recommender system (MLPRec) through Knowledge Distillation (KD). Despite effectiveness, we argue that this approach overlooks the significant gap between the complex teacher MMRec and the lightweight, ID-based student MLPRec, which differ significantly in size, architecture, and input modalities, leading to ineffective knowledge transfer and suboptimal student performance. To bridge this gap, we propose TARec, a novel teacher-assisted Wasserstein Knowledge Distillation framework for compressing MMRecs into an efficient MLPRec. TARec introduces: (i) a two-staged KD process using an intermediate Teacher Assistant (TA) model to bridge the gap between teacher and student, facilitating smoother knowledge transfer; (ii) logit-level KD using the Wasserstein Distance as metric, replacing the conventional KL divergence to ensure stable gradient flow even with significant teacher-student gaps; and (iii) \xa0 embedding-level contrastive KD to further distill high-quality embedding-level knowledge from teacher. Extensive experiments on real-world datasets verify the effectiveness of TARec, demonstrating that TARec significantly outperforms the state-of-the-art MMRecs while reducing computational costs. Our code is available at: https://github.com/Suehn/TARec.git.}
}


@inproceedings{DBLP:conf/www/YangAWCW25,
	author = {Ruohan Yang and
                  Muhammad Asif Ali and
                  Huan Wang and
                  Junyang Chen and
                  Di Wang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {{LUSTER:} Link Prediction Utilizing Shared-Latent Space Representation
                  in Multi-Layer Networks},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {2476--2487},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714631},
	doi = {10.1145/3696410.3714631},
	timestamp = {Fri, 09 May 2025 20:28:09 +0200},
	biburl = {https://dblp.org/rec/conf/www/YangAWCW25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Link prediction in multi-layer networks is a longstanding issue that predicts missing links based on the observed structures across all layers. Existing link prediction methods in multi-layer network typically merge the multi-layer network into a single-layer network and/or perform explicit calculations using intra-layer and inter-layer similarity metrics. However, these approaches often overlook the role of coupling in multi-layer networks, specifically the shared information and latent relationships between layers, which in turn limits prediction performance. This calls the need for methods that can extract representations in a shared-latent space to enhance inter-layer information sharing and prediction performance. In this paper, we propose a novel end-to-end framework namely:  <u>L</u> ink prediction  <u>U</u> tilizing  <u>S</u> hared-la <u>T</u> ent spac <u>E</u> <u>R</u> epresentation (LUSTER) in multi-layer networks. LUSTER consists of four key modules: the representation extractor, the latent space learner, the complementary enhancer, and the link predictor. The representation extractor focuses on learning the intra-layer representations of each layer, capturing the data characteristics within the layer. The latent space learner extracts representations from the shared-latent space across different network layers through adversarial training. The complementary enhancer combines the intra-layer representations and the shared-latent space representations through orthogonal fusion, providing comprehensive information. Finally, the link predictor uses the enhanced representations to predict missing links. Extensive experimental analyses demonstrate that LUSTER outperforms state-of-the-art methods for link prediction in multi-layer networks, improving the AUC metric by up to 15.87%.}
}


@inproceedings{DBLP:conf/www/ZhangXCF25,
	author = {Jiayun Zhang and
                  Junshen Xu and
                  Bugra Can and
                  Yi Fan},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {{REACT:} Residual-Adaptive Contextual Tuning for Fast Model Adaptation
                  in Threat Detection},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {2488--2499},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714577},
	doi = {10.1145/3696410.3714577},
	timestamp = {Fri, 09 May 2025 20:28:09 +0200},
	biburl = {https://dblp.org/rec/conf/www/ZhangXCF25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Web and mobile systems show constant distribution shifts due to the evolvement of services, users, and threats, severely degrading the performance of threat detection models trained on prior distributions. Fast model adaptation with minimal new data is essential for maintaining reliable security measures. A key challenge in this context is the lack of ground truth, which undermines the ability of existing solutions to align classes across shifted distributions. Moreover, the limited new data often fails to represent the underlying distribution, providing sparse and potentially noisy information for adaptation. In this paper, we propose REACT, a novel framework that adapts the model using a few unlabeled data and contextual insights. We leverage the inherent data imbalance in threat detection and meta-train weights on diverse unlabeled subsets to generalize common patterns across distributions, eliminating the reliance on labels for alignment. REACT decomposes a neural network into two complementary components: meta weights as a shared foundation of general knowledge, and residual adaptive weights as adjustments for specific shifts. To compensate for the limited availability of new data, REACT trains a hypernetwork to predict adaptive weights based on data and contextual information, enabling knowledge sharing across distributions. The meta weights and the hypernetwork are updated alternately, maximizing both generalization and adaptability. Extensive experiments across multiple datasets and models demonstrate that REACT improves AUROC by 14.85% over models without adaptation, outperforming the state-of-the-art.}
}


@inproceedings{DBLP:conf/www/DuZCSJ00025,
	author = {Linkang Du and
                  Zheng Zhu and
                  Min Chen and
                  Zhou Su and
                  Shouling Ji and
                  Peng Cheng and
                  Jiming Chen and
                  Zhikun Zhang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {ArtistAuditor: Auditing Artist Style Pirate in Text-to-Image Generation
                  Models},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {2500--2513},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714602},
	doi = {10.1145/3696410.3714602},
	timestamp = {Fri, 09 May 2025 20:28:09 +0200},
	biburl = {https://dblp.org/rec/conf/www/DuZCSJ00025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Text-to-image models based on diffusion processes, such as DALL-E, Stable Diffusion, and Midjourney, are capable of transforming texts into detailed images and have widespread applications in art and design. As such, amateur users can easily imitate professional-level paintings by collecting an artist's work and fine-tuning the model, leading to concerns about artworks' copyright infringement. To tackle these issues, previous studies either add visually imperceptible perturbation to the artwork to change its underlying styles (perturbation-based methods) or embed post-training detectable watermarks in the artwork (watermark-based methods). However, when the artwork or the model has been published online, i.e., modification to the original artwork or model retraining is not feasible, these strategies might not be viable. To this end, we propose a novel method for data-use auditing in the text-to-image generation model. The general idea of ArtistAuditor is to identify if a suspicious model has been finetuned using the artworks of specific artists by analyzing the features related to the style. Concretely, ArtistAuditor employs a style extractor to obtain the multi-granularity style representations and treats artworks as samplings of an artist's style. Then, ArtistAuditor queries a trained discriminator to gain the auditing decisions. The experimental results on six combinations of models and datasets show that ArtistAuditor can achieve high AUC values (> 0.937). By studying ArtistAuditor's transferability and core modules, we provide valuable insights into the practical implementation. Finally, we demonstrate the effectiveness of ArtistAuditor in real-world cases by an online platform Scenario. ArtistAuditor is open-sourced at https://github.com/Jozenn/ArtistAuditor.}
}


@inproceedings{DBLP:conf/www/HeX0ZKS25,
	author = {Yunjie He and
                  Bo Xiong and
                  Daniel Hern{\'{a}}ndez and
                  Yuqicheng Zhu and
                  Evgeny Kharlamov and
                  Steffen Staab},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {{DAGE:} {DAG} Query Answering via Relational Combinator with Logical
                  Constraints},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {2514--2529},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714677},
	doi = {10.1145/3696410.3714677},
	timestamp = {Thu, 01 May 2025 20:27:23 +0200},
	biburl = {https://dblp.org/rec/conf/www/HeX0ZKS25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Predicting answers to queries over knowledge graphs is called a complex reasoning task because answering a query requires subdividing it into subqueries. Existing query embedding methods use this decomposition to compute the embedding of a query as the combination of the embedding of the subqueries. This requirement limits the answerable queries to queries having a single free variable and being decomposable, which are called tree-form queries and correspond to the SROI -  description logic. In this paper, we define a more general set of queries, called DAG queries and formulated in the ALCOIR description logic, propose a query embedding method for them, called DAGE, and a new benchmark to evaluate query embeddings on them. Given the computational graph of a DAG query, DAGE combines the possibly multiple paths between two nodes into a single path with a trainable operator that represents the intersection of relations and learns DAG-DL concepts from tautologies. We implement DAGE on top of existing query embedding methods, and we empirically measure the improvement of our method over the results of vanilla methods evaluated in tree-form queries that approximate the DAG queries of our proposed benchmark.}
}


@inproceedings{DBLP:conf/www/0001LLL025,
	author = {Mingyang Zhou and
                  Gang Liu and
                  Kezhong Lu and
                  Hao Liao and
                  Rui Mao},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Highly-efficient Minimization of Network Connectivity in Large-scale
                  Graphs},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {2530--2539},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714806},
	doi = {10.1145/3696410.3714806},
	timestamp = {Fri, 09 May 2025 20:28:09 +0200},
	biburl = {https://dblp.org/rec/conf/www/0001LLL025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Network connectivity minimization is a fundamental problem in controlling the spread of viruses in the Internet and facilitating information propagation in online social networks. The problem aims to identify a budget number of key nodes whose removal would minimize the connectivity of a network. However, the existing solutions heavily rely on the number of edges, making it challenging to handle large and densely connected social networks. In this study, we present a fast algorithm that is independent of the number of edges. To achieve this, we first introduce a surrogate matrix that approximates the residual adjacency matrix with arbitrary small predefined error. We then devise an efficient approach for inferring  k  influential nodes by optimizing the eigenvalues of the surrogate matrix. Remarkably, the algorithm has a small time complexity of O(knr 3 ), with  r  being a small tunable number. Our algorithm thereby maintains a linear scalability in terms of the number of nodes and is unaffected by the number of edges. Hence, it has the capability to efficiently handle large and dense social networks. At last, we evaluate its performance against state-of-the-art techniques using diverse real-world datasets. The experimental results demonstrate the superiority of our proposed method in terms of both solution quality and computational efficiency.}
}


@inproceedings{DBLP:conf/www/Sun0HWY25,
	author = {Jiahao Sun and
                  Chen Chen and
                  Chunyan Hou and
                  Yike Wu and
                  Xiaojie Yuan},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Multimodal Taylor Series Network for Misinformation Detection},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {2540--2548},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714719},
	doi = {10.1145/3696410.3714719},
	timestamp = {Fri, 09 May 2025 20:28:09 +0200},
	biburl = {https://dblp.org/rec/conf/www/Sun0HWY25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the rapid development of the Internet and the widespread use of social media, the proliferation of multimodal misinformation combining images and text poses serious risks to societal trust, individual well-being, and the integrity of AI models trained on such data. Recently, the automatic detection multimodal misinformation has become an essential area of research. However, traditional methods often rely on hierarchical neural networks that compress and fuse modalities, potentially overlooking deeper interactions between modalities and reducing model interpretability. In this paper, we present a novel Multimodal Taylor Series (MTS) network for detecting multimodal misinformation. The MTS network leverages Taylor series expansion to explicitly capture both low-order and high-order interactions between modalities, which also enhances interpretability by decomposing the model's processing into distinct terms. Additionally, the proposed MTS network avoids exponential parameter growth and maintains linear scalability, allowing the model to effectively capture complex cross-modal correlations. Extensive experiments on three benchmark datasets demonstrate that the MTS network significantly outperforms state-of-the-art models. We have open-sourced the code and logs at: https://github.com/OneForAllSama/MTS.}
}


@inproceedings{DBLP:conf/www/ZhaoZLWQLH25,
	author = {Wenkuan Zhao and
                  Shanshan Zhong and
                  Yifan Liu and
                  Wushao Wen and
                  Jinghui Qin and
                  Mingfu Liang and
                  Zhongzhan Huang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {{DVIB:} Towards Robust Multimodal Recommender Systems via Variational
                  Information Bottleneck Distillation},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {2549--2561},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714840},
	doi = {10.1145/3696410.3714840},
	timestamp = {Fri, 09 May 2025 20:28:09 +0200},
	biburl = {https://dblp.org/rec/conf/www/ZhaoZLWQLH25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In multimodal recommender systems (MRS), integrating various modalities helps to model user preferences and item characteristics more accurately, thereby assisting users in discovering items that match their interests. Although the introduction of multimodal information offers opportunities for performance improvement, it will increase the risks of inherent noise and information redundancy, posing challenges to the robustness of MRS. Many existing methods typically address these two issues separately either by introducing perturbations at the model input for robust training to handle noise or by designing complex network structures to filter out redundant information. In contrast, we propose the DVIB framework to simultaneously address both issues in a simple manner. We found that moving the perturbations from the input layer to the hidden layer, combined with feature self-distillation, can mitigate noise and handle information redundancy without altering the original network architecture. Additionally, we also provide theoretical evidence for the effectiveness of DVIB, demonstrating that the framework not only explicitly enhances the robustness of model training but also implicitly exhibits an information bottleneck effect, which effectively reduces redundant information during multimodal fusion and improves feature extraction quality. Extensive experiments show that DVIB consistently improves the performance of MRS across different datasets and model settings, and it can complement existing robust training methods, representing a promising new paradigm in MRS. See code at https://github.com/MarshmallowLight/DVIB.git.}
}


@inproceedings{DBLP:conf/www/WangJZCHCGWM25,
	author = {Tianlong Wang and
                  Xianfeng Jiao and
                  Yinghao Zhu and
                  Zhongzhi Chen and
                  Yifan He and
                  Xu Chu and
                  Junyi Gao and
                  Yasha Wang and
                  Liantao Ma},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Adaptive Activation Steering: {A} Tuning-Free {LLM} Truthfulness Improvement
                  Method for Diverse Hallucinations Categories},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {2562--2578},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714640},
	doi = {10.1145/3696410.3714640},
	timestamp = {Fri, 09 May 2025 20:28:09 +0200},
	biburl = {https://dblp.org/rec/conf/www/WangJZCHCGWM25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recent studies have indicated that Large Language Models (LLMs) harbor an inherent understanding of truthfulness, yet often fail to consistently express it and generate false statements. This gap between ''knowing'' and ''telling'' poses a challenge for ensuring the truthfulness of generated content. Inspired by recent work on the practice of encoding human-interpretable concepts linearly within large language models, we treat truthfulness as a specially linearly encoded concept within LLMs, and introduce Adaptive Activation Steering (ACT), a tuning-free method that adaptively shifts LLM's activations in the ''truthful'' direction during inference. ACT addresses diverse categories of hallucinations by utilizing diverse truthfulness-related steering vectors and adjusting the steering intensity adaptively. Applied as an add-on across various models, ACT significantly improves truthfulness in LLaMA (↑142%), LLaMA2 (↑24%), Alpaca (↑36%), Vicuna (↑28%), LLaMA2-Chat (↑19%), and LLaMA3(↑34%). Furthermore, we verify ACT's scalability across larger models (13B, 33B, 65B), underscoring the adaptability of ACT to large-scale language models. Our code is available at https://github.com/tianlwang/ACT.}
}


@inproceedings{DBLP:conf/www/WangZ0FW25,
	author = {Shuaiqi Wang and
                  Shuran Zheng and
                  Zinan Lin and
                  Giulia Fanti and
                  Zhiwei Steven Wu},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Inferentially-Private Private Information},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {2579--2595},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714702},
	doi = {10.1145/3696410.3714702},
	timestamp = {Fri, 09 May 2025 20:28:09 +0200},
	biburl = {https://dblp.org/rec/conf/www/WangZ0FW25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Information disclosure can compromise privacy when revealed information is correlated with private information. We consider the notion of  inferential privacy , which measures privacy leakage by bounding the inferential power a Bayesian adversary can gain by observing a released signal. Our goal is to devise an  inferentially-private private information structure  that maximizes the informativeness of the released signal, following the Blackwell ordering principle, while adhering to inferential privacy constraints. To achieve this, we devise an efficient release mechanism that achieves the inferentially-private Blackwell optimal private information structure for the setting where the private information is binary. Additionally, we propose a programming approach to compute the optimal structure for general cases given the utility function. The design of our mechanisms builds on our geometric characterization of the Blackwell-optimal disclosure mechanisms under privacy constraints, which may be of independent interest.}
}


@inproceedings{DBLP:conf/www/ZhangXLSZCK25,
	author = {Junjie Zhang and
                  Ruobing Xie and
                  Hongyu Lu and
                  Wenqi Sun and
                  Wayne Xin Zhao and
                  Yu Chen and
                  Zhanhui Kang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Frequency-Augmented Mixture-of-Heterogeneous-Experts Framework for
                  Sequential Recommendation},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {2596--2605},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714663},
	doi = {10.1145/3696410.3714663},
	timestamp = {Wed, 18 Jun 2025 13:00:45 +0200},
	biburl = {https://dblp.org/rec/conf/www/ZhangXLSZCK25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recently, many efforts have been devoted to building effective sequential recommenders. Despite their effectiveness, these methods typically develop a single model to serve all users. However, our empirical studies reveal that different sequential encoders have intrinsic architectural biases and tend to focus on specific behavioral patterns, \\ie particular frequency range of user behavior sequences. For example, the Self-Attention module is essentially a low-pass filter, focusing on low-frequency information while neglecting the high-frequency details. This evidently limits their ability to capture diverse user patterns, leading to suboptimal recommendations. To tackle this problem, we present  FamouSRec,  a  F requency- A ugmented  M ixture-of-Heterogeneous -Experts Framework for personalized  Rec  ommendations. Our approach builds an MoE-based recommender system, integrating the strengths of various experts to achieve diversified user modeling. For developing the MoE framework, as the key to our approach, we instantiate experts with various model architectures, aiming to leverage their inherent architectural biases and capture diverse behavioral patterns. For selecting appropriate experts to serve individuals, we introduce a frequency-augmented router. It first identifies frequency components in user behavior sequences that are suited for expert encoding, and then conducts customized routing based on the informativeness of these components. Building on this framework, we further propose two novel contrastive tasks to enhance expert specialization and alignment, thus improving modeling efficacy and enabling robust recommendations. Extensive experiments on five real-world datasets demonstrate the effectiveness of our approach.}
}


@inproceedings{DBLP:conf/www/BouadiABO25,
	author = {Mohamed Bouadi and
                  Arta Alavi and
                  Salima Benbernou and
                  Mourad Ouziri},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Synergizing Large Language Models and Knowledge-Based Reasoning for
                  Interpretable Feature Engineering},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {2606--2620},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714720},
	doi = {10.1145/3696410.3714720},
	timestamp = {Fri, 09 May 2025 20:28:09 +0200},
	biburl = {https://dblp.org/rec/conf/www/BouadiABO25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Feature engineering stands as a pivotal step in enhancing the performance of machine learning (ML) models, particularly with tabular data. However, traditional feature engineering methods are often time-consuming and requires case-by-case domain knowledge. In addition, as ML systems become more common, interpretability becomes increasingly important, especially among domain experts. To this end, we propose  ReaGen , an automated feature engineering (AutoFE) approach that combines knowledge graphs (KGs) with large language models (LLMs) to generate interpretable features.  ReaGen  begins by symbolic  REAsoning  over the KG to extract relevant information based on datasets description. Then, it uses an LLM to iteratively  GENerate  meaningful features. Finally, to overcome challenges such as hallucinations and handling long contexts typical in LLMs, our model performs logical reasoning on the KG to ensure that the generated features maintain interpretability.  ReaGen  provides Python code for automatic feature generation and detailed explanations of feature utility. It leverages both LLM's internal knowledge and retrieved information from KGs. Experiments on public datasets demonstrate that  ReaGen  significantly improves prediction accuracy while ensuring high interpretability through human-like explanations for each feature. This work highlights the potential of integrating LLMs and KGs in feature engineering, paving the way for interpretable ML models.}
}


@inproceedings{DBLP:conf/www/JungP25,
	author = {Heesoo Jung and
                  Hogun Park},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Balancing Graph Embedding Smoothness in Self-supervised Learning via
                  Information-Theoretic Decomposition},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {2621--2632},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714611},
	doi = {10.1145/3696410.3714611},
	timestamp = {Fri, 09 May 2025 20:28:09 +0200},
	biburl = {https://dblp.org/rec/conf/www/JungP25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Self-supervised learning (SSL) in graphs has garnered significant attention, particularly in employing Graph Neural Networks (GNNs) with pretext tasks initially designed for other domains, such as contrastive learning and feature reconstruction. However, it remains uncertain whether these methods effectively reflect essential graph properties, precisely representation similarity with its neighbors. We observe that existing methods position opposite ends of a spectrum driven by the graph embedding smoothness, with each end corresponding to outperformance on specific downstream tasks. Decomposing the SSL objective into three terms via an information-theoretic framework with a neighbor representation variable reveals that this polarization stems from an imbalance among the terms, which existing methods may not effectively maintain. Further insights suggest that balancing between the extremes can lead to improved performance across a wider range of downstream tasks. A framework, BSG (Balancing Smoothness in Graph SSL), introduces novel loss functions designed to supplement the representation quality in graph-based SSL by balancing the derived three terms: neighbor loss, minimal loss, and divergence loss. We present a rigorous theoretical analysis of the effects of these loss functions, highlighting their significance from both the SSL and graph smoothness perspectives. Extensive experiments on multiple real-world datasets across node classification and link prediction consistently demonstrate that BSG achieves state-of-the-art performance, outperforming existing methods. Our implementation code is available at https://github.com/steve30572/BSG.}
}


@inproceedings{DBLP:conf/www/ZhouLZC25,
	author = {Yiyun Zhou and
                  Zheqi Lv and
                  Shengyu Zhang and
                  Jingyuan Chen},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Disentangled Knowledge Tracing for Alleviating Cognitive Bias},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {2633--2645},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714607},
	doi = {10.1145/3696410.3714607},
	timestamp = {Tue, 13 May 2025 07:31:04 +0200},
	biburl = {https://dblp.org/rec/conf/www/ZhouLZC25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the realm of Intelligent Tutoring System (ITS), the accurate assessment of students' knowledge states through Knowledge Tracing (KT) is crucial for personalized learning. However, due to data bias,  i.e.,  the unbalanced distribution of question groups (  e.g.,  concepts), conventional KT models are plagued by cognitive bias, which tends to result in cognitive underload for overperformers and cognitive overload for underperformers. More seriously, this bias is amplified with the exercise recommendations by ITS. After delving into the causal relations in the KT models, we identify the main cause as the confounder effect of students' historical correct rate distribution over question groups on the student representation and prediction score. Towards this end, we propose a Disentangled Knowledge Tracing (DisKT) model, which separately models students' familiar and unfamiliar abilities based on causal effects and eliminates the impact of the confounder in student representation within the model. Additionally, to shield the contradictory psychology (  e.g.,  guessing and mistaking) in the students' biased data, DisKT introduces a contradiction attention mechanism. Furthermore, DisKT enhances the interpretability of the model predictions by integrating a variant of Item Response Theory. Experimental results on 11 benchmarks and 3 synthesized datasets with different bias strengths demonstrate that DisKT significantly alleviates cognitive bias and outperforms 16 baselines in evaluation accuracy.}
}


@inproceedings{DBLP:conf/www/0001LG00FG25,
	author = {Yonghao Liu and
                  Mengyu Li and
                  Fausto Giunchiglia and
                  Lan Huang and
                  Ximing Li and
                  Xiaoyue Feng and
                  Renchu Guan},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Dual-level Mixup for Graph Few-shot Learning with Fewer Tasks},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {2646--2656},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714905},
	doi = {10.1145/3696410.3714905},
	timestamp = {Fri, 09 May 2025 20:28:09 +0200},
	biburl = {https://dblp.org/rec/conf/www/0001LG00FG25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graph neural networks have been demonstrated as a powerful paradigm for effectively learning graph-structured data on the  web  and mining content from it. %the  wide web.  for downstream task analysis. Current leading graph models require a large number of labeled samples for training, which unavoidably leads to overfitting in few-shot scenarios. Recent research has sought to alleviate this issue by simultaneously leveraging graph learning and meta-learning paradigms. However, these graph meta-learning models assume the availability of numerous meta-training tasks to learn transferable meta-knowledge. Such assumption may not be feasible in the real world due to the difficulty of constructing tasks and the substantial costs involved. Therefore, we propose a  S i M ple yet effect I ve approach for graph few-shot  L earning with f E wer tasks, named  SMILE.  We introduce a dual-level mixup strategy, encompassing both within-task and across-task mixup, to simultaneously enrich the available nodes and tasks in meta-learning. Moreover, we explicitly leverage the prior information provided by the node degrees in the graph to encode expressive node representations. Theoretically, we demonstrate that SMILE can enhance the model generalization ability. Empirically, SMILE consistently outperforms other competitive models by a large margin across all evaluated datasets with in-domain and cross-domain settings. Our anonymous code can be found https://github.com/KEAML-JLU/SMILE.}
}


@inproceedings{DBLP:conf/www/KhirianovaSPOSD25,
	author = {Alexandra Khirianova and
                  Ekaterina Solodneva and
                  Andrey Pudovikov and
                  Sergey Osokin and
                  Egor Samosvat and
                  Yuriy Dorn and
                  Alexander Ledovsky and
                  Yana Zenkova},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {{BAT:} Benchmark for Auto-bidding Task},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {2657--2667},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714657},
	doi = {10.1145/3696410.3714657},
	timestamp = {Fri, 09 May 2025 20:28:09 +0200},
	biburl = {https://dblp.org/rec/conf/www/KhirianovaSPOSD25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The optimization of bidding strategies for online advertising slot auctions presents a critical challenge across numerous digital marketplaces. A significant obstacle to the development, evaluation, and refinement of real-time autobidding algorithms is the scarcity of comprehensive datasets and standardized benchmarks. To address this deficiency, we present an auction benchmark encompassing the two most prevalent auction formats. We implement a series of robust baselines on a novel dataset, addressing the most salient Real-Time Bidding (RTB) problem domains: budget pacing uniformity and Cost Per Click (CPC) constraint optimization. This benchmark provides a user-friendly and intuitive framework for researchers and practitioners to develop and refine innovative autobidding algorithms, thereby facilitating advancements in the field of programmatic advertising. The implementation and additional resources can be accessed at the following repository https://github.com/avito-tech/bat-autobidding-benchmark, https://doi.org/10.5281/zenodo.14794182.}
}


@inproceedings{DBLP:conf/www/WangLZ00D25,
	author = {Taotao Wang and
                  Zibin Lin and
                  Shengli Zhang and
                  Long Shi and
                  Qing Yang and
                  Boris D{\"{u}}dder},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Linking Souls to Humans: Blockchain Accounts with Credible Anonymity
                  for Web 3.0 Decentralized Identity},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {2668--2676},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714784},
	doi = {10.1145/3696410.3714784},
	timestamp = {Fri, 09 May 2025 20:28:09 +0200},
	biburl = {https://dblp.org/rec/conf/www/WangLZ00D25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A decentralized identity system that can provide users with self-sovereign digital identities to facilitate complete control over their own data is paramount to Web 3.0. The account system on blockchain is an ideal archetype for realizing Web 3.0 decentralized identity. However, a disadvantage of such completely anonymous identity system is that users can create multiple accounts without authentication to obfuscate their activities on the blockchain. In particular, the current anonymous blockchain account system cannot accurately register the social relationships and interactions between real human users, given the amorphous mappings between users and blockchain identities. This work proposes zkBID, a zero-knowledge blockchain-account-based Web 3.0 decentralized identity scheme, to overcome endemic mistrust in blockchain account systems. zkBID links souls (blockchain accounts) to humans (users' personhood credentials) in a one-to-one manner to truly reflect the social relationships and interactions between humans on the blockchain. zkBID conceals the one-to-one relationships between blockchain accounts and users' personhood credentials for privacy protection using zero-knowledge proofs and linkable ring signatures. Thus, with zkBID, the users' blockchain accounts are credibly anonymous. Importantly, zkBID is fully decentralized: all user-related data are generated by users and verified by smart contracts on the blockchain. We implemented zkBID and built a blockchain test network for evaluation purposes. Our tests demonstrate the effectiveness of zkBID and suggest proper ways to configure zkBID system parameters.}
}


@inproceedings{DBLP:conf/www/ChengZJW025,
	author = {Zihao Cheng and
                  Li Zhou and
                  Feng Jiang and
                  Benyou Wang and
                  Haizhou Li},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Beyond Binary: Towards Fine-Grained LLM-Generated Text Detection via
                  Role Recognition and Involvement Measurement},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {2677--2688},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714770},
	doi = {10.1145/3696410.3714770},
	timestamp = {Fri, 09 May 2025 20:28:09 +0200},
	biburl = {https://dblp.org/rec/conf/www/ChengZJW025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The rapid development of large language models (LLMs), like ChatGPT, has resulted in the widespread presence of LLM-generated content on social media platforms, raising concerns about misinformation, data biases, and privacy violations, which can undermine trust in online discourse. While detecting LLM-generated content is crucial for mitigating these risks, current methods often focus on binary classification, failing to address the complexities of real-world scenarios like human-LLM collaboration. To move beyond binary classification and address these challenges, we propose a new paradigm for detecting LLM-generated content. This approach introduces two novel tasks: LLM Role Recognition (LLM-RR), a multi-class classification task that identifies specific roles of an LLM in content generation, and LLM Involvement Measurement (LLM-IM), a regression task that quantifies the extent of LLM involvement in content creation. To support these tasks, we propose LLMDetect, a benchmark designed to evaluate detectors' performance on these new tasks. LLMDetect includes the Hybrid News Detection Corpus (HNDC) for training detectors, as well as DetectEval, a comprehensive evaluation suite that considers five distinct cross-context variations and two multi-intensity variations within the same LLM role. This allows for a thorough assessment of detectors' generalization and robustness across diverse contexts. Our empirical validation of 10 baseline detection methods demonstrates that fine-tuned Pre-trained Language Model (PLM)-based models consistently outperform others on both tasks, while advanced LLMs face challenges in accurately detecting their own generated content. Our experimental results and analysis offer insights for developing more effective detection models for LLM-generated content. This research enhances the understanding of LLM-generated content and establishes a foundation for more nuanced detection methodologies.}
}


@inproceedings{DBLP:conf/www/FengLYZ0Z25,
	author = {Xiaohua Feng and
                  Yuyuan Li and
                  Fengyuan Yu and
                  Li Zhang and
                  Chaochao Chen and
                  Xiaolin Zheng},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Plug and Play: Enabling Pluggable Attribute Unlearning in Recommender
                  Systems},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {2689--2699},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714671},
	doi = {10.1145/3696410.3714671},
	timestamp = {Fri, 09 May 2025 20:28:09 +0200},
	biburl = {https://dblp.org/rec/conf/www/FengLYZ0Z25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the escalating privacy concerns in recommender systems, attribute unlearning has drawn widespread attention as an effective approach against attribute inference attacks. This approach focuses on unlearning users' privacy attributes to reduce the performance of attackers while preserving the overall effectiveness of recommendation. Current research attempts to achieve attribute unlearning through adversarial training and distribution alignment in the statistic setting. However, these methods often struggle in dynamic real-world environments, particularly when considering scenarios where unlearning requests are frequently updated. In this paper, we first identify three main challenges of current methods in dynamic environments, i.e., irreversible operation, low efficiency, and unsatisfied recommendation preservation. To overcome these challenges, we propose a Pluggable Attribute Unlearning framework, PAU. Upon receiving an unlearning request, PAU plugs an additional erasure module into the original model to achieve unlearning. This module can perform a reverse operation if the request is later withdrawn. To enhance the efficiency of unlearning, we introduce rate distortion theory and reduce the attack performance by maximizing the encoded bits required for users' embedding within the same class of the unlearned attribute and minimizing those for different classes, which eliminates the need to calculate the centroid distribution for alignment. We further preserve recommendation performance by constraining the compactness of the user embedding space around a reasonable flood level. Extensive experiments conducted on four real-world datasets and three mainstream recommendation models demonstrate the effectiveness of our proposed framework.}
}


@inproceedings{DBLP:conf/www/0006SLWWW025,
	author = {Yichen Li and
                  Yijing Shan and
                  Yi Liu and
                  Haozhao Wang and
                  Wei Wang and
                  Yi Wang and
                  Ruixuan Li},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Personalized Federated Recommendation for Cold-Start Users via Adaptive
                  Knowledge Fusion},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {2700--2709},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714635},
	doi = {10.1145/3696410.3714635},
	timestamp = {Fri, 09 May 2025 20:28:09 +0200},
	biburl = {https://dblp.org/rec/conf/www/0006SLWWW025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated Recommendation System (FRS) usually offers recommendation services for users while keeping their data locally to ensure privacy. Currently, most FRS literature assumes that fixed users participate in federated training with personal IoT devices (e.g., mobile phones and PC). However, users may join incrementally, and retraining the entire FRS for each new participating user is unfeasible due to the high training costs and the limited global knowledge contribution from a small number of new users. To guarantee the quality service for these new users, we take a dive into the federated recommendation for cold-start users, a novel scenario where the new participating users can directly obtain a promising recommendation without comprehensive training with all participating users by leveraging both transferred knowledge from the converged warm clients and the knowledge learned from the local data. Nevertheless, the efficient transfer of knowledge from warm clients remains controversial. On the one hand, cold clients may introduce new sparse items, resulting in a shift in the item embedding distribution compared to that converged on warm clients. On the other hand, cold-start users need to match similar user information from warm clients for a collaborative recommendation, but directly sharing user information is a violation of privacy and unacceptable. To tackle these challenges, we propose an efficient and privacy-enhanced federated recommendation for cold-start users (FR-CSU) that each client can adaptively transfer both user and item knowledge separately from warm clients and implement recommendations with local and transferred knowledge fusion. Specifically, each cold client will train a mapping function locally to transfer the aligned item embedding. Meanwhile, warm clients will maintain a user prototype network collaboratively that provides privacy-friendly yet effective user information for cold-start users. Then, a linear function system will integrate the transferred and local knowledge to improve recommendations. Extensive experiments show that FR-CSU achieves superior performance compared to state-of-the-art methods.}
}


@inproceedings{DBLP:conf/www/Jazi0BT25,
	author = {Hossein Nekouyan Jazi and
                  Bo Sun and
                  Raouf Boutaba and
                  Xiaoqi Tan},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Posted Price Mechanisms for Online Allocation with Diseconomies of
                  Scale},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {2710--2728},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714590},
	doi = {10.1145/3696410.3714590},
	timestamp = {Fri, 09 May 2025 20:28:09 +0200},
	biburl = {https://dblp.org/rec/conf/www/Jazi0BT25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper addresses the online  k -selection problem with diseconomies of scale (ØSDoS), where a seller seeks to maximize social welfare by optimally pricing items for sequentially arriving buyers, accounting for increasing marginal production costs. Previous studies have investigated deterministic dynamic pricing mechanisms for such settings. However, significant challenges remain, particularly in achieving optimality with small or finite inventories and developing effective randomized posted price mechanisms. To bridge this gap, we propose a novel randomized dynamic pricing mechanism for ØSDoS, providing a tighter lower bound on the competitive ratio compared to prior work. Our approach ensures optimal performance in small inventory settings (i.e., when  k  is small) and surpasses existing online mechanisms in large inventory settings (i.e., when  k  is large), leading to the best-known posted price mechanism for optimizing online selection and allocation with diseconomies of scale across varying inventory sizes.}
}


@inproceedings{DBLP:conf/www/Zeng0C00025,
	author = {Ximu Zeng and
                  Liwei Deng and
                  Penghao Chen and
                  Xu Chen and
                  Han Su and
                  Kai Zheng},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {{LIRA:} {A} Learning-based Query-aware Partition Framework for Large-scale
                  {ANN} Search},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {2729--2741},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714633},
	doi = {10.1145/3696410.3714633},
	timestamp = {Fri, 09 May 2025 20:28:09 +0200},
	biburl = {https://dblp.org/rec/conf/www/Zeng0C00025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Approximate nearest neighbor search is fundamental in information retrieval. Previous partition-based methods enhance search efficiency by probing partial partitions, yet they face two common issues. In the query phase, a common strategy is to probe partitions based on the distance ranks of a query to partition centroids, which inevitably probes irrelevant partitions as it ignores data distribution. In the partition construction phase, all partition-based methods face the boundary problem that separates a query's nearest neighbors to multiple partitions, resulting in a long-tailed  k NN distribution and degrading the optimal nprobe (i.e., the number of probing partitions). To address this gap, we propose LIRA, a <u>L</u>earn<u>I</u>ng-based que<u>R</u>y-aware p<u>A</u>rtition framework. Specifically, we propose a probing model to directly probe the partitions containing the  k NN of a query, which can reduce probing waste and allow for query-aware probing with nprobe individually. Moreover, we incorporate the probing model into a learning-based redundancy strategy to mitigate the adverse impact of the long-tailed  k NN distribution on search efficiency. Extensive experiments on real-world vector datasets demonstrate the superiority of LIRA in the trade-off among accuracy, latency, and query fan-out. The codes are available at https://github.com/SimoneZeng/LIRA-ANN-search.}
}


@inproceedings{DBLP:conf/www/Zhang000025,
	author = {Yusong Zhang and
                  Kun Xie and
                  Xingyi Zhang and
                  Xiangyu Dong and
                  Sibo Wang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Rumor Detection on Social Media with Reinforcement Learning-based
                  Key Propagation Graph Generator},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {2742--2753},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714651},
	doi = {10.1145/3696410.3714651},
	timestamp = {Thu, 01 May 2025 20:27:29 +0200},
	biburl = {https://dblp.org/rec/conf/www/Zhang000025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The spread of rumors on social media, particularly during significant events like the US elections and the COVID-19 pandemic, poses a serious threat to social stability and public health. Current rumor detection methods primarily rely on propagation graphs to improve the model performance. However, the effectiveness of these methods is often compromised by noisy and irrelevant structures in the propagation process. To tackle this issue, techniques such as weight adjustment and data augmentation have been proposed. However, they depend heavily on rich original propagation structures, limiting their effectiveness in handling rumors that lack sufficient propagation information, especially in the early stages of dissemination. In this work, we introduce the  <u>K</u>ey <u>P</u>ropagation Graph <u>G</u>enerator (KPG) , a novel reinforcement learning-based framework, that generates contextually coherent and informative propagation patterns for events with insufficient topology information and identifies significant substructures in events with redundant and noisy propagation structures. KPG comprises two key components: the  <u>C</u>andidate <u>R</u>esponse <u>G</u>enerator (CRG)  and the  <u>E</u>nding <u>N</u>ode <u>S</u>elector (ENS) . CRG learns latent variable distributions from refined propagation patterns to eliminate noise and generate new candidates for ENS, while ENS identifies the most influential substructures in propagation graphs and provides training data for CRG. Furthermore, we develop an end-to-end framework that utilizes rewards derived from a pre-trained graph neural network to guide the training process. The resulting key propagation graphs are then employed in downstream rumor detection tasks. Extensive experiments conducted on four datasets demonstrate that KPG outperforms current state-of-the-art methods.}
}


@inproceedings{DBLP:conf/www/Hong00ZWCYDDZ025,
	author = {Minjie Hong and
                  Yan Xia and
                  Zehan Wang and
                  Jieming Zhu and
                  Ye Wang and
                  Sihang Cai and
                  Xiaoda Yang and
                  Quanyu Dai and
                  Zhenhua Dong and
                  Zhimeng Zhang and
                  Zhou Zhao},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {{EAGER-LLM:} Enhancing Large Language Models as Recommenders through
                  Exogenous Behavior-Semantic Integration},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {2754--2762},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714933},
	doi = {10.1145/3696410.3714933},
	timestamp = {Fri, 09 May 2025 20:28:09 +0200},
	biburl = {https://dblp.org/rec/conf/www/Hong00ZWCYDDZ025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Large language models (LLMs) are increasingly leveraged as foundational backbones in the development of advanced recommender systems, offering enhanced capabilities through their extensive knowledge and reasoning. Existing llm-based recommender systems (RSs) often face challenges due to the significant differences between the linguistic semantics of pre-trained LLMs and the collaborative semantics essential for RSs. These systems use pre-trained linguistic semantics but learn collaborative semantics from scratch via the llm-Backbone. However, LLMs are not designed for recommendations, leading to inefficient collaborative learning, weak result correlations, and poor integration of traditional RS features. To address these challenges, we propose  EAGER-LLM , a decoder-only llm-based generative recommendation framework that integrates endogenous and exogenous behavioral and semantic information in a non-intrusive manner. Specifically, we propose 1) dual-source knowledge-rich item indices that integrates indexing sequences for exogenous signals, enabling efficient link-wide processing; 2) non-invasive multiscale alignment reconstruction tasks guide the model toward a deeper understanding of both collaborative and semantic signals; 3) an annealing adapter designed to finely balance the model's recommendation performance with its comprehension capabilities. We demonstrate EAGER-LLM's effectiveness through rigorous testing on three public benchmarks.}
}


@inproceedings{DBLP:conf/www/LangHXLX025,
	author = {Jian Lang and
                  Rongpei Hong and
                  Jin Xu and
                  Yili Li and
                  Xovee Xu and
                  Fan Zhou},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Biting Off More Than You Can Detect: Retrieval-Augmented Multimodal
                  Experts for Short Video Hate Detection},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {2763--2774},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714560},
	doi = {10.1145/3696410.3714560},
	timestamp = {Fri, 09 May 2025 20:28:09 +0200},
	biburl = {https://dblp.org/rec/conf/www/LangHXLX025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Short Video Hate Detection (SVHD) is increasingly vital as hateful content - such as racial and gender-based discrimination - spreads rapidly across platforms like TikTok, YouTube Shorts, and Instagram Reels. Existing approaches face significant challenges: hate expressions continuously evolve, hateful signals are dispersed across multiple modalities (audio, text, and vision), and the contribution of each modality varies across different hate content. To address these issues, we introduce  MoRE ( M ixture  o f  R etrieval-augmented multimodal  E xperts), a novel framework designed to enhance SVHD. MoRE employs specialized multimodal experts for each modality, leveraging their unique strengths to identify hateful content effectively. To ensure model's adaptability to rapidly evolving hate content, MoRE leverages contextual knowledge extracted from relevant instances retrieved by a powerful joint multimodal video retriever for each target short video. Moreover, a dynamic sample-sensitive integration network adaptively adjusts the importance of each modality on a per-sample basis, optimizing the detection process by prioritizing the most informative modalities for each instance. Our MoRE adopts an end-to-end training strategy that jointly optimizes both expert networks and the overall framework, resulting in nearly a twofold improvement in training efficiency, which in turn enhances its applicability to real-world scenarios. Extensive experiments on three benchmarks demonstrate that MoRE surpasses state-of-the-art baselines, achieving an average improvement of 6.91% in macro-F1 score across all datasets.}
}


@inproceedings{DBLP:conf/www/LiuWY25,
	author = {Yi Liu and
                  Cong Wang and
                  Xingliang Yuan},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {FedMobile: Enabling Knowledge Contribution-aware Multi-modal Federated
                  Learning with Incomplete Modalities},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {2775--2786},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714623},
	doi = {10.1145/3696410.3714623},
	timestamp = {Fri, 09 May 2025 20:28:09 +0200},
	biburl = {https://dblp.org/rec/conf/www/LiuWY25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Web of Things (WoT) enhances interoperability across web-based and ubiquitous computing platforms while complementing existing IoT standards. The multimodal Federated Learning (FL) paradigm has been introduced to enhance WoT by enabling the fusion of multi-source mobile sensing data while preserving privacy. However, a key challenge in mobile sensing systems using multimodal FL is modality incompleteness, where some modalities may be unavailable or only partially captured, potentially degrading the system's performance and reliability. Current multimodal FL frameworks typically train multiple unimodal FL subsystems or apply interpolation techniques on the node side to approximate missing modalities. However, these approaches overlook the shared latent feature space among incomplete modalities across different nodes and fail to discriminate against low-quality nodes. To address this gap, we present FedMobile, a new knowledge contribution-aware multimodal FL framework designed for robust learning despite missing modalities. FedMobile prioritizes local-to-global knowledge transfer, leveraging cross-node multimodal feature information to reconstruct missing features. It also enhances system performance and resilience to modality heterogeneity through rigorous node contribution assessments and knowledge contribution-aware aggregation rules. Empirical evaluations on five widely recognized multimodal benchmark datasets demonstrate that FedMobile maintains robust learning even when up to 90% of modality information is missing or when data from two modalities are randomly missing, outperforming state-of-the-art baselines. Our code and data are available at the https://doi.org/10.5281/zenodo.14802364 link.}
}


@inproceedings{DBLP:conf/www/LiWZYC25,
	author = {Jin Li and
                  Shoujin Wang and
                  Qi Zhang and
                  Shui Yu and
                  Fang Chen},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Generating with Fairness: {A} Modality-Diffused Counterfactual Framework
                  for Incomplete Multimodal Recommendations},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {2787--2798},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714606},
	doi = {10.1145/3696410.3714606},
	timestamp = {Fri, 09 May 2025 20:28:09 +0200},
	biburl = {https://dblp.org/rec/conf/www/LiWZYC25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Incomplete scenario is a prevalent, practical, yet challenging setting in Multimodal Recommendations (MMRec), where some item modalities are missing due to various factors. Recently, a few efforts have sought to improve the recommendation accuracy by exploring generic structures from incomplete data. However, two significant gaps persist: 1) the difficulty in accurately generating missing data due to the limited ability to capture modality distributions; and 2) the critical but overlooked visibility bias, where items with missing modalities are more likely to be disregarded due to the prioritization of items' multimodal data over user preference alignment. This bias raises serious concerns about the fair treatment of items. To bridge these two gaps, we propose a novel Modality-Diffused Counterfactual (MoDiCF) framework for incomplete multimodal recommendations. MoDiCF features two key modules: a novel modality-diffused data completion module and a new counterfactual multimodal recommendation module. The former, equipped with a particularly designed multimodal generative framework, accurately generates and iteratively refines missing data from learned modality-specific distribution spaces. The latter, grounded in the causal perspective, effectively mitigates the negative causal effects of visibility bias and thus assures fairness in recommendations. Both modules work collaboratively to address the two aforementioned significant gaps for generating more accurate and fair results. Extensive experiments on three real-world datasets demonstrate the superior performance of MoDiCF in terms of both recommendation accuracy and fairness. The code and processed datasets are released at https://github.com/JinLi-i/MoDiCF.}
}


@inproceedings{DBLP:conf/www/HaoCZL25,
	author = {Xixuan Hao and
                  Wei Chen and
                  Xingchen Zou and
                  Yuxuan Liang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Nature Makes No Leaps: Building Continuous Location Embeddings with
                  Satellite Imagery from the Web},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {2799--2812},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714629},
	doi = {10.1145/3696410.3714629},
	timestamp = {Fri, 09 May 2025 20:28:09 +0200},
	biburl = {https://dblp.org/rec/conf/www/HaoCZL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Building location embedding from web-sourced satellite imagery has emerged as an enduring research focus in web mining. However, most existing methods are inherently constrained by their reliance on discrete, sparse sampling strategies, failing to capture the essential spatial continuity of geographic spaces. Moreover, the presence of confounding factors in satellite images can distort the perception of actual objects, leading to semantic discontinuity in the embeddings. In this work, we propose SatCLE, a novel framework for <u>C</u>ontinuous <u>L</u>ocation <u>E</u>mbeddings leveraging <u>Sat</u>ellite imagery. Specifically, to address the out-of-sample query challenge of spatial continuity, we propose a geospatial refinement strategy comprising stochastic perturbation continuity expansion and graph propagation fusion, which transforms discrete geospatial coordinates into a continuous space. To mitigate the effects of confounders on semantic continuity, we introduce causal refinement, integrating causal theory to localize and eliminate spurious correlations arising from the environmental context. Through extensive experiments, SatCLE shows state-of-the-art performance, exhibiting superior spatial coherence and semantic fidelity across diverse geospatial tasks. The source code is available at https://github.com/CityMind-Lab/SatCLE.}
}


@inproceedings{DBLP:conf/www/ShiY0DLX25,
	author = {Hequan Shi and
                  Lingyun Ying and
                  Libo Chen and
                  Haixin Duan and
                  Ming Liu and
                  Zhi Xue},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Dr. Docker: {A} Large-Scale Security Measurement of Docker Image Ecosystem},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {2813--2823},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714653},
	doi = {10.1145/3696410.3714653},
	timestamp = {Fri, 09 May 2025 20:28:09 +0200},
	biburl = {https://dblp.org/rec/conf/www/ShiY0DLX25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Docker has transformed modern software development, enabling the widespread reuse of containerized applications. Currently, Docker images are primarily distributed through centralized registries, among which Docker Hub is the largest, allowing developers to share and reuse images easily. The threats within these images also spread through the supply chain via dependency relationships, posing risks to anyone using the image and all images built based on it. However, it is unclear to what extent the threats within Docker images are distributed and propagated. In this paper, we investigate five potential security risks in Docker images and propose a security analysis framework DITector based on these security issues. We then utilize DITector to conduct a large-scale security measurement of the Docker image ecosystem. We collect descriptions of over 12 million image repositories from Docker Hub, construct an image dependency graph based on the layer information of the images, and select two sets of influential images based on their pull counts and dependency weight, totaling 33,952 images. Our findings are alarming: 93.7% of analyzed images contain known vulnerabilities, 4,437 images have secret leaks, 50 images contain misconfigurations and 24 malicious images. Furthermore, we identify 334 downstream images affected by malicious images and uncover patterns of attack propagation within the supply chain. We have discussed the measures to mitigate these issues, reported our findings to the relevant parties, and received positive responses.}
}


@inproceedings{DBLP:conf/www/CabralHABNP25,
	author = {Rina Carines Cabral and
                  Soyeon Caren Han and
                  Areej Alhassan and
                  Riza Batista{-}Navarro and
                  Goran Nenadic and
                  Josiah Poon},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {TriG-NER: Triplet-Grid Framework for Discontinuous Named Entity Recognition},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {2824--2837},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714639},
	doi = {10.1145/3696410.3714639},
	timestamp = {Fri, 09 May 2025 20:28:10 +0200},
	biburl = {https://dblp.org/rec/conf/www/CabralHABNP25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Discontinuous Named Entity Recognition (DNER) presents a challenging problem where entities may be scattered across multiple non-adjacent tokens, making traditional sequence labelling approaches inadequate. Existing methods predominantly rely on custom tagging schemes to handle these discontinuous entities, resulting in models tightly coupled to specific tagging strategies and lacking generalisability across diverse datasets. To address these challenges, we propose TriG-NER, a novel Triplet-Grid Framework that introduces a generalisable approach to learning robust token-level representations for discontinuous entity extraction. Our framework applies triplet loss at the token level, where similarity is defined by word pairs existing within the same entity, effectively pulling together similar and pushing apart dissimilar ones. This approach enhances entity boundary detection and reduces the dependency on specific tagging schemes by focusing on word-pair relationships within a flexible grid structure. We evaluate TriG-NER on three benchmark DNER datasets and demonstrate significant improvements over existing grid-based architectures. These results underscore our framework's effectiveness in capturing complex entity structures and its adaptability to various tagging schemes, setting a new benchmark for discontinuous entity extraction.}
}


@inproceedings{DBLP:conf/www/Yin0S0H025,
	author = {Junwei Yin and
                  Min Gao and
                  Kai Shu and
                  Wentao Li and
                  Yinqiu Huang and
                  Zongwei Wang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Graph with Sequence: Broad-Range Semantic Modeling for Fake News Detection},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {2838--2849},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714906},
	doi = {10.1145/3696410.3714906},
	timestamp = {Fri, 09 May 2025 20:28:10 +0200},
	biburl = {https://dblp.org/rec/conf/www/Yin0S0H025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The rapid proliferation of fake news on social media threatens social stability, creating an urgent demand for more effective detection methods. While many promising approaches have emerged, most rely on content analysis with limited semantic depth, leading to suboptimal comprehension of news content. To address this limitation, capturing broader-range semantics is essential yet challenging, as it introduces two primary types of noise: fully connecting sentences in news graphs often adds unnecessary structural noise, while highly similar but authenticity-irrelevant sentences introduce feature noise, complicating the detection process. To tackle these issues, we propose BREAK, a <u>b</u>road-<u>r</u>ange s<u>e</u>mantics model for f<u>ak</u>e news detection that leverages a fully connected graph to capture comprehensive semantics while employing dual denoising modules to minimize both structural and feature noise. The semantic structure denoising module balances the graph's connectivity by iteratively refining it between two bounds: a sequence-based structure as a lower bound and a fully connected graph as the upper bound. This refinement uncovers label-relevant semantic interrelations structures. Meanwhile, the semantic feature denoising module reduces noise from similar semantics by diversifying representations, aligning distinct outputs from the denoised graph and sequence encoders using KL-divergence to achieve feature diversification in high-dimensional space. The two modules are jointly optimized in a bi-level framework, enhancing the integration of denoised semantics into a comprehensive representation for detection. Extensive experiments across four datasets prove that BREAK significantly outperforms existing fake news detection methods.}
}


@inproceedings{DBLP:conf/www/Aggarwal0TZ25,
	author = {Gagan Aggarwal and
                  Anupam Gupta and
                  Xizhi Tan and
                  Mingfei Zhao},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Multi-Platform Autobidding with and without Predictions},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {2850--2859},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714936},
	doi = {10.1145/3696410.3714936},
	timestamp = {Fri, 09 May 2025 20:28:10 +0200},
	biburl = {https://dblp.org/rec/conf/www/Aggarwal0TZ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We study the problem of finding the optimal bidding strategy for an advertiser in a multi-platform auction setting. The competition on a platform is captured by a value and a cost function, mapping bidding strategies to value and cost respectively. We assume a diminishing returns property, whereby the marginal cost is increasing in value. The advertiser uses an autobidder that selects a bidding strategy for each platform, aiming to maximize total value subject to budget and return-on-spend constraint. The advertiser has no prior information and learns about the value and cost functions by querying a platform with a specific bidding strategy. Our goal is to design algorithms that find the optimal bidding strategy with a small number of queries. We first present an algorithm that requires (O( m  log ( mn ) log  n )) queries, where  m  is the number of platforms and  n  is the number of possible bidding strategies in each platform. Moreover, we adopt the learning-augmented framework and propose an algorithm that utilizes a (possibly erroneous) prediction of the optimal bidding strategy. We provide a O(m log (mη) log η) query-complexity bound on our algorithm as a function of the prediction error η. This guarantee gracefully degrades to (O( m  log ( mn ) log  n )). This achieves a "best-of-both-worlds" scenario: (O( m )) queries when given a correct prediction, and (O( m  log ( mn ) log  n )) even for an arbitrary incorrect prediction.}
}


@inproceedings{DBLP:conf/www/0001HSHWY25,
	author = {Di Jin and
                  Cuiying Huo and
                  Jiayi Shi and
                  Dongxiao He and
                  Jianguo Wei and
                  Philip S. Yu},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {LLGformer: Learnable Long-range Graph Transformer for Traffic Flow
                  Prediction},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {2860--2871},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714596},
	doi = {10.1145/3696410.3714596},
	timestamp = {Fri, 09 May 2025 20:28:10 +0200},
	biburl = {https://dblp.org/rec/conf/www/0001HSHWY25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Traffic prediction plays a pivotal role in intelligent transportation systems. Most existing studies only predict traffic flow for a specific time period based on traffic data from a short period, such as an hour, overlooking the influence of periodicity present in traffic data. Moreover, most of the existing advanced methods rely on manually constructed spatio-temporal graphs for joint modeling, or use pure spatial and pure temporal modules to separately model spatial and temporal features, which limits the learning of complex spatio-temporal patterns in traffic data due to structural inadequacies in the model. To address these issues, we propose a novel approach by constructing a learnable long-range spatio-temporal graph, which can better capture complex patterns in traffic data. We introduce a new model, LLGformer, which improves upon traditional Transformer-style models, facilitating more efficient learning of traffic flow data by integrating long-range historical information. Leveraging attention mechanisms on a spatiotemporal graph enables direct interaction of information across different time slices and locations. Additionally, we propose two optimization strategies to further boost the speed of training and inference. Extensive experiments on four real-world datasets show that the new model significantly outperforms state-of-the-art methods.}
}


@inproceedings{DBLP:conf/www/ZhangM0HLC025,
	author = {Han Zhang and
                  Zixiang Meng and
                  Meng Luo and
                  Hong Han and
                  Lizi Liao and
                  Erik Cambria and
                  Hao Fei},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Towards Multimodal Empathetic Response Generation: {A} Rich Text-Speech-Vision
                  Avatar-based Benchmark},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {2872--2881},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714739},
	doi = {10.1145/3696410.3714739},
	timestamp = {Tue, 13 May 2025 07:31:04 +0200},
	biburl = {https://dblp.org/rec/conf/www/ZhangM0HLC025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Empathetic Response Generation (ERG) is one of the key tasks of the affective computing area, which aims to produce emotionally nuanced and compassionate responses to user's queries. However, existing ERG research is predominantly confined to the singleton text modality, limiting its effectiveness since human emotions are inherently conveyed through multiple modalities. To combat this, we introduce an avatar-based Multimodal ERG (MERG) task, entailing rich text, speech, and facial vision information. We first present a large-scale high-quality benchmark dataset,  AvaMERG , which extends traditional text ERG by incorporating authentic human speech audio and dynamic talking-face avatar videos, encompassing a diverse range of avatar profiles and broadly covering various topics of real-world scenarios. Further, we deliberately tailor a system, named  Empatheia , for MERG. Built upon a Multimodal Large Language Model (MLLM) with multimodal encoder, speech and avatar generators, Empatheia performs end-to-end MERG, with Chain-of-Empathetic reasoning mechanism integrated for enhanced empathy understanding and reasoning.Finally, we devise a list of empathetic-enhanced tuning strategies, strengthening the capabilities of emotional accuracy and content, avatar-profile consistency across modalities. Experimental results on AvaMERG data demonstrate that Empatheia consistently shows superior performance than baseline methods on both textual ERG and MERG. All data and code are open at https://AvaMERG.github.io/.}
}


@inproceedings{DBLP:conf/www/000500LWZFPW25,
	author = {Weiming Liu and
                  Chaochao Chen and
                  Jiahe Xu and
                  Xinting Liao and
                  Fan Wang and
                  Xiaolin Zheng and
                  Zhihui Fu and
                  Ruiguang Pei and
                  Jun Wang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Joint Similarity Item Exploration and Overlapped User Guidance for
                  Multi-Modal Cross-Domain Recommendation},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {2882--2893},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714860},
	doi = {10.1145/3696410.3714860},
	timestamp = {Fri, 09 May 2025 20:28:10 +0200},
	biburl = {https://dblp.org/rec/conf/www/000500LWZFPW25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cross-Domain Recommendation (CDR) has been widely investi- gated for solving long-standing data sparsity problem via knowl- edge sharing across domains. In this paper, we focus on the Multi- Modal Cross-Domain Recommendation (MMCDR) problem where different items have multi-modal information while few users are overlapped across domains. MMCDR is particularly challenging in two aspects: fully exploiting diverse multi-modal information within each domain and leveraging useful knowledge transfer across domains. However, previous methods fail to cluster items with similar characteristics while filtering out inherit noises within different modalities, hurdling the model performance. What is worse, conventional CDR models primarily rely on overlapped users for domain adaptation, making them ill-equipped to handle scenarios where the majority of users are non-overlapped. To fill this gap, we propose Joint Similarity Item Exploration and Overlapped User Guidance ( SIEOUG ) for solving the MMCDR problem.  SIEOUG  first proposes similarity item exploration module, which not only obtains pair-wise and group-wise item-item graph knowledge, but also reduces irrelevant noise for multi-modal modeling. Then  SIEOUG  proposes user-item collaborative filtering module to aggregate user/item embeddings with the attention mechanism for collaborative filtering. Finally  SIEOUG  proposes overlapped user guidance module with optimal user matching for knowledge sharing across domains. Our empirical study on Amazon dataset with several different tasks demonstrates that  SIEOUG  significantly outperforms the state-of-the-art models under the MMCDR setting.}
}


@inproceedings{DBLP:conf/www/LiuZ025,
	author = {Mingrui Liu and
                  Sixiao Zhang and
                  Cheng Long},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Mask-based Membership Inference Attacks for Retrieval-Augmented Generation},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {2894--2907},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714771},
	doi = {10.1145/3696410.3714771},
	timestamp = {Thu, 01 May 2025 20:27:24 +0200},
	biburl = {https://dblp.org/rec/conf/www/LiuZ025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Retrieval-Augmented Generation (RAG) has been an effective approach to mitigate hallucinations in large language models (LLMs) by incorporating up-to-date and domain-specific knowledge. Recently, there has been a trend of storing up-to-date or copyrighted data in RAG knowledge databases instead of using it for LLM training. This practice has raised concerns about Membership Inference Attacks (MIAs), which aim to detect if a specific target document is stored in the RAG system's knowledge database so as to protect the rights of data producers. While research has focused on enhancing the trustworthiness of RAG systems, existing MIAs for RAG systems remain largely insufficient. Previous work either relies solely on the RAG system's judgment or is easily influenced by other documents or the LLM's internal knowledge, which is unreliable and lacks explainability. To address these limitations, we propose a  <u>M</u> ask- <u>B</u> ased Membership Inference  <u>A</u> ttacks (MBA) framework. Our framework first employs a masking algorithm that effectively masks a certain number of words in the target document. The masked text is then used to prompt the RAG system, and the RAG system is required to predict the mask values. If the target document appears in the knowledge database, the masked text will retrieve the complete target document as context, allowing for accurate mask prediction. Finally, we adopt a simple yet effective threshold-based method to infer the membership of target document by analyzing the accuracy of mask prediction. Our mask-based approach is more document-specific, making the RAG system's generation less susceptible to distractions from other documents or the LLM's internal knowledge. Extensive experiments demonstrate the effectiveness of our approach compared to existing baseline models.}
}


@inproceedings{DBLP:conf/www/LiSWZQLW25,
	author = {Xunkai Li and
                  Daohan Su and
                  Zhengyu Wu and
                  Guang Zeng and
                  Hongchao Qin and
                  Rong{-}Hua Li and
                  Guoren Wang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Toward Effective Digraph Representation Learning: {A} Magnetic Adaptive
                  Propagation based Approach},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {2908--2923},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714939},
	doi = {10.1145/3696410.3714939},
	timestamp = {Tue, 10 Jun 2025 16:57:47 +0200},
	biburl = {https://dblp.org/rec/conf/www/LiSWZQLW25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The  q -parameterized magnetic Laplacian serves as the foundation of directed graph (digraph) convolution, enabling this kind of digraph neural network (MagDG) to encode node features and structural insights by complex-domain message passing. Despite their success, limitations still exist: (1) The performance of MagDGs depends on selecting an appropriate  q -parameter to construct suitable graph propagation equations in the complex domain. This parameter tuning limits model flexibility and significantly increases manual effort. (2) Most approaches treat all nodes with the same complex-domain propagation and aggregation rules, neglecting their unique digraph contexts. This oversight results in sub-optimal performance. To address the above issues, we propose two key techniques: (1) MAP is crafted to be a plug-and-play complex-domain propagation optimization strategy, enabling seamless integration into any MagDG to improve predictions while enjoying high running efficiency. (2) MAP++ is a new digraph learning framework, further incorporating a learnable mechanism to achieve adaptively edge-wise propagation and node-wise aggregation in the complex domain for better performance. Extensive experiments on 12 datasets demonstrate that MAP enjoys flexibility for it can be incorporated with any MagDG, and scalability as it can deal with web-scale digraphs. MAP++ achieves SOTA predictive performance on 4 different downstream tasks.}
}


@inproceedings{DBLP:conf/www/WangWHPYYWF25,
	author = {Zheng Wang and
                  Wanwan Wang and
                  Yimin Huang and
                  Zhaopeng Peng and
                  Ziqi Yang and
                  Ming Yao and
                  Cheng Wang and
                  Xiaoliang Fan},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {{P4GCN:} Vertical Federated Social Recommendation with Privacy-Preserving
                  Two-Party Graph Convolution Network},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {2924--2934},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714721},
	doi = {10.1145/3696410.3714721},
	timestamp = {Fri, 09 May 2025 20:28:10 +0200},
	biburl = {https://dblp.org/rec/conf/www/WangWHPYYWF25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent years, graph neural networks (GNNs) have been commonly utilized for social recommendation systems. However, real-world scenarios often present challenges related to user privacy and business constraints, inhibiting direct access to valuable social information from other platforms. While many existing methods have tackled matrix factorization-based social recommendations without direct social data access, developing GNN-based federated social recommendation models under similar conditions remains largely unexplored. To address this issue, we propose a novel vertical federated social recommendation method leveraging privacy-preserving two-party graph convolution networks (P4GCN) to enhance recommendation accuracy without requiring direct access to sensitive social information. First, we introduce a Sandwich-Encryption module to ensure comprehensive data privacy during the collaborative computing process. Second, we provide a thorough theoretical analysis of the privacy guarantees, considering the participation of both curious and honest parties. Extensive experiments on four real-world datasets demonstrate that P4GCN outperforms state-of-the-art methods in terms of recommendation accuracy.}
}


@inproceedings{DBLP:conf/www/0005S0SS0W25,
	author = {Xiao Tan and
                  Yangyang Shen and
                  Yan Zhang and
                  Jingwen Shao and
                  Dian Shen and
                  Meng Wang and
                  Beilun Wang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {NoTeNet: Normalized Mutual Information-Driven Tuning-free Dynamic
                  Dependence Network Inference Method for Multimodal Data},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {2935--2947},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714855},
	doi = {10.1145/3696410.3714855},
	timestamp = {Fri, 09 May 2025 20:28:10 +0200},
	biburl = {https://dblp.org/rec/conf/www/0005S0SS0W25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Dynamic Dependence Network (DDN) inference is crucial for understanding evolving relationships in multimodal time series web data, with broad applications in fields like medical and financial network analysis. The inherent dynamic nature, temporal continuity, and heterogeneous data sources in multimodal time series data pose three fundamental challenges: computational efficiency, prediction stability and robustness, and modality quality disparity. Previous methods, generally lacking utilization of multiple modalities, either struggle with computational efficiency due to the time-intensive manual hyperparameter tuning, or compromise prediction stability and robustness by neglecting temporal coherence. To address these challenges, we propose a <u>No</u>rmalized mutual information-driven <u>T</u>uning-fre<u>e</u> Dynamic Dependence <u>Net</u>work inference method for multimodal data, namely NoTeNet. NoTeNet provides a promising paradigm that can integrate two different data modalities to enhance prediction accuracy. It uses normalized mutual information transforms noisy auxiliary data into relationship matrices and employs a kernel function for smooth temporal estimation. Additionally, NoTeNet significantly reduces the need for manual hyperparameter adjustments, offering a tuning-free approach with theoretical guarantees. On various synthetic datasets and real-world data, NoTeNet demonstrates superior prediction accuracy and efficiency without the need for hyperparameter tuning, making it potential for a wide range of web data applications.}
}


@inproceedings{DBLP:conf/www/HirschZNGS25,
	author = {Sharon Hirsch and
                  Lilach Zitnitski and
                  Slava Novgorodov and
                  Ido Guy and
                  Bracha Shapira},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Graph Meets {LLM} for Review Personalization based on User Votes},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {2948--2958},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714691},
	doi = {10.1145/3696410.3714691},
	timestamp = {Fri, 09 May 2025 20:28:10 +0200},
	biburl = {https://dblp.org/rec/conf/www/HirschZNGS25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Review personalization aims at presenting the most relevant reviews of a product according to the preferences of the individual user. Existing studies of review personalization use the reviews authored by the user as a proxy for their preferences, and henceforth as a means for learning and evaluating personalization quality. In this work, we suggest using review votes rather than authorship for personalization. We propose  MAGLLM , an approach that leverages heterogeneous graphs for modeling the relationships among reviews, products, and users, with large language model (LLM) to enrich user representation on the graph. Our evaluation over a unique public dataset that includes user voting information indicates that the vote signal yields substantially higher personalization performance across a variety of recommendation methods and e-commerce domains. It also indicates that our graph-LLM approach outperforms comparative baselines and algorithmic alternatives. We conclude with concrete recommendations for e-commerce platforms seeking to enhance their review personalization experience.}
}


@inproceedings{DBLP:conf/www/Yao0LDGW25,
	author = {Yixuan Yao and
                  Ming Yang and
                  Zixia Liu and
                  Kai Dong and
                  Xiaodan Gu and
                  Chunmian Wang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Do Not Trust What They Tell: Exposing Malicious Accomplices in Tor
                  via Anomalous Circuit Detection},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {2959--2968},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714767},
	doi = {10.1145/3696410.3714767},
	timestamp = {Mon, 02 Jun 2025 21:06:29 +0200},
	biburl = {https://dblp.org/rec/conf/www/Yao0LDGW25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Tor network, while offering anonymity through traffic routing across volunteer-operated nodes, remains vulnerable to attacks that aim to deanonymize users by correlating traffic patterns between colluded entry and exit nodes in circuits. This paper presents a novel approach for detecting anomalous circuits in the Tor network, and for the first time provides a more comprehensive identification of potential malicious accomplice nodes in Tor by taking roles of nodes in anomalous circuits into consideration. Our method strategically utilizes modified middle nodes to capture traffic data, followed by a novel circuit classification based on traffic patterns to pinpoint concerned circuits. Two kinds of anomalies are identified: routing anomalies and usage anomalies, that respectively represent the anomalies with explicit or implicit violation of Tor's circuit construction guidelines. This leads to a successful revealing of totally 1,960 anomalous nodes in Tor. Furthermore, we apply clustering analysis with considering corresponding anomalous circuits and other key characteristics to the detected anomalous nodes, revealing potential hidden organizations behind these nodes that can threaten the network's security. Our findings highlight the necessity for the Tor project to adopt targeted mitigation strategies to enhance overall network security and privacy.}
}


@inproceedings{DBLP:conf/www/KimKLS25,
	author = {Jane Kim and
                  Jung{-}Hun Kang and
                  Hyunwoo Lee and
                  Seung{-}Hyun Seo},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {ExpressPQDelivery: Toward Efficient and Immediately Deployable Post-Quantum
                  Key Delivery for Web-of-Things},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {2969--2980},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714944},
	doi = {10.1145/3696410.3714944},
	timestamp = {Fri, 09 May 2025 20:28:10 +0200},
	biburl = {https://dblp.org/rec/conf/www/KimKLS25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Post-quantum cryptography (PQC) aims to develop quantum-safe algorithms against attacks by a quantum computer. As quantum-safe algorithms require much larger keys in their operation compared to the current RSA/ECC practice, the networking latency significantly increases when executing the protocols with sending such large keys. This problem gets more challenging in the era of Web-of-Things (WoT) with low-memory devices. To tackle the problem, we propose E xpress PQD elivery , which is, to the best of our knowledge, the first immediately deployable protocol to efficiently transport large keys. It leverages the DNS infrastructure, as DNS is close to clients, guaranteeing express key delivery with a short round-trip time (RTT). We split a large PQ key along with a server's signature and feed them into several DNS records. To show the feasibility of E xpress PQD elivery , we instantiate it with TLS 1.3 and demonstrate that it reduces 27% of network latency between a server and a client on average compared to the standard TLS 1.3. We deploy E xpress PQD elivery  on a low-capability board with 256 KB RAM, showing a significant high gain (34%).}
}


@inproceedings{DBLP:conf/www/ChenL0WC0R25,
	author = {Zhongpu Chen and
                  Yinfeng Liu and
                  Long Shi and
                  Zhi{-}Jie Wang and
                  Xingyan Chen and
                  Yu Zhao and
                  Fuji Ren},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {MDEval: Evaluating and Enhancing Markdown Awareness in Large Language
                  Models},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {2981--2991},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714674},
	doi = {10.1145/3696410.3714674},
	timestamp = {Fri, 09 May 2025 20:28:10 +0200},
	biburl = {https://dblp.org/rec/conf/www/ChenL0WC0R25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Large language models (LLMs) are expected to offer structured Markdown responses for the sake of readability in web chatbots (e.g., ChatGPT). Although there are a myriad of metrics to evaluate LLMs, they fail to evaluate the readability from the view of output content structure. To this end, we focus on an overlooked yet important metric ---  Markdown Awareness,  which directly impacts the readability and structure of the content generated by these language models. In this paper, we introduce MDEval, a comprehensive benchmark to assess  Markdown Awareness  for LLMs, by constructing a dataset with 20K instances covering 10 subjects in English and Chinese. Unlike traditional model-based evaluations, MDEval provides excellent interpretability by combining model-based generation tasks and statistical methods. Our results demonstrate that MDEval achieves a Spearman correlation of 0.791 and an accuracy of 84.1% with human, outperforming existing methods by a large margin. Extensive experimental results also show that through fine-tuning over our proposed dataset, less performant open-source models are able to achieve comparable performance to GPT-4o in terms of  Markdown Awareness.  To ensure reproducibility and transparency, MDEval is open sourced at https://github.com/SWUFE-DB-Group/MDEval-Benchmark.}
}


@inproceedings{DBLP:conf/www/FangFYCYGH25,
	author = {Yuan Fang and
                  Xiaofeng Feng and
                  Geping Yang and
                  Ruichu Cai and
                  Yiyang Yang and
                  Zhiguo Gong and
                  Zhifeng Hao},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {{EVA-MVC:} Equitable View-weight Allocation for Generic Multi-View
                  Clustering},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {2992--3003},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714545},
	doi = {10.1145/3696410.3714545},
	timestamp = {Fri, 09 May 2025 20:28:10 +0200},
	biburl = {https://dblp.org/rec/conf/www/FangFYCYGH25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Contemporary datasets sourced from the web often adopt a multi-view format, collecting data from diverse sources, domains, or modules. Existing methodologies employed to analyze such datasets frequently overlook or inaccurately allocate the view-weights, pivotal metrics reflecting each view's significance. This work introduces EVA-MVC, a simple yet effective algorithm designed for Equitable View-weight Allocation (EVA) seamlessly integrated with arbitrary Multi-view Clustering (MVC) methods. Within the EVA module, we establish theoretical connections between view supplementarity and Multi-view Subspace Learning (MSL), leading to the partition of views into View Communities (VCs) based on these foundational principles. These VCs exhibit internal supplementarity similarities, facilitating Equitable View-weights Allocation through VC-specific MSL. The proposed EVA process precedes and operates independently of traditional or SOTA MVC approaches, requiring no additional processing or specialized design, making it an ideal preprocessing step for MVC applications. Through comprehensive evaluations across diverse multi-view datasets, our findings reveal that our EVA significantly enhances the effectiveness of mainstream MVC frameworks, resulting in a notable performance improvement.}
}


@inproceedings{DBLP:conf/www/HuangCWG25,
	author = {Jianwei Huang and
                  Sridatta Raghavendra Chintapalli and
                  Mengxiao Wang and
                  Guofei Gu},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Beyond Visual Confusion: Understanding How Inconsistencies in {ENS}
                  Normalization Facilitate Homoglyph Attacks},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {3004--3013},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714675},
	doi = {10.1145/3696410.3714675},
	timestamp = {Fri, 09 May 2025 20:28:10 +0200},
	biburl = {https://dblp.org/rec/conf/www/HuangCWG25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent years, the Ethereum Name Service (ENS) has garnered significant attention within the community for enabling the use of Unicode in domain names, thereby facilitating the inclusion of a wide array of character sets such as Greek, Cyrillic, Arabic, and Chinese. While this feature enhances the versatility and global accessibility of domain names, it concurrently introduces a substantial security vulnerability due to the presence of homoglyphs-characters that are visually similar to others across Unicode and ASCII sets. These similarities can be exploited in homoglyph attacks, posing a distinct threat to domain name integrity. Despite community efforts to counteract this issue through a normalization process prior to domain resolution, our analysis uncovers significant discrepancies in how the normalization processes are applied across various applications. This inconsistency could result in the same domain name being resolved to different addresses in different applications, underscoring a critical vulnerability. We also discovered the new attack scenario in ENS which may cause legitimate domains resolved into malicious addresses even when they are verified by authorities. To systematically evaluate this inconsistency, we designed a tool for detecting application-level discrepancies in domain normalization process without requiring access to the application's source code. Our evaluation on hundreds of real-world Web3 applications identifies widespread deviations from established homoglyph mitigation practices, with more than 60% digital wallets and 80% dApps (decentralized applications) not able to produce consistent ENS resolving results, potentially impacting millions of users. This analysis underscores the urgent need for a standardized implementation of normalization processes to safeguard the integrity and security of ENS domains.}
}


@inproceedings{DBLP:conf/www/WangLW25,
	author = {Yulong Wang and
                  Hong Li and
                  Ni Wei},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {{SAHSD:} Enhancing Hate Speech Detection in LLM-Powered Web Applications
                  via Sentiment Analysis and Few-Shot Learning},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {3014--3025},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714644},
	doi = {10.1145/3696410.3714644},
	timestamp = {Fri, 09 May 2025 20:28:10 +0200},
	biburl = {https://dblp.org/rec/conf/www/WangLW25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As large language models (LLMs) increasingly power web applications, including social networks, the challenge of moderating hate speech has become a critical concern for the Web. These LLM-powered applications, while offering near-human interaction capabilities, are vulnerable to harmful or biased content due to imperfect training data scraped from the Web. Current hate speech detection methods often struggle with limited annotated data, especially for real-time moderation on these platforms. This paper introduces Sentiment-Aided Hate Speech Detection (SAHSD), a novel approach designed to enhance hate speech detection specifically in LLM-powered web applications. By treating hate speech detection as a few-shot learning task, SAHSD utilizes sentiment analysis to refine pre-trained language models (LM) for improved accuracy in recognizing harmful content. SAHSD first employs publicly available sentiment datasets to train a sentiment analysis model, which is then fine-tuned by merging sentiment prompts with hate speech prompts, enabling efficient and accurate detection even with limited training samples. The effectiveness of SAHSD is demonstrated through experiments on widely used web-sourced datasets like SBIC and HateXplain. SAHSD achieves an exceptional F1-score of 0.99 with only 64 training samples and outperforms advanced techniques such as ToKen, MRP, and HARE, with significant improvements of 33% on SBIC and 95% on HateXplain. SAHSD surpasses GPT-4 in generalization performance across multiple datasets, showing an 8% improvement when trained on equal-sized samples. These results underscore SAHSD's potential to enhance content moderation in LLM-driven web platforms, contributing to a safer, more inclusive and accountable Web ecosystem.}
}


@inproceedings{DBLP:conf/www/HosseiniMP25,
	author = {Hadi Hosseini and
                  Debmalya Mandal and
                  Amrit Puhan},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Surprisingly Popular Voting with Concentric Rank-Order Models},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {3026--3036},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714707},
	doi = {10.1145/3696410.3714707},
	timestamp = {Fri, 09 May 2025 20:28:10 +0200},
	biburl = {https://dblp.org/rec/conf/www/HosseiniMP25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {An important problem on social information sites is the recovery of ground truth from individual reports when the experts are in the minority. The wisdom of the crowd, i.e. the collective opinion of a group of individuals fails in such a scenario. However, the surprisingly popular (SP) algorithm[15] can recover the ground truth even when the experts are in the minority, by asking the individuals to report additional prediction reports--their beliefs about the reports of others. Several recent works have extended the surprisingly popular algorithm to an equivalent voting rule (SP-voting) to recover the ground truth ranking over a set of  m  alternatives. However, we are yet to fully understand when SP-voting can recover the ground truth ranking, and if so, how many samples (votes and predictions) it needs. We answer this question by proposing two rank-order models and analyzing the sample complexity of SP-voting under these models. In particular, we propose concentric mixtures of Mallows and Plackett-Luce models with G (≥ 2) groups. Our models generalize previously proposed concentric mixtures of Mallows models with 2 groups, and we highlight the importance of G > 2 groups by identifying three distinct groups (expert, intermediate, and non-expert) from existing datasets. Next, we provide conditions on the parameters of the underlying models so that SP-voting can recover ground-truth rankings with high probability, and also derive sample complexities under the same. We complement the theoretical results by evaluating SP-voting on simulated and real datasets.}
}


@inproceedings{DBLP:conf/www/ChenH0H0WF0025,
	author = {Sirui Chen and
                  Shen Han and
                  Jiawei Chen and
                  Binbin Hu and
                  Sheng Zhou and
                  Gang Wang and
                  Yan Feng and
                  Chun Chen and
                  Can Wang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Rankformer: {A} Graph Transformer for Recommendation based on Ranking
                  Objective},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {3037--3048},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714547},
	doi = {10.1145/3696410.3714547},
	timestamp = {Fri, 09 May 2025 20:28:10 +0200},
	biburl = {https://dblp.org/rec/conf/www/ChenH0H0WF0025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recommender Systems (RS) aim to generate personalized ranked lists for each user and are evaluated using ranking metrics. Although personalized ranking is a fundamental aspect of RS, this critical property is often overlooked in the design of model architectures. To address this issue, we propose Rankformer, a ranking-inspired recommendation model. The architecture of Rankformer is inspired by the gradient of the ranking objective, embodying a unique (graph) transformer architecture --- it leverages global information from all users and items to produce more informative representations and employs specific attention weights to guide the evolution of embeddings towards improved ranking performance. We further develop an acceleration algorithm for Rankformer, reducing its complexity to a linear level with respect to the number of positive instances. Extensive experimental results demonstrate that Rankformer outperforms state-of-the-art methods. The code is available at https://github.com/StupidThree/Rankformer.}
}


@inproceedings{DBLP:conf/www/FarukZ25,
	author = {Ahmed Sayeed Faruk and
                  Elena Zheleva},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Leveraging Heterogeneous Spillover in Maximizing Contextual Bandit
                  Rewards},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {3049--3060},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714706},
	doi = {10.1145/3696410.3714706},
	timestamp = {Fri, 09 May 2025 20:28:10 +0200},
	biburl = {https://dblp.org/rec/conf/www/FarukZ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recommender systems relying on contextual multi-armed bandits continuously improve relevant item recommendations by taking into account the contextual information. The objective of bandit algorithms is to learn the best arm (e.g., best item to recommend) for each user and thus maximize the cumulative rewards from user engagement with the recommendations. The context that these algorithms typically consider are the user and item attributes. However, in the context of social networks where  the action of one user can influence the actions and rewards of other users,  neighbors' actions are also a very important context, as they can have not only predictive power but also can impact future rewards through spillover. Moreover, influence susceptibility can vary for different people based on their preferences and the closeness of ties to other users which leads to heterogeneity in the spillover effects. Here, we present a framework that allows contextual multi-armed bandits to account for such heterogeneous spillovers when choosing the best arm for each user. Our experiments on several semi-synthetic and real-world datasets show that our framework leads to significantly higher rewards than existing state-of-the-art solutions that ignore the network information and potential spillover.}
}


@inproceedings{DBLP:conf/www/WangT0025,
	author = {Weiqi Wang and
                  Zhiyi Tian and
                  An Liu and
                  Shui Yu},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {{TAPE:} Tailored Posterior Difference for Auditing of Machine Unlearning},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {3061--3072},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714875},
	doi = {10.1145/3696410.3714875},
	timestamp = {Fri, 09 May 2025 20:28:10 +0200},
	biburl = {https://dblp.org/rec/conf/www/WangT0025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the increasing prevalence of Web-based platforms handling vast amounts of user data, machine unlearning has emerged as a crucial mechanism to uphold users' right to be forgotten, enabling individuals to request the removal of their specified data from trained models. However, the auditing of machine unlearning processes remains significantly underexplored. Although some existing methods offer unlearning auditing by leveraging backdoors, these backdoor-based approaches are inefficient and impractical, as they necessitate involvement in the initial model training process to embed the backdoors. In this paper, we propose a TAilored Posterior diffErence (TAPE) method to provide unlearning auditing independently of original model training. We observe that the process of machine unlearning inherently introduces changes in the model, which contains information related to the erased data. TAPE leverages unlearning model differences to assess how much information has been removed through the unlearning operation. Firstly, TAPE mimics the unlearned posterior differences by quickly building unlearned shadow models based on first-order influence estimation. Secondly, we train a Reconstructor model to extract and evaluate the private information of the unlearned posterior differences to audit unlearning. Existing privacy reconstructing methods based on posterior differences are only feasible for model updates of a single sample. To enable the reconstruction effective for multi-sample unlearning requests, we propose two strategies, unlearned data perturbation and unlearned influence-based division, to augment the posterior difference. Extensive experimental results indicate the significant superiority of TAPE over the state-of-the-art unlearning verification methods, at least 4.5x efficiency speedup and supporting the auditing for broader unlearning scenarios.}
}


@inproceedings{DBLP:conf/www/Cao0L0H25,
	author = {Haifang Cao and
                  Yu Wang and
                  Jialu Li and
                  Pengfei Zhu and
                  Qinghua Hu},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Hyperbolic-Euclidean Deep Mutual Learning},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {3073--3083},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714659},
	doi = {10.1145/3696410.3714659},
	timestamp = {Fri, 09 May 2025 20:28:10 +0200},
	biburl = {https://dblp.org/rec/conf/www/Cao0L0H25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graph neural networks (GNNs) exhibit powerful performance in handling graph data, with Euclidean and hyperbolic variants excelling in processing grid-based and hierarchical structures, respectively. However, existing methods focus on learning specific structures linked to the inherent properties of the underlying space, failing to fully exploit their complementary properties in distinct geometric spaces, thus limiting their ability to efficiently model complex graph structures. In this paper, we propose a Hyperbolic-Euclidean Deep Mutual Learning (H-EDML) framework, which leverages the unique properties of hyperbolic space to effectively capture the hierarchical relationships present in graph data, while also utilizes the familiar Euclidean space to handle local interactions. Specifically, We design a topology mutual learning module to bolster the capacity of each single model to perceive the holistic topological structure of the graph. Then, we integrate a decision mutual learning module to further advance the models' comprehensive judgment capabilities towards graph data, thereby strengthening the robustness and generalization. Furthermore, we employ an attention-based probabilistic integration strategy for the final prediction to alleviate potential disparities in decision-making among different models. Extensive experiments on node classification are conducted on five real-world graph datasets and the results show that our proposed H-EDML achieves competitive performances compared to the state-of-the-art methods. The source code will be available at: https://github.com/caohaifang123/H-EDML.}
}


@inproceedings{DBLP:conf/www/KimuraLHCCKW0OL25,
	author = {Tomoyoshi Kimura and
                  Xinlin Li and
                  Osama A. Hanna and
                  Yatong Chen and
                  Yizhuo Chen and
                  Denizhan Kara and
                  Tianshi Wang and
                  Jinyang Li and
                  Xiaomin Ouyang and
                  Shengzhong Liu and
                  Mani Srivastava and
                  Suhas N. Diggavi and
                  Tarek F. Abdelzaher},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {InfoMAE: Pair-Efficient Cross-Modal Alignment for Multimodal Time-Series
                  Sensing Signals},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {3084--3095},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714853},
	doi = {10.1145/3696410.3714853},
	timestamp = {Fri, 09 May 2025 20:28:10 +0200},
	biburl = {https://dblp.org/rec/conf/www/KimuraLHCCKW0OL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Standard multimodal self-supervised learning (SSL) algorithms regard cross-modal synchronization as implicit supervisory labels during pretraining, thus posing high requirements on the scale and quality of multimodal samples. These constraints significantly limit the performance of sensing intelligence in IoT applications, as the heterogeneity and the non-interpretability of time-series signals result in abundant unimodal data but scarce high-quality multimodal pairs. This paper proposes InfoMAE, a cross-modal alignment framework that tackles the challenge of multimodal pair efficiency under the SSL setting by facilitating efficient cross-modal alignment of pretrained unimodal representations. InfoMAE achieves  efficient cross-modal alignment  with  limited data pairs  through a novel information theory-inspired formulation that simultaneously addresses distribution-level and instance-level alignment. Extensive experiments on two real-world IoT applications are performed to evaluate InfoMAE's pairing efficiency to bridge pretrained unimodal models into a cohesive joint multimodal model. InfoMAE enhances downstream multimodal tasks by over 60% with significantly improved multimodal pairing efficiency. It also improves unimodal task accuracy by an average of 22%.}
}


@inproceedings{DBLP:conf/www/VijayanFPSS025,
	author = {Sushant Vijayan and
                  Zhe Feng and
                  Swati Padmanabhan and
                  Karthikeyan Shanmugam and
                  Arun Sai Suggala and
                  Di Wang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Online Bidding under RoS Constraints without Knowing the Value},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {3096--3107},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714734},
	doi = {10.1145/3696410.3714734},
	timestamp = {Thu, 10 Jul 2025 21:21:08 +0200},
	biburl = {https://dblp.org/rec/conf/www/VijayanFPSS025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We consider the problem of bidding in online advertising, where an advertiser aims to maximize value while adhering to budget and Return-on-Spend (RoS) constraints. Unlike prior work that assumes knowledge of the value generated by winning each impression (e.g., conversions), we address the more realistic setting where the advertiser must simultaneously learn the optimal bidding strategy and the value of each impression opportunity. This introduces a challenging exploration-exploitation dilemma: the advertiser must balance exploring different bids to estimate impression values with exploiting current knowledge to bid effectively. To address this, we propose a novel Upper Confidence Bound (UCB)-style algorithm that carefully manages this trade-off. Via a rigorous theoretical analysis, we prove that our algorithm achieves Õ(₲T log(|B|T) ) regret and constraint violation, where  T  is the number of bidding rounds and B is the domain of possible bids. This establishes the first optimal regret and constraint violation bounds for bidding in the online setting with unknown impression values. Moreover, our algorithm is computationally efficient and simple to implement. We validate our theoretical findings through experiments on synthetic data, demonstrating that our algorithm exhibits strong empirical performance compared to existing approaches.}
}


@inproceedings{DBLP:conf/www/0001WFX25,
	author = {Yankai Chen and
                  Taotao Wang and
                  Yixiang Fang and
                  Yunyu Xiao},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Semi-supervised Node Importance Estimation with Informative Distribution
                  Modeling for Uncertainty Regularization},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {3108--3118},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714591},
	doi = {10.1145/3696410.3714591},
	timestamp = {Fri, 09 May 2025 20:28:10 +0200},
	biburl = {https://dblp.org/rec/conf/www/0001WFX25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Node importance estimation , a classical problem in network analysis, underpins various web applications. Previous methods either exploit intrinsic topological characteristics, e.g., graph centrality, or leverage additional information, e.g., data heterogeneity, for node feature enhancement. However, these methods follow the  supervised learning  setting, overlooking the fact that ground-truth node-importance data are usually partially labeled in practice. In this work, we propose the first semi-supervised node importance estimation framework, i.e., EASING, to improve learning quality for unlabeled data in heterogeneous graphs. Different from previous approaches, EASING explicitly captures  uncertainty  to reflect the confidence of model predictions. To jointly estimate the importance values and uncertainties, EASING incorporates DJE, a deep encoder-decoder neural architecture. DJE introduces  distribution modeling  for graph nodes, where the distribution representations derive both importance and uncertainty estimates. Additionally, DJE facilitates effective pseudo-label generation for the unlabeled data to enrich the training samples. Based on labeled and pseudo-labeled data, EASING develops effective semi-supervised heteroscedastic learning with the varying node uncertainty regularization. Extensive experiments on three real-world datasets highlight the superior performance of EASING compared to competing methods. Codes are available via https://github.com/yankai-chen/EASING.}
}


@inproceedings{DBLP:conf/www/KimKLS25a,
	author = {Yeongho Kim and
                  Yuyeong Kim and
                  Geon Lee and
                  Kijung Shin},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Beyond Neighbors: Distance-Generalized Graphlets for Enhanced Graph
                  Characterization},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {3119--3135},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714558},
	doi = {10.1145/3696410.3714558},
	timestamp = {Fri, 09 May 2025 20:28:10 +0200},
	biburl = {https://dblp.org/rec/conf/www/KimKLS25a.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graphs are widely used to model complex systems across various domains, including social networks and biological systems. A key task in graph analysis is identifying recurring structural patterns, known as graphlets, which capture connectivity among a fixed-size subset of nodes. While graphlets have been extensively applied in tasks such as measuring graph similarity and identifying communities, conventional graphlets focus only on direct connections between nodes. This limitation overlooks potential insights from more distant relationships within the graph structure. In this paper, we introduce (d,s)-graphlets, a generalization of size-s graphlets that incorporates indirect connections between nodes up to distance d. This new formulation provides a more fine-grained and comprehensive understanding of local graph structures. To efficiently count (d,s)-graphlets in a graph, we present EDGE, an exact counting algorithm that employs optimized combinatorial techniques to significantly reduce computational complexity compared to naive enumeration. Our empirical analysis across diverse real-world datasets demonstrates that (d,s)-graphlets provide superior graph characterization, outperforming conventional graphlets in a graph clustering task. Moreover, our case studies show that (d,s)-graphlets uncover non-trivial insights that would remain undiscovered when using conventional graphlets.}
}


@inproceedings{DBLP:conf/www/YangHZDCTY25,
	author = {Jiyu Yang and
                  Qiang He and
                  Zheyu Zhou and
                  Xiaohai Dai and
                  Feifei Chen and
                  Cong Tian and
                  Yun Yang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {EdgeThemis: Ensuring Model Integrity for Edge Intelligence},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {3136--3146},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714662},
	doi = {10.1145/3696410.3714662},
	timestamp = {Tue, 13 May 2025 07:31:04 +0200},
	biburl = {https://dblp.org/rec/conf/www/YangHZDCTY25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Machine learning (ML) models are widely deployed on edge nodes, such as mobile phones and edge servers, to power a wide range of AI applications over the web. Ensuring the integrity of these edge models is paramount, as they are subject to corruption caused by software/hardware exceptions and malicious tampering, which may undermine model performance, incur economic losses, and pose health risks. Existing data integrity mechanisms designed for files stored on disks cannot properly verify the integrity of models running in GPUs or mitigate the new integrity threats against edge models. This paper proposes EdgeThemis, a novel mechanism for verifying the integrity of edge models through sentinel verification. To enable verifiability for a model  M , EdgeThemis embeds a sentinel backdoor and a verification module into  M . Then, a challenger can send verification requests to the edge node hosting  M  to verify its integrity. Next, the sentinel activates the verification module to generate a unique integrity proof tied to the identity of the edge node for verification. Finally, the challenger can verify the integrity proof to detect model corruption. Theoretical analysis proves that EdgeThemis can properly mitigate potential integrity threats against edge models. Experiments demonstrate that EdgeThemis achieves a verification accuracy of 100.00% across various models and different types of model corruption with robustness against replay attacks, theft attacks, and replacement attacks.}
}


@inproceedings{DBLP:conf/www/SunYLYS025,
	author = {Peishuai Sun and
                  Xiaochun Yun and
                  Shuhao Li and
                  Tao Yin and
                  Chengxiang Si and
                  Jiang Xie},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {AdvTG: An Adversarial Traffic Generation Framework to Deceive DL-Based
                  Malicious Traffic Detection Models},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {3147--3159},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714876},
	doi = {10.1145/3696410.3714876},
	timestamp = {Fri, 09 May 2025 20:28:10 +0200},
	biburl = {https://dblp.org/rec/conf/www/SunYLYS025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Deep learning-based (DL-based) malicious traffic detection models are effective but vulnerable to adversarial attacks. Existing adversarial attacks have shown promising results when targeting traffic detection models based on statistics and sequence features. However, these attacks are less effective against models that rely on payload analysis. The main reason is the difficulty in generating semantic, compliant, and functional payloads, which limits their practical application. In this paper, we propose AdvTG, an adversarial traffic generation framework to deceive DL-based malicious traffic based on the large language model (LLM) and reinforcement learning (RL). Specifically, AdvTG is designed to attack various DL-based detection models across diverse payload features and architectures, thereby enhancing the generalization capabilities of the generated adversarial traffic. Moreover, we design a specialized prompt for traffic generation tasks, where functional fields and target types are supplied as input, while non-functional fields are generated to produce the mutated traffic. This fine-tuning endows the LLM with task comprehension and traffic pattern reasoning abilities, allowing it to generate traffic that remains compliant and functional. Furthermore, leveraging RL, AdvTG automatically selects traffic fields that exhibit more robust adversarial properties. Experimental results show that AdvTG achieves over 40% attack success rate (ASR) across six detection models on four base datasets and two extended datasets, significantly outperforming other adversarial attack methods.}
}


@inproceedings{DBLP:conf/www/LiCZWLZZY25,
	author = {Zhixun Li and
                  Dingshuo Chen and
                  Tong Zhao and
                  Daixin Wang and
                  Hongrui Liu and
                  Zhiqiang Zhang and
                  Jun Zhou and
                  Jeffrey Xu Yu},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {IceBerg: Debiased Self-Training for Class-Imbalanced Node Classification},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {3160--3170},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714963},
	doi = {10.1145/3696410.3714963},
	timestamp = {Fri, 09 May 2025 20:28:10 +0200},
	biburl = {https://dblp.org/rec/conf/www/LiCZWLZZY25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graph Neural Networks (GNNs) have achieved great success in dealing with non-Euclidean graph-structured data and have been widely deployed in many real-world applications. However, their effectiveness is often jeopardized under class-imbalanced training sets. Most existing studies have analyzed class-imbalanced node classification from a supervised learning perspective, they do not fully utilize the large number of unlabeled nodes in semi-supervised scenarios. We claim that the supervised signal is just the tip of the iceberg and a large number of unlabeled nodes have not yet been effectively utilized. In this work, we propose IceBerg, a debiased self-training framework to address the class-imbalanced and few-shot challenges for GNNs at the same time. Specifically, to figure out the Matthew effect and label distribution shift in self-training, we propose Double Balancing, which can largely improve the performance of existing baselines with just a few lines of code as a simple plug-and-play module. Secondly, to enhance the long-range propagation capability of GNNs, we disentangle the propagation and transformation operations of GNNs. Therefore, the weak supervision signals can propagate more effectively to address the few-shot issue. In summary, we find that leveraging unlabeled nodes can significantly enhance the performance of GNNs in class-imbalanced and few-shot scenarios, and even small, surgical modifications can lead to substantial performance improvements. Systematic experiments on benchmark datasets show that our method can deliver considerable performance gain over existing class-imbalanced node classification baselines. Additionally, due to IceBerg's outstanding ability to leverage unsupervised signals, it also achieves state-of-the-art results in few-shot node classification scenarios. The code of IceBerg is available at: https://github.com/ZhixunLEE/IceBerg.}
}


@inproceedings{DBLP:conf/www/Zhao25,
	author = {Rui Zhao},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Beast in the Cage: {A} Fine-grained and Object-oriented Permission
                  System to Confine JavaScript Operations on the Web},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {3171--3182},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714878},
	doi = {10.1145/3696410.3714878},
	timestamp = {Mon, 05 May 2025 07:55:32 +0200},
	biburl = {https://dblp.org/rec/conf/www/Zhao25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {JavaScript plays a crucial role on web. However, the inclusion of unknown, vulnerable, and malicious scripts on websites and in browser extensions and the use of browsers' developer tools often lead to undesired web content manipulations and data acquisitions. To restrict JavaScript operations on web content and data, we introduce a fine-grained, mandatory access control-based, and object-oriented permission system to browsers. With our system, web developers can define policies for sensitive web elements on their web pages to allow or deny scripts' operations on web content and data within browsers. The system substantially thwarts many web threats and attacks, and offers benefits to personal data governance. We developed a tool for automatic policy generation and demonstrated the usability and compatibility of the system in a three-month study. Our system is a reasonable and practical solution, bolstering the security and trustworthiness on the internet.}
}


@inproceedings{DBLP:conf/www/BianCLX0K25,
	author = {Qingtian Bian and
                  Marcus Vin{\'{\i}}cius de Carvalho and
                  Tieying Li and
                  Jiaxing Xu and
                  Hui Fang and
                  Yiping Ke},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {{ABXI:} Invariant Interest Adaptation for Task-Guided Cross-Domain
                  Sequential Recommendation},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {3183--3192},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714819},
	doi = {10.1145/3696410.3714819},
	timestamp = {Fri, 09 May 2025 20:28:10 +0200},
	biburl = {https://dblp.org/rec/conf/www/BianCLX0K25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cross-Domain Sequential Recommendation (CDSR) has recently gained attention for countering data sparsity by transferring knowledge across domains. A common approach merges domain-specific sequences into cross-domain sequences, serving as bridges to connect domains. One key challenge is to correctly extract the shared knowledge among these sequences and appropriately transfer it. Most existing works directly transfer unfiltered cross-domain knowledge rather than extracting domain-invariant components and adaptively integrating them into domain-specific modelings. Another challenge lies in aligning the domain-specific and cross-domain sequences. Existing methods align these sequences based on timestamps, but this approach can cause prediction mismatches when the current tokens and their targets belong to different domains. In such cases, the domain-specific knowledge carried by the current tokens may degrade performance. To address these challenges, we propose the A-B-Cross-to-Invariant Learning Recommender ( ABXI ). Specifically, leveraging LoRA's effectiveness for efficient adaptation, ABXI incorporates two types of LoRAs to facilitate knowledge adaptation. First, all sequences are processed through a shared encoder that employs a domain LoRA for each sequence, thereby preserving unique domain characteristics. Next, we introduce an invariant projector that extracts domain-invariant interests from cross-domain representations, utilizing an invariant LoRA to adapt these interests into modeling each specific domain. Besides, to avoid prediction mismatches, all domain-specific sequences are aligned to match the domains of the cross-domain ground truths. Experimental results on three datasets demonstrate that our approach outperforms other CDSR counterparts by a large margin. The codes are available in https://github.com/DiMarzioBian/ABXI.}
}


@inproceedings{DBLP:conf/www/0001SG25,
	author = {Guangyi Zhang and
                  Ilie Sarpe and
                  Aristides Gionis},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Efficient and Practical Approximation Algorithms for Advertising in
                  Content Feeds},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {3193--3203},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714902},
	doi = {10.1145/3696410.3714902},
	timestamp = {Fri, 09 May 2025 20:28:10 +0200},
	biburl = {https://dblp.org/rec/conf/www/0001SG25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Content feeds provided by platforms such as X (formerly Twitter) and TikTok are consumed by users on a daily basis. In this paper, we revisit the native advertising problem in content feeds, initiated by Ieong et al. Given a sequence of organic items (e.g., videos or posts) relevant to a user's interests or to an information search, the goal is to place ads within the organic content so as to maximize a reward function (e.g., number of clicks), while accounting for two considerations: (1) an ad can only be inserted after a relevant content item; (2) the users' attention decays after consuming content or ads. These considerations provide a natural model for capturing both the advertisement effectiveness and the user experience. In this paper, we design fast and practical 2-approximation greedy algorithms for the associated optimization problem, improving over the best-known practical algorithm that only achieves an approximation factor of 4. Our algorithms exploit a counter-intuitive observation, namely, while top items are seemingly more important due to the decaying attention of the user, taking good care of the bottom items is key for obtaining improved approximation guarantees. We then provide the first comprehensive empirical evaluation on the problem, showing the strong empirical performance of our~methods.}
}


@inproceedings{DBLP:conf/www/Kyrychenko0BQ25,
	author = {Yara Kyrychenko and
                  Ke Zhou and
                  Edyta Paulina Bogucka and
                  Daniele Quercia},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {{C3AI:} Crafting and Evaluating Constitutions for Constitutional {AI}},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {3204--3218},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714705},
	doi = {10.1145/3696410.3714705},
	timestamp = {Fri, 09 May 2025 20:28:10 +0200},
	biburl = {https://dblp.org/rec/conf/www/Kyrychenko0BQ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Constitutional AI (CAI) guides LLM behavior using constitutions, but identifying which principles are most effective for model alignment remains an open challenge. We introduce the C3AI framework ( Crafting Constitutions for CAI models ), which serves two key functions: (1) selecting and structuring principles to form effective constitutions before fine-tuning; and (2) evaluating whether fine-tuned CAI models follow these principles in practice. By analyzing principles from AI and psychology, we found that positively framed, behavior-based principles align more closely with human preferences than negatively framed or trait-based principles. In a safety alignment use case, we applied a graph-based principle selection method to refine an existing CAI constitution, improving safety measures while maintaining strong general reasoning capabilities. Interestingly, fine-tuned CAI models performed well on negatively framed principles but struggled with positively framed ones, in contrast to our human alignment results. This highlights a potential gap between principle design and model adherence. Overall, C3AI provides a structured and scalable approach to both crafting and evaluating CAI constitutions.}
}


@inproceedings{DBLP:conf/www/WangHBCDA25,
	author = {Tingting Wang and
                  Shixun Huang and
                  Zhifeng Bao and
                  J. Shane Culpepper and
                  Volkan Dedeoglu and
                  Reza Arablouei},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Distinctiveness Maximization in Datasets Assemblage},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {3219--3232},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714830},
	doi = {10.1145/3696410.3714830},
	timestamp = {Fri, 09 May 2025 20:28:10 +0200},
	biburl = {https://dblp.org/rec/conf/www/WangHBCDA25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, given a user's query set and budget, we aim to use the limited budget to help users assemble a set of datasets that can enrich a base dataset by introducing the maximum number of distinct tuples (i.e., maximizing distinctiveness). We prove this problem to be NP-hard. A greedy algorithm using exact distinctiveness computation attains an approximation ratio of (1-e -1  )/2, but it lacks efficiency and scalability due to its frequent computation of the exact distinctiveness marginal gain of any candidate dataset for selection. This requires scanning through every tuple in candidate datasets and thus is unaffordable in practice. To overcome this limitation, we propose an efficient machine learning (ML)-based method for estimating the distinctiveness marginal gain of any candidate dataset. This effectively eliminates the need to test each tuple individually. Estimating the distinctiveness marginal gain of a dataset involves estimating the number of distinct tuples in the tuple sets returned by each query in a query set across multiple datasets. This can be viewed as the cardinality estimation for a query set on a set of datasets, and the proposed method is the first to tackle this cardinality estimation problem. This is a significant advancement over prior methods that were limited to single-query cardinality estimation on a single dataset and struggled with identifying overlaps among tuple sets returned by each query in a query set across multiple datasets. Extensive experiments using five real-world data pools demonstrate that our algorithm, which utilizes ML-based distinctiveness estimation, outperforms all relevant baselines in effectiveness, efficiency, and scalability. A case study on two downstream ML tasks also highlights its potential to find datasets with more useful tuples to enhance the performance of ML tasks.}
}


@inproceedings{DBLP:conf/www/Ananthasubramaniam25,
	author = {Aparna Ananthasubramaniam and
                  Yufei 'Louise' Zhu and
                  David Jurgens and
                  Daniel M. Romero},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Roles of Network and Identity in Hashtag Diffusion},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {3233--3246},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714716},
	doi = {10.1145/3696410.3714716},
	timestamp = {Fri, 09 May 2025 20:28:10 +0200},
	biburl = {https://dblp.org/rec/conf/www/Ananthasubramaniam25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The diffusion of culture online is theorized to be influenced by many interacting social factors (e.g., network and identity). However, most existing computational cascade models consider just a single factor (e.g., network or identity). This work offers a new framework for teasing apart the mechanisms underlying hashtag cascades. We curate a new dataset of 1,337 hashtags representing cultural innovation online, develop a 10-factor evaluation framework for comparing empirical and simulated cascades, and show that a combined network+identity model better simulates hashtag cascades than network- or identity-only counterfactuals. We also explore heterogeneity in performance: While a combined network+identity model best predicts the popularity of cascades, a network-only model best predicts cascade growth and an identity-only model best predicts adopter composition. The network+identity model has the highest comparative advantage among hashtags used for expressing racial or regional identity and talking about sports or news. In fact, we are able to predict what combination of network and/or identity best models each hashtag and use this to further improve performance. Our results show the utility of models incorporating the interactions of network, identity, and other social factors in the diffusion of hashtags in social media.}
}


@inproceedings{DBLP:conf/www/CaiJZ0CCS0H025,
	author = {Ruichu Cai and
                  Zhifan Jiang and
                  Kaitao Zheng and
                  Zijian Li and
                  Weilin Chen and
                  Xuexin Chen and
                  Yifan Shen and
                  Guangyi Chen and
                  Zhifeng Hao and
                  Kun Zhang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Learning Disentangled Representation for Multi-Modal Time-Series Sensing
                  Signals},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {3247--3266},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714931},
	doi = {10.1145/3696410.3714931},
	timestamp = {Sun, 15 Jun 2025 20:53:29 +0200},
	biburl = {https://dblp.org/rec/conf/www/CaiJZ0CCS0H025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Multi-modal time series data is common in web technologies like the Internet of Things (IoT). Existing methods for multi-modal time series representation learning aim to disentangle the modality-shared and modality-specific latent variables. Although achieving notable performances on downstream tasks, they usually assume an orthogonal latent space. However, the modality-specific and modality-shared latent variables might be dependent on real-world scenarios. Therefore, we propose a general generation process, where the modality-shared and modality-specific latent variables are dependent, and further develop a  M ulti-mod A l  TE mporal Disentanglement ( MATE ) model. Specifically, our  MATE  model is built on a temporally variational inference architecture with the modality-shared and modality-specific prior networks for the disentanglement of latent variables. Furthermore, we establish identifiability results to show that the extracted representation is disentangled. More specifically, we first achieve the subspace identifiability for modality-shared and modality-specific latent variables by leveraging the pairing of multi-modal data. Then we establish the component-wise identifiability of modality-specific latent variables by employing sufficient changes of historical latent variables. Extensive experimental studies on 12 datasets show a general improvement in different downstream tasks, highlighting the effectiveness of our method in real-world scenarios.}
}


@inproceedings{DBLP:conf/www/LiuQM0W0ZDZB25,
	author = {Yuwen Liu and
                  Lianyong Qi and
                  Xingyuan Mao and
                  Weiming Liu and
                  Fan Wang and
                  Xiaolong Xu and
                  Xuyun Zhang and
                  Wanchun Dou and
                  Xiaokang Zhou and
                  Amin Beheshti},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Hyperbolic Variational Graph Auto-Encoder for Next {POI} Recommendation},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {3267--3275},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714804},
	doi = {10.1145/3696410.3714804},
	timestamp = {Fri, 09 May 2025 20:28:10 +0200},
	biburl = {https://dblp.org/rec/conf/www/LiuQM0W0ZDZB25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Next Point-of-Interest (POI) recommendation has become a crucial task in Location-Based Social Networks (LBSNs), which provide personalized recommendations by predicting the user's next check-in locations. Commonly used models including Recurrent Neural Networks (RNNs) and Graph Convolutional Networks (GCNs) have been widely explored. However, these models face significant challenges, including the difficulty of capturing the hierarchical and tree-like structure of POIs in Euclidean space and the sparsity problem inherent in POI recommendations. To address these challenges, we propose a Hyperbolic Variational Graph Auto-Encoder (HVGAE) for next POI recommendation. Specifically, we utilize a Hyperbolic Graph Convolutional Network (Hyperbolic GCN) to model hierarchical structures and tree-like relationships by converting node embeddings from euclidean space to hyperbolic space. Then we use Variational Graph Auto-Encoder (VGAE) to convert node embeddings to probabilistic distributions, enhancing the capture of deeper latent features and providing a more robust model structure. Furthermore, we combine the Mamba4Rec recommender and Rotary Position Embedding (RoPE) and propose Rotary Position Mamba (RPMamba) to effectively utilize POI embeddings rich in sequential information, which improves the accuracy of the next POI recommendation. Extensive experiments on three public datasets demonstrate the superior performance of the HVGAE model.}
}


@inproceedings{DBLP:conf/www/LiYLL25,
	author = {Guoming Li and
                  Jian Yang and
                  Shangsong Liang and
                  Dongsheng Luo},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Polynomial Selection in Spectral Graph Neural Networks: An Error-Sum
                  of Function Slices Approach},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {3276--3287},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714760},
	doi = {10.1145/3696410.3714760},
	timestamp = {Fri, 09 May 2025 20:28:10 +0200},
	biburl = {https://dblp.org/rec/conf/www/LiYLL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Spectral graph neural networks are proposed to harness spectral information inherent in graph-structured data through the application of polynomial-defined graph filters, recently achieving notable success in graph-based web applications. Existing studies reveal that various polynomial choices greatly impact spectral GNN performance, underscoring the importance of polynomial selection. However, this selection process remains a critical and unresolved challenge. Although prior work suggests a connection between the approximation capabilities of polynomials and the efficacy of spectral GNNs, there is a lack of theoretical insights into this relationship, rendering polynomial selection a largely heuristic process. To address the issue, this paper examines polynomial selection from an error-sum of function slices perspective. Inspired by the conventional signal decomposition, we represent graph filters as a sum of disjoint function slices. Building on this, we then bridge the polynomial capability and spectral GNN efficacy by proving that the construction error of graph convolution layer is bounded by the sum of polynomial approximation errors on function slices. This result leads us to develop an advanced filter based on trigonometric polynomials, a widely adopted option for approximating narrow signal slices. The proposed filter remains provable parameter efficiency, with a novel Taylor-based parameter decomposition that achieves streamlined, effective implementation. With this foundation, we propose TFGNN, a scalable spectral GNN operating in a decoupled paradigm. We validate the efficacy of TFGNN via benchmark node classification tasks, along with an example graph anomaly detection application to show its practical utility.}
}


@inproceedings{DBLP:conf/www/LiLLZ25,
	author = {Jiecheng Li and
                  Xudong Luo and
                  Guangquan Lu and
                  Shichao Zhang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Hyper-Relational Knowledge Representation Learning with Multi-Hypergraph
                  Disentanglement},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {3288--3299},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714907},
	doi = {10.1145/3696410.3714907},
	timestamp = {Tue, 13 May 2025 07:31:05 +0200},
	biburl = {https://dblp.org/rec/conf/www/LiLLZ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Hyper-relational knowledge graphs (HKGs) extend the traditional triplet-based knowledge graph by adding qualifiers to the relationships, making HKGs particularly useful for tasks that require more profound understanding and inference from relationships between entities. However, existing hyper-relational knowledge representation learning methods (HKRL) focus on direct neighbourhood information of entities only by neglecting the relational similarity of the main triple in hyper-relational facts and the attribute details in the qualifiers. In addition, few works extract common and private information across multiple views to minimize noise and interference. This paper proposes a multi-hypergraph disentanglement method for HKRL to address the above issues. Specifically, we first construct four hypergraphs to mine and utilise the inherent structure information of HKGs, and then propose to extract common representations among hypergraphs and private representations within individual hypergraphs to mine the semantic information and the task-relevant information, respectively. Experiment results on four real datasets demonstrate the effectiveness of the proposed method compared to SOTA methods in link prediction tasks on HKGs.}
}


@inproceedings{DBLP:conf/www/KongZG0W25,
	author = {Fanshuang Kong and
                  Richong Zhang and
                  Xiaohui Guo and
                  Junfan Chen and
                  Ziqiao Wang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Preserving Label Correlation for Multi-label Text Classification by
                  Prototypical Regularizations},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {3300--3310},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714797},
	doi = {10.1145/3696410.3714797},
	timestamp = {Fri, 09 May 2025 20:28:10 +0200},
	biburl = {https://dblp.org/rec/conf/www/KongZG0W25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Multi-label text classification (MLTC) assigns multiple labels to a sentence, with the key challenge being capturing label correlations. Existing models prioritize leveraging correlations but often overlook overfitting, while plug-and-play regularization methods fail to preserve correlations effectively. In this paper, we distinguish two types of label correlations: explicit co-occurring correlations and implicit semantic correlations, and propose regularizations on prototypical label embeddings for correlation preservation. Specifically, we first generate the prototypical embedding of multiple co-occurred labels as an intermediate. We then apply a prototypical regularization on the distance between the sentence embedding and corresponding prototypical embedding to alleviate the over-alignment issue caused by binary cross entropy loss and facilitate explicit correlation preservation. We finally extend the vanilla Mixup, which solely mixes multi-hot labels, on prototypical embedding mixing to promote implicit correlation preservation. Empirical studies show the effectiveness of our regularization methods.}
}


@inproceedings{DBLP:conf/www/WuHHF025,
	author = {Xiao Wu and
                  Junzhou He and
                  Liyan Huang and
                  Cai Fu and
                  Weihang Wang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {WBSan: WebAssembly Bug Detection for Sanitization and Binary-Only
                  Fuzzing},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {3311--3322},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714622},
	doi = {10.1145/3696410.3714622},
	timestamp = {Fri, 09 May 2025 20:28:10 +0200},
	biburl = {https://dblp.org/rec/conf/www/WuHHF025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the advancement of WebAssembly, abbreviated as Wasm, various memory bugs and undefined behaviors have emerged, leading to security issues that affect usability and portability. Existing methods struggle to detect these problems in Wasm binaries due to challenges associated with binary instrumentation and the difficulty of defining legal memory bounds.While sanitizers combined with fuzzing are recognized as effective means for identifying bugs, current Wasm sanitizers necessitate compile-time instrumentation, rendering them unsuitable for practical scenarios where only binaries are accessible. In this paper, we propose WBSan, the first Wasm binary sanitizer employing static analysis and Wasm binary instrumentation to detect memory bugs and undefined behaviors. We develop distinct instrumentation patterns tailored for each type of bug and introduce  Wasm shadow memory  to address complex memory bugs. Our results reveal that WBSan achieves a 16.8% false detection rate, outperforming current Wasm binary checkers and native sanitizers in detecting memory bugs and undefined behaviors. Furthermore, when compared with the binary-only fuzzer, WBSan uncovers more crashes and achieves greater code coverage.}
}


@inproceedings{DBLP:conf/www/ZhuWSLFKL25,
	author = {Yaochen Zhu and
                  Chao Wan and
                  Harald Steck and
                  Dawen Liang and
                  Yesu Feng and
                  Nathan Kallus and
                  Jundong Li},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Collaborative Retrieval for Large Language Model-based Conversational
                  Recommender Systems},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {3323--3334},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714908},
	doi = {10.1145/3696410.3714908},
	timestamp = {Fri, 09 May 2025 20:28:10 +0200},
	biburl = {https://dblp.org/rec/conf/www/ZhuWSLFKL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Conversational recommender systems (CRS) aim to provide personalized recommendations via interactive dialogues with users. While large language models (LLMs) enhance CRS with their superior understanding of context-aware user preferences, they typically struggle to leverage behavioral data, which have proven to be important for classical collaborative filtering (CF)-based approaches. For this reason, we propose CRAG-Collaborative Retrieval Augmented Generation for LLM-based CRS. To the best of our knowledge, CRAG is the first approach that combines state-of-the-art LLMs with CF for conversational recommendations. Our experiments on two publicly available movie conversational recommendation datasets, i.e., a refined Reddit dataset (which we name Reddit-v2) as well as the Redial dataset, demonstrate the superior item coverage and recommendation performance of CRAG, compared to several CRS baselines. Moreover, we observe that the improvements are mainly due to better recommendation accuracy on recently released movies. The code and data are available at https://github.com/yaochenzhu/CRAG.}
}


@inproceedings{DBLP:conf/www/GkatzelisML25,
	author = {Vasilis Gkatzelis and
                  Randolph Preston McAfee and
                  Renato Paes Leme},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Procurement Auctions with Best and Final Offers},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {3335--3343},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714709},
	doi = {10.1145/3696410.3714709},
	timestamp = {Fri, 09 May 2025 20:28:10 +0200},
	biburl = {https://dblp.org/rec/conf/www/GkatzelisML25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We study sequential procurement auctions where the sellers are provided with a ''best and final offer'' (BAFO) strategy. This strategy allows each seller  i  to effectively ''freeze'' their price while remaining active in the auction, and it signals to the buyer, as well as all other sellers, that seller  i  would reject any price lower than that. This is in contrast to prior work, e.g., on descending auctions, where the options provided to each seller are to either accept a price reduction or reject it and drop out. As a result, the auctions that we consider induce different extensive form games and our goal is to study the subgame perfect equilibria of these games. We focus on settings involving multiple sellers who have full information regarding each other's cost (i.e., the minimum price that they can accept) and a single buyer (the auctioneer) who has no information regarding these costs. Our main result shows that the auctions enhanced with the BAFO strategy can guarantee efficiency in every subgame perfect equilibrium, even if the buyer's valuation function is an arbitrary monotone function. This is in contrast to prior work which required that the buyer's valuation satisfies restrictive properties, like gross substitutes, to achieve efficiency. We then also briefly analyze the seller's cost in the subgame perfect equilibria of these auctions and we show that even if the auctions all return the same outcome, the cost that they induce for the buyer can vary significantly.}
}


@inproceedings{DBLP:conf/www/JradehRDLSTT25,
	author = {Chlo{\'{e}} Khadija Jradeh and
                  Ensiyeh Raoufi and
                  J{\'{e}}r{\^{o}}me David and
                  Pierre Larmande and
                  Fran{\c{c}}ois Scharffe and
                  Konstantin Todorov and
                  C{\'{a}}ssia Trojahn},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Graph Embeddings Meet Link Keys Discovery for Entity Matching},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {3344--3353},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714581},
	doi = {10.1145/3696410.3714581},
	timestamp = {Fri, 04 Jul 2025 22:10:06 +0200},
	biburl = {https://dblp.org/rec/conf/www/JradehRDLSTT25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Entity Matching (EM) automates the discovery of identity links between entities within different Knowledge Graphs (KGs). Link keys are crucial for EM, serving as rules allowing to identify identity links across different KGs, possibly described using different ontologies. However, the approach for extracting link keys struggles to scale on large KGs. While embedding-based EM methods efficiently handle large KGs they lack explainability. This paper proposes a novel hybrid EM approach to guarantee the scalability link key extraction approach and improve the explainability of embedding-based EM methods. First, embedding-based EM approaches are used to sample the KGs based on the identity links they generate, thereby reducing the search space to relevant sub-graphs for link key extraction. Second, rules (in the form of link keys) are extracted to explain the generation of identity links by the embedding-based methods. Experimental results demonstrate that the proposed approach allows link key extraction to scale on large KGs, preserving the quality of the extracted link keys. Additionally, it shows that link keys can improve the explainability of the identity links generated by embedding-methods, allowing for the regeneration of 77% of the identity links produced for a specific EM task, thereby providing an approximation of the reasons behind their generation.}
}


@inproceedings{DBLP:conf/www/WilkSMM25,
	author = {Brian Wilk and
                  Homaira Huda Shomee and
                  Suman Kalyan Maity and
                  Sourav Medya},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Fact-based Counter Narrative Generation to Combat Hate Speech},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {3354--3365},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714718},
	doi = {10.1145/3696410.3714718},
	timestamp = {Fri, 09 May 2025 20:28:10 +0200},
	biburl = {https://dblp.org/rec/conf/www/WilkSMM25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Online hatred has become an increasingly pervasive issue, affecting individuals and communities across various digital platforms. To combat hate speech in such platforms, counter narratives (CNs) are regarded as an effective method. In recent years, there has been growing interest in using generative AI tools to construct CNs. However, most of the generative models produce generic responses to hate speech and can hallucinate, reducing their effectiveness. To address the above limitations, we propose a counter narrative generation method that enhances CNs by providing non-aggressive, fact-based narratives with relevant background knowledge from two distinct sources, including a web search module. Furthermore, we conduct a comprehensive evaluation using multiple metrics, including LLM-based measures for persuasion, factuality, and informativeness, along with human and traditional NLP evaluations. Our method significantly outperforms baselines, achieving an average factuality score of 0.915, compared to 0.741, 0.701, and 0.69 for competitive baselines, and performs well in human evaluations.}
}


@inproceedings{DBLP:conf/www/Li0025,
	author = {Zitong Li and
                  Qingqing Ye and
                  Haibo Hu},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {{FUNU:} Boosting Machine Unlearning Efficiency by Filtering Unnecessary
                  Unlearning},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {3366--3376},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714711},
	doi = {10.1145/3696410.3714711},
	timestamp = {Fri, 09 May 2025 20:28:10 +0200},
	biburl = {https://dblp.org/rec/conf/www/Li0025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Machine unlearning is an emerging field that selectively removes specific data samples from a trained model. This capability is crucial for addressing privacy concerns, complying with data protection regulations, and correcting errors or biases introduced by certain data. Unlike traditional machine learning, where models are typically static once trained, machine unlearning facilitates dynamic updates that enable the model to ''forget'' information without requiring complete retraining from scratch. There are various machine unlearning methods, some of which are more time-efficient when data removal requests are fewer. To decrease the execution time of such machine unlearning methods, we aim to reduce the size of data removal requests based on the fundamental assumption that the removal of certain data would not result in a distinguishable retrained model. We first propose the concept of unnecessary unlearning, which indicates that the model would not alter noticeably after removing some data points. Subsequently, we review existing solutions that can be used to solve our problem. We highlight their limitations in adaptability to different unlearning scenarios and their reliance on manually selected parameters. We consequently put forward FUNU, a method to identify data points that lead to unnecessary unlearning. FUNU circumvents the limitations of existing solutions. The idea is to discover data points within the removal requests that have similar neighbors in the remaining dataset. We utilize a reference model to set parameters for finding neighbors, inspired from the area of model memorization. We provide a theoretical analysis of the privacy guarantee offered by FUNU and conduct extensive experiments to validate its efficacy.}
}


@inproceedings{DBLP:conf/www/GaoSY025,
	author = {Hepeng Gao and
                  Yijun Su and
                  Funing Yang and
                  Yongjian Yang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Fine-Grained Data Inference via Incomplete Multi-Granularity Data},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {3377--3388},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714628},
	doi = {10.1145/3696410.3714628},
	timestamp = {Fri, 09 May 2025 20:28:10 +0200},
	biburl = {https://dblp.org/rec/conf/www/GaoSY025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Urban fine-grained data map inference, leveraging information from coarse-grained maps, has emerged as a significant area of research due to the growing complexity and data heterogeneity in urban environments. Existing methods have a priori assumption that a coarse-grained data map, one fixed-size granularity, transforms into a fine-grained data map, also one fixed-size granularity. However, in actual scenarios, the collected coarse-grained data maps are often incomplete and have significantly distinct granularities in various urban areas, which results in incomplete heterogeneous data, i.e., multi-granularity data maps in terms of spatial information. Meanwhile, different granularity data maps are needed for various urban downstream tasks, which is a multi-task problem. To that end, this paper proposes a novel framework, a multi-granularity super-resolution data map inference framework (MGSR), designed to harness spatio-temporal information to transform incomplete coarse-grained multi-granularity data maps into fine-grained multi-granularity data maps. Specifically, we design a granularity alignment network to align multi-granularity information and address missing data on each granularity data map by leveraging the other granularity data maps with a well-designed self-supervised task. Then, we introduce a feature extraction network to capture spatio-temporal dependencies and extract features. Finally, we devise a recurrent super-resolution network with shared parameters to infer multi-granularity data maps. We conduct extensive experiments on three real-world benchmark datasets and demonstrate that MGSR significantly outperforms the state-of-the-art methods for multi-granularity urban data map inference and reduces RMSE and MAE by up to 40.1% and 50.3%, respectively. The source code has been released at https://github.com/wn13/MGSR\\_code.}
}


@inproceedings{DBLP:conf/www/WangLHM25,
	author = {Hongyu Wang and
                  Ying Li and
                  Ronghong Huang and
                  Xianghang Mi},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Detecting and Understanding the Promotion of Illicit Goods and Services
                  on Twitter},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {3389--3404},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714550},
	doi = {10.1145/3696410.3714550},
	timestamp = {Fri, 09 May 2025 20:28:10 +0200},
	biburl = {https://dblp.org/rec/conf/www/WangLHM25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this study, we reveal, for the first time, popular online social networks (especially Twitter) are being extensively abused by miscreants to promote illicit goods and services of diverse categories. This study is made possible by multiple machine learning tools that are designed to detect and analyze Posts of Illicit Promotion (PIPs) as well as revealing their underlying promotion campaigns. Particularly, we observe that PIPs are prevalent on Twitter, along with extensive visibility on other three popular OSNs including YouTube, Facebook, and TikTok. For instance, applying our PIP hunter to the Twitter platform for 6 months has led to the discovery of 12 million distinct PIPs which are widely distributed in 5 major natural languages and 10 illicit categories, e.g., drugs, data leakage, gambling, and weapon sales. Along the discovery of PIPs are 580K Twitter accounts publishing PIPs as well as 37K distinct instant messaging accounts that are embedded in PIPs and serve as next hops of communication with prospective customers. Also, an arms race between Twitter and illicit promotion operators is also observed. Especially, 90% PIPs can survice the first two months since getting published on Twitter, which is likely due to the diverse evasion tactics adopted by miscreants to masquerade PIPs.}
}


@inproceedings{DBLP:conf/www/QuanXGJ00025,
	author = {Lili Quan and
                  Xiaofei Xie and
                  Qianyu Guo and
                  Lingxiao Jiang and
                  Sen Chen and
                  Junjie Wang and
                  Xiaohong Li},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {TensorJSFuzz: Effective Testing of Web-Based Deep Learning Frameworks
                  via Input-Constraint Extraction},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {3405--3414},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714649},
	doi = {10.1145/3696410.3714649},
	timestamp = {Fri, 09 May 2025 20:28:10 +0200},
	biburl = {https://dblp.org/rec/conf/www/QuanXGJ00025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As web applications grow in popularity, developers are increasingly integrating deep learning (DL) models into these environments. Web-based DL frameworks (e.g., TensorFlow.js) are essential for building and deploying such applications. Therefore, ensuring the quality of these frameworks is critical. While extensive testing efforts have been made for native DL frameworks such as TensorFlow and PyTorch, web-based DL frameworks have not yet undergone systematic testing. A key challenge is generating syntactically and semantically valid inputs while designing effective test oracles for web environments. To address this, we introduce TensorJSFuzz, a novel method for testing web-based DL frameworks. To ensure input quality, TensorJSFuzz extracts constraints directly from the source code of DL operators. By leveraging Large Language Models (e.g., ChatGPT) to understand the code and extract input constraints, TensorJSFuzz performs type-aware random generation coupled with dependency-aware refinement to create high-quality test inputs. These inputs are then subjected to differential testing across various backends, including CPU, TensorFlow, Wasm, and WebGL. Our experimental results show that TensorJSFuzz outperforms all baselines in generating valid inputs and identifying bugs. In particular, TensorJSFuzz successfully detected 92 bugs, with 30 already confirmed or fixed by developers, demonstrating its effectiveness in improving the robustness of web-based DL frameworks.}
}


@inproceedings{DBLP:conf/www/HeZC0WGT25,
	author = {Chengkun He and
                  Xiangmin Zhou and
                  Yurong Cheng and
                  Jie Shao and
                  Guoren Wang and
                  Iqbal Gondal and
                  Zahir Tari},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Motivation-Aware Session Planning over Heterogeneous Social Platforms},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {3415--3425},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714942},
	doi = {10.1145/3696410.3714942},
	timestamp = {Fri, 09 May 2025 20:28:10 +0200},
	biburl = {https://dblp.org/rec/conf/www/HeZC0WGT25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the explosive growth of online service platforms, an increasing number of people and enterprises are undertaking personal and professional tasks online. In real applications such as trip planning and online marketing, planning sessions for a sequence of activities or services will enable social users to receive the optimal services, improving their experience and reducing the cost of their activities. These online platforms are heterogeneous, including different types of services with different attributes. However, the problem of session planning over heterogeneous platforms has not been studied so far. In this paper, we propose a Motivation-Aware Session Planning (MASP) framework for session planning over heterogeneous social platforms. Specifically, we first propose a novel HeterBERT model to handle the heterogeneity of items at both type and attribute levels. Then, we propose to predict user preference using the motivations behind user activities. Finally, we propose an algorithm together with its optimisations for efficient session generation. The extensive tests prove the high effectiveness and efficiency of MASP.}
}


@inproceedings{DBLP:conf/www/Ding00S25,
	author = {Zhongjun Ding and
                  Ke Li and
                  Lisi Chen and
                  Shuo Shang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Parallel Online Similarity Join over Trajectory Streams},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {3426--3437},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714945},
	doi = {10.1145/3696410.3714945},
	timestamp = {Fri, 09 May 2025 20:28:10 +0200},
	biburl = {https://dblp.org/rec/conf/www/Ding00S25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Trajectory Similarity Join (TS-Join), as a fundamental operation in trajectory data analytics, has been extensively investigated by existing studies in data science. However, existing solutions are almost designed for offline static trajectories, which cannot ensure real-time feedback. In addition, the join results retrieved from existing solutions generally contain a large proportion of outdated similar pairs, making them inapplicable to evolving trajectories. In this light, we study a novel problem of online time-aware trajectory similarity join: Given a stream of evolving trajectories, we aim to dynamically discover trajectory pairs whose spatio-temporal similarity is no less than a specified threshold in a real-time manner. We innovatively introduce a time-aware exponential-decaying similarity function to eliminate outdated results. To support real-time querying over large populations of trajectories, we develop a Parallel Online Trajectory Similarity Join (POTSJ) framework with workload balancing techniques. We further enhance join efficiency through pruning strategies and tailored approximation techniques. The POTSJ framework we propose, which incorporates these elements, is capable of processing online TS-Join while simultaneously satisfying three key objectives: real-time result updates, comprehensive trajectory evaluation, and scalability. Extensive experiments on real-world datasets validate the efficiency and scalability of our POTSJ framework in processing online TS-Join.}
}


@inproceedings{DBLP:conf/www/Ahmat0Y00LMW25,
	author = {Ahtamjan Ahmat and
                  Lei Wang and
                  Yating Yang and
                  Bo Ma and
                  Rui Dong and
                  Kaiwen Lu and
                  Rong Ma and
                  Xinyue Wang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {M\({}^{\mbox{2}}\)-VLP: Enhancing Multilingual Vision-Language Pre-Training
                  via Multi-Grained Alignment},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {3438--3450},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714861},
	doi = {10.1145/3696410.3714861},
	timestamp = {Fri, 09 May 2025 20:28:10 +0200},
	biburl = {https://dblp.org/rec/conf/www/Ahmat0Y00LMW25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recently, multilingual Vision-Language Pre-training (mVLP) has shown remarkable progress in learning joint representations across different modalities and languages. However, most existing methods learn semantic alignment at a coarse-grained level and fail to capture fine-grained correlations between different languages and modalities. To address this, we propose a  M ulti-grained  M ultilingual  V ision-Language  P re-training (M 2 -VLP) model, which aims to learn cross-lingual cross-modal alignment at different semantic granular levels. In cross-lingual interaction, the model learns the global alignment of parallel sentence pairs and the word-level correlations. In cross-modal interaction, the model aligns images with captions and image regions with corresponding words. To integrate the cross-lingual and cross-modal alignment above, we propose a unified multi-grained contrastive learning paradigm. Under zero-shot cross-lingual and fine-tuned multilingual settings, extensive experiments on vision-language downstream tasks across twenty languages demonstrate the effectiveness of M2-VLP over competitive contrastive models. Code and models are available at https://github.com/ahtamjan/M2-VLP.}
}


@inproceedings{DBLP:conf/www/LundyRKL25,
	author = {Taylor Lundy and
                  Narun K. Raman and
                  Scott Duke Kominers and
                  Kevin Leyton{-}Brown},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {NFTs as a Data-Rich Test Bed: Conspicuous Consumption and its Determinants},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {3451--3465},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714724},
	doi = {10.1145/3696410.3714724},
	timestamp = {Fri, 09 May 2025 20:28:10 +0200},
	biburl = {https://dblp.org/rec/conf/www/LundyRKL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Conspicuous consumption occurs when a consumer derives value from a good based on its social meaning as a signal of wealth, taste, and/or community affiliation. Common conspicuous goods include designer footwear, country club memberships, and artwork; conspicuous goods also exist in the digital sphere, with non-fungible tokens (NFTs) as a prominent example. The NFT market merits deeper study for two key reasons: first, it is poorly understood relative to its economic scale; and second, it is unusually amenable to analysis because NFT transactions are publicly available on the blockchain, making them useful as a test bed for conspicuous consumption dynamics. This paper introduces a model that incorporates two previously identified elements of conspicuous consumption: the  bandwagon effect  (goods increase in value as they become more popular) and the  snob effect  (goods increase in value as they become rarer). Our model resolves the apparent tension between these two effects, exhibiting net complementarity between others' and one's own conspicuous consumption. We also introduce a novel dataset combining NFT transactions with embeddings of the corresponding NFT images computed using an off-the-shelf vision transformer architecture. We use our dataset to validate the model, showing that the bandwagon effect raises an NFT collection's value as more consumers join, while the snob effect drives consumers to seek rarer NFTs within a given collection.}
}


@inproceedings{DBLP:conf/www/0025XYDK00YX025,
	author = {Qian Wang and
                  Xuanzhi Xia and
                  Zongjun Yang and
                  Xiaotie Deng and
                  Yuqing Kong and
                  Zhilin Zhang and
                  Liang Wang and
                  Chuan Yu and
                  Jian Xu and
                  Bo Zheng},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Learning against Non-credible Second-Price Auctions},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {3466--3480},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714847},
	doi = {10.1145/3696410.3714847},
	timestamp = {Fri, 09 May 2025 20:28:10 +0200},
	biburl = {https://dblp.org/rec/conf/www/0025XYDK00YX025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The standard framework of online bidding algorithm design assumes that the seller commits himself to faithfully implementing the rules of the adopted auction. However, the seller may attempt to cheat in execution to increase his revenue if the auction belongs to the class of non-credible auctions. For example, in a second-price auction, the seller could create a fake bid between the highest bid and the second highest bid. This paper focuses on one such case of online bidding in repeated second-price auctions. At each time  t , the winner with bid b t  is charged not the highest competing bid d t  but a manipulated price p t  = α 0  d t  + (1-α 0 ) b t , where the parameter α 0  ∈ [0, 1] in essence measures the seller's credibility. Unlike classic repeated-auction settings where the bidder has access to samples (d s ) s=1 t-1 , she can only receive mixed signals of (b s ) s=1 t-1 , (d s ) s=1 t-1  and α 0  in this problem. The task for the bidder is to learn not only the bid distributions of her competitors but also the seller's credibility. We establish regret lower bounds in various information models and provide corresponding online bidding algorithms that can achieve near-optimal performance. Specifically, we consider three cases of prior information based on whether the credibility α 0  and the distribution of the highest competing bids are known. Our goal is to characterize the landscape of online bidding in non-credible second-price auctions and understand the impact of the seller's credibility on online bidding algorithm design under different information structures.}
}


@inproceedings{DBLP:conf/www/SuiZ0ZY25,
	author = {Xuhui Sui and
                  Ying Zhang and
                  Yu Zhao and
                  Baohang Zhou and
                  Xiaojie Yuan},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Multimodal Knowledge Graph Error Detection with Disentanglement {VAE}
                  and Multi-Grained Triplet Confidence},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {3481--3491},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714813},
	doi = {10.1145/3696410.3714813},
	timestamp = {Fri, 09 May 2025 20:28:10 +0200},
	biburl = {https://dblp.org/rec/conf/www/SuiZ0ZY25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Multimodal knowledge graphs inevitably contain numerous errors due to the lack of human supervision in their automated construction and updating processes. These errors can significantly degrade the performance of downstream applications that rely on them. Existing researches on knowledge graph error detection primarily focus on leveraging graph structural and textual information to identify triplet errors in unimodal knowledge graphs. However, unlike unimodal knowledge graphs, multimodal knowledge graphs also suffer from mismatches between images and their corresponding entities, referred to as modality errors. These modality errors not only hinder the performance of downstream applications but also impede our effective utilization of the abundant complementary information provided by the visual modality for detecting triplet errors. To this end, we introduce a novel task of multimodal knowledge graph error detection (MKGED) in this paper, aiming at simultaneously identifying both modality errors and triplet errors. Given the lack of datasets for evaluating this task, we first establish two comprehensive MKGED datasets. Furthermore, we propose a novel framework, KGDMC, to address the MKGED task. Within KGDMC, we devise a disentanglement modality reconstruction (DMR) module for modality error detection. This module disentangles each original modality representation into two disjoint components: modality-specific representations and modality-invariant representations, leveraging the cross-modality reconstruction process to detect mismatched visual modalities. Additionally, for the triplet error detection, we propose a multi-grained triplet confidence (MTC) module, incorporating local triplet confidence, global structure confidence, and global path confidence, to collaboratively detect mismatched triplets. Extensive experiments on our constructed two datasets demonstrate the superiority of our proposed framework.}
}


@inproceedings{DBLP:conf/www/GaoWCCYZ25,
	author = {Jianqi Gao and
                  Hao Wu and
                  Yiu{-}ming Cheung and
                  Jian Cao and
                  Hang Yu and
                  Yonggang Zhang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Mitigating Forgetting in Adapting Pre-trained Language Models to Text
                  Processing Tasks via Consistency Alignment},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {3492--3504},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714687},
	doi = {10.1145/3696410.3714687},
	timestamp = {Sun, 06 Jul 2025 13:23:29 +0200},
	biburl = {https://dblp.org/rec/conf/www/GaoWCCYZ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {There are a large number of text processing tasks in web applications, such as sentiment classification, summary extraction, and question answering. Recently, fine-tuning pre-trained language models (PLMs) to adapt to downstream text-processing tasks has attracted much attention. However, due to the differences in data, model, and tasks between the pre-training and fine-tuning processes, the fine-tuning process may suffer from catastrophic forgetting of pre-training knowledge, which may implicitly limit the model's performance and generalization ability. To address these challenges, we propose a novel dual-model framework, termed as  co nsistency  a l i gnment (CoAi). The insight of CoAi lies in building an auxiliary model that simulates the distribution of pre-training knowledge in real-time according to the current task, and co-training the task-specific model and the auxiliary model to balance the pre-training knowledge and task-specific knowledge during fine-tuning. Specifically, the auxiliary model is constructed on-the-fly to maintain the pre-training knowledge. Subsequently, CoAi simulates the pre-training process by performing distributional exploration in the parameter space, which is built upon our novel insight into the transformation between data and model parameter space. However, the objectives leveraged to construct the auxiliary model lead to the misalignment between the pre-training and task-specific knowledge. To alleviate the inconsistency, we employ an auxiliary variable to align the prediction distribution of the task-specific and the auxiliary models, inspired by constrastive clustering. We validate the effectiveness of CoAi on nine classic classification tasks and three generation tasks, showing consistent and significant improvements compared with state-of-the-art methods.}
}


@inproceedings{DBLP:conf/www/TanWLXYZ25,
	author = {Xingyu Tan and
                  Xiaoyang Wang and
                  Qing Liu and
                  Xiwei Xu and
                  Xin Yuan and
                  Wenjie Zhang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Paths-over-Graph: Knowledge Graph Empowered Large Language Model Reasoning},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {3505--3522},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714892},
	doi = {10.1145/3696410.3714892},
	timestamp = {Fri, 16 May 2025 11:17:37 +0200},
	biburl = {https://dblp.org/rec/conf/www/TanWLXYZ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Large Language Models (LLMs) have achieved impressive results in various tasks but struggle with hallucination problems and lack of relevant knowledge, especially in deep complex reasoning and knowledge-intensive tasks. Knowledge Graphs (KGs), which capture vast amounts of facts in a structured format, offer a reliable source of knowledge for reasoning. However, existing KG-based LLM reasoning methods face challenges like handling multi-hop reasoning, multi-entity questions, and effectively utilizing graph structures. To address these issues, we propose Paths-over-Graph (PoG), a novel method that enhances LLM reasoning by integrating knowledge reasoning paths from KGs, improving the interpretability and faithfulness of LLM outputs. PoG tackles multi-hop and multi-entity questions through a three-phase dynamic multi-hop path exploration, which combines the inherent knowledge of LLMs with factual knowledge from KGs. In order to improve the efficiency, PoG prunes irrelevant information from the graph exploration first and introduces efficient three-step pruning techniques that incorporate graph structures, LLM prompting, and a pre-trained language model (e.g., SBERT) to effectively narrow down the explored candidate paths. This ensures all reasoning paths contain highly relevant information captured from KGs, making the reasoning faithful and interpretable in problem-solving. PoG innovatively utilizes graph structure to prune the irrelevant noise and represents the first method to implement multi-entity deep path detection on KGs for LLM reasoning tasks. Comprehensive experiments on five benchmark KGQA datasets demonstrate PoG outperforms the state-of-the-art method ToG across GPT-3.5-Turbo and GPT-4, achieving an average accuracy improvement of 18.9%. Notably, PoG with GPT-3.5-Turbo surpasses ToG with GPT-4 by up to 23.9%.}
}


@inproceedings{DBLP:conf/www/ChaintreauMZ25,
	author = {Augustin Chaintreau and
                  Roland Maio and
                  Juba Ziani},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {The Cost of Balanced Training-Data Production in an Online Data Market},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {3523--3542},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714882},
	doi = {10.1145/3696410.3714882},
	timestamp = {Fri, 09 May 2025 20:28:10 +0200},
	biburl = {https://dblp.org/rec/conf/www/ChaintreauMZ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Many ethical issues in machine learning are connected to the training data. Online data markets are an important source of training data, facilitating both production and distribution. Recently, a trend has emerged of for-profit ''ethical'' participants in online data markets. This trend raises a fascinating question: Can online data markets sustainably and efficiently address ethical issues in the broader machine-learning economy? In this work, we study this question in a stylized model of an online data market. We investigate the effects of intervening in the data market to achieve balanced training-data production. The model reveals the crucial role of market conditions. In small and emerging markets, an intervention can  drive the data producers out of the market,  so that the cost of fairness is maximal. Yet, in large and established markets,  the cost of fairness can vanish  (as a fraction of overall welfare) as the market grows. Our results suggest that ''ethical'' online data markets can be economically feasible under favorable market conditions, and motivate more models to consider the role of data production and distribution in mediating the impacts of ethical interventions.}
}


@inproceedings{DBLP:conf/www/MaSYD0025,
	author = {Huidong Ma and
                  Hui Sun and
                  Liping Yi and
                  Yanfeng Ding and
                  Xiaoguang Liu and
                  Gang Wang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {MSDZip: Universal Lossless Compression for Multi-source Data via Stepwise-parallel
                  and Learning-based Prediction},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {3543--3551},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714655},
	doi = {10.1145/3696410.3714655},
	timestamp = {Fri, 09 May 2025 20:28:10 +0200},
	biburl = {https://dblp.org/rec/conf/www/MaSYD0025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the rapid development of the Internet, the huge amount of Multi-Source Data (MSD) brings challenges in data sharing and storing. Lossless data compression is the major way to solve those problems. Nowadays, neural-network technologies bring significant advantage in data modeling, making learning-based lossless compressors (LLCs) for multi-source data have emerged continuously. Compared with traditional compressors, the LLCs are more useful to catch complex redundancy patterns in MSD, and thus have great potential in enhancing compression ratio. However, existing LLCs still suffer from unsatisfactory compression ratios and lower throughput. To solve those problems, we propose a novel universal MSD lossless compressor called MSDZip via Stepwise-parallel and learning-based prediction technologies, it introduces two major designs: 1) We propose a Local-Global-Deep Mixing block in the learning-based prediction module to establish dependencies for MSD symbols, where designed Deep Mixing block solves the problem of unstable weights in the perceptual layers caused by cold-start problem to enhance the compression ratio significantly. 2) We design a Stepwise-parallel multi-GPU-accelerated compression strategy to address the compression speed and graphics memory constraints of single GPU in the face of large-scale data. The Stepwise-parallel module passes the source MSD to learning-based prediction model through the data chunking strategy, where the model of the previous chunk is used to guide the compression of the next chunk in parallel. We compare MSDZip with 5 classical learning-based and 6 traditional compressors on 12 well-studied real-world datasets. The experimental results demonstrate that MSDZip optimizes 3.418%-69.874% in terms of compression ratio and 31.171%-495.649% in terms of throughput compared to advanced LLCs. The source code of MSDZip and the linkages of the experimental datasets are available at https://github.com/mhuidong/MSDZip.}
}


@inproceedings{DBLP:conf/www/LeiSYLZ25,
	author = {Dian Lei and
                  Zijun Song and
                  Yanli Yuan and
                  Chunhai Li and
                  Liehuang Zhu},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Achieving Personalized Privacy-Preserving Graph Neural Network via
                  Topology Awareness},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {3552--3560},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714555},
	doi = {10.1145/3696410.3714555},
	timestamp = {Fri, 09 May 2025 20:28:10 +0200},
	biburl = {https://dblp.org/rec/conf/www/LeiSYLZ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graph neural networks (GNNs) with differential privacy (DP) offer a reliable solution for safeguarding sensitive information within graph data. Nonetheless, existing DP-based privacy-preserving GNN learning frameworks generally overlook the local topological heterogeneity of graph nodes and tailor the same privacy budget for all nodes, which may lead to either overprotection or underprotection of some nodes, potentially diminishing model utility or posing privacy leakage risks. To address this issue, we propose a  T opology-aware  D ifferential  P rivacy  G raph  N eural  N etwork learning framework, termed  TDP-GNN,  which can achieve personalized privacy protection for each node with improved privacy-utility guarantees. Specifically,  TDP-GNN  first identifies the topological importance of each node via an adjacency information entropy method. Then, the personalized topology-aware privacy budget is designed to quantify the privacy sensitivity of each node and adaptively allocate the privacy protection strength. Besides, a weighted neighborhood aggregation mechanism is proposed during the message-passing process of GNN training, which can eliminate the impact of the introduced differentiated DP noise on the utility of the GNN model. Since  TDP-GNN  is based on node-level local DP, it can be seamlessly integrated into any GNN architecture in a plug-and-play manner while ensuring formal privacy guarantees. Theoretical analysis indicates that  TDP-GNN  achieves ε-differential privacy over the entire graph nodes while providing personalized privacy protection. Extensive experiments demonstrate that  TDP-GNN  consistently yields better utilities when applied to various GNN architectures (e.g., GCN and GraphSAGE) across a diverse set of benchmarks.}
}


@inproceedings{DBLP:conf/www/Zhang0YSZ25,
	author = {Yuchao Zhang and
                  Xiangjie Kong and
                  Kailun Ye and
                  Guojiang Shen and
                  Shangfei Zheng},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Tackling Sparse Facts for Temporal Knowledge Graph Completion},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {3561--3570},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714839},
	doi = {10.1145/3696410.3714839},
	timestamp = {Fri, 09 May 2025 20:28:10 +0200},
	biburl = {https://dblp.org/rec/conf/www/Zhang0YSZ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Temporal knowledge graph completion (TKGC) seeks to develop more comprehensive knowledge representations by addressing missing relationships and entities within temporal knowledge graphs (TKGs), thereby enhancing reasoning and predictive capabilities in downstream tasks. Nonetheless, real-world knowledge-such as the progression of social network interactions and the unfolding of news events-is inherently dynamic, resulting in substantial sparsity issues in TKGs that profoundly impair the performance of TKGC models. To overcome this challenge, we introduce the  A daptive  N eighborhood  E nhancement  L ayer (ANEL), a novel module that can be effortlessly integrated into existing TKGC models to substantially elevate the representation quality of sparse entities. ANEL first derives initial entity embeddings through a base model and then uncovers concealed semantic relationships between entities via a latent relation module, enriching the explicit relationships within the knowledge graph. Furthermore, ANEL incorporates an adaptive latent information adjustment component, which dynamically calibrates the influence of latent information based on the entity's relational structure: entities with fewer connections derive greater benefit from latent information, while entities with denser connections become less dependent on latent augmentation, ensuring precise and resilient representations. We conducted comprehensive experiments on four prominent benchmark datasets, and the results underscore the effectiveness and superiority of ANEL in TKGC tasks.}
}


@inproceedings{DBLP:conf/www/0001HWMWYS25,
	author = {Zhikang Fan and
                  Lan Hu and
                  Ruirui Wang and
                  Zhongrui Ma and
                  Yue Wang and
                  Qi Ye and
                  Weiran Shen},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Two-stage Auction Design in Online Advertising},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {3571--3585},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714735},
	doi = {10.1145/3696410.3714735},
	timestamp = {Fri, 09 May 2025 20:28:10 +0200},
	biburl = {https://dblp.org/rec/conf/www/0001HWMWYS25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Modern online advertising systems often involve a substantial number of advertisers in each auction, which results in scalability issues. To address this challenge, two-stage auctions have been designed and implemented in practice. These auctions enable efficient allocation of ad slots among numerous candidate advertisers in a short response time. This approach employs a fast yet coarse model in the first stage to select a small subset of advertisers, followed by a slow, more refined model to determine the final winners. However, existing two-stage auction mechanisms primarily focus on optimizing welfare, overlooking other critical objectives of the platform, such as revenue. In this paper, we propose ad-wise selection metrics, named Max-Wel and Max-Rev, which optimize the platform's welfare and revenue, respectively. These metrics are based on each ad's contribution to the corresponding objective function. We also provide theoretical guarantees for the proposed metrics. Our method is applicable to both welfare and revenue optimizations and can be easily implemented using neural networks. Through extensive experiments conducted on both synthetic and industrial data, we demonstrate the advantages of our proposed selection metrics compared to existing baselines.}
}


@inproceedings{DBLP:conf/www/LiLWW25,
	author = {Zhengpin Li and
                  Minhua Lin and
                  Jian Wang and
                  Suhang Wang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Fairness-aware Prompt Tuning for Graph Neural Networks},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {3586--3597},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714780},
	doi = {10.1145/3696410.3714780},
	timestamp = {Tue, 13 May 2025 07:31:04 +0200},
	biburl = {https://dblp.org/rec/conf/www/LiLWW25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graph prompt tuning has achieved significant success for its ability to effectively adapt pre-trained graph neural networks to various downstream tasks. However, the pre-trained models may learn discriminatory representation due to the inherent prejudice in graph-structured data. Existing graph prompt tuning overlooks such unfairness, leading to biased outputs towards certain demographic groups determined by sensitive attributes such as gender, age, and political ideology. To overcome this limitation, we propose a fairness-aware graph prompt tuning method to promote fairness while enhancing the generality of any pre-trained GNNs (named FPrompt). FPrompt introduces hybrid graph prompts to augment counterfactual data while aligning the pre-training and downstream tasks. It also applies edge modification to increase sensitivity heterophily. We provide a two-fold theoretical analysis: first, we demonstrate that FPrompt possesses universal capabilities in handling pre-trained GNN models across various pre-training strategies, ensuring its adaptability in different scenarios. Second, we show that FPrompt effectively reduces the upper bound of generalized statistical parity, thereby mitigating the bias of pre-trained models. Extensive experiments demonstrate that FPrompt outperforms baseline models in both accuracy and fairness (33%) on benchmark datasets. Additionally, we introduce a new benchmark for transferable evaluation, showing that FPrompt achieves state-of-the-art generalization performance.}
}


@inproceedings{DBLP:conf/www/GaoOZYZCXDY25,
	author = {Kangyue Gao and
                  Chuangyu Ouyang and
                  Xinkui Zhao and
                  Miao Ye and
                  Chen Zhi and
                  Guanjie Cheng and
                  Yueshen Xu and
                  Shuiguang Deng and
                  Jianwei Yin},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {HeatSnap: {A} Hot Page-Aware Continuous Snapshots System for Virtual
                  Machines in Web Infrastructure},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {3598--3606},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714824},
	doi = {10.1145/3696410.3714824},
	timestamp = {Fri, 09 May 2025 20:28:10 +0200},
	biburl = {https://dblp.org/rec/conf/www/GaoOZYZCXDY25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Snapshot technology is crucial for data protection and system recovery in virtualized environments, particularly with the growing need for continuous snapshots to maintain the integrity of long-running web-based and distributed applications. However, traditional snapshot methods often suffer from performance bottlenecks, and inefficient storage usage. These challenges are closely tied to the way memory pages are accessed during VM execution, where memory access patterns show significant disparities between frequently accessed "hot" pages and less-used "cold" pages. In this paper, we introduce HeatSnap, a continuous snapshot system designed to address these issues by leveraging the uneven access frequencies of memory pages. HeatSnap distinguishes between intensive hot pages and dirty pages, applying specialized snapshotting and storage strategies to optimize the handling of both hot and cold memory regions. This approach aims to optimize snapshot efficiency, minimize performance impact on the VM, and decrease storage costs. Our implementation of HeatSnap on QEMU/KVM demonstrates significant improvements in VM performance loss, snapshot duration, and storage efficiency compared to existing methods, as evidenced by evaluations on common web and cloud-based workloads.}
}


@inproceedings{DBLP:conf/www/ZhangCZPCCC25,
	author = {Xin Zhang and
                  Fei Cai and
                  Jianming Zheng and
                  Zhiqiang Pan and
                  Wanyu Chen and
                  Honghui Chen and
                  Chonghao Chen},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Triangle Matters! TopDyG: Topology-aware Transformer for Link Prediction
                  on Dynamic Graphs},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {3607--3617},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714564},
	doi = {10.1145/3696410.3714564},
	timestamp = {Wed, 23 Apr 2025 16:35:50 +0200},
	biburl = {https://dblp.org/rec/conf/www/ZhangCZPCCC25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Dynamic graph link prediction is widely utilized in the complex web of the real world, such as social networks, citation networks, recommendation systems, etc. Recent Transformer-based link prediction methods on dynamic graphs not only fail to model the fine-grained structures such as  triangles  with the vanilla Transformers in the  graph serialization  process, but also amplify the imbalanced distribution of graphs because of their  over-estimation of high-degree nodes . To tackle these issues, we propose a Topology-aware Transformer on Dynamic Graph (TopDyG) for link prediction, consisting of a topology injected Transformer (Ti-Transformer) and a mutual information learning (Mi-Learning). The Ti-Transformer explores the explicit structure of serialized graphs, capturing the topological features. The Mi-Learning mines the relationship between nodes by modeling the mutual information with a prior knowledge, alleviating the over-estimation of high-degree nodes when applying the Transformer-based models for the dynamic graph link prediction task. Extensive experiments on four public datasets containing both transductive and inductive settings present the superiority of our proposal. In particular, TopDyG presents an improvement of 43.27% and 28.75% against the state-of-the-art baselines in terms of NDCG and Jaccard, respectively. The advantages are especially obvious on the high-density graphs.}
}


@inproceedings{DBLP:conf/www/Jiang000CY25,
	author = {Wei Jiang and
                  Tong Chen and
                  Xinyi Gao and
                  Wentao Zhang and
                  Lizhen Cui and
                  Hongzhi Yin},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Epidemiology-informed Network for Robust Rumor Detection},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {3618--3627},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714610},
	doi = {10.1145/3696410.3714610},
	timestamp = {Fri, 09 May 2025 20:28:10 +0200},
	biburl = {https://dblp.org/rec/conf/www/Jiang000CY25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The rapid spread of rumors on social media has posed significant challenges to maintaining public trust and information integrity. Since an information cascade process is essentially a propagation tree, recent rumor detection models leverage graph neural networks to additionally capture information propagation patterns, thus outperforming text-only solutions. Given the variations in topics and social impact of the root node, different source information naturally has distinct outreach capabilities, resulting in different heights of propagation trees. This variation, however, impedes the data-driven design of existing graph-based rumor detectors. Given a shallow propagation tree with limited interactions, it is unlikely for graph-based approaches to capture sufficient cascading patterns, questioning their ability to handle less popular news or early detection needs. In contrast, a deep propagation tree is prone to noisy user responses, and this can in turn obfuscate the predictions. In this paper, we propose a novel Epidemiology-informed Network (EIN) that integrates epidemiological knowledge to enhance performance by overcoming data-driven methods' sensitivity to data quality. Meanwhile, to adapt epidemiology theory to rumor detection, it is expected that each user's stance toward the source information will be annotated. To bypass the costly and time-consuming human labeling process, we take advantage of large language models to generate stance labels, facilitating optimization objectives for learning epidemiology-informed representations. Our experimental results demonstrate that the proposed EIN not only outperforms state-of-the-art methods on real-world datasets but also exhibits enhanced robustness across varying tree depths.}
}


@inproceedings{DBLP:conf/www/LiuZZRL0G25,
	author = {Yizhong Liu and
                  Zedan Zhao and
                  Boyu Zhao and
                  Feiang Ran and
                  Xun Lin and
                  Dawei Li and
                  Zhenyu Guan},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Fully Anonymous Decentralized Identity Supporting Threshold Traceability
                  with Practical Blockchain},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {3628--3638},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714762},
	doi = {10.1145/3696410.3714762},
	timestamp = {Fri, 09 May 2025 20:28:10 +0200},
	biburl = {https://dblp.org/rec/conf/www/LiuZZRL0G25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Decentralized identity (DID) holds significant potential for applications in Web3, such as digital markets and financial systems. Traditional DID paradigms offer a degree of privacy but struggle to prevent the link analysis on user behaviours and repeated public key usage. Anonymity is not fully achieved, as users' real identities or public keys are exposed to the issuing authority, while introducing high public key management complexity. Besides, existing anonymous credential schemes lack effective mechanisms for threshold traceability, not meeting Web3's distributed governance requirements. In this paper, we propose FADID-TT, a  F ully  A nonymous  DID  system supporting  T hreshold  T racing with practical blockchain, to tackle the above challenges. Firstly, we propose a distributed identity registration scheme based on secret sharing. A committee composed of distributed issuing authorities is responsible for issuing user's secret key shares and no single entity in the system can obtain a user's real identity or public key, achieving anonymity to authority. Moreover, we design a  fully anonymous  DID system combined with anonymous signatures and decentralized anonymous credentials (DAC). A service provider can only use the committee public key to verify a user identity, eliminating the need for user public keys, fully resisting link attacks, and reducing the user public key management complexity from O(n) to O(1). Furthermore, we design a publicly verifiable  threshold tracing  mechanism that enables committee members to collaboratively trace the identity of a malicious user without compromising privacy guarantees. FADID-TT realizes publicly verifiable tracing via zero-knowledge proofs. Finally, we give comprehensive security analysis and concrete performance evaluation. In addition to evaluate each part of proposal, we also deploy FADID-TT on two well-known blockchain platforms including Hyperledger Fabric (permissioned) and Ethereum (permissionless) to demonstrate the practical feasibility of FADID-TT.}
}


@inproceedings{DBLP:conf/www/LiuS00G0DLG25,
	author = {Jiahao Liu and
                  Yiyang Shao and
                  Peng Zhang and
                  Dongsheng Li and
                  Hansu Gu and
                  Chao Chen and
                  Longzhi Du and
                  Tun Lu and
                  Ning Gu},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Filtering Discomforting Recommendations with Large Language Models},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {3639--3650},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714850},
	doi = {10.1145/3696410.3714850},
	timestamp = {Fri, 09 May 2025 20:28:10 +0200},
	biburl = {https://dblp.org/rec/conf/www/LiuS00G0DLG25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Personalized algorithms can inadvertently expose users to discomforting recommendations, potentially triggering negative consequences. The subjectivity of discomfort and the black-box nature of these algorithms make it challenging to effectively identify and filter such content. To address this, we first conducted a formative study to understand users' practices and expectations regarding discomforting recommendation filtering. Then, we designed a Large Language Model (LLM)-based tool named DiscomfortFilter, which constructs an editable preference profile for a user and helps the user express filtering needs through conversation to mask discomforting preferences within the profile. Based on the edited profile, DiscomfortFilter facilitates the discomforting recommendations filtering in a plug-and-play manner, maintaining flexibility and transparency. The constructed preference profile improves LLM reasoning and simplifies user alignment, enabling a 3.8B open-source LLM to rival top commercial models in an offline proxy task. A one-week user study with 24 participants demonstrated the effectiveness of DiscomfortFilter, while also highlighting its potential impact on platform recommendation outcomes. We conclude by discussing the ongoing challenges, highlighting its relevance to broader research, assessing stakeholder impact, and outlining future research directions.}
}


@inproceedings{DBLP:conf/www/TengLW0025,
	author = {Yixiao Teng and
                  Jiamei Lv and
                  Ziping Wang and
                  Yi Gao and
                  Wei Dong},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {TimeChain: {A} Secure and Decentralized Off-chain Storage System for
                  IoT Time Series Data},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {3651--3659},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714791},
	doi = {10.1145/3696410.3714791},
	timestamp = {Fri, 09 May 2025 20:28:10 +0200},
	biburl = {https://dblp.org/rec/conf/www/TengLW0025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Blockchain-based distributed storage systems offer enhanced security, transparency, and lower costs compared to traditional centralized storage, making them ideal for peer-to-peer collaboration. However, with the trend towards the Web of Things (WoT), lower transaction speeds and higher computational requirements limit their access to high-density data such as IoT. To address this, we propose TimeChain, an efficient off-chain blockchain storage system for IoT time series data. TimeChain batches discrete time series data, storing only the hash value of each batch on-chain while keeping the complete data off-chain. This significantly reduces storage overhead on the blockchain and storage latency by 37.4 times. TimeChain adopts an adaptive packaging mechanism to reduce the additional latency in range queries by converting the batch processing problem into a graph partitioning problem. To reduce the overhead of node selection, TimeChain integrates a node selection mechanism based on consensus protocol, combining node selection and consensus processes together. TimeChain also proposes a Locality-Sensitive Hashing tree-based data integrity verification mechanism to reduce transmission size. Our evaluation shows a reduction in query latency by 64.6% and storage latency by 35.3% compared to existing systems.}
}


@inproceedings{DBLP:conf/www/Gao0YYHZL25,
	author = {Weibo Gao and
                  Qi Liu and
                  Linan Yue and
                  Fangzhou Yao and
                  Zhenya Huang and
                  Zheng Zhang and
                  Rui Lv},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {BoxCD: Leveraging Contrastive Probabilistic Box Embedding for Effective
                  and Efficient Learner Modeling},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {3660--3671},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714645},
	doi = {10.1145/3696410.3714645},
	timestamp = {Fri, 09 May 2025 20:28:10 +0200},
	biburl = {https://dblp.org/rec/conf/www/Gao0YYHZL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In digital education, Cognitive Diagnosis (CD) is essential for modeling learners' cognitive states, such as problem-solving ability and knowledge proficiency, by analyzing their response data, like answer correctness. However, traditional CD methods struggle with  effectiveness  and  efficiency . They fail to capture the diversity and uncertainty of learners' cognitive states. Additionally, response prediction can be time-consuming. To address these issues, we propose BoxCD, a contrastive probabilistic box embedding model for cognitive diagnosis. BoxCD utilizes high-dimensional axis-aligned hyper-rectangles (boxes) to represent learners and exercises, with the volume of intersecting boxes used to predict learners' responses. This approach effectively captures semantic diversity and uncertainty while enhancing diagnostic effectiveness. To stabilize box embeddings, we integrate contrastive learning objectives with response prediction goals, optimizing the distance between positive and negative samples of learner and exercise boxes to improve uniformity. Additionally, we develop a rank-based response prediction method that leverages the geometric properties of box embeddings to assess learners' response correctness efficiently. Comprehensive experiments on two real-world datasets demonstrate that BoxCD outperforms traditional CD models in effectiveness and efficiency. This showcases its potential to enhance personalized learning in digital education platforms.}
}


@inproceedings{DBLP:conf/www/Zhang0S0025,
	author = {Shengzhe Zhang and
                  Liyi Chen and
                  Dazhong Shen and
                  Chao Wang and
                  Hui Xiong},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Hierarchical Time-Aware Mixture of Experts for Multi-Modal Sequential
                  Recommendation},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {3672--3682},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714676},
	doi = {10.1145/3696410.3714676},
	timestamp = {Fri, 09 May 2025 20:28:10 +0200},
	biburl = {https://dblp.org/rec/conf/www/Zhang0S0025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Multi-modal sequential recommendation (SR) leverages multi-modal data to learn more comprehensive item features and user preferences than traditional SR methods, which has become a critical topic in both academia and industry. Existing methods typically focus on enhancing multi-modal information utility through adaptive modality fusion to capture the evolving of user preference from user-item interaction sequences. However, most of them overlook the interference caused by redundant interest-irrelevant information contained in rich multi-modal data. Additionally, they primarily rely on implicit temporal information based solely on chronological ordering, neglecting explicit temporal signals that could more effectively represent dynamic user interest over time. To address these limitations, we propose a  H ierarchical time-aware  M ixture of experts for multi-modal  S equential  R ecommendation (HM4SR) with a two-level Mixture of Experts (MoE) and a multi-task learning strategy. Specifically, the first MoE, named Interactive MoE, extracts essential user interest-related information from the multi-modal data of each item. Then, the second MoE, termed Temporal MoE, captures user dynamic interests by introducing explicit temporal embeddings from timestamps in modality encoding. To further address data sparsity, we propose three auxiliary supervision tasks: sequence-level category prediction (CP) for item feature understanding, contrastive learning on ID (IDCL) to align sequence context with user interests, and placeholder contrastive learning (PCL) to integrate temporal information with modalities for dynamic interest modeling. Extensive experiments on four public datasets verify the effectiveness of HM4SR compared to several state-of-the-art approaches.}
}


@inproceedings{DBLP:conf/www/DingDLDCSL25,
	author = {Ziqi Ding and
                  Gelei Deng and
                  Yi Liu and
                  Junchen Ding and
                  Jieshan Chen and
                  Yulei Sui and
                  Yuekang Li},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {IllusionCAPTCHA: {A} {CAPTCHA} based on Visual Illusion},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {3683--3691},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714726},
	doi = {10.1145/3696410.3714726},
	timestamp = {Fri, 09 May 2025 20:28:10 +0200},
	biburl = {https://dblp.org/rec/conf/www/DingDLDCSL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {CAPTCHAs have long been essential tools for protecting applications from automated bots. Initially designed as simple questions to distinguish humans from bots, they have become increasingly complex to keep pace with the proliferation of CAPTCHA-cracking techniques employed by malicious actors. However, with the advent of advanced large language models (LLMs), the effectiveness of existing CAPTCHAs is now being undermined. To address this issue, we have conducted an empirical study to evaluate the performance of multimodal LLMs in solving CAPTCHAs and to assess how many attempts human users typically need to pass them. Our findings reveal that while LLMs can solve most CAPTCHAs, they struggle with those requiring complex reasoning-a type of CAPTCHA that also presents significant challenges for human users. Interestingly, our user study shows that the majority of human participants require a second attempt to pass these reasoning CAPTCHAs, a finding not reported in previous research. Based on empirical findings, we present IllusionCAPTCHA, a novel security mechanism employing the "Human-Easy but AI-Hard" paradigm. This new CAPTCHA employs visual illusions to create tasks that are intuitive for humans but highly confusing for AI models. Furthermore, we developed a structured, step-by-step method that generates misleading options, which particularly guide LLMs towards making incorrect choices and reduce their chances of successfully solving CAPTCHAs. Our evaluation shows that IllusionCAPTCHA can effectively deceive LLMs 100% of the time. Moreover, our structured design significantly increases the likelihood of AI errors when solving these challenges. Results from our user study indicate that 86.95% of participants successfully passed the CAPTCHA on their first attempt, outperforming other CAPTCHA systems.}
}


@inproceedings{DBLP:conf/www/RenW0ZW0WC25,
	author = {Ruiyang Ren and
                  Yuhao Wang and
                  Kun Zhou and
                  Wayne Xin Zhao and
                  Wenjie Wang and
                  Jing Liu and
                  Ji{-}Rong Wen and
                  Tat{-}Seng Chua},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Self-Calibrated Listwise Reranking with Large Language Models},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {3692--3701},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714658},
	doi = {10.1145/3696410.3714658},
	timestamp = {Wed, 28 May 2025 16:47:37 +0200},
	biburl = {https://dblp.org/rec/conf/www/RenW0ZW0WC25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Large language models (LLMs), with advanced linguistic capabilities, have been employed in reranking tasks through a sequence-to-sequence approach. In this paradigm, multiple passages are reranked in a listwise manner and a textual reranked permutation is generated. However, due to the limited context window of LLMs, this reranking paradigm requires a sliding window strategy to iteratively handle larger candidate sets. This not only increases computational costs but also restricts the LLM from fully capturing all the comparison information for all candidates. To address these challenges, we propose a novel self-calibrated listwise reranking method, which aims to leverage LLMs to produce global relevance scores for ranking. To achieve it, we first propose the relevance-aware listwise reranking framework, which incorporates explicit list-view relevance scores to improve reranking efficiency and enable global comparison across the entire candidate set. Second, to ensure the comparability of the computed scores, we propose self-calibrated training that uses point-view relevance assessments generated internally by the LLM itself to calibrate the list-view relevance assessments. Extensive experiments and comprehensive analysis on the BEIR benchmark and TREC Deep Learning Tracks demonstrate the effectiveness and efficiency of our proposed method.}
}


@inproceedings{DBLP:conf/www/BrennanCYLPMHPH25,
	author = {Jennifer Brennan and
                  Yahu Cong and
                  Yiwei Yu and
                  Lina Lin and
                  Yajun Peng and
                  Changping Meng and
                  Ningren Han and
                  Jean Pouget{-}Abadie and
                  David M. Holtz},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Reducing Symbiosis Bias through Better {A/B} Tests of Recommendation
                  Algorithms},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {3702--3715},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714738},
	doi = {10.1145/3696410.3714738},
	timestamp = {Fri, 09 May 2025 20:28:10 +0200},
	biburl = {https://dblp.org/rec/conf/www/BrennanCYLPMHPH25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {It is increasingly common in digital environments to use A/B tests to compare the performance of recommendation algorithms. However, such experiments often violate the stable unit treatment value assumption (SUTVA), particularly SUTVA's ''no hidden treatments'' assumption, due to the shared data between algorithms being compared. This results in a novel form of bias, which we term ''symbiosis bias,'' where the performance of each algorithm is influenced by the training data generated by its competitor. In this paper, we investigate three experimental designs--cluster-randomized, data-diverted, and user-corpus co-diverted experiments--aimed at mitigating symbiosis bias. We present a theoretical model of symbiosis bias and simulate the impact of each design in dynamic recommendation environments. Our results show that while each design reduces symbiosis bias to some extent, they also introduce new challenges, such as reduced training data in data-diverted experiments. We further validate the existence of symbiosis bias using data from a large-scale A/B test conducted on a global recommender system, demonstrating that symbiosis bias affects treatment effect estimates in the field. Our findings provide actionable insights for researchers and practitioners seeking to design experiments that accurately capture algorithmic performance without bias in treatment effect estimates introduced by shared data.}
}


@inproceedings{DBLP:conf/www/BalagopalanWSBG25,
	author = {Aparna Balagopalan and
                  Kai Wang and
                  Olawale Salaudeen and
                  Asia Biega and
                  Marzyeh Ghassemi},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {What's in a Query: Polarity-Aware Distribution-Based Fair Ranking},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {3716--3730},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714660},
	doi = {10.1145/3696410.3714660},
	timestamp = {Fri, 09 May 2025 20:28:10 +0200},
	biburl = {https://dblp.org/rec/conf/www/BalagopalanWSBG25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Machine learning-driven rankings, where individuals (or items) are ranked in response to a query, mediate search exposure or attention in a variety of safety-critical settings. Thus, it is important to ensure that such rankings are fair. Under the goal of equal opportunity, attention allocated to an individual on a ranking interface should be proportional to their relevance across search queries. In this work, we examine amortized fair ranking -- where relevance and attention are cumulated over a sequence of user queries to make fair ranking more feasible in practice. Unlike prior methods that operate on expected amortized attention for each individual, we define new divergence-based measures for attention distribution-based fairness in ranking (DistFaiR), characterizing unfairness as the divergence between the distribution of attention and relevance corresponding to an individual over time. This allows us to propose new definitions of unfairness, which are more reliable at test time. Second, we prove that group fairness is upper-bounded by individual fairness under this definition for a useful class of divergence measures, and experimentally show that maximizing individual fairness through an integer linear programming-based optimization is often beneficial to group fairness. Lastly, we find that prior research in amortized fair ranking ignores critical information about queries, potentially leading to a  fairwashing  risk in practice by making rankings appear more fair than they actually are.}
}


@inproceedings{DBLP:conf/www/MittalGWCDMAH25,
	author = {Govind Mittal and
                  Sarthak Gupta and
                  Shruti Wagle and
                  Chirag Chopra and
                  Anthony J. DeMattee and
                  Nasir D. Memon and
                  Mustaque Ahamad and
                  Chinmay Hegde},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {WavePulse: Real-time Content Analytics of Radio Livestreams},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {3731--3750},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714810},
	doi = {10.1145/3696410.3714810},
	timestamp = {Fri, 09 May 2025 20:28:10 +0200},
	biburl = {https://dblp.org/rec/conf/www/MittalGWCDMAH25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Radio remains a pervasive medium for mass information dissemination, with AM/FM stations reaching more Americans than either smartphone-based social networking or live television. Increasingly, radio broadcasts are also streamed online and accessed over the Internet. We present  WavePulse , a framework that records, documents, and analyzes radio content in real-time. While our framework is generally applicable, we showcase the efficacy of  WavePulse  in a collaborative project with a team of political scientists focusing on the 2024 Presidential Election. We use  WavePulse  to monitor livestreams of 396 news radio stations over a period of three months, processing close to 500,000 hours of audio streams. These streams were converted into time-stamped, diarized transcripts and analyzed to answer key political science questions at both the national and state levels. Our analysis revealed how local issues interacted with national trends, providing insights into information flow. Our results demonstrate  WavePulse 's efficacy in capturing and analyzing content from radio livestreams sourced from the Web. Code and dataset can be accessed at https://wave-pulse.io}
}


@inproceedings{DBLP:conf/www/DeBBS25,
	author = {Soham De and
                  Michiel A. Bakker and
                  Jay Baxter and
                  Martin Saveski},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Supernotes: Driving Consensus in Crowd-Sourced Fact-Checking},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {3751--3761},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714934},
	doi = {10.1145/3696410.3714934},
	timestamp = {Fri, 09 May 2025 20:28:10 +0200},
	biburl = {https://dblp.org/rec/conf/www/DeBBS25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {X's Community Notes, a crowd-sourced fact-checking system, allows users to annotate potentially misleading posts. Notes rated as helpful by a diverse set of users are prominently displayed below the original post. While demonstrably effective at reducing misinformation's impact when notes are displayed, there is an opportunity for notes to appear on many more posts: for 91% of posts where at least one note is proposed, no notes ultimately achieve sufficient support from diverse users to be shown on the platform. This motivates the development of Supernotes: AI-generated notes that synthesize information from several existing community notes and are written to foster consensus among a diverse set of users. Our framework uses an LLM to generate many diverse Supernote candidates from existing proposed notes. These candidates are then evaluated by a novel scoring model, trained on millions of historical Community Notes ratings, selecting candidates that are most likely to be rated helpful by a diverse set of users. To test our framework, we ran a human subjects experiment in which we asked participants to compare the Supernotes generated by our framework to the best existing community notes for 100 sample posts. We found that participants rated the Supernotes as significantly more helpful, and when asked to choose between the two, preferred the Supernotes 75.2% of the time. Participants also rated the Supernotes more favorably than the best existing notes on quality, clarity, coverage, context, and argumentativeness. Finally, in a follow-up experiment, we asked participants to compare the Supernotes against LLM-generated summaries and found that the participants rated the Supernotes significantly more helpful, demonstrating that both the LLM-based candidate generation and the consensus-driven scoring play crucial roles in creating notes that effectively build consensus among diverse users.}
}


@inproceedings{DBLP:conf/www/KumarswamySN25,
	author = {Nihal Kumarswamy and
                  Mohit Singhal and
                  Shirin Nilizadeh},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Causal Insights into Parler's Content Moderation Shift: Effects on
                  Toxicity and Factuality},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {3762--3771},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714865},
	doi = {10.1145/3696410.3714865},
	timestamp = {Fri, 09 May 2025 20:28:10 +0200},
	biburl = {https://dblp.org/rec/conf/www/KumarswamySN25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Social media platforms employ various content moderation techniques to remove harmful, offensive, and toxic content, with moderation levels varying across platforms and evolving over time. Parler, a fringe platform popular among conservative users, initially had minimal moderation, promoting itself as a space for open discussion. However, in 2021, it was removed from the Apple and Google App Stores and suspended from Amazon Web Services due to inadequate moderation of harmful content. After a month-long suspension, Parler returned with stricter guidelines, offering a unique opportunity to study the impact of platform-wide policy changes on user behavior and content outcomes. In this paper, we analyzed Parler data to assess the causal associations of these moderation changes on content toxicity and factuality. Using a longitudinal dataset of 17M posts from 432K users, who were active both before and after replatforming, we employed quasi-experimental analysis, controlling for confounding factors. We introduced a novel approach by using data from another social media platform, Twitter, to account for a critical confounding factor: offline events. This allowed us to isolate the effects of Parler's replatforming policies from external real-world influences. Our findings demonstrate that Parler's moderation changes are causally associated with a significant reduction in all forms of toxicity (p < 0.001). Additionally, we observed an increase in the factuality of the news sites shared and a reduction in the number of conspiracy/ pseudoscience sources.}
}


@inproceedings{DBLP:conf/www/Zeng00ZL25,
	author = {Long Zeng and
                  Jianxiang Yu and
                  Jiapeng Zhu and
                  Qingsong Zhong and
                  Xiang Li},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Hierarchical Vector Quantized Graph Autoencoder with Annealing-Based
                  Code Selection},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {3772--3782},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714656},
	doi = {10.1145/3696410.3714656},
	timestamp = {Fri, 09 May 2025 20:28:10 +0200},
	biburl = {https://dblp.org/rec/conf/www/Zeng00ZL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graph self-supervised learning has gained significant attention recently. However, many existing approaches heavily depend on perturbations, and inappropriate perturbations may corrupt the graph's inherent information. The Vector Quantized Variational Autoencoder (VQ-VAE) is a powerful autoencoder extensively used in fields such as computer vision; however, its application to graph data remains underexplored. In this paper, we provide an empirical analysis of vector quantization in the context of graph autoencoders, demonstrating its significant enhancement of the model's capacity to capture graph topology. Furthermore, we identify two key challenges associated with vector quantization when applying in graph data: codebook underutilization and codebook space sparsity. For the first challenge, we propose an annealing-based encoding strategy that promotes broad code utilization in the early stages of training, gradually shifting focus toward the most effective codes as training progresses. For the second challenge, we introduce a hierarchical two-layer codebook that captures relationships between embeddings through clustering. The second layer codebook links similar codes, encouraging the model to learn closer embeddings for nodes with similar features and structural topology in the graph. Our proposed model outperforms 16 representative baseline methods in self-supervised link prediction and node classification tasks across multiple datasets. Our implementation is available at https://github.com/vitaminzl/hqa-gae.}
}


@inproceedings{DBLP:conf/www/WuJH25,
	author = {Wenhan Wu and
                  Jiawei Jiang and
                  Chuang Hu},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Aegis: Post-Training Attribute Unlearning in Federated Recommender
                  Systems against Attribute Inference Attacks},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {3783--3793},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714823},
	doi = {10.1145/3696410.3714823},
	timestamp = {Fri, 09 May 2025 20:28:10 +0200},
	biburl = {https://dblp.org/rec/conf/www/WuJH25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As privacy concerns in recommender systems become increasingly prominent, federated recommender systems (FedRecs) have emerged as a promising distributed training paradigm. FedRecs enable the collaborative training of a shared global recommendation model without requiring the exchange of raw client interaction data. However, models trained using standard FedRec methods remain vulnerable to personal information leakage, particularly through attribute inference attacks, which can expose sensitive user attributes such as gender and race. In this paper, we address these user-sensitive attributes as targets for federated unlearning. To protect users' sensitive information, attribute unlearning aims to eliminate sensitive attributes from user embeddings, thereby preventing inference attacks while preserving recommendation performance. We introduce a novel post-training federated unlearning framework, Aegis, which performs unlearning based on private attribute requests after the model has been trained, minimizing the degradation in recommendation accuracy. Aegis employs an information-theoretic multi-component loss function to balance privacy protection and recommendation performance. Additionally, Aegis adapts to scenarios where training interaction data may be unavailable, reflecting real-world centralized protection scenarios. Comprehensive evaluations of various benchmark datasets demonstrate that our proposed method effectively safeguards user privacy while maintaining high-quality recommendations.}
}


@inproceedings{DBLP:conf/www/ChiuTYC25,
	author = {Shih{-}Hsuan Chiu and
                  Ya{-}Wen Teng and
                  De{-}Nian Yang and
                  Ming{-}Syan Chen},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Human-Centric Community Detection in Hybrid Metaverse Networks with
                  Integrated {AI} Entities},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {3794--3808},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714679},
	doi = {10.1145/3696410.3714679},
	timestamp = {Fri, 09 May 2025 20:28:10 +0200},
	biburl = {https://dblp.org/rec/conf/www/ChiuTYC25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Community detection is a cornerstone problem in social network analysis (SNA), aimed at identifying cohesive communities with minimal external links. However, the rise of generative AI and Metaverse introduce complexities by creating hybrid human-AI social networks (denoted by HASNs), where traditional methods fall short, especially in human-centric settings. This paper introduces a novel community detection problem in HASNs (denoted by MetaCD), which seeks to enhance human connectivity within communities while reducing the presence of AI nodes. Effective processing of MetaCD poses challenges due to the delicate trade-off between excluding certain AI nodes and maintaining community structure. To address this, we propose CUSA, an innovative framework incorporating AI-aware clustering techniques that navigate this trade-off by selectively retaining AI nodes that contribute to community integrity. Furthermore, given the scarcity of real-world HASNs, we devise four strategies for synthesizing these networks under various hypothetical scenarios. Empirical evaluations on real social networks, reconfigured as HASNs, demonstrate the effectiveness and practicality of our approach compared to traditional non-deep learning and graph neural network (GNN)-based methods.}
}


@inproceedings{DBLP:conf/www/PeintnerMMZ25,
	author = {Andreas Peintner and
                  Amir Reza Mohammadi and
                  Michael M{\"{u}}ller and
                  Eva Zangerle},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Hypergraph-based Temporal Modelling of Repeated Intent for Sequential
                  Recommendation},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {3809--3818},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714896},
	doi = {10.1145/3696410.3714896},
	timestamp = {Thu, 01 May 2025 20:27:25 +0200},
	biburl = {https://dblp.org/rec/conf/www/PeintnerMMZ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In sequential recommendation scenarios, user intent is a key driver of consumption behavior. However, consumption intents are usually latent and hence, difficult to leverage for recommender systems. Additionally, intents can be of repeated nature (e.g. yearly shopping for christmas gifts or buying a new phone), which has not been exploited by previous approaches. To navigate these impediments we propose the  HyperHawkes  model which models user sessions via hypergraphs and extracts user intents via contrastive clustering. We use Hawkes Processes to model the temporal dynamics of intents, namely repeated consumption patterns and long-term interests of users. For short-term interest adaption, which is more fine-grained than intent-level modeling, we use a multi-level attention mixture network and fuse long-term and short-term signals. We use the generalized expectation-maximization (EM) framework for training the model by alternating between intent representation learning and optimizing parameters of the long- and short-term modules. Extensive experiments on four real-world datasets from different domains show that HyperHawkes significantly outperforms existing state-of-the-art methods.}
}


@inproceedings{DBLP:conf/www/ZhaoLZWZL25,
	author = {Peiyao Zhao and
                  Xin Li and
                  Zeyu Zhang and
                  Mingzhong Wang and
                  Xueying Zhu and
                  Lejian Liao},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Robust Deep Signed Graph Clustering via Weak Balance Theory},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {3819--3830},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714915},
	doi = {10.1145/3696410.3714915},
	timestamp = {Tue, 13 May 2025 07:31:05 +0200},
	biburl = {https://dblp.org/rec/conf/www/ZhaoLZWZL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Signed graph clustering is a critical technique for discovering community structures in graphs that exhibit both positive and negative relationships. We have identified two significant challenges in this domain: i) existing signed spectral methods are highly vulnerable to noise, which is prevalent in real-world scenarios; ii) the guiding principle "an enemy of my enemy is my friend", rooted in  Social Balance Theory,  often narrows or disrupts cluster boundaries in mainstream signed graph neural networks. Addressing these challenges, we propose the <u>D</u>eep <u>S</u>igned <u>G</u>raph <u>C</u>lustering framework (DSGC), which leverages  Weak Balance Theory  to enhance preprocessing and encoding for robust representation learning. First, DSGC introduces Violation Sign-Refine to denoise the signed network by correcting noisy edges with high-order neighbor information. Subsequently, Density-based Augmentation enhances semantic structures by adding positive edges within clusters and negative edges across clusters, following  Weak Balance  principles. The framework then utilizes  Weak Balance  principles to develop clustering-oriented signed neural networks to broaden cluster boundaries by emphasizing distinctions between negatively linked nodes. Finally, DSGC optimizes clustering assignments by minimizing a regularized clustering loss. Comprehensive experiments on synthetic and real-world datasets demonstrate DSGC consistently outperforms all baselines, establishing a new benchmark in signed graph clustering.}
}


@inproceedings{DBLP:conf/www/YanGLMWB25,
	author = {Chuan Yan and
                  Bowei Guan and
                  Yazhi Li and
                  Mark Huasong Meng and
                  Liuhuo Wan and
                  Guangdong Bai},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Understanding and Detecting File Knowledge Leakage in {GPT} App Ecosystem},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {3831--3839},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714755},
	doi = {10.1145/3696410.3714755},
	timestamp = {Fri, 09 May 2025 20:28:10 +0200},
	biburl = {https://dblp.org/rec/conf/www/YanGLMWB25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {OpenAI has enabled third-party developers to build applications around ChatGPT, known as GPTs, to expand its capability to handle complex and specialized tasks. A key feature of GPTs is Retrieval-Augmented Generation (RAG), which allows developers to upload documents containing domain knowledge or application context, referred to as  file knowledge . However, these documents often contain sensitive information, and the security mechanisms governing access control in GPTs remains an underexplored area. In this work, we present the first comprehensive study on file knowledge leakage within GPTs. We develop GPTs-Filtor, leveraging the unique characteristics of GPTs deployment, to perform an in-depth analysis and detection of file knowledge leakage at both user interaction (i.e., prompt) and network transmission levels. Applying GPTs-Filtor to 8,000 popular GPTs across eight different categories, we reveal widespread vulnerabilities in the current GPTs development and deployment model. We detect 618 cases of leakage among 1,331 GPTs that involve uploaded file knowledge, leading to the exfiltration of 3,645 file contents that contain highly-sensitive data such as internal bank audit transaction records. Our work underscores the pressing need for improved security practices in GPTs development and deployment, providing crucial insights for the secure development of this young but rapidly evolving ecosystem.}
}


@inproceedings{DBLP:conf/www/CaoZCZW25,
	author = {Yang Cao and
                  Changhao Zhang and
                  Xiaoshuang Chen and
                  Kaiqiao Zhan and
                  Ben Wang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {xMTF: {A} Formula-Free Model for Reinforcement-Learning-Based Multi-Task
                  Fusion in Recommender Systems},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {3840--3849},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714959},
	doi = {10.1145/3696410.3714959},
	timestamp = {Fri, 09 May 2025 20:28:11 +0200},
	biburl = {https://dblp.org/rec/conf/www/CaoZCZW25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recommender systems need to optimize various types of user feedback, e.g., clicks, likes, and shares. A typical recommender system handling multiple types of feedback has two components: a multi-task learning (MTL) module, predicting feedback such as click-through rate and like rate; and a multi-task fusion (MTF) module, integrating these predictions into a single score for item ranking. MTF is essential for ensuring user satisfaction, as it directly influences recommendation outcomes. Recently, reinforcement learning (RL) has been applied to MTF tasks to improve long-term user satisfaction. However, existing RL-based MTF methods are formula-based methods, which only adjust limited coefficients within pre-defined formulas. The pre-defined formulas restrict the RL search space and become a bottleneck for MTF. To overcome this, we propose a formula-free MTF framework. We demonstrate that any suitable fusion function can be expressed as a composition of single-variable monotonic functions, as per the Sprecher Representation Theorem. Leveraging this, we introduce a novel learnable monotonic fusion cell (MFC) to replace pre-defined formulas. We call this new MFC-based model eXtreme MTF (xMTF). Furthermore, we employ a two-stage hybrid (TSH) learning strategy to train xMTF effectively. By expanding the MTF search space, xMTF outperforms existing methods in extensive offline and online experiments.}
}


@inproceedings{DBLP:conf/www/JiangWMCWWZ25,
	author = {Chumeng Jiang and
                  Jiayin Wang and
                  Weizhi Ma and
                  Charles L. A. Clarke and
                  Shuai Wang and
                  Chuhan Wu and
                  Min Zhang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Beyond Utility: Evaluating {LLM} as Recommender},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {3850--3862},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714759},
	doi = {10.1145/3696410.3714759},
	timestamp = {Fri, 09 May 2025 20:28:11 +0200},
	biburl = {https://dblp.org/rec/conf/www/JiangWMCWWZ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the rapid development of Large Language Models (LLMs), recent studies employed LLMs as recommenders to provide personalized information services for distinct users. Despite efforts to improve the accuracy of LLM-based recommendation models, relatively little attention is paid to beyond-utility dimensions. Moreover, there are unique evaluation aspects of LLM-based recommendation models, which have been largely ignored. To bridge this gap, we explore four new evaluation dimensions and propose a multidimensional evaluation framework. The new evaluation dimensions include: 1) history length sensitivity, 2) candidate position bias, 3) generation-involved performance, and 4) hallucinations. All four dimensions have the potential to impact performance, but are largely unnecessary for consideration in traditional systems. Using this multidimensional evaluation framework, along with traditional aspects, we evaluate the performance of seven LLM-based recommenders, with three prompting strategies, comparing them with six traditional models on both ranking and re-ranking tasks on four datasets. We find that LLMs excel at handling tasks with prior knowledge and shorter input histories in the ranking setting, and perform better in the re-ranking setting, beating traditional models across multiple dimensions. However, LLMs exhibit substantial candidate position bias issues, and some models hallucinate nonexistent items much more often than others. We intend our evaluation framework and observations to benefit future research on the use of LLMs as recommenders. The code and data are available at https://github.com/JiangDeccc/EvaLLMasRecommender.}
}


@inproceedings{DBLP:conf/www/YueL0YG025,
	author = {Linan Yue and
                  Qi Liu and
                  Yawen Li and
                  Fangzhou Yao and
                  Weibo Gao and
                  Junping Du},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Empowering Federated Graph Rationale Learning with Latent Environments},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {3863--3873},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714929},
	doi = {10.1145/3696410.3714929},
	timestamp = {Fri, 09 May 2025 20:28:11 +0200},
	biburl = {https://dblp.org/rec/conf/www/YueL0YG025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The success of Graph Neural Networks (GNNs) in graph classification has heightened interest in explainable GNNs, particularly through graph rationalization. This method aims to enhance GNNs explainability by identifying subgraph structures (i.e., rationales) that support model predictions. However, existing methods often rely on centralized datasets, posing challenges in scenarios where data privacy is crucial, such as in molecular property prediction. Federated Learning (FL) offers a solution by enabling collaborative model training without sharing raw data. In this context, Federated Graph Rationalization emerges as a promising research direction. However, in each client, the rationalization methods often rely on client-specific shortcuts to compose rationales and make task predictions. Data heterogeneity, characterized by non-IID data across clients, exacerbates this problem, leading to poor prediction performance. To address these challenges, we propose the Environment-aware Data Augmentation (EaDA) method for Federated Graph Rationalization. EaDA comprises two main components: the Environment-aware Rationale Extraction (ERE) module and the Local-Global Alignment (LGA) module. The ERE module employs prototype learning to infer and share abstract environment information across clients, which are then aggregated to form a global environment. This information is used to generate counterfactual samples for local clients, enhancing the robustness of task predictions. The LGA module uses contrastive learning methods to align local and global rationale representations, mitigating performance degradation due to data heterogeneity. Comprehensive experiments on benchmark datasets demonstrate the effectiveness of our approaches. Code is available at https://github.com/yuelinan/Codes-of-EaDA.}
}


@inproceedings{DBLP:conf/www/LiYJWYW25,
	author = {Rong{-}Hua Li and
                  Xiaowei Ye and
                  Fusheng Jin and
                  Yu{-}Ping Wang and
                  Ye Yuan and
                  Guoren Wang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Counting Cohesive Subgraphs with Hereditary Properties},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {3874--3884},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714730},
	doi = {10.1145/3696410.3714730},
	timestamp = {Fri, 09 May 2025 20:28:11 +0200},
	biburl = {https://dblp.org/rec/conf/www/LiYJWYW25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The classic clique model has properties of hereditaries and cohesiveness. Here hereditaries means a subgraph of a clique is still a clique. Counting small cliques in a graph is a fundamental operation of numerous applications. However, the clique model is often too restrictive for practical use, leading to the focus on other relaxed-cliques with properties of hereditaries and cohesiveness. To address this issue, we investigate a new problem of counting general hereditary cohesive subgraphs (HCS). All subgraphs with properties of hereditaries and cohesiveness can be called a kind of HCS. To count HCS, we propose a general framework called HCSPivot, which can be applied to count all kinds of HCS. HCSPivot can count most HCS combinatorially without explicitly listing them. Two additional noteworthy features of HCSPivot are its ability to (1) simultaneously count HCS of any size and (2) simultaneously count HCS for each node or each edge. Based on our HCSPivot framework, we propose two novel algorithms with several carefully designed pruning techniques to count  s -defective cliques and  s -plexes, which are two specific types of HCS. We conduct extensive experiments on 8 large real-world graphs, and the results demonstrate the high efficiency and effectiveness of our solutions.}
}


@inproceedings{DBLP:conf/www/AyoubRLSK25,
	author = {Alex Ayoub and
                  Samuel Robertson and
                  Dawen Liang and
                  Harald Steck and
                  Nathan Kallus},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Does Weighting Improve Matrix Factorization for Recommender Systems?},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {3885--3895},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714680},
	doi = {10.1145/3696410.3714680},
	timestamp = {Fri, 09 May 2025 20:28:11 +0200},
	biburl = {https://dblp.org/rec/conf/www/AyoubRLSK25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Matrix factorization is a widely used approach for top-N recommendation and collaborative filtering. When implemented on implicit feedback data (such as clicks), a common heuristic is to upweight the observed interactions. This strategy has been shown to improve performance for certain algorithms. In this paper, we conduct a systematic study of various weighting schemes and matrix factorization algorithms. Somewhat surprisingly, we find that training with unweighted data can perform comparably to-and sometimes outperform-training with weighted data, especially for large models. This observation challenges the conventional wisdom. Nevertheless, we identify cases where weighting can be beneficial, particularly for models with lower capacity and specific regularization schemes. We also derive efficient algorithms for exactly minimizing several weighted objectives that were previously considered computationally intractable. Our work provides a comprehensive analysis of the interplay between weighting, regularization, and model capacity in matrix factorization for recommender systems.}
}


@inproceedings{DBLP:conf/www/AnnamalaiCB25,
	author = {Meenatchi Sundaram Muthu Selva Annamalai and
                  Emiliano De Cristofaro and
                  Igor Bilogrevic},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Beyond the Crawl: Unmasking Browser Fingerprinting in Real User Interactions},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {3896--3907},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714871},
	doi = {10.1145/3696410.3714871},
	timestamp = {Fri, 09 May 2025 20:28:11 +0200},
	biburl = {https://dblp.org/rec/conf/www/AnnamalaiCB25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Browser fingerprinting is a pervasive online tracking technique used increasingly often for profiling and targeted advertising. Prior research on the prevalence of fingerprinting heavily relied on automated web crawls, which inherently struggle to replicate the nuances of human-computer interactions. This raises concerns about the accuracy of current understandings of real-world fingerprinting deployments. As a result, this paper presents a user study involving 30 participants over 10 weeks, capturing telemetry data from real browsing sessions across 3,000 top-ranked websites. Our evaluation reveals that automated crawls miss almost half (45%) of the fingerprinting websites encountered by real users. This discrepancy mainly stems from the crawlers' inability to access authentication-protected pages, circumvent bot detection, and trigger fingerprinting scripts activated by specific user interactions. We also identify potential new fingerprinting vectors present in real user data but absent from automated crawls. Finally, we evaluate the effectiveness of federated learning for training browser fingerprinting detection models on real user data, yielding improved performance than models trained solely on automated crawl data.}
}


@inproceedings{DBLP:conf/www/LianCLX0Z25,
	author = {Xinglin Lian and
                  Chengtai Cao and
                  Yan Liu and
                  Xovee Xu and
                  Yu Zheng and
                  Fan Zhou},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Facing Anomalies Head-On: Network Traffic Anomaly Detection via Uncertainty-Inspired
                  Inter-Sample Differences},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {3908--3917},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714621},
	doi = {10.1145/3696410.3714621},
	timestamp = {Fri, 09 May 2025 20:28:11 +0200},
	biburl = {https://dblp.org/rec/conf/www/LianCLX0Z25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Network traffic anomaly detection is pivotal in cybersecurity, especially as data volume grows and security requirement intensifies. This study addresses critical limitations in existing reconstruction-based methods, which quantify anomalies relying on intra-sample differences and struggle to detect drifted anomalies. In response, we propose a novel approach, the Uncertainty-Inspired Inter-Sample Differences (UnDiff) method, which leverages model uncertainty to enhance anomaly detection capabilities, particularly in scenarios involving anomaly drift. By employing evidential learning, the UnDiff model gathers evidence to minimize uncertainty in normal network traffic, enhancing its ability to differentiate between normal and anomalous traffic. To overcome the limitations of intra-sample difference quantification in reconstruction-based methods, we propose a novel anomaly score based on inter-sample uncertainty deviation that directly quantifies the anomaly degree. Benefiting from a concise model design and parameterized uncertainty quantification, UnDiff achieves high efficiency. Extensive experiments on three benchmarks demonstrate UnDiff's superior performance in detecting both undrifted and drifted anomalies with minimal computational overhead.}
}


@inproceedings{DBLP:conf/www/Li00ZZ25,
	author = {Yingxuan Li and
                  Yuanyuan Xu and
                  Xuemin Lin and
                  Wenjie Zhang and
                  Ying Zhang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Ranking on Dynamic Graphs: An Effective and Robust Band-Pass Disentangled
                  Approach},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {3918--3929},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714943},
	doi = {10.1145/3696410.3714943},
	timestamp = {Fri, 09 May 2025 20:28:11 +0200},
	biburl = {https://dblp.org/rec/conf/www/Li00ZZ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Ranking is an essential and practical task on dynamic graphs, which aims to prioritize future interaction candidates for given queries. While existing solutions achieve promising ranking performance, they leverage a single listwise loss to jointly optimize candidate sets, which leads to the gradient vanishing issue; and they employ neural networks to model complex temporal structures within a shared latent space, which fails to accurately capture multi-scale temporal patterns due to the frequency aliasing issue. To address these issues, we propose BandRank, a novel and robust band-pass disentangled ranking approach for dynamic graphs in the frequency domain. Concretely, we propose a band-pass disentangled representation (BPDR) approach, which disentangles complex temporal structures into multiple frequency bands and employs non-shared frequency-enhanced multilayer perceptrons (MLPs) to model each band independently. We prove that our BPDR approach ensures effective multi-scale learning for temporal structures by demonstrating its multi-scale global convolution property. Besides, we design a robust Harmonic Ranking (HR) loss to jointly optimize candidate sets and continuously track comparisons between real and virtual candidates, where we theoretically guarantee its ability to alleviate the gradient vanishing issue. Extensive experimental results show that our BandRank achieves an average improvement of 21.31% against eight baselines while demonstrating superior robustness across different learning scenarios.}
}


@inproceedings{DBLP:conf/www/XianL00XY25,
	author = {Yantuan Xian and
                  Pu Li and
                  Hao Peng and
                  Zhengtao Yu and
                  Yan Xiang and
                  Philip S. Yu},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Community Detection in Large-Scale Complex Networks via Structural
                  Entropy Game},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {3930--3941},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714837},
	doi = {10.1145/3696410.3714837},
	timestamp = {Fri, 09 May 2025 20:28:11 +0200},
	biburl = {https://dblp.org/rec/conf/www/XianL00XY25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Community detection is a critical task in graph theory, social network analysis, and bioinformatics, where communities are defined as clusters of densely interconnected nodes. However, detecting communities in large-scale networks with millions of nodes and billions of edges remains challenging due to the inefficiency and unreliability of existing methods. Moreover, many current approaches are limited to specific graph types, such as unweighted or undirected graphs, reducing their broader applicability. To address these issues, we propose a novel heuristic community detection algorithm, termed CoDeSEG, which identifies communities by minimizing the network's two-dimensional (2D) structural entropy within a potential game framework. In the game, nodes decide to stay in the current community or move to another based on a strategy that maximizes the 2D structural entropy utility function. Additionally, we introduce a structural entropy-based node overlapping heuristic for detecting overlapping communities, with a near-linear time complexity. Experimental results on real-world networks demonstrate that CoDeSEG is the fastest method available and achieves state-of-the-art performance in overlapping normalized mutual information (ONMI) and F1 scores.}
}


@inproceedings{DBLP:conf/www/LiuLX0ZLLS25,
	author = {Zheng Liu and
                  Chaofan Li and
                  Shitao Xiao and
                  Chaozhuo Li and
                  Chen Jason Zhang and
                  Hao Liao and
                  Defu Lian and
                  Yingxia Shao},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Fitting Into Any Shape: {A} Flexible LLM-Based Re-Ranker With Configurable
                  Depth and Width},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {3942--3951},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714620},
	doi = {10.1145/3696410.3714620},
	timestamp = {Fri, 09 May 2025 20:28:11 +0200},
	biburl = {https://dblp.org/rec/conf/www/LiuLX0ZLLS25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Large language models (LLMs) provide powerful foundations to perform fine-grained text re-ranking. However, they are often prohibitive in reality due to constraints on computation bandwidth. In this work, we propose a  flexible  architecture called  Matroyshka Re-Ranker,  which is designed to facilitate  runtime customization  of model layers and sequence lengths at each layer based on users' configurations. Consequently, the LLM-based re-rankers can be made applicable across various real-world situations. The increased flexibility may come at the cost of precision loss. To address this problem, we introduce a suite of techniques to optimize the performance. First, we propose  cascaded self-distillation,  where each sub-architecture learns to preserve a precise re-ranking performance from its super components, whose predictions can be exploited as smooth and informative teacher signals. Second, we design a  factorized compensation mechanism,  where two collaborative LoRA modules, vertical and horizontal, are jointly employed to compensate for the precision loss resulted from arbitrary combinations of layer and sequence compression. We perform comprehensive experiments using passage and document retrieval datasets from MSMARCO, along with all public datasets from BEIR. In our experiments, Matryoshka Re-Ranker substantially outperforms existing methods, while effectively preserving its superior performance across various compression forms and application scenarios. We have publicly released our method at this https://github.com/FlagOpen/FlagEmbedding repo.}
}


@inproceedings{DBLP:conf/www/GuoK25,
	author = {Yongkang Guo and
                  Yuqing Kong},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Robust Aggregation with Adversarial Experts},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {3952--3967},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714557},
	doi = {10.1145/3696410.3714557},
	timestamp = {Fri, 09 May 2025 20:28:11 +0200},
	biburl = {https://dblp.org/rec/conf/www/GuoK25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We consider a robust aggregation problem in the presence of both truthful and adversarial experts. The truthful experts will report their private signals truthfully, while the adversarial experts can report arbitrarily. We assume experts are marginally symmetric in the sense that they share the same common prior and marginal posteriors. The rule maker needs to design an aggregator to predict the true world state from these experts' reports, without knowledge of the underlying information structures or adversarial strategies. We aim to find the optimal aggregator that outputs a forecast minimizing regret under the worst information structure and adversarial strategies. The regret is defined by the difference in expected loss between the aggregator and a benchmark who aggregates optimally given the information structure and reports of truthful experts. We focus on binary states and reports. Under L1 loss, we show that the truncated mean aggregator is optimal. When there are at most k adversaries, this aggregator discards the k lowest and highest reported values and averages the remaining ones. For L2 loss, the optimal aggregators are piecewise linear functions. All the optimalities hold when the ratio of adversaries is bounded above by a value determined by the experts' priors and posteriors. The regret only depends on the ratio of adversaries, not on their total number. For hard aggregators that output a decision, we prove that a random version of the truncated mean is optimal for both L1 and L2. This aggregator randomly follows a remaining value after discarding the  k  lowest and highest reported values. We extend the hard aggregator to multi-state setting. We evaluate our aggregators numerically in an ensemble learning task. We also obtain negative results for general adversarial aggregation problems under broader information structures and report spaces.}
}


@inproceedings{DBLP:conf/www/AcharyaLCH25,
	author = {Bhupendra Acharya and
                  Dario Lazzaro and
                  Antonio Emanuele Cin{\`{a}} and
                  Thorsten Holz},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Pirates of Charity: Exploring Donation-based Abuses in Social Media
                  Platforms},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {3968--3981},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714634},
	doi = {10.1145/3696410.3714634},
	timestamp = {Fri, 09 May 2025 20:28:11 +0200},
	biburl = {https://dblp.org/rec/conf/www/AcharyaLCH25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the widespread use of social media, organizations, and individuals use these platforms to raise funds and support causes. Unfortunately, this has led to the rise of scammers in soliciting fraudulent donations. In this study, we conduct a large-scale analysis of donation-based scams on social media platforms. More specifically, we studied profile creation and scam operation fraudulent donation solicitation on X, Instagram, Facebook, YouTube, and Telegram. By collecting data from 151,966 accounts and their 3,053,333 posts related to donations between March 2024 and May 2024, we identified 832 scammers using various techniques to deceive users into making fraudulent donations. Analyzing the fraud communication channels such as phone number, email, and external URL linked, we show that these scamming accounts perform various fraudulent donation schemes, including classic abuse such as fake fundraising website setup, crowdsourcing fundraising, and asking users to communicate via email, phone, and pay via various payment methods. Through collaboration with industry partners PayPal and cryptocurrency abuse database Chainabuse, we further validated the scams and measured the financial losses on these platforms. Our study highlights significant weaknesses in social media platforms' ability to protect users from fraudulent donations. Additionally, we recommended social media platforms, and financial services for taking proactive steps to block these fraudulent activities. Our study provides a foundation for the security community and researchers to automate detecting and mitigating fraudulent donation solicitation on social media platforms.}
}


@inproceedings{DBLP:conf/www/SharmaS25,
	author = {Saurabh Sharma and
                  Ambuj K. Singh},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Dynamic Gradient Influencing for Viral Marketing Using Graph Neural
                  Networks},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {3982--3993},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714886},
	doi = {10.1145/3696410.3714886},
	timestamp = {Thu, 01 May 2025 20:27:25 +0200},
	biburl = {https://dblp.org/rec/conf/www/SharmaS25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The problem of maximizing the adoption of a product through viral marketing in social networks has been studied heavily through postulated network models. We present a novel data-driven formulation of the problem. We use Graph Neural Networks (GNNs) to model the adoption of products by utilizing both topological and attribute information. The resulting  Dynamic Viral Marketing (DVM)  problem seeks to find the minimum budget and minimal set of dynamic topological and attribute changes in order to attain a specified adoption goal. We show that DVM is NP-Hard and is related to the existing influence maximization problem. Motivated by this connection, we develop the idea of Dynamic Gradient Influencing (DGI) that uses gradient ranking to find optimal perturbations and targets low-budget and high influence non-adopters in discrete steps. We use an efficient strategy for computing node budgets and develop the ''Meta-Influence'' heuristic for assessing a node's downstream influence. We evaluate DGI against multiple baselines and demonstrate gains on average of 24% on budget and 37% on AUC on real-world attributed networks. Our code is publicly available at https://github.com/saurabhsharma1993/dynamic_viral_marketing.}
}


@inproceedings{DBLP:conf/www/ZhangYW00L0C25,
	author = {Jiaqing Zhang and
                  Mingjia Yin and
                  Hao Wang and
                  Yawen Li and
                  Yuyang Ye and
                  Xingyu Lou and
                  Junping Du and
                  Enhong Chen},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {{TD3:} Tucker Decomposition Based Dataset Distillation Method for
                  Sequential Recommendation},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {3994--4003},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714613},
	doi = {10.1145/3696410.3714613},
	timestamp = {Fri, 09 May 2025 20:28:11 +0200},
	biburl = {https://dblp.org/rec/conf/www/ZhangYW00L0C25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the era of data-centric AI, the focus of recommender systems has shifted from model-centric innovations to data-centric approaches. The success of modern AI models is built on large-scale datasets, but this also results in significant training costs. Dataset distillation has emerged as a key solution, condensing large datasets to accelerate model training while preserving model performance. However, condensing discrete and sequentially correlated user-item interactions, particularly with extensive item sets, presents considerable challenges. This paper introduces  TD3,  a novel  T ucker  D ecomposition based  D ataset  D istillation method within a meta-learning framework, designed for sequential recommendation. TD3 distills a fully expressive  synthetic sequence summary  from original data. To efficiently reduce computational complexity and extract refined latent patterns, Tucker decomposition decouples the summary into four factors:  synthetic user latent factor, temporal dynamics latent factor, shared item latent factor,  and a  relation core  that models their interconnections. Additionally, a surrogate objective in bi-level optimization is proposed to align feature spaces extracted from models trained on both original data and synthetic sequence summary beyond the naive performance matching approach. In the  inner-loop,  an augmentation technique allows the learner to closely fit the synthetic summary, ensuring an accurate update of it in the  outer-loop.  To accelerate the optimization process and address long dependencies, RaT-BPTT is employed for bi-level optimization. Experiments and analyses on multiple public datasets have confirmed the superiority and cross-architecture generalizability of the proposed designs. Codes are released at https://github.com/USTC-StarTeam/TD3.}
}


@inproceedings{DBLP:conf/www/MaWLYZ25,
	author = {Junxiao Ma and
                  Jingjing Wang and
                  Jiamin Luo and
                  Peiying Yu and
                  Guodong Zhou},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Sherlock: Towards Multi-scene Video Abnormal Event Extraction and
                  Localization via a Global-local Spatial-sensitive {LLM}},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {4004--4013},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714617},
	doi = {10.1145/3696410.3714617},
	timestamp = {Fri, 09 May 2025 20:28:11 +0200},
	biburl = {https://dblp.org/rec/conf/www/MaWLYZ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Prior studies on Video Anomaly Detection (VAD) mainly focus on detecting whether each video frame is abnormal or not in the video, which largely ignore the structured video semantic information (i.e., what, when, and where does the abnormal event happen). With this in mind, this paper propose a new chat-paradigm  M ulti-scene  V ideo  A bnormal  E vent Extraction and Localization (M-VAE) task, aiming to extract the abnormal event quadruples (i.e., subject, event type, object, scene) and localize such event. Further, this paper believes that this new task faces two key challenges, i.e., global-local spatial modeling and global-local spatial balancing. To this end, this paper proposes a Global-local Spatial-sensitive Large Language Model (LLM) named Sherlock, i.e., acting like Sherlock Holmes to track down the criminal events, for this M-VAE task. Specifically, this model designs a Global-local Spatial-enhanced MoE (GSM) module and a Spatial Imbalance Regulator (SIR) to address the two challenges respectively. Extensive experiments on our M-VAE instruction dataset show the significant advantages of Sherlock over several advanced Video-LLMs. This justifies the importance of global-local spatial information for the M-VAE task and the effectiveness of Sherlock in capturing such information.}
}


@inproceedings{DBLP:conf/www/JungPLOL25,
	author = {Sungjun Jung and
                  Yongsang Park and
                  Haeun Lee and
                  Young H. Oh and
                  Jae W. Lee},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Angular Distance-Guided Neighbor Selection for Graph-Based Approximate
                  Nearest Neighbor Search},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {4014--4023},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714870},
	doi = {10.1145/3696410.3714870},
	timestamp = {Fri, 09 May 2025 20:28:11 +0200},
	biburl = {https://dblp.org/rec/conf/www/JungPLOL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graph-based approximate nearest neighbor search (ANNS) algorithms are widely used to identify the most similar vectors to a given query vector. Graph-based ANNS consists of two stages: constructing a graph and searching on the graph for a given query vector. While reducing the query response time is of great practical importance, less attention has been paid to improving the online search method than the offline graph construction method. This paper provides an extensive experimental analysis on the popular greedy search and other search optimization strategies. We also propose a novel <u>a</u>ngular <u>d</u>istance-guided search method for graph-based <u>ANNS</u> (ADA-NNS) to improve search efficiency. The key innovation of ADA-NNS is introducing a low-cost neighbor selection mechanism based on approximate similarity score derived from angular distance estimation, which effectively filters out less relevant neighbors. We compare state-of-the-art search techniques, including FINGER, on six datasets using different similarity metrics. It provides a comprehensive perspective on their tradeoffs in terms of throughput, latency, and recall. Our evaluation shows that ADA-NNS achieves 34%-107% higher queries per second (QPS) than the greedy search at 95% recall@10 on HNSW, one of the most popular graph structures for ANNS.}
}


@inproceedings{DBLP:conf/www/000100LC25,
	author = {Sungwon Park and
                  Sungwon Han and
                  Xing Xie and
                  Jae{-}Gil Lee and
                  Meeyoung Cha},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Adversarial Style Augmentation via Large Language Model for Robust
                  Fake News Detection},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {4024--4033},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714569},
	doi = {10.1145/3696410.3714569},
	timestamp = {Fri, 09 May 2025 20:28:11 +0200},
	biburl = {https://dblp.org/rec/conf/www/000100LC25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The spread of fake news harms individuals and presents a critical social challenge that must be addressed. Although numerous algorithmic and insightful features have been developed to detect fake news, many of these features can be manipulated with style-conversion attacks, especially with the emergence of advanced language models, making it more difficult to differentiate from genuine news. This study proposes adversarial style augmentation, AdStyle, designed to train a fake news detector that remains robust against various style-conversion attacks. The primary mechanism involves the strategic use of LLMs to automatically generate a diverse and coherent array of style-conversion attack prompts, enhancing the generation of particularly challenging prompts for the detector. Experiments indicate that our augmentation strategy significantly improves robustness and detection performance when evaluated on fake news benchmark datasets.}
}


@inproceedings{DBLP:conf/www/BariledF25,
	author = {Roberto Barile and
                  Claudia d'Amato and
                  Nicola Fanizzi},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {{LP-DIXIT:} Evaluating Explanations for Link Predictions on Knowledge
                  Graphs using Large Language Models},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {4034--4042},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714667},
	doi = {10.1145/3696410.3714667},
	timestamp = {Thu, 01 May 2025 20:27:22 +0200},
	biburl = {https://dblp.org/rec/conf/www/BariledF25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Knowledge Graphs provide a machine-readable representation of knowledge conforming to graph-based data models. Link prediction methods predict missing facts in incomplete knowledge graphs, often using scalable embedding based solutions that, however, lack comprehensibility which is crucial in many domains. Filling this gap, explanation methods identify supporting knowledge. For evaluating them, user studies are the obvious choice as users are the main recipients of explanations. However, finding domain experts is often challenging. In contrast, an automated approach is to measure the influence of explanations on the very same link prediction task, thus disregarding the perspective of users. Additionally, current evaluation methods vary across different explanation approaches. We propose LP-DIXIT, the first protocol to evaluate the utility of explanations of link predictions. LP-DIXIT is user-aware, algorithmic and unique for different explanation methods. It builds on a typical setting of user studies, but adopts Large Language Models (LLMs) to mimic users. Specifically, it measures how explanations improve the user (LLM) ability to perform predictions, which is key to trust. We experimentally proved an overall agreement between LP-DIXIT and user evaluations. Moreover, we adopted LP-DIXIT to conduct a comparative study of state-of-the-art explanation methods. The outcomes suggest that less is more: the most effective explanations are those consisting of a single fact.}
}


@inproceedings{DBLP:conf/www/HuangZYW25,
	author = {Qihe Huang and
                  Zhengyang Zhou and
                  Kuo Yang and
                  Yang Wang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Exploiting Language Power for Time Series Forecasting with Exogenous
                  Variables},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {4043--4052},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714793},
	doi = {10.1145/3696410.3714793},
	timestamp = {Tue, 13 May 2025 07:31:04 +0200},
	biburl = {https://dblp.org/rec/conf/www/HuangZYW25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The World Wide Web thrives on intelligent services that depend heavily on accurate time series forecasting to navigate dynamic and evolving environments. Due to the partially-observed nature of real world, exclusively focusing on the target of interest, so-called  endogenous variables , is insufficient for accurate forecasting, especially in web systems that are susceptible to external influences. Thus, utilizing  exogenous variables  to harness external information, i.e., forecasting with exogenous variable (FEV), is imperative. Nevertheless, as the external environment is complex and ever-evolving, inadequately capturing external influences can even lead to learning spurious correlations and invalid prediction. Fortunately, recent studies have demonstrated that large language models (LLMs) exhibit exceptional recognition capabilities across open real-world systems, including a deep understanding of exogenous environments. However, it is difficult to directly apply LLMs for FEV due to challenges of task activation, exogenous knowledge extraction, and feature space alignment. In this work, we devise ExoLLM, an <u>LLM</u>-driven method to sufficiently utilize <u>Exo</u>genous variables for time series forecasting. We begin by Meta-task Instruction to activate the knowledge transfer of LLM from natural language processing to FEV. To comprehensively understand the intricate and hierarchical influences of exogenous variables, we propose Multi-grained Prompts, encompassing diverse external influences, including natural attributes, trend correlations, and period relationships between two types of variables. Additionally, a Dual TS-Text Attention is devised to bridge the feature gap between text and numeric data in LLM. Evaluation on real-world datasets demonstrates ExoLLM's superiority in exploiting exogenous information for forecasting with open-world language knowledge.}
}


@inproceedings{DBLP:conf/www/Wijesinghe0K25,
	author = {Asiri Wijesinghe and
                  Hao Zhu and
                  Piotr Koniusz},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Graph Self-Supervised Learning with Learnable Structural and Positional
                  Encodings},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {4053--4067},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714745},
	doi = {10.1145/3696410.3714745},
	timestamp = {Fri, 09 May 2025 20:28:11 +0200},
	biburl = {https://dblp.org/rec/conf/www/Wijesinghe0K25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Traditional Graph Self-Supervised Learning (GSSL) struggles to capture complex structural properties well. This limitation stems from two main factors: (1) the inadequacy of conventional Graph Neural Networks (GNNs) in representing sophisticated topological features, and (2) the focus of self-supervised learning solely on final graph representations. To address these issues, we introduce GenHopNet, a GNN framework that integrates a  k -hop message-passing scheme, enhancing its ability to capture local structural information without explicit substructure extraction. We theoretically demonstrate that GenHopNet surpasses the expressiveness of the classical Weisfeiler-Lehman (WL) test for graph isomorphism. Furthermore, we propose a structural- and positional-aware GSSL framework that incorporates topological information throughout the learning process. This approach enables the learning of representations that are both sensitive to graph topology and invariant to specific structural and feature augmentations. Comprehensive experiments on graph classification datasets, including those designed to test structural sensitivity, show that our method consistently outperforms the existing approaches and maintains computational efficiency. Our work significantly advances GSSL's capability in distinguishing graphs with similar local structures but different global topologies.}
}


@inproceedings{DBLP:conf/www/ShiCF00C25,
	author = {Ruizhe Shi and
                  Ruizhi Cheng and
                  Yuqi Fu and
                  Bo Han and
                  Yue Cheng and
                  Songqing Chen},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Centralization in the Decentralized Web: Challenges and Opportunities
                  in {IPFS} Data Management},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {4068--4076},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714627},
	doi = {10.1145/3696410.3714627},
	timestamp = {Wed, 23 Apr 2025 16:35:50 +0200},
	biburl = {https://dblp.org/rec/conf/www/ShiCF00C25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The InterPlanetary File System (IPFS) is a pioneering effort for Web 3.0, well-known for its decentralized infrastructure. However, some recent studies have shown that IPFS exhibits a high degree of centralization and has integrated centralized components for improved performance. While this change contradicts the core decentralized ethos of IPFS and introduces risks of hurting the data replication level and thus availability, it also opens some opportunities for better data management and cost savings through deduplication. To explore these challenges and opportunities, we start by collecting an extensive dataset of IPFS internal traffic spanning the last three years with 20+ billion messages. By analyzing this long-term trace, we obtain a more complete and accurate view of how the status of centralization evolves over an extended period. In particular, our study reveals that (1) IPFS shows a low replication level, with only 2.71% of data files replicated more than 5 times. While increasing replication enhances lookup performance and data availability, it adversely affects downloading throughput due to the overhead involved in managing peer connections, (2) there is a clear growing trend in centralization within IPFS in the last 3 years, with just 5% of peers now hosting over 80% of the content, significantly decreasing from 21.38% 3 years ago, which is largely driven by the increase of cloud nodes, (3) the default deduplication strategy of IPFS using Fixed-Size Chunking (FSC) is largely inefficient, especially with the default 256KB chunk size, showing near-zero duplication being detected. Although Content-Defined Chunking (CDC) with smaller chunks could save ~1.8 petabytes (PB) storage space, it could impact user performance negatively. We thus design and evaluate a new metadata format that optimizes deduplication without compromising performance.}
}


@inproceedings{DBLP:conf/www/YuZM025,
	author = {Fangchen Yu and
                  Yicheng Zeng and
                  Jianfeng Mao and
                  Wenye Li},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {A Theory-Driven Approach to Inner Product Matrix Estimation for Incomplete
                  Data: An Eigenvalue Perspective},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {4077--4088},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714947},
	doi = {10.1145/3696410.3714947},
	timestamp = {Fri, 09 May 2025 20:28:11 +0200},
	biburl = {https://dblp.org/rec/conf/www/YuZM025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Addressing the critical challenge of data incompleteness in inner product matrix estimation, we introduce a novel eigenvalue correction method designed to precisely reconstruct true inner product matrices from incomplete data. Utilizing random matrix theory, our method adjusts the eigenvalue distribution of the estimated inner product matrix to align with the ground truth. This approach significantly reduces estimation errors for both inner product matrices and the associated Euclidean distance matrices, thereby enhancing the effectiveness of similarity searches on incomplete data. Our method surpasses traditional data imputation and similarity calibration techniques in both maximum inner product search and nearest neighbor search tasks, demonstrating marked advancements in managing incomplete data.}
}


@inproceedings{DBLP:conf/www/Zhao00CX0LL00W25,
	author = {Peng Zhao and
                  You Zhou and
                  Di Wang and
                  Zhiguang Cao and
                  Yubin Xiao and
                  Xuan Wu and
                  Yuanshu Li and
                  Hongjia Liu and
                  Wei Du and
                  Yuan Jiang and
                  Liupu Wang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Dual Operation Aggregation Graph Neural Networks for Solving Flexible
                  Job-Shop Scheduling Problem with Reinforcement Learning},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {4089--4100},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714616},
	doi = {10.1145/3696410.3714616},
	timestamp = {Fri, 09 May 2025 20:28:11 +0200},
	biburl = {https://dblp.org/rec/conf/www/Zhao00CX0LL00W25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the widespread adoption of Internet Protocol (IP) communication technology and web-based platforms, cloud manufacturing has become a significant hallmark of Industry 4.0. Integrating graph algorithms into these web-enabled environments is crucial as they facilitate the representation and analysis of complex relationships in manufacturing processes, enabling efficient decision-making and adaptability in dynamic environments. As a key scheduling problem in cloud manufacturing, the flexible job-shop scheduling problem (FJSP) finds extensive applications in real-world scenarios. However, traditional FJSP-solving methods struggle to meet the efficiency and adaptability demands of cloud manufacturing due to generalization issues and excessive computational time, while reinforcement learning-based methods fail to learn relationships between FJSP nodes, such as interactions between operations of different jobs, leading to limited interpretability and performance. To address these issues, we propose a dual operation aggregation graph neural network (GNN) for solving FJSP. Specifically, we decouple the disjunctive graph into two distinct graphs, reducing graph density and clarifying relationships between machines and operations, thus enabling more effective aggregation and understanding by neural networks. We develop two distinct graph aggregation methods to minimize the influence of non-critical machine and operation nodes on decision-making while enhancing the model's ability to account for long-term benefits. Additionally, to achieve more accurate multi-objective estimation and mitigate reward sparsity, we design a reward function that simultaneously considers machine efficiency, schedule balance, and makespan minimization. Extensive experimental results on well-known datasets demonstrate that our model outperforms state-of-the-art models and exhibits excellent generalization capabilities, effectively addressing the challenges of cloud manufacturing.}
}


@inproceedings{DBLP:conf/www/PanGCCZCL25,
	author = {Zhiqiang Pan and
                  Chen Gao and
                  Fei Cai and
                  Wanyu Chen and
                  Xin Zhang and
                  Honghui Chen and
                  Yong Li},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {On the Cross-Graph Transferability of Dynamic Link Prediction},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {4101--4110},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714712},
	doi = {10.1145/3696410.3714712},
	timestamp = {Fri, 09 May 2025 20:28:11 +0200},
	biburl = {https://dblp.org/rec/conf/www/PanGCCZCL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Dynamic link prediction aims to predict the future links on dynamic graphs, which can be applied to wide scenarios such as recommender systems and social networks on the World Wide Web. Existing methods mainly (1) focus on the in-graph learning, which cannot generalize to graphs unobserved during training; or (2) achieve the cross-graph predictions in a many-many mechanism by training on multiple graphs across various domains, which results in a large computational cost. In this paper, we propose a cross-graph dynamic link predictor named CrossDyG, which achieves the cross-graph transferability in a one-many mechanism which trains on one single source graph and test on different target graphs. Specifically, we provide causal and empirical analysis on the structural bias caused by the graph-specific structural characteristics in cross-graph predictions. Then, we conduct deconfounded training to learn the universal network evolution pattern from one single source graph during training. Finally, we apply the causal intervention to leverage the graph-specific structural characteristics of each target graph during inference. Extensive experiments conducted on three benchmark data of dynamic graphs demonstrate that CrossDyG outperforms the state-of-the-art baselines by up to 11.01% and 17.02% in terms of AP and AUC, respectively. In addition, the improvements are especially significant when training on small source graphs.}
}


@inproceedings{DBLP:conf/www/WangWGLY25,
	author = {Hui Wang and
                  Xin Wang and
                  Jiake Ge and
                  Lei Liang and
                  Peng Yi},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {ShapeShifter: Workload-Aware Adaptive Evolving Index Structures Based
                  on Learned Models},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {4111--4123},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714681},
	doi = {10.1145/3696410.3714681},
	timestamp = {Tue, 13 May 2025 07:31:05 +0200},
	biburl = {https://dblp.org/rec/conf/www/WangWGLY25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In real-world tasks like data management and Web search, index operations often exhibit strong skewness, unlike standard benchmarks with uniform data distribution. While learned indexes improve query and update efficiency, they typically fail to address the skewed workload access, often prioritizing a single performance metric at the cost of overall index effectiveness. Additionally, the full reliance on learned models can increase vulnerability to attacks, compromising system stability. To address these challenges, we propose ShapeShifter, an adaptive evolutionary structure based on traditional indexes, capable of dynamically adjusting node structures according to the workload. ShapeShifter introduces a node evolution strategy with workload-skew-aware policies to adaptively adjust and optimize the partial index structure, leveraging a hybrid mechanism that combines traditional and learned structures for robust performance and optimal time-space tradeoff under skewed workloads and extreme data conditions. The evaluation results show that ShapeShifter achieves the optimal tradeoff while maintaining robustness.}
}


@inproceedings{DBLP:conf/www/KharbandaGKMSHB25,
	author = {Siddhant Kharbanda and
                  Devaansh Gupta and
                  Gururaj K and
                  Pankaj Malhotra and
                  Amit Singh and
                  Cho{-}Jui Hsieh and
                  Rohit Babbar},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {UniDEC : Unified Dual Encoder and Classifier Training for Extreme
                  Multi-Label Classification},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {4124--4133},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714704},
	doi = {10.1145/3696410.3714704},
	timestamp = {Wed, 18 Jun 2025 08:09:27 +0200},
	biburl = {https://dblp.org/rec/conf/www/KharbandaGKMSHB25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Extreme Multi-label Classification (XMC) involves predicting a subset of relevant labels from an extremely large label space, given an input query and labels with textual features. Models developed for this problem have conventionally made use of dual encoder (DE) to embed the queries and label texts and one-vs-all (OvA) classifiers to rerank the shortlisted labels by the DE. While such methods have shown empirical success, a major drawback is their computational cost, often requiring upto 16 GPUs to train on the largest public dataset. Such a high cost is a consequence of calculating the loss over the entire label space. While shortlisting strategies have been proposed for classifiers, we aim to study such methods for the DE framework. In this work, we develop UniDEC, a loss-independent, end-to-end trainable framework which trains the DE and classifier together in a unified manner with a multi-class loss, while reducing the computational cost by 4--16x. This is done via the proposed  pick-some-label (PSL)  reduction, which aims to compute the loss on only a subset of positive and negative labels. These labels are carefully chosen in-batch so as to maximise their supervisory signals. Not only does the proposed framework achieve state-of-the-art results on datasets with labels in the order of millions, it is also computationally and resource efficient in achieving this performance on a single GPU. Code is made available at https://github.com/the-catalyst/UniDEC.}
}


@inproceedings{DBLP:conf/www/WenGHYL25,
	author = {Bao Wen and
                  Jingjing Gu and
                  Hao Han and
                  Pengfei Yu and
                  Yang Liu},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Instruction Vulnerability Prediction for WebAssembly with Semantic
                  Enhanced Code Property Graph},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {4134--4145},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714723},
	doi = {10.1145/3696410.3714723},
	timestamp = {Fri, 09 May 2025 20:28:11 +0200},
	biburl = {https://dblp.org/rec/conf/www/WenGHYL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {WebAssembly (Wasm) is a universal low-level bytecode designed to build modern web systems. Recent studies have shown that technologies such as voltage scaling and RowHammer attacks are expected to increase the likelihood of bit flips, which may cause unacceptable or catastrophic system failures. This raises concerns about the impact of bit flips on Wasm programs, which run as instructions in web systems, and it is an undeveloped topic since the features of Wasm differ from traditional programs. In this paper, we propose a novel paradigm, namely IVPSEG, to understand the error propagation of bit flips within Wasm programs. Specifically, we first use Large Language Models (LLMs) to automatically extract instruction embeddings containing semantic knowledge of each instruction's context. Then, we exploit these embeddings and program structure (control execution and data transfer) to construct a semantic enhanced code property graph, which implicates the potential path of error propagation. Based on this graph, we utilize graph neural networks and attention diffusion to optimize instruction embeddings by capturing different error propagation patterns for instruction vulnerability prediction. In particular, we build a Wasm compilation and fault generation system to simulate bit flips at Wasm runtime. Our experimental results with 14 benchmark programs and test cases show IVPSEG outperforms the state-of-the-art methods in terms of accuracy (average 13.06%ͽ ), F1-score (average 14.93%↑), and model robustness.}
}


@inproceedings{DBLP:conf/www/XuMSLBSW25,
	author = {Xinyao Xu and
                  Ziyu Mao and
                  Jianzhong Su and
                  Xingwei Lin and
                  David Basin and
                  Jun Sun and
                  Jingyi Wang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Quantitative Runtime Monitoring of Ethereum Transaction Attacks},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {4146--4159},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714682},
	doi = {10.1145/3696410.3714682},
	timestamp = {Fri, 09 May 2025 20:28:11 +0200},
	biburl = {https://dblp.org/rec/conf/www/XuMSLBSW25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The rapid growth of decentralized applications, while revolutionizing financial transactions, has created an attractive target for malicious attacks. Existing approaches to detecting attacks often rely on predefined rules or simplistic and overly-specialized models, which lack the flexibility to handle the wide spectrum of diverse and dynamically changing attack types. To address this challenge, we present a general and extensible framework, MoE (<u> Mo </u>nitoring <u> E </u>thereum), that leverages  runtime verification  to detect a wide range of attacks on Ethereum. MoE features an expressive attack modeling language, based on Metric First-order Temporal Logic (MFOTL), that can formalize a wide range of attacks. We integrate a novel semantic lifting approach that extracts system behaviors relevant for various attacks, which can be analyzed using the monitoring tool  MonPoly.  Furthermore, we also equip MoE with quantitative capabilities to evaluate the similarity between a transaction and an attack formula to enhance its performance in identifying attacks, including near-miss attacks. We carry out extensive experiments with MoE on a labeled benchmark and a large-scale dataset containing over one million transactions. On the labeled benchmark, MoE successfully detects 92.0% attacks and achieves a 45.0% higher recall rate than competing state-of-the-art tool. MoE finds 3,319 attacks with 95.4% precision on the large dataset. Furthermore, MoE uses quantitative analysis to uncover 8% additional attacks. Finally, the average time for monitoring a transaction is less than 23 ms, positioning MoE as a promising practical solution for real-time attack detection for Ethereum.}
}


@inproceedings{DBLP:conf/www/LiDYHZR25,
	author = {Wei Li and
                  Jiawen Deng and
                  Jiali You and
                  Yuanyuan He and
                  Yan Zhuang and
                  Fuji Ren},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {{ETS-MM:} {A} Multi-Modal Social Bot Detection Model Based on Enhanced
                  Textual Semantic Representation},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {4160--4170},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714551},
	doi = {10.1145/3696410.3714551},
	timestamp = {Fri, 09 May 2025 20:28:11 +0200},
	biburl = {https://dblp.org/rec/conf/www/LiDYHZR25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Social bots are becoming increasingly common in social networks, and their activities affect the security and authenticity of social media platforms. Current state-of-the-art social bot detection methods leverage multimodal approaches that analyze various modalities, such as user metadata, text, and social network relationships. However, these methods may not always extract additional dimensions of semantic feature information that could offer a deeper understanding of users' social patterns. To address this issue, we propose ETS-MM, a multimodal detection framework designed to augment multidimensional information from text and extract the semantic feature representation of user text information. We first analyze the user's tweeting behavior based on topic preference and emotion tendency, integrating them into the textual data. Then, we try to extract enhanced semantic representations that reveal the latent relationship between tweeting behavior and tweet content while identifying potential contextual associations and emotional changes. Additionally, to capture the complex interaction between users, we integrate the user's multimodal information, including metadata, textual features, enhanced semantic features, and social network relationships to propagate and aggregate information across various modalities. Experimental results demonstrate that ETS-MM significantly outperforms existing methods across two widely used social bot detection benchmark datasets, validating its effectiveness and superiority.}
}


@inproceedings{DBLP:conf/www/LianSG25,
	author = {Yahong Lian and
                  Chunyao Song and
                  Tingjian Ge},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {ITMPRec: Intention-based Targeted Multi-round Proactive Recommendation},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {4171--4182},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714592},
	doi = {10.1145/3696410.3714592},
	timestamp = {Fri, 09 May 2025 20:28:11 +0200},
	biburl = {https://dblp.org/rec/conf/www/LianSG25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Personalized recommendations are integrated into daily life, but providers may want certain items to become more appealing over time through user interactions, yet this issue is often overlooked. The existing works are often based on the assumption that users will passively accept all intermediate sequences or not explore intention modeling in the targeted nudging process. Both of these factors result in suboptimal performance in the proactive recommendation. In this paper, we propose a novel intention-based targeted multi-round proactive recommendation method, dubbed ITMPRec. We first select target items using a pre-match strategy. Then, we employ a multi-round nudging recommendation method, incorporating a module to quantify users' intention-level evolution, helping choose suitable intermediate items. Additionally, we model users' sensitivity to changes caused by these items. Lastly, we propose an LLM agent as a pluggable component to simulate user feedback, offering an alternative to traditional click models by leveraging the agent's external knowledge and reasoning capabilities. Through extensive experiments on four public datasets, we demonstrate the superiority of ITMPRec compared to eight baseline models.}
}


@inproceedings{DBLP:conf/www/WangZLCRR25,
	author = {Zihan Wang and
                  Ziqi Zhao and
                  Yougang Lyu and
                  Zhumin Chen and
                  Maarten de Rijke and
                  Zhaochun Ren},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {A Cooperative Multi-Agent Framework for Zero-Shot Named Entity Recognition},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {4183--4195},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714923},
	doi = {10.1145/3696410.3714923},
	timestamp = {Fri, 09 May 2025 20:28:11 +0200},
	biburl = {https://dblp.org/rec/conf/www/WangZLCRR25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Zero-shot named entity recognition (NER) aims to develop entity recognition systems from unannotated text corpora. This task presents substantial challenges due to minimal human intervention. Recent work has adapted large language models (LLMs) for zero-shot NER by crafting specialized prompt templates. And it advances models' self-learning abilities by incorporating self-annotated demonstrations. Two important challenges persist: (i) Correlations between contexts surrounding entities are overlooked, leading to wrong type predictions or entity omissions. (ii) The indiscriminate use of task demonstrations, retrieved through shallow similarity-based strategies, severely misleads LLMs during inference. In this paper, we introduce the cooperative multi-agent system (CMAS), a novel framework for zero-shot NER that uses the collective intelligence of multiple agents to address the challenges outlined above. CMAS has four main agents: (i) a self-annotator, (ii) a type-related feature (TRF) extractor, (iii) a demonstration discriminator, and (iv) an overall predictor. To explicitly capture correlations between contexts surrounding entities, CMAS reformulates NER into two subtasks: recognizing named entities and identifying entity type-related features within the target sentence. To enable controllable utilization of demonstrations, a demonstration discriminator is established to incorporate the self-reflection mechanism, automatically evaluating helpfulness scores for the target sentence. Experimental results show that CMAS significantly improves zero-shot NER performance across six benchmarks, including both domain-specific and general-domain scenarios. Furthermore, CMAS demonstrates its effectiveness in few-shot settings and with various LLM backbones.}
}


@inproceedings{DBLP:conf/www/ZhouLWX25,
	author = {Cheng Zhou and
                  Guangxia Li and
                  Hao Weng and
                  Yiyu Xiang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Training-free Graph Anomaly Detection: {A} Simple Approach via Singular
                  Value Decomposition},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {4196--4205},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714776},
	doi = {10.1145/3696410.3714776},
	timestamp = {Fri, 09 May 2025 20:28:11 +0200},
	biburl = {https://dblp.org/rec/conf/www/ZhouLWX25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graph anomaly detection (GAD) is essential for identifying irregular behavior within graphs. Recent advances in GAD rely on deep learning techniques and have shown promise. However, prior deep learning-based GAD methods suffer from various limitations such as low accuracy, long training time, and limited scalability. To tackle these limitations, we propose TFGAD, a training-free graph anomaly detection approach. Our main idea is to process node attributes and local structures separately using distinct matrices, which are optimally determined via singular value decomposition, thus eliminating the need for additional training. For anomaly detection, we propose a lightweight scoring function that combines the reconstruction errors of node attributes with the projection lengths of local structures to quantify node abnormalities. Extensive experiments demonstrate that TFGAD significantly outperforms state-of-the-art deep learning-based baselines while reducing runtime and memory overhead. The results highlight TFGAD's potential as an effective and efficient solution for GAD, particularly in scenarios where computational resources are constrained.}
}


@inproceedings{DBLP:conf/www/Dong0ZWWD25,
	author = {Guanting Dong and
                  Yutao Zhu and
                  Chenghao Zhang and
                  Zechen Wang and
                  Ji{-}Rong Wen and
                  Zhicheng Dou},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Understand What {LLM} Needs: Dual Preference Alignment for Retrieval-Augmented
                  Generation},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {4206--4225},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714717},
	doi = {10.1145/3696410.3714717},
	timestamp = {Wed, 02 Jul 2025 18:51:58 +0200},
	biburl = {https://dblp.org/rec/conf/www/Dong0ZWWD25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Retrieval-augmented generation (RAG) has effectively mitigated the hallucination problem of large language models (LLMs). However, the difficulty of aligning the retriever with the LLMs' diverse knowledge preferences inevitably poses a challenge in developing a reliable RAG system. To address this issue, we propose DPA-RAG, a universal framework designed to align diverse knowledge preferences within RAG systems. Specifically, we initially introduce a preference knowledge construction pipeline and incorporate five novel query augmentation strategies to alleviate preference data scarcity. Based on preference data, DPA-RAG accomplishes both external and internal preference alignment: 1) It jointly integrates pairwise, pointwise, and contrastive preference alignment abilities into the reranker, achieving external preference alignment among RAG components. 2) It further introduces a pre-aligned stage before vanilla Supervised Fine-tuning (SFT), enabling LLMs to implicitly capture knowledge aligned with their reasoning preferences, achieving LLMs' internal alignment. Experimental results across four knowledge-intensive QA datasets demonstrate that DPA-RAG outperforms all baselines and seamlessly integrates both black-box and open-sourced LLM readers. Further qualitative analysis and discussions provide empirical guidance for achieving reliable RAG systems. Our code and example dataset are available at https://github.com/dongguanting/DPA-RAG.}
}


@inproceedings{DBLP:conf/www/0001LDL25,
	author = {Zhuohua Li and
                  Maoli Liu and
                  Xiangxiang Dai and
                  John C. S. Lui},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Towards Efficient Conversational Recommendations: Expected Value of
                  Information Meets Bandit Learning},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {4226--4238},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714773},
	doi = {10.1145/3696410.3714773},
	timestamp = {Fri, 09 May 2025 20:28:11 +0200},
	biburl = {https://dblp.org/rec/conf/www/0001LDL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In conversational recommender systems, interactively presenting queries and leveraging user feedback are crucial for efficiently estimating user preferences and improving recommendation quality. Selecting optimal queries in these systems is a significant challenge that has been extensively studied as a sequential decision problem. The  expected value of information (EVOI) , which computes the expected reward improvement, provides a principled criterion for query selection. However, it is computationally expensive and lacks theoretical performance guarantees. Conversely,  conversational bandits  offer provable regret upper bounds, but their query selection strategies yield only marginal regret improvements over non-conversational approaches. To address these limitations, we integrate EVOI within the conversational bandit framework by proposing a new conversational mechanism featuring two key techniques: (1)  gradient-based EVOI , which replaces the complex Bayesian updates in conventional EVOI with efficient stochastic gradient descent, significantly reducing computational complexity and facilitating theoretical analysis; and (2)  smoothed key term contexts , which enhance exploration by adding random perturbations to uncover more specific user preferences. Our approach applies to both Bayesian (Thompson Sampling) and frequentist (UCB) variants of conversational bandits. We introduce two new algorithms, ConTS-EVOI and ConUCB-EVOI, and rigorously prove that they achieve substantially tighter regret bounds, with both algorithms offering a √d improvement in their dependence on the time horizon  T , where  d  is the dimension of the feature space. Extensive evaluations on synthetic and real-world datasets validate the effectiveness of our methods.}
}


@inproceedings{DBLP:conf/www/XuNWY25,
	author = {Hongyuan Xu and
                  Yuhang Niu and
                  Yanlong Wen and
                  Xiaojie Yuan},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Compress and Mix: Advancing Efficient Taxonomy Completion with Large
                  Language Models},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {4239--4249},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714690},
	doi = {10.1145/3696410.3714690},
	timestamp = {Fri, 09 May 2025 20:28:11 +0200},
	biburl = {https://dblp.org/rec/conf/www/XuNWY25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Taxonomy completion aims to integrate new concepts into existing taxonomies by determining their appropriate hypernym and hyponym. While semantic and structural information are crucial for this task, existing approaches often struggle to balance these aspects effectively. In this paper, we propose  COMI , an efficient taxonomy completion framework that leverages large language models (LLMs) to capture both semantic and structural information in a unified manner. COMI  <u>co</u> mpresses node semantics into token representations, enabling LLMs to efficiently process the input structure composed of these tokens. To enhance the model's understanding of the structure, a further fine-tuning process using contrastive learning with  <u>mi</u> xup data augmentation is applied, where mixup generates diverse and challenging negative samples. Through these innovations, COMI improves the integration of semantic and structural information, leading to more accurate taxonomy completion. The experimental results on three real-world datasets demonstrate that COMI achieves state-of-the-art performance while showing up to 284x faster inference compared to the previous best method. Our code and compressed tokens are available at https://github.com/cyclexu/COMI.}
}


@inproceedings{DBLP:conf/www/Niu0JL25,
	author = {Yudong Niu and
                  Yuchen Li and
                  Jiaxin Jiang and
                  Laks V. S. Lakshmanan},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {{SANS:} Efficient Densest Subgraph Discovery over Relational Graphs
                  without Materialization},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {4250--4263},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714603},
	doi = {10.1145/3696410.3714603},
	timestamp = {Fri, 09 May 2025 20:28:11 +0200},
	biburl = {https://dblp.org/rec/conf/www/Niu0JL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {How can we efficiently identify the densest subgraph over relational graphs? Existing dense subgraph discovery (DSD) approaches assume that a relational graph H is already derived from a heterogeneous data source and they focus on efficient discovery of the densest subgraph on the materialized H. Unfortunately, materializing relational graphs can be resource-intensive, which thus limits the practical usefulness of existing algorithms over large datasets. To mitigate this, we propose a novel Summary-bAsed deNsest Subgraph discovery (SANS) system. Our unique summary-based peeling algorithm forms the core of SANS. Following the peeling paradigm, it utilizes summaries of each node's neighborhood to efficiently estimate peeling coefficients and subgraph densities at each peeling iteration and thus avoids materializing the relational graph completely. Through extensive experiments, we demonstrate the efficacy and efficiency of SANS, reaching orders of magnitude speedups compared to the conventional baselines with materialization, while consistently achieving at least 95% accuracy compared to peeling algorithms based on materialization.}
}


@inproceedings{DBLP:conf/www/Chen0SL25,
	author = {Zhiyang Chen and
                  Yun Ma and
                  Haiyang Shen and
                  Mugeng Liu},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {WeInfer: Unleashing the Power of WebGPU on {LLM} Inference in Web
                  Browsers},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {4264--4273},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714553},
	doi = {10.1145/3696410.3714553},
	timestamp = {Thu, 01 May 2025 20:27:22 +0200},
	biburl = {https://dblp.org/rec/conf/www/Chen0SL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Web-based large language model (LLM) has garnered significant attention from both academia and industry as it combines the benefits of on-device computation with the accessibility and portability of Web applications. The advent of WebGPU, a modern browser API that enables Web applications to utilize a device's GPU, has opened up new possibilities for GPU-accelerated LLM inference within browsers. However, our experiment reveals that existing Web-based LLM inference frameworks exhibit inefficiencies in GPU utilization, limiting the inference speed. These inefficiencies primarily arise from underutilizing the full capabilities of WebGPU, particularly in resource management and execution synchronization. To address these limitations, we present WeInfer, an efficient Web-based LLM inference framework specifically designed to unleash the power of WebGPU. WeInfer incorporates two key innovations: 1) buffer reuse strategies that reduce the overhead associated with resource preparation, optimizing the lifecycle management of WebGPU buffers, and 2) an asynchronous pipeline that decouples resource preparation from GPU execution, enabling parallelized computation and deferred result fetching to improve overall efficiency. We conduct extensive evaluations across 9 different LLMs and 5 heterogeneous devices, covering a broad spectrum of model architectures and hardware configurations. The results demonstrate that WeInfer delivers substantial improvements in decoding speed, achieving up to a 3.76× performance boost compared with WebLLM, the state-of-the-art Web-based LLM inference framework.}
}


@inproceedings{DBLP:conf/www/LiuWWM25,
	author = {Qi Liu and
                  Bo Wang and
                  Nan Wang and
                  Jiaxin Mao},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Leveraging Passage Embeddings for Efficient Listwise Reranking with
                  Large Language Models},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {4274--4283},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714554},
	doi = {10.1145/3696410.3714554},
	timestamp = {Fri, 09 May 2025 20:28:11 +0200},
	biburl = {https://dblp.org/rec/conf/www/LiuWWM25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recent studies have demonstrated the effectiveness of using large language language models (LLMs) in passage ranking. The listwise approaches, such as RankGPT, have become new state-of-the-art in this task. However, the efficiency of RankGPT models is limited by the maximum context length and relatively high latency of LLM inference. To address these issues, in this paper, we propose PE-Rank, leveraging the single passage embedding as a good context compression for efficient listwise passage reranking. By treating each passage as a special token, we can directly input passage embeddings into LLMs, thereby reducing input length. Additionally, we introduce an inference method that dynamically constrains the decoding space to these special tokens, accelerating the decoding process. For adapting the model to reranking, we employ listwise learning to rank loss for training. Evaluation results on multiple benchmarks demonstrate that PE-Rank significantly improves efficiency in both prefilling and decoding, while maintaining competitive ranking effectiveness. The code is available at https://github.com/liuqi6777/pe_rank}
}


@inproceedings{DBLP:conf/www/MeisamiDLTD25,
	author = {Sajad Meisami and
                  Hugo Dabadie and
                  Song Li and
                  Yuzhe Tang and
                  Yue Duan},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {SigScope: Detecting and Understanding Off-Chain Message Signing-related
                  Vulnerabilities in Decentralized Applications},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {4284--4299},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714686},
	doi = {10.1145/3696410.3714686},
	timestamp = {Fri, 09 May 2025 20:28:11 +0200},
	biburl = {https://dblp.org/rec/conf/www/MeisamiDLTD25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In Web 3.0, an emerging paradigm of building decentralized applications or DApps is off-chain message signing, which has advantages in performance, cost efficiency, and usability compared to conventional transaction-signing schemes. However, message signing burdens DApp developers with extra coding complexity and message designing, leading to new security risks. This paper presents the first systematic study to uncover and characterize the security issues in off-chain message signing schemes and the DApps built atop them. We present a holistic static-analysis framework,  SigScope , that uniquely combines the insights extracted from DApp front-end code (HTML and Javascript) off-chain and back-end smart contracts on-chain. We evaluate  SigScope  using the top 100 DApps to showcase its effectiveness and efficiency. Further, we leverage  SigScope  to study a large dataset of 4937 real-world DApps and show that 1579 DApps (including 73% of the top 100) rely on the off-chain message signing feature, and 1154 contain vulnerabilities. Finally, we use two real-world vulnerabilities in popular DApps to showcase our findings.}
}


@inproceedings{DBLP:conf/www/Zhang000Z25,
	author = {Xinwei Zhang and
                  Haibo Hu and
                  Qingqing Ye and
                  Li Bai and
                  Huadi Zheng},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {MER-Inspector: Assessing Model Extraction Risks from An Attack-Agnostic
                  Perspective},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {4300--4315},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714894},
	doi = {10.1145/3696410.3714894},
	timestamp = {Fri, 09 May 2025 20:28:11 +0200},
	biburl = {https://dblp.org/rec/conf/www/Zhang000Z25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Information leakage issues in machine learning-based Web applications have attracted increasing attention. While the risk of data privacy leakage has been rigorously analyzed, the theory of model function leakage, known as Model Extraction Attacks (MEAs), has not been well studied. In this paper, we are the first to understand MEAs theoretically from an attack-agnostic perspective and to propose analytical metrics for evaluating model extraction risks. By using the Neural Tangent Kernel (NTK) theory, we formulate the linearized MEA as a regularized kernel classification problem and then derive the fidelity gap and generalization error bounds of the attack performance. Based on these theoretical analyses, we propose a new theoretical metric called Model Recovery Complexity (MRC), which measures the distance of weight changes between the victim and surrogate models to quantify risk. Additionally, we find that victim model accuracy, which shows a strong positive correlation with model extraction risk, can serve as an empirical metric. By integrating these two metrics, we propose a framework, namely Model Extraction Risk Inspector (MER-Inspector), to compare the extraction risks of models under different model architectures by utilizing relative metric values. We conduct extensive experiments on 16 model architectures and 5 datasets. The experimental results demonstrate that the proposed metrics have a high correlation with model extraction risks, and MER-Inspector can accurately compare the extraction risks of any two models with up to 89.58%.}
}


@inproceedings{DBLP:conf/www/0001CHXQXD25,
	author = {Xiaolong Xu and
                  Yuxin Cao and
                  Hongsheng Hu and
                  Haolong Xiang and
                  Lianyong Qi and
                  Junqun Xiong and
                  Wanchun Dou},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {{MGF-ESE:} An Enhanced Semantic Extractor with Multi-Granularity Feature
                  Fusion for Code Summarization},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {4316--4324},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714544},
	doi = {10.1145/3696410.3714544},
	timestamp = {Fri, 09 May 2025 20:28:11 +0200},
	biburl = {https://dblp.org/rec/conf/www/0001CHXQXD25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Code summarization aims to generate concise natural language descriptions of source code, helping developers to acquaint with software systems and reduce maintenance costs. Existing code summarization approaches widely employ attention mechanisms to assess the relevance between nodes in the Abstract Syntax Tree (AST), which generates context vectors that reflect the semantics of the source code. However, these approaches solely relying on AST lack the extraction of features at other levels of granularity, such as code tokens and Control Flow Graph (CFG), which suffer from severe semantic gaps when capturing data and control dependencies. To address this issue, we design an enhanced semantic extractor with multi-granularity feature fusion (MGF-ESE) to improve the model capability in comprehending and processing the overall semantics of the code. Specifically, we present a novel AST generation method that, based on controlling the scale of nodes, introduces syntactic description nodes to raise the semantic density of AST feature. Then we perform both local and global encoding of CFG after embedding the statement nodes. Moreover, through a cross-attention mechanism, we fuse code tokens and CFG with AST to enhance the model's capacity to capture both syntactic and structural information from source code. Finally, extensive experiments on two open-source datasets show that MGF-ESE outperforms the state-of-the-arts with higher-quality code summaries on key metrics, including BLEU, METEOR, and ROUGE-L.}
}


@inproceedings{DBLP:conf/www/HuygheRQ25,
	author = {Maxime Huyghe and
                  Walter Rudametkin and
                  Cl{\'{e}}ment Quinton},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {FP-Rainbow: Fingerprint-Based Browser Configuration Identification},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {4325--4335},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714699},
	doi = {10.1145/3696410.3714699},
	timestamp = {Thu, 01 May 2025 20:27:23 +0200},
	biburl = {https://dblp.org/rec/conf/www/HuygheRQ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Browser fingerprinting is a tracking technique that collects attributes and calls functions from the browser's APIs. Unlike cookies, browser fingerprints are difficult to evade or delete, raising significant privacy concerns for users as they can be used to re-identify individuals over browsing sessions without their consent. Yet, there has been limited research on the impact of browser configuration settings on these fingerprints. This paper introduces  FP-Rainbow,  a novel approach to systematically explore and map the configuration space of Chromium-based web browsers aiming to identify the impact of configuration parameters on browser fingerprints and their changes over time. We explore 1,748 configuration parameters (switches) and identify their impact on the browser's BOM (Browser Object Model). By collecting and analyzing over 61,000 fingerprints from 18 versions of Chromium, our study reveals that 32 to 56 of these configuration parameters (depending on versions), such as  disable-3d-apis  or  disable-notifications,  influence the fingerprint of a web browser. FP-Rainbow  also proves efficient in identifying browser configuration parameters from unknown fingerprints, achieving an average successful identification rate of 84% when considering a single configuration parameter and 78% when multiple parameters are involved, across all evaluated browser versions. These findings emphasize the importance of measuring the impact of configuration parameters on browsers to develop safer and more privacy-friendly web browsers.}
}


@inproceedings{DBLP:conf/www/NguyenV25,
	author = {Hoang Dai Nguyen and
                  Phani Vadrevu},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Breaking the Shield: Analyzing and Attacking Canvas Fingerprinting
                  Defenses in the Wild},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {4336--4345},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714713},
	doi = {10.1145/3696410.3714713},
	timestamp = {Thu, 01 May 2025 20:27:25 +0200},
	biburl = {https://dblp.org/rec/conf/www/NguyenV25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Canvas fingerprinting has become one of the most effective techniques for tracking users online, allowing websites to identify and track visitors without their consent. In this paper, we investigate four primary defense techniques designed to counter canvas fingerprinting, systematically analyzing their adoption across 18 browser extensions in Chrome and Firefox, as well as built-in protections from five major browsers: Chrome, Firefox, Brave, Tor, and Safari. Our analysis reveals significant disparities in the implementation and effectiveness of these defenses, with randomization-based techniques being the most widely adopted, particularly across nine extensions and in the privacy-focused browser, Brave. Despite their sophistication, we demonstrate successful attacks on all these randomization mechanisms, revealing that their supposed non-deterministic behavior can, in fact, be predicted and exploited. In summary, we demonstrate that, unfortunately, no fully deployable defense against canvas fingerprinting attacks exists currently. We conclude by proposing recommendations to strengthen existing defenses and enhance their resistance to future attacks.}
}


@inproceedings{DBLP:conf/www/ChenW0S25,
	author = {Qin Chen and
                  Liang Wang and
                  Bo Zheng and
                  Guojie Song},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {DAGPrompT: Pushing the Limits of Graph Prompting with a Distribution-aware
                  Graph Prompt Tuning Approach},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {4346--4358},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714917},
	doi = {10.1145/3696410.3714917},
	timestamp = {Fri, 09 May 2025 20:28:11 +0200},
	biburl = {https://dblp.org/rec/conf/www/ChenW0S25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The ''pre-train then fine-tune'' approach has advanced GNNs by enabling general knowledge capture without task-specific labels. However, an objective gap between pre-training and downstream tasks limits its effectiveness. Recent graph prompting methods aim to close this gap through task reformulations and learnable prompts. Despite this, they struggle with complex graphs like heterophily graphs. Freezing the GNN encoder can reduce the impact of prompting, while simple prompts fail to handle diverse hop-level distributions. This paper identifies two key challenges in adapting graph prompting methods for complex graphs: (i)  adapting the model to new distributions in downstream tasks to mitigate pre-training and fine-tuning discrepancies from heterophily  and (ii)  customizing prompts for hop-specific node requirements.  To overcome these challenges, we propose Distribution-aware Graph Prompt Tuning (DAGPrompT), which integrates a GLoRA module for optimizing the GNN encoder's projection matrix and message-passing schema through low-rank adaptation. DAGPrompT also incorporates hop-specific prompts accounting for varying graph structures and distributions among hops. Evaluations on 10 datasets and 14 baselines demonstrate that DAGPrompT improves accuracy by up to 4.79% in node and graph classification tasks, setting a new state-of-the-art while preserving efficiency. Codes are available at https://github.com/Cqkkkkkk/DAGPrompT GitHub.}
}


@inproceedings{DBLP:conf/www/0001Y00YY25,
	author = {Xinyi Gao and
                  Guanhua Ye and
                  Tong Chen and
                  Wentao Zhang and
                  Junliang Yu and
                  Hongzhi Yin},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Rethinking and Accelerating Graph Condensation: {A} Training-Free
                  Approach with Class Partition},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {4359--4373},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714916},
	doi = {10.1145/3696410.3714916},
	timestamp = {Fri, 09 May 2025 20:28:11 +0200},
	biburl = {https://dblp.org/rec/conf/www/0001Y00YY25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The increasing prevalence of large-scale graphs poses a significant challenge for graph neural network training, attributed to their substantial computational requirements. In response, graph condensation (GC) emerges as a promising data-centric solution aiming to substitute the large graph with a small yet informative condensed graph to facilitate data-efficient GNN training. However, existing GC methods suffer from intricate optimization processes, necessitating excessive computing resources and training time. In this paper, we revisit existing GC optimization strategies and identify two pervasive issues therein: (1) various GC optimization strategies converge to coarse-grained class-level node feature matching between the original and condensed graphs; (2) existing GC methods rely on a Siamese graph network architecture that requires time-consuming bi-level optimization with iterative gradient computations. To overcome these issues, we propose a training-free GC framework termed Class-partitioned Graph Condensation (CGC), which refines the node distribution matching from the class-to-class paradigm into a novel class-to-node paradigm, transforming the GC optimization into a class partition problem which can be efficiently solved by any clustering methods. Moreover, CGC incorporates a pre-defined graph structure to enable a closed-form solution for condensed node features, eliminating the need for back-and-forth gradient descent in existing GC approaches. Extensive experiments demonstrate that CGC achieves an exceedingly efficient condensation process with advanced accuracy. Compared with the state-of-the-art GC methods, CGC condenses the Ogbn-products graph within 30 seconds, achieving a speedup ranging from 10 2  × to 10 4  × and increasing accuracy by up to 4.2%.}
}


@inproceedings{DBLP:conf/www/ChenSW0WL0025,
	author = {Hongxu Chen and
                  Guanglei Song and
                  Zhiliang Wang and
                  Jiahai Yang and
                  Songyun Wu and
                  Jinlei Lin and
                  Lin He and
                  Chenglong Li},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {IPdb: {A} High-Precision {IP} Level Industry Categorization of Web
                  Services},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {4374--4385},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714669},
	doi = {10.1145/3696410.3714669},
	timestamp = {Fri, 09 May 2025 20:28:11 +0200},
	biburl = {https://dblp.org/rec/conf/www/ChenSW0WL0025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {IP addresses with web services are crucial in the Internet ecosystem. Classifying these addresses by industry and organization offers valuable insights into the entities utilizing them, enabling more efficient network management and enhanced security. Previous work in website classification and Internet management struggles to offer an IP-level perspective of the industries of web services due to their limited industry categories or potential industry inconsistencies between IP address owners and AS owners. To this end, we present IPdb, an IP-level industry categorization dataset. To construct the dataset, we developed LLMIC, a Large Language Model-based Industry Categorization framework with a precision of nearly 96%. IPdb serves as a labeled database for future endeavors in developing IP-level industry classifiers, encompassing over 200 million IP addresses. Furthermore, our study indicates that 30% ~ 50% of organizations within critical infrastructure industries deploy web servers across multiple ASes. Our study also validates the problem of mismatched granularity in industry categorization at the AS level with 87.83% ASes in IPv4 and 72.96% ASes in IPv6 containing IP addresses from different industries.}
}


@inproceedings{DBLP:conf/www/DongAWL0S0CM25,
	author = {Qian Dong and
                  Qingyao Ai and
                  Hongning Wang and
                  Yiding Liu and
                  Haitao Li and
                  Weihang Su and
                  Yiqun Liu and
                  Tat{-}Seng Chua and
                  Shaoping Ma},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Decoupling Knowledge and Context: An Efficient and Effective Retrieval
                  Augmented Generation Framework via Cross Attention},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {4386--4395},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714608},
	doi = {10.1145/3696410.3714608},
	timestamp = {Fri, 09 May 2025 20:28:11 +0200},
	biburl = {https://dblp.org/rec/conf/www/DongAWL0S0CM25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Retrieval-Augmented Generation (RAG) systems have become a crucial tool to augment large language models (LLMs) with external knowledge for better task performance. However, existing traditional RAG methods inject knowledge directly into the context, resulting in several limitations. First, these methods highly rely on the in-context learning capability of LLMs, which often leads to excessively long contexts. This is inefficient due to the quadratic complexity of self-attention, leading to significant increase in inference time. Second, the extended context and the nature of self-attention can cause the LLMs to lose important information in the context, thereby degrading the original capabilities of LLMs. Third, the effectiveness of knowledge injection is perturbed by the permutation of knowledge within the extended context, reducing the robustness of existing RAG methods. To tackle the above problems, we propose DecoupledRAG, a method that decouples external knowledge from the context within the RAG framework. Specifically, we introduce a cross-attention based method that injects retrieved knowledge directly into the inference process of LLM on the fly, without modifying its parameters or the input context, so that the external knowledge can be utilized robustly in a permutation-independent manner. To the best of our knowledge, this is the first work that explore how to utilize cross-attention to inject knowledge with low training cost in decoder-only LLM era. By leveraging cross-attention operation, DecoupledRAG enables seamless knowledge aggregation without creating extended context. Experimental results demonstrate that our method could achieve high efficiency while maintaining strong performance, which indicates that RAG frameworks have the potential to benefit further from more knowledge.}
}


@inproceedings{DBLP:conf/www/PaimFRBS25,
	author = {Eduardo C. Paim and
                  Roberto Iraj{\'{a}} Tavares da Costa Filho and
                  Valter Roesler and
                  Theophilus A. Benson and
                  Alberto Schaeffer{-}Filho},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Hidden Impact of Hardware Technologies on Throughput: a Case Study
                  on a Brazilian Mobile Web Network},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {4396--4407},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714599},
	doi = {10.1145/3696410.3714599},
	timestamp = {Fri, 09 May 2025 20:28:11 +0200},
	biburl = {https://dblp.org/rec/conf/www/PaimFRBS25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Web has shifted towards a mobile-first ecosystem with tools, frameworks, and forums explicitly discussing and catering for the mobile users, both mobile apps and mobile web-pages. Unfortunately, much of the studies and designs are often based on analysis and findings from developed regions (e.g., N. America and Europe) or based on user-generated data (introducing bias). In this paper, we present one of the first studies to understand the interplay between hardware characteristics (e.g., cellular and mobile) on expected network and application level performance in Brazil (the largest developing region in S. America). We analyze more than 170 million measurement sessions collected from within the network of one of the largest Mobile Network Operators in Brazil. Our findings (1) illustrate limitations of existing crowdsourced measurements and inaccuracies in assumptions about adoption patterns and performance in the global south, (2) highlight the differences between recommendations made by standardization bodies and real world performance, (3) disclose a significant change pre- and post-pandemic, and (4) quantify the benefits of using both client side and network data for analysis.}
}


@inproceedings{DBLP:conf/www/DaiXDZL0D25,
	author = {Quanyu Dai and
                  Jiaren Xiao and
                  Zhaocheng Du and
                  Jieming Zhu and
                  Chengxiao Luo and
                  Xiao{-}Ming Wu and
                  Zhenhua Dong},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {MCNet: Monotonic Calibration Networks for Expressive Uncertainty Calibration
                  in Online Advertising},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {4408--4419},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714802},
	doi = {10.1145/3696410.3714802},
	timestamp = {Fri, 09 May 2025 20:28:11 +0200},
	biburl = {https://dblp.org/rec/conf/www/DaiXDZL0D25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In online advertising, uncertainty calibration aims to adjust a ranking model's probability predictions to better approximate the true likelihood of an event, e.g., a click or a conversion. However, existing calibration approaches may lack the ability to effectively model complex nonlinear relations, consider context features, and achieve balanced performance across different data subsets. To tackle these challenges, we introduce a novel model called Monotonic Calibration Networks, featuring three key designs: a monotonic calibration function (MCF), an order-preserving regularizer, and a field-balance regularizer. The nonlinear MCF is capable of naturally modeling and universally approximating the intricate relations between uncalibrated predictions and the posterior probabilities, thus being much more expressive than existing methods. MCF can also integrate context features using a flexible model architecture, thereby achieving context awareness. The order-preserving and field-balance regularizers promote the monotonic relationship between adjacent bins and the balanced calibration performance on data subsets, respectively. Experimental results on both public and industrial datasets demonstrate the superior performance of our method in generating well-calibrated probability predictions.}
}


@inproceedings{DBLP:conf/www/0023H25,
	author = {Zhen Zhang and
                  Bingsheng He},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Aggregate to Adapt: Node-Centric Aggregation for Multi-Source-Free
                  Graph Domain Adaptation},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {4420--4431},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714605},
	doi = {10.1145/3696410.3714605},
	timestamp = {Fri, 09 May 2025 20:28:11 +0200},
	biburl = {https://dblp.org/rec/conf/www/0023H25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Unsupervised graph domain adaptation (UGDA) focuses on transferring knowledge from labeled source graph to unlabeled target graph under domain discrepancies. Most existing UGDA methods are designed to adapt information from a single source domain, which cannot effectively exploit the complementary knowledge from multiple source domains. Furthermore, their assumptions that the labeled source graphs are accessible throughout the training procedure might not be practical due to privacy, regulation, and storage concerns. In this paper, we investigate multi-source-free unsupervised graph domain adaptation, i.e., adapting knowledge from multiple source domains to an unlabeled target domain without utilizing labeled source graphs but relying solely on source pre-trained models. Unlike previous multi-source domain adaptation approaches that aggregate predictions at model level, we introduce a novel model named GraphATA which conducts adaptation at node granularity. Specifically, we parameterize each node with its own graph convolutional matrix by automatically aggregating weight matrices from multiple source models according to its local context, thus realizing dynamic adaptation over graph structured data. We also demonstrate the capability of GraphATA to generalize to both model-centric and layer-centric methods. Comprehensive experiments on various public datasets show that our GraphATA can consistently surpass recent state-of-the-art baselines with different gains.}
}


@inproceedings{DBLP:conf/www/WangCMC25,
	author = {Hengzhi Wang and
                  Haoran Chen and
                  Minghe Ma and
                  Laizhong Cui},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Dealing with Noisy Data in Federated Learning: An Incentive Mechanism
                  with Flexible Pricing},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {4432--4441},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714961},
	doi = {10.1145/3696410.3714961},
	timestamp = {Fri, 09 May 2025 20:28:11 +0200},
	biburl = {https://dblp.org/rec/conf/www/WangCMC25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated Learning (FL) has emerged as a promising training framework that enables a server to effectively train a global model by coordinating multiple devices, i.e., clients, without sharing their raw data. Keeping data locally can ensure data privacy, but also makes the server difficult to assess data quality, leading to the noisy data issue. Specifically, for any given training task, only a portion of each client's data is relevant and beneficial, while the rest may be redundant or noisy. Training with excessive noisy data can degrade performance. Motivated by this, we investigate the limitations of existing studies and develop an incentive mechanism with flexible pricing tailored for noisy data settings. The insight lies in mitigating the impact of noisy data by selecting appropriate clients and incentivizing them to clean their data spontaneously. Further, both rigorous theoretical analysis and extensive simulations compared with state-of-the-art methods have been well-conducted to validate the effectiveness of the proposed mechanism.}
}


@inproceedings{DBLP:conf/www/ZhaoLYM25,
	author = {Xuejiao Zhao and
                  Siyan Liu and
                  Su{-}Yin Yang and
                  Chunyan Miao},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {MedRAG: Enhancing Retrieval-augmented Generation with Knowledge Graph-Elicited
                  Reasoning for Healthcare Copilot},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {4442--4457},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714782},
	doi = {10.1145/3696410.3714782},
	timestamp = {Fri, 09 May 2025 20:28:11 +0200},
	biburl = {https://dblp.org/rec/conf/www/ZhaoLYM25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Retrieval-augmented generation (RAG) is a well-suited technique for retrieving privacy-sensitive Electronic Health Records (EHR). It can serve as a key module of the healthcare copilot, helping reduce misdiagnosis for healthcare practitioners and patients. However, the diagnostic accuracy and specificity of existing heuristic-based RAG models used in the medical domain are inadequate, particularly for diseases with similar manifestations. This paper proposes MedRAG, a RAG model enhanced by knowledge graph (KG)-elicited reasoning for the medical domain that retrieves diagnosis and treatment recommendations based on manifestations. MedRAG systematically constructs a comprehensive four-tier hierarchical diagnostic KG encompassing critical diagnostic differences of various diseases. These differences are dynamically integrated with similar EHRs retrieved from an EHR database, and reasoned within a large language model. This process enables more accurate and specific decision support, while also proactively providing follow-up questions to enhance personalized medical decision-making. MedRAG is evaluated on both a public dataset DDXPlus and a private chronic pain diagnostic dataset (CPDD) collected from Tan Tock Seng Hospital, and its performance is compared against various existing RAG methods. Experimental results show that, leveraging the information integration and relational abilities of the KG, our MedRAG provides more specific diagnostic insights and outperforms state-of-the-art models in reducing misdiagnosis rates. Our code will be available at  https://github.com/SNOWTEAM2023/MedRAG}
}


@inproceedings{DBLP:conf/www/GadekarGT25,
	author = {Ameet Gadekar and
                  Aristides Gionis and
                  Suhas Thejaswi},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Fair Clustering for Data Summarization: Improved Approximation Algorithms
                  and Complexity Insights},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {4458--4469},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714857},
	doi = {10.1145/3696410.3714857},
	timestamp = {Fri, 09 May 2025 20:28:11 +0200},
	biburl = {https://dblp.org/rec/conf/www/GadekarGT25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Data summarization tasks are often modeled as  k -clustering problems, where the goal is to choose  k  data points, called cluster centers, that best represent the dataset by minimizing a clustering objective. A popular objective is to minimize the maximum distance between any data point and its nearest center, which is formalized as the  k -center problem. While in some applications all data points can be chosen as centers, in the general setting, centers must be chosen from a predefined subset of points, referred as facilities or suppliers; this is known as the  k -supplier problem. In this work, we focus on  fair  data summarization modeled as the fair  k -supplier problem, where data consists of several groups, and a minimum number of centers must be selected from each group while minimizing the  k -supplier objective. The groups can be disjoint or overlapping, leading to two distinct problem variants each with different computational complexity. We present 3-approximation algorithms for both variants, improving the previously known factor of 5. For disjoint groups, our algorithm runs in polynomial time, while for overlapping groups, we present a fixed-parameter tractable algorithm, where the exponential runtime depends only on the number of groups and centers. We show that these approximation factors match the theoretical lower bounds, assuming standard complexity theory conjectures. Finally, using an open-source implementation, we demonstrate the scalability of our algorithms on large synthetic datasets and assess the price of fairness on real-world data, comparing solution quality with and without fairness constraints.}
}


@inproceedings{DBLP:conf/www/ZhangCW0SC25,
	author = {Kaike Zhang and
                  Qi Cao and
                  Yunfan Wu and
                  Fei Sun and
                  Huawei Shen and
                  Xueqi Cheng},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Personalized Denoising Implicit Feedback for Robust Recommender System},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {4470--4481},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714932},
	doi = {10.1145/3696410.3714932},
	timestamp = {Fri, 09 May 2025 20:28:11 +0200},
	biburl = {https://dblp.org/rec/conf/www/ZhangCW0SC25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {While implicit feedback is foundational to modern recommender systems, factors such as human error, uncertainty, and ambiguity in user behavior inevitably introduce significant noise into this feedback, adversely affecting the accuracy and robustness of recommendations. To address this issue, existing methods typically aim to reduce the training weight of noisy feedback or discard it entirely, based on the observation that noisy interactions often exhibit higher losses in the overall loss distribution. However, we identify two key issues: (1) there is a significant overlap between normal and noisy interactions in the overall loss distribution, and (2) this overlap becomes even more pronounced when transitioning from pointwise loss functions (e.g., BCE loss) to pairwise loss functions (e.g., BPR loss). This overlap leads traditional methods to misclassify noisy interactions as normal, and vice versa. To tackle these challenges, we further investigate the loss overlap and find that for a given user, there is a clear distinction between normal and noisy interactions in the user's personal loss distribution. Based on this insight, we propose a resampling strategy to Denoise using the user's Personal Loss distribution, named PLD, which reduces the probability of noisy interactions being optimized. Specifically, during each optimization iteration, we create a candidate item pool for each user and resample the items from this pool based on the user's personal loss distribution, prioritizing normal interactions. Additionally, we conduct a theoretical analysis to validate PLD's effectiveness and suggest ways to further enhance its performance. Extensive experiments conducted on three datasets with varying noise ratios demonstrate PLD's efficacy and robustness.}
}


@inproceedings{DBLP:conf/www/ParkYS25,
	author = {Jin{-}Duk Park and
                  Jaemin Yoo and
                  Won{-}Yong Shin},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Criteria-Aware Graph Filtering: Extremely Fast Yet Accurate Multi-Criteria
                  Recommendation},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {4482--4493},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714799},
	doi = {10.1145/3696410.3714799},
	timestamp = {Fri, 09 May 2025 20:28:11 +0200},
	biburl = {https://dblp.org/rec/conf/www/ParkYS25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Multi-criteria (MC) recommender systems, which utilize MC rating information for recommendation, are increasingly widespread in various e-commerce domains. However, the MC recommendation using training-based collaborative filtering, requiring consideration of multiple ratings compared to single-criterion counterparts, often poses practical challenges in achieving state-of-the-art performance along with scalable model training. To solve this problem, we propose CA-GF, a  training-free  MC recommendation method, which is built upon  criteria-aware  graph filtering for  efficient yet accurate  MC recommendations. Specifically, first, we construct an item-item similarity graph using an MC user-expansion graph. Next, we design CA-GF composed of the following key components, including 1)  criterion-specific  graph filtering where the optimal filter for each criterion is found using various types of polynomial low-pass filters and 2)  criteria preference-infused aggregation  where the smoothed signals from each criterion are aggregated. We demonstrate that CA-GF is  (a) efficient : providing computational efficiency, offering an extremely fast runtime of less than <u> 0.2 seconds </u> even on the largest benchmark dataset,  (b) accurate : outperforming benchmark MC recommendation methods, achieving substantial accuracy gains up to 24% compared to the best competitor, and  (c) interpretable : providing interpretations for the contribution of each criterion to the model prediction based on visualizations.}
}


@inproceedings{DBLP:conf/www/Xiao00HWSZ25,
	author = {Zhenbang Xiao and
                  Yu Wang and
                  Shunyu Liu and
                  Bingde Hu and
                  Huiqiong Wang and
                  Mingli Song and
                  Tongya Zheng},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Disentangled Condensation for Large-scale Graphs},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {4494--4506},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714851},
	doi = {10.1145/3696410.3714851},
	timestamp = {Fri, 09 May 2025 20:28:11 +0200},
	biburl = {https://dblp.org/rec/conf/www/Xiao00HWSZ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graph condensation has emerged as an intriguing technique to save the expensive training costs of Graph Neural Networks (GNNs) by substituting a condensed small graph with the original graph. Despite the promising results achieved, previous methods usually employ an entangled paradigm of redundant parameters (nodes, edges, GNNs), which incurs complex joint optimization during condensation. This paradigm has considerably impeded the scalability of graph condensation, making it challenging to condense extremely large-scale graphs and generate high-fidelity condensed graphs. Therefore, we propose to disentangle the condensation process into a two-stage  GNN-free  paradigm, independently condensing nodes and generating edges while eliminating the need to optimize GNNs at the same time. The node condensation module avoids the complexity of GNNs by focusing on node feature alignment with anchors of the original graph, while the edge translation module constructs the edges of the condensed nodes by transferring the original structure knowledge with neighborhood anchors. This simple yet effective approach achieves at least 10 times faster than state-of-the-art methods with comparable accuracy on medium-scale graphs. Moreover, the proposed DisCo can successfully scale up to the Ogbn-papers100M graph containing over 100 million nodes with flexible reduction rates and improves performance on the second-largest Ogbn-products dataset by over 5%. Extensive downstream tasks and ablation study on five common datasets further demonstrate the effectiveness of the proposed DisCo framework. Our code is available at https://github.com/BangHonor/DisCo.}
}


@inproceedings{DBLP:conf/www/Wang0ZW0025,
	author = {Haotian Wang and
                  Hao Zou and
                  Xueguang Zhou and
                  Shangwen Wang and
                  Wenjing Yang and
                  Peng Cui},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Learning Feasible Causal Algorithmic Recourse: {A} Prior Structural
                  Knowledge Free Approach},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {4507--4518},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714859},
	doi = {10.1145/3696410.3714859},
	timestamp = {Fri, 09 May 2025 20:28:11 +0200},
	biburl = {https://dblp.org/rec/conf/www/Wang0ZW0025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Algorithmic recourse (AR) has made significant progress by identifying small perturbations in input features that can alter predictions, which provide a data-centric approach to understand decisions from diverse black-box models on the Web. Towards the feasibility issue, i.e., whether the recoursed examples provides actionable and reliable recommendations to end-users, causal algorithmic recourse have incorporated structural causal model (SCM) to preserve the realistic constraints among input features. For instance, preserving structural causal knowledge between "age" and "educational level" can avoid generating samples with decreasing age and increasing educational level. However, previous causal AR methods suffer from the requirement of prior  structural causal knowledge , e.g., prior causal graph or the whole SCM, which restricts the realistic application of causal AR methods. To bridge this gap, we aim to develop a novel framework for causal algorithmic recourse that does not rely on neither prior causal graph or prior SCM. Since identifying counterfactuals without causal graph is impossible, we instead propose to approximate and constrain the variation of the perturbed components, i.e., the exogenous noise variables, by formulating the generation of AR as the structure-preserving intervention. With the aid of development in non-linear Independent Component Analysis (ICA), our method can further achieve theoretically guaranteed constraints on such variation of exogeneous variables. Experimental results on synthetic, semi-synthetic, and real-world data demonstrate the effectiveness of our proposed methods without any prior causal graph or SCM knowledge.}
}


@inproceedings{DBLP:conf/www/WuWZZW25,
	author = {Zhiying Wu and
                  Jiajing Wu and
                  Hui Zhang and
                  Zibin Zheng and
                  Weiqiang Wang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Hunting in the Dark Forest: {A} Pre-trained Model for On-chain Attack
                  Transaction Detection in Web3},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {4519--4530},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714928},
	doi = {10.1145/3696410.3714928},
	timestamp = {Wed, 14 May 2025 08:12:21 +0200},
	biburl = {https://dblp.org/rec/conf/www/WuWZZW25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent years, a large number of on-chain attacks have emerged in the blockchain empowered Web3 ecosystem. In the year of 2023 alone, on-chain attacks have caused losses of over 585 million. Attackers use blockchain transactions to carry out on-chain attacks, for example, exploiting vulnerabilities or business logic flaws in Web3 applications. A wealth of efforts have been devoted to detecting on-chain attack transactions through expert patterns and machine learning techniques. However, in this ever-evolving ecosystem, the performance of current methods is limited in detecting new on-chain attacks, due to the obsoleting of attack recognition patterns or the reliance on on-chain attack samples. In this paper, we propose a universal approach for detecting on-chain attacks even when there are few or even no new on-chain attack samples. Specifically, an in-depth analysis of the transaction characteristics is conducted, and we propose a new insight to train a generic attack transaction detecting model, i.e., transaction reconstruction. Particularly, to overcome the over-fitting in the transaction reconstruction task, we use the web-scale function comments related to transactions as supervision information, rather than expert-confirmed labels. Experimental results demonstrate that the proposed approach surpasses the supervised state-of-the-art by 13% in AUC, with just 30 known on-chain attack samples. Moreover, without any known attack samples, our method can still detect new on-chain attacks in the wild (with a precision of 61.83%). Among attacks detected in the wild, we confirm 1,692 address poisoning attacks, a new type of on-chain attack targeting token holders. Our code is available at: https://github.com/wuzhy1ng/attack_trans_detection_www25.}
}


@inproceedings{DBLP:conf/www/PanHZS0025,
	author = {Yudai Pan and
                  Jiajie Hong and
                  Tianzhe Zhao and
                  Lingyun Song and
                  Jun Liu and
                  Xuequn Shang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Logic-Aware Knowledge Graph Reasoning for Structural Sparsity under
                  Large Language Model Supervision},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {4531--4542},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714685},
	doi = {10.1145/3696410.3714685},
	timestamp = {Fri, 09 May 2025 20:28:11 +0200},
	biburl = {https://dblp.org/rec/conf/www/PanHZS0025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Knowledge Graph (KG) reasoning aims to predict missing entities in incomplete triples, which requires adequate structural information to derive accurate embeddings. However, KGs in the real world are not as dense as the idealized benchmarks, where sparse graph structures restrict the comprehensive structural information for superior performance. Although the logical semantics in KGs shows its potential in alleviating the impact of structural sparsity, there still exist some challenges. The deficient supervision and the semantic gap of logic make it difficult to introduce logical semantics in sparse KG reasoning. To this end, we propose a novel KG reasoning approach LoLLM injecting logic with the supervised information supplied by the Large Language Model (LLM), which is proved to be effective in evaluating and scoring. Firstly, LoLLM derives structural embeddings employing a graph convolutional network (GCN) with relation-aware and triple-aware attention. LoLLM secondly constructs reasoning paths instantiated from the first-order logic rules extracted from sparse KGs, and injects the logical semantics by a designed LLM-enhanced tuning strategy. We propose a textual loss (TL) and a logical loss (LL) in the optimization and obtain logical tuning embeddings of KG in this process. Finally, LoLLM fuses structural embeddings from the GCN and logical tuning embeddings from the LLM-enhanced tuning for scoring and incomplete triple prediction. Extensive experiments on two sparse KGs and a benchmark show that LoLLM outperforms state-of-the-art structure-based and Language Model (LM)-augmented baselines. Moreover, the logic rules with corresponding confidences provide explicit explanations as an interpretable paradigm.}
}


@inproceedings{DBLP:conf/www/EberhardRH25,
	author = {Lukas Eberhard and
                  Thorsten Ruprechter and
                  Denis Helic},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Large Language Models as Narrative-Driven Recommenders},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {4543--4561},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714668},
	doi = {10.1145/3696410.3714668},
	timestamp = {Fri, 09 May 2025 20:28:11 +0200},
	biburl = {https://dblp.org/rec/conf/www/EberhardRH25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Narrative-driven recommenders aim to provide personalized suggestions for user requests expressed in free-form text such as ''I want to watch a thriller with a mind-bending story, like Shutter Island.'' Although large language models (LLMs) have been shown to excel in processing general natural language queries, their effectiveness for handling such recommendation requests remains relatively unexplored. To close this gap, we compare the performance of 38 open- and closed-source LLMs of various sizes, such as LLama 3.2 and GPT-4o, in a movie recommendation setting. For this, we utilize a gold-standard, crowdworker-annotated dataset of posts from reddit's movie suggestion community and employ various prompting strategies, including zero-shot, identity, and few-shot prompting. Our findings demonstrate the ability of LLMs to generate contextually relevant movie recommendations, significantly outperforming other state-of-the-art approaches, such as doc2vec. While we find that closed-source and large-parameterized models generally perform best, medium-sized open-source models remain competitive, being only slightly outperformed by their more computationally expensive counterparts. Furthermore, we observe no significant differences across prompting strategies for most models, underscoring the effectiveness of simple approaches such as zero-shot prompting for narrative-driven recommendations. Overall, this work offers valuable insights for recommender system researchers as well as practitioners aiming to integrate LLMs into real-world recommendation tools.}
}


@inproceedings{DBLP:conf/www/HuangHW025,
	author = {Liyan Huang and
                  Junzhou He and
                  Chao Wang and
                  Weihang Wang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {WaSCR: {A} WebAssembly Instruction-Timing Side Channel Repairer},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {4562--4571},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714693},
	doi = {10.1145/3696410.3714693},
	timestamp = {Fri, 09 May 2025 20:28:11 +0200},
	biburl = {https://dblp.org/rec/conf/www/HuangHW025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {WebAssembly (Wasm) is a platform-independent, low-level binary language that enables near-native performance in web applications. Given its growing importance in the web ecosystem, securing WebAssembly programs becomes increasingly important. A key security concern with WebAssembly is the threat of instruction-timing side-channel attacks, which exploit timing variations in branch instructions dependent on sensitive data, allowing attackers to infer sensitive information through timing measurement. In this paper, we introduce WaSCR, an automated  W eb A ssembly instruction-timing  S ide- C hannel  R epairer. WaSCR uses control and data dependencies to trace the flow of sensitive data and prevent its leakage. It employs rule-based code transformations to linearize the program, eliminating branches dependent on sensitive data and substituting them with constant-time selectors. Our evaluation demonstrates that WaSCR effectively eliminates instruction-timing side channels while maintaining program correctness, with efficient repairs and moderate performance overhead.}
}


@inproceedings{DBLP:conf/www/HanSTX25,
	author = {Qishen Han and
                  Grant Schoenebeck and
                  Biaoshuai Tao and
                  Lirong Xia},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Strong Equilibria in Bayesian Games with Bounded Group Size},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {4572--4581},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714585},
	doi = {10.1145/3696410.3714585},
	timestamp = {Thu, 01 May 2025 20:27:23 +0200},
	biburl = {https://dblp.org/rec/conf/www/HanSTX25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We study the group strategic behaviors in Bayesian games. Equilibria in previous work do not consider group strategic behaviors with bounded sizes and are too ''strong'' to exist in many scenarios. We propose the ex-ante Bayesian k-strong equilibrium and the Bayesian k-strong equilibrium, where no group of at most k agents can benefit from deviation. The two solution concepts differ in how agents calculate their utilities when contemplating whether a deviation is beneficial. Intuitively, agents are more conservative in the Bayesian k-strong equilibrium than in the ex-ante Bayesian k-strong equilibrium. With our solution concepts, we study collusion in the peer prediction mechanisms, as a representative of the Bayesian games with group strategic behaviors. We characterize the thresholds of the group size k so that truthful reporting in the peer prediction mechanism is an equilibrium for each solution concept, respectively. Our solution concepts can serve as criteria to evaluate the robustness of a peer prediction mechanism against collusion. Besides the peer prediction problem, we also discuss two other potential applications of our new solution concepts, voting and Blotto games, where introducing bounded group sizes provides more fine-grained insights into the behavior of strategic agents.}
}


@inproceedings{DBLP:conf/www/WangLXSGL25,
	author = {Jia Wang and
                  Yawen Li and
                  Zhe Xue and
                  Yingxia Shao and
                  Zeli Guan and
                  Wenling Li},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Horizontal Federated Heterogeneous Graph Learning: {A} Multi-Scale
                  Adaptive Solution to Data Distribution Challenges},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {4582--4591},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714722},
	doi = {10.1145/3696410.3714722},
	timestamp = {Tue, 13 May 2025 07:31:05 +0200},
	biburl = {https://dblp.org/rec/conf/www/WangLXSGL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated heterogeneous graph learning, an extension of federated learning, effectively represents complex multidimensional relationships while maintaining data privacy. In horizontal federated heterogeneous graph learning, data from different parties often vary in topology and semantics, leading to sensitivity to distribution imbalances and increasing topological complexity. These differences hinder models from learning shared representations and cause instability during training. To address these challenges, this paper proposes a novel multi-scale adaptive horizontal federated heterogeneous graph learning method MAFedHGL. A random masking mechanism forces the model to infer missing connections. The model also captures multi-hop and multi-path connections using high-order topology mining, enhancing robustness against structural heterogeneity. Dynamic semantic consistency modeling uses a masking matrix to recover and integrate diverse node attributes, ensuring both global and local semantic consistency. Using clustering coefficients as aggregation weights enables clients with richer structural information to contribute more effectively to the global model, improving adaptability and performance across varying data distributions in horizontal federated heterogeneous graph learning. Extensive experiments on multiple public heterogeneous graph datasets validate that the proposed method outperforms state-of-the-art methods in both performance and robustness across various data distribution scenarios.}
}


@inproceedings{DBLP:conf/www/FriedlerFKT25,
	author = {Ophir Friedler and
                  Hu Fu and
                  Anna R. Karlin and
                  Ariana Tang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Price Stability and Improved Buyer Utility with Presentation Design:
                  {A} Theoretical Study of the Amazon Buy Box},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {4592--4611},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714688},
	doi = {10.1145/3696410.3714688},
	timestamp = {Fri, 09 May 2025 20:28:11 +0200},
	biburl = {https://dblp.org/rec/conf/www/FriedlerFKT25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Platforms design the form of presentation by which sellers are shown to the buyers. This design not only shapes the buyers' experience but also leads to different market equilibria or dynamics. One component in this design is through the platform's mediation of the search frictions experienced by the buyers for different sellers. We take a model of monopolistic competition and show that, on one hand, when all sellers have the same inspection costs, the market sees no stable price since the sellers always have incentives to undercut each other, and, on the other hand, the platform may stabilize the price by giving prominence to one seller chosen by a carefully designed mechanism. This calls to mind Amazon's Buy Box. We study natural mechanisms for choosing the prominent seller, characterize the range of equilibrium prices implementable by them, and find that in certain scenarios the buyers' surplus improves as the search friction increases.}
}


@inproceedings{DBLP:conf/www/XuHW0Y0HW25,
	author = {Hefei Xu and
                  Min Hou and
                  Le Wu and
                  Fei Liu and
                  Yonghui Yang and
                  Haoyue Bai and
                  Richang Hong and
                  Meng Wang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Fair Personalized Learner Modeling Without Sensitive Attributes},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {4612--4624},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714787},
	doi = {10.1145/3696410.3714787},
	timestamp = {Fri, 09 May 2025 20:28:11 +0200},
	biburl = {https://dblp.org/rec/conf/www/XuHW0Y0HW25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Personalized learner modeling uses learners' historical behavior data to diagnose their cognitive abilities, a process known as Cognitive Diagnosis (CD). This is essential for web-based learning services such as learning resource recommendation and adaptive testing. However, prior studies have shown that CD models may unfairly correlate learners' abilities with sensitive attributes (e.g., gender, region), leading to biased outcomes. While existing approaches mitigate this issue by decorrelating sensitive attributes from the modeling process, privacy concerns make collecting such attributes impractical. Furthermore, the presence of multiple sensitive attributes complicates fairness improvements. In this paper, we explore how to achieve fair personalized learner modeling without relying on any sensitive attribute input. We introduce a novel fairness objective tailored for personalized learner modeling and design a max-min strategy to facilitate both sensitive information inference and fair CD modeling. In the max step, we infer pseudo-labels by maximizing the fairness objective, while in the min step, we retrain the CD model by minimizing it. Additionally, we provide a theoretical guarantee that our framework reduces the upper bound of fairness generalization error. Extensive experiments demonstrate that the proposed framework significantly outperforms existing methods. Our code is available at: https://github.com/HeFei-X/FairWISA.}
}


@inproceedings{DBLP:conf/www/WuZK025,
	author = {Longfeng Wu and
                  Yao Zhou and
                  Jian Kang and
                  Dawei Zhou},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Bridging Fairness and Uncertainty: Theoretical Insights and Practical
                  Strategies for Equalized Coverage in GNNs},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {4625--4634},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714909},
	doi = {10.1145/3696410.3714909},
	timestamp = {Fri, 09 May 2025 20:28:11 +0200},
	biburl = {https://dblp.org/rec/conf/www/WuZK025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graph Neural Networks (GNNs) have become indispensable tools in many domains, such as social network analysis, financial fraud detection, and drug discovery. Prior research primarily concentrated on improving prediction accuracy while overlooking how reliable the model predictions are. Conformal prediction on graphs emerges as a promising solution, offering statistically sound uncertainty estimates with a pre-defined coverage level. Despite the promising progress, existing works only focus on achieving model coverage guarantees without considering fairness in the coverage within different demographic groups. To bridge the gap between conformal prediction and fair coverage across different groups, we pose the fundamental question:  Can fair GNNs enable the uncertainty estimates to be fairly applied across demographic groups?  To answer this question, we provide a comprehensive analysis of the uncertainty estimation in fair GNNs employing various strategies. We prove theoretically that fair GNNs can enforce consistent uncertainty bounds across different demographic groups, thereby minimizing bias in uncertainty estimates. Furthermore, we conduct extensive experiments on five commonly used datasets across seven state-of-the-art fair GNN models to validate our theoretical findings. Additionally, based on the theoretical and empirical insights, we identify and analyze the key strategies from various fair GNN models that contribute to ensuring equalized uncertainty estimates. Our work estimates a solid foundation for future exploration of the practical implications and potential adjustments needed to enhance fairness in GNN applications across various domains. For reproducibility, we publish our data and code at https://github.com/wulongfeng/EqualizedCoverage_CP.}
}


@inproceedings{DBLP:conf/www/Ye0025,
	author = {Shanshan Ye and
                  Jie Lu and
                  Guangquan Zhang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Towards Safe Machine Unlearning: {A} Paradigm that Mitigates Performance
                  Degradation},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {4635--4652},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714638},
	doi = {10.1145/3696410.3714638},
	timestamp = {Thu, 01 May 2025 20:27:29 +0200},
	biburl = {https://dblp.org/rec/conf/www/Ye0025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We study the machine unlearning problem which aims to remove specific training data from a pre-trained machine learning model to allow users to exercise their 'right to be forgotten' to protect user privacy. Conventional machine unlearning methods would degrade the model performance after the unlearning procedure. To mitigate the issue, they typically rely on the access to the remaining training data to fine-tune the unlearned model to mitigate the influence of unlearning. However, accessing the remaining training data may not always be practical for different reasons (e.g., data expiration policies, storage limitations, or additional privacy constraints). Machine unlearning without access to the remaining training data poses significant challenges to retaining model performance. In this paper, we study how to unlearn specific training data from a pre-trained model without accessing the remaining training data and protect model performance without dramatically changing the model's parameters. We propose a practical method called Targeted Label Noise Injection. Intuitively, our method assigns incorrect yet controllable labels to the examples that need to be forgotten and fine-tunes the pre-trained model to learn these new labels. This strategy effectively moves the to-be-forgotten examples across the decision boundary with a small impact on the model's overall performance. We theoretically prove the effectiveness of the proposed method and empirically show that it achieves state-of-the-art unlearning performance across various datasets.}
}


@inproceedings{DBLP:conf/www/ZhuHS25,
	author = {Lixi Zhu and
                  Xiaowen Huang and
                  Jitao Sang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {A LLM-based Controllable, Scalable, Human-Involved User Simulator
                  Framework for Conversational Recommender Systems},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {4653--4661},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714858},
	doi = {10.1145/3696410.3714858},
	timestamp = {Tue, 13 May 2025 07:31:04 +0200},
	biburl = {https://dblp.org/rec/conf/www/ZhuHS25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Conversational Recommender System (CRS) leverages real-time feedback from users to dynamically model their preferences, thereby enhancing the system's ability to provide personalized recommendations and improving the overall user experience. CRS has demonstrated significant promise, prompting researchers to concentrate their efforts on developing user simulators that are both more realistic and trustworthy. The advent of Large Language Models (LLMs) has demonstrated capabilities that approach human-level intelligence across a diverse range of tasks. Research efforts have been made to utilize LLMs for building user simulators to evaluate the performance of CRS. Although these efforts showcase innovation, they are accompanied by certain limitations. In this work, we introduce a Controllable, Scalable, and Human-Involved (CSHI) simulator framework that manages the behavior of user simulators across various stages via a plugin manager. CSHI tailors behavioral simulations and interaction patterns to deliver authentic user-system engagement experiences. Through experiments and case studies in two conversational recommendation scenarios, we show that our framework can adapt to a variety of conversational recommendation settings and effectively simulate users' personalized preferences. Consequently, our simulator is able to generate feedback that closely mirrors that of real users. This facilitates a reliable assessment of existing CRS studies and promotes the creation of high-quality conversational recommendation datasets.}
}


@inproceedings{DBLP:conf/www/Some25,
	author = {Doli{\`{e}}re Francis Som{\'{e}}},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {MatriXSSed: {A} New Taxonomy for {XSS} in the Modern Web},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {4662--4672},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714774},
	doi = {10.1145/3696410.3714774},
	timestamp = {Thu, 01 May 2025 20:27:25 +0200},
	biburl = {https://dblp.org/rec/conf/www/Some25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cross-site scripting (XSS) has constantly remained one of the most prevalent attacks on the Web. In this work, we question its current taxonomy, i.e., the client- or server-side reflected (non-persistent) or stored (persistent) matrix. The Web has extensively changed. Consequently, considering XSS with the lenses of this famous matrix has become at least imprecise, at most impossible for many code injection scenarios where (i) a service worker or an edge worker generates HTTP responses and can reflect or persist XSS payloads infecting not only JavaScript in web pages but also Web assembly, web workers and affecting one or many users automatically; (ii) an attacker sends a web push message directly to a browser push service to trigger code execution in a dormant service worker; or (iii) a cross-origin adversary tampers with code stored by a vulnerable website on the user's physical/permanent file system, etc. Our proposal --to get out of the matrix and not enter another rigid one-- expresses the essence of XSS as code infection and affection attack and allows for clearly specifying the different actors and components involved, their environments, contexts, and storages, as well as their recurrence and persistence seen as a continuum rather than a binary marker. From a defensive perspective, we showcase the challenges and limitations of current mechanisms for mitigating XSS, which targets the entire attack surface of modern websites. Finally, we demonstrate an abuse of the Service-Worker-Allowed header to control entire domains with malicious service workers.}
}


@inproceedings{DBLP:conf/www/WangWWCZ025,
	author = {Jinghao Wang and
                  Yanping Wu and
                  Xiaoyang Wang and
                  Chen Chen and
                  Ying Zhang and
                  Lu Qin},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Effective Influence Maximization with Priority},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {4673--4683},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714888},
	doi = {10.1145/3696410.3714888},
	timestamp = {Fri, 09 May 2025 20:28:11 +0200},
	biburl = {https://dblp.org/rec/conf/www/WangWWCZ025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Influence maximization (IM) aims to identify a small set of influential users to maximize the information spread. It has been widely applied in the context of viral marketing, where a company distributes incentives to a few influencers to promote the product. However, in practical scenarios, not all users hold equal importance and certain users need to be prioritized for the specific requirements. Motivated by this, recently, a variant problem of IM, called  influence maximization with priority  (IMP), has been proposed. Given a graph G=(V,E), a priority set P ⊆ V and a threshold T ∈ [0, |P|], IMP aims to identify a set of  k  nodes (termed  seeds  ) to maximize the expected number of activated nodes in  G  while satisfying that the expected number of activated nodes in~ P  is no less than the given threshold. Nevertheless, we show that existing solutions for IMP are inferior in maximizing the influence spread in  G , and can only offer poor approximation ratios in many cases. To address these limitations, in this paper, we first propose a novel framework named SAR with both superior effectiveness and strong theoretical guarantees. In addition, to obtain more practical results, we study the IMP problem under the  adaptive  setting, where the seeds are iteratively selected after observing the diffusion result of the previous seeds. We design an effective method AAS that achieves expected approximation guarantees. Extensive experiments demonstrate that, compared with the state-of-the-art method, SAR achieves up to 22.3% larger spread and ås achieves up to 42.6% larger spread, with both exhibiting a higher approximation ratio.}
}


@inproceedings{DBLP:conf/www/HongLXCZ025,
	author = {Rongpei Hong and
                  Jian Lang and
                  Jin Xu and
                  Zhangtao Cheng and
                  Ting Zhong and
                  Fan Zhou},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Following Clues, Approaching the Truth: Explainable Micro-Video Rumor
                  Detection via Chain-of-Thought Reasoning},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {4684--4698},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714559},
	doi = {10.1145/3696410.3714559},
	timestamp = {Fri, 09 May 2025 20:28:11 +0200},
	biburl = {https://dblp.org/rec/conf/www/HongLXCZ025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The rapid spread of rumor content on online micro-video platforms poses significant threats to public health and safety. However, existing Micro-Video Rumor Detection (MVRD) methods are generally black-box, which lacks transparency and makes it difficult to understand the reasoning behind classification decisions. In this work, we introduce  ExMRD , a novel  Ex plainable  M icro-video  R umor  D etection framework designed to generate detailed and coherent explanations for enhancing MVRD. Inspired by the powerful reasoning capacity of Chain-of-Thought (CoT), we introduce a novel inference mechanism called R 3 CoT-- consisting of Refining, Retrieving, and Reasoning on MVRD. This mechanism enables Multimodal Large Language Models (MLLMs) to reorganize the original video content, retrieve domain knowledge related to rumors, and generate explainable conclusions regarding whether the micro-video contains rumor information. Instead of directly fine-tuning MLLMs for MVRD, which is computationally expensive, we propose a Small Language Reviewer (SLReviewer), which distills the outputs of R 3 CoT guided MLLMs to ensure efficient and reliable predictions. Extensive experiments on three real-world benchmarks demonstrate that ExMRD significantly outperforms competitive baselines while providing high-quality rationales.}
}


@inproceedings{DBLP:conf/www/WangMFMMW0B25,
	author = {Zihan Wang and
                  Zhongkui Ma and
                  Xinguo Feng and
                  Zhiyang Mei and
                  Ethan Ma and
                  Derui Wang and
                  Minhui Xue and
                  Guangdong Bai},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {{AI} Model Modulation with Logits Redistribution},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {4699--4709},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714737},
	doi = {10.1145/3696410.3714737},
	timestamp = {Fri, 09 May 2025 20:28:11 +0200},
	biburl = {https://dblp.org/rec/conf/www/WangMFMMW0B25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Large-scale models are typically adapted to meet the diverse requirements of model owners and users. However, maintaining multiple specialized versions of the model is inefficient. In response, we propose AIM, a novel model modulation paradigm that enables a single model to exhibit diverse behaviors to meet the specific end requirements. AIM enables two key modulation modes: utility and focus modulations. The former provides model owners with dynamic control over output quality to deliver varying utility levels, and the latter offers users precise control to shift model's focused input features. AIM introduces a logits redistribution strategy that operates in a training data-agnostic and retraining-free manner. We establish a formal foundation to ensure AIM's regulation capability, based on the statistical properties of logits ordering via joint probability distributions. Our evaluation confirms AIM's practicality and versatility for AI model modulation, with tasks spanning image classification, semantic segmentation and text generation, and prevalent architectures including ResNet, SegFormer and Llama.}
}


@inproceedings{DBLP:conf/www/Cui0025,
	author = {Shuang Cui and
                  Kai Han and
                  Jing Tang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Linear-Time Algorithms for Representative Subset Selection From Data
                  Streams},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {4710--4721},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714890},
	doi = {10.1145/3696410.3714890},
	timestamp = {Fri, 09 May 2025 20:28:11 +0200},
	biburl = {https://dblp.org/rec/conf/www/Cui0025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Representative subset selection from data streams is a critical problem with wide-ranging applications in web data mining and machine learning, such as social media marketing, big data summarization, and recommendation systems. This problem is often framed as maximizing a monotone submodular function subject to a knapsack constraint, where each data element in the stream has an associated cost, and the goal is to select elements within a budget  B  to maximize revenue. However, existing algorithms typically rely on restrictive assumptions about the costs of data elements, and their performance bounds heavily depend on the budget  B . As a result, these algorithms are only effective in limited scenarios and have super-linear time complexity, making them unsuitable for large-scale data streams. In this paper, we introduce the first linear-time streaming algorithms for this problem, without any assumptions on the data stream, while also minimizing memory usage. Specifically, our single-pass streaming algorithm achieves an approximation ratio of 1/8-ε under  O  (n) time complexity and  O (k log 1/ε) space complexity, where  k  is the largest cardinality of any feasible solution. Our multi-pass streaming algorithm improves this to a (1/2-ε)-approximation using only three passes over the stream, with  O  (n/ε log 1/ε) time complexity and  O (k/ε log 1/ε) space complexity. Extensive experiments across various applications related to web data mining and social media marketing demonstrate the superiority of our algorithms in terms of both effectiveness and efficiency.}
}


@inproceedings{DBLP:conf/www/TianDYGL025,
	author = {Zhihua Tian and
                  Yuan Ding and
                  Xiang Yu and
                  Enchao Gong and
                  Jian Liu and
                  Kui Ren},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Towards Collaborative Anti-Money Laundering Among Financial Institutions},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {4722--4733},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714576},
	doi = {10.1145/3696410.3714576},
	timestamp = {Fri, 09 May 2025 20:28:11 +0200},
	biburl = {https://dblp.org/rec/conf/www/TianDYGL025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Money laundering is the process that intends to legalize the income derived from illicit activities, thus facilitating their entry into the monetary flow of the economy without jeopardizing their source. It is crucial to identify such activities accurately and reliably in order to enforce anti-money laundering (AML). Despite considerable efforts to AML, a large number of such activities still go undetected. Rule-based methods were first introduced and are still widely used in current detection systems. With the rise of machine learning, graph-based learning methods have gained prominence in detecting illicit accounts through the analysis of money transfer graphs. Nevertheless, these methods generally assume that the transaction graph is centralized, whereas in practice, money laundering activities usually span multiple financial institutions. Due to regulatory, legal, commercial, and customer privacy concerns, institutions tend not to share data, restricting their utility in practical usage. In this paper, we propose the  first  algorithm that supports performing AML over multiple institutions while protecting the security and privacy of local data. To evaluate, we construct Alipay-ECB, a real-world dataset comprising digital transactions from Alipay, the world's largest mobile payment platform, alongside transactions from E-Commerce Bank (ECB). The dataset includes over 200 million accounts and 300 million transactions, covering both intra-institution transactions and those between Alipay and ECB. This makes it the largest real-world transaction graph available for analysis. The experimental results demonstrate that our methods can effectively identify cross-institution money laundering subgroups. Additionally, experiments on synthetic datasets also demonstrate that our method is efficient, requiring only a few minutes on datasets with millions of transactions. Our code and dataset are available on https://github.com/zhihuat/Collaborative-AML.}
}


@inproceedings{DBLP:conf/www/LinJJHN25,
	author = {Xuanrui Lin and
                  Chao Jia and
                  Junhui Ji and
                  Hui Han and
                  Usman Naseem},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Ask, Acquire, Understand: {A} Multimodal Agent-based Framework for
                  Social Abuse Detection in Memes},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {4734--4744},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714895},
	doi = {10.1145/3696410.3714895},
	timestamp = {Fri, 09 May 2025 20:28:11 +0200},
	biburl = {https://dblp.org/rec/conf/www/LinJJHN25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Memes serve as a powerful medium of expression in the digital age, shaping cultural discourse and conveying ideas succinctly and engagingly. However, their potential for social abuse highlights the importance of developing effective methods to detect harmful content within memes. Recent studies on memes have focused on transforming images into textual captions using large language models (LLMs). However, these approaches often result in non-informative captions. Furthermore, previous methods have only been tested on limited datasets, providing insufficient evidence of their robustness. To address these limitations, we present a multimodal, agent-based framework designed to generate informative visual descriptions of memes by asking insightful questions to improve visual descriptions in zero-shot visual question-answering settings. Specifically, we leverage an LLM as agents with distinct roles and a large multimodal model (LMM) as a vision expert. These agents first analyze the images and then ask informative questions related to potential social abuse in memes to obtain high-quality answers about the images. Through continuous discussion guided by instructional prompts, the agents gather high-quality information while repeatedly acquiring image data from the LMM, which helps detect social abuse in memes. Results on a dataset of 6,626 memes across 5 tasks show our framework surpasses state-of-the-art methods, demonstrating strong generalizability and improved detection of social abuse in memes.}
}


@inproceedings{DBLP:conf/www/WuWLLLYL25,
	author = {Wenhao Wu and
                  Zhaohua Wang and
                  Qinxin Li and
                  Zihan Li and
                  Yi Li and
                  Jin Yan and
                  Zhenyu Li},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {{ODNS} Clustering: Unveiling Client-Side Dependency in Open {DNS}
                  Infrastructure},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {4745--4754},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714834},
	doi = {10.1145/3696410.3714834},
	timestamp = {Thu, 17 Jul 2025 16:37:43 +0200},
	biburl = {https://dblp.org/rec/conf/www/WuWLLLYL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {There are over a million open DNS servers in the wild. However, not all servers perform recursive queries directly. Instead, many DNS forwarders forward queries to upstream recursive servers or other DNS forwarders for name resolving on their behalf. The groups of open servers that have such dependencies on each other form  ODNS Clusters . The dependencies can result in vulnerabilities; yet we have little knowledge of the ODNS cluster structure. In this work, we measure the inter-dependence of open DNS resolvers and find that 1.9 million open DNS servers form  only  81,636 ODNS clusters. We further analyze the characteristics of the clustered ODNS structure. The key observations include biased cluster size distribution, discrepancy of ODNS infrastructures among countries, concentration in major public DNS server providers, and potential security and resilience risks due to the dependence.}
}


@inproceedings{DBLP:conf/www/Lin0SZ00ZZ025,
	author = {Xixun Lin and
                  Yanan Cao and
                  Nan Sun and
                  Lixin Zou and
                  Chuan Zhou and
                  Peng Zhang and
                  Shuai Zhang and
                  Ge Zhang and
                  Jia Wu},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Conformal Graph-level Out-of-distribution Detection with Adaptive
                  Data Augmentation},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {4755--4765},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714879},
	doi = {10.1145/3696410.3714879},
	timestamp = {Fri, 09 May 2025 20:28:11 +0200},
	biburl = {https://dblp.org/rec/conf/www/Lin0SZ00ZZ025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graph-level out-of-distribution (OOD) detection, which attempts to identify OOD graphs originated from an unknown distribution, is a vital building block for safety-critical applications in Web and society. Current approaches concentrate on how to learn better graph representations, but fail to provide any statistically guarantee on detection results, therefore impeding their deployments in the scenario where detection errors would result in serious consequences. To overcome this critical issue, we propose the Conformal Graph-level Out-of-distribution Detection (CGOD), extending the theory of conformal prediction to graph-level OOD detection with a rigorous control over the false positive rate. In CGOD, we develop a new aggregated non-conformity score function based on the proposed adaptive data augmentation. Through the guidance from two designed metrics, i.e., score consistency and representation diversity, our augmentation strategy can generate multiple non-conformity scores, and aggregating these generated non-conformity scores together is robust to the misleading information. Meanwhile, our score function can perceive the subsequent process of conformal inference, enabling the aggregated non-conformity score to be adaptive to different input graphs and deriving a more accurate score estimation. We conduct experiments on multiple real-world datasets with different empirical settings. Extensive results and model analyses demonstrate the superior performance of our approach over several competitive baselines.}
}


@inproceedings{DBLP:conf/www/SunSZZ00025,
	author = {Zhongxiang Sun and
                  Zihua Si and
                  Xiaoxue Zang and
                  Kai Zheng and
                  Yang Song and
                  Xiao Zhang and
                  Jun Xu},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {LargePiG for Hallucination-Free Query Generation: Your Large Language
                  Model is Secretly a Pointer Generator},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {4766--4779},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714800},
	doi = {10.1145/3696410.3714800},
	timestamp = {Sat, 31 May 2025 23:12:38 +0200},
	biburl = {https://dblp.org/rec/conf/www/SunSZZ00025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recent research on query generation has focused on using Large Language Models (LLMs), which, despite achieving state-of-the-art performance, also introduce hallucination issues in generated queries. In this work, we categorize these issues into relevance hallucination and factuality hallucination, proposing a new typology for hallucinations arising from LLM-based query generation. We present an effective approach to decouple content from form in LLM-generated queries, preserving the factual knowledge extracted and integrated from inputs while leveraging the LLM's linguistic capabilities to construct syntactic structures, including function words. Specifically, we introduce a model-agnostic and training-free method that transforms the  Large  Language Model into a  P o i nter- G enerator ( LargePiG ), where the pointer attention distribution utilizes the LLM's inherent attention weights, and the copy probability is derived from the difference between the vocabulary distribution in the model's high layers and the last layer. To validate the effectiveness of LargePiG, we constructed two datasets for assessing hallucination issues in query generation, covering both document and video scenarios. Empirical studies on various LLMs demonstrated LargePiG's superiority across both datasets. Additional experiments further verified that LargePiG reduces hallucination in large vision-language models and enhances the accuracy of document-based question-answering and factuality evaluation tasks. The source code and dataset are available at https://github.com/Jeryi-Sun/LargePiG.}
}


@inproceedings{DBLP:conf/www/ZhuoWWP025,
	author = {Xingrui Zhuo and
                  Jiapu Wang and
                  Gongqing Wu and
                  Shirui Pan and
                  Xindong Wu},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Effective Instruction Parsing Plugin for Complex Logical Query Answering
                  on Knowledge Graphs},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {4780--4792},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714794},
	doi = {10.1145/3696410.3714794},
	timestamp = {Fri, 09 May 2025 20:28:11 +0200},
	biburl = {https://dblp.org/rec/conf/www/ZhuoWWP025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Knowledge Graph Query Embedding (KGQE) aims to embed First-Order Logic (FOL) queries in a low-dimensional KG space for complex reasoning over incomplete KGs. To enhance the generalization of KGQE models, recent studies integrate various external information (such as entity types and relation context) to better capture the logical semantics of FOL queries. The whole process is commonly referred to as  Query Pattern Learning  (QPL). However, current QPL methods typically suffer from the pattern-entity alignment bias problem, leading to the learned defective query patterns limiting KGQE models' performance. To address this problem, we propose an effective Query Instruction Parsing Plugin (QIPP) that leverages the context awareness of Pre-trained Language Models (PLMs) to capture latent query patterns from code-like query instructions. Unlike the external information introduced by previous QPL methods, we first propose code-like instructions to express FOL queries in an alternative format. This format utilizes textual variables and nested tuples to convey the logical semantics within FOL queries, serving as raw materials for a PLM-based instruction encoder to obtain complete query patterns. Building on this, we design a query-guided instruction decoder to adapt query patterns to KGQE models. To further enhance QIPP's effectiveness across various KGQE models, we propose a query pattern injection mechanism based on compressed optimization boundaries and an adaptive normalization component, allowing KGQE models to utilize query patterns more efficiently. Extensive experiments demonstrate that our plug-and-play method improves the performance of eight basic KGQE models and outperforms two state-of-the-art QPL methods.}
}


@inproceedings{DBLP:conf/www/Shimizu0W0OKSYS25,
	author = {Ryotaro Shimizu and
                  Takashi Wada and
                  Yu Wang and
                  Johannes Kruse and
                  Sean O'Brien and
                  Sai Htaung Kham and
                  Linxin Song and
                  Yuya Yoshikawa and
                  Yuki Saito and
                  Fugee Tsung and
                  Masayuki Goto and
                  Julian J. McAuley},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Disentangling Likes and Dislikes in Personalized Generative Explainable
                  Recommendation},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {4793--4809},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714583},
	doi = {10.1145/3696410.3714583},
	timestamp = {Wed, 21 May 2025 14:14:07 +0200},
	biburl = {https://dblp.org/rec/conf/www/Shimizu0W0OKSYS25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recent research on explainable recommendation generally frames the task as a standard text generation problem, and evaluates models simply based on the textual similarity between the predicted and ground-truth explanations. However, this approach fails to consider one crucial aspect of the systems: whether their outputs accurately reflect the users' (post-purchase) sentiments, i.e., whether and why they would like and/or dislike the recommended items. To shed light on this issue, we introduce new datasets and evaluation methods that focus on the users' sentiments. Specifically, we construct the datasets by explicitly extracting users' positive and negative opinions from their post-purchase reviews using an LLM, and propose to evaluate systems based on whether the generated explanations 1) align well with the users' sentiments, and 2) accurately identify both positive and negative opinions of users on the target items. We benchmark several recent models on our datasets and demonstrate that achieving strong performance on existing metrics does not ensure that the generated explanations align well with the users' sentiments. Lastly, we find that existing models can provide more sentiment-aware explanations when the users' (predicted) ratings for the target items are directly fed into the models as input. The datasets and benchmark implementation are available at: https://github.com/jchanxtarov/sent_xrec.}
}


@inproceedings{DBLP:conf/www/KochOSWCDDHWHP25,
	author = {Luke Koch and
                  Sean Oesch and
                  Amir Sadovnik and
                  Brian Weber and
                  Amul Chaulagain and
                  Matthew Dixson and
                  Jared Dixon and
                  Mike Huettel and
                  Cory L. Watson and
                  Jacob Hartman and
                  Richard Patulski},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {On the Abuse and Detection of Polyglot Files},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {4810--4822},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714814},
	doi = {10.1145/3696410.3714814},
	timestamp = {Fri, 09 May 2025 20:28:11 +0200},
	biburl = {https://dblp.org/rec/conf/www/KochOSWCDDHWHP25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A polyglot is a file that is valid in two or more formats. Polyglot files pose a problem for file-upload and generative AI web interfaces that rely on format identification to determine how to securely handle incoming files. In this work we found that existing file-format and embedded-file detection tools, even those developed specifically for polyglot files, fail to reliably detect polyglot files used in the wild. To address this issue, we studied the use of polyglot files by malicious actors in the wild, finding 30 polyglot samples and 15 attack chains that leveraged polyglot files. Using knowledge from our survey of polyglot usage in the wild---the first of its kind---we created a novel data set based on adversary techniques. We then trained a machine learning detection solution, PolyConv, using this data set. PolyConv achieves a precision-recall area-under-curve score of 0.999 with an F1 score of 99.20% for polyglot detection and 99.47% for file-format identification, significantly outperforming all other tools tested. We developed a content disarmament and reconstruction tool,  ImSan,  that successfully sanitized 100% of the tested image-based polyglots, which were the most common type found via the survey. Our work provides concrete tools and suggestions to enable defenders to better defend themselves against polyglot files, as well as directions for future work to create more robust file specifications and methods of disarmament.}
}


@inproceedings{DBLP:conf/www/ZhouZZSY25,
	author = {Baohang Zhou and
                  Ying Zhang and
                  Yu Zhao and
                  Xuhui Sui and
                  Xiaojie Yuan},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Multimodal Graph-Based Variational Mixture of Experts Network for
                  Zero-Shot Multimodal Information Extraction},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {4823--4831},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714832},
	doi = {10.1145/3696410.3714832},
	timestamp = {Fri, 09 May 2025 20:28:11 +0200},
	biburl = {https://dblp.org/rec/conf/www/ZhouZZSY25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Multimodal information extraction on social media is a series of fundamental tasks to construct the multimodal knowledge graph. The tasks aim to extract the structural information in free texts with the incorporate images, including: multimodal named entity typing and multimodal relation extraction. However, the growing number of multimodal data implies a growing category set and the newly emerged entity types or relations should be recognized without additional training. To address the aforementioned challenges, we focus on the zero-shot multimodal information extraction tasks which require using textual and visual modalities for recognizing unseen categories. Compared with text-based zero-shot information extraction models, the existing multimodal ones make the textual and visual modalities aligned directly and exploit various fusion strategies to improve their performances. But the existing methods ignore the fine-grained semantic correlation of text-image pairs and samples. Therefore, we propose the multimodal graph-based variational mixture of experts network (MG-VMoE) which takes the MoE network as the backbone and exploits it for aligning multimodal representations in a fine-grained way. Considering to learn informative representations of multimodal data, we design each expert network as a variational information bottleneck to process two modalities in a uni-backbone. Moreover, we also propose the multimodal graph-based virtual adversarial training to learn the semantic correlation between the samples. The experimental results on the two benchmark datasets demonstrate the superiority of MG-VMoE over the baselines.}
}


@inproceedings{DBLP:conf/www/KancherlaGB25,
	author = {Gayatri Priyadarsini Kancherla and
                  Dishank Goel and
                  Abhishek Bichhawat},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Least Privilege Access for Persistent Storage Mechanisms in Web Browsers},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {4832--4840},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714887},
	doi = {10.1145/3696410.3714887},
	timestamp = {Fri, 09 May 2025 20:28:11 +0200},
	biburl = {https://dblp.org/rec/conf/www/KancherlaGB25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Web applications often include third-party content to personalize a user's online experience. These scripts have unrestricted access to a user's private data stored in the browser's persistent storage, associated with the host page. Various mechanisms have been implemented to restrict access to these storage objects, however, the existing mechanisms provide an all-or-none access and do not work in scenarios where web applications need to allow controlled access to cookies and localstorage objects by third-party scripts. If some of these scripts behave maliciously, they can easily access and modify private user information that are stored in the browser objects. The goal of our work is to design a mechanism to enforce fine-grained control of persistent storage objects. We perform an empirical study of persistent storage access by third-party scripts on Tranco's top 10,000 websites and find that 89.84% of all cookie accesses, 90.98% of all localstorage accesses and 72.49% of IndexedDB accesses are done by third-party scripts. Our approach enforces least privilege access for third-party scripts on these objects to ensure their security by attaching labels to the storage objects that specify which domains are allowed to read from and write to these objects. We implement our approach on the Firefox browser and show that it effectively blocks scripts from other domains, which are not allowed access based on these labels, from accessing the storage objects. We show that our enforcement results in some functionality breakage in websites with the default settings, which can be fixed by correctly labeling the storage objects used by the third-party scripts.}
}


@inproceedings{DBLP:conf/www/Bermejo-AguedaC25,
	author = {Miguel A. Bermejo{-}Agueda and
                  Patricia Callejo and
                  Rub{\'{e}}n Cuevas and
                  {\'{A}}ngel Cuevas and
                  Ramakrishnan Durairajan and
                  Reza Rejaie and
                  {\'{A}}lvaro Mayol},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Unveiling Network Performance in the Wild: An Ad-Driven Analysis of
                  Mobile Download Speeds},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {4841--4852},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714761},
	doi = {10.1145/3696410.3714761},
	timestamp = {Fri, 09 May 2025 20:28:11 +0200},
	biburl = {https://dblp.org/rec/conf/www/Bermejo-AguedaC25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Accurate measurement of mobile network performance is crucial for optimizing user experience and ensuring regulatory compliance. Traditional methods like crowdsourcing approaches, though effective, depend heavily on user participation and extensive infrastructure. In this paper, we introduce  adNPM,  a novel technique for measuring download speed by embedded measurement code in ads displayed across web browsers and mobile apps, without requiring user participation. Through controlled lab tests and real-world deployments in 15 countries, we demonstrate that  adNPM  achieves accuracy comparable to well-established tools like Speedtest by Ookla and Opensignal while significantly reducing data consumption. adNPM  leverages ad campaigns to collect extensive data from diverse demographics and geographic regions, providing deep insights into the performance of major Internet Service Providers (ISPs). Furthermore,  adNPM  can segment download speed analyses by demographic factors and operating systems, making it a versatile and scalable tool for network performance assessment.}
}


@inproceedings{DBLP:conf/www/HuGSE25,
	author = {Jiazhen Hu and
                  Jiaying Gong and
                  Hongda Shen and
                  Hoda Eldardiry},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Hypergraph-based Zero-shot Multi-modal Product Attribute Value Extraction},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {4853--4862},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714714},
	doi = {10.1145/3696410.3714714},
	timestamp = {Fri, 09 May 2025 20:28:11 +0200},
	biburl = {https://dblp.org/rec/conf/www/HuGSE25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {It is essential for e-commerce platforms to provide accurate, complete, and timely product attribute values, in order to improve the search and recommendation experience for both customers and sellers. In the real-world scenario, it is difficult for these platforms to identify attribute values for the newly introduced products given no similar product history records for training or retrieval. Besides, how to jointly learn the product representation given various product information in multiple modalities, such as textual modality (e.g., product titles and descriptions) and visual modality (e.g., product images), is also a challenging task. To address these limitations, we propose a novel method for extracting multi-label product attribute-value pairs from multiple modalities in the zero-shot scenario, where labeled data is absent during training. Specifically, our method constructs heterogeneous hypergraphs, where product information from different modalities is represented by different types of nodes, and the text and image nodes are embedded and learned through CLIP encoders to effectively capture and integrate multi-modal product information. Then, the complex interrelations among these nodes are modeled through the hyperedges. By learning informative node representations, our method can accurately predict links between unseen product nodes and attribute-value nodes, enabling zero-shot attribute value extraction. We conduct extensive experiments and ablation studies on several categories of the public MAVE dataset and the results demonstrate that our proposed method significantly outperforms several state-of-the-art generative model baselines in multi-label, multi-modal product attribute value extraction in the zero-shot setting.}
}


@inproceedings{DBLP:conf/www/HanZCH0WF0025,
	author = {Shen Han and
                  Zhiyao Zhou and
                  Jiawei Chen and
                  Zhezheng Hao and
                  Sheng Zhou and
                  Gang Wang and
                  Yan Feng and
                  Chun Chen and
                  Can Wang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Uncertainty-Aware Graph Structure Learning},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {4863--4874},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714927},
	doi = {10.1145/3696410.3714927},
	timestamp = {Fri, 09 May 2025 20:28:11 +0200},
	biburl = {https://dblp.org/rec/conf/www/HanZCH0WF0025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graph Neural Networks  (GNNs) have become a prominent approach for learning from graph-structured data. However, their effectiveness can be significantly compromised when the graph structure is suboptimal. To address this issue,  Graph Structure Learning  (GSL) has emerged as a promising technique that refines node connections adaptively. Nevertheless, we identify two key limitations in existing GSL methods: 1) Most methods primarily focus on node similarity to construct relationships, while overlooking the quality of node information. Blindly connecting low-quality nodes and aggregating their ambiguous information can degrade the performance of other nodes. 2) The constructed graph structures are often constrained to be symmetric, which may limit the model's flexibility and effectiveness. To overcome these limitations, we propose an  Uncertainty-aware Graph Structure Learning  (UnGSL) strategy. UnGSL estimates the uncertainty of node information and utilizes it to adjust the strength of directional connections, where the influence of nodes with high uncertainty is adaptively reduced. Importantly, UnGSL serves as a plug-in module that can be seamlessly integrated into existing GSL methods with minimal additional computational cost. In our experiments, we implement UnGSL into six representative GSL methods, demonstrating consistent performance improvements. The code is available at https://github.com/UnHans/UnGSL.}
}


@inproceedings{DBLP:conf/www/ZimmertB0QCSSSX25,
	author = {Julian Zimmert and
                  R{\'{o}}bert Busa{-}Fekete and
                  Andr{\'{a}}s Gy{\"{o}}rgy and
                  Linhai Qiu and
                  Hyomin Choi and
                  Tzu{-}Wei Sung and
                  Hao Shen and
                  Sharmila Subramaniam and
                  Li Xiao},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {A Scalable Crawling Algorithm Utilizing Noisy Change-Indicating Signals},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {4875--4888},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714692},
	doi = {10.1145/3696410.3714692},
	timestamp = {Fri, 09 May 2025 20:28:11 +0200},
	biburl = {https://dblp.org/rec/conf/www/ZimmertB0QCSSSX25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Web refresh crawling is the problem of keeping a cache of web pages fresh, that is, having the most recent copy available when a page is requested, given a limited bandwidth available to the crawler. Under the assumption that the change and request events, resp., to each web page follow independent Poisson processes, the optimal scheduling policy was derived by Azar et al. 2018. In this paper, we study an extension of this problem where side information indicating content changes, such as various types of web pings, for example, signals from sitemaps, content delivery networks, etc., is available. Incorporating such side information into the crawling policy is challenging, because (i) the signals can be noisy with false positive events and with missing change events; and (ii) the crawler should achieve a fair performance over web pages regardless of the quality of the side information, which might differ from web page to web page. We propose a scalable crawling algorithm which (i) uses the noisy side information in an optimal way under mild assumptions; (ii) can be deployed without heavy centralized computation; (iii) is able to crawl web pages at a constant total rate without spikes in the total bandwidth usage over any time interval, and automatically adapt to the new optimal solution when the total bandwidth changes without centralized computation. Experiments clearly demonstrate the versatility of our approach.}
}


@inproceedings{DBLP:conf/www/KweonJKY25,
	author = {Wonbin Kweon and
                  Sanghwan Jang and
                  SeongKu Kang and
                  Hwanjo Yu},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Uncertainty Quantification and Decomposition for LLM-based Recommendation},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {4889--4901},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714601},
	doi = {10.1145/3696410.3714601},
	timestamp = {Fri, 09 May 2025 20:28:11 +0200},
	biburl = {https://dblp.org/rec/conf/www/KweonJKY25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Despite the widespread adoption of large language models (LLMs) for recommendation, we demonstrate that LLMs often exhibit uncertainty in their recommendations. To ensure the trustworthy use of LLMs in generating recommendations, we emphasize the importance of assessing the reliability of recommendations generated by LLMs. We start by introducing a novel framework for estimating the predictive uncertainty to quantitatively measure the reliability of LLM-based recommendations. We further propose to decompose the predictive uncertainty into recommendation uncertainty and prompt uncertainty, enabling in-depth analyses of the primary source of uncertainty. Through extensive experiments, we (1) demonstrate predictive uncertainty effectively indicates the reliability of LLM-based recommendations, (2) investigate the origins of uncertainty with decomposed uncertainty measures, and (3) propose uncertainty-aware prompting for a lower predictive uncertainty and enhanced recommendation. Our source code and model weights are available at https://github.com/WonbinKweon/UNC_LLM_REC_WWW2025}
}


@inproceedings{DBLP:conf/www/WuL0ZWS25,
	author = {Jiajing Wu and
                  Kaixin Lin and
                  Dan Lin and
                  Bozhao Zhang and
                  Zhiying Wu and
                  Jianzhong Su},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Safeguarding Blockchain Ecosystem: Understanding and Detecting Attack
                  Transactions on Cross-chain Bridges},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {4902--4912},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714604},
	doi = {10.1145/3696410.3714604},
	timestamp = {Fri, 09 May 2025 20:28:12 +0200},
	biburl = {https://dblp.org/rec/conf/www/WuL0ZWS25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cross-chain bridges are essential decentralized applications (DApps) to facilitate interoperability between different blockchain networks. Unlike regular DApps, the functionality of cross-chain bridges relies on the collaboration of information both on and off the chain, which exposes them to a wider risk of attacks. According to our statistics, attacks on cross-chain bridges have resulted in losses of nearly 4.3 billion since 2021. Therefore, it is particularly necessary to understand and detect attacks on cross-chain bridges. In this paper, we collect the largest number of cross-chain bridge attack incidents to date, including 49 attacks that occurred between June 2021 and September 2024, of which 22 were attacks on cross-chain bridge business logic. Our analysis reveal that attacks against cross-chain business logic cause significantly more damage than those that do not. These cross-chain attacks exhibit different patterns compared to normal transactions in terms of call structure, which effectively indicates potential attack behaviors. Given the significant losses in these cases and the scarcity of related research, this paper aims to detect attacks against cross-chain business logic, and propose the BridgeGuard tool. Specifically, BridgeGuard models cross-chain transactions from a graph perspective, and employs a two-stage detection framework comprising global and local graph mining to identify attack patterns in cross-chain transactions. We conduct multiple experiments on the datasets with 203 attack transactions and 40,000 normal cross-chain transactions. The results show that BridgeGuard's reported recall score is 36.32% higher than that of state-of-the-art tools and can detect unknown attack transactions.}
}


@inproceedings{DBLP:conf/www/NiCSCSMY25,
	author = {Congning Ni and
                  Qingxia Chen and
                  Lijun Song and
                  Patricia Commiskey and
                  Qingyuan Song and
                  Bradley A. Malin and
                  Zhijun Yin},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Catalysts of Conversation: Examining Interaction Dynamics Between
                  Topic Initiators and Commentors in Alzheimer's Disease Online Communities},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {4913--4924},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714736},
	doi = {10.1145/3696410.3714736},
	timestamp = {Fri, 09 May 2025 20:28:12 +0200},
	biburl = {https://dblp.org/rec/conf/www/NiCSCSMY25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Informal caregivers (e.g., family members or friends) of people living with Alzheimer's Disease and Related Dementias (ADRD) face substantial challenges and often seek support through online communities. Understanding the factors driving engagement within these platforms is crucial, as it can enhance communities' long-term value to meet their needs effectively. This study investigated the user interaction dynamics within two large, popular ADRD communities, TalkingPoint and ALZConnected, focusing on topic initiator engagement, initial post content, and the linguistic patterns of comments at the thread level. Using analytical methods such as propensity score matching, topic modeling, and predictive modeling, we found that active topic initiator engagement drives a higher comment volume, and reciprocal replies from topic initiators encourage further commentor engagement at the community level. Practical caregiving topics prompt more re-engagement of topic initiators, while emotional support topics attract more comments from commentors. Additionally, the linguistic complexity and emotional tone of a comment are associated with its likelihood of receiving replies from topic initiators. These findings highlight the importance of fostering active and reciprocal engagement and providing effective strategies to enhance sustainability in ADRD caregiving and broader health-related online communities.}
}


@inproceedings{DBLP:conf/www/LiCZ025,
	author = {Zihao Li and
                  Yakun Chen and
                  Tong Zhang and
                  Xianzhi Wang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Reembedding and Reweighting are Needed for Tail Item Sequential Recommendation},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {4925--4936},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714572},
	doi = {10.1145/3696410.3714572},
	timestamp = {Tue, 08 Jul 2025 09:19:45 +0200},
	biburl = {https://dblp.org/rec/conf/www/LiCZ025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Applying large vision models (LVMs) and large language models (LLMs) for item embedding is becoming cutting-edge for sequential recommendation, given their success in broad applications. Despite their advantages over traditional approaches, these models suffer more significant performance degradation on tail items against conventional ID-based solutions, which are largely overlooked by recent research. In this paper, we substantiate the above challenges as (1)  all-in ground-truth,  i.e., the standard cross-entropy (CE) loss focuses solely on the target items while treating all non-ground-truth equally, causing insufficient optimization for tail items, and (2)  knowledge transfer tax,  i.e., the knowledge encapsulated in LLMs and LVMs dominates the optimization process due to insufficient training for tail items. We propose  Rewarding and reembedding,  a simple yet efficient method to address the above challenges. Specifically, we reinitialize tail item embedding via a Gaussian distribution to alleviate knowledge transfer tax; besides, a rewarding function is incorporated in the CE loss, which adaptively adjusts item rewards during training to encourage the model to pay more attention to tail items rather than exclusively optimizing for ground-truth. Overall, our method enables a more nuanced optimization and is mathematically comparable to the direct preference optimization (DPO) in LLMs. Our extensive experiments on three public datasets show our method outperforms fourteen baselines in overall performance and improves the performance on tail items by a large margin. Our code is available at https://github.com/Yuhanleeee/R2Rec.}
}


@inproceedings{DBLP:conf/www/LuoZMPY25,
	author = {Jiayin Luo and
                  Xinkui Zhao and
                  Yuxin Ma and
                  Shengye Pang and
                  Jianwei Yin},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Mer\emph{K}ury: Adaptive Resource Allocation to Enhance the \emph{K}ubernetes
                  Performance for Large-Scale Clusters},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {4937--4948},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714844},
	doi = {10.1145/3696410.3714844},
	timestamp = {Fri, 09 May 2025 20:28:12 +0200},
	biburl = {https://dblp.org/rec/conf/www/LuoZMPY25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As a dominant paradigm in modern web applications, cloud computing has seen a surge in adoption. The deployment of vast and various workloads encapsulated within containers has become ubiquitous across cloud platforms, imposing substantial demands on the supporting infrastructure. However, Kubernetes (k8s), the de facto standard for container orchestration, struggles with low scheduling throughput and high latency in large-scale clusters. The primary challenges are identified as excessive load from read requests and resource contention between co-located components. In this paper, we present MerKury, a general and lightweight framework designed to enhance the Kubernetes performance for large-scale clusters. MerKury employs a dual strategy: first, it preprocesses specific requests to alleviate excessive load; second, it introduces an adaptive resource allocation algorithm to mitigate resource contention. Evaluations across various cluster scales demonstrate that MerKury notably augments node capacity by up to 4.5×, increases scheduling throughput by up to 7.3×, and reduces request latency by 5.6%-57.7%, outperforming vanilla Kubernetes and baseline resource allocation methods.}
}


@inproceedings{DBLP:conf/www/PenalozaGWC25,
	author = {Emiliano Penaloza and
                  Olivier Gouvert and
                  Haolun Wu and
                  Laurent Charlin},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {{TEARS:} Text Representations for Scrutable Recommendations},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {4949--4968},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714948},
	doi = {10.1145/3696410.3714948},
	timestamp = {Fri, 09 May 2025 20:28:12 +0200},
	biburl = {https://dblp.org/rec/conf/www/PenalozaGWC25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Traditional recommender systems rely on high-dimensional (latent) embeddings for modeling user-item interactions, often resulting in opaque representations that lack interpretability. Moreover, these systems offer limited control to users over their recommendations. Inspired by recent work, we introduce TExtuAl Representations for Scrutable recommendations (TEARS) to address these challenges. Instead of representing a user's interests through a latent embedding, TEARS encodes them in natural text, providing transparency and allowing users to edit them. To do so, TEARS uses a modern LLM to generate user summaries based on user preferences. Using these summaries, we take a hybrid approach where we use an optimal transport procedure to align the summaries' representation with the learned representation of a standard VAE for collaborative filtering. We find this approach can surpass the performance of popular VAE models while providing user-controllable recommendations. We also analyze the controllability of TEARS through three simulated user tasks to evaluate the effectiveness of a user editing its summary. A more detailed version of this manuscript with more experiments, baselines and detail is provided on arXiv.}
}


@inproceedings{DBLP:conf/www/HanLFTX25,
	author = {Jindong Han and
                  Hao Liu and
                  Jun Fang and
                  Naiqiang Tan and
                  Hui Xiong},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Automatic Instruction Data Selection for Large Language Models via
                  Uncertainty-Aware Influence Maximization},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {4969--4979},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714817},
	doi = {10.1145/3696410.3714817},
	timestamp = {Fri, 09 May 2025 20:28:12 +0200},
	biburl = {https://dblp.org/rec/conf/www/HanLFTX25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recent years have witnessed the prevalent integration of Large Language Models (LLMs) in various Web applications, such as search engines and recommender systems. As an emerging technique, instruction tuning aims to align pre-trained LLMs as capable chatbots that excel at following human instructions. Previous research indicates that selecting an appropriate subset of a large instruction dataset can enhance the capabilities of LLMs and reduce training costs. However, existing works tend to overlook external correlations between instruction examples during data selection process, which can introduce potential bias and lead to sub-optimal performance. To bridge this gap, we formalize this problem from graph influence maximization perspective and propose  Un certainty-aware  i nfluence  Max imization (UniMax), a data selection framework that explicitly incorporates the complex inter-dependencies within instruction data. Specifically, we first define a latent instruction graph, treating each instruction example as a graph node and representing their implicit relations as graph edges. Instead of solely relying on heuristic metrics for graph construction, we develop a self-supervised graph learner to uncover the latent structure beyond surface-level feature correlations. After that, we propose an uncertainty-aware influence function to score each example on the instruction graph, allowing a simple greedy algorithm to select a valuable subset that embodies both high influence and uncertainty with an approximation guarantee. Extensive experiments on public datasets show that the proposed approach can significantly enhance model capabilities, underscoring the importance of exploiting data dependencies in instruction data selection.}
}


@inproceedings{DBLP:conf/www/LiuDCWS25,
	author = {Zengrui Liu and
                  Jimmy Dani and
                  Yinzhi Cao and
                  Shujiang Wu and
                  Nitesh Saxena},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {The First Early Evidence of the Use of Browser Fingerprinting for
                  Online Tracking},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {4980--4995},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714548},
	doi = {10.1145/3696410.3714548},
	timestamp = {Fri, 09 May 2025 20:28:12 +0200},
	biburl = {https://dblp.org/rec/conf/www/LiuDCWS25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {While advertising has become commonplace in today\'s online interactions, there is a notable dearth of research investigating the extent to which browser fingerprinting is harnessed for user tracking and targeted advertising. Prior studies only measured whether fingerprinting-related scripts are being run on the websites but that in itself does not necessarily mean that fingerprinting is being used for the privacy-invasive purpose of online tracking because fingerprinting might be deployed for the defensive purposes of bot/fraud detection and user authentication. It is imperative to address the mounting concerns regarding the utilization of browser fingerprinting in the realm of online advertising. This paper introduces "FPTrace" (fingerprinting-based tracking assessment and comprehensive evaluation framework), a framework to assess fingerprinting-based user tracking by analyzing ad changes from browser fingerprinting adjustments. Using FPTrace, we emulate user interactions, capture ad bid data, and monitor HTTP traffic. Our large-scale study reveals strong evidence of browser fingerprinting for ad tracking and targeting, shown by bid value disparities and reduced HTTP records after fingerprinting changes. We also show fingerprinting can bypass GDPR/CCPA opt-outs, enabling privacy-invasive tracking. In conclusion, our research unveils the widespread employment of browser fingerprinting in online advertising, prompting critical considerations regarding user privacy and data security within the digital advertising landscape.}
}


@inproceedings{DBLP:conf/www/LinLC0HWL25,
	author = {Shao{-}En Lin and
                  Brian Liu and
                  Miao{-}Chen Chiang and
                  Ming{-}Yi Hong and
                  Yu{-}Shiang Huang and
                  Chuan{-}Ju Wang and
                  Che Lin},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {BETag: Behavior-enhanced Item Tagging with Finetuned Large Language
                  Models},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {4996--5009},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714769},
	doi = {10.1145/3696410.3714769},
	timestamp = {Fri, 09 May 2025 20:28:12 +0200},
	biburl = {https://dblp.org/rec/conf/www/LinLC0HWL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Tags play a critical role in enhancing product discoverability, optimizing search results, and enriching recommendation systems on e-commerce platforms. Despite the recent advancements in large language models (LLMs), which have shown proficiency in processing and understanding textual information, their application in tag generation remains an under-explored yet complex challenge. To this end, we introduce a novel method for automatic product tagging using LLMs to create behavior-enhanced tags (BETags). Specifically, our approach begins by generating base tags using an LLM. These base tags are then refined into BETags by incorporating user behavior data. This method aligns the tags with users' actual browsing and purchasing behavior, enhancing the accuracy and relevance of tags to user preferences. By personalizing the base tags with user behavior data, BETags are able to capture deeper behavioral insights, which is essential for understanding nuanced user interests and preferences in e-commerce environments. Moreover, since BETags are generated offline, they do not impose real-time computational overhead and can be seamlessly integrated into downstream tasks commonly associated with recommendation systems and search optimization. Our evaluation of BETag across three datasets--- Amazon (Scientific), MovieLens-1M, and FreshFood---shows that our approach significantly outperforms both human-annotated tags and other automated methods. These results highlight BETag as a scalable and efficient solution for personalized automated tagging, advancing e-commerce platforms by creating more tailored and engaging user experiences.}
}


@inproceedings{DBLP:conf/www/BaeJSK25,
	author = {Hong{-}Kyun Bae and
                  Hae{-}Ri Jang and
                  Won{-}Yong Shin and
                  Sang{-}Wook Kim},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Ranking Items by the Current-Preferences and Profits: {A} List-wise
                  Learning-to-Rank Approach to Profit Maximization},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {5010--5021},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714731},
	doi = {10.1145/3696410.3714731},
	timestamp = {Fri, 09 May 2025 20:28:12 +0200},
	biburl = {https://dblp.org/rec/conf/www/BaeJSK25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In e-commerce platforms,  profit-aware recommender systems  aim to  improve the platform's profits while maintaining high overall accuracy  by recommending items with high profits as top-ranked items. We explore two issues faced by existing  model-based profit-aware approaches  (i.e., MBAs) when training recommendation models for profit enhancement. First, existing MBAs tend to inaccurately infer the item ranking  without considering the user's current preference  for each item through their  profit-based weighting scheme . Second, through the  point-wise learning-to-rank  (LTR), the model is optimized solely for the preference score of each item  independently  rather than  being directly optimized for the overall ranking of items . To tackle these issues, we propose a novel MBA that involves three key steps:  (S1)  defining the  Current Preference incorporated with Profit  (i.e., CPP) for items;  (S2)  classifying items through CPP; and  (S3)  training the model by  list-wise  LTR based on CPP. Extensive experimental results using real-world platform datasets demonstrate that our approach improves accuracy by approximately 4% and profits by about 24% compared to the best-competing method.}
}


@inproceedings{DBLP:conf/www/CimaMTADC25,
	author = {Lorenzo Cima and
                  Alessio Miaschi and
                  Amaury Trujillo and
                  Marco Avvenuti and
                  Felice Dell'Orletta and
                  Stefano Cresci},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Contextualized Counterspeech: Strategies for Adaptation, Personalization,
                  and Evaluation},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {5022--5033},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714507},
	doi = {10.1145/3696410.3714507},
	timestamp = {Fri, 09 May 2025 20:28:12 +0200},
	biburl = {https://dblp.org/rec/conf/www/CimaMTADC25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {AI-generated counterspeech offers a promising and scalable strategy to curb online toxicity through direct replies that promote civil discourse. However, current counterspeech is one-size-fits-all, lacking adaptation to the moderation context and the users involved. We propose and evaluate multiple strategies for generating tailored counterspeech that is adapted to the moderation context and personalized for the moderated user. We instruct a LLaMA2-13B model to generate counterspeech, experimenting with various configurations based on different contextual information and fine-tuning strategies. We identify the configurations that generate persuasive counterspeech through a combination of quantitative indicators and human evaluations collected via a pre-registered mixed-design crowdsourcing experiment. Results show that contextualized counterspeech can significantly outperform state-of-the-art generic counterspeech in adequacy and persuasiveness, without compromising other characteristics. Our findings also reveal a poor correlation between quantitative indicators and human evaluations, suggesting that these methods assess different aspects and highlighting the need for nuanced evaluation methodologies. The effectiveness of contextualized AI-generated counterspeech and the divergence between human and algorithmic evaluations underscore the importance of increased human-AI collaboration in content moderation.}
}


@inproceedings{DBLP:conf/www/SwartHC25,
	author = {Milena de Swart and
                  Floris den Hengst and
                  Jieying Chen},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Detecting Linguistic Bias in Government Documents Using Large language
                  Models},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {5034--5044},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714526},
	doi = {10.1145/3696410.3714526},
	timestamp = {Thu, 17 Jul 2025 18:15:58 +0200},
	biburl = {https://dblp.org/rec/conf/www/SwartHC25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper addresses the critical need for detecting bias in government documents, an underexplored area with significant implications for governance. Existing methodologies often overlook the unique context and far-reaching impacts of governmental documents, potentially obscuring embedded biases that shape public policy and citizen-government interactions. To bridge this gap, we introduce the Dutch Government Data for Bias Detection (DGDB), a dataset sourced from the Dutch House of Representatives and annotated for bias by experts. We fine-tune several BERT-based models on this dataset and compare their performance with that of generative language models. Additionally, we conduct a comprehensive error analysis that includes explanations of the models' predictions. Our findings demonstrate that fine-tuned models achieve strong performance and significantly outperform generative language models, indicating the effectiveness of DGDB for bias detection. This work underscores the importance of labeled datasets for bias detection in various languages and contributes to more equitable governance practices.}
}


@inproceedings{DBLP:conf/www/DingLZLZLCLL25,
	author = {Donghui Ding and
                  Zhao Li and
                  Jiarun Zhang and
                  Xuanwu Liu and
                  Ji Zhang and
                  Yuchen Li and
                  Peng Cai and
                  JianXun Liu and
                  Guodong Long},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {eBaaS: AIoT-Enabled eBike Battery-Swap as a Service for Last-Mile
                  Delivery},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {5045--5053},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714503},
	doi = {10.1145/3696410.3714503},
	timestamp = {Wed, 04 Jun 2025 16:40:23 +0200},
	biburl = {https://dblp.org/rec/conf/www/DingLZLZLCLL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In China, the number of riders in the on-demand delivery industry has surpassed ten million. Ensuring that these riders earn a decent income can enhance their financial security, reduce poverty, and promote social equity and stability. Due to ease of use, lower-cost maintenance and environmental friendliness, electric bicycles (e-bikes) are the primary mode of transportation for delivery riders. However, these riders frequently encounter depleted batteries due to limited capacity and prolonged charging times, necessitating inconvenient swaps or recharges during deliveries. To address this issue, we propose the e-bike Battery Swap-as-a-Service (eBaaS), an innovative battery-swapping system that leverages an intelligent AIoT network for seamless battery swapping at distributed locations across urban areas. eBaaS integrates edge-cloud collaboration, battery resource allocation, battery anomaly detection, and battery range prediction to minimize downtime and reduce unnecessary mileage. While eBaaS's potential benefits are evident, there has been a lack of robust methods to quantify its impact. Thus, we further developed the eBaaS Impact Evaluation Method (EIEM), the first comprehensive model to address this gap. EIEM analyzes data from approximately 260,000 delivery riders and 5 million riding trajectories. Findings indicate that eBaaS reduces average invalid mileage by 6 km and increases the order volume by an average of over 20% daily per e-bike rider. Meanwhile, the annual electricity savings result in a reduction of 2.74 million kilograms of carbon emissions for 260,000 riders. The eBaaS system is therefore significantly beneficial for environmental conservation and sustainable urban development.}
}


@inproceedings{DBLP:conf/www/0010FG0SXYL25,
	author = {Wei Fan and
                  Jingru Fei and
                  Dingyu Guo and
                  Kun Yi and
                  Xiaozhuang Song and
                  Haolong Xiang and
                  Hangting Ye and
                  Min Li},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Towards Multi-resolution Spatiotemporal Graph Learning for Medical
                  Time Series Classification},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {5054--5064},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714514},
	doi = {10.1145/3696410.3714514},
	timestamp = {Fri, 09 May 2025 20:28:12 +0200},
	biburl = {https://dblp.org/rec/conf/www/0010FG0SXYL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Medical time series has been playing a vital role in real-world healthcare systems as valuable information in monitoring health conditions of patients. Traditional methods towards medical time series classification rely on handcrafted feature extraction and statistical methods; with the recent advancement of artificial intelligence, the machine learning and deep learning methods have become more popular. However, existing methods often fail to fully model the complex spatial dynamics under different scales, which ignore the dynamic multi-resolution spatial and temporal joint inter-dependencies. Moreover, they are less likely to consider the special baseline wander problem as well as the multi-view characteristics of medical time series, which largely hinders their prediction performance. To address these limitations, we propose a Multi-resolution Spatiotemporal Graph Learning framework,  MedGNN , for medical time series classification. Specifically, we first propose to construct multi-resolution adaptive graph structures to learn dynamic multi-scale embeddings. Then, to address the baseline wander problem, we propose Difference Attention Networks to operate self-attention mechanisms on the finite difference for temporal modeling. Moreover, to learn the multi-view characteristics, we utilize the Frequency Convolution Networks to capture complementary information of medical time series from the frequency domain. In addition, we introduce the Multi-resolution Graph Transformer architecture to model the dynamic dependencies and fuse the information from different resolutions. Finally, we have conducted extensive experiments on multiple medical real-world datasets that demonstrate the superior performance of our method. Our Code is available at this repository: https://github.com/aikunyi/MedGNN.}
}


@inproceedings{DBLP:conf/www/FangDDNLF025,
	author = {Kai Fang and
                  Jiangtao Deng and
                  Chengzu Dong and
                  Usman Naseem and
                  Tongcun Liu and
                  Hailin Feng and
                  Wei Wang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {MoCFL: Mobile Cluster Federated Learning Framework for Highly Dynamic
                  Network},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {5065--5074},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714515},
	doi = {10.1145/3696410.3714515},
	timestamp = {Thu, 01 May 2025 20:27:22 +0200},
	biburl = {https://dblp.org/rec/conf/www/FangDDNLF025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Frequent fluctuations of client nodes in highly dynamic mobile clusters can lead to significant changes in feature space distribution and data drift, posing substantial challenges to the robustness of existing federated learning (FL) strategies. To address these issues, we proposed a mobile cluster federated learning framework (MoCFL). MoCFL enhances feature aggregation by introducing an affinity matrix that quantifies the similarity between local feature extractors from different clients, addressing dynamic data distribution changes caused by frequent client churn and topology changes. Additionally, MoCFL integrates historical and current feature information when training the global classifier, effectively mitigating the catastrophic forgetting problem frequently encountered in mobile scenarios. This synergistic combination ensures that MoCFL maintains high performance and stability in dynamically changing mobile environments. Experimental results on the UNSW-NB15 dataset show that MoCFL excels in dynamic environments, demonstrating superior robustness and accuracy while maintaining reasonable training costs.}
}


@inproceedings{DBLP:conf/www/GaoCYHY025,
	author = {Chongming Gao and
                  Ruijun Chen and
                  Shuai Yuan and
                  Kexin Huang and
                  Yuanqing Yu and
                  Xiangnan He},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {SPRec: Self-Play to Debias LLM-based Recommendation},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {5075--5084},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714524},
	doi = {10.1145/3696410.3714524},
	timestamp = {Fri, 09 May 2025 20:28:12 +0200},
	biburl = {https://dblp.org/rec/conf/www/GaoCYHY025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Large language models (LLMs) have attracted significant attention in recommendation systems. Current work primarily applies supervised fine-tuning (SFT) to adapt the model for recommendation tasks. However, SFT on positive examples only limits the model's ability to align with user preference. To address this, researchers recently introduced Direct Preference Optimization (DPO), which explicitly aligns LLMs with user preferences using offline preference ranking data. However, we found that DPO inherently biases the model towards a few items, exacerbating the filter bubble issue and ultimately degrading user experience. In this paper, we propose SPRec, a novel self-play framework designed to mitigate over-recommendation and improve fairness without requiring additional data or manual intervention. In each self-play iteration, the model undergoes an SFT step followed by a DPO step, treating offline interaction data as positive samples and the predicted outputs from the previous iteration as negative samples. This effectively re-weights the DPO loss function using the model's logits, adaptively suppressing biased items. Extensive experiments on multiple real-world datasets demonstrate SPRec's effectiveness in enhancing recommendation accuracy and fairness.}
}


@inproceedings{DBLP:conf/www/GeisslerMF25,
	author = {Dominique Geissler and
                  Abdurahman Maarouf and
                  Stefan Feuerriegel},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Analyzing User Characteristics of Hate Speech Spreaders on Social
                  Media},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {5085--5095},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714502},
	doi = {10.1145/3696410.3714502},
	timestamp = {Fri, 09 May 2025 20:28:12 +0200},
	biburl = {https://dblp.org/rec/conf/www/GeisslerMF25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Hate speech on social media threatens the mental and physical well-being of individuals and contributes to real-world violence. Resharing is an important driver behind the spread of hate speech on social media. Yet, little is known about who reshares hate speech and what their characteristics are. In this paper, we analyze the role of user characteristics in hate speech resharing across different types of hate speech (e.g., political hate). For this, we first cluster hate speech posts using large language models into different types of hate speech. Then we model the effects of user attributes on users' probability to reshare hate speech using an explainable machine learning model. To do so, we apply debiasing to control for selection bias in our observational social media data and further control for the latent vulnerability of users to hate speech. We find that, all else equal, users with fewer followers, fewer friends, fewer posts, and older accounts share more hate speech. This shows that users with little social influence tend to share more hate speech. Further, we find substantial heterogeneity across different types of hate speech. For example, racist and misogynistic hate is spread mostly by users with little social influence. In contrast, political anti-Trump and anti-right-wing hate is reshared by users with larger social influence. Overall, understanding the factors that drive users to share hate speech is crucial for detecting individuals at risk of engaging in harmful behavior and for designing effective mitigation strategies.  Disclaimer : This work contains terms that are offensive and hateful.}
}


@inproceedings{DBLP:conf/www/0014P0SWGWSJLB25,
	author = {Ming Gu and
                  Lei Pei and
                  Sheng Zhou and
                  Ming Shen and
                  Yuxuan Wu and
                  Zirui Gao and
                  Ziwei Wang and
                  Shuo Shan and
                  Wei Jiang and
                  Yong Li and
                  Jiajun Bu},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Towards an Inclusive Mobile Web: {A} Dataset and Framework for Focusability
                  in {UI} Accessibility},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {5096--5107},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714523},
	doi = {10.1145/3696410.3714523},
	timestamp = {Fri, 09 May 2025 20:28:12 +0200},
	biburl = {https://dblp.org/rec/conf/www/0014P0SWGWSJLB25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The rapid growth of mobile web technologies has revolutionized how people manage daily activities, emphasizing the critical need for accessible mobile user interfaces (UIs) that accommodate users with disabilities and situational impairments. Current AI-driven UI understanding methods show promise but primarily target general UI modeling, neglecting nuanced, user-centric accessibility requirements. To bridge this gap, we first conducted a formative study with 12 visually impaired participants. Our study uncovers selective-accessible issues, a new class of accessibility challenges requiring finer granularity and selective focus on UI components, which existing methods largely overlook. Our findings also reveal that the severity of issues varies across interaction stages, with earlier stages posing a more significant impact. Building on these insights, we propose a comprehensive framework of three accessibility stages: focusability, information, and functionality (FIF), encompassing 12 sub-tasks under 3 overarching tasks. Identifying UI element focusability prediction (UFP) as a pivotal yet underexplored task within FIF, hindered by the absence of dedicated datasets, we introduce a new dataset (NOS) with 117,480 annotated components addressing accessibility issues comprehensively. To further enhance UFP, we introduce Graph-based UI Focusability Prediction (GIFT), a method leveraging graph neural networks to model UFP-targeted UI relationships. User studies validate the dataset's quality, while experiments show GIFT's effectiveness in improving UFP outcomes. Our code and datasets are publicly available to support further web inclusivity advancements at https://github.com/eaglelab-zju/NOS.}
}


@inproceedings{DBLP:conf/www/GuoQXH00025,
	author = {Teng Guo and
                  Yu Qin and
                  Yubin Xia and
                  Mingliang Hou and
                  Zitao Liu and
                  Feng Xia and
                  Weiqi Luo},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Enhancing Knowledge Tracing through Decoupling Cognitive Pattern from
                  Error-Prone Data},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {5108--5116},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714486},
	doi = {10.1145/3696410.3714486},
	timestamp = {Fri, 09 May 2025 20:28:12 +0200},
	biburl = {https://dblp.org/rec/conf/www/GuoQXH00025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Knowledge tracing (KT) aims to predict students' future performance based on their past learning activities. However, no one is perfect. Factors such as carelessness, fatigue, and stress often cause students to make mistakes on problems they have already mastered, leading to anomalies in their historical learning data. These anomalies disrupt inherent patterns in the data, misleading the KT model. Extracting cognitive patterns that accurately reflect students' knowledge mastery from such error-prone data remains a significant challenge. Against this background, this paper proposes a novel KT method named RoubstKT, inspired by educational measurement theory and frequency-based decomposition. A cognitive decoupling analyzer is proposed to decouple the student's cognitive pattern and random factors from the data through smoothing and subtraction operations, then recombine them using a gating mechanism or adaptive parameter fusion strategy. To more effectively diagnose students' knowledge mastery, we employ a decay-based attention mechanism that focuses on random behaviors at adjacent time steps. We conducted comprehensive experiments based on real-world datasets and targeted datasets with added random noise. The experimental results demonstrated the effectiveness of the proposed method.}
}


@inproceedings{DBLP:conf/www/0002ZCO25,
	author = {Muhammad Imran and
                  Abdul Wahab Ziaullah and
                  Kai Chen and
                  Ferda Ofli},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Evaluating Robustness of LLMs on Crisis-Related Microblogs across
                  Events, Information Types, and Linguistic Features},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {5117--5126},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714511},
	doi = {10.1145/3696410.3714511},
	timestamp = {Fri, 09 May 2025 20:28:12 +0200},
	biburl = {https://dblp.org/rec/conf/www/0002ZCO25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The widespread use of microblogging platforms like X (formerly Twitter) during disasters provides real-time information to governments and response authorities. However, the data from these platforms is often noisy, requiring automated methods to filter relevant information. Traditionally, supervised machine learning models have been used, but they lack generalizability. In contrast, Large Language Models (LLMs) show better capabilities in understanding and processing natural language out of the box. This paper provides a detailed analysis of the performance of six well-known LLMs in processing disaster-related social media data from a large-set of real-world events. Our findings indicate that while LLMs, particularly GPT-4o and GPT-4, offer better generalizability across different disasters and information types, most LLMs face challenges in processing flood-related data, show minimal improvement despite the provision of examples (i.e., shots), and struggle to identify critical information categories like urgent requests and needs. Additionally, we examine how various linguistic features affect model performance and highlight LLMs' vulnerabilities against certain features like typos. Lastly, we provide benchmarking results for all events across both zero- and few-shot settings and observe that proprietary models outperform open-source ones in all tasks.}
}


@inproceedings{DBLP:conf/www/KheyaBA25,
	author = {Tahsin Alamgir Kheya and
                  Mohamed Reda Bouadjenek and
                  Sunil Aryal},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Unmasking Gender Bias in Recommendation Systems and Enhancing Category-Aware
                  Fairness},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {5127--5138},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714528},
	doi = {10.1145/3696410.3714528},
	timestamp = {Thu, 01 May 2025 20:27:23 +0200},
	biburl = {https://dblp.org/rec/conf/www/KheyaBA25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recommendation systems are now an integral part of our daily lives. We rely on them for tasks such as discovering new movies, finding friends on social media, and connecting job seekers with relevant opportunities. Given their vital role, we must ensure these recommendations are free from societal stereotypes. Therefore, evaluating and addressing such biases in recommendation systems is crucial. Previous work evaluating the fairness of recommended items fails to capture certain nuances as they mainly focus on comparing performance metrics for different sensitive groups. In this paper, we introduce a set of comprehensive metrics for quantifying gender bias in recommendations. Specifically, we show the importance of evaluating fairness on a more granular level, which can be achieved using our metrics to capture gender bias using categories of recommended items like genres for movies. Furthermore, we show that employing a category-aware fairness metric as a regularization term along with the main recommendation loss during training can help effectively minimize bias in the models' output. We experiment on three real-world datasets, using five baseline models alongside two popular fairness-aware models, to show the effectiveness of our metrics in evaluating gender bias. Our metrics help provide an enhanced insight into bias in recommended items compared to previous metrics. Additionally, our results demonstrate how incorporating our regularization term significantly improves the fairness in recommendations for different categories without substantial degradation in overall recommendation performance.}
}


@inproceedings{DBLP:conf/www/LiuLLYZ025,
	author = {Yifan Liu and
                  Yaokun Liu and
                  Zelin Li and
                  Ruichen Yao and
                  Yang Zhang and
                  Dong Wang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Modality Interactive Mixture-of-Experts for Fake News Detection},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {5139--5150},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714522},
	doi = {10.1145/3696410.3714522},
	timestamp = {Tue, 13 May 2025 07:31:05 +0200},
	biburl = {https://dblp.org/rec/conf/www/LiuLLYZ025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The proliferation of fake news on social media platforms disproportionately impacts vulnerable populations, eroding trust, exacerbating inequality, and amplifying harmful narratives. Detecting fake news in multimodal contexts-where deceptive content combines text and images-is particularly challenging due to the nuanced interplay between modalities. Existing multimodal fake news detection methods often emphasize cross-modal consistency but ignore the complex interactions between text and visual elements, which may complement, contradict, or independently influence the predicted veracity of a post. To address these challenges, we present  M odality  I nteractive  M ixture- o f- E xperts for  F ake  N ews  D etection ( MIMoE-FND ), a novel hierarchical Mixture-of-Expert framework designed to enhance multimodal fake news detection by explicitly modeling modality interactions through an interaction gating mechanism. Our approach models modality interactions by evaluating two key aspects of modality interactions: unimodal prediction agreement and semantic alignment. The hierarchical structure of MIMoE-FND allows for distinct learning pathways tailored to different fusion scenarios, adapting to the unique characteristics of each modality interaction. By tailoring fusion strategies to diverse modality interaction scenarios, MIMoE-FND provides a more robust and nuanced approach to multimodal fake news detection. We evaluate our approach on three real-world benchmarks spanning two languages, demonstrating its superior performance compared to state-of-the-art methods. By enhancing the accuracy and interpretability of fake news detection, MIMoE-FND offers a promising tool to mitigate the spread of misinformation, with potential to better safeguard vulnerable communities against its harmful effects.}
}


@inproceedings{DBLP:conf/www/LiuRCHZZ25,
	author = {Xin Liu and
                  Haojun Rui and
                  Dawei Cheng and
                  Li Han and
                  Zhongyun Zhou and
                  Guoping Zhao},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Multi-Granularity Augmented Graph Learning for Spoofing Transaction
                  Detection},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {5151--5160},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714521},
	doi = {10.1145/3696410.3714521},
	timestamp = {Tue, 13 May 2025 07:31:04 +0200},
	biburl = {https://dblp.org/rec/conf/www/LiuRCHZZ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Spoofing is a deceptive trading strategy where fraudsters place a large number of fake orders to manipulate market prices, severely distorting market fairness and threatening market stability. With the advancement of fraudulent tactics, spoofing patterns span across various levels of interaction, involving not only the local structure of individual spoofing transactions but also spoofing groups and global patterns. Relying solely on local context makes it challenging to capture multi-granularity risk signals, especially for organized and covert spoofing.Additionally, existing methods fail to consider the differences and relative importance between features of varying granularity, leading to feature distortion and noise. Therefore, we propose a multi-granularity augmented graph learning method that differentially captures fraud signals at local, group, and global levels. It utilizes multi-hop differential aggregation and community-augmented strategy to capture information from local to global perspectives, adaptively distinguishing the contributions of different granularity. To avoid excessive fusion of multi-granularity information, we combine contrastive loss and cross-entropy loss for joint optimization, preserving key features while enhancing the method's robustness and accuracy. Extensive experiments on real-world datasets demonstrate the effectiveness of our proposed approach in spoofing detection, providing a robust solution for regulatory agencies. Our work will help financial institutions enhance their regulatory capabilities, protect investors' interests, and promote the healthy development of financial markets.}
}


@inproceedings{DBLP:conf/www/LiZLP0SGH25,
	author = {Yishuo Li and
                  Qi Zhang and
                  Wenpeng Lu and
                  Xueping Peng and
                  Weiyu Zhang and
                  Jiasheng Si and
                  Yongshun Gong and
                  Liang Hu},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Time-aware Medication Recommendation via Intervention of Dynamic Treatment
                  Regimes},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {5161--5172},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714533},
	doi = {10.1145/3696410.3714533},
	timestamp = {Fri, 09 May 2025 20:28:12 +0200},
	biburl = {https://dblp.org/rec/conf/www/LiZLP0SGH25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Medication recommendation aims to suggest personalized drug combinations to patients based on their longitudinal medical histories stored in electronic health record (EHR) datasets. Patients' Dynamic Treatment Regimes (DTRs) determine how patients' drug combinations change along with the evolution of disease treatment. DTRs are effective for comprehending disease-treatment dynamics and for recommending a timely and personalized combination of medications for patients. However, existing medication recommender systems (MRSs) overlook the multiple treatment pathways generated by the intervention of DTRs and can only recommend a single treatment paradigm, ignoring the fact that patients may be at different treatment stages and thus require different treatment regime. Such disregard leads to a significant limitation in recommending personalized medication combinations tailored to different treatment stages, yielding greatly compromised accuracy and applicability of MRSs. Moreover, existing methods often overlook the time interval information over patients' successive visits, which is critical to indicate patients' treatment evolution. To address these significant gaps, we propose a Time-aware Medication Recommendation Framework via Intervention of Dynamic Treatment Regimes, called MR-DTR. To explicitly illustrate the intervention processes of DTRs on similar patients, we employ a co-guided graph to connect various patient sequences. In addition, to fully utilize the time interval information, we design a time-aware guidance mechanism dedicated to the co-guided graph to efficiently learn medication representation using the patient's guidance information. We also introduce relative time intervals in the encoder to act as positional information. Extensive experiments on two real-world datasets demonstrate that MR-DTR surpasses state-of-the-art models in terms of recommendation performance. Our code is available at: https://github.com/liyifo/MR-DTR.}
}


@inproceedings{DBLP:conf/www/LongY00025,
	author = {Ting Long and
                  Li'ang Yin and
                  Yi Chang and
                  Wei Xia and
                  Yong Yu},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Simulating Question-answering Correctness with a Conditional Diffusion},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {5173--5182},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714508},
	doi = {10.1145/3696410.3714508},
	timestamp = {Fri, 09 May 2025 20:28:12 +0200},
	biburl = {https://dblp.org/rec/conf/www/LongY00025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A question-answering (QA) simulator is a model that simulates human students QA behaviors. By leveraging QA history to estimate the probability of correctly answering a newly recommended question, the simulator enables the educational recommender systems to be trained in a simulated environment, protecting human students from the potential negative impact of low-quality recommendations. Despite its significant importance, the construction of QA simulators has not been thoroughly explored in the research domain of AI. Previous methods mainly rely on existing knowledge tracing (KT) models to construct such a simulator. However, due to the discrepancy between the KT task and the simulation task, those KT-based simulators suffer from severe bias accumulation, which limits the effectiveness of the simulation. In this paper, we propose a method called Diffusion-based Simulator (DSim), which takes advantage of diffusion to alleviate the bias accumulation. To our knowledge, DSim is the first to focus on building a QA simulator.}
}


@inproceedings{DBLP:conf/www/LyuZYW0WL0Z25,
	author = {Wenjun Lyu and
                  Shuxin Zhong and
                  Guang Yang and
                  Haotian Wang and
                  Yi Ding and
                  Shuai Wang and
                  Yunhuai Liu and
                  Tian He and
                  Desheng Zhang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {InCo: Exploring Inter-Trip Cooperation for Efficient Last-mile Delivery},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {5183--5191},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714483},
	doi = {10.1145/3696410.3714483},
	timestamp = {Fri, 09 May 2025 20:28:12 +0200},
	biburl = {https://dblp.org/rec/conf/www/LyuZYW0WL0Z25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {An efficient last-mile delivery scheme in logistics benefits customers, couriers, and the platform. In practice, the delivery scope of a delivery station is divided into multiple areas, each of which is covered by a courier. The long distances between the delivery station and areas limit the couriers' delivery efficiency given that they need to travel back and forth multiple times a day. To solve this problem, we explore an inter-trip cooperation scheme for last-mile delivery, in which couriers traveling to the delivery station and back to corresponding areas earlier can help to take others' orders back. Coordinating the courier cooperation is challenging because we need to consider the courier's status, e.g., locations, and vehicle capacity constraint simultaneously. In this work, we design an inter-trip cooperation-based last-mile delivery system, InCo, aiming to minimize the average order delivery time. InCo includes two components: i) a time-aware spanning tree algorithm to generate the cooperation result for a group of couriers; and ii) a capacity-constrained courier grouping algorithm to optimize the courier grouping result iteratively. Extensive evaluation results with real-world order data collected from one of the largest logistics companies show that InCo improves the average saved delivery time and reduces average travel time by up to 80.2% and 28.4%, respectively, compared to baseline methods. The deployment results show InCo improves the average courier working efficiency by 21.6% to the state-of-the-practice.}
}


@inproceedings{DBLP:conf/www/Naseem0ZWJ25,
	author = {Usman Naseem and
                  Liang Hu and
                  Qi Zhang and
                  Shoujin Wang and
                  Shoaib Jameel},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {DiGrI: Distorted Greedy Approach for Human-Assisted Online Suicide
                  Ideation Detection},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {5192--5201},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714529},
	doi = {10.1145/3696410.3714529},
	timestamp = {Fri, 09 May 2025 20:28:12 +0200},
	biburl = {https://dblp.org/rec/conf/www/Naseem0ZWJ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {User-generated content on social media platforms provides a valuable resource for developing automated computational methods to detect mental health issues online leading to suicidal thoughts automatically. Although current fully automated methods show promise, they may produce uncertain predictions, leading to flawed conclusions. To address this, we propose a novel model called DiGrI, or Distorted Greedy Approach for Human-Assisted Online Suicide Ideation Detection, which reformulates suicide ideation assessment as a selective, prioritized prediction problem. The model incorporates a novel multi-classifier distorted greedy model that is optimized to operate under various levels of automation and abstains from making uncertain predictions with theoretical guarantees. Our results show that DiGrI outperforms strong comparative models including large language models in detecting mental health issues on a publicly available Reddit dataset. We discuss the empirical and practical implications, including the ethical considerations of using DiGrI for online automatic suicide ideation detection involving humans, if it were to be translated for use in clinical and public health practice.}
}


@inproceedings{DBLP:conf/www/PiaoLGL25,
	author = {Jinghua Piao and
                  Zhihong Lu and
                  Chen Gao and
                  Yong Li},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Social Bots Meet Large Language Model: Political Bias and Social Learning
                  Inspired Mitigation Strategies},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {5202--5211},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714537},
	doi = {10.1145/3696410.3714537},
	timestamp = {Fri, 09 May 2025 20:28:12 +0200},
	biburl = {https://dblp.org/rec/conf/www/PiaoLGL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recent advances in the large language models (LLM) have empowered traditional bots to gain human-level intelligence and exhibit human-like social behaviors, giving rise to a new form of LLM-driven social agents. However, the inherent limitations in LLMs could potentially result in politically biased behaviors of these agents, posing unexpected risks to human society. While great efforts have been made to examine political bias and related concerns in traditional bots and LLMs, little is known about the existence, unique characteristics, underlying origins, and potential mitigation strategies of this bias in LLM-driven social agents. To address this gap, we systematically assess political bias in LLM-driven social agents, by examining how it emerges as these agents self-reflect, communicate, and understand others during social interactions. Through designing and implementing social experiments, we discover that this bias consistently manifests in the social behaviors of agents driven by diverse LLMs, across nine key political topics. Inspired by the social learning theory, we propose to mitigate political bias by guiding these agents to emulate how humans learn to behave. By incorporating self-regulated and role-model learning processes, we reduce their political bias by 4.89% to 51.26% across diverse LLMs and topics, demonstrating the effectiveness and generalizability of the proposed strategy. This study not only advances the understanding of political bias in emerging LLM-driven agents, but also offers insights into harnessing social bots for social good.}
}


@inproceedings{DBLP:conf/www/ShenDSLZ25,
	author = {Xin Shen and
                  Heming Du and
                  Hongwei Sheng and
                  Lincheng Li and
                  Kaihao Zhang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {AuslanWeb: {A} Scalable Web-Based Australian Sign Language Communication
                  System for Deaf and Hearing Individuals},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {5212--5223},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714525},
	doi = {10.1145/3696410.3714525},
	timestamp = {Fri, 09 May 2025 20:28:12 +0200},
	biburl = {https://dblp.org/rec/conf/www/ShenDSLZ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Effective communication between the deaf community and hearing individuals facilitates social inclusion, equal opportunities, and the dignity of vulnerable populations. However, existing region-specific sign language systems are constrained by limited training datasets and narrow topic domains, rendering them ineffective for bridging the linguistic gaps between sign languages and spoken languages. Auslan, as the sign language specific to Australia, still lacks a reliable bidirectional translation tool for effective communication. To address these challenges, we propose AuslanWeb, a web-based system for bidirectional translation of both isolated and successive sign language. For the former, AuslanWeb achieves high-precision mapping between isolated signs (glosses) and spoken language words or phrases through a multimodal recognition system and a versatile Auslan dictionary. For the latter, it leverages the advanced contextual understanding and text generation capabilities of Large Language Models (LLMs) to support bidirectional translation between successive sign language videos and long-form spoken language. By integrating linguistic structure with advanced AI capabilities, AuslanWeb overcomes the limitations of dataset dependency and enhances the scalability of sign language translation systems. The effectiveness of the system is further validated through user feedback, receiving consistent praise from Auslan experts, Australian deaf individuals, and volunteers. The demo video of AuslanWeb is provided here.}
}


@inproceedings{DBLP:conf/www/SunSUR25,
	author = {Jinglin Sun and
                  Basem Suleiman and
                  Imdad Ullah and
                  Imran Razzak},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Effectiveness of Privacy-preserving Algorithms in LLMs: {A} Benchmark
                  and Empirical Analysis},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {5224--5233},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714531},
	doi = {10.1145/3696410.3714531},
	timestamp = {Thu, 01 May 2025 20:27:25 +0200},
	biburl = {https://dblp.org/rec/conf/www/SunSUR25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Preserving individual privacy is crucial when interacting with Large Language Models (LLMs) during both training and inference stages. Privacy leakage at either stage can lead to irreversible negative consequences. Although data-level privacy-preserving algorithms have been developed for smaller Natural Language Processing (NLP) models, their application to LLMs has not been extensively explored. Moreover, with plenty of algorithms emerging, it brings challenges for organizations or researchers to compare and evaluate these different algorithms to select the most suitable one for their certain requirements. To address these challenges, we introduce ''Privacy-preserving4LLM Benchmarking'', a systematic evaluation framework that systematically assesses different privacy-preserving algorithms' utility-privacy trade-offs across different LLM architectures. Our framework evaluates these algorithms in three practical scenarios: protecting training data only, user queries only, and both. We also introduce a novel Parameter Optimizer to ensure fair comparisons. To quantify privacy protection levels, we use exposure metrics, where canary data sequences are intentionally inserted into training data to measure information memorization and potential leakage. Our study presents a comprehensive empirical analysis comparing three privacy-preserving algorithms across three LLM architectures (Mistral-7B, Llama2-7b, Falcon-7b) using three different datasets. Our findings reveal that algorithm selection, protection scenarios, LLM architectures, and privacy budget settings all impact the utility and privacy level.}
}


@inproceedings{DBLP:conf/www/TangWCZJ25,
	author = {Jiehao Tang and
                  Wenjun Wang and
                  Dawei Cheng and
                  Hui Zhao and
                  Changjun Jiang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Dual Pairwise Pre-training and Prompt-tuning with Aligned Prototypes
                  for Interbank Credit Rating},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {5234--5243},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714530},
	doi = {10.1145/3696410.3714530},
	timestamp = {Fri, 09 May 2025 20:28:12 +0200},
	biburl = {https://dblp.org/rec/conf/www/TangWCZJ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the global financial market, assessing bank credit ratings is essential for evaluating financial health, managing risk, and safeguarding systemic stability. While risk can transmit rapidly within the interbank lending network, timely incorporation of the latest financial disclosures to update bank ratings is vital in the swiftly evolving financial markets. However, existing approaches primarily conduct credit rating tasks using end-to-end models trained on historical financial data, thereby overlooking the staggered timing of financial disclosure from banks. Limited excavation of the credit rating records and the temporal distribution shifts existed in different financial periods still pose challenges to improving the accuracy of the credit rating tasks. To address these challenges, in this work we propose a Dual Pairwise pre-training and prompt Tuning framework with Aligned Prototypes (DPTAP) for interbank credit rating, which enables dynamic credit updates. Specifically, the dual pairwise pre-training strategy allows the framework to capture direction and distance discrepancies between rating categories. To alleviate the adverse impact of temporal distribution shifts in quarters, the latest financial features are prompted to dynamically map the patterns of the corresponding banks in the last quarter. Furthermore, we integrate rating guides from two consecutive quarters into a set of aligned prototypes to enhance supervision during the prompt tuning process. We conducted extensive experiments on a real-world bank dataset globally in the latest 8 years. The results demonstrate the superiority of our proposed framework over various competitive models, highlighting its notable capabilities in early warning and risk contagion forecasting.}
}


@inproceedings{DBLP:conf/www/TianBBDR25,
	author = {Lin Tian and
                  Emily Booth and
                  Francesco Bailo and
                  Julian Droogan and
                  Marian{-}Andrei Rizoiu},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Before It's Too Late: {A} State Space Model for the Early Prediction
                  of Misinformation and Disinformation Engagement},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {5244--5254},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714527},
	doi = {10.1145/3696410.3714527},
	timestamp = {Fri, 09 May 2025 20:28:12 +0200},
	biburl = {https://dblp.org/rec/conf/www/TianBBDR25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In today's digital age, conspiracies and information campaigns can emerge rapidly and erode social and democratic cohesion. While recent deep learning approaches have made progress in modeling engagement through language and propagation models, they struggle with irregularly sampled data and early trajectory assessment. We present IC-Mamba, a novel state space model that forecasts social media engagement by modeling interval-censored data with integrated temporal embeddings. Our model excels at predicting engagement patterns within the crucial first 15-30 minutes of posting (RMSE 0.118-0.143), enabling rapid assessment of content reach. By incorporating interval-censored modeling into the state space framework, IC-Mamba captures fine-grained temporal dynamics of engagement growth, achieving a 4.72% improvement over state-of-the-art across multiple engagement metrics (likes, shares, comments, and emojis). Our experiments demonstrate IC-Mamba's effectiveness in forecasting both post-level dynamics and broader narrative patterns (F1 0.508-0.751 for narrative-level predictions). The model maintains strong predictive performance across extended time horizons, successfully forecasting opinion-level engagement up to 28 days ahead using observation windows of 3-10 days. These capabilities enable earlier identification of potentially problematic content, providing crucial lead time for designing and implementing countermeasures. Code is available at: https://github.com/ltian678/ic-mamba. An interactive dashboard demonstrating our results is available at: https://ic-mamba.behavioral-ds.science/.}
}


@inproceedings{DBLP:conf/www/WangTL25,
	author = {Han Wang and
                  Rui Yang Tan and
                  Roy Ka{-}Wei Lee},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Cross-Modal Transfer from Memes to Videos: Addressing Data Scarcity
                  in Hateful Video Detection},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {5255--5263},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714534},
	doi = {10.1145/3696410.3714534},
	timestamp = {Thu, 01 May 2025 20:27:26 +0200},
	biburl = {https://dblp.org/rec/conf/www/WangTL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Detecting hate speech in online content is essential to ensuring safer digital spaces. While significant progress has been made in text and meme modalities, video-based hate speech detection remains under-explored, hindered by a lack of annotated datasets and the high cost of video annotation. This gap is particularly problematic given the growing reliance on large models, which demand substantial amounts of training data. To address this challenge, we leverage meme datasets as both a substitution and an augmentation strategy for training hateful video detection models. Our approach introduces a human-assisted reannotation pipeline to align meme dataset labels with video datasets, ensuring consistency with minimal labeling effort. Using two state-of-the-art vision-language models, we demonstrate that meme data can substitute for video data in resource-scarce scenarios and augment video datasets to achieve further performance gains. Our results consistently outperform state-of-the-art benchmarks, showcasing the potential of cross-modal transfer learning for advancing hateful video detection. Dataset and code are available at (https://github.com/Social-AI-Studio/CrossModalTransferLearning).}
}


@inproceedings{DBLP:conf/www/0011LC0025,
	author = {Wei Wu and
                  Shiqi Li and
                  Ling Chen and
                  Fangfang Li and
                  Chuan Luo},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Sketching Very Large-scale Dynamic Attributed Networks More Practically},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {5264--5274},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714519},
	doi = {10.1145/3696410.3714519},
	timestamp = {Fri, 09 May 2025 20:28:12 +0200},
	biburl = {https://dblp.org/rec/conf/www/0011LC0025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Real-world networks, particularly those in web and social media, are dynamic with evolving node attributes and structures, often involving billions of nodes and edges. Dynamic attributed network embedding is a powerful tool for capturing these changes, enabling data owners and problem owners to better understand interactions and trends for more effective engagement and decision-making. While some existing algorithms are capable of handling very large-scale dynamic attributed networks with billions of nodes and edges, they often suffer from accuracy loss or high computational overhead. In this paper, we propose a practical and sustainable framework of sketching very large-scale dynamic attributed networks called VLS 2 ketch, which incorporates incremental embedding updates alongside storage-efficient, binarized representation of both node attributes and topological variations. By the sparse random projection technique in an incremental update manner, VLS 2 ketch significantly reduces the energy-intensive computational workload while maintaining accuracy. Also, we introduce an information decay mechanism, which adapts to temporally varying topologies and node attributes. This mechanism ensures that outdated information gradually diminishes over time. Extensive experiments on real-world very large-scale datasets demonstrate that our proposed VLS 2 ketch method delivers comparable embedding quality against the state-of-the-art learning-based competitors with dramatically reduced runtime. We have released the source code and the datasets in https://github.com/AIandBD/graph-hashing/tree/main/VLS2ketch. .}
}


@inproceedings{DBLP:conf/www/XiangJCCZJ25,
	author = {Sheng Xiang and
                  Yidong Jiang and
                  Yunting Chen and
                  Dawei Cheng and
                  Guoping Zhao and
                  Changjun Jiang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Generative Dynamic Graph Representation Learning for Conspiracy Spoofing
                  Detection},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {5275--5284},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714518},
	doi = {10.1145/3696410.3714518},
	timestamp = {Fri, 09 May 2025 20:28:12 +0200},
	biburl = {https://dblp.org/rec/conf/www/XiangJCCZJ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Spoofing detection in financial trading is crucial, especially for identifying complex behaviors such as conspiracy spoofing. Traditional machine-learning approaches primarily focus on isolated node features, often overlooking the broader context of interconnected nodes. Graph-based techniques, particularly Graph Neural Networks (GNNs), have advanced the field by leveraging relational information effectively. However, in real-world spoofing detection datasets, trading behaviors exhibit dynamic, irregular patterns. Existing spoofing detection methods, though effective in some scenarios, struggle to capture the complexity of dynamic and diverse, evolving inter-node relationships. To address these challenges, we propose a novel framework called the Generative Dynamic Graph Model (GDGM), which models dynamic trading behaviors and the relationships among nodes to learn representations for conspiracy spoofing detection. Specifically, our approach incorporates the generative dynamic latent space to capture the temporal patterns and evolving market conditions. Raw trading data is first converted into time-stamped sequences. Then we model trading behaviors using the neural ordinary differential equations and gated recurrent units, to generate the representation incorporating temporal dynamics of spoofing patterns. Furthermore, pseudo-label generation and heterogeneous aggregation techniques are employed to gather relevant information and enhance the detection performance for conspiratorial spoofing behaviors. Experiments conducted on spoofing detection datasets demonstrate that our approach outperforms state-of-the-art models in detection accuracy. Additionally, our spoofing detection system has been successfully deployed in one of the largest global trading markets, further validating the practical applicability and performance of the proposed method.}
}


@inproceedings{DBLP:conf/www/XuDLZ0025,
	author = {Qingzheng Xu and
                  Heming Du and
                  Szymon Lukasik and
                  Tianqing Zhu and
                  Sen Wang and
                  Xin Yu},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {MDAM\({}^{\mbox{3}}\): {A} Misinformation Detection and Analysis Framework
                  for Multitype Multimodal Media},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {5285--5296},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714498},
	doi = {10.1145/3696410.3714498},
	timestamp = {Fri, 09 May 2025 20:28:12 +0200},
	biburl = {https://dblp.org/rec/conf/www/XuDLZ0025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Misinformation is a significant societal issue with potentially severe consequences. It appears in text, image, audio, and video modalities, encompassing various categories such as unimodal deception (fact-conflicting, AI-generated & offensive content) and cross-modal inconsistencies. However, current detection approaches often focus on text and image, overlooking the growing prevalence of misinformation in audio and video content. Moreover, these methods typically tend to address only one or two types of misinformation, failing to address all categories simultaneously. These detectors are also usually designed to make judgments without providing explanations, reducing transparency and limiting their broader applicability. To address these issues, we propose  MDAM 3 , a Misinformation Detection and Analysis Framework for Multitype Multimodal Media.  MDAM 3  analyzes each input in internal detection and examines relationships across modalities to identify inconsistencies. It utilizes web resources and integrates Large Vision-Language Models (LVLMs) to deliver accurate detection results along with detailed analysis. To evaluate  MDAM 3 , we curate  MDAM 3 -DB , a specialized multitype multimodal misinformation dataset. A user study is conducted to explore MDAM 3 's usability, interpretability, and effectiveness. We hope this research contributes to advancing misinformation detection methodologies and provides valuable insights for developing robust multimodal analysis tools.}
}


@inproceedings{DBLP:conf/www/Yang00WWL25,
	author = {Xuankai Yang and
                  Yan Wang and
                  Xiuzhen Zhang and
                  Shoujin Wang and
                  Huaxiong Wang and
                  Kwok{-}Yan Lam},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {A Macro- and Micro-Hierarchical Transfer Learning Framework for Cross-Domain
                  Fake News Detection},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {5297--5307},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714517},
	doi = {10.1145/3696410.3714517},
	timestamp = {Fri, 09 May 2025 20:28:12 +0200},
	biburl = {https://dblp.org/rec/conf/www/Yang00WWL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cross-domain fake news detection aims to mitigate domain shift and improve detection performance by transferring knowledge across domains. Existing approaches transfer knowledge based on news content and user engagements from a source domain to a target domain. However, these approaches face two main limitations, hindering effective knowledge transfer and optimal fake news detection performance. Firstly, from a micro perspective, they neglect the negative impact of veracity-irrelevant features in news content when transferring domain-shared features across domains. Secondly, from a macro perspective, existing approaches ignore the relationship between user engagement and news content, which reveals shared behaviors of common users across domains and can facilitate more effective knowledge transfer. To address these limitations, we propose a novel macro- and micro- hierarchical transfer learning framework (MMHT) for cross-domain fake news detection. Firstly, we propose a micro-hierarchical disentangling module to disentangle veracity-relevant and veracity-irrelevant features from news content in the source domain for improving fake news detection performance in the target domain. Secondly, we propose a macro-hierarchical transfer learning module to generate engagement features based on common users' shared behaviors in different domains for improving effectiveness of knowledge transfer. Extensive experiments on real-world datasets demonstrate that our framework significantly outperforms the state-of-the-art baselines.}
}


@inproceedings{DBLP:conf/www/YangZCCYW25,
	author = {Jie Yang and
                  Rui Zhang and
                  Ziyang Cheng and
                  Dawei Cheng and
                  Guang Yang and
                  Bo Wang},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Grad: Guided Relation Diffusion Generation for Graph Augmentation
                  in Graph Fraud Detection},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {5308--5319},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714520},
	doi = {10.1145/3696410.3714520},
	timestamp = {Fri, 11 Jul 2025 07:46:03 +0200},
	biburl = {https://dblp.org/rec/conf/www/YangZCCYW25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Nowadays, Graph Fraud Detection (GFD) in financial scenarios has become an urgent research topic to protect online payment security. However, as organized crime groups are becoming more professional in real-world scenarios, fraudsters are employing more sophisticated camouflage strategies. Specifically, fraudsters disguise themselves by mimicking the behavioral data collected by platforms, ensuring that their key characteristics are consistent with those of benign users to a high degree, which we call Adaptive Camouflage. Consequently, this narrows the differences in behavioral traits between them and benign users within the platform's database, thereby making current GFD models lose efficiency. To address this problem, we propose a relation diffusion-based graph augmentation model Grad. In detail, Grad leverages a supervised graph contrastive learning module to enhance the fraud-benign difference and employs a guided relation diffusion generator to generate auxiliary homophilic relations from scratch. Based on these, weak fraudulent signals would be enhanced during the aggregation process, thus being obvious enough to be captured. Extensive experiments have been conducted on two real-world datasets provided by WeChat Pay, one of the largest online payment platforms with billions of users, and three public datasets. The results show that our proposed model Grad outperforms SOTA methods in both various scenarios, achieving at most 11.10% and 43.95% increases in AUC and AP, respectively.}
}


@inproceedings{DBLP:conf/www/YangZL00G0L25,
	author = {Huayi Yang and
                  Chunyuan Zheng and
                  Guorui Liao and
                  Shanshan Huang and
                  Jun Liao and
                  Zhili Gong and
                  Haoxuan Li and
                  Li Liu},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {{CAP:} Causal Air Quality Index Prediction Under Interference with
                  Unmeasured Confounding},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {5320--5329},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714482},
	doi = {10.1145/3696410.3714482},
	timestamp = {Fri, 09 May 2025 20:28:12 +0200},
	biburl = {https://dblp.org/rec/conf/www/YangZL00G0L25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A significant challenge in air quality index (AQI) prediction is to accurately evaluate the potential outcomes after conducting interventions in pollutant factors such as industrial emissions for each enterprise. Existed methods often suffer from spurious correlations caused by unmeasured confounders and are lack of interpretability of the model, leading to sub-optimal prediction performance. This motivates us to propose a causal AQI prediction framework (CAP) that employs a structural causal model (SCM) to characterize the causal structural variability of various AQI factors for robust AQI prediction. Specifically, we employ the front-door adjustment to explicitly eliminate unmeasured confounders by intervening in industrial emissions from the target enterprise. Meanwhile, we take industrial emissions of neighboring enterprises into account when intervening in the target enterprise and simulate the dispersion of industrial emissions through a Gaussian plume model based on meteorological factors. Experiments on two real-world datasets validate the superior performance of our model on AQI prediction compared to the state-of-the-art baselines.}
}


@inproceedings{DBLP:conf/www/ZhangL0025,
	author = {Ziheng Zhang and
                  Zhenxi Lin and
                  Yefeng Zheng and
                  Xian Wu},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {How much Medical Knowledge do LLMs have? An Evaluation of Medical
                  Knowledge Coverage for LLMs},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {5330--5341},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714535},
	doi = {10.1145/3696410.3714535},
	timestamp = {Fri, 09 May 2025 20:28:12 +0200},
	biburl = {https://dblp.org/rec/conf/www/ZhangL0025.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Previous evaluation frameworks for large language models (LLMs) have mostly relied on existing question-answering benchmarks, which are primarily task-oriented rather than knowledge-oriented. In the medical domain, however, the effective deployment of LLMs necessitates a thorough evaluation of their medical knowledge coverage. To this end, we propose a systematic evaluation framework, MedKGEval, to assess the coverage of medical knowledge in LLMs through the lens of medical knowledge graphs (KGs). MedKGEval transforms various levels of knowledge (entity-level, relation-level, and subgraph-level) from the medical KG into distinct groups of question-answer pairs, which serve as comprehensive evaluation benchmarks. In addition to traditional task-oriented evaluations, MedKGEval introduces a novel knowledge-oriented evaluation approach that encompasses the assessment of knowledge coverage across entities, relations, and triples. This multi-aspect evaluation approach allows for a more nuanced understanding of LLMs' knowledge coverage in the medical context. Using these benchmarks, we conduct a systematic evaluation of 11 LLMs from multiple perspectives, revealing insights into their strengths and weaknesses in medical knowledge memorization and reasoning.}
}


@inproceedings{DBLP:conf/www/ZhangMZL25,
	author = {Yunke Zhang and
                  Ruolong Ma and
                  Xin Zhang and
                  Yong Li},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Perceiving Urban Inequality from Imagery Using Visual Language Models
                  with Chain-of-Thought Reasoning},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {5342--5351},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714536},
	doi = {10.1145/3696410.3714536},
	timestamp = {Tue, 13 May 2025 07:31:04 +0200},
	biburl = {https://dblp.org/rec/conf/www/ZhangMZL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The rapid pace of urbanization has led to unequal benefits for residents, creating significant inequality issues and discussions around Sustainable Development Goals 10 and 11. Accurate measurement of inequality within urban areas is essential for effective mitigation strategies. Traditional methods rely on survey-based census data, which are time-consuming and delayed, while some studies use coarse proxies like nighttime lights. However, these methods are limited by resolution and fail to capture fine-grained disparities within communities. To address this, we aim to leverage accessible urban imagery, which offers detailed visual features. Two key challenges must be addressed: 1) accurately perceiving micro-level inequalities within neighborhoods, and 2) ensuring that this perception is interpretable for policy guidance. To address these gaps, we propose  UI-CoT,  a framework that leverages the power of urban imagery-based visual language models in urban inequality perceiving, enhanced by Chain-of-Thought prompting to improve reasoning capabilities. We fine-tune a visual language model to predict three essential neighborhood inequality indicators: the income Gini coefficient, dominant race, and racial income ratio. Extensive experiments show that our model can effectively perceive micro-level inequalities, with the incorporation of Chain-of-Thought reasoning further improving the model's performance by 17.2%. This research offers valuable insights into addressing inequalities within urban environments and demonstrates the potential of web resources in empowering urban sustainable development. The code and data are available at https://github.com/tsinghua-fib-lab/UI-CoT.}
}


@inproceedings{DBLP:conf/www/Zhang0DYL25,
	author = {Yuheng Zhang and
                  Yuan Yuan and
                  Jingtao Ding and
                  Jian Yuan and
                  Yong Li},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {Noise Matters: Diffusion Model-based Urban Mobility Generation with
                  Collaborative Noise Priors},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {5352--5363},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714516},
	doi = {10.1145/3696410.3714516},
	timestamp = {Fri, 09 May 2025 20:28:12 +0200},
	biburl = {https://dblp.org/rec/conf/www/Zhang0DYL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With global urbanization, the focus on sustainable cities has largely grown, driving research into equity, resilience, and urban planning, which often relies on mobility data. The rise of web-based apps and mobile devices has provided valuable user data for mobility-related research. However, real-world mobility data is costly and raises privacy concerns. To protect privacy while retaining key features of real-world movement, the demand for synthetic data has steadily increased. Recent advances in diffusion models have shown great potential for mobility trajectory generation due to their ability to model randomness and uncertainty. However, existing approaches often directly apply identically distributed (i.i.d.) noise sampling from image generation techniques, which fail to account for the spatiotemporal correlations and social interactions that shape urban mobility patterns. In this paper, we propose CoDiffMob, a diffusion model for urban mobility generation with collaborative noise priors, we emphasize the critical role of noise in diffusion models for generating mobility data. By leveraging both individual movement characteristics and population-wide dynamics, we construct novel collaborative noise priors that provide richer and more informative guidance throughout the generation process. Extensive experiments demonstrate the superiority of our method, with generated data accurately capturing both individual preferences and collective patterns, achieving an improvement of over 32%. Furthermore, it can effectively replace web-derived mobility data to better support downstream applications, while safeguarding user privacy and fostering a more secure and ethical web. This highlights its tremendous potential for applications in sustainable city-related research. The code and data are available at https://github.com/tsinghua-fib-lab/CoDiffMob.}
}


@inproceedings{DBLP:conf/www/ZhengZWBLL25,
	author = {Xiaofan Zheng and
                  Zinan Zeng and
                  Heng Wang and
                  Yuyang Bai and
                  Yuhan Liu and
                  Minnan Luo},
	editor = {Guodong Long and
                  Michale Blumestein and
                  Yi Chang and
                  Liane Lewin{-}Eytan and
                  Zi Helen Huang and
                  Elad Yom{-}Tov},
	title = {From Predictions to Analyses: Rationale-Augmented Fake News Detection
                  with Large Vision-Language Models},
	booktitle = {Proceedings of the {ACM} on Web Conference 2025, {WWW} 2025, Sydney,
                  NSW, Australia, 28 April 2025- 2 May 2025},
	pages = {5364--5375},
	publisher = {{ACM}},
	year = {2025},
	url = {https://doi.org/10.1145/3696410.3714532},
	doi = {10.1145/3696410.3714532},
	timestamp = {Fri, 09 May 2025 20:28:12 +0200},
	biburl = {https://dblp.org/rec/conf/www/ZhengZWBLL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The rapid development of social media has led to a surge of eye-catching fake news on the Internet, with multimodal news comprising both images and text being particularly prevalent. To address the challenges of Multimodal Fake News Detection (MFND), numerous supervised task-specific Multimodal Small Language Models (MSLMs) have been developed. However, these models lack the breadth of knowledge and the depth of language understanding, which results in unsatisfactory adaptability, generalization, and explainability performance. To address these issues, we attempt to introduce Large Vision-Language Models (LVLMs), aiming to leverage the common sense understanding and logical reasoning abilities of LVLMs for the MFND task. We observed that LVLMs can generate reasonable analyses of news content from specific angles. However, when it comes to synthesizing these analyses for final judgment, their performance declines significantly, failing to meet the accuracy benchmarks set by existing MSLMs detection models. This reflects the need for a more effective way for LVLMs, which have not undergone task-specific training, to utilize their knowledge and capabilities. Based on these findings, we propose the  E xplainable  A daptive  R ationale- A ugmented  M ultimodal (EARAM) framework, which adaptively uses MSLMs to extract useful rationales from the multi-perspective analyses of LVLMs. After making judgments based on these rationales, EARAM then assists LVLMs in generating more reliable explanations. Extensive experiments demonstrate that our model not only achieves state-of-the-art results on widely used datasets but also significantly outperforms other models in terms of generalization and explainability.}
}
