@inproceedings{DBLP:conf/acsac/KoideFN023,
	author = {Takashi Koide and
                  Naoki Fukushi and
                  Hiroki Nakano and
                  Daiki Chiba},
	title = {PhishReplicant: {A} Language Model-based Approach to Detect Generated
                  Squatting Domain Names},
	booktitle = {Annual Computer Security Applications Conference, {ACSAC} 2023, Austin,
                  TX, USA, December 4-8, 2023},
	pages = {1--13},
	publisher = {{ACM}},
	year = {2023},
	url = {https://doi.org/10.1145/3627106.3627111},
	doi = {10.1145/3627106.3627111},
	timestamp = {Sun, 10 Dec 2023 17:00:07 +0100},
	biburl = {https://dblp.org/rec/conf/acsac/KoideFN023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Domain squatting is a technique used by attackers to create domain names for phishing sites. In recent phishing attempts, we have observed many domain names that use multiple techniques to evade existing methods for domain squatting. These domain names, which we call generated squatting domains (GSDs), are quite different in appearance from legitimate domain names and do not contain brand names, making them difficult to associate with phishing. In this paper, we propose a system called PhishReplicant that detects GSDs by focusing on the linguistic similarity of domain names. We analyzed newly registered and observed domain names extracted from certificate transparency logs, passive DNS, and DNS zone files. We detected 3,498 domain names acquired by attackers in a four-week experiment, of which 2,821 were used for phishing sites within a month of detection. We also confirmed that our proposed system outperformed existing systems in both detection accuracy and number of domain names detected. As an in-depth analysis, we examined 205k GSDs collected over 150 days and found that phishing using GSDs was distributed globally. However, attackers intensively targeted brands in specific regions and industries. By analyzing GSDs in real time, we can block phishing sites before or immediately after they appear.}
}


@inproceedings{DBLP:conf/acsac/StivalaAMGFP23,
	author = {Giada Stivala and
                  Sahar Abdelnabi and
                  Andrea Mengascini and
                  Mariano Graziano and
                  Mario Fritz and
                  Giancarlo Pellegrino},
	title = {From Attachments to {SEO:} Click Here to Learn More about Clickbait
                  PDFs!},
	booktitle = {Annual Computer Security Applications Conference, {ACSAC} 2023, Austin,
                  TX, USA, December 4-8, 2023},
	pages = {14--28},
	publisher = {{ACM}},
	year = {2023},
	url = {https://doi.org/10.1145/3627106.3627172},
	doi = {10.1145/3627106.3627172},
	timestamp = {Sun, 10 Dec 2023 17:00:07 +0100},
	biburl = {https://dblp.org/rec/conf/acsac/StivalaAMGFP23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Clickbait PDFs are PDF documents that do not embed malware but trick victims into visiting malicious web pages leading to attacks like password theft or drive-by download. While recent reports indicate a surge of clickbait PDFs, prior works have largely neglected this new threat, considering PDFs only as accessories of email phishing campaigns.}
}


@inproceedings{DBLP:conf/acsac/KotziasRPSB23,
	author = {Platon Kotzias and
                  Kevin A. Roundy and
                  Michalis Pachilakis and
                  Iskander S{\'{a}}nchez{-}Rola and
                  Leyla Bilge},
	title = {Scamdog Millionaire: Detecting E-commerce Scams in the Wild},
	booktitle = {Annual Computer Security Applications Conference, {ACSAC} 2023, Austin,
                  TX, USA, December 4-8, 2023},
	pages = {29--43},
	publisher = {{ACM}},
	year = {2023},
	url = {https://doi.org/10.1145/3627106.3627184},
	doi = {10.1145/3627106.3627184},
	timestamp = {Fri, 22 Dec 2023 15:25:03 +0100},
	biburl = {https://dblp.org/rec/conf/acsac/KotziasRPSB23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Better Business Bureau ranked online e-commerce scams as the top consumer threat for 2022. Our measurements of real consumer devices confirm that e-commerce scams receive large traffic volumes, a total of 6.3M visits during seven months. In this work, we study e-commerce scams in depth and design a detection classifier that combines novel features that target salient characteristics of e-commerce scam websites and features for detecting malicious and scam domains proposed by prior work. In addition, we specify a method for automatically creating reliable ground-truth sets that are an order of magnitude larger than that of prior work. We use this data set to evaluate the classifier and achieve a high 0.973 F1-score (Prec: 0.988, Rec: 0.959). In a best-effort comparison, we demonstrate that our classifier outperforms the F-1 score of the prior art by 11% and that our novel features offer an F1-score boost of 4.3% over the features used in the prior art. In addition, we deploy our classifier in a real-world setting, analyze over 760K e-shops visited by real users, and identify 10% of those as e-commerce scams. We demonstrate that the classifier has a low False Positive rate in real-world settings and can protect over 176K users in one week.}
}


@inproceedings{DBLP:conf/acsac/CarboneriGKP23,
	author = {Alberto Carboneri and
                  Mohammad Ghasemisharif and
                  Soroush Karami and
                  Jason Polakis},
	title = {When Push Comes to Shove: Empirical Analysis of Web Push Implementations
                  in the Wild},
	booktitle = {Annual Computer Security Applications Conference, {ACSAC} 2023, Austin,
                  TX, USA, December 4-8, 2023},
	pages = {44--55},
	publisher = {{ACM}},
	year = {2023},
	url = {https://doi.org/10.1145/3627106.3627186},
	doi = {10.1145/3627106.3627186},
	timestamp = {Sun, 10 Dec 2023 17:00:06 +0100},
	biburl = {https://dblp.org/rec/conf/acsac/CarboneriGKP23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Web push notifications are becoming an increasingly prevalent capability of modern web apps, intended to create a direct communication pipeline with users and increase user engagement. The seemingly straightforward functionality of push notifications obscures the complexities of the underlying design and implementation, which deviates from a near-universal practice in the web ecosystem: the ability to access an account (and the associated functionality) from practically any browser or device upon successful completion of the authentication process. Instead, push notifications create a communication endpoint for a specific browser instance. As a result, the challenges of deploying push notifications are further exacerbated due to the integration obstacles that arise from other aspects of web apps and user browsing behaviors (e.g., multi-device environments, account and session management). In this paper, we conduct an empirical analysis of push notification implementations in the wild, and identify common deployment pitfalls. We also demonstrate a series of attacks that target push notification functionality, including a novel subscription-sniffing attack, through a selection of use cases. To better understand current practices in push notifications implementations, we present a large-scale measurement of their deployment and also provide the first, to our knowledge, exploration and analysis of third-party service providers. Finally, we provide guidelines for developers and propose an approach for correctly handling push notifications in multi-browser, post-authentication settings.}
}


@inproceedings{DBLP:conf/acsac/GerettoHGBKG23,
	author = {Elia Geretto and
                  Julius Hohnerlein and
                  Cristiano Giuffrida and
                  Herbert Bos and
                  Erik van der Kouwe and
                  Klaus von Gleissenthall},
	title = {Triereme: Speeding up hybrid fuzzing through efficient query scheduling},
	booktitle = {Annual Computer Security Applications Conference, {ACSAC} 2023, Austin,
                  TX, USA, December 4-8, 2023},
	pages = {56--70},
	publisher = {{ACM}},
	year = {2023},
	url = {https://doi.org/10.1145/3627106.3627173},
	doi = {10.1145/3627106.3627173},
	timestamp = {Sun, 10 Dec 2023 17:00:07 +0100},
	biburl = {https://dblp.org/rec/conf/acsac/GerettoHGBKG23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Hybrid fuzzing, the combination between fuzzing and concolic execution, holds great promise in theory, but has so far failed to deliver all the expected advantages in practice due to its high overhead. The cause is the large amount of time spent in the SMT solver. As a result, hybrid fuzzers often lose out to simpler, yet faster techniques. This issue remains despite novel query pruning techniques that reduce the number and complexity of solver queries as they preclude other crucial optimizations like incremental solving.}
}


@inproceedings{DBLP:conf/acsac/LadisaPRMB23,
	author = {Piergiorgio Ladisa and
                  Serena Elisa Ponta and
                  Nicola Ronzoni and
                  Matias Martinez and
                  Olivier Barais},
	title = {On the Feasibility of Cross-Language Detection of Malicious Packages
                  in npm and PyPI},
	booktitle = {Annual Computer Security Applications Conference, {ACSAC} 2023, Austin,
                  TX, USA, December 4-8, 2023},
	pages = {71--82},
	publisher = {{ACM}},
	year = {2023},
	url = {https://doi.org/10.1145/3627106.3627138},
	doi = {10.1145/3627106.3627138},
	timestamp = {Sun, 10 Dec 2023 17:00:06 +0100},
	biburl = {https://dblp.org/rec/conf/acsac/LadisaPRMB23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Current software supply chains heavily rely on open-source packages hosted in public repositories. Given the popularity of ecosystems like npm and PyPI, malicious users started to spread malware by publishing open-source packages containing malicious code.}
}


@inproceedings{DBLP:conf/acsac/MooreKC23,
	author = {Marina Moore and
                  Trishank Karthik Kuppusamy and
                  Justin Cappos},
	title = {Artemis: Defanging Software Supply Chain Attacks in Multi-repository
                  Update Systems},
	booktitle = {Annual Computer Security Applications Conference, {ACSAC} 2023, Austin,
                  TX, USA, December 4-8, 2023},
	pages = {83--97},
	publisher = {{ACM}},
	year = {2023},
	url = {https://doi.org/10.1145/3627106.3627129},
	doi = {10.1145/3627106.3627129},
	timestamp = {Sun, 10 Dec 2023 17:00:06 +0100},
	biburl = {https://dblp.org/rec/conf/acsac/MooreKC23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Modern software installation tools often use packages from more than one repository, presenting a unique set of security challenges. Such a configuration increases the risk of repository compromise and introduces attacks like dependency confusion and repository fallback. In this paper, we offer the first exploration of attacks that specifically target multiple repository update systems, and propose a unique defensive strategy we call articulated trust. Articulated trust is a principle that allows software installation tools to specify trusted developers and repositories for each package. To implement articulated trust, we built Artemis, a framework that introduces several new security techniques, such as per-package prioritization of repositories, multi-role delegations, multiple-repository consensus, and key pinning. These techniques allow for a greater diversity of trust relationships while eliminating the security risk of single points of failure.}
}


@inproceedings{DBLP:conf/acsac/LiuJLLWL23,
	author = {Xinyu Liu and
                  Ze Jin and
                  Jiaxi Liu and
                  Wei Liu and
                  Xiaoxi Wang and
                  Qixu Liu},
	title = {ANDetect: {A} Third-party Ad Network Libraries Detection Framework
                  for Android Applications},
	booktitle = {Annual Computer Security Applications Conference, {ACSAC} 2023, Austin,
                  TX, USA, December 4-8, 2023},
	pages = {98--112},
	publisher = {{ACM}},
	year = {2023},
	url = {https://doi.org/10.1145/3627106.3627182},
	doi = {10.1145/3627106.3627182},
	timestamp = {Wed, 17 Apr 2024 17:20:54 +0200},
	biburl = {https://dblp.org/rec/conf/acsac/LiuJLLWL23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Third-party advertising libraries, which furnish mobile applications with ads, offer a revenue stream for Android application developers. However, the loaded ads potentially expose application users to privacy infringements and security threats. For instance, tracking scripts embedded in third-party ads monitor user behavior and can entice users into downloading malicious files. Therefore, the detection of advertising libraries in mobile applications is crucial for mobile security protection and serves as the foundation for preventing third-party ads from compromising user privacy.}
}


@inproceedings{DBLP:conf/acsac/YoonCK23,
	author = {Daegeun Yoon and
                  Taejoong Chung and
                  Yongdae Kim},
	title = {Delegation of {TLS} Authentication to CDNs using Revocable Delegated
                  Credentials},
	booktitle = {Annual Computer Security Applications Conference, {ACSAC} 2023, Austin,
                  TX, USA, December 4-8, 2023},
	pages = {113--123},
	publisher = {{ACM}},
	year = {2023},
	url = {https://doi.org/10.1145/3627106.3627144},
	doi = {10.1145/3627106.3627144},
	timestamp = {Sun, 10 Dec 2023 17:00:07 +0100},
	biburl = {https://dblp.org/rec/conf/acsac/YoonCK23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {When using a Content Delivery Network (CDN), domain owners typically delegate Transport Layer Security (TLS) authentication to the CDN by sharing their TLS certificate’s private key. However, this practice not only delegates TLS authentication but also grants the CDN complete control over the certificate. To mitigate these concerns, Delegated Credential (DC) was proposed as a solution; DC, which contains both the CDN’s public key and the domain owner’s signature, allows the domain owners to delegate their own credentials for TLS authentication, thereby avoiding the need to share their private keys. However, the absence of a mechanism to distribute the revocation status of a DC renders it non-revocable, even when a compromise of a credential has been detected. DCs were thus designed to be short-lived, necessitating frequent renewal for continued use.}
}


@inproceedings{DBLP:conf/acsac/SebastianDCSB23,
	author = {Silvia Sebasti{\'{a}}n and
                  Raluca{-}Georgia Diugan and
                  Juan Caballero and
                  Iskander S{\'{a}}nchez{-}Rola and
                  Leyla Bilge},
	title = {Domain and Website Attribution beyond {WHOIS}},
	booktitle = {Annual Computer Security Applications Conference, {ACSAC} 2023, Austin,
                  TX, USA, December 4-8, 2023},
	pages = {124--137},
	publisher = {{ACM}},
	year = {2023},
	url = {https://doi.org/10.1145/3627106.3627190},
	doi = {10.1145/3627106.3627190},
	timestamp = {Sun, 10 Dec 2023 17:00:06 +0100},
	biburl = {https://dblp.org/rec/conf/acsac/SebastianDCSB23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Currently, WHOIS is the main method for identifying which company or individual owns a domain or website. But, WHOIS usefulness is limited due to privacy protection services and data redaction. We present a novel automated approach for domain and website attribution. When WHOIS data does not reveal the owner, our approach leverages information from multiple other sources such as passive DNS, TLS certificates, and the analysis of website content. We propose a novel ranking technique to select the domain owner among multiple identified entities. Our approach identifies the domain owner with an F1 score of 0.94 compared to 0.54 for WHOIS. When applied on 3,001 tracker domains from the popular Disconnect list, it identifies needed updates to the list. It also attributes 84% of previously unattributed tracker domains.}
}


@inproceedings{DBLP:conf/acsac/DinaS023,
	author = {Ayesha S. Dina and
                  A. B. Siddique and
                  D. Manivannan},
	title = {{FS3:} Few-Shot and Self-Supervised Framework for Efficient Intrusion
                  Detection in Internet of Things Networks},
	booktitle = {Annual Computer Security Applications Conference, {ACSAC} 2023, Austin,
                  TX, USA, December 4-8, 2023},
	pages = {138--149},
	publisher = {{ACM}},
	year = {2023},
	url = {https://doi.org/10.1145/3627106.3627193},
	doi = {10.1145/3627106.3627193},
	timestamp = {Sun, 10 Dec 2023 17:00:06 +0100},
	biburl = {https://dblp.org/rec/conf/acsac/DinaS023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Securing the Internet of Things is critical for its successful deployment in various industries. While Machine Learning techniques have shown promise for intrusion detection in the Internet of Things, existing methods require large amounts of labeled training data; moreover, they encounter challenges with the presence of extreme class imbalance, i.e., some classes are underrepresented in the datasets used. Supervised methods rely on extensive labeled data, which can be costly and time-consuming to obtain. Class imbalance in datasets further exacerbates the challenge by skewing the model’s learning process toward the majority classes, leading to poor detection of attacks belonging to minority classes. This issue is particularly pronounced in the Internet of Things environments due to diverse devices and the varying frequency of intrusions targeting them. To overcome these challenges, we present a Few-Shot and Self-Supervised framework, called, for detecting intrusions in IoT networks. works in three phases. The first phase employs self-supervised learning to learn latent patterns and robust representations from unlabeled data. The second phase introduces Few-shot learning with contrastive training. Few-shot learning enables the model to learn from a few labeled examples, thereby eliminating the dependency on a large amount of labeled data. Contrastive Training addresses the class imbalance issue by improving the discriminative power of the model. The third phase introduces a novel K-Nearest neighbor algorithm that sub-samples the majority class instances to further reduce imbalance and improve overall performance. Experimental results based on three publicly available benchmark datasets demonstrate the efficacy of in addressing the challenges posed by the limited availability of labeled data as well as class imbalance in datasets. Our proposed framework, utilizing only of labeled data, outperforms fully supervised state-of-the-art models by up to and with respect to the metrics precision and F1 score, respectively.}
}


@inproceedings{DBLP:conf/acsac/MirianHSV23,
	author = {Ariana Mirian and
                  Grant Ho and
                  Stefan Savage and
                  Geoffrey M. Voelker},
	title = {An Empirical Analysis of Enterprise-Wide Mandatory Password Updates},
	booktitle = {Annual Computer Security Applications Conference, {ACSAC} 2023, Austin,
                  TX, USA, December 4-8, 2023},
	pages = {150--162},
	publisher = {{ACM}},
	year = {2023},
	url = {https://doi.org/10.1145/3627106.3627198},
	doi = {10.1145/3627106.3627198},
	timestamp = {Sun, 10 Dec 2023 17:00:06 +0100},
	biburl = {https://dblp.org/rec/conf/acsac/MirianHSV23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Enterprise-scale mandatory password changes are disruptive, complex endeavors that require the entire workforce to prioritize a goal that is often secondary to most users. While ample literature exists around user perceptions and struggles, there are few “best practices” from the perspective of the enterprise—either to achieve the end goal or to minimize IT costs. In this paper, we provide an empirical analysis of an enterprise-scale mandatory password change, covering almost 10,000 faculty and staff at an academic institution. Using a combination of user notifications logs, password update records, and help desk ticket information, we construct an empirical model of user response over time. In particular, we characterize the elements of the campaign that relate to ideal and non-ideal outcomes, including unnecessary user actions and IT help desk overhead. We aim to provide insight into successes and challenges that can generalize to other organizations implementing similar initiatives.}
}


@inproceedings{DBLP:conf/acsac/OchoaVTB23,
	author = {Mart{\'{\i}}n Ochoa and
                  Hern{\'{a}}n Vanegas and
                  Jorge Toro{-}Pozo and
                  David A. Basin},
	title = {SealClub: Computer-aided Paper Document Authentication},
	booktitle = {Annual Computer Security Applications Conference, {ACSAC} 2023, Austin,
                  TX, USA, December 4-8, 2023},
	pages = {163--177},
	publisher = {{ACM}},
	year = {2023},
	url = {https://doi.org/10.1145/3627106.3627176},
	doi = {10.1145/3627106.3627176},
	timestamp = {Mon, 05 Feb 2024 20:28:57 +0100},
	biburl = {https://dblp.org/rec/conf/acsac/OchoaVTB23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Paper documents, where digital signatures are not directly applicable, are still widely utilized due to usability and legal reasons. We propose a novel approach to authenticating paper documents by taking short videos of them with smartphones. Our solution combines cryptographic and image comparison techniques to detect and highlight semantic-changing attacks on rich documents, containing text and graphics. We provide geometrical arguments for the security of our novel comparison algorithm, and prove that its combination with a cryptographic protocol is secure against strong adversaries capable of compromising different system components. We also measure its accuracy on a set of 128 videos of paper documents and a set of 960 synthetically generated warped documents, half containing subtle forgeries. Our algorithm finds all forgeries accurately with no false positives. The highlighted regions are large enough to be visible to users, but small enough to precisely locate forgeries.}
}


@inproceedings{DBLP:conf/acsac/TedeschiSP23,
	author = {Pietro Tedeschi and
                  Savio Sciancalepore and
                  Roberto Di Pietro},
	title = {Lightweight Privacy-Preserving Proximity Discovery for Remotely-Controlled
                  Drones},
	booktitle = {Annual Computer Security Applications Conference, {ACSAC} 2023, Austin,
                  TX, USA, December 4-8, 2023},
	pages = {178--189},
	publisher = {{ACM}},
	year = {2023},
	url = {https://doi.org/10.1145/3627106.3627174},
	doi = {10.1145/3627106.3627174},
	timestamp = {Sun, 10 Dec 2023 17:00:06 +0100},
	biburl = {https://dblp.org/rec/conf/acsac/TedeschiSP23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Discovering mutual proximity and avoiding collisions is one of the most critical services needed by the next generation of Unmanned Aerial Vehicles (UAVs). However, currently available solutions either rely on sharing mutual locations, neglecting the location privacy of involved parties, or are applicable for fully autonomous vehicles only—leaving unaddressed Remotely-Piloted UAVs’ safety needs. Alternatively, proximity can be discovered by adding sensing capabilities. However, in addition to the cost of the sensors, the complexity of integration, and the toll on the energy budget, the effectiveness of such solutions is usually limited by short detection ranges, making them hardly useful in high-mobility scenarios. In this paper, we propose LPPD (an acronym for Lightweight Privacy-preserving Proximity Discovery), a unique solution for privacy-preserving proximity discovery among remotely piloted UAVs based on the exchange of wireless messages. LPPD integrates two main building blocks: (i) a custom space tessellation technique based on randomized spheres; and, (ii) a lightweight cryptographic primitive for private-set intersection. Another feature enjoyed by LPPD is that it does not require online third parties. LPPD is rooted in sound theoretical results and is supported by an experimental assessment performed on a real drone. In particular, experimental results show that LPPD achieves 100% proximity discovery while taking only 39.66 milliseconds in the most lightweight configuration and draining only the 5 · 10− 6% of the UAV’s battery capacity. In addition, LPPD’s security properties are formally verified.}
}


@inproceedings{DBLP:conf/acsac/PutzMMS23,
	author = {Philipp P{\"{u}}tz and
                  Richard Mitev and
                  Markus Miettinen and
                  Ahmad{-}Reza Sadeghi},
	title = {Unleashing IoT Security: Assessing the Effectiveness of Best Practices
                  in Protecting Against Threats},
	booktitle = {Annual Computer Security Applications Conference, {ACSAC} 2023, Austin,
                  TX, USA, December 4-8, 2023},
	pages = {190--204},
	publisher = {{ACM}},
	year = {2023},
	url = {https://doi.org/10.1145/3627106.3627133},
	doi = {10.1145/3627106.3627133},
	timestamp = {Sun, 10 Dec 2023 17:00:06 +0100},
	biburl = {https://dblp.org/rec/conf/acsac/PutzMMS23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Internet of Things (IoT) market is rapidly growing and is expected to double from 2020 to 2025. The increasing use of IoT devices, particularly in smart homes, raises crucial concerns as inadequate security designs and implementations by IoT vendors can lead to significant vulnerabilities endangering the privacy and security of sensitive user information handled by these devices. To address these IoT device vulnerabilities, institutions and organizations have published IoT security best practices (BPs) to guide manufacturers in ensuring the security of their products. However, there is currently no standardized approach for evaluating the effectiveness of individual BP recommendations. This leads to manufacturers investing effort in implementing less effective BPs while potentially neglecting measures with greater impact. In this paper, we propose a methodology for evaluating the security impact of IoT BPs and ranking them based on their effectiveness in protecting against security threats. Our approach involves translating identified BPs into concrete test cases that can be applied to real-world IoT devices to assess their effectiveness in mitigating vulnerabilities. We applied this methodology to evaluate the security impact of nine commodity IoT products, discovering 18 vulnerabilities. By empirically assessing the actual impact of BPs on device security, IoT designers and implementers can prioritize their security investments more effectively, improving security outcomes and optimizing limited security budgets.}
}


@inproceedings{DBLP:conf/acsac/KaplanLGQ23,
	author = {Berkay Kaplan and
                  Israel J. Lopez{-}Toledo and
                  Carl A. Gunter and
                  Jingyu Qian},
	title = {A Tagging Solution to Discover IoT Devices in Apartments},
	booktitle = {Annual Computer Security Applications Conference, {ACSAC} 2023, Austin,
                  TX, USA, December 4-8, 2023},
	pages = {205--215},
	publisher = {{ACM}},
	year = {2023},
	url = {https://doi.org/10.1145/3627106.3627108},
	doi = {10.1145/3627106.3627108},
	timestamp = {Sun, 10 Dec 2023 17:00:07 +0100},
	biburl = {https://dblp.org/rec/conf/acsac/KaplanLGQ23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The number of Internet of Things (IoT) devices in smart homes is increasing. This broad adoption facilitates users’ lives, but it also brings problems. One such issue is that some IoT devices may invade users’ privacy through obscure data collection practices or hidden devices. Specific IoT devices can exist out of sight and still collect user data to send to third parties via the Internet. Owners can easily forget the location or even the existence of these devices, especially if the owner is a landlord managing several properties. The landlord-owner scenario creates multi-user problems as designers typically build IoT devices for single users. We developed tag models that use wireless protocols, buzzers, and LED lighting to guide users toward the hidden device in shared spaces and accommodate multi-user scenarios. They are attached to IoT devices inside a residential unit during their installation to be later discovered by a tenant. These tags are similar to Tile models or Airtag but have different features based on our privacy use case. For instance, our tags do not require pairing; multiple users can interact with them through our Android application. Our tags can also embed the IoT device’s information while protecting against unwanted access to that information through a proximity requirement. Researchers have developed several other tools, such as thermal cameras or virtual reality (VR), for discovering devices, but we focused on wireless technologies. We measured specific performance metrics of our tags to analyze their feasibility for this problem. We also conducted a user study to measure the participants’ comfort levels while finding objects with our tags attached. Our results indicate that wireless tags can be viable for device tracking in residential properties.}
}


@inproceedings{DBLP:conf/acsac/WangGWZLG023,
	author = {Ke Wang and
                  Jianbo Gao and
                  Qiao Wang and
                  Jiashuo Zhang and
                  Yue Li and
                  Zhi Guan and
                  Zhong Chen},
	title = {Hades: Practical Decentralized Identity with Full Accountability and
                  Fine-grained Sybil-resistance},
	booktitle = {Annual Computer Security Applications Conference, {ACSAC} 2023, Austin,
                  TX, USA, December 4-8, 2023},
	pages = {216--228},
	publisher = {{ACM}},
	year = {2023},
	url = {https://doi.org/10.1145/3627106.3627110},
	doi = {10.1145/3627106.3627110},
	timestamp = {Wed, 01 May 2024 10:27:36 +0200},
	biburl = {https://dblp.org/rec/conf/acsac/WangGWZLG023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Decentralized identity (DID), the idea of giving users complete control over their identity-related data, is being used to solve the privacy tension in the identity management of decentralized applications (Dapps). While existing approaches do an excellent job of solving the privacy tension, they have not adequately addressed the accountability and Sybil-resistance issues. Moreover, these approaches have a considerable gas overhead, making them impractical for Dapps.}
}


@inproceedings{DBLP:conf/acsac/XuZHJDCX23,
	author = {Shaowen Xu and
                  Qihang Zhou and
                  Heqing Huang and
                  Xiaoqi Jia and
                  Haichao Du and
                  Yang Chen and
                  Yamin Xie},
	title = {Log2Policy: An Approach to Generate Fine-Grained Access Control Rules
                  for Microservices from Scratch},
	booktitle = {Annual Computer Security Applications Conference, {ACSAC} 2023, Austin,
                  TX, USA, December 4-8, 2023},
	pages = {229--240},
	publisher = {{ACM}},
	year = {2023},
	url = {https://doi.org/10.1145/3627106.3627137},
	doi = {10.1145/3627106.3627137},
	timestamp = {Sun, 10 Dec 2023 17:00:06 +0100},
	biburl = {https://dblp.org/rec/conf/acsac/XuZHJDCX23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Microservice application architecture is one of the most widely used service architectures in the industry. To prevent a compromised microservice from abusing other microservices, authorization policy is applied to regulate the access among them. However, configuring access control policy manually is challenging due to the complexity and dynamic nature of microservice applications. In this paper, we present Log2Policy, a novel approach to generate microservice authorization policy based on access logs. Our approach consists of three fundamental techniques: (1) a log-based topological graph generation mechanism that automatically infers the invocation logic among microservices, (2) a machine learning based attributes mining method that extracts the relevant attributes of requests, and (3) a policy upgrade mechanism based on traffic management that can significantly reduce the upgrade time. We have implemented a prototype of Log2Policy on mainstream microservice infrastructures and have evaluated it with several microservice applications. The results show that Log2Policy can generate fine-grained and effective access control rules and upgrade them with negligible overhead.}
}


@inproceedings{DBLP:conf/acsac/ShaonRK23,
	author = {Fahad Shaon and
                  Sazzadur Rahaman and
                  Murat Kantarcioglu},
	title = {The Queen's Guard: {A} Secure Enforcement of Fine-grained Access Control
                  In Distributed Data Analytics Platforms},
	booktitle = {Annual Computer Security Applications Conference, {ACSAC} 2023, Austin,
                  TX, USA, December 4-8, 2023},
	pages = {241--255},
	publisher = {{ACM}},
	year = {2023},
	url = {https://doi.org/10.1145/3627106.3627132},
	doi = {10.1145/3627106.3627132},
	timestamp = {Sun, 10 Dec 2023 17:00:07 +0100},
	biburl = {https://dblp.org/rec/conf/acsac/ShaonRK23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Distributed data analytics platforms (i.e., Apache Spark, Hadoop) provide high-level APIs to programmatically write analytics tasks that are run distributedly in multiple computing nodes. The design of these frameworks was primarily motivated by performance and usability. Thus, the security takes a back seat. Consequently, they do not inherently support fine-grained access control or offer any plugin mechanism to enable it, making them risky to be used in multi-tier organizational settings.}
}


@inproceedings{DBLP:conf/acsac/InnocentiGOMCK23,
	author = {Tommaso Innocenti and
                  Matteo Golinelli and
                  Kaan Onarlioglu and
                  Seyed Ali Mirheidari and
                  Bruno Crispo and
                  Engin Kirda},
	title = {OAuth 2.0 Redirect {URI} Validation Falls Short, Literally},
	booktitle = {Annual Computer Security Applications Conference, {ACSAC} 2023, Austin,
                  TX, USA, December 4-8, 2023},
	pages = {256--267},
	publisher = {{ACM}},
	year = {2023},
	url = {https://doi.org/10.1145/3627106.3627140},
	doi = {10.1145/3627106.3627140},
	timestamp = {Sun, 10 Dec 2023 17:00:06 +0100},
	biburl = {https://dblp.org/rec/conf/acsac/InnocentiGOMCK23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {OAuth 2.0 requires a complex redirection trail between websites and Identity Providers (IdPs). In particular, the "redirect URI" parameter included in the popular Authorization Grant Code flow governs the callback endpoint that users are routed to, together with their security tokens. The protocol specification, therefore, includes guidelines on protecting the integrity of the redirect URI.}
}


@inproceedings{DBLP:conf/acsac/Plappert023,
	author = {Christian Plappert and
                  Andreas Fuchs},
	title = {Secure and Lightweight Over-the-Air Software Update Distribution for
                  Connected Vehicles},
	booktitle = {Annual Computer Security Applications Conference, {ACSAC} 2023, Austin,
                  TX, USA, December 4-8, 2023},
	pages = {268--282},
	publisher = {{ACM}},
	year = {2023},
	url = {https://doi.org/10.1145/3627106.3627135},
	doi = {10.1145/3627106.3627135},
	timestamp = {Sun, 10 Dec 2023 17:00:06 +0100},
	biburl = {https://dblp.org/rec/conf/acsac/Plappert023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Connected vehicles are increasingly threatened by cyberattacks during their long lifecycle. Therefore, timely Over-the-Air (OTA) update processes are becoming a mandatory mitigation mechanism and their security a critical task. In this paper, we present a novel secure OTA update distribution mechanism for connected vehicles that addresses threats and requirements of recent automotive security regulations and standards. We tailor our security concept to the capabilities of a Trusted Platform Module 2.0 (TPM) that we deploy as hardware trust anchor at the vehicle telematics unit and show its benefits and uniqueness regarding security guarantees and functionality in comparison to related work. In our concept, the TPM acts as trusted update distribution point that securely translates the asymmetric backend cryptography to the symmetric in-vehicle cryptography and as update authorization point that coordinates the update installation, e.g., regarding the vehicle state. These concepts are completely enforced inside the shielded location of the TPM, which then represents our minimal hardened trusted computing base on the telematics unit. The solution does not rely on boot time integrity mechanisms and thus even mitigates against advanced runtime and physical hardware cyberattacks. We evaluate our solution using a prototypical implementation within an automotive evaluation platform.}
}


@inproceedings{DBLP:conf/acsac/Plappert023a,
	author = {Christian Plappert and
                  Andreas Fuchs},
	title = {Secure and Lightweight {ECU} Attestations for Resilient Over-the-Air
                  Updates in Connected Vehicles},
	booktitle = {Annual Computer Security Applications Conference, {ACSAC} 2023, Austin,
                  TX, USA, December 4-8, 2023},
	pages = {283--297},
	publisher = {{ACM}},
	year = {2023},
	url = {https://doi.org/10.1145/3627106.3627202},
	doi = {10.1145/3627106.3627202},
	timestamp = {Sun, 10 Dec 2023 17:00:06 +0100},
	biburl = {https://dblp.org/rec/conf/acsac/Plappert023a.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recent automotive standards and regulations define requirements for over-the-air (OTA) software updates as a mandatory mitigation mechanism to secure the increasingly connected vehicles against future cyberthreats in a timely manner. Targeting these requirements, we design, implement, and evaluate a novel security concept targeted at securing the in-vehicle processes participating in the OTA update process. It is designed as complementary security measure to further harden already in-place secure update distribution mechanisms and is compliant to recent automotive standards and regulations. Its security is bootstrapped from the secure interlocking of two trusted computing technologies: The Trusted Platform Module 2.0 (TPM 2.0) as overall hardware trust anchor within the vehicle and the Device Identifier Composition Engine (DICE) for securely bootstrapping the resource constrained controllers. Our concept allows the controllers to report their currently running software version to the TPM 2.0 in a secure and lightweight way. Depending on the controllers’ software state, the TPM 2.0 may authorize to transition the vehicle from an update-ready state back to the fully functional drive mode, e.g., after an OTA software update was successfully installed.}
}


@inproceedings{DBLP:conf/acsac/KernKH23,
	author = {Dustin Kern and
                  Christoph Krau{\ss} and
                  Matthias Hollick},
	title = {Detection of Anomalies in Electric Vehicle Charging Sessions},
	booktitle = {Annual Computer Security Applications Conference, {ACSAC} 2023, Austin,
                  TX, USA, December 4-8, 2023},
	pages = {298--309},
	publisher = {{ACM}},
	year = {2023},
	url = {https://doi.org/10.1145/3627106.3627127},
	doi = {10.1145/3627106.3627127},
	timestamp = {Sun, 10 Dec 2023 17:00:07 +0100},
	biburl = {https://dblp.org/rec/conf/acsac/KernKH23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Electric Vehicle (EV) charging involves a complex system with cyber-physical components, backend systems, and communication protocols. A potential security incident in this system can open up cyber-physical threats and, for instance, lead to EV battery fires or power grid blackouts. In this paper, we propose a hybrid Intrusion Detection System (IDS) method consisting of regression-based charging session forecasting and anomaly detection. The method considers an EV’s detailed charging behavior throughout a session and we discuss and evaluate different design choices. For anomaly detection, we consider both classification- and novelty-based models as well as an ensemble method to combine both models. We perform evaluations based on real-world EV charging session data with simulated attacks. Our results show that regression-based forecasting provides a significant increase in detection performance for attacks affecting individual reports during a charging session. Additionally, the proposed ensemble method, which combines artificial neural network-based classification and local outlier factor-based novelty detection, can maintain a low false alarm rate while offering good detection performance w.r.t. known attacks as well as generalization to previously unseen attacks. We thus argue that the proposed solution can provide a positive contribution to EV charging security, resilience, and trustworthiness.}
}


@inproceedings{DBLP:conf/acsac/MengYZGDC0Z23,
	author = {Jie Meng and
                  Zeyu Yang and
                  Zhenyong Zhang and
                  Yangyang Geng and
                  Ruilong Deng and
                  Peng Cheng and
                  Jiming Chen and
                  Jianying Zhou},
	title = {SePanner: Analyzing Semantics of Controller Variables in Industrial
                  Control Systems based on Network Traffic},
	booktitle = {Annual Computer Security Applications Conference, {ACSAC} 2023, Austin,
                  TX, USA, December 4-8, 2023},
	pages = {310--323},
	publisher = {{ACM}},
	year = {2023},
	url = {https://doi.org/10.1145/3627106.3627179},
	doi = {10.1145/3627106.3627179},
	timestamp = {Tue, 09 Jul 2024 15:32:27 +0200},
	biburl = {https://dblp.org/rec/conf/acsac/MengYZGDC0Z23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Programmable logic controllers (PLCs), the essential components of critical infrastructure, play a crucial role in various industrial manufacturing processes. Recent attack events show that attackers have a strong interest in tampering with the controller variables, such as the device status and internal program logic. A typical attack strategy is that the attackers just send malicious network traffic of industrial control protocols (ICPs) to change the controller variables of PLCs. To defend against this attack, a lot of countermeasures have been proposed to detect anomalies in network traffic based on the semantic analysis.}
}


@inproceedings{DBLP:conf/acsac/NichollsKL23,
	author = {Jack Nicholls and
                  Aditya Kuppa and
                  Nhien{-}An Le{-}Khac},
	title = {FraudLens: Graph Structural Learning for Bitcoin Illicit Activity
                  Identification},
	booktitle = {Annual Computer Security Applications Conference, {ACSAC} 2023, Austin,
                  TX, USA, December 4-8, 2023},
	pages = {324--336},
	publisher = {{ACM}},
	year = {2023},
	url = {https://doi.org/10.1145/3627106.3627200},
	doi = {10.1145/3627106.3627200},
	timestamp = {Sun, 10 Dec 2023 17:00:07 +0100},
	biburl = {https://dblp.org/rec/conf/acsac/NichollsKL23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Illicit activity in cryptocurrency has increased dramatically over the years. Bitcoin mechanics allow for users to mask their identity through obfuscation techniques. Much research has been published in the domain of identifying illicit activity in cryptocurrency, and in particular the emergence of Graph Neural Networks (GNNs) has shown great promise in this area. In this paper, we propose two graph preprocessing methods to improve performance and robustness of our node classification GNN models in identifying illicit transactions in the Bitcoin network. Our methods focus on graph restructuring through measuring the connectivity of nodes in a graph, and the similarity of the underlying features each node possesses. We demonstrate the graph restructuring methodologies on five GNN architectures and empirically show an improvement of evaluation metrics when compared against the unprocessed graph dataset. We compare our proposed methods against other imbalanced node classification techniques on a common graph dataset. This methodology has great opportunity in the transaction monitoring landscape for exchanges and financial institutions attempting to capture potential illicit activity taking place on their networks including money laundering.}
}


@inproceedings{DBLP:conf/acsac/SeveriBOHKM23,
	author = {Giorgio Severi and
                  Simona Boboila and
                  Alina Oprea and
                  John T. Holodnak and
                  Kendra Kratkiewicz and
                  Jason Matterer},
	title = {Poisoning Network Flow Classifiers},
	booktitle = {Annual Computer Security Applications Conference, {ACSAC} 2023, Austin,
                  TX, USA, December 4-8, 2023},
	pages = {337--351},
	publisher = {{ACM}},
	year = {2023},
	url = {https://doi.org/10.1145/3627106.3627123},
	doi = {10.1145/3627106.3627123},
	timestamp = {Sun, 10 Dec 2023 17:00:06 +0100},
	biburl = {https://dblp.org/rec/conf/acsac/SeveriBOHKM23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As machine learning (ML) classifiers increasingly oversee the automated monitoring of network traffic, studying their resilience against adversarial attacks becomes critical. This paper focuses on poisoning attacks, specifically backdoor attacks, against network traffic flow classifiers. We investigate the challenging scenario of clean-label poisoning where the adversary’s capabilities are constrained to tampering only with the training data — without the ability to arbitrarily modify the training labels or any other component of the training process. We describe a trigger crafting strategy that leverages model interpretability techniques to generate trigger patterns that are effective even at very low poisoning rates. Finally, we design novel strategies to generate stealthy triggers, including an approach based on generative Bayesian network models, with the goal of minimizing the conspicuousness of the trigger, and thus making detection of an ongoing poisoning campaign more challenging. Our findings provide significant insights into the feasibility of poisoning attacks on network traffic classifiers used in multiple scenarios, including detecting malicious communication and application classification.}
}


@inproceedings{DBLP:conf/acsac/LiGL0LXX23,
	author = {Sijia Li and
                  Gaopeng Gou and
                  Chang Liu and
                  Gang Xiong and
                  Zhen Li and
                  Junchao Xiao and
                  Xinyu Xing},
	title = {{TGC:} Transaction Graph Contrast Network for Ethereum Phishing Scam
                  Detection},
	booktitle = {Annual Computer Security Applications Conference, {ACSAC} 2023, Austin,
                  TX, USA, December 4-8, 2023},
	pages = {352--365},
	publisher = {{ACM}},
	year = {2023},
	url = {https://doi.org/10.1145/3627106.3627109},
	doi = {10.1145/3627106.3627109},
	timestamp = {Wed, 07 Feb 2024 17:25:00 +0100},
	biburl = {https://dblp.org/rec/conf/acsac/LiGL0LXX23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Phishing scams have become the most serious type of crime involved in Ethereum. However, existing methods ignore the natural camouflage and sparse distribution of phishing scams in Ethereum leading to unsatisfactory performance, and they are also limited by the data scale which cannot be applied to real-world dynamic scenarios. In this paper, we propose a Transaction Graph Contrast network (TGC) to enhance phishing scam detection performance on Ethereum. TGC inputs subgraphs instead of the entire graph for training, which eases the model’s requirements for machine configuration and data connectivity. Motivated by phishing nodes are surrounded by normal nodes, we design the comparison between node-level to help phishing nodes learn the unique properties of themselves different from their neighbors. Observing the small number and sparse distribution of phishing nodes, we narrow the distance between phishing nodes by comparing node context-level structures, so as to learn universal transaction patterns. We further combine the obtained features with common statistics to identify phishing addresses. Evaluated on real-world Ethereum phishing scams datasets, our TGC outperforms the state-of-the-art methods in detecting phishing addresses and has obvious advantages in large-scale and dynamic scenarios.}
}


@inproceedings{DBLP:conf/acsac/ChenAC23,
	author = {Yufan Chen and
                  Arjun Arunasalam and
                  Z. Berkay Celik},
	title = {Can Large Language Models Provide Security {\&} Privacy Advice?
                  Measuring the Ability of LLMs to Refute Misconceptions},
	booktitle = {Annual Computer Security Applications Conference, {ACSAC} 2023, Austin,
                  TX, USA, December 4-8, 2023},
	pages = {366--378},
	publisher = {{ACM}},
	year = {2023},
	url = {https://doi.org/10.1145/3627106.3627196},
	doi = {10.1145/3627106.3627196},
	timestamp = {Sun, 10 Dec 2023 17:00:07 +0100},
	biburl = {https://dblp.org/rec/conf/acsac/ChenAC23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Users seek security & privacy (S&P) advice from online resources, including trusted websites and content-sharing platforms. These resources help users understand S&P technologies and tools and suggest actionable strategies. Large Language Models (LLMs) have recently emerged as trusted information sources. However, their accuracy and correctness have been called into question. Prior research has outlined the shortcomings of LLMs in answering multiple-choice questions and user ability to inadvertently circumvent model restrictions (e.g., to produce toxic content). Yet, the ability of LLMs to provide reliable S&P advice is not well-explored.}
}


@inproceedings{DBLP:conf/acsac/SeonghunRB23,
	author = {Son Seonghun and
                  Debopriya Roy Dipta and
                  Berk G{\"{u}}lmezoglu},
	title = {DefWeb: Defending User Privacy against Cache-based Website Fingerprinting
                  Attacks with Intelligent Noise Injection},
	booktitle = {Annual Computer Security Applications Conference, {ACSAC} 2023, Austin,
                  TX, USA, December 4-8, 2023},
	pages = {379--393},
	publisher = {{ACM}},
	year = {2023},
	url = {https://doi.org/10.1145/3627106.3627191},
	doi = {10.1145/3627106.3627191},
	timestamp = {Wed, 29 May 2024 15:00:01 +0200},
	biburl = {https://dblp.org/rec/conf/acsac/SeonghunRB23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cache-based website fingerprinting (WF) attacks violate user privacy where the attacker leverages the shared last-level cache in CPUs and analyzes the fingerprints through machine learning and deep learning models. WF attacks are even applicable in Incognito and anonymized browser platforms, leading to a serious threat to the public. Several defense techniques inject random noise during website rendering to degrade the attack success rate, while these techniques either create large performance overhead or cannot obfuscate the WF dataset entirely when the attacker retrains a new learning model with noisy fingerprints.}
}


@inproceedings{DBLP:conf/acsac/LiuZM23,
	author = {Zihao Liu and
                  Yan Zhang and
                  Chenglin Miao},
	title = {Protecting Your Voice from Speech Synthesis Attacks},
	booktitle = {Annual Computer Security Applications Conference, {ACSAC} 2023, Austin,
                  TX, USA, December 4-8, 2023},
	pages = {394--408},
	publisher = {{ACM}},
	year = {2023},
	url = {https://doi.org/10.1145/3627106.3627183},
	doi = {10.1145/3627106.3627183},
	timestamp = {Sun, 10 Dec 2023 17:00:07 +0100},
	biburl = {https://dblp.org/rec/conf/acsac/LiuZM23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent years, much attention has been paid to speech synthesis, which aims to generate synthetic speeches in a voice of a target speaker. Although the speech synthesis technique has facilitated a wide spectrum of applications that positively impact our daily lives, it can also be used by attackers to perform speech synthesis attacks. An attacker can use this technique to mimic the voice of a victim and transform arbitrarily chosen text or voice samples into the same content spoken by the victim. To protect a speaker’s voice from speech synthesis attacks, in this paper, we propose two novel defense schemes that can be used by the speaker to process his or her speeches before publishing them on social media platforms or sending them to others. The processed speeches cannot only significantly degrade the performance of speech synthesis systems but also keep the sound of the speaker’s voice so that they can still be used for normal purposes. The desirable performance of the proposed defense schemes is verified through extensive experiments conducted on several real-world speaker recognition (SR) systems and a user study on a public crowdsourcing platform.}
}


@inproceedings{DBLP:conf/acsac/MuraliJSZJ0023,
	author = {Srinivasan Murali and
                  Wenqiang Jin and
                  Vighnesh Sivaraman and
                  Huadi Zhu and
                  Tianxi Ji and
                  Pan Li and
                  Ming Li},
	title = {Continuous Authentication Using Human-Induced Electric Potential},
	booktitle = {Annual Computer Security Applications Conference, {ACSAC} 2023, Austin,
                  TX, USA, December 4-8, 2023},
	pages = {409--423},
	publisher = {{ACM}},
	year = {2023},
	url = {https://doi.org/10.1145/3627106.3627124},
	doi = {10.1145/3627106.3627124},
	timestamp = {Sun, 10 Dec 2023 17:00:06 +0100},
	biburl = {https://dblp.org/rec/conf/acsac/MuraliJSZJ0023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Most terminal devices authenticate users only once at the time of initial login, leaving the terminal unprotected during an active session when the original user leaves it unattended. To address this issue, continuous authentication has been proposed by automatically locking the terminal after a period of inactivity. However, it does not fully eliminate the risk of unauthorized access before the session expires. Recent research has also investigated the feasibility of using physiological and behavioral patterns as biometrics. This study presents a novel two-factor continuous authentication that explores a new form of signal called human-induced electric potential captured by wearables in contact with the user’s body. By analyzing this signal, we can determine the time of user-terminal interactions and compare it with information recorded by the terminal’s OS. If the original user remains on the same terminal, the two-source readings would match. Additionally, the proposed scheme includes an extra layer of protection by extracting terminal’s physical fingerprints from the human-induced electric potential to defend against advanced mimicry attacks. To test the effectiveness of our design, a low-cost wearable prototype is developed. Through extensive experiments, it is found that the proposed scheme has a low error rate of 2.3%, with minimal computational and energy requirements.}
}


@inproceedings{DBLP:conf/acsac/Pourbemany023,
	author = {Jafar Pourbemany and
                  Ye Zhu},
	title = {Cross Body Signal Pairing {(CBSP):} {A} Key Generation Protocol for
                  Pairing Wearable Devices with Cardiac and Respiratory Sensors},
	booktitle = {Annual Computer Security Applications Conference, {ACSAC} 2023, Austin,
                  TX, USA, December 4-8, 2023},
	pages = {424--438},
	publisher = {{ACM}},
	year = {2023},
	url = {https://doi.org/10.1145/3627106.3627185},
	doi = {10.1145/3627106.3627185},
	timestamp = {Sun, 10 Dec 2023 17:00:07 +0100},
	biburl = {https://dblp.org/rec/conf/acsac/Pourbemany023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we propose a cross body signal pairing (CBSPCR) protocol to enable key generation between wearable devices with cardiac and respiratory sensors. Most previous pairing protocols require both wearable devices to access the same biometric signal for pairing. The restriction can greatly limit communication between wearable devices and the development of new applications on the devices. We implemented CBSPCR for pairing wearable devices based on respiratory and cardiac signals. Two pairing modes are proposed for the pairing: (1) The model-based pairing is based on mathematical models between respiratory and cardiac signals. (2) The extraction-based pairing is based on the extraction of respiratory signals from cardiac signals. The pairing performance of these two modes varies with exercise intensity. To take full advantage of both pairing modes, we developed a mode switching based on the respiration rate, a reliable indicator of exercise intensity level. CBSPCR uses Lloyd-Max quantization and a BCH-based mismatch correction method to digitize the signals and correct mismatches between bit-strings. Our extensive experiments with 30 participants show that CBSPCR can generate about 0.0125 keys per second with high resistance to impersonation attacks and negligible battery consumption.}
}


@inproceedings{DBLP:conf/acsac/SaeifSG23,
	author = {Saeif Alhazbi and
                  Savio Sciancalepore and
                  Gabriele Oligeri},
	title = {The Day-After-Tomorrow: On the Performance of Radio Fingerprinting
                  over Time},
	booktitle = {Annual Computer Security Applications Conference, {ACSAC} 2023, Austin,
                  TX, USA, December 4-8, 2023},
	pages = {439--450},
	publisher = {{ACM}},
	year = {2023},
	url = {https://doi.org/10.1145/3627106.3627192},
	doi = {10.1145/3627106.3627192},
	timestamp = {Sun, 10 Dec 2023 17:00:06 +0100},
	biburl = {https://dblp.org/rec/conf/acsac/SaeifSG23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The performance of Radio Frequency (RF) Fingerprinting (RFF) techniques is negatively impacted when the training data is not temporally close to the testing data. This can limit the practical implementation of physical-layer authentication solutions. To circumvent this problem, current solutions involve collecting training and testing datasets at close time intervals—this being detrimental to the real-life deployment of any physical-layer authentication solution. We refer to this issue as the Day-After-Tomorrow (DAT) effect, being widely attributed to the temporal variability of the wireless channel, which masks the physical-layer features of the transmitter, thus impairing the fingerprinting process.}
}


@inproceedings{DBLP:conf/acsac/DengHW23,
	author = {Zeyu Deng and
                  Long Huang and
                  Chen Wang},
	title = {Enhanced In-air Signature Verification via Hand Skeleton Tracking
                  to Defeat Robot-level Replays},
	booktitle = {Annual Computer Security Applications Conference, {ACSAC} 2023, Austin,
                  TX, USA, December 4-8, 2023},
	pages = {451--462},
	publisher = {{ACM}},
	year = {2023},
	url = {https://doi.org/10.1145/3627106.3627195},
	doi = {10.1145/3627106.3627195},
	timestamp = {Mon, 18 Dec 2023 11:22:01 +0100},
	biburl = {https://dblp.org/rec/conf/acsac/DengHW23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Behavioral biometrics has emerged as an important security factor for user authentication. Compared to static biometrics (e.g., faces, irises, and fingerprints), using human motion behaviors for authentication causes lower concern about privacy abuse, and behavior biometrics are shown hard to be replicated by humans. In-air 3D signature is one representative of behavioral biometrics. Specifically, a user’s hand movements can be tracked by visual or wireless sensors for contact-free signature authentication, where both the fingertip trajectory and the dynamic motion features are verified to provide enhanced security. However, with the advancement of 3D printing and robot technology, we find that 1) existing hand-tracking interfaces (e.g., Leap Motion and Google MediaPipe) are easily tricked by a fake hand, and 2) a robotic arm can reproduce a user’s in-air 3D signature with high similarity regarding both trajectory and motion behaviors. Thus, this work investigates the security of in-air signatures under robot-level replays and proposes to extend the signature verification from a single-point fingertip to multiple hand joints for enhanced security. We develop the hand skeleton-based 3D signature verification system, which can be deployed on any single camera devices (2D or 3D). The key insight is that current robots could hardly replicate the minute and unique inter-joint motions of a user. In particular, we track the hand skeleton using a single camera and reconstruct/draw the trajectories of its joints in a virtual 3D space, using the color gradients to represent time-lapse and using varying line widths to describe joint significance. Based on that, we extract the three-view skeleton signatures and inter-joint motion features and develop a convolutional neural network for verification. Extensive experiments show that our system not only achieves high authentication performance but also effectively mitigates robot-level replay attacks.}
}


@inproceedings{DBLP:conf/acsac/0021ZCPTLY23,
	author = {Yu Zheng and
                  Qizhi Zhang and
                  Sherman S. M. Chow and
                  Yuxiang Peng and
                  Sijun Tan and
                  Lichun Li and
                  Shan Yin},
	title = {Secure Softmax/Sigmoid for Machine-learning Computation},
	booktitle = {Annual Computer Security Applications Conference, {ACSAC} 2023, Austin,
                  TX, USA, December 4-8, 2023},
	pages = {463--476},
	publisher = {{ACM}},
	year = {2023},
	url = {https://doi.org/10.1145/3627106.3627175},
	doi = {10.1145/3627106.3627175},
	timestamp = {Sun, 10 Dec 2023 17:00:07 +0100},
	biburl = {https://dblp.org/rec/conf/acsac/0021ZCPTLY23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Softmax and sigmoid, composing exponential functions (ex) and division (1/x), are activation functions often required in training. Secure computation on non-linear, unbounded 1/x and ex is already challenging, let alone their composition. Prior works aim to compute softmax by its exact formula via iteration (CrypTen, NeurIPS ’21) or with ASM approximation (Falcon, PoPETS ’21). They fall short in efficiency and/or accuracy. For sigmoid, existing solutions such as ABY2.0 (Usenix Security ’21) compute it via piecewise functions, incurring logarithmic communication rounds.}
}


@inproceedings{DBLP:conf/acsac/WangW23,
	author = {Xiuling Wang and
                  Wendy Hui Wang},
	title = {Link Membership Inference Attacks against Unsupervised Graph Representation
                  Learning},
	booktitle = {Annual Computer Security Applications Conference, {ACSAC} 2023, Austin,
                  TX, USA, December 4-8, 2023},
	pages = {477--491},
	publisher = {{ACM}},
	year = {2023},
	url = {https://doi.org/10.1145/3627106.3627115},
	doi = {10.1145/3627106.3627115},
	timestamp = {Sun, 10 Dec 2023 17:00:07 +0100},
	biburl = {https://dblp.org/rec/conf/acsac/WangW23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Significant advancements have been made in recent years in the field of unsupervised graph representation learning (UGRL) approaches. UGRL involves representing large graphs as low-dimensional vectors, commonly referred to as embeddings. These embeddings can be publicly released or shared with third parties for downstream analytics. However, adversaries can deduce sensitive structural information from the target graph through its embedding using various types of privacy inference attacks. This paper investigates the privacy vulnerabilities of UGRL models through the lens of link membership inference attack (LMIA). Specifically, an LMIA adversary aims to infer whether any two nodes are connected in the target graph from the node embeddings generated by a UGRL model. To achieve this, we propose two LMIA attacks that leverage the properties of node embeddings and various forms of adversary knowledge for inference. By conducting experiments on four state-of-the-art UGRL models using five real-world graph datasets, we demonstrate the effectiveness of the two LMIA attacks against these UGRL models. Furthermore, we conduct a comprehensive analysis to examine how varying degrees of preserved structural information in the embeddings impact the performance of LMIA. To enhance the security of UGRL models against LMIA, we design a family of defense mechanisms that perturb the least significant dimensions of embeddings. Our experimental results show that our defense mechanism achieves a favorable balance between defense effectiveness and embedding quality.}
}


@inproceedings{DBLP:conf/acsac/TekgulA23,
	author = {Buse G. A. Tekgul and
                  N. Asokan},
	title = {{FLARE:} Fingerprinting Deep Reinforcement Learning Agents using Universal
                  Adversarial Masks},
	booktitle = {Annual Computer Security Applications Conference, {ACSAC} 2023, Austin,
                  TX, USA, December 4-8, 2023},
	pages = {492--505},
	publisher = {{ACM}},
	year = {2023},
	url = {https://doi.org/10.1145/3627106.3627128},
	doi = {10.1145/3627106.3627128},
	timestamp = {Sun, 10 Dec 2023 17:00:07 +0100},
	biburl = {https://dblp.org/rec/conf/acsac/TekgulA23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We propose FLARE, the first fingerprinting mechanism to verify whether a suspected Deep Reinforcement Learning (DRL) policy is an illegitimate copy of another (victim) policy. We first show that it is possible to find non-transferable, universal adversarial masks, i.e., perturbations, to generate adversarial examples that can successfully transfer from a victim policy to its modified versions but not to independently trained policies. FLARE employs these masks as fingerprints to verify the true ownership of stolen DRL policies by measuring an action agreement value over states perturbed by such masks. Our empirical evaluations show that FLARE is effective (100% action agreement on stolen copies) and does not falsely accuse independent policies (no false positives). FLARE is also robust to model modification attacks and cannot be easily evaded by more informed adversaries without negatively impacting agent performance. We also show that not all universal adversarial masks are suitable candidates for fingerprints due to the inherent characteristics of DRL policies. The spatio-temporal dynamics of DRL problems and sequential decision-making process make characterizing the decision boundary of DRL policies more difficult, as well as searching for universal masks that capture the geometry of it.}
}


@inproceedings{DBLP:conf/acsac/QuiringMR23,
	author = {Erwin Quiring and
                  Andreas M{\"{u}}ller and
                  Konrad Rieck},
	title = {On the Detection of Image-Scaling Attacks in Machine Learning},
	booktitle = {Annual Computer Security Applications Conference, {ACSAC} 2023, Austin,
                  TX, USA, December 4-8, 2023},
	pages = {506--520},
	publisher = {{ACM}},
	year = {2023},
	url = {https://doi.org/10.1145/3627106.3627134},
	doi = {10.1145/3627106.3627134},
	timestamp = {Sun, 10 Dec 2023 17:00:06 +0100},
	biburl = {https://dblp.org/rec/conf/acsac/QuiringMR23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Image scaling is an integral part of machine learning and computer vision systems. Unfortunately, this preprocessing step is vulnerable to so-called image-scaling attacks where an attacker makes unnoticeable changes to an image so that it becomes a new image after scaling. This opens up new ways for attackers to control the prediction or to improve poisoning and backdoor attacks. While effective techniques exist to prevent scaling attacks, their detection has not been rigorously studied yet. Consequently, it is currently not possible to reliably spot these attacks in practice.}
}


@inproceedings{DBLP:conf/acsac/WeeksCAKYV23,
	author = {Connor Weeks and
                  Aravind Cheruvu and
                  Sifat Muhammad Abdullah and
                  Shravya Kanchi and
                  Daphne Yao and
                  Bimal Viswanath},
	title = {A First Look at Toxicity Injection Attacks on Open-domain Chatbots},
	booktitle = {Annual Computer Security Applications Conference, {ACSAC} 2023, Austin,
                  TX, USA, December 4-8, 2023},
	pages = {521--534},
	publisher = {{ACM}},
	year = {2023},
	url = {https://doi.org/10.1145/3627106.3627122},
	doi = {10.1145/3627106.3627122},
	timestamp = {Sun, 10 Dec 2023 17:00:07 +0100},
	biburl = {https://dblp.org/rec/conf/acsac/WeeksCAKYV23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Chatbot systems have improved significantly because of the advances made in language modeling. These machine learning systems follow an end-to-end data-driven learning paradigm and are trained on large conversational datasets. Imperfections or harmful biases in the training datasets can cause the models to learn toxic behavior, and thereby expose their users to harmful responses. Prior work has focused on measuring the inherent toxicity of such chatbots, by devising queries that are more likely to produce toxic responses. In this work, we ask the question: How easy or hard is it to inject toxicity into a chatbot after deployment? We study this in a practical scenario known as Dialog-based Learning (DBL), where a chatbot is periodically trained on recent conversations with its users after deployment. A DBL setting can be exploited to poison the training dataset for each training cycle. Our attacks would allow an adversary to manipulate the degree of toxicity in a model and also enable control over what type of queries can trigger a toxic response. Our fully automated attacks only require LLM-based software agents masquerading as (malicious) users to inject high levels of toxicity. We systematically explore the vulnerability of popular chatbot pipelines to this threat. Lastly, we show that several existing toxicity mitigation strategies (designed for chatbots) can be significantly weakened by adaptive attackers.}
}


@inproceedings{DBLP:conf/acsac/ParkAWMGKN23,
	author = {Seonhye Park and
                  Alsharif Abuadbba and
                  Shuo Wang and
                  Kristen Moore and
                  Yansong Gao and
                  Hyoungshick Kim and
                  Surya Nepal},
	title = {DeepTaster: Adversarial Perturbation-Based Fingerprinting to Identify
                  Proprietary Dataset Use in Deep Neural Networks},
	booktitle = {Annual Computer Security Applications Conference, {ACSAC} 2023, Austin,
                  TX, USA, December 4-8, 2023},
	pages = {535--549},
	publisher = {{ACM}},
	year = {2023},
	url = {https://doi.org/10.1145/3627106.3627204},
	doi = {10.1145/3627106.3627204},
	timestamp = {Mon, 18 Dec 2023 11:22:01 +0100},
	biburl = {https://dblp.org/rec/conf/acsac/ParkAWMGKN23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Training deep neural networks (DNNs) requires large datasets and powerful computing resources, which has led some owners to restrict redistribution without permission. Watermarking techniques that embed confidential data into DNNs have been used to protect ownership, but these can degrade model performance and are vulnerable to watermark removal attacks. Recently, DeepJudge was introduced as an alternative approach to measuring the similarity between a suspect and a victim model. While DeepJudge shows promise in addressing the shortcomings of watermarking, it primarily addresses situations where the suspect model copies the victim’s architecture. In this study, we introduce DeepTaster, a novel DNN fingerprinting technique, to address scenarios where a victim’s data is unlawfully used to build a suspect model. DeepTaster can effectively identify such DNN model theft attacks, even when the suspect model’s architecture deviates from the victim’s. To accomplish this, DeepTaster generates adversarial images with perturbations, transforms them into the Fourier frequency domain, and uses these transformed images to identify the dataset used in a suspect model. The underlying premise is that adversarial images can capture the unique characteristics of DNNs built with a specific dataset. To demonstrate the effectiveness of DeepTaster, we evaluated the effectiveness of DeepTaster by assessing its detection accuracy on three datasets (CIFAR10, MNIST, and Tiny-ImageNet) across three model architectures (ResNet18, VGG16, and DenseNet161). We conducted experiments under various attack scenarios, including transfer learning, pruning, fine-tuning, and data augmentation. Specifically, in the Multi-Architecture Attack scenario, DeepTaster was able to identify all the stolen cases across all datasets, while DeepJudge failed to detect any of the cases.}
}


@inproceedings{DBLP:conf/acsac/ChiAR23,
	author = {Andrew Chi and
                  Blake Anderson and
                  Michael K. Reiter},
	title = {Prioritizing Remediation of Enterprise Hosts by Malware Execution
                  Risk},
	booktitle = {Annual Computer Security Applications Conference, {ACSAC} 2023, Austin,
                  TX, USA, December 4-8, 2023},
	pages = {550--564},
	publisher = {{ACM}},
	year = {2023},
	url = {https://doi.org/10.1145/3627106.3627180},
	doi = {10.1145/3627106.3627180},
	timestamp = {Sun, 10 Dec 2023 17:00:06 +0100},
	biburl = {https://dblp.org/rec/conf/acsac/ChiAR23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Defending an enterprise network requires making prioritization decisions daily; one is deciding which compromised hosts to remediate (reimage). We study the utility of endpoint monitoring data to perform this prioritization, with the driving goal being to minimize “regret” as measured by future (next-week) malware execution on hosts whose remediation was deprioritized. Leveraging data gathered by the vendor of a major endpoint protection product, we show that it is possible to prioritize remediation by training a classifier that predicts imminent malware execution. Perhaps surprisingly, while it might seem essential to maximize the amount of training data by collecting across an array of enterprises to which endpoint protection is deployed, at least in the case of the endpoint protection vendor (itself a major, worldwide company), predictive performance for a single enterprise can remain excellent when training is restricted to the enterprise itself. One advantage of single-enterprise training is the ease of combining different views of the hosts, such as via file-based and network-based monitoring. In the cases studied, although an exact comparison was impossible due to a time gap, the single-enterprise dataset with richer features resulted in superior prediction of malware execution compared to the multi-enterprise dataset.}
}


@inproceedings{DBLP:conf/acsac/ZhangDNBBS23,
	author = {Yizhe Zhang and
                  Hongying Dong and
                  Alastair Nottingham and
                  Molly Buchanan and
                  Donald E. Brown and
                  Yixin Sun},
	title = {Global Analysis with Aggregation-based Beaconing Detection across
                  Large Campus Networks},
	booktitle = {Annual Computer Security Applications Conference, {ACSAC} 2023, Austin,
                  TX, USA, December 4-8, 2023},
	pages = {565--579},
	publisher = {{ACM}},
	year = {2023},
	url = {https://doi.org/10.1145/3627106.3627126},
	doi = {10.1145/3627106.3627126},
	timestamp = {Sun, 10 Dec 2023 17:00:06 +0100},
	biburl = {https://dblp.org/rec/conf/acsac/ZhangDNBBS23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We present a new approach to effectively detect and prioritize malicious beaconing activities in large campus networks by profiling the server activities through aggregated signals across multiple traffic protocols and networks. Key components of our system include a novel time-series analysis algorithm that uncovers hidden periodicity in aggregated signals, and a ranking-based detection pipeline that utilizes self-training and active-learning techniques. We evaluate our detection system on 10 months of real-world traffic collected at two large campus networks, comprising over 75 billion connections. On a daily average, we detect 43% more periodic domains by aggregating signals across multiple networks compared to single-network analysis. Furthermore, our ranking pipeline successfully identifies 1,387 unique malicious domains, out of which 781 (56%) were unknown to the major online threat intelligence platform, VirusTotal, at the time of our detection.}
}


@inproceedings{DBLP:conf/acsac/ZhanBLHZGP23,
	author = {Dazhi Zhan and
                  Wei Bai and
                  Xin Liu and
                  Yue Hu and
                  Lei Zhang and
                  Shize Guo and
                  Zhisong Pan},
	title = {PSP-Mal: Evading Malware Detection via Prioritized Experience-based
                  Reinforcement Learning with Shapley Prior},
	booktitle = {Annual Computer Security Applications Conference, {ACSAC} 2023, Austin,
                  TX, USA, December 4-8, 2023},
	pages = {580--593},
	publisher = {{ACM}},
	year = {2023},
	url = {https://doi.org/10.1145/3627106.3627178},
	doi = {10.1145/3627106.3627178},
	timestamp = {Thu, 21 Dec 2023 15:38:27 +0100},
	biburl = {https://dblp.org/rec/conf/acsac/ZhanBLHZGP23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the widespread application of machine learning techniques in malware detection, researchers have proposed various adversarial attack methods to generate adversarial examples (AEs) of malware, thereby evading detection. Previous studies have shown that the reinforcement learning (RL) framework can enable black-box attacks by performing a sequence of function-preserving operations, which produces functional evasive malware samples. However, it is difficult to obtain the useful guidance and feedbacks from the environment for agent training in the black-box scenario, which results in the RL framework being unable to learn the effective evasion policy. In this paper, we propose the Shapley prior and establish a prior-guidance-based RL framework, namely PSP-Mal, to generate AEs against Portable Executable (PE) malware detectors. Our framework improves on existing methods in three aspects: 1) We explore feature effects of the black-box model by computing Shapley values and further propose the Shapley prior to represent the expected impact of operations. 2) A novel prioritized experience utilization mechanism is established regarding the Shapley prior guidance in the RL framework. 3) The actions are expanded into item-content pairs and we use the Thompson sampling to choose effective content, which helps to reduce randomness and ensure repeatability. We compare the attack performance of our framework with other methods, and experimental results demonstrate that our algorithm is more effective. The evasion rates of PSP-Mal against the LightGBM models trained on EMBER and SOREL-20M reach 76.88% and 72.03%, respectively.}
}


@inproceedings{DBLP:conf/acsac/SeeG0K23,
	author = {Richard August See and
                  Maximilian Gehring and
                  Mathias Fischer and
                  Shankar Karuppayah},
	title = {Binary Sight-Seeing: Accelerating Reverse Engineering via Point-of-Interest-Beacons},
	booktitle = {Annual Computer Security Applications Conference, {ACSAC} 2023, Austin,
                  TX, USA, December 4-8, 2023},
	pages = {594--608},
	publisher = {{ACM}},
	year = {2023},
	url = {https://doi.org/10.1145/3627106.3627139},
	doi = {10.1145/3627106.3627139},
	timestamp = {Sun, 10 Dec 2023 17:00:06 +0100},
	biburl = {https://dblp.org/rec/conf/acsac/SeeG0K23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Reverse engineering is still a largely manual and very time-consuming process. To ease this process, beacons in the form of known instructions or code patterns are commonly used to guide reverse engineers in dissecting a binary. However, if done manually, identifying high-quality beacons can be very laborious. This paper introduces a novel method to automatically identify the so-called Points-of-Interests (POIs) in binaries. POIs are instructions that interact with data specified by the analyst known a priori, e.g., via sandbox analysis or expert knowledge. These POIs are then used as beacons to guide analysts to find interesting parts of the binary that interact with the specified data, e.g., the encryption routine. Compared to taint analysis, our approach offers simplicity while delivering a select few, yet high-quality beacons, thereby establishing clear focus points. Based on our proposed method, we implemented two types of prototypes. First, a prototype whose output can be loaded via custom plugins into IDA and Ghidra, i.e., two of the more popular reverse-engineering tools. We show the applicability of our method via the prototype by summarizing the insights of the analysis for the Locky and Wannacry ransomware as one of the potential application domains, i.e., malware reverse engineering. Second, we also introduced a prototype that monitors P2P botnets in a fully-automated manner by directly instrumenting the botnet malware without requiring manual reverse-engineering. We demonstrate the effectiveness of our prototype by applying it to the ZeroAccess, Sality, Nugache, and Kelihos botnets and summarize our findings in this paper. Using our approach, we effortlessly found the encryption function in the two analyzed ransomware. For P2P botnets, our monitoring prototype could enumerate the bots in all analyzed botnets, only relying on our POIs.}
}


@inproceedings{DBLP:conf/acsac/ZhuangZTLWZ023,
	author = {Xirong Zhuang and
                  Lan Zhang and
                  Chen Tang and
                  Huiqi Liu and
                  Bin Wang and
                  Yan Zheng and
                  Bo Ren},
	title = {DeepContract: Controllable Authorization of Deep Learning Models},
	booktitle = {Annual Computer Security Applications Conference, {ACSAC} 2023, Austin,
                  TX, USA, December 4-8, 2023},
	pages = {609--620},
	publisher = {{ACM}},
	year = {2023},
	url = {https://doi.org/10.1145/3627106.3627107},
	doi = {10.1145/3627106.3627107},
	timestamp = {Fri, 22 Dec 2023 16:43:30 +0100},
	biburl = {https://dblp.org/rec/conf/acsac/ZhuangZTLWZ023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Well-trained deep learning (DL) models are widely used in various fields and recognized as valuable intellectual property. However, most existing efforts to fully exploit their value either require users to upload input data to provide machine learning services, which raises serious privacy concerns, or deploy DL models on the user side, resulting in a loss of control over the models. While a few active model authorization methods protect the model from unauthorized users, they cannot prevent the model from being redistributed or abused by authorized users. To address the urgent need to efficiently protect both model confidentiality and input data privacy, and achieve uninterrupted model controllability, we propose a contract-based model authorization framework called DeepContract. This framework enables model owners to deploy their models on the user side for local inference without revealing original model weights. Moreover, it allows them to grant and revoke the right to use their models at any time. Specifically, we propose a generic model encryption method that significantly outperforms the state-of-the-art method in both efficiency and security. Leveraging the integrity verification in the Trusted Execution Environment, contract-based and verifiable enclave codes generated by DeepContract can perform controlled inference using the encrypted model distributed on the user side. Our extensive evaluations show that DeepContract can achieve efficient and secure controllable model authorization for the pre-signed contract.}
}


@inproceedings{DBLP:conf/acsac/LiLG23,
	author = {Fabing Li and
                  Xiang Li and
                  Mingyu Gao},
	title = {Secure MLaaS with Temper: Trusted and Efficient Model Partitioning
                  and Enclave Reuse},
	booktitle = {Annual Computer Security Applications Conference, {ACSAC} 2023, Austin,
                  TX, USA, December 4-8, 2023},
	pages = {621--635},
	publisher = {{ACM}},
	year = {2023},
	url = {https://doi.org/10.1145/3627106.3627145},
	doi = {10.1145/3627106.3627145},
	timestamp = {Thu, 14 Dec 2023 17:38:23 +0100},
	biburl = {https://dblp.org/rec/conf/acsac/LiLG23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Machine Learning as a Service (MLaaS) is becoming a highly available and cost-efficient way to embrace machine learning techniques in various domains. But it suffers from data privacy risks as user data must be uploaded to untrusted clouds. We propose a trusted and efficient MLaaS system, Temper, based on secure hardware enclaves such as Intel SGX. Temper significantly improves the performance without sacrificing the data security guarantees or the model inference accuracy. With the two key techniques of enclave reuse and model partitioning, it reduces the enclave initialization and model loading costs, and alleviates the secure paging overheads due to the limited hardware-protected memory capacity in SGX. We also provide rigorous security guarantees for enclave sharing and batched processing, by ensuring stateless, non-interference, and data-oblivious processing and data transfers across model partitions. Temper achieves on average 2.2 × and 1.8 × improvements over the state-of-the-art designs for latency and throughput, respectively, and within 2.1 × slowdown of untrusted native execution. Its distributed paradigm provides a more scalable way for future MLaaS with large models.}
}


@inproceedings{DBLP:conf/acsac/CuiM23,
	author = {Bo Cui and
                  Tianyu Mei},
	title = {{ABFL:} {A} Blockchain-enabled Robust Framework for Secure and Trustworthy
                  Federated Learning},
	booktitle = {Annual Computer Security Applications Conference, {ACSAC} 2023, Austin,
                  TX, USA, December 4-8, 2023},
	pages = {636--646},
	publisher = {{ACM}},
	year = {2023},
	url = {https://doi.org/10.1145/3627106.3627121},
	doi = {10.1145/3627106.3627121},
	timestamp = {Sun, 10 Dec 2023 17:00:06 +0100},
	biburl = {https://dblp.org/rec/conf/acsac/CuiM23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The demand for effective, safe, and privacy-preserving machine learning methods has increased due to the rapid growth of large pre-trained models in recent years. In large-scale AI applications, federated learning (FL) has emerged as a cutting-edge method for addressing privacy and data silos issues. However, FL systems are vulnerable to poisoning attacks, and centralized master-slave architectures have reliability, fairness, and security limitations. We propose a secure and efficient decentralized FL framework called ABFL to address these challenges. The framework tightly integrates FL with blockchain technology to strengthen data ownership guarantees and significantly lessen the negative impact of malicious nodes on the global model. Using historical data stored on the blockchain, ABFL enables model update prediction and identifies malicious nodes by verifying consistency. In addition, we present a novel agent consensus mechanism to lower the expense of model cross-validation and increase consensus efficiency. The ABFL framework’s robustness to various sophisticated poisoning attacks while maintaining high model performance and increasing consensus efficiency is demonstrated in a comprehensive analysis of three benchmark datasets.}
}


@inproceedings{DBLP:conf/acsac/CastilloRF0S23,
	author = {Jorge Castillo and
                  Phillip Rieger and
                  Hossein Fereidooni and
                  Qian Chen and
                  Ahmad{-}Reza Sadeghi},
	title = {{FLEDGE:} Ledger-based Federated Learning Resilient to Inference and
                  Backdoor Attacks},
	booktitle = {Annual Computer Security Applications Conference, {ACSAC} 2023, Austin,
                  TX, USA, December 4-8, 2023},
	pages = {647--661},
	publisher = {{ACM}},
	year = {2023},
	url = {https://doi.org/10.1145/3627106.3627194},
	doi = {10.1145/3627106.3627194},
	timestamp = {Fri, 05 Apr 2024 08:54:10 +0200},
	biburl = {https://dblp.org/rec/conf/acsac/CastilloRF0S23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated learning (FL) is a distributed learning process that uses a trusted aggregation server to allow multiple parties (or clients) to collaboratively train a machine learning model without having them share their private data. Recent research, however, has demonstrated the effectiveness of inference and poisoning attacks on FL. Mitigating both attacks simultaneously is very challenging. State-of-the-art solutions have proposed the use of poisoning defenses with Secure Multi-Party Computation (SMPC) and/or Differential Privacy (DP). However, these techniques are not efficient and fail to address the malicious intent behind the attacks, i.e., adversaries (curious servers and/or compromised clients) seek to exploit a system for monetization purposes. To overcome these limitations, we present a ledger-based FL framework known as FLEDGE that allows making parties accountable for their behavior and achieve reasonable efficiency for mitigating inference and poisoning attacks. Our solution leverages crypto-currency to increase party accountability by penalizing malicious behavior and rewarding benign conduct. We conduct an extensive evaluation on four public datasets: Reddit, MNIST, Fashion-MNIST, and CIFAR-10. Our experimental results demonstrate that (1) FLEDGE provides strong privacy guarantees for model updates without sacrificing model utility; (2) FLEDGE can successfully mitigate different poisoning attacks without degrading the performance of the global model; and (3) FLEDGE offers unique reward mechanisms to promote benign behavior during model training and/or model aggregation.}
}


@inproceedings{DBLP:conf/acsac/MaarSRGM23,
	author = {Lukas Maar and
                  Martin Schwarzl and
                  Fabian Rauscher and
                  Daniel Gruss and
                  Stefan Mangard},
	title = {{DOPE:} DOmain Protection Enforcement with {PKS}},
	booktitle = {Annual Computer Security Applications Conference, {ACSAC} 2023, Austin,
                  TX, USA, December 4-8, 2023},
	pages = {662--676},
	publisher = {{ACM}},
	year = {2023},
	url = {https://doi.org/10.1145/3627106.3627113},
	doi = {10.1145/3627106.3627113},
	timestamp = {Sun, 10 Dec 2023 17:00:06 +0100},
	biburl = {https://dblp.org/rec/conf/acsac/MaarSRGM23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The number of Linux kernel vulnerabilities discovered has increased drastically over the past years. In the kernel, even simple memory safety vulnerabilities can have devastating consequences, e.g., compromising the entire system. Efforts to mitigate these vulnerabilities have so far focused mainly on control-flow hijacking attacks in the kernel. Yet, data-oriented attacks remain largely unmitigated in practice as existing mitigations are limited in providing robust security guarantees at reasonable performance overhead for multiple sensitive data objects.}
}


@inproceedings{DBLP:conf/acsac/FranzenWG23,
	author = {Fabian Franzen and
                  Andreas Chris Wilhelmer and
                  Jens Grossklags},
	title = {RandCompile: Removing Forensic Gadgets from the Linux Kernel to Combat
                  its Analysis},
	booktitle = {Annual Computer Security Applications Conference, {ACSAC} 2023, Austin,
                  TX, USA, December 4-8, 2023},
	pages = {677--690},
	publisher = {{ACM}},
	year = {2023},
	url = {https://doi.org/10.1145/3627106.3627197},
	doi = {10.1145/3627106.3627197},
	timestamp = {Sun, 10 Dec 2023 17:00:06 +0100},
	biburl = {https://dblp.org/rec/conf/acsac/FranzenWG23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recently proposed tools such as LogicMem, Katana, and AutoProfile enable a fine-grained inspection of the operating system’s memory. They provide insights that were previously only available for Linux machines specifically instrumented for cooperation with virtual machine introspection frameworks. An overly controlling cloud operator can now regularly deep-inspect VMs under their control.}
}


@inproceedings{DBLP:conf/acsac/MahmudKC0TM23,
	author = {Farabi Mahmud and
                  Sungkeun Kim and
                  Harpreet Singh Chawla and
                  Eun Jung Kim and
                  Chia{-}Che Tsai and
                  Abdullah Muzahid},
	title = {Attack of the Knights: Non Uniform Cache Side Channel Attack},
	booktitle = {Annual Computer Security Applications Conference, {ACSAC} 2023, Austin,
                  TX, USA, December 4-8, 2023},
	pages = {691--703},
	publisher = {{ACM}},
	year = {2023},
	url = {https://doi.org/10.1145/3627106.3627199},
	doi = {10.1145/3627106.3627199},
	timestamp = {Sun, 10 Dec 2023 17:00:07 +0100},
	biburl = {https://dblp.org/rec/conf/acsac/MahmudKC0TM23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {For a distributed last-level cache (LLC) in a large multicore chip, the access time to one LLC bank can significantly differ from that to another due to the difference in physical distance. In this paper, we successfully demonstrate a new distance-based side-channel attack by timing the AES decryption operation and extracting part of an AES secret key on an Intel Knights Landing CPU. We introduce several techniques to overcome the challenges of the attack, including the use of multiple attack threads to ensure LLC hits, to detect vulnerable memory locations, and to obtain fine-grained timing of the victim operations. While operating as a covert channel, this attack can reach a bandwidth of 205 KBPS with an error rate of only 0.02%. We also observed that the side-channel attack can extract 4 bytes of an AES key with 100% accuracy with only 4000 trial rounds of encryption.}
}


@inproceedings{DBLP:conf/acsac/GanzIHR23,
	author = {Tom Ganz and
                  Erik Imgrund and
                  Martin H{\"{a}}rterich and
                  Konrad Rieck},
	title = {{PAVUDI:} Patch-based Vulnerability Discovery using Machine Learning},
	booktitle = {Annual Computer Security Applications Conference, {ACSAC} 2023, Austin,
                  TX, USA, December 4-8, 2023},
	pages = {704--717},
	publisher = {{ACM}},
	year = {2023},
	url = {https://doi.org/10.1145/3627106.3627188},
	doi = {10.1145/3627106.3627188},
	timestamp = {Sun, 10 Dec 2023 17:00:07 +0100},
	biburl = {https://dblp.org/rec/conf/acsac/GanzIHR23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Machine learning has been increasingly adopted for automatic security vulnerability discovery in research and industry. The ability to automatically identify and prioritize bugs in patches is crucial to organizations seeking to defend against potential threats. Previous works, however only consider bug discovery on statement, function or file level. How one would apply them to patches in realistic scenarios remains unclear. This paper presents a novel deep learning-based approach leveraging an interprocedural patch graph representation and graph neural networks to analyze software patches for identifying and locating potential security vulnerabilities. We modify current state-of-the-art learning-based static analyzers to be applicable to patches and show that our patch-based vulnerability discovery method, a context and flow-sensitive learning-based model, has a more than increased detection performance, is twice as robust against concept drift after model deployment and is particularly better suited for analyzing large patches. In comparison, other methods already lose their efficiency when a patch touches more than five methods.}
}


@inproceedings{DBLP:conf/acsac/EckelGGK23,
	author = {Michael Eckel and
                  Dominik Roy George and
                  Bj{\"{o}}rn Grohmann and
                  Christoph Krau{\ss}},
	title = {Remote Attestation with Constrained Disclosure},
	booktitle = {Annual Computer Security Applications Conference, {ACSAC} 2023, Austin,
                  TX, USA, December 4-8, 2023},
	pages = {718--731},
	publisher = {{ACM}},
	year = {2023},
	url = {https://doi.org/10.1145/3627106.3627118},
	doi = {10.1145/3627106.3627118},
	timestamp = {Sun, 10 Dec 2023 17:00:06 +0100},
	biburl = {https://dblp.org/rec/conf/acsac/EckelGGK23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Trusted Platform Modules (TPMs) are used for remote attestation to ensure the authenticity and integrity of software running on a computer system. However, measuring software executed as containers or virtual machines can be challenging as it is measured concurrently, resulting in a jumbled measurement log that is difficult to disentangle. Moreover, disclosing the entire measurement log in traditional binary remote attestation raises privacy and intellectual property concerns. To address these issues, we propose a remote attestation method with constrained disclosure, allowing for selective disclosure of entries in the measurement log using a non-interactive zero-knowledge (NIZK) proof with Schnorr signatures. Our approach is evaluated for security and privacy and proven to be correct, sound, and satisfies the properties of a NIZK proof. Formal verification of our solution with ProVerif also supports our claims. Furthermore, the performance evaluation of our proof-of-concept implementation shows that our contribution is feasible, and the overhead introduced is negligible.}
}


@inproceedings{DBLP:conf/acsac/NarayananCRABYF23,
	author = {Vikram Narayanan and
                  Cl{\'{a}}udio Carvalho and
                  Angelo Ruocco and
                  Gheorghe Alm{\'{a}}si and
                  James Bottomley and
                  Mengmei Ye and
                  Tobin Feldman{-}Fitzthum and
                  Daniele Buono and
                  Hubertus Franke and
                  Anton Burtsev},
	title = {Remote attestation of confidential VMs using ephemeral vTPMs},
	booktitle = {Annual Computer Security Applications Conference, {ACSAC} 2023, Austin,
                  TX, USA, December 4-8, 2023},
	pages = {732--743},
	publisher = {{ACM}},
	year = {2023},
	url = {https://doi.org/10.1145/3627106.3627112},
	doi = {10.1145/3627106.3627112},
	timestamp = {Sun, 10 Dec 2023 17:00:06 +0100},
	biburl = {https://dblp.org/rec/conf/acsac/NarayananCRABYF23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Trying to address the security challenges of a cloud-centric software deployment paradigm, silicon and cloud vendors are introducing confidential computing – an umbrella term aimed at providing hardware and software mechanisms for protecting cloud workloads from the cloud provider and its software stack. Today, Intel Software Guard Extensions (SGX), AMD secure encrypted virtualization (SEV), Intel trust domain extensions (TDX), etc., provide a way to shield cloud applications from the cloud provider through encryption of the application’s memory below the hardware boundary of the CPU, hence requiring trust only in the CPU vendor. Unfortunately, existing hardware mechanisms do not automatically enable the guarantee that a protected system was not tampered with during configuration and boot time. Such a guarantee relies on a hardware root of trust, i.e., an integrity-protected location that can store measurements in a trustworthy manner, extend them, and authenticate the measurement logs to the user (remote attestation).}
}


@inproceedings{DBLP:conf/acsac/BriongosKSW23,
	author = {Samira Briongos and
                  Ghassan Karame and
                  Claudio Soriente and
                  Annika Wilde},
	title = {No Forking Way: Detecting Cloning Attacks on Intel {SGX} Applications},
	booktitle = {Annual Computer Security Applications Conference, {ACSAC} 2023, Austin,
                  TX, USA, December 4-8, 2023},
	pages = {744--758},
	publisher = {{ACM}},
	year = {2023},
	url = {https://doi.org/10.1145/3627106.3627187},
	doi = {10.1145/3627106.3627187},
	timestamp = {Sun, 10 Dec 2023 17:00:06 +0100},
	biburl = {https://dblp.org/rec/conf/acsac/BriongosKSW23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Forking attacks against TEEs like Intel SGX can be carried out either by rolling back the application to a previous state, or by cloning the application and by partitioning its inputs across the cloned instances. Current solutions to forking attacks require Trusted Third Parties (TTP) that are hard to find in real-world deployments. In the absence of a TTP, many TEE applications rely on monotonic counters to mitigate forking attacks based on rollbacks; however, they have no protection mechanism against forking attack based on cloning. In this paper, we analyze 72 SGX applications and show that approximately 20% of those are vulnerable to forking attacks based on cloning—including those that rely on monotonic counters.}
}


@inproceedings{DBLP:conf/acsac/ChiEM23,
	author = {Andrew Chi and
                  Brandon Enright and
                  David A. McGrew},
	title = {Detecting Weak Keys in Manufacturing Certificates: {A} Case Study},
	booktitle = {Annual Computer Security Applications Conference, {ACSAC} 2023, Austin,
                  TX, USA, December 4-8, 2023},
	pages = {759--771},
	publisher = {{ACM}},
	year = {2023},
	url = {https://doi.org/10.1145/3627106.3627120},
	doi = {10.1145/3627106.3627120},
	timestamp = {Sun, 10 Dec 2023 17:00:06 +0100},
	biburl = {https://dblp.org/rec/conf/acsac/ChiEM23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Weak entropy is an industry-wide challenge for network device vendors. We conducted a large scale analysis of RSA keys in about 226 million device certificates from one vendor, covering products that were manufactured over a 12-year time period. By focusing on specific data features of the manufacturing certificates, we tested for common keys and common factors across distinct devices. The scale of our analysis enabled the detection of entropy failures that manifested in the RSA keys of millions of devices. The affected devices included several products not implicated in any prior studies, resulting in the discovery of three new vulnerabilities in actively supported products. The entropy failures were complex, resulting from both low initial entropy and the faulty composition of manufacturing processes. Most affected product families were lower-margin devices past their end-of-support date; higher-end products that used a vendor-sanctioned hardware entropy source did not exhibit these weaknesses. However, our findings warrant more proactive and systematic entropy testing by device vendors.}
}


@inproceedings{DBLP:conf/acsac/Chen00ZJL23,
	author = {Joann Qiongna Chen and
                  Tianhao Wang and
                  Zhikun Zhang and
                  Yang Zhang and
                  Somesh Jha and
                  Zhou Li},
	title = {Differentially Private Resource Allocation},
	booktitle = {Annual Computer Security Applications Conference, {ACSAC} 2023, Austin,
                  TX, USA, December 4-8, 2023},
	pages = {772--786},
	publisher = {{ACM}},
	year = {2023},
	url = {https://doi.org/10.1145/3627106.3627181},
	doi = {10.1145/3627106.3627181},
	timestamp = {Thu, 25 Jan 2024 16:11:16 +0100},
	biburl = {https://dblp.org/rec/conf/acsac/Chen00ZJL23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recent studies have shown that systems with limited resources like Metadata-private Messenger (MPM) suffer from side-channel attacks under resource allocation (RA). In the case of MPM, which is designed to keep the identities and activities of both callers and callees private from network adversaries, an attacker can compromise a victim’s friends and keep calling the victim to infer whether the victim is busy, which breaks the privacy guarantee of MPM.}
}


@inproceedings{DBLP:conf/acsac/TanX0023,
	author = {Mingtian Tan and
                  Xiaofei Xie and
                  Jun Sun and
                  Tianhao Wang},
	title = {Mitigating Membership Inference Attacks via Weighted Smoothing},
	booktitle = {Annual Computer Security Applications Conference, {ACSAC} 2023, Austin,
                  TX, USA, December 4-8, 2023},
	pages = {787--798},
	publisher = {{ACM}},
	year = {2023},
	url = {https://doi.org/10.1145/3627106.3627189},
	doi = {10.1145/3627106.3627189},
	timestamp = {Sun, 10 Dec 2023 17:00:06 +0100},
	biburl = {https://dblp.org/rec/conf/acsac/TanX0023.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recent advancements in deep learning have spotlighted a crucial privacy vulnerability to membership inference attack (MIA), where adversaries can determine if specific data was present in a training set, thus potentially revealing sensitive information. In this paper, we introduce a technique, weighted smoothing (WS), to mitigate MIA risks. Our approach is anchored on the observation that training samples differ in their vulnerability to MIA, primarily based on their distance to clusters of similar samples. The intuition is clusters will make model predictions more confident and increase MIA risks. Thus WS strategically introduces noise to training samples, depending on whether they are near a cluster or isolated. We evaluate WS against MIAs on multiple benchmark datasets and model architectures, demonstrating its effectiveness. We publish code at https://github.com/BennyTMT/weighted-smoothing.}
}


@inproceedings{DBLP:conf/acsac/BaiSZWCCR23,
	author = {Jianli Bai and
                  Xiangfu Song and
                  Xiaowu Zhang and
                  Qifan Wang and
                  Shujie Cui and
                  Ee{-}Chien Chang and
                  Giovanni Russello},
	title = {Mostree: Malicious Secure Private Decision Tree Evaluation with Sublinear
                  Communication},
	booktitle = {Annual Computer Security Applications Conference, {ACSAC} 2023, Austin,
                  TX, USA, December 4-8, 2023},
	pages = {799--813},
	publisher = {{ACM}},
	year = {2023},
	url = {https://doi.org/10.1145/3627106.3627131},
	doi = {10.1145/3627106.3627131},
	timestamp = {Sun, 10 Dec 2023 17:00:07 +0100},
	biburl = {https://dblp.org/rec/conf/acsac/BaiSZWCCR23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A private decision tree evaluation (PDTE) protocol allows a feature vector owner (FO) to classify its data using a tree model from a model owner (MO) and only reveals an inference result to the FO. This paper proposes Mostree, a PDTE protocol secure in the presence of malicious parties with sublinear communication. We design Mostree in the three-party honest-majority setting, where an (untrusted) computing party (CP) assists the FO and MO in the secure computation. We propose two low-communication oblivious selection (OS) protocols by exploiting nice properties of three-party replicated secret sharing (RSS) and distributed point function. Mostree combines OS protocols with a tree encoding method and three-party secure computation to achieve sublinear communication. We observe that most of the protocol components already maintain privacy even in the presence of a malicious adversary, and what remains to achieve is correctness. To ensure correctness, we propose a set of lightweight consistency checks and seamlessly integrate them into Mostree. As a result, Mostree achieves sublinear communication and malicious security simultaneously. We implement Mostree and compare it with the state-of-the-art. Experimental results demonstrate that Mostree is efficient and comparable to semi-honest PDTE schemes with sublinear communication. For instance, when evaluated on the MNIST dataset in a LAN setting, Mostree achieves an evaluation using approximately 768 ms with communication of around 168 KB.}
}
