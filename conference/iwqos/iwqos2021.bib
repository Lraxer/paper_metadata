@inproceedings{DBLP:conf/iwqos/ZhaoHCS21,
	author = {Na Zhao and
                  Biao Han and
                  Yang Cai and
                  Jinshu Su},
	title = {SeqAD: An Unsupervised and Sequential Autoencoder Ensembles based
                  Anomaly Detection Framework for {KPI}},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--6},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521258},
	doi = {10.1109/IWQOS52092.2021.9521258},
	timestamp = {Tue, 31 Aug 2021 11:59:55 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/ZhaoHCS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Key Performance Indicator (KPI), a kind of time-series data, its anomalies are the most intuitive characteristics when failures occurred in IT systems. KPI anomaly detection is increasingly critical to provide reliable and stable services for IT systems. Unsupervised learning is a promising method because of lacking labels and the unbalance in KPI samples. However, existing unsupervised KPI anomaly detection methods suffer from high false alarm rates. They handle KPI sequence as non-sequential data and ignore the time information, which is an essential KPI character. To this end, in this paper, we propose an unsupervised and sequential autoencoder ensembles based anomaly detection framework called SeqAD. SeqAD inherits the advantages both from the sequence-to-sequence model and autoencoder ensembles. SeqAD reduces the KPI over-fitting problem effectively by introducing autoencoder ensembles. In order to better capture the time information of KPI, we propose a random step connection based recurrent neural network (RSC-RNN) to train the KPI sequence, which can provide random connections to construct autoencoders with different structures and retain time information to the most extent. Extensive experiments are conducted on two public KPI data-sets from real-world deployed systems to evaluate the efficiency and robustness of our proposed SeqAD framework. Results show that SeqAD is able to smoothly capture most of the characteristics in all KPI data-sets, as well as to achieve a high F1 score between 0.93 and 0.98, which is better than the state-of-art unsupervised KPI anomaly detection methods.}
}


@inproceedings{DBLP:conf/iwqos/WangYLCL21,
	author = {Zhiyuan Wang and
                  Jiancheng Ye and
                  Dong Lin and
                  Yipei Chen and
                  John C. S. Lui},
	title = {Designing Approximate and Deployable {SRPT} Scheduler: {A} Unified
                  Framework},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--6},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521259},
	doi = {10.1109/IWQOS52092.2021.9521259},
	timestamp = {Tue, 20 Jun 2023 14:04:12 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/WangYLCL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The scheduling policy installed on switches of datacenters plays a significant role on congestion control. Shortest-Remaining-Processing-Time (SRPT) achieves the near-optimal average message completion time (MCT) in various scenarios, but is difficult to deploy as viewed by the industry. The reasons are two-fold: 1) many commodity switches only provide FIFO queues, and 2) the information of remaining message size is not available. Recently, the idea of emulating SRPT using only a few FIFO queues and the original message size has been coined as the approximate and deployable SRPT (ADS) design. In this paper, we provide the first theoretical study on ADS design. Specifically, we first characterize a wide range of feasible ADS scheduling policies via a unified framework, and then derive the steady-state MCT and slowdown in the M/G/1 setting. We formulate the optimal ADS design as a non-linear combinatorial optimization problem, which aims to minimize the average MCT given the available FIFO queues. To prevent the starvation of long messages, we also take into account the fairness condition based on the steady-state slowdown. The optimal ADS design problem is NP-hard in general, and does not exhibit monotonicity or sub-modularity. We leverage its decomposable structure and devise an efficient algorithm to solve the optimal ADS policy. Numerical results based on the realistic heavy-tail message size distribution show that the optimal ADS policy installed on eight FIFO queues is capable of emulating the true SRPT in terms of MCT and slowdown.}
}


@inproceedings{DBLP:conf/iwqos/FaisalMSM21,
	author = {Tooba Faisal and
                  Damiano Di Francesco Maesa and
                  Nishanth Sastry and
                  Simone Mangiante},
	title = {Automated Quality of Service Monitoring for 5G and Beyond Using Distributed
                  Ledgers},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--6},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521260},
	doi = {10.1109/IWQOS52092.2021.9521260},
	timestamp = {Tue, 07 May 2024 20:11:32 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/FaisalMSM21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The viability of new mission-critical networked applications such as connected cars or remote surgery is heavily dependent on the availability of truly customized network services at a Quality of Service (QoS) level that both the network operator and the customer can agree on. This is difficult to achieve in todayâ€™s mainly "best effort" Internet. Even if a level of service were to be agreed upon between a consumer and an operator, it is important for both parties to be able to scalably and impartially monitor the quality of service delivered in order to enforce the service level agreement (SLA). Building upon a recently proposed architecture for automated negotiation of SLAs using smart contracts, we develop a low overhead solution for monitoring these SLAs and arranging automated payments based on the smart contracts. Our solution uses cryptographically secure bloom filters to create succinct summaries of the data exchanged over fine-grained epochs. We then use a state channel-based design for both parties to quickly and scalably agree and sign off on the data that was delivered in each epoch, making it possible to monitor and enforce at run time the agreed upon QoS levels.}
}


@inproceedings{DBLP:conf/iwqos/ChenMGXH21,
	author = {Jing Chen and
                  Zili Meng and
                  Yaning Guo and
                  Mingwei Xu and
                  Hongxin Hu},
	title = {HierTopo: Towards High-Performance and Efficient Topology Optimization
                  for Dynamic Networks},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521261},
	doi = {10.1109/IWQOS52092.2021.9521261},
	timestamp = {Sat, 30 Sep 2023 09:51:33 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/ChenMGXH21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Dynamic networks have enabled dynamically adapting the network topology to meet the need of real-time traffic demands. However, due to the complexity of topology optimization, existing solutions suffer from a trade-off between performance and efficiency, which either have large optimality gaps or excessive optimization overhead. To break through this trade-off, our key observation is that we could offload the optimization procedure to every network node to handle the complexity. Thus, we propose HierTopo, a hierarchical topology optimization method for dynamic networks that achieves both high performance and efficiency. HierTopo firstly runs a local policy on each network node to aggregate network information into low-dimension features, then uses these features to make global topology decisions. Evaluation on real-world network traces shows that HierTopo outperforms the state-of-the-art solutions by 11.52-38.91% with only milliseconds of decision latency, and is also superior in generalization ability.}
}


@inproceedings{DBLP:conf/iwqos/WangZFZGLJ021,
	author = {Xiaoyu Wang and
                  Hao Zhou and
                  Nikolaos M. Freris and
                  Wangqiu Zhou and
                  Xing Guo and
                  Zhi Liu and
                  Yusheng Ji and
                  Xiang{-}Yang Li},
	title = {{LCL:} Light Contactless Low-delay Load Monitoring via Compressive
                  Attentional Multi-label Learning},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--6},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521262},
	doi = {10.1109/IWQOS52092.2021.9521262},
	timestamp = {Tue, 16 Jul 2024 15:14:16 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/WangZFZGLJ021.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Fine-grained energy consumption analysis has great potential value in applications of Smart Grids, renewable energy, and Artificial Intelligence of Things. Non-Intrusive Load Monitoring (NILM) is a single-sensor alternative to the conventional one-sensor-for-one-appliance solution due to its ability to deduce individual appliances states from mixed measurements from the main power interface. Despite its advantages of low cost and easy maintenance, a few drawbacks hinders its widespread adoption. To enhance the Quality of Service (QoS) of NILM, four objectives should be achieved by careful designing: high accuracy, user transparency, low response delay, and low data redundancy.Inspired by observations of discriminative yet redundant current waveform and model sparsity, we propose LCL, a lightweight, contactless, plug-and-play solution for real-time load monitoring. The filtering module skips over unchanged input and compresses the measurements of interest using Compressed Sensing. The reconstruction-free inference module runs an attentional multi-label classification and returns all functioning appliance states directly from the compressed input. The compression module leverages model sparsity for real-time processing on edge devices. Evaluations based on our prototype deployed in real-life scenarios attest to the high QoS of LCL with a subset accuracy of 94.2% and a delay reduction of 52.2%. Our solution further filters out 96.8% of the redundant input and attains a Measurement Rate of 0.1 without noticeable impact on the performance.}
}


@inproceedings{DBLP:conf/iwqos/WeiSK21,
	author = {Bo Wei and
                  Hang Song and
                  Jiro Katto},
	title = {High-QoE {DASH} Live Streaming Using Reinforcement Learning},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--2},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521263},
	doi = {10.1109/IWQOS52092.2021.9521263},
	timestamp = {Mon, 22 Apr 2024 15:45:10 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/WeiSK21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the live video streaming becomes more and more common in daily life such as live meeting and live video call, it is an urgent task to ensure high-quality and low-delay live video streaming service. High user quality of experience (QoE) should be ensured to satisfy the requirement of user, for which latency is one of the important factors. In this paper, a high-QoE live streaming method is proposed with reinforcement learning. Experiments are conducted to evaluate the proposed method. Results demonstrate that the proposal shows the best performance with highest QoE compared with conventional methods in three network conditions. In Ferry case, the QoE is almost twice of the QoE of other methods.}
}


@inproceedings{DBLP:conf/iwqos/LiDDSL21,
	author = {Yuanjie Li and
                  Esha Datta and
                  Jiaxin Ding and
                  Ness B. Shroff and
                  Xin Liu},
	title = {Can Online Learning Increase the Reliability of Extreme Mobility Management?},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--6},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521264},
	doi = {10.1109/IWQOS52092.2021.9521264},
	timestamp = {Tue, 31 Aug 2021 11:59:55 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/LiDDSL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Seamless Internet access under extreme user mobility is highly demanded on high-speed trains and vehicles. However, existing mobile networks (e.g., 4G LTE and 5G NR) cannot reliably satisfy this demand, with a 5.5%-12.6% handover failure ratio at 200â€“350 km/h. A root cause is that, the 4G/5G handovers have to balance the exploration of more measurements for satisfactory handover and the exploitation for timely handover before the fast-moving user leaves the coverage.We design BaTT, an online learning solution for reliable handovers in extreme mobility. BaTT decomposes the explorationexploitation tradeoff into two multi-armed bandit problems. It uses Ïµ-binary-search to optimize the threshold of a serving cellâ€™s signal strength to initiate the handover with \\mathcal{O}(\\log J\\log T) regrets. It further adopts opportunistic Thompson sampling to optimize the sequence of target cells measured for reliable handovers. BaTT can be implemented using the recent Open Radio Access Network (O-RAN) framework in operational 4G LTE and 5G NR. Our evaluations over a dataset from operational LTE networks on the Chinese high-speed rails show a 29.1% handover failure reduction at the speed of 200-350 km/h.}
}


@inproceedings{DBLP:conf/iwqos/0001D21,
	author = {Kan Yang and
                  Senjuti Dutta},
	title = {Secure and Efficient Task Matching with Multi-keyword in Multi-requester
                  and Multi-worker Crowdsourcing},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--6},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521265},
	doi = {10.1109/IWQOS52092.2021.9521265},
	timestamp = {Sat, 09 Apr 2022 12:39:09 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/0001D21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Crowdsourcing enables users (task requesters) to outsource complex tasks to an unspecified crowd of workers. To guarantee the quality of crowdsourcing service, it is necessary to select the most appropriate task workers to complete the tasks. To this end, the crowdsourcing platform (broker) must conduct the mutual matching between tasks and workers based on the task requirements and worker preferences. However, both task requirements and worker preferences may contain sensitive information (e.g., time, location of the task, etc.), which should not be revealed to the broker and other adversaries. In this paper, we propose a secure and efficient task matching scheme to enable the broker to conduct the mutual matching between tasks and workers, according to task requirements and worker preferences with multiple keywords, while preserving the privacy of keywords contained in task requirements and worker preferences. Specifically, we design a new multi-reader and multi-writer searchable encryption primitive that can support the batch matching of multiple keywords. The security proof shows that our proposed task matching scheme is provably secure in the random oracle model under the Bilinear Diffie-Hellman (BDH) assumption. The performance evaluation shows that our multi-keyword batch matching can significantly reduce the computation cost compared to existing methods.}
}


@inproceedings{DBLP:conf/iwqos/ZhuZGLC21,
	author = {Andong Zhu and
                  Deze Zeng and
                  Lin Gu and
                  Peng Li and
                  Quan Chen},
	title = {Gost: Enabling Efficient Spatio-Temporal {GPU} Sharing for Network
                  Function Virtualization},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521266},
	doi = {10.1109/IWQOS52092.2021.9521266},
	timestamp = {Sat, 30 Sep 2023 09:51:34 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/ZhuZGLC21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Network Function Virtualization (NFV) enables network functions to run on general-purpose servers, thus alleviates the reliance on dedicated hardware and significantly improves the scalability and flexibility in networking service provisioning. Meanwhile, it is recognized that Virtualized Network Functions (VNFs) suffer from serious performance problem. Graphics Processing Unit (GPU), with massive processing cores, has been advocated as a potential accelerator for improving the performance efficiency of VNFs. However, the special architecture of GPU makes existing CPU-oriented task scheduling strategies fail to be applied, limiting the acceleration potential of GPUs. To this end, we propose a GPU-oriented spatio-temporal sharing framework as Gost to improve the performance of GPU-accelerated VNFs. We also study how to minimize the end-to-end latency of VNF flows via careful scheduling on the execution order and the GPU resource allocation (i.e., the number of threads). We first formally describe the problem as a non-linear integer programming problem, which is then equivalently transformed into an integer linear programming (ILP) form. Considering the high computation complexity of solving ILP, we further propose a customized list scheduling based spatio-temporal GPU sharing strategy (LSSTG). We have practically implemented a prototype of Gost, based on which we also verify the high efficiency of LSSTG by extensive experiments.}
}


@inproceedings{DBLP:conf/iwqos/TaoXL21,
	author = {Zeyi Tao and
                  Qi Xia and
                  Qun Li},
	title = {Neuron Manifold Distillation for Edge Deep Learning},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521267},
	doi = {10.1109/IWQOS52092.2021.9521267},
	timestamp = {Tue, 07 May 2024 20:11:32 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/TaoXL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Although deep neural networks show their extraordinary power in various object detection tasks, it is very challenging for them to be deployed on resource constrained devices or embedded systems due to their high computational cost. Efforts such as model partition, pruning or quantization have been used at an expense of accuracy loss. Recently proposed knowledge distillation (KD) aims at transferring model knowledge from a well-trained model (teacher) to a smaller and faster model (student), which can significantly reduce the computational cost, memory usage, and prolong the battery lifetime. In this work, we propose a novel neuron manifold distillation (NMD), where the student models not only imitate teacherâ€™s output activations, but also learn the feature geometry structure of the teacher. Our approach produces a high-quality, compact, and lightweight student model. We conduct comprehensive experiments with different distillation configurations over multiple datasets, and the proposed method demonstrates a consistent improvement in accuracy-speed trade-offs for the distilled model.}
}


@inproceedings{DBLP:conf/iwqos/0004SJC21,
	author = {Yanjun Li and
                  Xiaofeng Su and
                  Huatong Jiang and
                  Chung Shue Chen},
	title = {Throughput Maximization for Wireless Powered Communication: Reinforcement
                  Learning Approaches},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521268},
	doi = {10.1109/IWQOS52092.2021.9521268},
	timestamp = {Tue, 31 Aug 2021 11:59:55 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/0004SJC21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {To maximize the throughput of wireless powered communication (WPC), it is critical for the device to decide when to harvest energy, when to transmit data and what transmit power to use. In this paper, we consider a WPC system with a single device using harvest-store-transmit protocol and aim to maximize the longterm average throughput with optimal allocation of the energy harvesting time, data transfer time and the deviceâ€™s transmit power. With the consideration of many practical constraints including finite battery capacity, time-varying channels and non-linear energy harvesting model, we propose both deep Q-learning (DQL) and actor-critic (AC) approaches to solve the problem and obtain fully online policies. Simulation results show that the performance of our proposed AC approach comes close to that achieved by value iteration and is superior to DQL and other baseline algorithm. Meanwhile, its space complexity is 2-3 orders of magnitude less than that required by value iteration.}
}


@inproceedings{DBLP:conf/iwqos/XiaoHC21,
	author = {Qingjun Xiao and
                  Xiongqin Hu and
                  Shigang Chen},
	title = {Supporting Flow-Cardinality Queries with {O(1)} Time Complexity in
                  High-speed Networks},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521269},
	doi = {10.1109/IWQOS52092.2021.9521269},
	timestamp = {Tue, 31 Aug 2021 11:59:55 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/XiaoHC21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In high-speed networks, such as Internet backbone, a router may witness millions of IP packet flows passing through concurrently. Maintaining the state of each flow is a fundamental task underlying many network functions, such as load balancing and network anomaly detection. There are two important kinds of per-flow states: per-flow size (e.g., the number of packets received by an arbitrary destination IP) and per-flow cardinality (e.g., the number of distinct source IP addresses that contacted each destination IP). In this paper, we focus on the latter kind of states, and we propose a new problem: online flow-cardinality query, in which we must query any given flowâ€™s cardinality entirely on the data plane with low time complexity. We propose two solutions named On-vHLL and On-vLLC, whose time cost is\nO(1)\nfor the query operation. Our query acceleration techniques are three folds. First, we redesign the traditional vHLL and vLLC with new supplementary data structures called incremental update units. When querying a flowâ€™s cardinality, these units can avoid scanning the whole data structure and reduce the time complexity to\nO(1)\n. Second, we adopt LogLogCount estimation formula to avoid floating number calculation. Third, we add a fast path implemented by hash table, alongside the relatively slower On-vHLL or On-vLLC sketch. The fast path can absorb the packets belonging to the top-k superspreaders detected in previous time interval. We evaluate our new sketches by experiments based on CAIDA traffic traces. The results show that our sketches need less than 5 memory accesses per arrival packet. The time cost of our query operation decreases by hundreds of times, and the accuracy of flow cardinality estimation degrades quite modestly by only 20%, as compared with the counterpart vHLL.}
}


@inproceedings{DBLP:conf/iwqos/SongHMS21,
	author = {Lixing Song and
                  Emir Halepovic and
                  Alamin Mohammed and
                  Aaron Striegel},
	title = {{CUP:} Cellular Ultra-light Probe-based Available Bandwidth Estimation},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--11},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521270},
	doi = {10.1109/IWQOS52092.2021.9521270},
	timestamp = {Tue, 31 Aug 2021 11:59:55 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/SongHMS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cellular networks provide an essential connectivity foundation for a sizable number of mobile devices and applications, making it compelling to measure their performance in regard to user experience. Although cellular infrastructure provides low-level mechanisms for network-specific performance measurements, there is still a distinct gap in discerning the actual application-level or user-perceivable performance from such methods. Put simply, there is little substitute for direct sampling and testing to measure end-to-end performance. Unfortunately, most existing technologies often fall quite short. Achievable Throughput tests use bulk TCP downloads to provide an accurate but costly (time, bandwidth, energy) view of network performance. Conversely, Available Bandwidth techniques offer improved speed and low cost but are woefully inaccurate when faced with the typical dynamics of cellular networks. In this paper, we propose CUP, a novel approach for Cellular Ultra-light Probe-based available bandwidth estimation that seeks to operate at the cost point of Available Bandwidth techniques while correcting accuracy issues by leveraging the intrinsic aggregation properties of cellular scheduling, coupled with intelligent packet timing trains and the application of Bayesian probabilistic analysis. By keeping the costs low with reasonable accuracy, our approach enables scaling both with respect to time (longitude) and space (user device density). We construct a CUP prototype to evaluate our approach under various demanding real-world cellular environments (longitudinal, driving, multiple vendors) to demonstrate the efficacy of our approach.}
}


@inproceedings{DBLP:conf/iwqos/WangYL21,
	author = {Xiong Wang and
                  Jiancheng Ye and
                  John C. S. Lui},
	title = {Joint {D2D} Collaboration and Task Offloading for Edge Computing:
                  {A} Mean Field Graph Approach},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521271},
	doi = {10.1109/IWQOS52092.2021.9521271},
	timestamp = {Sat, 09 Apr 2022 12:39:09 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/WangYL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Mobile edge computing (MEC) facilitates computation offloading to edge server, as well as task processing via device-to-device (D2D) collaboration. Existing works mainly focus on centralized network-assisted offloading solutions, which are unscalable to scenarios involving collaboration among massive users. In this paper, we propose a joint framework of decentralized D2D collaboration and efficient task offloading for a large-population MEC system. Specifically, we utilize the power of two choices for D2D collaboration, which enables users to beneficially assist each other in a decentralized manner. Due to short-range D2D communication and user movements, we formulate a mean field model on a finite-degree and dynamic graph to analyze the state evolution of D2D collaboration. We derive the existence, uniqueness and convergence of the state stationary point so as to provide a tractable collaboration performance. Complementing this D2D collaboration, we further build a Stackelberg game to model usersâ€™ task offloading, where edge server is the leader to determine a service price, while users are followers to make offloading decisions. By embedding the Stackelberg game into Lyapunov optimization, we develop an online offloading and pricing scheme, which could optimize serverâ€™s service utility and usersâ€™ system cost simultaneously. Extensive evaluations show that our D2D collaboration can mitigate usersâ€™ workloads by 73.8% and task offloading can achieve high energy efficiency.}
}


@inproceedings{DBLP:conf/iwqos/ShenGZ021,
	author = {Meng Shen and
                  Zhenbo Gao and
                  Liehuang Zhu and
                  Ke Xu},
	title = {Efficient Fine-Grained Website Fingerprinting via Encrypted Traffic
                  Analysis with Deep Learning},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521272},
	doi = {10.1109/IWQOS52092.2021.9521272},
	timestamp = {Fri, 12 May 2023 15:00:49 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/ShenGZ021.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Fine-grained website fingerprinting (WF) enables potential attackers to infer individual webpages on a monitored website that victims are visiting, by analyzing the resulting traffic protected by security protocols such as TLS. Most existing studies focus on WF at the granularity of website, which takes website homepages as their representatives for fingerprinting. Fine-grained WF can reveal more user privacy, such as online purchasing habits and video-viewing interests, and can also be employed for web censorship. Due to striking similarly of webpages on a same website, it is still an open problem to conduct fine-grained WF in an accurate and time-efficient way.In this paper, we propose BurNet, a fine-grained WF method using Convolutional Neural Networks (CNNs). To extract differences of similar webpages, we propose a new concept named unidirectional burst, which is a sequence of packets corresponding to a piece of HTTP message. BurNet takes as input unidirectional burst sequences, instead of bidirectional packet sequences, which makes it applicable to local and remote attack scenarios. BurNet employs CNNs to build a powerful classifier, where sophisticated architecture is designed to improve classification accuracy while reducing time complexity in training. We collect real-world datasets from two well-known websites and conduct extensive experiments to evaluate the performance of BurNet. The closed-world evaluation results show that BurNet outperforms the state-of-the-art methods in both attack scenarios. In the more realistic open-world setting, BurNet can achieve 0.99 precision and 0.99 recall. BurNet is also superior to its CNN-based counterparts in terms of training efficiency.}
}


@inproceedings{DBLP:conf/iwqos/YangLG21,
	author = {Qiuying Yang and
                  Xuan Liu and
                  Song Guo},
	title = {No Wait, No Waste: {A} Novel and Efficient Coordination Algorithm
                  for Multiple readers in {RFID} Systems},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521273},
	doi = {10.1109/IWQOS52092.2021.9521273},
	timestamp = {Mon, 27 Sep 2021 08:16:57 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/YangLG21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {How to efficiently coordinate multiple readers to work together is critical for high throughput in RFID systems. Existing researchers focus on designing efficient reader scheduling strategies that arrange adjacent readers to work in different time to avoid signal collisions. However, the impact of unbalanced tag number of readers on tag read throughput is still very challenging. In RFID systems, the distribution of tags is usually variable and uneven, which makes the number of tags covered by each reader (i.e. the load of it) imbalanced. This imbalance leads to different execution time for readers: the heavy load readers take longer time to collect all tags, while the other readers that finish execution earlier have to wait for nothing. To avoid this useless waiting and improve the system throughput, this paper focuses on the load balancing problem of multiple readers. It is an NP-hard problem, for which we design heuristic algorithms that adjust readersâ€™ interrogation regions according to designed strategies to efficiently balance their loads. The amazing advantage of our algorithm is that it can be adopted by almost all existing protocols in multi-reader systems, including the reader scheduling protocol, to improve system throughput. Extensive experiments demonstrate that our algorithm can significantly improve the throughput in various scenarios.}
}


@inproceedings{DBLP:conf/iwqos/LiuMYWL21,
	author = {Gaoyang Liu and
                  Xiaoqiang Ma and
                  Yang Yang and
                  Chen Wang and
                  Jiangchuan Liu},
	title = {FedEraser: Enabling Efficient Client-Level Data Removal from Federated
                  Learning Models},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521274},
	doi = {10.1109/IWQOS52092.2021.9521274},
	timestamp = {Mon, 18 Jul 2022 08:17:45 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/LiuMYWL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated learning (FL) has recently emerged as a promising distributed machine learning (ML) paradigm. Practical needs of the "right to be forgotten" and countering data poisoning attacks call for efficient techniques that can remove, or unlearn, specific training data from the trained FL model. Existing unlearning techniques in the context of ML, however, are no longer in effect for FL, mainly due to the inherent distinction in the way how FL and ML learn from data. Therefore, how to enable efficient data removal from FL models remains largely under-explored. In this paper, we take the first step to fill this gap by presenting FedEraser, the first federated unlearning method-ology that can eliminate the influence of a federated clientâ€™s data on the global FL model while significantly reducing the time used for constructing the unlearned FL model. The basic idea of FedEraser is to trade the central serverâ€™s storage for unlearned modelâ€™s construction time, where FedEraser reconstructs the unlearned model by leveraging the historical parameter updates of federated clients that have been retained at the central server during the training process of FL. A novel calibration method is further developed to calibrate the retained updates, which are further used to promptly construct the unlearned model, yielding a significant speed-up to the reconstruction of the unlearned model while maintaining the model efficacy. Experiments on four realistic datasets demonstrate the effectiveness of FedEraser, with an expected speed-up of 4Ã— compared with retraining from the scratch. We envision our work as an early step in FL towards compliance with legal and ethical criteria in a fair and transparent manner.}
}


@inproceedings{DBLP:conf/iwqos/WangZYX021,
	author = {En Wang and
                  Mijia Zhang and
                  Yongjian Yang and
                  Yuanbo Xu and
                  Jie Wu},
	title = {Exploiting Outlier Value Effects in Sparse Urban CrowdSensing},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521275},
	doi = {10.1109/IWQOS52092.2021.9521275},
	timestamp = {Sun, 02 Oct 2022 16:10:47 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/WangZYX021.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Sparse spatiotemporal data completion is crucial in Mobile CrowdSensing for urban application scenarios. In fact, accurate urban data completion can enhance data expression, improve urban analysis, and ultimately guide city planning. However, it is a non-trivial task to consider outlier values caused by the special events (e.g., parking peak, traffic congestion, or festival parade) in spatiotemporal data completion because of the following challenges: 1) the rarity and unpredictability, 2) the inconsistency compared to normal values, and 3) the complex spatiotemporal relations. In spite of the considerable improvements, recent deep learning-based methods overlook the existence of outlier values, which results in misidentifying these values. To this end, focusing on spatiotemporal data, we propose a matrix completion method that takes outlier value effects into consideration. Specifically, an outlier value model is proposed by adding a memory network and modifying the loss function to traditional matrix completion. Along this line, we extract the features of outlier values and further efficiently complete and predict the unsensed data. Finally, we conduct both qualitative and quantitative experiments on three different datasets, and the results demonstrate that the performance of our method outperforms the state-of-the-art baselines.}
}


@inproceedings{DBLP:conf/iwqos/Xia0XWM21,
	author = {Yu Xia and
                  Jinsong Wu and
                  Jingwen Xia and
                  Ting Wang and
                  Sun Mao},
	title = {Multipath-aware {TCP} for Data Center Traffic Load-balancing},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--6},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521276},
	doi = {10.1109/IWQOS52092.2021.9521276},
	timestamp = {Mon, 26 Jun 2023 20:43:55 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/Xia0XWM21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Traffic load-balancing is important to data center performance. However, existing data center load-balancing solutions are either limited to simple topologies or cannot provide satisfactory performance. In this paper, we propose a multipath-aware TCP (MA-TCP) which can sense the path migration of TCP flows. With this new mechanism, the reduction in TCP congestion window due to packet reordering during the path migration can be avoided. This, in turn, makes the path migration more timely as soon as the original path is congested. Furthermore, if the new path is congested (again), the flow can securely continue to migrate without worrying about transmitting rate reduction. Through NS-3 simulations, we show that MA-TCP achieves better flow completion time (FCT) than existing data center load-balancing solutions.}
}


@inproceedings{DBLP:conf/iwqos/QiaoWWLT21,
	author = {Chunyu Qiao and
                  Jiliang Wang and
                  Yanan Wang and
                  Yunhao Liu and
                  Hu Tuo},
	title = {Understanding and Improving User Engagement in Adaptive Video Streaming},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521277},
	doi = {10.1109/IWQOS52092.2021.9521277},
	timestamp = {Tue, 20 Dec 2022 21:20:02 +0100},
	biburl = {https://dblp.org/rec/conf/iwqos/QiaoWWLT21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Todayâ€™s video service providers all desire to deeply understand the ever changing factors on user QoE to attract more users. In this paper, we study the user engagement with respect to video quality metrics and improve user engagement in adaptive video streaming systems. We conduct a comprehensive study of the real data from iQIYI, covering 700K users and 150K videos. We find bitrate switch becomes the new dominant factor on user engagement instead of rebuffering events. We also observe the impact of rate of rebuffering is more dominant than rebuffering time. We examine novel interdependencies between quality metrics in the system, e.g., the positive correlation between bitrate switch and average bitrate, which is due to the context system strategy, i.e., conservative bitrate enhancing strategy adopted by iQIYI. To improve user engagement, we propose a new engagement centric QoE function based on real data and design server side ABR algorithm which leverages our new QoE function. We evaluate our method for online test in iQIYI, with 490K real users viewing 666K streams. The results show our approach outperforms existing approaches by significantly improving the viewing time, i.e., 2.8 minutes longer viewing time per user.}
}


@inproceedings{DBLP:conf/iwqos/LiuXCHX0M21,
	author = {Jianwei Liu and
                  Chaowei Xiao and
                  Kaiyan Cui and
                  Jinsong Han and
                  Xian Xu and
                  Kui Ren and
                  XuFei Mao},
	title = {A Behavior Privacy Preserving Method towards {RF} Sensing},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521278},
	doi = {10.1109/IWQOS52092.2021.9521278},
	timestamp = {Thu, 09 Mar 2023 17:43:24 +0100},
	biburl = {https://dblp.org/rec/conf/iwqos/LiuXCHX0M21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recent years have witnessed the booming development of RF sensing, which supports both identity authentication and behavior recognition by analysing the signal distortion caused by human body. In particular, RF-based identity authentication is more attractive to researchers, because it can capture the unique biological characteristics of users. However, the openness of wireless transmission raises privacy concerns since human behaviors can expose the massive private information of users, which impedes the real-world implementation of RF-based user authentication applications. Unfortunately, it is difficult to filter out the behavior information from the collected RF signals.In this paper, we propose a privacy-preserving deep neural network named BPCloak to erase the behavior information in RF signals while retaining the ability of user authentication. We conduct extensive experiments over mainstream RF signals collected from three real wireless systems, including the WiFi, Radio Frequency IDentification (RFID), and millimeter-wave (mmWave) systems. The experimental results show that BPCloak significantly reduces the behavior recognition accuracy, i.e., 85%+, 75%+, and 65%+ reduction for WiFi, RFID, and mmWave systems respectively, merely with a slight penalty of accuracy decrease when using these three systems for user authentication, i.e., 1%-, 3%-, and 5%-, respectively.}
}


@inproceedings{DBLP:conf/iwqos/XuZXZ21,
	author = {Minze Xu and
                  Yuan Zhang and
                  Fengyuan Xu and
                  Sheng Zhong},
	title = {Privacy-Preserving Optimal Recovering for the Nearly Exhausted Payment
                  Channels},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521279},
	doi = {10.1109/IWQOS52092.2021.9521279},
	timestamp = {Tue, 22 Mar 2022 08:38:27 +0100},
	biburl = {https://dblp.org/rec/conf/iwqos/XuZXZ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Payment Channel Network (PCN) is one of the most promising technologies for scaling the capacity of blockchain-based cryptocurrencies and improving the quality of blockchain-based services. However, during the use of PCNs, a significant portion of the payment channels gradually become exhausted, which triggers additional consumption of on-chain resources and makes PCNs less useful. This is a fundamental problem for blockchain-based cryptocurrencies, worthy of a thorough investigation.In this paper, we propose OPRE, a protocol for OPtimal off-chain REcovering of payment channels, to solve this problem. It is optimal in that it recovers the maximum number of nearly exhausted channels in the PCN. Furthermore, we consider usersâ€™ privacy concerns and design a privacy-preserving version of this protocol, so that usersâ€™ balance information does not need to be revealed. This protocol maintains optimality in recovering payment channels while providing cryptographically strong privacy guarantee. In addition to the theoretical design and analysis, we also implement OPRE and experimentally evaluate its performance. The results show that the OPRE protocol is both efficient and effective.}
}


@inproceedings{DBLP:conf/iwqos/CaoYGWLXGDZ21,
	author = {Xinzhe Cao and
                  Gen Yang and
                  Yunfei Gu and
                  Chentao Wu and
                  Jie Li and
                  Guangtao Xue and
                  Minyi Guo and
                  Yuanyuan Dong and
                  Yafei Zhao},
	title = {EC-Scheduler: {A} Load-Balanced Scheduler to Accelerate the Straggler
                  Recovery for Erasure Coded Storage Systems},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521280},
	doi = {10.1109/IWQOS52092.2021.9521280},
	timestamp = {Tue, 14 Sep 2021 19:20:57 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/CaoYGWLXGDZ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Erasure codes (EC) have become a typical technology for distributed storage systems in place of data replication, providing similar data availability but lower storage cost. However, a great number of data computations and migrations during the EC recovery process bring high I/O and network latency penalties. Although several EC recovery methods have been designed to compromise the recovery penalty with high parallelism, the performance of these schemes was usually bounded by the straggler problems due to the various (I/O) performance among different nodes in the storage system. Moreover, the variation of the access popularity from the upper layer application causes the dynamic load fluctuation and asymmetry upon different nodes, which makes the scheduling more difficult during the recovery. To address the above problem, we propose a dynamic load-balanced scheduling algorithm for straggler recovery called EC-Scheduler. EC-Scheduler adjusts the recovery schedule dynamically with the awareness of continuous load fluctuation on the nodes, guaranteeing high parallelism and load balance ability simultaneously. To demonstrate the effectiveness of EC-Scheduler, we conduct several experiments in a cluster. The results show that, compared to typical recovery schemes such as Fast-PR and EC-Store, EC-Scheduler could achieve a 1.3X speed-up in the recovery process and 10X improvement in recovery load imbalance factor.}
}


@inproceedings{DBLP:conf/iwqos/0001PSBLSLX021,
	author = {Tian Pan and
                  Xiaoyu Peng and
                  Qianqian Shi and
                  Zizheng Bian and
                  Xingchen Lin and
                  Enge Song and
                  Fuliang Li and
                  Yang Xu and
                  Tao Huang},
	title = {GreenTE.ai: Power-Aware Traffic Engineering via Deep Reinforcement
                  Learning},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--6},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521281},
	doi = {10.1109/IWQOS52092.2021.9521281},
	timestamp = {Thu, 30 Mar 2023 20:45:28 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/0001PSBLSLX021.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Power-aware traffic engineering via coordinated sleeping is usually formulated into Integer Programming problems, which are generally NP-hard with unbounded computation time for large-scale networks. This results in delayed control decision making in dynamic network environments. Motivated by advances in deep Reinforcement Learning, we consider building intelligent systems that learn to adaptively change router/switchâ€™s power state according to changing network conditions. Neural networkâ€™s forward propagation can greatly speed up power on/off decision making. Generally, conducting RL requires a learning agent to iteratively explore and perform the "good" actions based on the feedback from the environment. By coupling Software-Defined Networking for performing centrally calculated actions to the environment and In-band Network Telemetry for collecting feedback from the environment, we develop GreenTE.ai, a closed-loop control/training system to automate power-aware traffic engineering. Furthermore, we propose novel techniques to enhance the learning ability and reduce the learning complexity. With both energy efficiency and traffic load balancing considered, GreenTE.ai can generate reasonable power saving actions within 276ms under a network testbed of 11 software P4 switches.}
}


@inproceedings{DBLP:conf/iwqos/FanSSL21,
	author = {Xiaodi Fan and
                  Angel Saldivia and
                  Pedro Soto and
                  Jun Li},
	title = {Coded Matrix Chain Multiplication},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--6},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521282},
	doi = {10.1109/IWQOS52092.2021.9521282},
	timestamp = {Sun, 02 Oct 2022 16:10:47 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/FanSSL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The matrix multiplication is a fundamental building block in many machine learning models. As the input matrices may be too large to be multiplied on a single server, it is common to split input matrices into multiple submatrices and execute the multiplications on different servers. However, in a distributed infrastructure it is common to observe stragglers whose performance is lower than other servers at some time. In order to mitigate the adversarial effects of potential stragglers, various coding schemes for the distributed matrix multiplication have been recently proposed. While most existing works have only considered the simplest case where only two matrices are multiplied, we investigate a more general case in this paper where multiple matrices are multiplied, and propose a coding scheme that the result can be directly decoded in one round, instead of in multiple rounds of computation. Compared to completing the matrix chain multiplication in multiple rounds, our coding scheme can achieve significant savings of completion time by up to 90.3%.}
}


@inproceedings{DBLP:conf/iwqos/WeiW21,
	author = {Xinliang Wei and
                  Yu Wang},
	title = {Joint Resource Placement and Task Dispatching in Mobile Edge Computing
                  across Timescales},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--6},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521283},
	doi = {10.1109/IWQOS52092.2021.9521283},
	timestamp = {Mon, 14 Mar 2022 17:07:56 +0100},
	biburl = {https://dblp.org/rec/conf/iwqos/WeiW21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The proliferation of Internet of Things (IoT) data and innovative mobile services has promoted an increasing need for low-latency access to resources such as data and computing services. Mobile edge computing has become an effective computing paradigm to meet the requirement for low-latency access by placing resources and dispatching tasks at the network edge near mobile users. The key challenge of such solution is how to efficiently place resources and dispatch tasks to meet the QoS of mobile users or maximize the platformâ€™s utility. In this paper, we study the joint optimization problem of resource placement and task dispatching in mobile edge computing across multiple timescales under the dynamic status of edge servers. We first propose a two-stage iterative algorithm to solve the joint optimization problem in different timescales, which can handle the varieties among the dynamic of edge resources and/or tasks. We then propose a reinforcement learning (RL) based algorithm which leverages the learning capability of Deep Deterministic Policy Gradient (DDPG) technique to tackle the network variation and dynamic as well. The results from trace-driven simulations demonstrate that our proposed approaches can effectively place resources and dispatching tasks across two timescales to maximize the total utility of all scheduled tasks.}
}


@inproceedings{DBLP:conf/iwqos/ZhaoSG0WXY21,
	author = {Zongyi Zhao and
                  Xingang Shi and
                  Arpit Gupta and
                  Qing Li and
                  Zhiliang Wang and
                  Bin Xiong and
                  Xia Yin},
	title = {Continuous Flow Measurement with SuperFlow},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--6},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521284},
	doi = {10.1109/IWQOS52092.2021.9521284},
	timestamp = {Tue, 31 Aug 2021 11:59:55 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/ZhaoSG0WXY21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Flow-based network measurement enables operators to perform a wide range of network management tasks in a scalable manner. Recently, various algorithms have been proposed for flow record collection at very high speed. However, they all focus on processing traffic in a short time window, but overlook the fact that flow measurements are typically needed continuously for unlimited time. To this end, we propose a new algorithm named SuperFlow to support continuous and accurate flow record collection at very high speed by monitoring the flow activeness and exporting the inactive records from the data plane automatically. Our data structures and the corresponding algorithms are carefully designed and analyzed, so the above goal is achieved with limited memory and bandwidth consumption. We implement SuperFlow on both x86 CPU and state-of-the-art PISA target. Comprehensive experiments show that SuperFlow consistently outperforms its competitors significantly. Especially, compared with the best competitor, it records around 136.7% more flows, reduces the error in flow size estimation by 51.5%, and reduces the memory or bandwidth consumption by up to 71.0%, while bringing only negligible throughput degradation.}
}


@inproceedings{DBLP:conf/iwqos/He00TK021,
	author = {Nan He and
                  Song Yang and
                  Fan Li and
                  Stojan Trajanovski and
                  Fernando A. Kuipers and
                  Xiaoming Fu},
	title = {{A-DDPG:} Attention Mechanism-based Deep Reinforcement Learning for
                  {NFV}},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521285},
	doi = {10.1109/IWQOS52092.2021.9521285},
	timestamp = {Mon, 03 Jan 2022 22:21:49 +0100},
	biburl = {https://dblp.org/rec/conf/iwqos/He00TK021.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The efficacy of Network Function Virtualization (NFV) depends critically on (1) where the virtual network functions (VNFs) are placed and (2) how the traffic is routed. Unfortunately, these aspects are not easily optimized, especially under time-varying network states with different quality of service (QoS) requirements. Given the importance of NFV, many approaches have been proposed to solve the VNF placement and traffic routing problem. However, those prior approaches mainly assume that the state of the network is static and known, disregarding real-time network variations. To bridge that gap, in this paper, we formulate the VNF placement and traffic routing problem as a Markov Decision Process model to capture the dynamic network state transitions. In order to jointly minimize the delay and cost of NFV providers and maximize the revenue, we devise a customized Deep Reinforcement Learning (DRL) algorithm, called A-DDPG, for VNF placement and traffic routing in a real-time network. A-DDPG uses the attention mechanism to ascertain smooth network behavior within the general framework of network utility maximization (NUM). The simulation results show that A-DDPG outperforms the state-of-the-art in terms of network utility, delay, and cost.}
}


@inproceedings{DBLP:conf/iwqos/YuanWC0L21,
	author = {Jie Yuan and
                  Yonghui Wang and
                  Hanhua Chen and
                  Hai Jin and
                  Haikun Liu},
	title = {Eunomia: Efficiently Eliminating Abnormal Results in Distributed Stream
                  Join Systems},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--11},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521286},
	doi = {10.1109/IWQOS52092.2021.9521286},
	timestamp = {Tue, 31 Aug 2021 11:59:55 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/YuanWC0L21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the emergence of big data applications, stream join systems are widely used in extracting valuable information among multi-source streams. However, providing completeness of processing results in a large-scale distributed stream join system is challenging because it is hard to guarantee the consistency among all instances. We show through experiments that the abnormal result can make the quality of achieved data unacceptable in practice.In this paper, we propose Eunomia, a novel distributed stream join system which leverages an ordered propagation model for efficiently eliminating abnormal results. We design a light-weighted self-adaptive strategy to adjust the structure in the model according to the dynamic stream input rates and workloads. It can improve the scalability and performance significantly. We implement Eunomia and conduct comprehensive experiments to evaluate its performance. The results show that Eunomia eliminates abnormal results to guarantee the completeness, improves the system throughput by 25% and reduces the processing latency by 74% compared to state-of-the-art designs.}
}


@inproceedings{DBLP:conf/iwqos/HongFWK0CC21,
	author = {Hsiang{-}Jen Hong and
                  Wenjun Fan and
                  Simeon Wuthier and
                  Jinoh Kim and
                  Xiaobo Zhou and
                  C. Edward Chow and
                  Sang{-}Yoon Chang},
	title = {Robust {P2P} Connectivity Estimation for Permissionless Bitcoin Network},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--6},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521287},
	doi = {10.1109/IWQOS52092.2021.9521287},
	timestamp = {Mon, 03 Jan 2022 22:21:49 +0100},
	biburl = {https://dblp.org/rec/conf/iwqos/HongFWK0CC21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Blockchain relies on the underlying peer-to-peer (p2p) networking to broadcast and get up-to-date on the blocks and transactions. It is therefore imperative to have high p2p connectivity for the quality of the blockchain system operations. High p2p networking connectivity ensures that a peer node is connected to multiple other peers providing a diverse set of observers of the current state of the blockchain and transactions. However, in a permissionless blockchain network, using the peer identifiersâ€”including the current approach of counting the number of distinct IP addresses and port numbersâ€”can be ineffective in measuring the number of peer connections and estimating the networking connectivity. Such current approach is further challenged by the networking threats manipulating the identifiers. We build a robust estimation engine for the p2p networking connectivity by sensing and processing the p2p networking traffic. We implement a working Bitcoin prototype connected to the Bitcoin Mainnet to validate and improve our engineâ€™s performances and evaluate the estimation accuracy and cost efficiency of our estimation engine.}
}


@inproceedings{DBLP:conf/iwqos/MadanapalliMGS21,
	author = {Sharat Chandra Madanapalli and
                  Alex Mathai and
                  Hassan Habibi Gharakheili and
                  Vijay Sivaraman},
	title = {ReCLive: Real-Time Classification and QoE Inference of Live Video
                  Streaming Services},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--7},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521288},
	doi = {10.1109/IWQOS52092.2021.9521288},
	timestamp = {Mon, 03 Jan 2022 22:21:49 +0100},
	biburl = {https://dblp.org/rec/conf/iwqos/MadanapalliMGS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Social media, professional sports, and video games are driving rapid growth in live video streaming, on platforms such as Twitch and YouTube Live. Live streaming experience is very susceptible to short-time-scale network congestion since client playback buffers are often no more than a few seconds. Unfortunately, identifying such streams and measuring their QoE for network management is challenging, since content providers largely use the same delivery infrastructure for live and video-on-demand (VoD) streaming, and packet inspection techniques (including SNI/DNS query monitoring) cannot always distinguish between the two. In this paper, we design and develop ReCLive: a machine learning method for live video detection and QoE measurement based on network-level behavioral characteristics.}
}


@inproceedings{DBLP:conf/iwqos/LiZXCLS21,
	author = {Shiyu Li and
                  Yuan Zhang and
                  Chunxiang Xu and
                  Nan Cheng and
                  Zhi Liu and
                  Xuemin Sherman Shen},
	title = {{BESURE:} Blockchain-Based Cloud-Assisted eHealth System with Secure
                  Data Provenance},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--6},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521289},
	doi = {10.1109/IWQOS52092.2021.9521289},
	timestamp = {Mon, 15 Jul 2024 14:20:06 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/LiZXCLS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we investigate actual cloud-assisted electronic health (eHealth) systems in terms of security, efficiency, and functionality. Specifically, we propose a password-based subsequent-key-locked encryption mechanism to ensure the confidentiality of outsourced electronic health records (EHRs). We also propose a blockchain-based secure EHR provenance mechanism by designing the data structure of the EHR provenance record and deploying a public blockchain and smart contract to secure both EHRs and their provenance records. With the two mechanisms, we develop BESURE (blockchain-based cloud-assisted eHealth system with secure data provenance) to provide a secure EHR storage service with efficient provenance. Security analysis and comprehensive performance evaluation are conducted to demonstrate that BESURE is secure and efficient.}
}


@inproceedings{DBLP:conf/iwqos/ZhaoZCW21,
	author = {Shizhen Zhao and
                  Xiao Zhang and
                  Peirui Cao and
                  Xinbing Wang},
	title = {Design of Robust and Efficient Edge Server Placement and Server Scheduling
                  Policies},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--7},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521290},
	doi = {10.1109/IWQOS52092.2021.9521290},
	timestamp = {Tue, 31 Aug 2021 11:59:55 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/ZhaoZCW21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We study how to design edge server placement and server scheduling policies under workload uncertainty for 5G networks. We introduce a new metric called resource pooling factor to handle unexpected workload bursts. Maximizing this metric offers a strong enhancement on top of robust optimization against workload uncertainty. Using both real traces and synthetic traces, we show that the proposed server placement and server scheduling policies not only demonstrate better robustness against workload uncertainty than existing approaches, but also significantly reduce the cost of service providers. Specifically, in order to achieve close-to-zero workload rejection rate, the proposed server placement policy reduces the number of required edge servers by about 25% compared with the state-of-the-art approach; the proposed server scheduling policy reduces the energy consumption of edge servers by about 13% without causing much impact on the service quality.}
}


@inproceedings{DBLP:conf/iwqos/XiaCWCZLL21,
	author = {Zhenchang Xia and
                  Yanjiao Chen and
                  Libing Wu and
                  Yu{-}Cheng Chou and
                  Zhicong Zheng and
                  Haoyang Li and
                  Baochun Li},
	title = {A Multi-objective Reinforcement Learning Perspective on Internet Congestion
                  Control},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521291},
	doi = {10.1109/IWQOS52092.2021.9521291},
	timestamp = {Tue, 31 Aug 2021 11:59:55 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/XiaCWCZLL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The advent of new network architectures has resulted in the rise of network applications with different network performance requirements: live video streaming applications require low latency. In contrast, file transfer applications require high throughput. Existing congestion control protocols may fail to simultaneously meet the performance requirements of these different types of applications since their designed objective function is fixed and difficult to readjust according to the needs of the application. In this paper, we develop MOCC (Multi-Objective Congestion Control), a novel multi-objective congestion control protocol that can meet the performance requirements of different applications without the need to redesign the objective function. MOCC leverages multi-objective reinforcement learning with preferences in order to adapt to different types of applications. By addressing challenges such as slow convergence speed and the difficulty of designing the end of the episode, MOCC can quickly converge to the equilibrium point and adapt multi-objective reinforcement learning to congestion control. Through an extensive array of experiments, we discover that MOCC outperforms the most recent state-of-the-art congestion control protocols and can achieve a trade-off between throughput, latency, and packet loss, meeting the performance requirements of different types of applications by setting preferences.}
}


@inproceedings{DBLP:conf/iwqos/ChengSZQ021,
	author = {Qi Cheng and
                  Hangguan Shan and
                  Weihua Zhuang and
                  Tony Q. S. Quek and
                  Zhaoyang Zhang},
	title = {When Virtual Network Operator Meets E-Commerce Platform: Advertising
                  via Data Reward},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--11},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521292},
	doi = {10.1109/IWQOS52092.2021.9521292},
	timestamp = {Mon, 05 Feb 2024 20:33:54 +0100},
	biburl = {https://dblp.org/rec/conf/iwqos/ChengSZQ021.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In China, some e-commerce platform (EP) companies such as Alibaba and JD have been now allowed to partner with network operators (NOs) to act as virtual network operators (VNOs) to provide mobile data services for mobile users (MUs). However, it is a question worth researching on how to generate more profits for all network players after EP companies being VNOs through appropriate integration of the VNO business and the companiesâ€™ own e-commerce business. To address this issue, in this work we propose a novel incentive mechanism for advertising via mobile data reward, and model it as a three-stage Stackelberg game. In Stage I, the NO decides the price of mobile data for the VNO; in Stage II, the VNO decides its data plan fee for MUs and the ad price for e-commerce merchants (EMs); in Stage III, the MUs make their own decisions on the data plan subscription and the number of ads to be watched, while the EMs decide the number of ad slots they buy from the EP. We obtain the closed-form optimal solution of the Nash equilibrium by backward induction. Simulation results show the impact of the system parameters on the utilities of game players and social welfare, and reveal that the solution can indeed lead to a quadri-win outcome in some cases. At the same time, we summarize some insights that have economic guidance.}
}


@inproceedings{DBLP:conf/iwqos/XuWJC0ZF21,
	author = {Xianghao Xu and
                  Fang Wang and
                  Hong Jiang and
                  Yongli Cheng and
                  Dan Feng and
                  Yongxuan Zhang and
                  Peng Fang},
	title = {GraphCP: An I/O-Efficient Concurrent Graph Processing Framework},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521293},
	doi = {10.1109/IWQOS52092.2021.9521293},
	timestamp = {Wed, 05 Jun 2024 07:37:08 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/XuWJC0ZF21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Big data applications increasingly rely on the analysis of large graphs. In order to analyze and process the large graphs with high cost efficiency, researchers have developed a number of out-of-core graph processing systems in recent years based on just one commodity computer. On the other hand, with the rapidly growing need of analyzing graphs in the real-world, graph processing systems have to efficiently handle massive concurrent graph processing (CGP) jobs. Unfortunately, due to the inherent design for single graph processing job, existing out-of-core graph processing systems usually incur redundant data accesses and storage and severe competition of I/O bandwidth when handling the CGP jobs, thus leading to very long waiting time experienced by users for the computing results. In this paper, we propose an I/O-efficient out-of-core graph processing system, GraphCP, to support the processing of CGP jobs. GraphCP proposes a benefit-aware sharing execution model that shares the I/O access and processing of graph data among the CGP jobs and adaptively schedules the loading of graph data, which efficiently overcomes above challenges faced by existing out-of-core graph processing systems. In addition, GraphCP organizes the graph data with a Source-Sorted Sub-Block graph representation for better processing capacity and I/O access locality. Extensive evaluation results show that GraphCP is 10.3x and 4.6x faster than two state-of-the-art out-of-core graph processing systems GridGraph and GraphZ respectively, and 2.1x faster than a CGP-oriented graph processing system Seraph.}
}


@inproceedings{DBLP:conf/iwqos/XuJZZW0W0021,
	author = {Wenquan Xu and
                  Xuefeng Ji and
                  Chuwen Zhang and
                  Beichuan Zhang and
                  Yu Wang and
                  Xiaojun Wang and
                  Yunsheng Wang and
                  Jianping Wang and
                  Bin Liu},
	title = {{PQR:} Prediction-supported Quality-aware Routing for Uninterrupted
                  Vehicle Communication},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521294},
	doi = {10.1109/IWQOS52092.2021.9521294},
	timestamp = {Sun, 29 Jan 2023 15:40:40 +0100},
	biburl = {https://dblp.org/rec/conf/iwqos/XuJZZW0W0021.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Vehicle to Vehicle (V2V) communication opens a new way to make vehicles directly communicate with each other, providing faster responses for time-sensitive tasks than cellular networks. Effective V2V routing protocols are essential yet challenging, as the high dynamic road environment makes communication easy to break. Many prediction methods proposed in the existing protocols to address this issue are either flawed or have a poor effect. In this paper, to cope with the two aspects of the problems that cause communication interrupt, i.e., link breaks and route quality degradation, we design an acceleration-based trajectory prediction algorithm to estimate the link lifetime, and a machine learning model to predict route quality. Based on the prediction algorithms, we propose PQR, a Prediction-supported Quality-aware Routing protocol, which can proactively switch to a better route before the current link breaks or the route quality degrades. Especially, considering the limitations of the current routing protocols, we elaborate a new hybrid routing protocol that integrates the topology-based method and location-based method to achieve instant communication. Simulation results show that PQR outperforms the existing protocols in Packet Delivery Ratio (PDR), Roundtrip Time (RTT), and Normalized Routing Overhead (NRO). Specifically, we have also implemented a vehicular testbed to demonstrate PQRâ€™s real-world performance, and results show that PQR achieves almost no packet loss with latency less than 10ms during route handoff for topology change.}
}


@inproceedings{DBLP:conf/iwqos/HuangDY0ZKCXDC21,
	author = {Xiaojie Huang and
                  Jiaqing Dong and
                  Wenzheng Yang and
                  Chen Tian and
                  Jun Zhou and
                  Yi Kai and
                  Mingjie Cai and
                  Nai Xia and
                  Wanchun Dou and
                  Guihai Chen},
	title = {Clean: Minimize Switch Queue Length via Transparent ECN-proxy in Campus
                  Networks},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--6},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521295},
	doi = {10.1109/IWQOS52092.2021.9521295},
	timestamp = {Sat, 09 Apr 2022 12:39:09 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/HuangDY0ZKCXDC21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Campus networks are widely deployed for organizations like universities and large companies. Applications and network-based services require campus networks to guarantee short queue and provide low latency and large bandwidth. However, the widely adopted packet-loss-based congestion control mechanism in client hosts builds up long queues in the switch buffer, which is prone to packet loss in burst scenarios, resulting in great network delay. Therefore, a scheme for efficiently controlling queue length of shallow buffer switches in campus networks is urgently needed. Explicit Congestion Notification(ECN) as an explicit feedback mechanism is widely adopted in data center networks to build lossless networks. In this paper, we propose Clean, an efficient queue length control scheme based on transparent ECN-proxy for campus networks. Clean is able to exert fine-grained control over arbitrary client TCP stacks by enforcing per-flow congestion control in the access point(AP). It allows the campus network switches to maintain a low queue length, resulting in high throughput, low latency and zero packet loss. Evaluation results demonstrate that Clean reduces the maximum queue length of the switch by 86% and reduces the 99th percentile latency by 85%. Clean also achieves zero packet loss in burst scenarios.}
}


@inproceedings{DBLP:conf/iwqos/TanLL0L21,
	author = {Xiaobin Tan and
                  Simin Li and
                  Yangyang Liu and
                  Quan Zheng and
                  Dezheng Liu},
	title = {QoE-assured Live Video Streaming Based on Coalition Game in 5G eMBMS
                  Networks},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--6},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521296},
	doi = {10.1109/IWQOS52092.2021.9521296},
	timestamp = {Tue, 31 Aug 2021 11:59:55 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/TanLL0L21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The scenario that quantities of users subscribing to a same live video content cluster together in a spatially local area poses challenges to cellular operators even in 5G unicast networks. In this regard, we propose a network paradigm exploiting eMBMS and edge computing, which relieves resource starvation in both backbone and wired access networks by grouping users and distributing the desired content to each multicast group only once. However, problems are raised by operators to perform an optimal server-side decision: how to partition users with the heterogeneity and dynamic of channel conditions, how to fairly and optimally allot resources considering both unicast and multicast users, and how to maximize the overall QoE of this live video service. To cope with these coupled problems, we formulate an optimization model based on coalition game with QoE assured, which defines a fair allocation strategy according to respective contributions and a dynamic grouping method. Subsequently, we propose a heuristic algorithm with a low-time complexity that guarantees QoE for most users and shows conspicuous reduction of annoying stalling events. Noticeably, numerical simulations reveal the fairness and near-optimality of our algorithm compared with state-of-the-art approaches in multiple scenarios.}
}


@inproceedings{DBLP:conf/iwqos/ShenWWL21,
	author = {Linfeng Shen and
                  Fangxin Wang and
                  Feng Wang and
                  Jiangchuan Liu},
	title = {Workload Migration across Distributed Data Centers under Electrical
                  Load Shedding},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--6},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521297},
	doi = {10.1109/IWQOS52092.2021.9521297},
	timestamp = {Fri, 01 Apr 2022 08:56:28 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/ShenWWL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Data centers are essential components in the current digital world. The number and scales of data centers have both increased a lot in recent years. The distributed data centers are standing out as a promising solution due to the development of modern applications which need a massive amount of computation resource and strict response requirement. However, compared to centralized data centers, distributed data centers are more fragile when the power supply is unstable. Power constraints or outages because of electrical load shedding or other reasons will significantly affect the service performance of data centers and damage the quality of service (QoS) for customers. Moreover, unlike conventional data centers, distributed data centers are often unattended, so we need a system that can automatically calculate the best workload schedule to maximize profit in such situations. In this paper, we closely investigate the influence of electrical load shedding in distributed data centers and construct a physical model to estimate the relationship among power, heat and workload. We then use queueing theory to approximate the tasksâ€™ response time and aim to minimize the overall response time of tasks by migration. Our extensive evaluations show that our method can improve the response time with more than 9% reduction.}
}


@inproceedings{DBLP:conf/iwqos/XuLLZQ21,
	author = {Renhai Xu and
                  Wenxin Li and
                  Keqiu Li and
                  Xiaobo Zhou and
                  Heng Qi},
	title = {DarkTE: Towards Dark Traffic Engineering in Data Center Networks with
                  Ensemble Learning},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521298},
	doi = {10.1109/IWQOS52092.2021.9521298},
	timestamp = {Tue, 01 Mar 2022 17:47:38 +0100},
	biburl = {https://dblp.org/rec/conf/iwqos/XuLLZQ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Over the last decade, traffic engineering (TE) has always been a research hotspot in data center networks. For routing flows efficiently and practically, existing TE schemes explore experience-driven heuristics or machine learning (ML) techniques to predict/identify network flowsâ€™ size information. However, these TE schemes have significant limitations: they either identify the flow size information too late or are unaware of the ML modelsâ€™ prediction errors. In this paper, we present DarkTE, a novel TE solution that can learn to predict flow size information timely for achieving better routing performance while being robust to the prediction errors. At its heart, DarkTE employs an ensemble learning technique (i.e., random forest) to classify flows into mice and elephant flows with high accuracy. It then leverages a confidence-based rate allocation and path selection scheme to mitigate the occasional classification errors. Large-scale simulations demonstrate that DarkTE classifies flows within hundreds of microseconds, and the classification accuracy is at least 86.4% over three different realistic workloads. Further, DarkTE completes flows 2.94 times faster on average and makes more links to experience over 90% bandwidth utilization than the Hedera solution.}
}


@inproceedings{DBLP:conf/iwqos/WuYD21,
	author = {Tao Wu and
                  Panlong Yang and
                  Haipeng Dai},
	title = {Charging on the Move: Scheduling Static Chargers with Tunable Power
                  for Mobile Devices},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521299},
	doi = {10.1109/IWQOS52092.2021.9521299},
	timestamp = {Mon, 09 May 2022 09:36:46 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/WuYD21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The breakthrough of Wireless Power Transfer (WPT) technique provides a promising paradigm to tackle the energy limitation problem for end-devices when replenishing energy wirelessly without the need of replacing battery. Existing works seldom consider the mobility of rechargeable devices like miniature sensors on-body or implanted medical devices which may induce great gap between practical energy supply and demand. In this paper, we study the novel issue of Charging on the Move (CM) to optimize the scheduling of transmitting power of static chargers for mobile devices. Unfortunately, solving this problem is non-trivial, because it involves nonlinearity due to time-varying distances caused by movement. Besides, charging scheduling with tunable power level is a variant of budgeted maximum coverage problem, which is NP-hard. To address CM, we approximate the variational charging power as piecewise constant power, and divide the movement trajectories with approximated charging utility. Then, we first consider our problem with fixed power level, where each charger can be scheduled off or on at a fixed power level. We prove the submodularity of the objective function and design a .. approximation algorithm. On this basis, we further bound the performance loss during the problem reformulation, and finally propose a\n1âˆ’1/e\n2(1+Îµ)T\napproximation algorithm for tunable scheduling strategy, where T is the maximum power level. Extensive simulations and trace-driven evaluations are conducted to evaluate the performance of our proposed algorithm.}
}


@inproceedings{DBLP:conf/iwqos/HanawaMYS21,
	author = {Hiroki Hanawa and
                  Takumi Miyoshi and
                  Taku Yamazaki and
                  Thomas Silverston},
	title = {Adaptive Search Area Configuration for Location-based {P2P} Networks},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--2},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521300},
	doi = {10.1109/IWQOS52092.2021.9521300},
	timestamp = {Tue, 31 Aug 2021 11:59:55 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/HanawaMYS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper proposes an adaptive peer search method that considers the dynamic usersâ€™ mobility in location-based peer-to-peer (P2P) networks. In the previous study, the neighbor peer search is periodically executed, and the search area is constantly fixed as a circle regardless of the peersâ€™ moving speed. Therefore, it is difficult to properly acquire on neighbor peers, especially in the situation when peers are moving at high speed. In this paper, we suggest a method to determine the peer search interval and the search area size adaptively depending on the peersâ€™ locations and moving speed. Simulation results show that the proposed method enables peers to search neighbor peers at appropriate intervals and to obtain nearby information efficiently.}
}


@inproceedings{DBLP:conf/iwqos/WangZWH21,
	author = {Zibo Wang and
                  Yifei Zhu and
                  Dan Wang and
                  Zhu Han},
	title = {FedACS: Federated Skewness Analytics in Heterogeneous Decentralized
                  Data Environments},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521301},
	doi = {10.1109/IWQOS52092.2021.9521301},
	timestamp = {Sat, 30 Sep 2023 09:51:34 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/WangZWH21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The emerging federated optimization paradigm performs data mining or artificial intelligence techniques locally on the edge devices, enabling scientists and engineers to utilize the blooming edge data with privacy protection. In such a paradigm, since data cannot be shared or gathered, data heterogeneity naturally emerges, which significantly degrades the performance of federated optimization, ultimately leading to poor quality of federated services. In this paper, we present the first work on characterizing the data heterogeneity in the framework of federated analytics, i.e., to collectively carry out analytics tasks without raw data sharing, and use the information to create a desirable data environment via intelligent client selection. Our proposed Analytics-driven Client Selection framework, named FedACS, tackles the data heterogeneity problem in three steps. First, clients are in charge of generating insights about local data without disclosure of sensitive information. Then, the server uses these insights to infer the situation of clientsâ€™ data heterogeneity based on the Hoeffdingâ€™s inequality. Finally, a dueling bandit is formulated to intelligently select clients with slighter data heterogeneity to form a desirable client pool. FedACS can be universally applied to all kinds of federated optimization tasks, and gains benefits including privacy protection, infrastructure reuse, and client load reduction. To test its efficiency, we further customize it to assist federated learning, a popular scenario of federated optimization. According to experiment results, FedACS reduces the accuracy degrading by up to 65.6%, and speeds up the convergence for up to 2.4 times.}
}


@inproceedings{DBLP:conf/iwqos/ZhouNWLLKZZ21,
	author = {Hao Zhou and
                  Zhiheng Niu and
                  Gang Wang and
                  Xiaoguang Liu and
                  Dongshi Liu and
                  Bingnan Kang and
                  Hu Zheng and
                  Yong Zhang},
	title = {A Proactive Failure Tolerant Mechanism for SSDs Storage Systems based
                  on Unsupervised Learning},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521302},
	doi = {10.1109/IWQOS52092.2021.9521302},
	timestamp = {Tue, 16 Jul 2024 20:30:52 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/ZhouNWLLKZZ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As a proactive failure tolerant mechanism in large scale cloud storage systems, drive failure prediction can be used to protect data by early warning before real failures of drives, and therefore improve system dependability and cloud storage service quality. At present, solid state drives (SSDs) are generally widely used in cloud storage systems due to their high performance. SSD failures seriously affect the dependability of the system and the quality of service. Existing proactive failure tolerant mechanisms for storage systems are basically aimed at HDD failure detection and use classification technology (Supervised learning), which relies on enough failure data to establish a classification model. However, the low failure rate of SSDs leads to a serious imbalance in the ratio of positive and negative samples, which brings a big challenge for establishing a proactive failure tolerance mechanism for SSDs storage systems by using classification technology.In this paper, we propose a proactive failure tolerance mechanism for SSDs storage systems based on unsupervised technology. It only uses data of normal SSDs to train the failure prediction model, which means that our method is not limited by the imbalance in SSDs data. At the core of our method is the idea to use VAE-LSTM to learn the pattern of normal SSDs, in which case faulty SSDs can be alerted when their patterns are very different from normal ones. Our method can provide early warning of failures, thereby effectively protecting data and improving the quality of cloud storage service. We also propose a drive failure cause location mechanism, which can help operators analyze the modes of failure by providing guiding suggestions. In order to evaluate the effectiveness of our method, we use cross-validation and online testing methods on SSDs data from a technology company. The results show that the FDR and FAR of our method outperform the baselines by 17.25% and 2.39% on average.}
}


@inproceedings{DBLP:conf/iwqos/GengX0LYLZ21,
	author = {Nan Geng and
                  Mingwei Xu and
                  Yuan Yang and
                  Chenyi Liu and
                  Jiahai Yang and
                  Qi Li and
                  Shize Zhang},
	title = {Distributed and Adaptive Traffic Engineering with Deep Reinforcement
                  Learning},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521303},
	doi = {10.1109/IWQOS52092.2021.9521303},
	timestamp = {Fri, 14 Apr 2023 18:21:50 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/GengX0LYLZ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Lots of studies focus on distributed traffic engineering (TE) where routers make routing decisions independently. Existing approaches usually tackle distributed TE problems through traditional optimization methods. However, due to the intrinsic complexity of the distributed TE problems, routing decisions cannot be obtained efficiently, which leads to significant performance degradation, especially for highly dynamic traffic. Emerging machine learning technologies like deep reinforcement learning (DRL) provide a new choice to address TE problems in an experience-driven method. In this paper, we propose DATE, a distributed and adaptive TE framework with DRL. DATE distributes well-trained agents to the routers in the located network. Each agent makes local routing decisions independently based on link utilization ratios flooded by each router periodically. To coordinate the distributed agents to achieve the global optimization in different traffic conditions, we construct candidate paths, develop the agents carefully, and realize a virtual environment to train the agents with a DRL algorithm. We do extensive simulations and experiments using real-world network topologies with both real and synthetic traffic traces. The results show that DATE outperforms some existing approaches and yields near-optimal performance with superior robustness.}
}


@inproceedings{DBLP:conf/iwqos/Duan021,
	author = {Yubin Duan and
                  Jie Wu},
	title = {Computation Offloading Scheduling for Deep Neural Network Inference
                  in Mobile Computing},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521304},
	doi = {10.1109/IWQOS52092.2021.9521304},
	timestamp = {Tue, 31 Aug 2021 11:59:55 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/Duan021.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The quality of service (QoS) of intelligent applications on mobile devices heavily depends on the inference speed of Deep Neural Network (DNN) models. Cooperative DNN inference has become an efficient way to reduce inference latency. In cooperative inference, a mobile device offloads a part of its inference task to cloud servers. The large communication volume usually is the bottleneck of such systems. Priory research focuses on reducing the communication volume by finding optimal partition points. We notice that the computation and communication resources on mobile devices can work in pipeline, which can hide the communication time behind computation and further reduce the inference latency. Based on the observation, we formulate the offloading pipeline scheduling problem. We aim to find the optimal sequence of DNN execution and offloading for mobile devices such that the inference latency is minimized. If we use a directed acyclic graph (DAG) to model a DNN, the complex precedence constraints in DAGs bring challenges to our problem. Notice that most DNN models have independent paths or tree structures, we present an optimal path-wise DAG scheduler and an optimal layer-wise scheduler for tree-structure DAGs. Then, we proposed a heuristic based on topological sort to schedule general-structure DAGs. The prototype of our offloading scheme is implemented on a real-world testbed, where we use Raspberry Pi as the mobile device and lab PCs as the cloud. Various DNN models are tested and our scheme can reduce their inference latencies in different network environments.}
}


@inproceedings{DBLP:conf/iwqos/ZhouZHZCTLL21,
	author = {Wangqiu Zhou and
                  Hao Zhou and
                  Wenxiong Hua and
                  Fengyu Zhou and
                  Xiang Cui and
                  Suhua Tang and
                  Zhi Liu and
                  Xiang{-}Yang Li},
	title = {{IMP:} Impedance Matching Enhanced Power-Delivered-to-Load Optimization
                  for Magnetic {MIMO} Wireless Power Transfer System},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521305},
	doi = {10.1109/IWQOS52092.2021.9521305},
	timestamp = {Wed, 13 Jul 2022 16:27:24 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/ZhouZHZCTLL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recently, multiple-input multiple-output (MIMO) technology has been introduced into magnetic resonant coupling (MRC) enabled wireless power transfer (WPT) systems for concurrent charging of multiple devices. However, impedance mismatching phenomena caused by strong TX-RX or RX-RX coupling greatly affect the power delivered to load (PDL) in practical charging systems. To solve this issue, we propose an effective scheduling algorithm for Impedance Matching enhanced PDL optimization in MIMO MRC-WPT systems (called IMP), which integrates the transmitter scheduling together with the impedance matching techniques, i.e., adjusting TX coils for tuning TX-RX coupling and grouping RXs to separate strongly coupled RX pairs. We formulate this as a joint optimization problem and decouple it into three sub-problems, i.e., current scheduling, coil adjustment, and RX grouping, and solve them through alternating direction method of multipliers (ADMM) based, tabu search (TS) based, and graph clique cover based algorithms, respectively. Extensive experiments are performed on a prototype testbed, and the results demonstrate the effectiveness of our solution. Compared with the state-of-the-art power transfer efficiency (PTE) maximization solution, the proposed algorithm IMP achieves a 74.7X performance improvement of PDL on average.}
}


@inproceedings{DBLP:conf/iwqos/ZhengHLZG21,
	author = {Jian Zheng and
                  Huawei Huang and
                  Canlin Li and
                  Zibin Zheng and
                  Song Guo},
	title = {Revisiting Double-Spending Attacks on the Bitcoin Blockchain: New
                  Findings},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--6},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521306},
	doi = {10.1109/IWQOS52092.2021.9521306},
	timestamp = {Sat, 09 Apr 2022 12:39:09 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/ZhengHLZG21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Bitcoin is currently the cryptocurrency with the largest market share. Many previous studies have explored the security of Bitcoin from the perspective of blockchain mining. Especially on the double-spending attacks (DSA), some state-of-the-art studies have proposed various analytical models, aiming to understand the insights behind the double-spending attacks. However, we believe that advanced versions of DSA can be developed to create new threats for the Bitcoin ecosystem. To this end, this paper mainly presents a new type of double-spending attack named Adaptive DSA in the context of the Bitcoin blockchain, and discloses the associated insights. In our analytical model, the double-spending attack is converted into a Markov Decision Process. We then exploit the Stochastic Dynamic Programming (SDP) approach to obtain the optimal attack strategies towards Adaptive DSA. Through the proposed analytical model and the disclosed insights behind Adaptive DSA, we aim to alert the Bitcoin ecosystem that the threat of double-spending attacks is still at a dangerous level.}
}


@inproceedings{DBLP:conf/iwqos/Wei00L21,
	author = {Dawei Wei and
                  Ning Xi and
                  Jianfeng Ma and
                  Jiayi Li},
	title = {Protecting Your Offloading Preference: Privacy-aware Online Computation
                  Offloading in Mobile Blockchain},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521307},
	doi = {10.1109/IWQOS52092.2021.9521307},
	timestamp = {Tue, 31 Aug 2021 11:59:55 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/Wei00L21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The high computational capacity demanded in blockchain mining hinders the involvement of mobile devices due to their limited computation power. Offloading the blockchain mining task to base stations (BSs) is a promising solution for mobile blockchain. Recently, many reinforcement learning (RL)-based approaches achieve the long-term performance of Quality of Service (QoS) during online computation offloading, but they fail to consider the risk of privacy leakage. Existing works for privacy preserving share an unresolved problem that they provide a private mechanism by adding private constraints into the value function of RL algorithm but neglect to protect the value function itself. Hence, we investigate a novel privacy issue caused by value function leakage, named offloading preference leakage. To solve this issue, we propose a privacy-aware deep RL method (PA-DRL) for computation offloading over the mobile blockchain. Specifically, a functional noise is generated, then added to the exploring and policy updating processes of DRL. Furthermore, we adopt a cooperative exploring mechanism and prioritized experience replay (PER) to improve the convergence rate of the proposed method. We provide the theoretical analysis for privacy preserving and convergence. Finally, simulation results show that our method can perform cost-efficient computation offloading, compared with benchmark methods.}
}


@inproceedings{DBLP:conf/iwqos/FengWWW21,
	author = {Cuiying Feng and
                  Luning Wang and
                  Kui Wu and
                  Jianping Wang},
	title = {Controlling the Maximum Link Estimation Error in Network Performance
                  Tomography},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--7},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521308},
	doi = {10.1109/IWQOS52092.2021.9521308},
	timestamp = {Sun, 02 Oct 2022 16:10:47 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/FengWWW21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Network performance tomography uses a small number of strategically deployed monitors to infer the link performance in a large network. With the limited number of monitors, however, people usually can only estimate the bound rather than the exact values of network link performance. We aim at developing an effective solution to minimize the maximum error bound (\\mathcal{M}\\mathcal{E}\\mathcal{B}\n) over all the links in the network. To achieve this, we develop a method that theoretically guarantees (1) the minimum number of monitors required to bring down the \\mathcal{M}\\mathcal{E}\\mathcal{B}\nover all unidentifiable links, and (2) the best places where these new monitors should be deployed. Using this method repeatedly, we can push down the \\mathcal{M}\\mathcal{E}\\mathcal{B}\ngradually until the desired level is reached. In addition, we develop a new sequential measurement technique that reduces the number of measurement paths and in the meantime guarantees the tightest link error bound. With extensive simulation over real-world network topology, we demonstrate the effectiveness and robustness of our solution in reducing the maximum link error bound with network performance tomography.}
}


@inproceedings{DBLP:conf/iwqos/ObioduARSM21,
	author = {Emeka Obiodu and
                  Abdullahi Abubakar and
                  Aravindh Raman and
                  Nishanth Sastry and
                  Simone Mangiante},
	title = {To share or not to share: reliability assurance via redundant cellular
                  connectivity in Connected Cars},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--6},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521309},
	doi = {10.1109/IWQOS52092.2021.9521309},
	timestamp = {Sun, 12 Nov 2023 02:07:25 +0100},
	biburl = {https://dblp.org/rec/conf/iwqos/ObioduARSM21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As adoption of connected cars (CCs) grows, the expectation is that 5G will better support safety-critical vehicle-to-everything (V2X) use cases. Operationally, most relationships between cellular network providers and car manufacturers or users are exclusive, providing a single network connectivity, with at best an occasional option of a back-up plan if the single network is unavailable. We question if this setup can provide QoS assurance for V2X use cases. Accordingly, in this paper, we investigate the role of redundancy in providing QoS assurance for cellular connectivity for CCs. Using our bespoke Android measurement app, we did a drive-through test on 380 kilometers of major and minor roads in South East England. We measured round trip times, jitter, page load times, packet loss, network type, uplink speed and downlink speeds on the four UK networks for 14 UK-centric websites every five minutes. In addition, we did the same measurement using a much more expensive universal SIM card provider that promises to fall back on any of the four UK networks to assure reliability. By comparing actual performance on the best performing network versus the universal SIM, and then projected performance of a two/three/four multi-operator setup, we make three major contributions. First, the use of redundant multi-connectivity, especially if managed by the demand-side, can deliver superior performance (up to 28 percentage points in some cases). Second, despite costing 95x more per GB of data, the universal SIM performed worse than the best performing network except for uplink speed, highlighting how the choice of parameter to monitor can influence operational decisions. Third, any assessment of CC connectivity reliability based on availability is sub-optimal as it can hide significant under-performance.}
}


@inproceedings{DBLP:conf/iwqos/WuCCHZ21,
	author = {Hua Wu and
                  Xiying Chen and
                  Guang Cheng and
                  Xiaoyan Hu and
                  Youqiong Zhuang},
	title = {{BCAC:} Batch Classifier based on Agglomerative Clustering for traffic
                  classification in a backbone network},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521310},
	doi = {10.1109/IWQOS52092.2021.9521310},
	timestamp = {Fri, 29 Jul 2022 09:29:21 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/WuCCHZ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Backbone network is the core part of the Internet. Due to the high transmission speed of traffic in the backbone network, Quality of Service (QoS) monitoring of services in the backbone network becomes a highly important and challenging issue. Traffic classification is the basis of QoS monitoring. The existing traffic classification is based on full traffic, which is impractical in high-speed backbone network traffic. This paper presents a method to classify the sampled traffic and gives an example of its application in QoS monitoring. Specifically, we design the Multiple Counter Sketch (MC Sketch) to quickly extract features from the sampled data stream in a backbone, propose the Batch Classifier based on Agglomerative Clustering (BCAC) for unsupervised clustering of traffic, and combine with the supervised machine learning method to train the labeled data in the clustering results to get the classification model. The experimental results of sampled traffic collected on a 10Gbps link show that even when the sampling ratio is 1:1024, the accuracy of our classification model reaches 96.3%. When different block sizes are set, the average clustering time of BCAC is only about one-third of the traditional agglomerative classifier. Moreover, we give an example of applying our traffic classification method to monitor the QoS, and the results show that our method can efficiently and accurately monitor the QoS dynamics of backbone network traffic.}
}


@inproceedings{DBLP:conf/iwqos/RezaeiAV21,
	author = {Hamed Rezaei and
                  Hamidreza Almasi and
                  Balajee Vamanan},
	title = {Smartbuf: An Agile Memory Management for Shared-Memory Switches in
                  Datacenters},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--7},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521311},
	doi = {10.1109/IWQOS52092.2021.9521311},
	timestamp = {Sun, 02 Oct 2022 16:10:47 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/RezaeiAV21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Important datacenter applications generate extremely bursty traffic patterns and demand low latency tails as well as high throughput. Datacenter networks employ shallow-buffered, shared-memory switches to cut cost and to cope up with ever-increasing link speeds. End-to-end congestion control cannot react in time to handle bursty, short flows that dominate datacenter traffic and they incur buffer overflows, which cause long latency tails and degrade throughput. Therefore, there is a need for agile, switch-local mechanisms that quickly sense congestion and provision enough buffer space dynamically to avoid costly buffer overflows. We propose Smartbuf, an online learning algorithm that accurately predicts buffer requirement of each switch port before the onset of congestion. Our key novelty lies in fingerprinting bursts based on the gradient of queue length and using this information to provision just enough buffer space. Our preliminary evaluations show that our algorithm can predict buffer demands accurately within an average error margin of 6% and achieve an improvement in the 99 th percentile latency by a factor of 8x at high loads, while providing good fairness among ports.}
}


@inproceedings{DBLP:conf/iwqos/KouZSW21,
	author = {Ziyi Kou and
                  Yang Zhang and
                  Lanyu Shang and
                  Dong Wang},
	title = {FairCrowd: Fair Human Face Dataset Sampling via Batch-Level Crowdsourcing
                  Bias Inference},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521312},
	doi = {10.1109/IWQOS52092.2021.9521312},
	timestamp = {Tue, 15 Mar 2022 17:41:08 +0100},
	biburl = {https://dblp.org/rec/conf/iwqos/KouZSW21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Human face image is a large category of visual information utilized by various human facial data services (e.g., face recognition, face generation, face attribute prediction). However, the quality of data services (QoDS) on human face datasets is usually biased towards the majority demographic group due to the data imbalance issue. In this paper, we focus on a fair human face dataset sampling problem where the goal is to sample a sub-dataset from the original dataset to reduce its bias by leveraging crowd intelligence to infer the demographic labels of face images (e.g., male or female, old or young). Our problem is motivated by the limitations of current fair data sampling solutions that require pre-annotated demographic labels to sample a fair dataset. Two important challenges exist in solving our problem: 1) it is extremely time-consuming and expensive to assign crowd workers to annotate demographic labels of all images in a large-scale facial dataset; 2) it is not a trivial task to improve the fairness of the sampled sub-dataset (with fewer data samples) without sacrificing the accuracy performance of data services on such dataset. To address the above challenges, we develop FairCrowd, a fair crowdsourcing-based data sampling framework that leverages an efficient batch-level demographic label inference model and a joint fair-accuracy-aware data shuffling method. We evaluate the performance of FairCrowd through a large-scale real-world face image dataset that consists of celebrity faces from a diversified set of demographic groups. The results show that FairCrowd not only reduces demographic bias but also improves the accuracy of data services trained on the sub-dataset generated by FairCrowd, leading to a more desirable QoDS of the application.}
}


@inproceedings{DBLP:conf/iwqos/LvC021,
	author = {Jiamei Lv and
                  Gonglong Chen and
                  Wei Dong},
	title = {Isolayer: The Case for an IoT Protocol Isolation Layer},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521313},
	doi = {10.1109/IWQOS52092.2021.9521313},
	timestamp = {Tue, 31 Aug 2021 11:59:55 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/LvC021.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Internet of Things (IoT), which connects a large number of devices with wireless connectivity, has come into the spotlight. Various wireless radio technologies and application protocols are proposed. Due to scarce channel resources, different network traffic may do interact in negative ways. This paper argues that there should be an isolation layer in IoT network communication stacks making each trafficâ€™s perception of the wireless channel independent of what other traffic is running.We present Isolayer, an isolation layer design providing fine-grained and flexible channel isolation services in the heterogeneous IoT networks. By a shared collision avoidance module, Isolayer can provide effective isolation even between different wireless technologies (e.g., BLE and 802.15.4). Isolayer provides four levels of isolation services for users, i.e., protocol level, packet-type level and source-/destination-address level. Considering the various isolation requirements in practice, we design a domain-specific language for users to specify the key logic of their requirements. Taking the codes as input, Isolayer generates the control packets automatically and lets related nodes that receive the control packets update their isolation services correspondingly.We implement Isolayer on realistic IoT nodes, i.e., TI CC2650, Heltec LoRa node 151, and perform extensive evaluations. The results show that: (1) Isolayer incurs acceptable overhead in terms of delay and memory usage; (2) Isolayer provides effective isolation service in the heterogeneous IoT network. (3) Isolayer achieves about 18.6% reduction of the end-to-end delay of isolated packets in the IoT network with heavy traffic load.}
}


@inproceedings{DBLP:conf/iwqos/ZhangCLWX21,
	author = {Yuchao Zhang and
                  Peizhuang Cong and
                  Bin Liu and
                  Wendong Wang and
                  Ke Xu},
	title = {{AIR:} An AI-based {TCAM} Entry Replacement Scheme for Routers},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521314},
	doi = {10.1109/IWQOS52092.2021.9521314},
	timestamp = {Wed, 07 Dec 2022 23:11:34 +0100},
	biburl = {https://dblp.org/rec/conf/iwqos/ZhangCLWX21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Ternary Content Addressable Memory (TCAM) is an important hardware used to store route entries in routers, which is used to assist routers to make fast decision on forwarding packets. In order to cope with the explosion of route entries due to massive IP terminals brought by 5G and the Internet of Things (IoT), todayâ€™s commercial TCAM has to keep the corresponding growth in capacity. But large TCAM capacity is causing many problems such as circuit design difficulties, production costs, and high energy consumption, so it is urgent to design a lightweight TCAM with small capacity while still maintains the original query performance.Designing such a TCAM faces two fundamental challenges. Firstly, it is essential to accurately predict the incoming flows in order to cache correct entries in limited TCAM capacity, but prediction on aggregated time-sequential data is challenging in the massive IoT scenarios. Secondly, the prediction algorithm needs to be real-time as the lookup process is in line-rate. In order to address the above two challenges, in this paper, we proposed a lightweight AI-based solution, called AIR, where we successfully decoupled the route entries and designed a parallel-LSTM prediction method. The experiment results under real backbone traffic showed that we successfully achieved comparable query performance by using just 1/8 TCAM size.}
}


@inproceedings{DBLP:conf/iwqos/WyssGLP21,
	author = {Marc Wyss and
                  Giacomo Giuliari and
                  Markus Legner and
                  Adrian Perrig},
	title = {Secure and Scalable QoS for Critical Applications},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521315},
	doi = {10.1109/IWQOS52092.2021.9521315},
	timestamp = {Wed, 07 Dec 2022 23:11:34 +0100},
	biburl = {https://dblp.org/rec/conf/iwqos/WyssGLP21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the proliferation of online payment systems, the emergence of globally distributed consensus algorithms, and the increase of remotely managed critical IoT infrastructure, the need for critical-yet-frugal communicationâ€”high-availability and low-rateâ€”is becoming increasingly pressing. For many of these applications, the use of leased lines or SD-WAN solutions is impractical due to their inflexibility and high costs, while standard Internet communication lacks the necessary reliability and attack resilience.To address this rising demand for strong quality-of-service (QoS) guarantees, we develop the GMA-based light-weight communication protocol (GLWP), building on a recent theoretical result, the GMA algorithm. GLWP is a capability-based protocol which is able to bootstrap network-wide bandwidth allocations in single round-trip times, and achieves high availability even under active attacks. Due to its clever use of cryptographic mechanisms, GLWP introduces minimal state in the network and causes low computation and communication overhead. We implement a GLWP prototype using Intel DPDK and show that it achieves line rate on a 40 Gbps link running on commodity hardware, thus showing that GLWP is a viable solution to provide strong QoS guarantees for critical-yet-frugal communications.}
}


@inproceedings{DBLP:conf/iwqos/MaoXHLZX21,
	author = {Kelong Mao and
                  Xi Xiao and
                  Guangwu Hu and
                  Xiapu Luo and
                  Bin Zhang and
                  Shutao Xia},
	title = {Byte-Label Joint Attention Learning for Packet-grained Network Traffic
                  Classification},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521316},
	doi = {10.1109/IWQOS52092.2021.9521316},
	timestamp = {Thu, 07 Oct 2021 08:37:35 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/MaoXHLZX21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Network traffic classification (TC) is to classify network traffic into a specific class which plays a fundamental role in terms of network measurement, network management, and so on. In this work, we focus on packet-grained traffic classification. We find that previous packet-grained methods based on the analogy between traffic packet and image or text are not sufficiently reasonable, leading to a sub-optimal performance on both accuracy and efficiency that still can be largely improved. In this paper, we devise a new method, called BLJAN, to jointly learn from byte sequence and labels for packet-grained traffic classification. BLJAN embeds the packetâ€™s bytes and all labels into a joint embedding space to capture their implicit correlations with a dual attention mechanism. It finally builds a more powerful packet representation with an enhancement from label embeddings to achieve high classification accuracy and interpretability. Extensive experiments on two benchmark traffic classification tasks, including application identification and traffic characterization, with three real-world datasets, demonstrate that BLJAN can achieve high performance (96.2%, 96.7%, and 99.7% Macro F1-scores on three datasets) for packet-grained traffic classification, outperforming six representative state-of-the-art baselines in terms of both accuracy and detection speed.}
}


@inproceedings{DBLP:conf/iwqos/ShenWXZ21,
	author = {Meng Shen and
                  Minghui Wang and
                  Ke Xu and
                  Liehuang Zhu},
	title = {Privacy-Preserving Approximate Top-k Nearest Keyword Queries over
                  Encrypted Graphs},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521317},
	doi = {10.1109/IWQOS52092.2021.9521317},
	timestamp = {Fri, 12 May 2023 15:00:49 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/ShenWXZ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the prosperity of graph-based applications, it is increasingly popular for graph nodes to have labels in terms of a set of keywords. The top-k nearest keyword (k-NK) query can find a set of k nearest nodes containing a designated keyword to a given source node. In cloud computing era, graph owners prefer to outsource their graphs to cloud servers, leading to severe privacy risk for conducting k-NK queries. The current studies fail to support efficient and accurate k-NK query under the premise of privacy protection.In this paper, we propose a new graph encryption scheme Aton, which enables efficient and privacy-preserving k-NK querying. Based on the symmetric-key encryption and particular pseudo-random functions, we construct a secure k-NK query index. Aton is built on a ciphertext sum comparison scheme which can achieve approximate distance comparison with high accuracy. Rigorous security analysis proves that it is CQA-2 secure. Experiments with real-world datasets demonstrate that it can efficiently answer k-NK queries with more accurate results compared with the state-of-the-art.}
}


@inproceedings{DBLP:conf/iwqos/CaiHLZS21,
	author = {Yang Cai and
                  Biao Han and
                  Jie Li and
                  Na Zhao and
                  Jinshu Su},
	title = {ModelCoder: {A} Fault Model based Automatic Root Cause Localization
                  Framework for Microservice Systems},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--6},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521318},
	doi = {10.1109/IWQOS52092.2021.9521318},
	timestamp = {Sat, 15 Apr 2023 20:58:53 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/CaiHLZS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Microservice system is an architectural style to develop a single application as a suite of small services running in its process and communicating with lightweight message mechanisms. Although microservice architecture enables rapid, frequent and reliable delivery of large, complex applications, it is increasingly challenging for operational staffs to locate the root cause of a microservice fault, which usually occurs on a service node and propagates to affect the entire system. To this end, in this paper, we first introduce the concept of deployment graph and service dependency graph to depict the deployment status and calling relationship between service nodes. Then we formulate the root cause localization problem in microservice systems based on the constructed graphs, in which fault model is defined to capture the characteristics of a faultâ€™s root cause. A fault model based automatic root cause localization framework called ModelCoder is later developed to figure out the root cause of unknown faults by comparing with the predefined fault models. We evaluate ModelCoder on a real-world microservice system monitoring data set spanning 15 days. Through extensive experiments, it is revealed that ModelCoder can localize the fault root cause nodes within 80 seconds on average and improve the root cause localization accuracy (to 93%) by 12% compared with the state-of-the-art root cause localization algorithm.}
}


@inproceedings{DBLP:conf/iwqos/ChenCXLGL21,
	author = {Sheng Chen and
                  Baochao Chen and
                  Junjie Xie and
                  Xiulong Liu and
                  Deke Guo and
                  Keqiu Li},
	title = {Joint Service Placement for Maximizing the Social Welfare in Edge
                  Federation},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--6},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521319},
	doi = {10.1109/IWQOS52092.2021.9521319},
	timestamp = {Tue, 31 Aug 2021 11:59:55 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/ChenCXLGL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Mobile Edge Computing (MEC) is a promising cloud-network convergence paradigm which provides computational resources close to end devices at the network edge. There exist multiple Edge Infrastructure Providers (EIPs) in MEC which independently manage edges and provide services to customers. Due to the exponentially increasing data generated by end devices, it is almost impossible for a single EIP to accommodate offloaded data. Moreover, when considering that multiple EIPs provide services through federation, an urgent challenge is how to ensure the sustainability of federation. Most of the existing work improves the service provision capabilities of MEC by optimizing service placement without considering the existence of multiple EIPs. In this paper, we design the horizontal collaboration of edge federation, which integrates all edges of all EIPs. First, we model the service placement problem as a programming problem, towards the goal of maximizing social welfare. Then, we propose two dynamic pricing methods for EIPs to determine typical price for customers and insourcing price for other EIPs. The evaluation results based on two real-world data sets demonstrate that our proposed service placement model can increase the total gain of EIPs by up to 24.5% with a decrease of 35.5% in total delay.}
}


@inproceedings{DBLP:conf/iwqos/ZhaoLDJL21,
	author = {Hanyu Zhao and
                  Qing Li and
                  Jingpu Duan and
                  Yong Jiang and
                  Kai Liu},
	title = {FlexNF: Flexible Network Function Orchestration on the Programmable
                  Data Plane},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--6},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521320},
	doi = {10.1109/IWQOS52092.2021.9521320},
	timestamp = {Tue, 04 Jan 2022 17:01:26 +0100},
	biburl = {https://dblp.org/rec/conf/iwqos/ZhaoLDJL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recently, Programmable Data Plane (PDP) has been leveraged to offload Network Functions (NFs). Due to its high processing capabilities, programmable data plane can improve the performance of NFs to more than one order of magnitude. However, the coarse-grained NF orchestration granularity on the PDP makes it hard to fulfill the dynamic service chain demands. In this paper, we propose the Flexible Network Function (FlexNF) Deployment on the programmable data plane. We first design an NF Selection Framework which leverages labels and the pipeline re-enter operation to support Selective Serving Mechanism for flexible NF orchestration. We then design a two-stage service path construction algorithm to provide on-path service based on SSM with load balancing taken into account. We implement 7 types of real network functions in the commodity P4 switch, based which we construct the comprehensive experiments. The results show that FlexNF can reduce the traffic routing delay by about 42.6% while increasing service chain acceptance rate by 5 times compared with current solutions.}
}


@inproceedings{DBLP:conf/iwqos/YuHZ0Z21,
	author = {Xixun Yu and
                  Yidan Hu and
                  Rui Zhang and
                  Zheng Yan and
                  Yanchao Zhang},
	title = {Secure Outsourced Top-k Selection Queries against Untrusted Cloud
                  Service Providers},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521321},
	doi = {10.1109/IWQOS52092.2021.9521321},
	timestamp = {Wed, 21 Dec 2022 16:55:35 +0100},
	biburl = {https://dblp.org/rec/conf/iwqos/YuHZ0Z21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As cloud computing reshapes the global IT industry, an increasing number of business owners have outsourced their datasets to third-party cloud service providers (CSP), which in turn answer data queries from end users on their behalf. A well known security challenge in data outsourcing is that the CSP cannot be fully trusted, which may return inauthentic or unsound query results for various reasons. This paper considers top-k selection queries, an important type of queries widely used in practice. In a top-k selection query, a user specifies a scoring function and asks for the k objects with the highest scores. Despite several recent efforts, existing solutions can only support a limited range of scoring functions with explicit forms known in advance. This paper presents three novel schemes that allow a user to verify the integrity and soundness of any top-k selection query result returned by an untrusted CSP. The first two schemes support monotone scoring functions, and the third scheme supports scoring functions comprised of both monotonically non-decreasing and non-increasing subscoring functions. Detailed simulation studies using a real dataset confirm the efficacy and efficiency of the proposed schemes and their significant advantages over prior solutions.}
}


@inproceedings{DBLP:conf/iwqos/ZhangGWLW021,
	author = {Jianhui Zhang and
                  Siqi Guan and
                  Jiacheng Wang and
                  Liming Liu and
                  Hanxiang Wang and
                  Feng Xia},
	title = {Time-expanded Method Improving Throughput in Dynamic Renewable Networks},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521323},
	doi = {10.1109/IWQOS52092.2021.9521323},
	timestamp = {Thu, 08 Dec 2022 10:28:42 +0100},
	biburl = {https://dblp.org/rec/conf/iwqos/ZhangGWLW021.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the Dynamic Rechargeable Networks (DRNs), the existing studies usually consider the spatio-temporal dynamics of the harvested energy so as to maximize the throughput by efficient energy allocation. However, the network dynamics have seldom been considered simultaneously including the time variable link quality, communication power and battery charge efficiency. Furthermore, the wireless interference brings extra challenge. To take these dynamics into account together, this paper studies the quite challenging problem, the network throughput maximization in the DRNs, by proper energy allocation while considering the additional affection of wireless interference. We introduce the Time-Expanded Graph (TEG) to describe the above dynamics in a feasible easy way, and then look into the scenario where there is only one pair of source-target firstly. To maximize the throughput, this paper designs the Single Pair Throughput maximization (SPT) algorithm based on TEG while considering the wireless interference. In the case of multiple pairs of source-targets, itâ€™s quite complex to solve the network throughput maximization problem directly. This paper introduces the Garg and KÃ¶nemanns framework and then designs the Multiple Pairs Throughput (MPT) algorithm to maximize the overall throughput of all pairs. MPT is a fast approximation solution with the ratio of 1-3Ïµ, where 0 < Ïµ < 1 is a small positive constant. This paper also conducts the extensive numerical evaluation based on the simulated data and the data collected by our real system. The numerical simulation results demonstrate the throughput improvement of our algorithms.}
}


@inproceedings{DBLP:conf/iwqos/ZhangCDWXYZ21,
	author = {Mengqian Zhang and
                  Yukun Cheng and
                  Xiaotie Deng and
                  Bo Wang and
                  Jan Xie and
                  Yuanyuan Yang and
                  Jiarui Zhang},
	title = {Accelerating Transactions Relay in Blockchain Networks via Reputation},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521324},
	doi = {10.1109/IWQOS52092.2021.9521324},
	timestamp = {Tue, 08 Feb 2022 09:07:03 +0100},
	biburl = {https://dblp.org/rec/conf/iwqos/ZhangCDWXYZ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {For a blockchain system, the network layer is of great importance for scalability and security. The critical task of blockchain networks is to provide a fast delivery of data. A rapid spread accelerates the transactions to be included into blocks and then confirmed. Existing blockchain systems, especially the cryptocurrencies like Bitcoin, take a simple strategy that requires relay nodes to verify all received transactions and then forward valid ones to all outbound neighbors. Unfortunately, this design is inefficient and slows down the transmission of transactions. In this paper, we introduce the concept of reputation and propose a novel relay protocol, RepuLay, to accelerate the transmission of transactions across the network. First of all, we design a reputation mechanism to help each node identify the unreliable and inactive neighbors. In this mechanism, two values are used to define oneâ€™s reputation. Each node keeps a local list of reputations of all its neighbors. Based on the reputation mechanism, RepuLay adopts probabilistic strategies to process transactions. More specifically, after receiving a transaction, the relay node verifies it with a certain probability, which is deduced from the first value of senderâ€™s reputation. Next, the valid and unverified transactions are forwarded to some neighbors. Each neighbor has some probability to be chosen as a receiver and the probability is determined by its second value of reputation. Theoretically, we prove that our design can guarantee the quality of relayed transactions. Further simulation results confirm that RepuLay effectively accelerates the spread of transactions and optimize the usage of nodesâ€™ bandwidths.}
}


@inproceedings{DBLP:conf/iwqos/LiX0WW21,
	author = {Teng Li and
                  Zhiyuan Xu and
                  Jian Tang and
                  Kun Wu and
                  Yanzhi Wang},
	title = {{EXTRA:} An Experience-driven Control Framework for Distributed Stream
                  Data Processing with a Variable Number of Threads},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--11},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521325},
	doi = {10.1109/IWQOS52092.2021.9521325},
	timestamp = {Fri, 14 Jun 2024 11:24:16 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/LiX0WW21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we present design, implementation and evaluation of a control framework, EXTRA (Experience-driven conTRol frAmework), for scheduling in general-purpose Distributed Stream Data Processing Systems (DSDPSs). Our design is novel due to the following reasons. First, EXTRA enables a DSDPS to dynamically change the number of threads on the fly according to system states and demands. Most existing methods, however, use a fixed number of threads to carry workload (for each processing unit of an application), which is specified by a user in advance and does not change during runtime. So our design introduces a whole new dimension for control in DSDPSs, which has a great potential to significantly improve system flexibility and efficiency, but makes the scheduling problem much harder. Second, EXTRA leverages an experience/data driven model-free approach for dynamic control using the emerging Deep Reinforcement Learning (DRL), which enables a DSDPS to learn the best way to control itself from its own experience just as a human learns a skill (such as driving and swimming) without any accurate and mathematically solvable model. We implemented it based on a widely-used DSDPS, Apache Storm, and evaluated its performance with three representative Stream Data Processing (SDP) applications: continuous queries, word count (stream version) and log stream processing. Particularly, we performed experiments under realistic settings (where multiple application instances are mixed up together), rather than a simplified setting (where experiments are conducted only on a single application instance) used in most related works. Extensive experimental results show: 1) Compared to Stormâ€™s default scheduler and the state-of-the-art model-based method, EXTRA substantially reduces average end-to-end tuple processing time by 39.6% and 21.6% respectively on average. 2) EXTRA does lead to more flexible and efficient stream data processing by enabling the use of a variable number of threads. 3) EXTRA is robust in a highly dynamic environment with significant workload change.}
}


@inproceedings{DBLP:conf/iwqos/MengR21,
	author = {Qingkai Meng and
                  Fengyuan Ren},
	title = {Lightning: {A} Practical Building Block for {RDMA} Transport Control},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521326},
	doi = {10.1109/IWQOS52092.2021.9521326},
	timestamp = {Tue, 31 Aug 2021 11:59:55 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/MengR21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {RoCEv2 (RDMA over Converged Ethernet version 2) is the canonical method for deploying RDMA in Ethernet-based datacenters. Traditionally, RoCEv2 runs over the lossless network which is in turn achieved by enabling Priority Flow Control (PFC) within the network. However, with the scale of data center increases, PFCâ€™s side effects, such as head-of-line blocking, congestion spreading, and PFC storms, are amplified. Datacenter operators can no longer tolerate these problems. They are seeking PFC alternatives for RDMA networks. Rather than aim at the lossless RDMA network, we instead handle packet loss effectively to support RDMA over Ethernet.In this paper, we propose Lightning, a switch building block to enhance RoCEâ€™s simple loss recovery. Lightning enhances the switches to send loss notifications directly to the sources with high priority, thus informing sources as quickly as possible. Then, sources can retransmit packets sooner. By addressing challenges such as that shared buffer status is not available at ingress in modern switches, Lightning generates loss notification only when the expected packet is dropped and filters other unexpected packets at ingress, so as to avoid timeouts and prevent unnecessary congestion from unexpected packets. We implement Lightning on commodity programmable switches. In our evaluation, Lightning achieves up to 16.08Ã— reduction of 99.9th percentile flow completion time compared to PFC, IRN and other alternatives.}
}


@inproceedings{DBLP:conf/iwqos/YuLLW21,
	author = {Zhaoyang Yu and
                  Wenwen Liu and
                  Xiaoguang Liu and
                  Gang Wang},
	title = {Drag-JDEC: {A} Deep Reinforcement Learning and Graph Neural Network-based
                  Job Dispatching Model in Edge Computing},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521327},
	doi = {10.1109/IWQOS52092.2021.9521327},
	timestamp = {Tue, 18 Jan 2022 17:38:49 +0100},
	biburl = {https://dblp.org/rec/conf/iwqos/YuLLW21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The emergence of edge computing eases latency pressure in remote cloud and computing pressure of terminal devices, providing new solutions for real-time applications. Jobs of end devices are offloaded to a server in the cloud or an edge cluster for execution. Unreasonable job dispatching strategies will not only affect the completion time of tasks violating the usersâ€™ QoS but also reduce the resource utilization of servers increasing the operating costs of service providers. In this paper, we propose an online job dispatching model named Drag-JDEC based on deep reinforcement learning and graph neural network. For natural directed acyclic graph-type jobs, we use a graph attention network to aggregate the features of neighbor nodes and transform them into high-dimensional ones. Combining with the current status of edge servers, the deep reinforcement learning module makes the dispatching decision for each task in the job to keep load balancing and meet the usersâ€™ QoS. Experiments using real job data sets show that Drag-JDEC outperforms traditional and state-of-the-art algorithms for balancing the workload of edge servers and adapts to various edge server configurations well, reaching the maximum improvement of 34.43%.}
}


@inproceedings{DBLP:conf/iwqos/Wu0MZQWZC21,
	author = {Kun Wu and
                  Yibo Jin and
                  Weiwei Miao and
                  Zeng Zeng and
                  Zhuzhong Qian and
                  Jingmian Wang and
                  Mingxian Zhou and
                  Tuo Cao},
	title = {Soudain: Online Adaptive Profile Configuration for Real-time Video
                  Analytics},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521328},
	doi = {10.1109/IWQOS52092.2021.9521328},
	timestamp = {Tue, 31 Aug 2021 11:59:55 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/Wu0MZQWZC21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Since the real-time video analytics with high accuracy requirement is resource-consuming, the profiles regarding such resource-accuracy trade-off are needed before the analytics for better resource allocation at resource-constrained edges. With the inner changes of the video contents, outdated profiles fail to capture the trade-off dynamically over time, which requires the profiles to be updated periodically and incurs an overwhelming resource overhead. Thus, we present Soudain, which dynamically adjusts the configurations in profiles and corresponding profiling intervals to capture the inner changes of multiple video streams at edges. Upon the fine-grained decisions for profiles, we propose an integer program to maximize the accuracy of video analytics in a long-term scope with resource constraint, and then design an algorithm to adjust the profiles in an online manner. We implement Soudain upon the server with GPU. Our testbed evaluations confirm that, by using the live video streams derived from real-world traffic cameras, Soudain ensures the real-time requirement and achieves up to 25% improvement on the detection accuracy, compared with multiple state-of-the-art alternatives.}
}


@inproceedings{DBLP:conf/iwqos/Chen0WMLCZZZW21,
	author = {Xiang Chen and
                  Qun Huang and
                  Peiqiao Wang and
                  Zili Meng and
                  Hongyan Liu and
                  Yuxin Chen and
                  Dong Zhang and
                  Haifeng Zhou and
                  Boyang Zhou and
                  Chunming Wu},
	title = {LightNF: Simplifying Network Function Offloading in Programmable Networks},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521329},
	doi = {10.1109/IWQOS52092.2021.9521329},
	timestamp = {Sat, 30 Sep 2023 09:51:33 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/Chen0WMLCZZZW21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In network function virtualization (NFV), network functions (NFs) are chained as a service function chain (SFC) to enhance NF management with high flexibility. Recent solutions indicate that the processing performance of SFCs can be significantly improved by offloading NFs to programmable switches. However, such offloading requires a deep understanding of NF properties to achieve the maximum SFC performance, which brings non-trivial burdens to network administrators. In this paper, we propose LightNF, a novel system that simplifies NF offloading in programmable networks. LightNF automatically dissects comprehensive NF properties (e.g., NF performance behaviors) via code analysis and performance profiling while eliminating manual efforts. It then leverages the analyzed NF properties in its SFC placement so as to produce the performance-optimal offloading. We have implemented a LightNF prototype. Our experiments show that LightNF outperforms state-of-the-art solutions with an orders-of-magnitude reduction in per-packet processing latency and 9.5Ã— improvement in SFC throughput.}
}


@inproceedings{DBLP:conf/iwqos/ShireyRS21,
	author = {Russell Shirey and
                  Sanjay G. Rao and
                  Shreyas Sundaram},
	title = {Optimizing Quality of Experience for Long-Range {UAS} Video Streaming},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521330},
	doi = {10.1109/IWQOS52092.2021.9521330},
	timestamp = {Mon, 27 Nov 2023 07:47:24 +0100},
	biburl = {https://dblp.org/rec/conf/iwqos/ShireyRS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {There is much emerging interest in operating Unmanned Aerial Systems (UAS) at long-range distances. Unfortunately, it is unclear whether network connectivity at these distances is sufficient to enable applications with stringent performance needs. In this paper, we consider this question in the context of video streaming, an important UAS use-case. We make three contributions. First, we characterize network data collected from real-world UAS flight tests. Our results show that while dropouts (i.e., extended periods of poor performance) present challenges, there is potential to enable video streaming with modest delays, and correlation of throughput with flight path (both distance and orientation) provides new opportunities. Second, we present Proteus, the first system for video streaming targeted at long-range UAS settings. Proteus is distinguished from Adaptive Bit Rate (ABR) algorithms developed for Internet settings by explicitly accounting for dropouts, and leveraging flight path information. Third, through experiments with real-world flight traces on an emulation test-bed, we show that at distances of around 4 miles, Proteus reduces the fraction of a viewing session encountering rebuffering from 14.33% to 1.57%, while also significantly improving well-accepted composite video delivery metrics. Overall, our results show promise for enabling video streaming with dynamic UAS networks at long-range distances.}
}


@inproceedings{DBLP:conf/iwqos/LiuLG21,
	author = {Tao Liu and
                  Peng Li and
                  Yu Gu},
	title = {Glint: Decentralized Federated Graph Learning with Traffic Throttling
                  and Flow Scheduling},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521331},
	doi = {10.1109/IWQOS52092.2021.9521331},
	timestamp = {Fri, 17 Mar 2023 16:38:59 +0100},
	biburl = {https://dblp.org/rec/conf/iwqos/LiuLG21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated learning has been proposed as a promising distributed machine learning paradigm with strong privacy protection on training data. Existing work mainly focuses on training convolutional neural network (CNN) models good at learning on image/voice data. However, many applications generate graph data and graph learning cannot be efficiently supported by existing federated learning techniques. In this paper, we study federated graph learning (FGL) under the cross-silo setting where several servers are connected by a wide-area network, with the objective of improving the Quality-of-Service (QoS) of graph learning tasks. We find that communication becomes the main system bottleneck because of frequent information exchanges among federated severs and limited network bandwidth. To conquer this challenge, we design Glint, a decentralized federated graph learning system with two novel designs: network traffic throttling and priority-based flows scheduling. To evaluate the effectiveness of Glint, we conduct both experiments on a testbed and trace-driven simulations. The results show that Glint can significantly outperform existing federated learning solutions.}
}


@inproceedings{DBLP:conf/iwqos/ZhangZSRW21,
	author = {Yang Zhang and
                  Ruohan Zong and
                  Lanyu Shang and
                  Md. Tahmid Rashid and
                  Dong Wang},
	title = {SuperClass: {A} Deep Duo-Task Learning Approach to Improving QoS in
                  Image-driven Smart Urban Sensing Applications},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--6},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521332},
	doi = {10.1109/IWQOS52092.2021.9521332},
	timestamp = {Thu, 23 Jun 2022 19:55:47 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/ZhangZSRW21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Image-driven smart urban sensing (ISUS) has emerged as a powerful sensing paradigm to capture abundant visual information about the urban environment for intelligent city monitoring, planning, and management. In this paper, we focus on a Classification and Super-resolution Coupling (CSC) problem in ISUS applications, where the goal is to explore the interdependence between two critical tasks (i.e., classification and super-resolution) to concurrently boost the Quality of Service (QoS) of both tasks. Previous efforts often focus on solving the two tasks individually and ignore the opportunity to explore the interdependence between them. In this paper, we develop SuperClass, a deep duo-task learning framework, to effectively integrate the classification and super-resolution tasks into a holistic network design that jointly optimizes the QoS of both tasks. The evaluation results on a real-world ISUS application show that SuperClass consistently outperforms state-of-the-art baselines by simultaneously achieving better land usage classification accuracy and higher reconstructed image quality.}
}


@inproceedings{DBLP:conf/iwqos/0002ZZ21,
	author = {Xin Yao and
                  Rui Zhang and
                  Yanchao Zhang},
	title = {Differential Privacy-Preserving User Linkage across Online Social
                  Networks},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521333},
	doi = {10.1109/IWQOS52092.2021.9521333},
	timestamp = {Fri, 24 Feb 2023 10:06:35 +0100},
	biburl = {https://dblp.org/rec/conf/iwqos/0002ZZ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Many people maintain accounts at multiple online social networks (OSNs). Multi-OSN user linkage seeks to link the same personâ€™s web profiles and integrate his/her data across different OSNs. It has been widely recognized as the key enabler for many important network applications. User linkage is unfortunately accompanied by growing privacy concerns about real identity leakage and the disclosure of sensitive user attributes. This paper initiates the study on privacy-preserving user linkage across multiple OSNs. We consider a social data collector (SDC) which collects perturbed user data from multiple OSNs and then performs user linkage for commercial data applications. To ensure strong user privacy, we introduce two novel differential privacy notions, Ïµ-attribute indistinguishability and Ïµ-profile indistinguishability, which ensure that any two usersâ€™ similar attributes and profiles cannot be distinguished after perturbation. We then present a novel Multivariate Laplace Mechanism (MLM) to achieve Ïµ-attribute indistinguishability and Ïµ-profile indistinguishability. We finally propose a novel differential privacy-preserving user linkage framework in which the SDC trains a classifier for user linkage across different OSNs. Extensive experimental studies based on three real datasets confirm the efficacy of our proposed framework.}
}


@inproceedings{DBLP:conf/iwqos/LiuDXYM21,
	author = {Bin Liu and
                  Huichen Dai and
                  Wenquan Xu and
                  Tong Yun and
                  Ji Miao},
	title = {Scalable Hardware Content Router: Architecture, Modeling and Performance},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--7},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521334},
	doi = {10.1109/IWQOS52092.2021.9521334},
	timestamp = {Fri, 03 Dec 2021 13:16:57 +0100},
	biburl = {https://dblp.org/rec/conf/iwqos/LiuDXYM21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Current Internet is evolving with the gradual shift from the traditional host-to-host communication model to the new host-to-content paradigm, which will eventually lead to a network of caches. The novel Named Data Networking (NDN) has been proposed as a future Internet architecture to embrace this paradigmatic shift, where caching becomes an ubiquitous functionality available at each router.A router with the functionality of content caching, running on NDN mechanisms, is termed as an NDN-based content router. Previous researchers focused on software content routers (SCR), which leverage a commercial off-the-shelf computer to execute content caching/accessing and named-based packet forwarding. SCR can only achieve limited throughput, which is far below the speed requirements of modern routers. Facing this situation, in this paper, we propose a hardware-based content router (HCR), aiming at purchasing wire-speed processing. We design a physically concise architecture for decoupling the packet buffers in line cards from the content caches attached to storage cards, enabling separate management and optimization while facilitating a modular structure for smooth capacity upgrade in response to increasing storage utilization. For lowering the operating complexity and reducing the storage management cost, we choose to employ distributed caches working in a cooperated manner by using consistent hashing. We model several candidate storage organizing schemes and carry out theoretical analyses for comparison. Analytical and synthetic workload-driven results show that the consistent hashing scheme achieves high cache performance and low cost simultaneously.}
}


@inproceedings{DBLP:conf/iwqos/ZhouC21,
	author = {Boyang Zhou and
                  Liang Cheng},
	title = {A Reality-Conforming Approach for QoS Performance Analysis of {AFDX}
                  in Cyber-Physical Avionics Systems},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--6},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521335},
	doi = {10.1109/IWQOS52092.2021.9521335},
	timestamp = {Thu, 03 Aug 2023 08:16:08 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/ZhouC21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {AFDX (Avionics Full Duplex Switched Ethernet) is developed to support mission-critical communications while providing deterministic Quality of Service (QoS) across cyber-physical avionics systems. Currently, AFDX utilizes FP/FIFO QoS mechanisms to guarantee its real-time performance. To analyze the real-time performance of avionic systems in their design processes, existing work analyzes the deterministic delay bound of AFDX using NC (Network Calculus). However, existing analytical work is based on an unrealistic assumption leading to assumed worst cases that may not be achievable in reality. In this paper, we present a family of algorithms that can search for realistic worst-case delay scenarios in both preemptive and non-preemptive situations. Then we integrate the proposed algorithms with NC and apply our approach to analyzing tandem AFDX networks. Our reality-conforming approach yields tighter delay bound estimations than the state of the art. When there are 100 virtual links in AFDX networks, our method can provide delay bounds more than 25% tighter than those calculated by the state of the art in our evaluation. Moreover, when using our reality-conforming method in the design process, it leads to 27.2% increase in the number of virtual links accommodated by the network in the tandem scenario.}
}


@inproceedings{DBLP:conf/iwqos/CaoLLHJY21,
	author = {Jiamin Cao and
                  Ying Liu and
                  Mingxing Liu and
                  Lin He and
                  Yihao Jia and
                  Fei Yang},
	title = {pSAV: {A} Practical and Decentralized Inter-AS Source Address Validation
                  Service Framework},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--7},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521336},
	doi = {10.1109/IWQOS52092.2021.9521336},
	timestamp = {Tue, 22 Feb 2022 11:32:55 +0100},
	biburl = {https://dblp.org/rec/conf/iwqos/CaoLLHJY21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Source IP address spoofing has been a major vulnerability of the Internet for many years. Although much work has been done to study the problem extensively, spoofing continues to occur frequently and has led to many serious network attacks. Inter-AS source address validation (SAV) is considered an important defense method for AS to filter spoofed packets. However, existing work has been unable to drive inter-AS SAV deployment into practice due to the lack of deployment incentives and trust foundation.In this paper, we propose a practical and decentralized inter-AS SAV service framework, pSAV, to promote inter-AS SAV deployment. pSAV increases deployment incentives by treating SAV as a payable service and dividing the participant ASes into service subscribers, providers, and auditors. On the control plane, pSAV leverages blockchain as a trust foundation to provide service subscriptions and audits with automatic incentive allocation. On the data plane, pSAV leverages P4-programmable switches to provide flexible and high-performance SAV services. We prototype the pSAV control plane based on Hyperledger Fabric and implement various SAV techniques on Barefoot Tofino switches. The evaluation results show that (1) on the control plane, pSAV blockchain can provide high-performance service transactions (hundreds of transactions per second with second latency), and (2) on the data plane, pSAV can provide various high-throughput (hundreds of Gbps) SAV services using only one programmable switch.}
}


@inproceedings{DBLP:conf/iwqos/Yan0WZX0W21,
	author = {Zhenxiong Yan and
                  Kun Xie and
                  Xin Wang and
                  Dafang Zhang and
                  Gaogang Xie and
                  Kenli Li and
                  Jigang Wen},
	title = {Multivariate Time Series Forecasting exploiting Tensor Projection
                  Embedding and Gated Memory Network},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--6},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521337},
	doi = {10.1109/IWQOS52092.2021.9521337},
	timestamp = {Wed, 05 Jan 2022 09:00:34 +0100},
	biburl = {https://dblp.org/rec/conf/iwqos/Yan0WZX0W21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Time series forecasting is very important and plays critical roles in many applications. However, making accurate forecasting is a challenge task due to the requirements of learning complex temporal and spatial patterns and combating noise during the feature learning. To address the challenge issues, we propose TEGMNet, a Tensor projection Embedding and Gated Memory Network for multivariate time series forecasting. To more accurately extract local features and reduce the influence of noise, we propose to amplify the data using several data transformation techniques based on MDT (Multi-way delay embedding transform) and TFNN (tensor factorized neural network) to transform the original 2D matrix data to low dimensional 3D tensor data. The local features are then extracted through convolution and LSTM upon the 3D tensor. We also design a long-term feature extraction module based on the structure of gated memory network, which can largely enhance the longterm pattern feature learning ability when the multivariate time series has complex long-term dependencies with dynamic-period patterns. We have done extensive experiments by comparing our TEGMNet with 7 baseline algorithms using 4 real data sets. The experiment results demonstrate that TEGMNet can achieve very good prediction performance even through the data are polluted with noise.}
}


@inproceedings{DBLP:conf/iwqos/JiangV0X21,
	author = {Nan Jiang and
                  Mehmet Can Vuran and
                  Sheng Wei and
                  Lisong Xu},
	title = {QoS-Aware Network Energy Optimization for Danmu Video Streaming in
                  WiFi Networks},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521338},
	doi = {10.1109/IWQOS52092.2021.9521338},
	timestamp = {Wed, 27 Sep 2023 09:30:47 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/JiangV0X21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Danmu (a.k.a., barrage videos or bullet comments) is a novel type of interactive video streaming, which displays instantaneous user comments flying across the screen during the video playback to better engage the users. However, such fancy experience brings a considerable burden to the battery of mobile user devices that have limited capacity. For example, WiFi testbed experiments show 15% to 35% increase in WiFi network energy consumption because of the large amount of additional network traffic for user comments. On the other hand, current network energy minimization methods adversely impact the Quality of Service (QoS) of Danmu users, because they put off the transmission and then delay the display of the user comments that should match with the timeline of the corresponding videos. In this paper, for the first time, a heuristic QoS-aware network energy optimization algorithm is proposed to reduce the WiFi network energy consumption while still maintaining the desired QoS of Danmu users. Comprehensive testbed experiments using an open-source Danmu streaming system and with real Danmu user traces indicate up to 28% WiFi network energy saving depending on different system, network, and user settings.}
}


@inproceedings{DBLP:conf/iwqos/XiLLLLZ21,
	author = {Binhan Xi and
                  Shaofeng Li and
                  Jiachun Li and
                  Hui Liu and
                  Hong Liu and
                  Haojin Zhu},
	title = {BatFL: Backdoor Detection on Federated Learning in e-Health},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521339},
	doi = {10.1109/IWQOS52092.2021.9521339},
	timestamp = {Tue, 31 Aug 2021 11:59:55 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/XiLLLLZ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated Learning (FL) has received significant interest both from the research field and industry perspective. One of the most promising cross-silo applications on FL is electronic health records mining which trains a model on siloed data. In this application, clients can be different hospitals or health centers that are located in geo-distributed data centers. A central orchestration server (superior health center) organizes the training, while never seeing patientsâ€™ raw data. In this paper, we demonstrate that any local hospital in such a collaborative training framework can introduce hidden backdoor functionality into the joint global model. The backdoored joint global model will produce an adversary-expected output when a predefined trigger is attached to its input but it will behave normally for clean inputs. This vulnerability is exacerbated by the distributed nature of FL, making detecting backdoor attacks on FL a challenging work. Based on the coalitional game and Shapley value, we propose an effective and real-time backdoor detection system on FL. Extensive experiments over two machine learning tasks show that our techniques achieve high accuracy and are robust against multi-attackers settings.}
}


@inproceedings{DBLP:conf/iwqos/Li0JZWZWJYWCZNS21,
	author = {Zeyan Li and
                  Junjie Chen and
                  Rui Jiao and
                  Nengwen Zhao and
                  Zhijun Wang and
                  Shuwei Zhang and
                  Yanjun Wu and
                  Long Jiang and
                  Leiqin Yan and
                  Zikai Wang and
                  Zhekang Chen and
                  Wenchi Zhang and
                  Xiaohui Nie and
                  Kaixin Sui and
                  Dan Pei},
	title = {Practical Root Cause Localization for Microservice Systems via Trace
                  Analysis},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521340},
	doi = {10.1109/IWQOS52092.2021.9521340},
	timestamp = {Mon, 03 Jan 2022 22:21:49 +0100},
	biburl = {https://dblp.org/rec/conf/iwqos/Li0JZWZWJYWCZNS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Microservice architecture is applied by an increasing number of systems because of its benefits on delivery, scalability, and autonomy. It is essential but challenging to localize root-cause microservices promptly when a fault occurs. Traces are helpful for root-cause microservice localization, and thus many recent approaches utilize them. However, these approaches are less practical due to relying on supervision or other unrealistic assumptions. To overcome their limitations, we propose a more practical root-cause microservice localization approach named TraceRCA. The key insight of TraceRCA is that a microservice with more abnormal and less normal traces passing through it is more likely to be the root cause. Based on it, TraceRCA is composed of trace anomaly detection, suspicious microservice set mining and microservice ranking. We conducted experiments on hundreds of injected faults in a widely-used open-source microservice benchmark and a production system. The results show that TraceRCA is effective in various situations. The top-1 accuracy of TraceRCA outperforms the state-of-the-art unsupervised approaches by 44.8%. Besides, TraceRCA is applied in a large commercial bank, and it helps operators localize root causes for real-world faults accurately and efficiently. We also share some lessons learned from our real-world deployment.}
}


@inproceedings{DBLP:conf/iwqos/ZhuangXWZYX21,
	author = {Rui Zhuang and
                  Yitao Xing and
                  Wenjia Wei and
                  Yuan Zhang and
                  Jiayu Yang and
                  Kaiping Xue},
	title = {wCompound: Enhancing Performance of Multipath Transmission in High-speed
                  and Long Distance Networks},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521341},
	doi = {10.1109/IWQOS52092.2021.9521341},
	timestamp = {Tue, 31 Aug 2021 11:59:55 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/ZhuangXWZYX21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As the user demand for data transmission over high-speed and long distance (hereafter abbreviated as HSLD) networks increases significantly, multipath TCP (MPTCP) shows a great potential to further improve the utilization of HSLD network resources than traditional TCP, and provides better quality of service (QoS). It has been reported that TCP causes serious waste of bandwidth in HSLD networks, while MPTCP can transmit data by using multiple network paths simultaneously between two distant hosts, thus provides better resource utilization, higher throughput and smoother failure recovery for applications. However, the existing multipath congestion control algorithms cannot perfectly meet the efficiency requirements of HSLD network, since they mainly emphasize fairness rather than other critical indicators of QoS such as throughput, but still encounter fairness issues when coexist with various TCP variants. To solve these problems, we develop weighted Compound (wCompound), a loss-and-delay-based compound multipath congestion control algorithm which is originated from Compound TCP, and is applicable to HSLD networks. Different from the traditional methods of setting an empirical value as the threshold, wCompound innovatively adopts a dynamic threshold and have the flexibility to adjust the sending window of each subflow based on current network state, so as to effectively couple all subflows and fully utilize the network capacity. Moreover, with the cooperation of delay-based and loss-based methods, wCompound also ensures good fairness to different types of TCP variants. We implement wCompound in the Linux kernel, then carry out sufficient experiments on our testbed. The results show that wCompound achieves higher utilization of network resources and can always maintain an appropriate throughput no matter competing with loss-based or delay-based network traffic.}
}


@inproceedings{DBLP:conf/iwqos/ZhaoCLC21,
	author = {Yuyu Zhao and
                  Guang Cheng and
                  Chunxiang Liu and
                  Zihan Chen},
	title = {Snapshot for IoT: Adaptive Measurement for Multidimensional QoS Resources},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521342},
	doi = {10.1109/IWQOS52092.2021.9521342},
	timestamp = {Sat, 30 Sep 2023 09:51:34 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/ZhaoCLC21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the increasing and extensive use of intelligent Internet of things (IoT) devices, its operational aspect in the network has become a significant dependent data for network QoS management and scheduling. For the resilient intelligent IoT cluster with flexible increase and decrease of devices and heterogeneous operating systems, this paper proposes an adaptive measurement method MRAM, which can snapshot the multidimensional QoS resources view (MRV) of the IoT devices in cluster. MRAM uses the measurement offloading architecture based on extensible gateway platform and cloud computing to liberate the local resources of monitored IoT devices. Based on the improved LSTM algorithm, the MRVâ€™s mutations detection method ELSTM is designed. Newly collected QoS resource can be judged whether mutations have occurred and adaptive measurement state machine is enabled by ELSTM. According to the state machine which ensures that the MRV is updated timely and reflected the current status of the cluster, MRAM adjusts the measurement granularity in real time. This method provides a high time efficiency global profile for the upper QoS services and reduces the impact of measurement on the IoT devices. A real environment is built to test the performance of this method. MRAM has high measurement accuracy and the precision of mutations detection is 98.29%. It converges the update MRV of second level under the condition of IoT devicesâ€™ low consumption of storage and CPU utilization.}
}


@inproceedings{DBLP:conf/iwqos/Ye00C21,
	author = {Minghao Ye and
                  Junjie Zhang and
                  Zehua Guo and
                  H. Jonathan Chao},
	title = {{DATE:} Disturbance-Aware Traffic Engineering with Reinforcement Learning
                  in Software-Defined Networks},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521343},
	doi = {10.1109/IWQOS52092.2021.9521343},
	timestamp = {Thu, 14 Oct 2021 10:04:45 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/Ye00C21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Traffic Engineering (TE) has been applied to optimize network performance by routing/rerouting flows based on traffic loads and network topologies. To cope with network dynamics from emerging applications, it is essential to reroute flows more frequently than todayâ€™s TE to maintain network performance. However, existing TE solutions may introduce considerable Quality of Service (QoS) degradation and service disruption since they do not take the potential negative impact of flow rerouting into account. In this paper, we apply a new QoS metric named network disturbance to gauge the impact of flow rerouting while optimizing network load balancing in backbone networks. To employ this metric in TE design, we propose a disturbance-aware TE called DATE, which uses Reinforcement Learning (RL) to intelligently select some critical flows between nodes for each traffic matrix and reroute them using Linear Programming (LP) to jointly optimize network performance and disturbance. DATE is equipped with a customized actor-critic architecture and Graph Neural Networks (GNNs) to handle dynamic traffic and single link failures. Extensive evaluations show that DATE can outperform state-of-the-art TE methods with close-to-optimal load balancing performance while effectively mitigating the 99th percentile network disturbance by up to 31.6%.}
}


@inproceedings{DBLP:conf/iwqos/ZhaiZXZLF21,
	author = {Yutong Zhai and
                  Gongming Zhao and
                  Hongli Xu and
                  Yangming Zhao and
                  Jiawei Liu and
                  Xingpeng Fan},
	title = {Towards Robust Multi-Tenant Clouds Through Multi-Constrained {VM}
                  Placement},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--6},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521344},
	doi = {10.1109/IWQOS52092.2021.9521344},
	timestamp = {Tue, 31 Aug 2021 11:59:55 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/ZhaiZXZLF21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {More and more tenants (enterprises and personal users) migrate their tasks to clouds since it is a simple and low-cost way to obtain enough computing resources. However, due to potential node failures and malicious tenants, the modern cloud encounters one critical challenge, i.e., robustness. Conventionally, the cloud vendors deploy auxiliary systems to protect the cloud, which requires additional resource cost and increases the network complexity. To enhance the system robustness, this paper proposes a complementary scheme to improve the cloud robustness through efficient VM placement. Specifically, to alleviate the impact of malicious tenants and node failures on the cloud, when deploying VMs, we limit the number of pods (or service nodes) that each tenant can access, and the number of tenants hosted by each pod (or service node). Though there are a lot of works on VM placement, it is very challenging when the robustness issue is taken into consideration. To solve this problem, we formulate an integer linear programming and propose a rounding-based algorithm with a logarithmic approximation ratio. The simulation results show the high efficiency of the proposed algorithm. For example, our algorithm can improve the network throughput by 150% with other alternatives.}
}


@inproceedings{DBLP:conf/iwqos/FuXLWYGD21,
	author = {Songtao Fu and
                  Ke Xu and
                  Qi Li and
                  Xiaoliang Wang and
                  Su Yao and
                  Yangfei Guo and
                  Xinle Du},
	title = {{MASK:} Practical Source and Path Verification based on Multi-AS-Key},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521345},
	doi = {10.1109/IWQOS52092.2021.9521345},
	timestamp = {Wed, 27 Sep 2023 11:04:06 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/FuXLWYGD21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The source and path verification in path-aware Internet consider the two critical issues: (1) end hosts could verify that their forwarding decisions followed by the network, (2) both intermediate routers and destination host could authenticate the source of packets and filter the malicious traffic. Unfortunately, the current verification mechanism requires validation operations in each router on the path in an inter-domain environment, thus requiring high communication and computation overhead, reducing its usefulness; besides, it is also difficult to meet the dynamic requirements of the end host. Ideally, the verification should be secure and provide the customized capability to meet the end hostâ€™s requirements. We propose a new mechanism called source and path verification based on Multi-AS-Key (MASK). Instead of each packet verified and marked at each router on the path, MASK improves the verification by empowering the end hosts to instruct the routers to achieve the verification, thus decreasing the routerâ€™s overhead while ensuring security performance to meet the end hostâ€™s requirements. With the plausible design, the communication overhead for realistic path lengths is 3â€“8 times smaller than the state-of-the-art mechanisms. The computation overhead in the routers is 2-5 times smaller. We implement our design in the BMv2 environment and commodity Barefoot Tofino programmable switch, demonstrating that MASK introduces significantly less overhead than the existing mechanisms.}
}


@inproceedings{DBLP:conf/iwqos/ZhangZKSW21,
	author = {Yang Zhang and
                  Ruohan Zong and
                  Ziyi Kou and
                  Lanyu Shang and
                  Dong Wang},
	title = {A Crowd-driven Dynamic Neural Architecture Searching Approach to Quality-aware
                  Streaming Disaster Damage Assessment},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--6},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521346},
	doi = {10.1109/IWQOS52092.2021.9521346},
	timestamp = {Tue, 07 May 2024 20:11:32 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/ZhangZKSW21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Streaming disaster damage assessment (DDA) aims to automatically assess the damage severity of affected areas in a disaster event on the fly by leveraging the streaming imagery data about the disaster on social media. In this paper, we focus on a dynamic optimal neural architecture searching (NAS) problem in streaming DDA applications. Our goal is to dynamically determine the optimal neural network architecture that accurately estimates the damage severity for each newly-arrived image in the stream by leveraging human intelligence from the crowdsourcing systems. Our work is motivated by the observations that the neural network architectures in current DDA solutions are mainly designed by AI experts, which often leads to non-negligible costs and errors given the dynamic nature of the streaming DDA applications and the lack of real-time annotations of the massive social media data inputs. In this paper, we develop CD-NAS, a crowd-driven dynamic NAS framework that is inspired by novel techniques from AI, crowdsourcing, and estimation theory to address the dynamic optimal NAS problem. The evaluation results from a real-world streaming DDA application show that CD-NAS consistently outperforms the state-of-the-art AI and NAS baselines by achieving the highest disaster damage assessment accuracy.}
}


@inproceedings{DBLP:conf/iwqos/LiuCL021,
	author = {Yu Liu and
                  Niangjun Chen and
                  Zhenhua Liu and
                  Yuanyuan Yang},
	title = {Online Cloud Resource Provisioning Under Cost Budget for QoS Maximization},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--6},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521347},
	doi = {10.1109/IWQOS52092.2021.9521347},
	timestamp = {Fri, 19 Aug 2022 14:05:12 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/LiuCL021.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cloud computing is becoming one of the ubiquitous computing paradigms for enterprises and organizations in recent years. Due to the volatility of system states such as cloud resource price and workload demand, it is challenging to provision cloud resources efficiently. This paper studies online cloud resource provisioning problems under cost budget where no accurate or distributional future information is available. We develop an algorithmic framework and design online algorithms based on the framework. We prove the competitive ratio of the proposed algorithms. We further show the proposed algorithms have better performance than a prominent existing algorithm named CR-Pursuit. While prior works on the problem require the objective functions to be concave, the proposed algorithms work for non-convex and non-concave objective functions. We conduct real-world trace-driven simulations. Results highlight the proposed algorithms outperform baselines significantly over a wide range of settings.}
}


@inproceedings{DBLP:conf/iwqos/ZhangH0Y21,
	author = {Jiarui Zhang and
                  Yaodong Huang and
                  Fan Ye and
                  Yuanyuan Yang},
	title = {A Novel Proof-of-Reputation Consensus for Storage Allocation in Edge
                  Blockchain Systems},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521348},
	doi = {10.1109/IWQOS52092.2021.9521348},
	timestamp = {Tue, 08 Feb 2022 09:07:03 +0100},
	biburl = {https://dblp.org/rec/conf/iwqos/ZhangH0Y21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Edge computing guides the collaborative work of widely distributed nodes with different sensing, storage, and computing resources. For example, sensor nodes collect data and then store it in storage nodes so that computing nodes can access the data when needed. In this paper, we focus on the quality of service (QoS) in storage allocation in edge networks. We design a reputation mechanism for nodes in edge networks, which enables interactive nodes to evaluate the quality of service for reference. Each node publicly broadcasts a personal reputation list to evaluate all other nodes, and each node can calculate the global reputation of all nodes by aggregating personal reputations. We then propose a storage allocation algorithm that stores data to appropriate locations. The algorithm considers fairness, efficiency, and reliability which is derived from reputations. We build a novel Proof-of-Reputation (PoR) blockchain to support consensus on the reputation mechanism and storage allocation. The PoR blockchain ensures safety performance, saves computing resources, and avoids centralization. Extensive simulation results show our proposed algorithm is fair, efficient, and reliable. The results also show that in the presence of attackers, the success rate of honest nodes accessing data can reach 99.9%.}
}


@inproceedings{DBLP:conf/iwqos/TuZXZZ21,
	author = {Huaqing Tu and
                  Gongming Zhao and
                  Hongli Xu and
                  Yangming Zhao and
                  Yutong Zhai},
	title = {Robustness-Aware Real-Time {SFC} Routing Update in Multi-Tenant Clouds},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--6},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521350},
	doi = {10.1109/IWQOS52092.2021.9521350},
	timestamp = {Tue, 31 Aug 2021 11:59:55 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/TuZXZZ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In multi-tenant clouds, requests need to traverse a set of network functions (NFs) in a specific order, referred to as a service function chain (SFC), for security and business logic issues. Due to workload dynamics, the central controller of a multi-tenant cloud needs to frequently update the SFC routing, so as to optimize various network performance, such as load balancing. To achieve effective SFC routing update, we should consider two critical requirements: system robustness and real-time update. Without considering these two requirements, prior works either result in fragile clouds or suffer from large update delay. In this paper, we propose a robustness-aware real-time SFC routing update (R 3 -UA) scheme which takes both requirements into consideration. R 3 -UA pursues robustness-aware real-time routing update through two phases: robust NF instance assignment and real-time SFC routing update. Two algorithms with bounded approximation ratios are proposed for these two phases, respectively. The large-scale simulation results show the superior performance of R 3 -UA compared with other alternatives.}
}


@inproceedings{DBLP:conf/iwqos/ZhengLGZS21,
	author = {Yandong Zheng and
                  Rongxing Lu and
                  Yunguo Guan and
                  Songnian Zhang and
                  Jun Shao},
	title = {Towards Private Similarity Query based Healthcare Monitoring over
                  Digital Twin Cloud Platform},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521351},
	doi = {10.1109/IWQOS52092.2021.9521351},
	timestamp = {Tue, 02 May 2023 15:56:56 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/ZhengLGZS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As the growing proportion of aging population, the demand for sustainable, high quality, and timely healthcare services has become increasingly pressing, especially since the outbreak of COVID-19 pandemic in the early of 2020. To meet this demand, a promising strategy is to introduce cloud computing and digital twin techniques into the healthcare systems, where the cloud server is employed for storing healthcare data and offering efficient query services, and the digital twin is used for building digital representation for patients and leverages the query services of the cloud server to monitor healthcare states of patients. Although several cloud computing and digital twin based healthcare monitoring frameworks have been proposed, none of them has considered the data privacy issue, yet the leakage of the private healthcare information may cause catastrophic losses to patients. Aiming at the challenge, in this paper, we propose an efficient and privacy-preserving similarity query based healthcare monitoring scheme over digital twin cloud platform, named PSim-DTH. Specifically, we first formalize a similarity query based healthcare monitoring model over digital twin cloud platform. Then, we deploy a partition-based tree (PB-tree) to index the healthcare data and introduce matrix encryption to propose a privacy-preserving PB-tree based similarity range query (PSRQ) algorithm. Based on PSRQ algorithm, we propose our PSim-DTH scheme. Both security analysis and performance evaluation are extensively conducted, and the results demonstrate that our proposed PSim-DTH scheme is really privacy-preserving and efficient.}
}


@inproceedings{DBLP:conf/iwqos/KimCIZHJ21,
	author = {Taejin Kim and
                  Siqi Chen and
                  Youngbin Im and
                  Xiaoxi Zhang and
                  Sangtae Ha and
                  Carlee Joe{-}Wong},
	title = {MoDEMS: Optimizing Edge Computing Migrations For User Mobility},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--2},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521352},
	doi = {10.1109/IWQOS52092.2021.9521352},
	timestamp = {Tue, 31 Aug 2021 11:59:55 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/KimCIZHJ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Edge computing systems benefit from knowledge of short-term mobility from 5G technologies, as tasks offloaded from user devices can be placed at the edge to reduce their latencies. However, as devices move, they will need to offload their tasks to different edge servers, which may require migrating data from one edge server to another. In this paper, we introduce MoDEMS, a system architecture through which we provide a rigorous theoretical framework to study the challenges of such migrations to minimize the service provider cost and user latency. We show that this cost minimization problem can be expressed as an integer linear programming problem, which is challenging to solve due to resource constraints at the servers and unknown user mobility patterns. We show that finding the optimal migration plan is in general NP-hard, and we propose alternative heuristic solution algorithms. We finally validate our results with realistic user mobility traces.}
}


@inproceedings{DBLP:conf/iwqos/WangZH21,
	author = {Yu Wang and
                  Xiaojun Zhu and
                  Hao Han},
	title = {ChirpMu: Chirp Based Imperceptible Information Broadcasting with Music},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--9},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521353},
	doi = {10.1109/IWQOS52092.2021.9521353},
	timestamp = {Tue, 07 Sep 2021 15:04:30 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/WangZH21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper presents ChirpMu, a system that encodes information into chirp symbols and embeds the symbols with music. Users enjoy music without realizing the existence of chirp sounds, while their smartphones can decode the information. ChirpMu can be used to broadcast information such as Wi-Fi secrets or coupons in shopping malls. It features novel chirp symbol design that can combat sound attenuation and environment noise. In addition, ChirpMu properly adjusts the portion of chirp symbols with music, so that the chirp symbols cannot be heard by users but can be decoded by smartphones with low error rate. Various real-world experiments show that ChirpMu can achieve low bit error rate.}
}


@inproceedings{DBLP:conf/iwqos/ZhangZ021,
	author = {Zhenyu Zhang and
                  Huan Zhou and
                  Dawei Li},
	title = {Joint Optimization of Multi-user Computing Offloading and Service
                  Caching in Mobile Edge Computing},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--2},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521354},
	doi = {10.1109/IWQOS52092.2021.9521354},
	timestamp = {Wed, 23 Feb 2022 10:43:25 +0100},
	biburl = {https://dblp.org/rec/conf/iwqos/ZhangZ021.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper jointly considers the optimization of multi-user computing offloading and service caching in Mobile Edge Computing (MEC), and formulates the problem as a Mixed-Integer Non-Linear Program (MINLP), aiming to minimize the task cost of the system. The original problem is decomposed into an equivalent master problem and sub-problem, and a Collaborative Computing Offloading and Resource Allocation Method (CCORAM) is proposed to solve the optimization problem, which includes two low-complexity algorithms. Simulation results show that CCORAM with low time complexity is very close to the optimal method, and performs much better than other benchmark methods.}
}


@inproceedings{DBLP:conf/iwqos/BoorC21,
	author = {Mark van der Boor and
                  C{\'{e}}line Comte},
	title = {Load Balancing in Heterogeneous Server Clusters: Insights From a Product-Form
                  Queueing Model},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521355},
	doi = {10.1109/IWQOS52092.2021.9521355},
	timestamp = {Tue, 31 Aug 2021 11:59:55 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/BoorC21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Efficiently exploiting servers in data centers requires performance analysis methods that account not only for the stochastic nature of demand but also for server heterogeneity. Although several recent works proved optimality results for heterogeneity-aware variants of classical load-balancing algorithms in the many-server regime, we still lack a fundamental understanding of the impact of heterogeneity on performance in finite-size systems. In this paper, we consider a load-balancing algorithm that leads to a product-form queueing model and can therefore be analyzed exactly even when the number of servers is finite. We develop new analytical methods that exploit its product-form stationary distribution to understand the joint impact of the speeds and buffer lengths of servers on performance. These analytical results are supported and complemented by numerical evaluations that cover a large variety of scenarios.}
}


@inproceedings{DBLP:conf/iwqos/MuhatiR21,
	author = {Eric Muhati and
                  Danda B. Rawat},
	title = {{ASAP:} Anti-Spoofing Aphorism Using Path-analysis},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521356},
	doi = {10.1109/IWQOS52092.2021.9521356},
	timestamp = {Sat, 09 Apr 2022 12:39:09 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/MuhatiR21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The immense vulnerabilities within network protocols have led to prevalent spoofing attacks. Security measures such as cryptographic authentication, router level filtering, and other anti-spoofing methods are promising yet inadequate. In fact, research shows almost 50% of existing autonomous systems can be "hijacked" and used as spurious network nodes. Spoofing is falsified node identification of a trusted node and subsequent delivery of imposter data packets. Correctly identifying a packetsâ€™ travel path has been widely used to ascertain node positions and flag unexpected locations as spoofing agents. Challenges and inadequacies arise in analyzing the copious dynamic possible packet paths. We propose a practical anti-spoofing technique when routing is asymmetric or multi-path that contrast network connections from trusted nodes after considering all possible routing alternatives, compared to a network path under scrutiny. We subtly perform obscured intrusion detection through hopcounts clustering via IP headerâ€™s time-to-live field and special representative nearest captain nodes that differentiate features of valid paths. While many proposed anti-spoofing solutions only analyze static traffic to give â‰ˆ 90% efficacy, we consider all alternatives that deviate from accurate features to achieve improved efficacy of 94.2%.}
}


@inproceedings{DBLP:conf/iwqos/LiZCL21,
	author = {Yinglong Li and
                  Jiaye Zhang and
                  Tieming Chen and
                  Weiru Liu},
	title = {FuzzySkyline: QoS-Aware Fuzzy Skyline Parking Recommendation Using
                  Edge Traffic Facilities},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--7},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521357},
	doi = {10.1109/IWQOS52092.2021.9521357},
	timestamp = {Thu, 23 Jun 2022 19:55:47 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/LiZCL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Drivers always confront parking difficulties when driving on urban roads, especially in crowded downtown or beauty spots. Some of the existing literatures concentrate on multi-consideration optimization for parking decision by collecting the nearby real-time parking-related data. Others provide online parking navigation services through outsourced storage and cloud computing. Massive (raw) data transmission and complex processing are always involved in the existing methods, which results in undesired QoS such as real-time performance and privacy protection. In this paper, we propose a fuzzy skyline parking recommendation scheme for real-time parking recommendation based on roadside traffic facilities. Linguistic parking information instead of raw parking-related data is used in fuzzy skyline fusion. We evaluated our solution with real-world data sets collected from edge parking facilities in Wulin downtown, Hangzhou city, China. The evaluation results show that our approaches achieve an average accuracy of parking recommendation over 91%, low data transmission, and quick response time with privacy protection.}
}


@inproceedings{DBLP:conf/iwqos/GuoLYZL21,
	author = {Lingfeng Guo and
                  Yan Liu and
                  Wenzheng Yang and
                  Yuming Zhang and
                  Jack Y. B. Lee},
	title = {Stateful-BBR - An Enhanced {TCP} for Emerging High-Bandwidth Mobile
                  Networks},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--9},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521358},
	doi = {10.1109/IWQOS52092.2021.9521358},
	timestamp = {Sat, 13 Apr 2024 22:38:44 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/GuoLYZL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the progressive deployment of 5G networks around the world, mobile networks are entering a new era where bandwidth will be breaking through the Gbps barrier. In this work, we investigate the performance of current TCP designs in such high-bandwidth networks, demonstrating the potential bottleneck due to TCPâ€™s Slow-Start mechanism which is an integral component in most TCP designs. For example, transferring a file of 1 MB size in a first-generation 5G network using Linuxâ€™s default TCP-Cubic and Googleâ€™s TCP-BBR resulted in average throughputs of 18.2 Mbps and 32.8 Mbps, respectively. Compared to the mean available bandwidth of 180 Mbps, the gap is significant. To tackle this problem, we developed an enhanced Stateful-TCP technique to transform BBR into a new S-BBR to accelerate its startup performance to narrow the gap. Results from trace-driven emulated 5G network experiments show that S-BBR could improve BBRâ€™s throughput performance by 50% to 100% while maintaining similar delay performance. This is further validated by an independent competitive benchmark using over 500 clients where S-BBR raised BBRâ€™s throughput by 69%. S-BBR is sender-based and thus can be readily deployed in Internet servers without any requirements from the client side, it retains BBRâ€™s desirable features and so offers a promising solution to enhance mobile applicationsâ€™ performance in the emerging high-bandwidth mobile and wireless networks.}
}


@inproceedings{DBLP:conf/iwqos/WangLWX21,
	author = {Xiangxiang Wang and
                  Jiangchuan Liu and
                  Fangxin Wang and
                  Ke Xu},
	title = {Demystifying the Relationship Between Network Latency and Mobility
                  on High-Speed Rails: Measurement and Prediction},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521359},
	doi = {10.1109/IWQOS52092.2021.9521359},
	timestamp = {Thu, 31 Mar 2022 08:37:34 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/WangLWX21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recent years have seen increasing attention on building High-Speed Railways (HSR) in many countries. Trains running on the railways have a top velocity of up to over 300 km/hour. This makes it become a scenario with unstable connection qualities. In this paper, we propose a novel model that can accurately estimate the mobility status on HSR based on the changing patterns of network latency. Though various impact factors make the prediction complex, we however argue that the recent advance of deep learning applies well in our context, and further we design a neural network model that can estimate the moving velocity based on monitoring network latencyâ€™s changing patterns in a short period. In this model, we use a new variable called Round Difference Time (RDT) to describe latencyâ€™s changing patterns. We also use the Fourier Transform to extract the hidden time-frequency and use the generated spectrum for estimation. Our data-driven evaluations show that with suitable parameters, this model can get an accuracy of up to 94% on all three lines.}
}


@inproceedings{DBLP:conf/iwqos/LiGCLC21,
	author = {Yan Li and
                  Deke Guo and
                  Xiaofeng Cao and
                  Feng Lyu and
                  Honghui Chen},
	title = {DeepDelivery: Leveraging Deep Reinforcement Learning for Adaptive
                  IoT Service Delivery},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--6},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521360},
	doi = {10.1109/IWQOS52092.2021.9521360},
	timestamp = {Fri, 05 Aug 2022 09:29:53 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/LiGCLC21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {To enable fast content delivery for delay-sensitive applications, large content providers build edge servers, Points of Presence (PoPs), and datacenters around the world. They are networked together as an integrated infrastructure via a private wide-area network (WAN), named content delivery network (CDN). To deliver quality services in the CDN, there are two critical decisions that should be properly made: 1) making assignments of PoP and datacenter for user requests, and 2) selecting routing paths from PoP to datacenter. However, with both the network variability and CDN environment complexity, it is challenging to achieve satisfying decisions. In this paper, we propose DeepDelivery, an adaptive deep reinforcement learning approach to intelligently make assignments and routing decisions in real time. Essentially, DeepDelivery adopts the Markov decision process (MDP) model to capture the dynamics of network variation, and the objective is to jointly maximize the infrastructure utilization of providers and minimize the total latency of end users. We conduct extensive trace-driven evaluations spanning various environment dynamics with both real-world and synthetic trace data. The result demonstrates that DeepDelivery can outperform the state-of-the-art scheme by 21.89% higher utilization and 11.27% lower end-to-end latency on average.}
}


@inproceedings{DBLP:conf/iwqos/XuDZLZ21,
	author = {Xiaohui Xu and
                  Sijing Duan and
                  Jinrui Zhang and
                  Yunzhen Luo and
                  Deyu Zhang},
	title = {Optimizing Federated Learning on Device Heterogeneity with {A} Sampling
                  Strategy},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521361},
	doi = {10.1109/IWQOS52092.2021.9521361},
	timestamp = {Tue, 31 Aug 2021 11:59:55 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/XuDZLZ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated learning (FL) is a novel machine learning that performs distributed training locally on devices and aggregating the local models into a global one. The limited network bandwidth and the tremendous amount of model data that need to be transported bring up expensive communication cost. Meanwhile, heterogeneity in the devicesâ€™ local datasets and computation power exerts a huge influence on the performance of FL. To address these issues, we provide an empirical and mathematical analysis of device heterogeneity on the performance of model convergence and quality, then propose a holistic design to efficiently sample devices. Furthermore, we design a dynamic strategy to further speed up convergence and propose the FedAgg algorithm to alleviate the deviation caused by device heterogeneity. With extensive experiments performed in PyTorch, we show that the number of communication rounds required in FL can be reduced by up to 52% on the MNIST dataset, 32% on CIFAR-10, and 28% on FashionMNIST in comparison to the Federated Averaging algorithm.}
}


@inproceedings{DBLP:conf/iwqos/HeLL21,
	author = {Lin He and
                  Lishan Li and
                  Ying Liu},
	title = {Towards Chain-Aware Scaling Detection in {NFV} with Reinforcement
                  Learning},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521362},
	doi = {10.1109/IWQOS52092.2021.9521362},
	timestamp = {Wed, 06 Jul 2022 16:05:30 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/HeLL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Elastic scaling enables dynamic and efficient re-source provisioning in Network Function Virtualization (NFV) to serve fluctuating network traffic. Scaling detection determines the appropriate time when a virtual network function (VNF) needs to be scaled, and its precision and agility profoundly affect system performance. Previous heuristics define fixed control rules based on a simplified or inaccurate understanding of deployment environments and workloads. Therefore, they fail to achieve optimal performance across a broad set of network conditions.In this paper, we propose a chain-aware scaling detection mechanism, namely CASD, which learns policies directly from experience using reinforcement learning (RL) techniques. Furthermore, CASD incorporates chain information into control policies to efficiently plan the scaling sequence of VNFs within a service function chain. This paper makes the following two key technical contributions. Firstly, we develop chain-aware representations, which embed global chains of arbitrary sizes and shapes into a set of embedding vectors based on graph embedding techniques. Secondly, we design an RL-based neural network model to make scaling decisions based on chain-aware representations. We implement a prototype of CASD, and its evaluation results demonstrate that CASD reduces the overall system cost and improves system performance over other baseline algorithms across different workloads and chains.}
}


@inproceedings{DBLP:conf/iwqos/GaiNT0J21,
	author = {Fangyu Gai and
                  Jianyu Niu and
                  Seyed Ali Tabatabaee and
                  Chen Feng and
                  Mohammad M. Jalalzai},
	title = {Cumulus: {A} Secure BFT-based Sidechain for Off-chain Scaling},
	booktitle = {29th {IEEE/ACM} International Symposium on Quality of Service, {IWQOS}
                  2021, Tokyo, Japan, June 25-28, 2021},
	pages = {1--6},
	publisher = {{IEEE}},
	year = {2021},
	url = {https://doi.org/10.1109/IWQOS52092.2021.9521363},
	doi = {10.1109/IWQOS52092.2021.9521363},
	timestamp = {Tue, 31 Aug 2021 11:59:55 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/GaiNT0J21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Sidechains enable off-chain scaling by sending transactions in a private network rather than broadcasting them in the public blockchain (i.e., the mainchain) network. To this end, classic Byzantine fault-tolerant (BFT) consensus protocols such as PBFT seem an excellent fit to fuel sidechains for their permissioned settings and inherent robustness. However, designing a secure and efficient BFT-based sidechain protocol remains an open challenge.This paper presents Cumulus, a novel BFT-based sidechain framework for blockchains to achieve off-chain scaling without compromising any security and efficiency properties of both sidesâ€™ consensus protocols. Cumulus encompasses a novel cryptographic sortition algorithm called Proof-of-Wait to fairly select sidechain nodes to communicate with the mainchain in an efficient and decentralized manner. To further reduce the operational cost, Cumulus provides an optimistic checkpointing approach in which the mainchain will not verify checkpoints unless disputes happen. Meanwhile, end-users enjoy a two-step withdrawal protocol, ensuring that they can safely collect assets back to the mainchain without relying on the BFT committee. Our experiments show that Cumulus sidechains outperform ZK-Rollup, another promising sidechain construction, achieving one and two orders of magnitude improvement in throughput and latency while retaining comparable operational cost.}
}
