@inproceedings{DBLP:conf/iwqos/LiZC24,
	author = {Zhexiong Li and
                  Deze Zeng and
                  Ranzhao Chen},
	title = {WebAssembly or Container? Joint Optimization of Microservice Consolidation
                  and Deployment towards Cost Efficient Edge-End Consortium},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682874},
	doi = {10.1109/IWQOS61813.2024.10682874},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/LiZC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Edge-End Consortium, with the integration of edge computing servers and end devices like IoT devices, has emerged as a promising infrastructure for on-site computing power provision. But the high heterogeneity has raised unprecedented challenges in its resource management and task scheduling. Both WebAssembly and Container provide lightweight and portable way to consolidate and deploy microservices to combat the heterogeneity problem. However, the inherent advantages and disadvantages of WebAssembly and Container make it nontrivial to decide the microservice consolidation way and the deployment site, especially in the consideration of dependency between microservices. In this paper, we investigate the problem of mixed deployment of WebAssembly and Container based dependent microservices to strike a balance between communication and deployment cost toward high overall cost efficiency. We first cast this problem into a Quadratic Integer Programming (QIP) formulation and prove it as NP-hard. We then introduce a Randomized Rounding WebAssembly and Containerized Microservice Deployment (RR-WCMD) algorithm with polynomial computation complexity and guaranteed performance efficiency. Experiment results show that RR-WCMD can significantly lower the cost by an average of 34% in comparison with state-of-theart algorithms, thanks to the joint consideration of consolidation way and deployment site.}
}


@inproceedings{DBLP:conf/iwqos/YingLL24,
	author = {Chen Ying and
                  Baochun Li and
                  Bo Li},
	title = {Blade: Pushing the Performance Envelope of Asynchronous Federated
                  Learning},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--6},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682956},
	doi = {10.1109/IWQOS61813.2024.10682956},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/YingLL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Asynchronous federated learning (FL) has been proposed to decrease the training time in conventional FL where the communication paradigm is synchronous. Instead of aggregating after receiving updates from all the selected clients, an asynchronous FL server conducts aggregation without waiting for slow clients. Though superior to synchronous FL, the performance of existing works in asynchronous FL — measured by the wall-clock time of global training — leaves much to be desired, as the staleness of client updates may degrade the performance substantially. In this paper, we propose Blade, a new stalenessaware framework that seeks to push the performance envelope of asynchronous FL by designing new mechanisms in all important design aspects of FL training, including client selection, adaptive pruning, quantization, and update aggregation. Blade selects clients based on their staleness and the quality of their previous updates. Before reporting to the server, every client prunes its update with a pruning amount related to its staleness and quantizes the pruned update. When aggregating updates, Blade tunes the aggregation weight of each update according to its staleness and divergence from the previous global model. In an extensive array of performance evaluations with six benchmark datasets, Blade consistently showed its substantial performance superiority over its state-of-the-art competitors. It decreased the wall-clock training time by up to 64.6%.}
}


@inproceedings{DBLP:conf/iwqos/WangLLQTY24,
	author = {Yanyan Wang and
                  Jia Liu and
                  Shen{-}Huan Lyu and
                  Zhihao Qu and
                  Bin Tang and
                  Baoliu Ye},
	title = {Identifying Key Tag Distribution in Large-Scale {RFID} Systems},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682898},
	doi = {10.1109/IWQOS61813.2024.10682898},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/WangLLQTY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the proliferation of RFID-enabled applications, multiple readers are required for the complete coverage of numerous tags in a large-scale RFID system. In this scenario, we sometimes pay more attention to a subset of tags instead of all, which are referred to as key tags. In this paper, we study an under-investigated problem key tag distribution identification, which aims to identify which key tags are beneath which readers. This is crucial for efficiently managing specific items of interest, which can quickly pinpoint key tags and help RFID readers covering these tags collaborate to improve the tag inventory efficiency. Since key tags typically make up a small part of all tags, it is time consuming to deal with all tags in the traditional way. We propose a protocol called Kadept that identifies the key tag distribution by using a sophisticatedly designed filter that teases out key tags as well as assigns each of them a singleton slot for response. With this design, a great number of trivial (non-key) tags will keep silent and free up bandwidth resources for key tags, and each key tag is sorted in a collision-free way and can be identified with only 1-bit response, which significantly improves the time efficiency. We theoretically analyze how can we optimize protocol parameters of Kadept and conduct extensive simulations under different tag distribution scenarios. Compared with the state-of-the-art, Kadept can improve the time efficiency by a factor of 3.7×, when the ratio of key tags to all tags is 0.1.}
}


@inproceedings{DBLP:conf/iwqos/FengZFZL24,
	author = {Yuming Feng and
                  Weizhe Zhang and
                  Zijun Feng and
                  Xiaoxiong Zhong and
                  Fangming Liu},
	title = {An MTD-driven Hybrid Defense Method Against DDoS Based on Markov Game
                  in Multi-controller SDN-enabled IoT Networks},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--6},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682921},
	doi = {10.1109/IWQOS61813.2024.10682921},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/FengZFZL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The widespread deployment of low-cost, vulnerable IoT devices allows attackers to exploit them to generate botnets and launch distributed denial-of-service (DDoS) attacks, which has become a serious security challenge for ensuring quality of service (QoS). For cost-effective defense against DDoS, we propose a novel hybrid defense method that includes proactive moving target defense (MTD) and passive security control to resist DDoS threats at different stages in IoT networks in this paper. We construct a multi-stage Markov game model to portray the game as a competition between the attacker and the defender for the control duration of the attack surface, and design an optimal defense strategy algorithm. In particular, we introduce a new parameter of action execution interval expectation in the game and add node importance evaluation in the reward quantification so that the optimal action execution interval of each defense technique can be output. We also consider the possibility that advanced attackers may launch DDoS on the SDN controller in the game. The experimental results demonstrate that our proposed method can defend against DDoS cost-effectively and ensure the QoS in IoT networks with acceptable overhead.}
}


@inproceedings{DBLP:conf/iwqos/CaoZFZ24,
	author = {Charles Cao and
                  Jie Zhuang and
                  Joshua Fu and
                  Wenjun Zhou},
	title = {Quality of Surveillance Analysis of {LEO} Satellite Constellations
                  for Orbital Edge Computing in Precision Agriculture and Climate Monitoring},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--6},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682842},
	doi = {10.1109/IWQOS61813.2024.10682842},
	timestamp = {Tue, 15 Oct 2024 16:43:28 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/CaoZFZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we study the Quality of Surveillance of Low Earth Orbit (LEO) satellite constellations in orbit edge computing platforms, with a focus on monitoring and detecting unpredictable intruding targets. We are primarily interested in targets for precision agriculture and climate monitoring purposes, ranging from natural events such as tornados and flooding, to human-induced phenomenon, such as forest fires and crop monitoring. Targets may be static or mobile. We develop an analytical model that seeks to predict performance attributes of the surveillance. The model takes into account tunable system parameters, such as the number of satellites and their altitude, thereby allowing us to decide the best constellation configuration for different purposes. The results from the analytical model validate the feasibility of using LEO constellation for surveillance purposes and illustrate how model-guided parameter tuning can significantly enhance the monitoring performance in precision agriculture and climate monitoring applications.}
}


@inproceedings{DBLP:conf/iwqos/ZhaoLLSZX24,
	author = {Yi Zhao and
                  Liang Lv and
                  Yusen Li and
                  Meng Shen and
                  Liehuang Zhu and
                  Ke Xu},
	title = {Rethinking and Optimizing Workload Redistribution in Large-scale Internet
                  Data Centers},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682613},
	doi = {10.1109/IWQOS61813.2024.10682613},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/ZhaoLLSZX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Heuristic-based workload redistribution is the most commonly adopted solution to provide enhanced service performance in large-scale Internet Data Centers (IDCs). However, statistics show that they cannot perform as well as expected in real-world IDCs. In this paper, we rethink existing solutions based on real-world trace data and pinpoint two major pitfalls: (i) Sensitive to hand-tuning parameters; (ii) Reassigning only a few workloads locally at a time. The two of them jointly limit the universal applicability of existing solutions in optimizing multiple objectives fairly. To address such issues, we propose the matching-theory-based solution for workload redistribution, namely Themis. It is an efficient and universal solution for large-scale IDCs, which can avoid empirical parameters in optimization and reassign several workloads globally each time. Moreover, the newly proposed Themis can optimize multiple objectives (e.g., resource utilization balancing and communication efficiency improving) simultaneously and fairly. In addition to its own performance advantages, our proposed Themis is also compatible with existing methods, thus adapting to a wider range of deployment scenarios. Extensive evaluations based on the trace data from two real-world IDCs demonstrate that our proposed Themis outperforms multiple comparison solutions, as well as the compatibility of parameter changes (i.e., stability properties in terms of parameter configuration).}
}


@inproceedings{DBLP:conf/iwqos/HuHLHWW24,
	author = {Jinbin Hu and
                  Yi He and
                  Wangqing Luo and
                  Jiawei Huang and
                  Jianxin Wang and
                  Jin Wang},
	title = {TaLB: Tensor-aware Load Balancing for Distributed {DNN} Training Acceleration},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682910},
	doi = {10.1109/IWQOS61813.2024.10682910},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/HuHLHWW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Increasingly large-scale models and rich data sets make communication overhead a key bottleneck for distributed Deep Neural Network (DNN) training, constantly attracting the attention of academia and industry. Despite continuous efforts, prior solutions such as pipelining computation/communication and in-network gradient compression/scheduling do not focus on how to accelerate DNN training through load balancing in datacenter networks (DCNs). However, the existing load balancing mechanisms are unaware of tensor integrity and priority for gradient parameter synchronization during the DNN training iterations, resulting in severe tensor tail latency and slow model convergence speed. In this paper, we present a Tensor-aware Load Balancing (TaLB) scheme to accelerate DNN training. Specifically, TaLB identifies the different priority tensors and makes (re)routing decisions based on the tensor-level granularity to cut the high-priority tensors tail delay. The testbed implementation and large-scale NS-3 simulation results show that TaLB effectively accelerates DNN training speed. For example, TaLB significantly reduces the average flow completion time (FCT) by up to 55%, and accelerates the model training speed up to 2.37× on VGG19, ResNet50 and AlexNet models.}
}


@inproceedings{DBLP:conf/iwqos/ZuoSZLLDZ24,
	author = {Tianyu Zuo and
                  Tao Sun and
                  Shuyong Zhu and
                  Wenxiao Li and
                  Lu Lu and
                  Zongpeng Du and
                  Yujun Zhang},
	title = {LoWAR: Enhancing {RDMA} over Lossy WANs with Transparent Error Correction},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682853},
	doi = {10.1109/IWQOS61813.2024.10682853},
	timestamp = {Fri, 15 Nov 2024 15:28:13 +0100},
	biburl = {https://dblp.org/rec/conf/iwqos/ZuoSZLLDZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As the increase of geographically distributed applications continues, the demand for high-speed, long-distance data transmission across wide area networks (WANs) has significantly increased. Remote Direct Memory Access (RDMA) is extensively deployed in data center networks (DCNs) for its high throughput, low latency, and reduced CPU utilization, and its extension to WANs is expected to fully leverage these benefits. However, existing RDMA solutions, while demonstrating superior performance in data centers, face a performance gap over WANs due to their reliance on DCNs for optimal performance and lack of optimization for WANs’ high latency and loss rates. To bridge this gap, we introduce Lossy Wide-Area RDMA (LoWAR), a high-goodput, high-reliability RDMA solution for lossy WANs. LoWAR incorporates a forward error correction (FEC) shim layer to protect RDMA messages from packet loss, thus minimizing the inefficiency of retransmissions. It also fully offloads processing to RNICs with minimal computational overhead and storage burden, operating transparently on RNICs without requiring modifications to existing applications and networks. We implement a LoWAR prototype with FPGA and evaluate its performance through testbed experiments. The results demonstrate LoWAR’s enhanced performance in lossy WANs: in WANs with 40ms RTT and 0.001% to 0.01% loss rates, LoWAR increases RDMA goodput by 2.05 to 5.01 times, reduces average flow completion times (FCTs) by 3.5% to 12.2%, and eliminates 99th percentile tail FCTs in most scenarios.}
}


@inproceedings{DBLP:conf/iwqos/LuoWSLQZW24,
	author = {Yizhou Luo and
                  Qiang Wang and
                  Shaohuai Shi and
                  Jiaxin Lai and
                  Shuhan Qi and
                  Jiajia Zhang and
                  Xuan Wang},
	title = {Scheduling Deep Learning Jobs in Multi-Tenant {GPU} Clusters via Wise
                  Resource Sharing},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682877},
	doi = {10.1109/IWQOS61813.2024.10682877},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/LuoWSLQZW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Deep learning (DL) has demonstrated significant success across diverse fields, leading to the construction of dedicated GPU accelerators within GPU clusters for high-quality training services. Efficient scheduler designs for such clusters are vital to reduce operational costs and enhance resource utilization. While recent schedulers have shown impressive performance in optimizing DL job performance and cluster utilization through periodic reallocation or selection of GPU resources, they also encounter challenges such as preemption and migration overhead, along with potential DL accuracy degradation. Nonetheless, few explore the potential benefits of GPU sharing to improve resource utilization and reduce job queuing times.Motivated by these insights, we present a job scheduling model allowing multiple jobs to share the same set of GPUs without altering job training settings. We introduce SJF-BSBF (shortest job first with best sharing benefit first), a straightforward yet effective heuristic scheduling algorithm. SJF-BSBF intelligently selects job pairs for GPU resource sharing and runtime settings (sub-batch size and scheduling time point) to optimize overall performance while ensuring DL convergence accuracy through gradient accumulation. In experiments with both physical DL workloads and trace-driven simulations, even as a preemptionfree policy, SJF-BSBF reduces the average job completion time by 27-33% relative to the state-of-the-art preemptive DL schedulers. Moreover, SJF-BSBF can wisely determine the optimal resource sharing settings, such as the sharing time point and sub-batch size for gradient accumulation, outperforming the aggressive GPU sharing approach (baseline SJF-FFS policy) by up to 17% in large-scale traces.}
}


@inproceedings{DBLP:conf/iwqos/SunMYWZCLX24,
	author = {Ruoshi Sun and
                  Hao Mei and
                  Ruyi Yao and
                  Hao Wang and
                  Yiren Zhou and
                  Zixuan Chen and
                  Sen Liu and
                  Yang Xu},
	title = {TCAMVisor: High-throughput {TCAM} Virtualization for Multi-tenant
                  Software Defined Networking},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682879},
	doi = {10.1109/IWQOS61813.2024.10682879},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/SunMYWZCLX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Software Defined Networking (SDN) provides users with a unified abstraction of physical networks. To meet the demands of modern data centers, many works have focused on designing network virtualization hypervisors that support multi-tenant SDN. Ternary Content Addressable Memory (TCAM) is widely used in SDN switches for rule storage. While it has extremely high lookup throughput, it also features drawbacks such as small capacity and slow update speed. Faced with multi-tenant scenarios, its limitations are even more pronounced. Existing hypervisors lack consideration for TCAM isolation, leading to slower TCAM updates and the mutual impact of requests from different tenants. Consequently, they fail to provide guaranteed performance to tenants. To solve these problems, we propose TCAMVisor, which further isolates TCAM resources based on traditional SDN hypervisors. Specifically, TCAMVisor provides better allocation mechanisms for TCAM entry and control bandwidth, ensuring inter-tenant isolation while improving resource utilization. Additionally, TCAMVisor improves the update speed of TCAM by delicately placing tenant rules. To the best of our knowledge, TCAMVisor is the first work to effectively achieve tenant isolation in TCAM, with an average throughput improvement of 5.5 times compared to FlowVisor.}
}


@inproceedings{DBLP:conf/iwqos/ZhuZCF24,
	author = {Yifei Zhu and
                  Botao Zhu and
                  Chen Chen and
                  Xiaoyi Fan},
	title = {Towards Efficient Compound Large Language Model System Serving in
                  the Wild},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--2},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682929},
	doi = {10.1109/IWQOS61813.2024.10682929},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/ZhuZCF24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Utilizing compound Large Language Model (LLM) systems, instead of a monolithic LLM model, is gradually becoming a practical solution to realize a diverse range of industry applications. In compound LLM systems, an LLM collaborates with other external tools, APIs, or LLMs to offer intelligent services. In this poster, we identify the unique challenges, namely temporal and topological uncertainty, brought about by compound LLM systems in system serving. We then propose a priority-based scheduling policy to schedule different stages in DAG-represented compound LLM systems. The preliminary results show promising performance of uncertainty-aware scheduling policies.}
}


@inproceedings{DBLP:conf/iwqos/ZhongYKDL24,
	author = {Zhengxi Zhong and
                  Hongyang Yan and
                  Arthur Sandor Voundi Koe and
                  Weichu Deng and
                  Junyang Li},
	title = {Towards Key-Escrow Free Attribute-Based Encryption for Self-Sovereign
                  Identity Systems},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682908},
	doi = {10.1109/IWQOS61813.2024.10682908},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/ZhongYKDL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent years, the exponential advances in cloud computing have upheld cloud data sharing as a prominent service of interest to practitioners. Data leakage risks and lack of fine-grained access control remain significant challenges limiting the wide adoption of cloud data sharing. Ciphertext policy attribute-based encryption (CP-ABE) stands as a promising solution for these issues. Current research in CP-ABE suffers from the key-escrow problem on the trusted key generation center, overlooks user identity sovereignty, and fails to guarantee user attributes’ privacy. This paper proposes a novel key escrow-free CP-ABE scheme that builds upon self-sovereign identity to enable secure and privacy-preserving cloud data sharing. We leverage multi-party computation to develop a novel user key generation protocol. We design a seamless and secure integration between CP-ABE and self-sovereign identity. The experimental and security analyses show that our scheme solves existing issues in CP-ABE while preserving security and flexibility. This research provides new insights to secure data sharing solutions in the cloud.}
}


@inproceedings{DBLP:conf/iwqos/WangHZXDXY24,
	author = {Zeyu Wang and
                  Xiaowu He and
                  Xiangwen Zhuge and
                  Shen Xu and
                  Fan Dang and
                  Jingao Xu and
                  Zheng Yang},
	title = {Enabling Network Diagnostics in Time-Sensitive Networking: Protocol,
                  Algorithm, and Hardware},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682902},
	doi = {10.1109/IWQOS61813.2024.10682902},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/WangHZXDXY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Time-Sensitive Networking (TSN) is foreseen as a foundational technology that enables Industry 4.0. It offers deterministic data transmission over Ethernet for critical applications such as industrial control and automotive systems. However, TSN is susceptible to hardware and software errors, necessitating an effective diagnostic system. Traditional network diagnostic tools are inadequate for TSN fault localization due to the unique characteristics of TSN. In response, this paper presents TSNCard, a cross-cycle postcard-based diagnostic system tailored for TSN. TSNCard introduces a novel telemetry protocol that leverages the cyclical nature of TSN networks for data collection at each node. This protocol, coupled with dedicated analytic algorithms and hardware innovations within switches, forms a comprehensive system for TSN monitoring and fault localization. Extensive experiments on both simulation and physical testbeds show that TSNCard can 100% localize the root cause of the TSN misbehavior while adhering to industrial bandwidth restrictions. TSNCard not only bridges the gap in the TSN protocol stack, but also serves as a versatile toolkit for time-synchronized network analysis, paving the way for future research.}
}


@inproceedings{DBLP:conf/iwqos/HuangMLKZYC24,
	author = {Yaodong Huang and
                  Changkang Mo and
                  Tianhang Liu and
                  Biying Kong and
                  Lei Zhang and
                  Yukun Yuan and
                  Laizhong Cui},
	title = {{QUIC} meets {ICN:} {A} Versatile Wireless Transport Strategy in Multi-access
                  Edge Environments},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--6},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682860},
	doi = {10.1109/IWQOS61813.2024.10682860},
	timestamp = {Thu, 17 Oct 2024 15:42:21 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/HuangMLKZYC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Information-centric Networking in edge computing environments exhibits the potential to significantly enhance the efficiency, reliability, and security of data transmission, making it a promising technology for future network deployments. However, the differences from traditional networks require applications to actively redevelop and redeploy onto edge devices, incurring additional costs for the proliferation of ICN applications. In this paper, we propose a system to adapt QUIC protocol over ICN networks in multi-access edge networks. The system aims to expand the application repertoire for ICN by providing a smooth transition of applications using QUIC to run on ICN networks. We design an ICN-QUIC conversion layer to manage the transmission of data from QUIC-based applications. We implement and evaluate the designed system. The experiment results show that, compared to existing networks, our system can enhance the transmission efficiency, i.e., up to 20 times better goodput in multicast situations, and achieves comparable results in unicast scenarios. We test the scalability of our system in real edge and wireless environments. We also deploy the real applications over the proposed system to demonstrate its compatibility in ICN and MEC environments.}
}


@inproceedings{DBLP:conf/iwqos/LuoZXCX24,
	author = {Luyao Luo and
                  Gongming Zhao and
                  Hongli Xu and
                  Chun{-}Jen Chung and
                  Liguang Xie},
	title = {{SMART:} Dual-channel Southbound Message Delivery in Clouds with Rate
                  Estimation},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682836},
	doi = {10.1109/IWQOS61813.2024.10682836},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/LuoZXCX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Driving southbound messages from a cloud control plane down to the distributed data plane on every compute node is one of the critical challenges in public clouds. Existing message delivery solutions solely based on remote procedure call (RPC) or message queue (MQ) tend to overlook strict resource constraints, e.g., network bandwidth and CPU capacity. This often results in extensive overhead in the control plane or message redundancy in the data plane, especially when a cloud receives highly concurrent user requests or experiences a rapid expansion. To this end, we design a dual-channel southbound message delivery framework, namely SMART, which combines an RPC channel with an MQ channel, to maximize the resource utilization in the cloud network. In the control plane, we implement a message parsing mechanism and propose a delivery channel selection algorithm based on the deep reinforcement learning (DRL) approach to support efficient dual-channel delivery under resource constraints. In the data plane, we design a message agent on each compute node to ensure the order preservation and state consistency of southbound messages. Both experimental and large-scale simulation results show that SMART demonstrates a reduction in control plane overhead by 64% compared to RPC and redundant messages by 45% compared to MQ, respectively.}
}


@inproceedings{DBLP:conf/iwqos/PanWZLNL24,
	author = {Cheng Pan and
                  Feng Wang and
                  Cong Zhang and
                  Jiaxing Li and
                  Edith C. H. Ngai and
                  Jiangchuan Liu},
	title = {Every Little Bit Helps: {A} Semantic-aware Tail Label Understanding
                  Framework},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--2},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682841},
	doi = {10.1109/IWQOS61813.2024.10682841},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/PanWZLNL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The rapid expansion of AI technology, driven by high-speed networks and high-performance mobile devices, enables personalized and cross-content recommendations across diverse applications. Recent methods consider a large number of textual content keywords or topics as labels for recommendations, transforming the problem into Extreme Multi-label Learning (XML). However, addressing the XML problem in AI-driven recommendation systems that handle extensive user-generated data while ensuring Quality of Service (QoS) faces two main challenges: significant computational costs and inferior tail label prediction performance. We propose SAT, a semantic-aware framework with a tree architecture that effectively tackles these challenges and demonstrates improved performance compared to well-established approaches.}
}


@inproceedings{DBLP:conf/iwqos/GuoSGHS24,
	author = {Miao Guo and
                  Yifei Sun and
                  Chaojie Gu and
                  Shibo He and
                  Zhiguo Shi},
	title = {Exploiting Dependency-Aware Priority Adjustment for Mixed-Criticality
                  {TSN} Flow Scheduling},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--6},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682868},
	doi = {10.1109/IWQOS61813.2024.10682868},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/GuoSGHS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Time-Sensitive Networking (TSN) serves as a one-size-fits-all solution for mixed-criticality communication, in which flow scheduling is vital to guarantee real-time transmissions. Traditional approaches statically assign priorities to flows based on their associated applications, resulting in significant queuing delays. In this paper, we observe that assigning different priorities to a flow leads to varying delays due to different shaping mechanisms applied to different flow types. Leveraging this insight, we introduce a new scheduling method in mixed-criticality TSN that incorporates a priority adjustment scheme among diverse flow types to mitigate queuing delays and enhance schedulability. Specifically, we propose dependency-aware priority adjustment algorithms tailored to different link-overlapping conditions. Experiments in various settings validate the effectiveness of the proposed method, which enhances the schedulability by 20.57% compared with the SOTA method.}
}


@inproceedings{DBLP:conf/iwqos/XuGZLCW24,
	author = {Changfu Xu and
                  Jianxiong Guo and
                  Jiandian Zeng and
                  Yupeng Li and
                  Jiannong Cao and
                  Tian Wang},
	title = {Incorporating Startup Delay into Collaborative Edge Computing for
                  Superior Task Efficiency},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682611},
	doi = {10.1109/IWQOS61813.2024.10682611},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/XuGZLCW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Collaborative edge computing enables low service delay for many delay-sensitive Internet of Things applications through edge-edge and edge-cloud collaborations. Due to the limited edge resources and varying task demands, optimizing Joint Service Placement and Task Offloading (JSPTO) becomes crucial in minimizing overall processing delays. However, existing JSPTO methods overlook the impact of service startup delay, which may undermine total latency reduction, especially in scenarios with large startup delays. This paper introduces an online JSPTO method that integrates the consideration of service startup delay to enhance task offloading efficiency. However, a significant challenge is ensuring timely service response with large startup delays. We formulate this problem as an integer linear programming problem, aiming to minimize the total service startup and task processing delay. We propose a novel algorithm called SD-JSPTO, which performs online JSPTO in the presence of large startup delays. Theoretical performance analyses reveal that SD-JSPTO attains a near-optimal solution within polynomial time, demonstrating a competitive ratio of\n1+\nA\n2\nV\nT\nopt\n. Experimental evaluations demonstrate that our method significantly reduces the total delay by no less than 18.72% compared to state-of-the-art baseline methods while preserving system stability.}
}


@inproceedings{DBLP:conf/iwqos/LongHWYX24,
	author = {Minfei Long and
                  Jiangping Han and
                  Wentao Wang and
                  Jiayu Yang and
                  Kaiping Xue},
	title = {{LSCC:} Link-Segmented Congestion Control for {RDMA} in Cross-Datacenter
                  Networks},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682909},
	doi = {10.1109/IWQOS61813.2024.10682909},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/LongHWYX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As multiple datacenters are established in different geographical locations, some applications run on cross-datacenter networks. In order to improve the service quality, service providers establish dedicated links between datacenters to take advantage of the high performance of RDMA. However, existing RDMA congestion control algorithms are designed for intra-datacenter networks. Due to the long distance between data-centers, cross-datacenter networks have higher latency, which leads to long feedback loop that prevents timely adjustments at the traffic source. Meanwhile, excessive congestion signals are generated due to untimely adjustments, which makes existing RDMA congestion control algorithms unable to accurately deal with congestion like in cross-datacenter networks. In addition, the long-haul link connecting datacenters has large bandwidth delay product (BDP), which brings great buffer pressure to switches. In this paper, link-segmented congestion control (LSCC) is proposed to avoid congestion through segmented link control. LSCC builds a segmented feedback loop between egress switches connecting to the long-haul link, which provides timely congestion feedback and greatly reduces the buffer pressure of switches. Evaluations based on DPDK implementation and large-scale simulation show that LSCC can reduce the average flow completion time (FCT) by 30%-65% and 31%-56% in realistic datacenter load and cross-datacenter load, respectively.}
}


@inproceedings{DBLP:conf/iwqos/ZhanWTZL24,
	author = {Shichen Zhan and
                  Yebo Wu and
                  Chunlin Tian and
                  Yan Zhao and
                  Li Li},
	title = {Heterogeneity-Aware Coordination for Federated Learning via Stitching
                  Pre-trained blocks},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682959},
	doi = {10.1109/IWQOS61813.2024.10682959},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/ZhanWTZL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated learning (FL) coordinates multiple devices to collaboratively train a shared model while preserving data privacy. However, large memory footprint and high energy consumption during the training process excludes the low-end devices from contributing to the global model with their own data, which severely deteriorates the model performance in real-world scenarios. In this paper, we propose FedStitch, a hierarchical coordination framework for heterogeneous federated learning with pre-trained blocks. Unlike the traditional approaches that train the global model from scratch, for a new task, FedStitch composes the global model via stitching pre-trained blocks. Specifically, each participating client selects the most suitable block based on their local data from the candidate pool composed of blocks from pre-trained models. The server then aggregates the optimal block for stitching. This process iterates until a new stitched network is generated. Except for the new training paradigm, FedStitch consists of the following three core components: 1) an RL-weighted aggregator, and 2) a search space optimizer deployed on the server side, and 3) a local energy optimizer deployed on each participating client. The RL-weighted aggregator helps to select the right block in the non-IID scenario, while the search space optimizer continuously reduces the size of the candidate block pool during stitching. Meanwhile, the local energy optimizer is designed to minimize the energy consumption of each client while guaranteeing the overall training progress. The results demonstrate that compared to existing approaches, FedStitch improves the model accuracy up to 20.93%. At the same time, it achieves up to 8.12× speedup, reduces the memory footprint up to 79.5%, and achieves 89.41% energy saving at most during the learning procedure.}
}


@inproceedings{DBLP:conf/iwqos/CaoOZLC24,
	author = {Xinyuan Cao and
                  Tao Ouyang and
                  Kongyange Zhao and
                  Yousheng Li and
                  Xu Chen},
	title = {Efficient Multi-Task Asynchronous Federated Learning in Edge Computing},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682892},
	doi = {10.1109/IWQOS61813.2024.10682892},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/CaoOZLC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Driven by the continuous upgrading of hardware devices, a notable shift from traditional single-FL task to complicated multi-FL tasks is emerging in edge computing, supporting richer intelligent services. With the presence of high capacity heterogeneity and intensive resource contention at the edge, it is highly non-trivial to collaboratively optimize resource scheduling of multiple FL tasks with diverse QoS requirements. To well tackle the above challenge, we firstly propose a novel Multi-Task Asynchronous Federated Learning (MTAFL) architecture. This novel framework has the potential to enhance resource utilization efficiency by enabling the orthogonal multiplexing of computation and communication resources through adjusting the number of local epochs on edge clients. Then, we formulate an optimization problem within the MTAFL framework, aiming at managing resource allocation and client scheduling to minimize the system-wide energy consumption while achieving the target FL performance. However, intricate couplings for resource allocation and local training decisions arise during the long-term FL process. We hence employ a two-step relaxation approach to transform original non-convex problem into a multi-convex problem, and further devise an efficient optimization strategy based on the block coordinate descent algorithm. Extensive numerical evaluations corroborate the superior performance of the proposed MTAFL framework over existing schemes.}
}


@inproceedings{DBLP:conf/iwqos/NiuLYDCYC24,
	author = {Kangli Niu and
                  Shenghao Liu and
                  Lingzhi Yi and
                  Xianjun Deng and
                  Suning Chen and
                  Laurence T. Yang and
                  Minmin Cheng},
	title = {{ENSIOT:} {A} Stacking Ensemble Learning Approach for IoT Device Identification},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--6},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682848},
	doi = {10.1109/IWQOS61813.2024.10682848},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/NiuLYDCYC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In order to resist network attacks on IoT devices, identifying IoT devices is the first step for ensuring device security. The traditional passive method identifies IoT devices by mining the potential relationship between traffic characteristics and devices. However, the form of selected traffic features are too singular without considering device behavioral characteristics and the classifier used is too specific with simple structure in these methods. This paper proposes a stacking ensemble learning approach for IoT device identification, ENSIOT, which fully considering the behavioral characteristics of devices and integrating the advantages of various machine learning methods to achieve efficient identification of IoT devices. Firstly, in the process of traffic processing, our method selects features from activity cycles, port numbers, signalling patterns, and cipher suites. Then, in model integration, many machine learning methods are used as base models to learn features selected, and output preliminary recognition results. Finally, the meta model learns the relationship between label and the recognition results of each base model and outputs the final device identification result. This stacking structure stacks the base models and the meta model to make a classifier with strong identification and generalization ability. Incremental learning is used to improve identification accuracy when traffic pattern changing. Comparative experiments are conducted on two datasets of UNSW and TMA-2021. The experimental results verify the effectiveness of ENSIOT, which achieve the accuracy of over 98% on two dataset and bring a noticeable improvement in terms of both accuracy and macro F1 score.}
}


@inproceedings{DBLP:conf/iwqos/JiangZZDTLL24,
	author = {Shenyao Jiang and
                  Wangqiu Zhou and
                  Hao Zhou and
                  Jialin Deng and
                  Haisheng Tan and
                  Zhi Liu and
                  Zhenjiang Li},
	title = {FreAuth: Novel Frequency Feature-Based Device Authentication for Magnetic
                  Wireless Charging},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--6},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682854},
	doi = {10.1109/IWQOS61813.2024.10682854},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/JiangZZDTLL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Device authentication plays a crucial role in preventing illegal access and ensuring smooth usage of magnetic wireless charging. However, current authentication techniques suffer from security vulnerabilities and are incompatible with low-cost receiver devices, thus severely limiting their applications. In this paper, we propose FreAuth, a novel Frequency feature-based device Authentication technology for magnetic wireless power transfer systems. Technically, we begin by conducting circuit measurements at the transmitter side to subtly retrieve impedance information related to the receiver without the need for its corporation. Then, we employ a dual-frequency interleaved-based subtraction technique to remove the ideal receiver impedance and capture the fairly weak frequency features. Furthermore, we normalize the captured frequency features to account for environment variations. These steps allow us to generate and store a hardware fingerprint for the receiver based on its frequency features. During device authentication, we use a discrete Frechet distance-based algorithm for fingerprint matching. We devise and implement a prototype of FreAuth and conduct extensive experiments to evaluate the proposed scheme. The experimental results validate the reliability (95.74% authentication accuracy among 60+ devices) and robustness (anti-interference with device location variations) of our FreAuth.}
}


@inproceedings{DBLP:conf/iwqos/CaoTPLM24,
	author = {Weipeng Cao and
                  Xi Tao and
                  Yinghui Pan and
                  Ye Liu and
                  Zhong Ming},
	title = {QoS Perception for Cloud Databases: Necessity, Trends, and Challenges},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--2},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682935},
	doi = {10.1109/IWQOS61813.2024.10682935},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/CaoTPLM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The advantages of resource elasticity and proactive data backup in cloud databases have attracted a large number of users to consider deploying their IT systems in the cloud. Factors such as performance, reliability, security, and ease of use are the most important considerations for users when choosing to migrate to the cloud. This paper mainly discusses the necessity of Quality of Service (QoS) awareness for cloud applications in the current public cloud environment, as well as the technological trends and challenges associated with it.}
}


@inproceedings{DBLP:conf/iwqos/ZhangZXWC24,
	author = {Jie Zhang and
                  Xutong Zuo and
                  Xiaohui Xie and
                  Wei Wang and
                  Yong Cui},
	title = {TransPortal: Keeping Applications Enjoying Tailored Transport Effortlessly},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--6},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682948},
	doi = {10.1109/IWQOS61813.2024.10682948},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/ZhangZXWC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Since its advent, TCP has been the overwhelming choice at the transport layer. Developers utilize transport entities of TCP provided by the operating system to implement their network applications. Recently, due to the limitations of TCP and challenges in extending it, noteworthy protocols, such as TLS and QUIC, are emerging. Applications are motivated to try these modern transport protocols for security, performance, flexibility, and extensibility purposes. Unlike TCP, which adheres to the POSIX standards, most entities of these new protocols provide complex project-specific interfaces, making integrating them difficult and may introduce security risks.In this paper, we propose TransPortal, a framework enabling applications to utilize modern transport services flexibly and safely. TransPortal decouples the implementation of applications from underlying entities, and executes transport entities in separate transport agents, which can be replaced without application modification and even runtime. In addition, TransPortal monitors the execution of agents and provides error handling, protecting applications from instability or misuse of new transport entities. We implement a prototype of TransPortal and explore it with several popular transport entities. Extensive evaluation demonstrates that TransPortal provides applications convenience and safety while incurring acceptable overhead.}
}


@inproceedings{DBLP:conf/iwqos/FanXFLX24,
	author = {Shuhui Fan and
                  Haoran Xu and
                  Shaojing Fu and
                  Yuchuan Luo and
                  Ming Xu},
	title = {Edge-feature Modeling-based Topological Graph Neural Networks for
                  Phishing Scams Detection on Ethereum},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682857},
	doi = {10.1109/IWQOS61813.2024.10682857},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/FanXFLX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Detecting phishing scams has become an important task in blockchain-based cryptocurrency applications. While many network representation learning-based approaches have been proposed for this task, they suffer from various issues including (1) the requirement of handcrafted features, which may not capture complex relationships and patterns in graph data, and/or (2) considering only node features while ignoring the more significant edge features, and/or (3) incapability of preserving complete network topology, which affects the generalization ability. In this paper, we propose a novel Edge-feature modeling-based Topological Graph Neural Network (ETGNN) to detect phishing scams on Ethereum, which avoids all aforementioned issues of existing approaches. Specifically, ETGNN involves two key components, one responsible for learning weighted features of nodes and edges in the Ethereum transaction graph, and the other responsible for incorporating global topological information of the graph using persistent homology. Finally, phishing scams are detected based on these two learned features. The experimental results demonstrate that ETGNN outperforms the state-of-the-art method with an improvement rate of 14.38% on F 1 -score.}
}


@inproceedings{DBLP:conf/iwqos/XuLWS24,
	author = {Heng Xu and
                  Letian Li and
                  Liang Wang and
                  Fei Song},
	title = {Congestion Control as a Service: Towards Low Latency Mobile Uploading},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682903},
	doi = {10.1109/IWQOS61813.2024.10682903},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/XuLWS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Ensuring quality of service (QoS) for data transmission in dynamic network environments presents a significant challenge. To solve the conflict between complex network conditions and strict transmission quality, effective solutions employing artificial intelligence have recently been introduced. Nonetheless, the prevalent methods primarily emphasize throughput oriented designs, concentrating on data’s downlink transmission while overlooking the upload of delay sensitive data during bidirectional interactions. Resource-constrained mobile devices struggle not only with executing long-term and continuous online computing tasks but also with rapidly adjusting to the constantly changing wireless networks. Models running on mobile devices must adapt to the changing wireless links. Diverse application demands and limited hardware capabilities pose significant obstacles to deploying relevant models.Consequently, we introduce a novel congestion control scheme named Colla, which enables mobile devices to achieve on-demand configurations through edge computing services. Colla reduces the computational load on the devices by incurring manageable communication overhead. It offers flexibility to balance latency and throughput according to the application’s requirements, thereby enabling low-latency data uploads. Experimental evaluations using real-world traces across 28 wireless scenarios demonstrate that Colla achieves effective bandwidth utilization, ranging from 66% to 93% in various conditions. Moreover, while maintaining comparable goodput, Colla significantly diminishes delay, reducing the average and the 99.9th percentile delays by 40% and 64%, respectively. Notably, even under conditions of unreliable edge links, Colla outperforms its competitors.}
}


@inproceedings{DBLP:conf/iwqos/ZhuYG24,
	author = {Haowen Zhu and
                  Minghao Ye and
                  Zehua Guo},
	title = {Toward Determined Service for Distributed Machine Learning},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--6},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682933},
	doi = {10.1109/IWQOS61813.2024.10682933},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/ZhuYG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Parameter Server (PS) is a typical Distributed Machine Learning (DML) enabler and widely used in industry and academia. Existing works propose to apply the emerging In-Network Aggregation (INA) technique to improve model training efficiency. However, existing INA systems may suffer from undetermined model training efficiency and service quality, given that many gradient aggregation processes are still performed by the server under irrational gradient aggregation strategies. In this paper, we propose a Deterministic In-Network Aggregation (DINA) scheme to improve model training efficiency by enhancing the efficiency of INA utilization in DML. Our key observation is to further increase worker sending rates by reducing gradient packets’ RTT. Based on this observation, DINA can rationally select the optimal global gradient aggregation switch depending on the switches’ available memory, worker sending rate, and server processing capacity. Simulation results show that DINA can provide determined training by improving worker sending rates by 16%-87% and network load by 28%-46.8% compared with existing solutions.}
}


@inproceedings{DBLP:conf/iwqos/BaoZXWY24,
	author = {Jianfeng Bao and
                  Gongming Zhao and
                  Hongli Xu and
                  Haibo Wang and
                  Peng Yang},
	title = {InGo: In-Network Aggregation Routing with Batch Size Adjustment for
                  Distributed Training},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682850},
	doi = {10.1109/IWQOS61813.2024.10682850},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/BaoZXWY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Distributed training has emerged as a critical application in clusters due to the widespread adoption of AI technology across various domains. However, as distributed training continues to advance, it has become increasingly time-consuming. To address this challenge, researchers have explored leveraging In-Network Aggregation (INA) to expedite distributed model training. Specifically, by harnessing programmable hardware, such as Intel Tofino switches, INA can aggregate gradients within the network, thereby reducing the amount of gradient transmission and accelerating distributed training. However, previous works assume fixed routing selection and batch size, ignoring their impact on model convergence and resulting in extended completion time. To bridge this gap, we propose InGo, a pioneering approach that considers both in-network aggregation routing and batch size adjustment, and provide the rigorous convergence analysis. Then, we formally define the problem of in-network aggregation routing with batch size adjustment, and present an efficient algorithm with bounded approximation factors to solve this problem. Through extensive experiments on both physical platforms and simulated environments, we demonstrate that InGo significantly reduces the completion time by 25.2%-74.7% compared to state-of-the-art solutions.}
}


@inproceedings{DBLP:conf/iwqos/HouTXXLG24,
	author = {Xiaofeng Hou and
                  Peng Tang and
                  Tongqiao Xu and
                  Cheng Xu and
                  Chao Li and
                  Minyi Guo},
	title = {{CPM:} {A} Cross-layer Power Management Facility to Enable QoS-Aware
                  AIoT Systems},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682859},
	doi = {10.1109/IWQOS61813.2024.10682859},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/HouTXXLG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the rapid progress and widespread adoption of AI technology, integrating powerful DNN models into AIoT devices in close proximity to users has become increasingly appealing. However, a significant challenge is that it is not easy to achieve the stringent Quality of Service (QoS) standards, especially in terms of real-time latency, demanded by the computationally intensive DNN workloads in energy-limited AIoT environments. To address this challenge, prior research has focused on per-layer power management techniques, which aggressively exploit the unique energy and performance relationships exhibited by each layer of the DNN at an exceedingly fine-grained control granularity. In this study, we identify the limitations of the existing per-layer DVFS mechanisms. They severely overlook the significant DVFS overhead caused by the excessively fine-grained control which can introduce complexity to power management in practical scenarios, consequently deteriorating QoS. To mitigate these challenges, we propose CPM, a Cross-layer Power Mangement facility which automatically modularizes different DNN layers and performs the best DVFS policy, thereby enhancing QoS by ensuring lower latency in real-time AIoT systems. Additionally, we integrate CPM into mainstream commercial AIoT boards and systems to validate its effusiveness. The results show that CPM can reduce the execution latency by up to 45.76% while improving the energy efficiency by up to 31.58% of real AIoT systems compared to SOTA per-layer power management methods.}
}


@inproceedings{DBLP:conf/iwqos/LiZZ24,
	author = {Zekai Li and
                  Miao Zhang and
                  Yifei Zhu},
	title = {{OAVS:} Efficient Online Learning of Streaming Policies for Drone-sourced
                  Live Video Analytics},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682870},
	doi = {10.1109/IWQOS61813.2024.10682870},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/LiZZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Drone-sourced live video analytics has extensive applications across diverse domains. Adaptive video streaming is a pivotal technique in these applications that targets at effectively delivering video content to servers under varying network conditions, enabling complex analytics afterward. However, our thorough data analysis reveals that conventional offline video streaming policies cannot effectively adapt to highly fluctuating drone network environments and dynamic changes in aerial view scenes. This results in suboptimal analytic performance and necessitates online adaptation for policy models. Yet, obtaining ground-truth analytics results directly from drones is infeasible due to their limited capacity. Furthermore, naively streaming original videos to the server for online adaption is greatly challenged by the scarce and dynamic networks, leading to decreased accuracy performance and escalated transmission cost if not properly designed. In this paper, we present OAVS, a novel online learning-enabled adaptive streaming framework for drone-sourced video analytics. To facilitate cost-effective online retraining, we design a hierarchical reinforcement learning approach in which the upper-level module intelligently determines the timing for online retraining, balancing machine-perceived quality of experience (QoE) improvement and transmission cost. Meanwhile, the lower-level module dynamically allocates bitrate to maximize machine-perceived QoE. Extensive experiments based on real-world drone video and aerial network datasets demonstrate that our proposed framework achieves a 17.7% mean accuracy increase, a 37.5% decrease in the mean failure rate of video uploading, and a 5.2% mean latency decrease compared to state-of-the-art solutions.}
}


@inproceedings{DBLP:conf/iwqos/ChenGSYLH24,
	author = {Yulong Chen and
                  Junchen Guo and
                  Yimiao Sun and
                  Haipeng Yao and
                  Yunhao Liu and
                  Yuan He},
	title = {ElaSe: Enabling Real-time Elastic Sensing Resource Scheduling in 5G
                  vRAN},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682934},
	doi = {10.1109/IWQOS61813.2024.10682934},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/ChenGSYLH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Integrated Sensing and Communication (ISAC) has been witnessed to be a new paradigm of wireless sensing in 5G networks. Users can benefit from pervasive sensing applications in various scenarios with no communication penalty. Given the diverse demands for sensing resources across different sensing tasks, elastic resource scheduling becomes crucial, particularly when resources are constrained. However, existing approaches often treat users equally, limiting their applicability in dealing with diverse sensing tasks in the real world. In this paper, we introduce ElaSe, a pioneering sensing technique that enables real-time elastic scheduling of sensing resources. At the core of ElaSa is the exploration of the user's state to precisely determine the sensing resource requirements and schedule resources accordingly. We build the first model for matching sensing resources with sensing demands, and further propose a predictive scheduling scheme to eliminate delays by leveraging the 5G virtualized radio access network (vRAN). We conduct experiments to evaluate the performance of ElaSe under different settings. The results demonstrate that ElaSe outperforms the non-scheduling scheme, with a 34% reduction in trajectory tracking error and a 92% decrease in resource allocation error.}
}


@inproceedings{DBLP:conf/iwqos/ChenHWXHCGYWZS24,
	author = {Qiaoling Chen and
                  Qinghao Hu and
                  Guoteng Wang and
                  Yingtong Xiong and
                  Ting Huang and
                  Xun Chen and
                  Yang Gao and
                  Hang Yan and
                  Yonggang Wen and
                  Tianwei Zhang and
                  Peng Sun},
	title = {Lins: Reducing Communication Overhead of ZeRO for Efficient {LLM}
                  Training},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682856},
	doi = {10.1109/IWQOS61813.2024.10682856},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/ChenHWXHCGYWZS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Training large language models (LLMs) encounters challenges in GPU memory consumption due to the high memory requirements of model states. The widely used Zero Redundancy Optimizer (ZeRO) addresses this issue through strategic sharding but introduces communication challenges at scale. To tackle this problem, we propose Lins, a system designed to optimize ZeRO for scalable LLM training. Lins incorporates three flexible sharding strategies: Full-Replica, Full-Sharding, and Partial-Sharding, and allows each component within the model states (Parameters, Gradients, Optimizer States) to independently choose a sharding strategy as well as the device mesh. We conduct a thorough analysis of communication costs, formulating an optimization problem to discover the optimal sharding strategy. Evaluations demonstrate up to 52% Model FLOPs Utilization (MFU) when training the LLaMA-based model on 1024 GPUs, resulting in a 1.56 times improvement in training throughput compared to newly proposed systems like MiCS and ZeRO++.}
}


@inproceedings{DBLP:conf/iwqos/PanHZLZC24,
	author = {Junchen Pan and
                  Kunpeng He and
                  Lei Zhang and
                  Zhuotao Liu and
                  Xinggong Zhang and
                  Yong Cui},
	title = {NetSentry: Scalable Volumetric DDoS Detection with Programmable Switches},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682912},
	doi = {10.1109/IWQOS61813.2024.10682912},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/PanHZLZC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Distributed Denial of Service (DDoS) attack is a critical and persistent threat to the Internet. Recent DDoS detection schemes based on emerging programmable switches can achieve higher processing throughput and improve detection accuracy. However, with limited data plane memory, such schemes are not suitable for handling a large number of concurrent flows. Prior arts that attempt to increase memory efficiency have failed to do so without the expense of cost and accuracy. In this paper, we propose NetSentry, the first programmable switch based dynamic pooled testing DDoS detector. NetSentry detects DDoS in a pooled testing manner, where multiple flows are grouped to share the same storage unit on the data plane. NetSentry designs an elastic flow aggregation mechanism to dynamically adjust the detection granularity. Further, to achieve accurate DDoS detection for aggregated flows, NetSentry implements frequency domain DDoS detection on programmable switches. Evaluations of NetSentry’s hardware prototype show that NetSentry can achieve better accuracy while saving up to 91% of the data plane memory required to store flow features compared to the state-of-the-art programmable switch-based flow classification scheme.}
}


@inproceedings{DBLP:conf/iwqos/QianSYZBS24,
	author = {Lang Qian and
                  Peng Sun and
                  Kun Yang and
                  Jingyu Zhang and
                  Azzedine Boukerche and
                  Liang Song},
	title = {Guidelines for Parameter Selection in Traffic Light Control Methods
                  Using Reinforcement Learning: Insights from Empirical Studies},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682954},
	doi = {10.1109/IWQOS61813.2024.10682954},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/QianSYZBS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The ever-changing traffic dynamics make the traditional traffic signal control methods unable to adapt to the environment. Meanwhile, deep reinforcement learning (DRL) has the property of interacting with the environment and adapting to changes in the environment. Therefore, in recent years, researchers have usually solved traffic signal control (TSC) problems through DRL methods. They have not only improved the design of neural networks, but also improved the ability of models to understand traffic conditions and learn corresponding task requests by designing different states and rewards. However, although the existing TSC algorithms based on DRL have proposed many well-designed states and reward strategies, which combinations of states and rewards should be adopted in practice to achieve the performance margin of models remains a question that researchers are seeking the answer to. Therefore, we introduce a general simulation platform to test and compare experimental performance under different combinations of states and rewards. Specifically, we test and analyze the experimental effects under different combinations of multiple traffic states and rewards through various TSC methods with a set of unified model settings. We further design and test some new state representations and reward strategies based on more detailed traffic information. The test results show that when researchers design the state and reward, refining the traffic state like vehicle running condition and making the state and reward match can make the experimental performance better than other combinations in most cases. We hope these results have some implications for the state and reward choice when researchers conduct experiments on TSC problem or other traffic decision management problems.}
}


@inproceedings{DBLP:conf/iwqos/LvLLX24,
	author = {Wenhao Lv and
                  Shouxi Luo and
                  Ke Li and
                  Huanlai Xing},
	title = {Towards Optimal Topology-Aware AllReduce Synthesis},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--2},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682896},
	doi = {10.1109/IWQOS61813.2024.10682896},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/LvLLX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this work, we propose TARS, a Topology-aware AllReduce algorithm Synthesizer, to generate optimal execution plans for AllReduce workloads over arbitrary interconnection network structures. Distinguished from existing topology-aware synthesizers that formulate the two stages of AllReduce (e.g., ReduceScatter-then-AllGather, or Reduce-then-Broadcast) separately, the power of TARS stems from employing a comprehensive Integer Quadratic Programming (IQP) model to formulate the entire workflow precisely. Preliminary studies confirm that, compared with the state-of-the-art scheme, TARS could significantly reduce the completion time of AllReduce.}
}


@inproceedings{DBLP:conf/iwqos/LiOCC24,
	author = {Yousheng Li and
                  Tao Ouyang and
                  Xu Chen and
                  Xinyuan Cao},
	title = {FedCarbon: Carbon-Efficient Federated Learning with Double Flexible
                  Controls for Green Edge {AI}},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682880},
	doi = {10.1109/IWQOS61813.2024.10682880},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/LiOCC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The deep integration of federated learning (FL) and edge computing holds great promise in delivering ubiquitous edge AI services. However, in light of the upcoming carbon peaking and neutrality era, existing research has largely overlooked the sustainability challenges of FL in future edge computing. Therefore, we first propose a novel carbon-efficient FL framework in this paper, which leverages client sampling and model pruning approaches to adjust carbon-aware local model training during the long-term FL procedure, adapt to heterogeneous and dynamic edge environments, such as time-varying renewable energy and edge workloads. We then conduct a theoretical analysis of its convergence bound, based on which we introduce an online control algorithm to efficiently balance the trade-off between training performance and carbon emission, i.e., maximizing carbon efficiency while ensuring satisfactory FL performance. The effectiveness of proposed algorithm is verified by extensive trace-driven simulations, reducing up-to 72% carbon emissions than other methods.}
}


@inproceedings{DBLP:conf/iwqos/YangWLHF24,
	author = {Luming Yang and
                  Yongjun Wang and
                  Lin Liu and
                  Junjie Huang and
                  Shaojing Fu},
	title = {ExpMD: an Explainable Framework for Traffic Identification Based on
                  Multi-Domain Features},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682894},
	doi = {10.1109/IWQOS61813.2024.10682894},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/YangWLHF24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Network traffic identification has a significant impact on the QoS (Quality of Service) of network. However, there are challenges in performing network traffic identification, including underutilization of information and weak of interpretability. To address these issues, in this paper, we propose an Explainable framework based on Multi-Domain features for network traffic identification, named ExpMD. The network information is divided into four feature domains: metadata domain, byte-distribution (BD) domain, textual domain, and temporal domain. On these feature domains, we construct four identification models independently, thereby achieving the extraction and utilization of multi-domain information of network flows. Subsequently, efficient identification of network traffic can be achieved through the ensemble of models from four domains. In addition, we employ post-hoc explainable approaches to attribute features across multiple feature domains, thus mitigating the black-box issue of network traffic identification. We run a set of experiments in the identification tasks of application network traffic. The extensive evaluation demonstrates that our framework not only achieves an accuracy of 97. 5%, but also generates high-fidelity, sparse, complete, and stable explanation results for network flows. Furthermore, each sub-model performed at a state-of-the-art effect within their feature domains, respectively.}
}


@inproceedings{DBLP:conf/iwqos/ZhangFXCXLM24,
	author = {Yucheng Zhang and
                  Yu Fan and
                  Yao Xiao and
                  Haoyang Chen and
                  Pengjin Xie and
                  Liang Liu and
                  Huadong Ma},
	title = {{BBQ:} Dynamic-Buffer-Driven Automatic {ECN} Tunning in Datacenter},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--6},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682919},
	doi = {10.1109/IWQOS61813.2024.10682919},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/ZhangFXCXLM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The current deployment of extremely shallow-shared-buffer switches in data center networks has posed challenges to widely adopted ECN-based congestion control algorithms, leading to the issue of ECN failure. Switches may not allocate sufficient buffer space for each port, leading to the possibility that the ECN marking threshold exceeds the buffer limit per port. This results in excessive packet loss during bursts, even before the ECN markings take effect. To address this problem, we propose BBQ, an automatic ECN tuning system based on reinforcement learning. BBQ ensures that the ECN threshold does not exceed the buffer capacity allocated to the port, thus avoiding the ECN failure issue. Besides, BBQ is designed to adapt to switches with varying buffer sizes ensuring generalization. We validate the effectiveness of BBQ through experiments conducted with shallow buffering and high bursts. The results show that BBQ efficiently controls the packet loss rate of incast flows to within 3%, 1.2 times lower than State-of-the-Arts in shallow-buffered environments.}
}


@inproceedings{DBLP:conf/iwqos/LiLZYJ24,
	author = {Tianyu Li and
                  Qing Li and
                  Mei Zhang and
                  Zhenhui Yuan and
                  Yong Jiang},
	title = {Adaptive Streaming Continuous Learning System for Video Analytics},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682886},
	doi = {10.1109/IWQOS61813.2024.10682886},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/LiLZYJ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Video analytics systems use deep learning models to perform inference on videos and are widely applied in fields such as smart cities and robotics. However, in order to improve inference speed, models with fewer parameters are often chosen to deploy on edge devices, thereby sacrificing the detection accuracy of the task. Continuous learning is an emerging approach to improve the accuracy of lightweight models deployed on the edge for video inference. However, most solutions constantly upload data from edge to the cloud without considering the limited resources and latency of system modules, resulting in the unreliability of the system and loss of model accuracy. This paper investigates the impact of retraining frequency and video encoding configurations on continuous learning. We then design an adaptive streaming continuous learning algorithm (ASCL) with the aim of achieving the desired level of accuracy while minimizing bandwidth resources as much as possible. First, ASCL can adaptively start up according to the needs of users. Second, during the retraining, an adaptive profiling method is designed to select the appropriate encoding configurations to ensure high profiling accuracy. Third, we perform a layer-wise downloading streaming algorithm to ensure secure and smooth transmission. Real-world network traces are driven to the overall evaluation of ASCL. The results of a multitude of videos show the advantages of ASCL over traditional baselines.}
}


@inproceedings{DBLP:conf/iwqos/WangFLYX24,
	author = {Ao Wang and
                  Xuewei Feng and
                  Qi Li and
                  Yuxiang Yang and
                  Ke Xu},
	title = {A Horizontal Study on the Mixed {IPID} Assignment Vulnerability in
                  the Linux Ecosystem},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682845},
	doi = {10.1109/IWQOS61813.2024.10682845},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/WangFLYX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The off-path TCP hijacking attack poses a significant threat to Internet security, allowing attackers to manipulate various upper-layer applications and causing severe real-world damage. In this paper, we undertake a horizontal study on a critical TCP hijacking attack affecting Linux servers, which was reported in November 2020 (CVE-2020-36516). This attack has the potential to compromise over 20% of popular websites on the Internet. Our study particularly focuses on determining the extent to which the developed stack patches, designed to address this vulnerability, have been effectively deployed in the real world and whether they have successfully mitigated the identified attack. In our horizontal study, we thoroughly examine the current status of the vulnerability, covering upstream and downstream components of the Linux ecosystem. This study encompasses 12 mainstream Linux distributions, 296 images from 7 leading cloud vendors, 2.92 million IPs from 301 network segments belonging to 6 major CDN vendors, as well as the top 1 million websites from 3 datasets. Our study unveils a notable disparity in the patching of the vulnerability in the Linux ecosystem, spanning various ISPs and vendors, which leaves the vulnerability open to potential exploitation and poses a serious threat to the Internet.}
}


@inproceedings{DBLP:conf/iwqos/FangLCXH24,
	author = {Xinyue Fang and
                  Jianwei Liu and
                  Yike Chen and
                  Xian Xu and
                  Jinsong Han},
	title = {WristPass: Secure Wearable Continuous Authentication via Ultrasonic
                  Sensing},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682871},
	doi = {10.1109/IWQOS61813.2024.10682871},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/FangLCXH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Smartwatches have become increasingly prevalent in people’s daily lives, offering support for a wide range of privacy and security-sensitive applications, such as SMS messaging and mobile payment. Consequently, there is an imperative need for independent user authentication on smartwatches to safeguard against property loss and personal privacy breaches. However, current authentication methods rely on passwords, leaving users vulnerable to shoulder surfing attacks. Moreover, existing biometric-based authentication methods either require dedicated sensors or cannot support continuous authentication. In this paper, we propose a replay-resistant continuous authentication system on smartwatches, namely WristPass. It extracts acoustic impedance biometrics from ultrasonic signals. Leveraging a theoretical model based on the principle of ultrasound propagation, WristPass correlates spectrograms of reflected signals with impedance features of wrist skin. Utilizing a deep learning model as a feature extractor, WristPass mines fine-grained impedance features from the spectrograms for accurate user authentication. Additionally, to prevent WristPass from replay attacks, we design a device fingerprinting method to detect replayed signals. Extensive experiments show that WristPass can achieve 96.7% accuracy in user authentication. Furthermore, WristPass exhibits robustness for long-term usage.}
}


@inproceedings{DBLP:conf/iwqos/LiXWRZL24,
	author = {Jiaxing Li and
                  Chi Xu and
                  Feng Wang and
                  Isaac M. von Riedemann and
                  Cong Zhang and
                  Jiangchuan Liu},
	title = {{SCALM:} Towards Semantic Caching for Automated Chat Services with
                  Large Language Models},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682957},
	doi = {10.1109/IWQOS61813.2024.10682957},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/LiXWRZL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Large Language Models (LLMs) have become increasingly popular, transforming a wide range of applications across various domains. However, the real-world effectiveness of their query cache systems has not been thoroughly investigated. In this work, we for the first time conducted an analysis on real-world human-to-LLM interaction data, identifying key challenges in existing caching solutions for LLM-based chat services. Our findings reveal that current caching methods fail to leverage semantic connections, leading to inefficient cache performance and extra token costs. To address these issues, we propose SCALM, a new cache architecture that emphasizes semantic analysis and identifies significant cache entries and patterns. We also detail the implementations of the corresponding cache storage and eviction strategies. Our evaluations show that SCALM increases cache hit ratios and reduces operational costs for LLMChat services. Compared with other state-of-the-art solutions in GPTCache, SCALM shows, on average, a relative increase of 63% in cache hit ratio and a relative improvement of 77% in tokens savings.}
}


@inproceedings{DBLP:conf/iwqos/QiuZYWQH24,
	author = {Lin Qiu and
                  Kaimin Zhang and
                  Bo Yi and
                  Xingwei Wang and
                  Yanpeng Qu and
                  Min Huang},
	title = {Efficient and Reliable Partitioning for Permissioned Blockchain: Two
                  Multi-group Collaborative Storage Mechanisms},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682950},
	doi = {10.1109/IWQOS61813.2024.10682950},
	timestamp = {Mon, 14 Oct 2024 08:21:04 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/QiuZYWQH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Blockchain, a promising distributed ledger for decentralization, plays a crucial role in JointCloud computing, offering secure data storage and sharing as well as reliable transaction tracking and resource allocation. While promising, it faces storage limitations due to its full-replication strategy. This issue has been addressed by scholars through storage partitioning mechanisms like BFT-Store and PartitionChain. These mechanisms leverage Erasure Coding with the Byzantine Fault Tolerant consensus protocol to overcome storage constraints. However, challenges persist: i) high computational complexity in encoding and decoding leading to prolonged computation time; ii) extensive use of verified signatures causing increased network message transmission and communication burden; iii) during system re-initialization, under-performing scalability and substantial time consumption due to the involving of all nodes in data decoding and re-encoding. To overcome these challenges, we propose two novel storage partitioning mechanisms (i.e., GPartition-Store and ParallelC-Store) for the permissioned blockchain that reduce the computational complexity of the coding processes by dividing nodes into multiple groups called storage units (SUs), avoid additional communication of generating verification proofs by employing the Bloom Filter, and improve the stability and scalability of the system by implementing the re-initialization process exclusively within a specific SU. Particularly, the computational complexity of encoding/decoding can be further degreased by about g 2 /g 3 and g/g 2 compared to PartitionChain, by GPartition-Store and ParallelC-Store respectively (g is the number of SUs). Compared with the full-replication strategy, BFT-Store and PartitionChain, the experimental results demonstrate that the proposed mechanisms improve the Quality of Service (QoS) of the blockchain system including performance (i.e., efficiency and throughput), scalability and stability, while guaranteeing the availability.}
}


@inproceedings{DBLP:conf/iwqos/DengLSFWL24,
	author = {Yuxuan Deng and
                  Xiuhua Li and
                  Chuan Sun and
                  Qilin Fan and
                  Xiaofei Wang and
                  Victor C. M. Leung},
	title = {Semi-Asynchronous Federated Learning with Trajectory Prediction for
                  Vehicular Edge Computing},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682953},
	doi = {10.1109/IWQOS61813.2024.10682953},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/DengLSFWL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated learning, as a distributed machine learning paradigm, offers promising solutions for vehicular edge computing (VEC) networks. However, federated learning in VEC with classification tasks still faces two key challenges: i) Delayed data labeling hampers supervised training; ii) Dynamic vehicle behavior complicates training scheduling and model uploads to edge servers. In this paper, we propose a semi-asynchronous federated learning algorithm for VEC. Specifically, it utilizes knowledge distillation to generate soft labels from raw data for supervised training, and estimates model training and uploading time through trajectory prediction. We further logically group vehicles based on the characteristics of their dynamic behavior. We then employ synchronous aggregation within groups and asynchronous aggregation between groups to optimize model performance while reducing latency. Finally, we conduct separate comparative experiments for all components, demonstrating that each component possesses unique advantages. Experiment results show that the proposed algorithm outperforms existing schemes in terms of accuracy and latency. The code is available at: https://github.com/dyxcode/Semi-Asynchronous-Federated-Learning.}
}


@inproceedings{DBLP:conf/iwqos/LuLBVSH24,
	author = {Shutao Lu and
                  Wuyungerile Li and
                  Yintu Bao and
                  Alvin C. Valera and
                  Winston K. G. Seah and
                  Baoqi Huang},
	title = {Routing over Best Links is not necessarily Better in Wireless Multi-hop
                  Networks},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--6},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682958},
	doi = {10.1109/IWQOS61813.2024.10682958},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/LuLBVSH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The conventional approach of choosing the best route to carry network traffic in wireless multi-hop networks does not maximize the overall network throughput and can lead to short-term instabilities in network state with dire consequences. To date, wireless network route selection considers mainly network or link metrics, always picking the best links, thus channeling all packets through a subset of all available links. This leaves weaker links under-utilized although such links can in fact be used to carry smaller packets or packets with less stringent requirements and free up bandwidth on the better links for larger packets or traffic with higher service requirements. As network traffic volume and heterogeneity increase in future networks, we need to maximize the usage of available network bandwidth and distribute the network traffic load. We combine network link metrics and packet attributes to determine the successful packet transmission probability, and then use this outcome to pick suitable links to forward the packet, which is not necessarily the link with the best metric. To validate the efficacy of our proposed approach in routing performance and energy efficiency, we applied it in routing for wireless multi-hop networks. More importantly, we are able to spread the traffic across nodes in the network, thus achieving better network load-balancing and higher network resource utilization.}
}


@inproceedings{DBLP:conf/iwqos/YanZXLX24,
	author = {Bodong Yan and
                  Yangming Zhao and
                  Sun Xu and
                  Jianchun Liu and
                  Hongli Xu},
	title = {{LHCC:} Low-Latency and Hi-Precision Congestion Control in {RDMA}
                  Datacenter Networks},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682889},
	doi = {10.1109/IWQOS61813.2024.10682889},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/YanZXLX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Congestion Control (CC) plays a vital role in deploying lossless datacenter networks based on Remote Direct Memory Access (RDMA). A high-performance CC scheme should provide low-latency and precise feedback to congestion events. However, no existing CC schemes achieved both features simultaneously. In this paper, we propose LHCC, a Low-latency and Hi-precision Congestion Control scheme for RDMA datacenter networks. LHCC uses out-band signaling to notify the network status and hence a packet sender can detect congestion events within an RTT. In addition, LHCC adjusts packet sending rate by taking into consideration all queues along the entire path that a packet has gone through. Accordingly, it provides a more precise CC compared with existing schemes especially when there are multiple bottlenecks in the networks. We build the LHCC prototype on a real testbed carrying NVIDIA BlueField-3 NICs and AGM39D FPGAs. Both testbed experiments and extensive simulations show that LHCC can reduce the Flow Completion Time (FCT) slow down and reduce the buffer usage (i.e., reduce the queue lengths) by up to 62.5% and 58%, respectively, compared with the state-of-the-art high-precision CC scheme, HPCC.}
}


@inproceedings{DBLP:conf/iwqos/WuLCQMZWW24,
	author = {Meihan Wu and
                  Li Li and
                  Tao Chang and
                  Peng Qiao and
                  Cui Miao and
                  Jie Zhou and
                  Jingnan Wang and
                  Xiaodong Wang},
	title = {FedEKT: Ensemble Knowledge Transfer for Model-Heterogeneous Federated
                  Learning},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682872},
	doi = {10.1109/IWQOS61813.2024.10682872},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/WuLCQMZWW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated Learning (FL) enables multiple clients to collaboratively train a shared server model while preserving data privacy. Most existing FL systems rely on the assumption that the server model and client models have homogeneous architecture. However, intensive resource requirements during the training process prevent low-end devices from contributing to the server model with their own data. On the other hand, the resource constraints on participating clients can significantly limit the size of the server model in the model-homogeneous setting, thereby restricting the application scope of FL. In this work, we propose FedEKT, a novel model-heterogeneous FL system designed to obtain a high-performance large server model while benefiting heterogeneous small client models. Specifically, a new aggregation approach is designed to enable the integration of knowledge from heterogeneous client models to a large server model while mitigating the adverse effects of biases stemming from data heterogeneity. Subsequently, to enhance the performance of client models by benefiting from the high-performance server model, FedEKT distills this large server model into multiple heterogeneous client models, facilitating the transfer of integrated knowledge back to the client models. In addition, we design specialized modules within the model and communication strategy to accomplish aggregation and transfer of knowledge in a data-free manner. The evaluation results demonstrate that FedEKT enhances the accuracy of the server model and client models by up to 53.96% and 12.35%, respectively, compared with the state-of-the-art FL approach on CIFAR-100.}
}


@inproceedings{DBLP:conf/iwqos/WangXLPC24,
	author = {Baiqing Wang and
                  Tao Xing and
                  Xiaoning Liu and
                  Zhe Peng and
                  Helei Cui},
	title = {Lightweight Multimodal Defect Detection at the Edge via Cross-Modal
                  Distillation},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--2},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682904},
	doi = {10.1109/IWQOS61813.2024.10682904},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/WangXLPC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The learning capabilities of single-modality images are often severely limited and fail to meet the requirements of complexity defect detection in industrial settings. For instance, traditional visible light images are susceptible to environmental factors such as lighting and occlusions, while infrared images cannot capture texture details due to their low spatial resolution. Consequently, employing multiple image modalities typically yields better results than relying on a single modality. However, utilizing data from multiple modalities inevitably introduces additional computational costs, posing high hardware demands on edge computing devices, and the need for real-time detection in industrial environments is critical. To address these challenges, we propose a multimodal distillation approach that uses visible and infrared images as inputs to train a complex teacher model, while the student model continues to operate with a single-modal image input. Through knowledge transfer, the student model is enhanced, and model light-weighting is implemented to ensure that it can acquire multi-modal feature information while still meeting real-time performance requirements.}
}


@inproceedings{DBLP:conf/iwqos/LiHYL24,
	author = {Ruiqi Li and
                  Jiahui Hou and
                  Haikuo Yu and
                  Xiangyang Li},
	title = {PPL-enc: {A} Personalized Pixel-Level Scheme for Video Privacy Protection},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682941},
	doi = {10.1109/IWQOS61813.2024.10682941},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/LiHYL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the rapid development of internet and computer technologies, video has become increasingly prevalent in information dissemination and daily communication. However, video data often contains a substantial amount of sensitive and private information, leading to security risks during its usage, such as privacy breaches, copyright infringements, and data theft. Current efforts in video encryption primarily focus on block-level or whole-frame-level encryption within video frames, which fails to achieve fine-grained privacy protection and lacks personalized access control. Moreover, many approaches also suffer from inadequate real-time performance and excessive storage overhead.To address these issues, we proposes a personalized pixel-level scheme for video privacy protection: PPL-enc. PPL-enc employs an instance segmentation model to delineate regions containing privacy information at the pixel level within video frames. Subsequently, we apply a highly real-time quadruple encryption algorithm to the pixel values within sensitive regions, which is performed before encoding and is robust to lossy compression. Different encryption keys utilize Attribute-Based Encryption (ABE) for personalized access control, allowing terminal users with different identities to access different content upon video decryption. We conduct extensive evaluations on the quality and efficiency of encryption and decryption, as well as security analysis, to demonstrate the efficiency of our proposed scheme. Experimental results show that the single-frame encryption overhead of PPL-enc is consistently less than 0.1s across videos of various resolutions, with the encrypted area having an average PSNR of 8.50 dB and an average SSIM of 0.079.}
}


@inproceedings{DBLP:conf/iwqos/LiYHLWDXX24,
	author = {Ziwei Li and
                  Zhaoqi Yang and
                  Bowen Hu and
                  Tong Li and
                  Bo Wu and
                  Yukuan Ding and
                  Dulin Xu and
                  Ke Xu},
	title = {ReND: Toward Reasoning-based {BLE} Neighbor Discovery by Integrating
                  with Wi-Fi Fingerprints},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--6},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682612},
	doi = {10.1109/IWQOS61813.2024.10682612},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/LiYHLWDXX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper proposes the novel concept of reasoning-based Bluetooth Low-Energy (BLE) neighbor discovery, an indirect paradigm of device-to-device sensing to address challenges (e.g., interference and power limitations) where direct sensing falls short. Inspired by the classical Rule of Syllogism, reasoning-based BLE neighbor discovery abstracts the device-to-device sensing as the presence detection of a BLE signal in a certain space. It deduces the presence of the BLE signal according to the presence of the Wi-Fi signal through the historical correlation between BLE and Wi-Fi. To demonstrate the feasibility of this new neighbor discovery paradigm, we report the design and evaluation of a prototype called ReND. By leveraging the complementary strengths of Wi-Fi and BLE, ReND reduces up to 91.3% and 65.9% of the 50 th and 95 th percentile BLE neighbor discovery latency, respectively. We further discuss the feasibility and incentive of ReND in the Polygon’s Mumbai Testnet public blockchain.}
}


@inproceedings{DBLP:conf/iwqos/WangLSHQLXKLSL24,
	author = {Yuxin Wang and
                  Haoyu Liu and
                  Haohao Song and
                  Siyong Huang and
                  Shaoxiang Qin and
                  Yutong Liu and
                  Qiao Xiang and
                  Linghe Kong and
                  Geng Li and
                  Jiwu Shu and
                  Xue Liu},
	title = {Peering the Edge: Enabling Low-Latency Interdomain Edge Communication
                  via Collaborative Transmission},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--6},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682890},
	doi = {10.1109/IWQOS61813.2024.10682890},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/WangLSHQLXKLSL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Enabling low-latency end-to-end interdomain communication is critical in edge networks. However, the current network architecture results in unnecessarily long communication paths, leading to high latency between devices. To address this issue, we propose a novel interdomain edge peering framework called Collie. In Collie, edge networks belonging to different network providers collaborate to forward traffic towards destinations, effectively reducing end-to-end communication latency. Importantly, Collie allows network providers to maintain their autonomy in link usage strategy. We also develop a distributed algorithm in Collie that enables edge nodes from different networks to collectively determine optimal routing and traffic assignment, ensuring low-latency delivery while respecting network policies without exposing them. We implement a prototype of Collie and extensively evaluate its performance using real-world topologies. Our results demonstrate that Collie achieves a tight approximation ratio and exhibits scalability in large interdomain edge networks.}
}


@inproceedings{DBLP:conf/iwqos/ZhuYHLHZZCW24,
	author = {Longlong Zhu and
                  Jiashuo Yu and
                  Long Huang and
                  Hang Lin and
                  Kaiwei Huang and
                  Zhengyan Zhou and
                  Dong Zhang and
                  Xiang Chen and
                  Chunming Wu},
	title = {TupleRadar: Accelerating Tuple Space Search in Packet Classification
                  by Learned Index},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682869},
	doi = {10.1109/IWQOS61813.2024.10682869},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/ZhuYHLHZZCW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Tuple space search(TSS)-based packet classification is the keystone of network system. Previous studies accelerate TSS by partitioning tuples, combining trees and tuples, and merging tuples. However, they do not scale with the number of rules, resulting in a high memory footprint or update time. In this paper, we propose TupleRadar, a framework for accelerating TSS while ensuring low memory footprint and fast rule updates. Our key idea is to construct learned indexes for tuples, which inherently improve the lookup speed but ensure the advantages of TSS. Specifically, TupleRadar builds orderly hash table-based tuples and then constructs the updatable learned index. It provides a bounded memory footprint of the index structure as well. We have evaluated TupleRadar on multiple scales rule-sets. Experimental results show that TupleRadar outperforms previous solutions, reducing 46.66% lookup time and 61.53% memory footprint on average, by up to 86.70% and 88.95%. It also performs a competitive rule update speed.}
}


@inproceedings{DBLP:conf/iwqos/HuangCHZZYW24,
	author = {Yukai Huang and
                  Lulu Chen and
                  Chunpu Huang and
                  Rui Zhang and
                  Yiren Zhou and
                  Ming Yan and
                  Jie Wu},
	title = {Mitigating Intra-host Network Congestion with SmartNIC},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682939},
	doi = {10.1109/IWQOS61813.2024.10682939},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/HuangCHZZYW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the rapid development and wide deployment of high-speed network technologies like RDMA and the relatively stagnant evolution of intra-host resources, intra-host network congestion has become a potential issue that may affect the QoS of network applications. Offloading hotspot data to modern Smart-NICs, enabling hotspot data access completion on the SmartNIC, and reducing intra-host network traffic, is a promising solution to this issue. However, due to the limited SmartNIC resources and the complexity of network application requirements, achieving efficient offload is challenging.We present Magician, an architecture to mitigate intra-host network congestion with SmartNIC. Magician adopts a client-driven data access approach to avoid performance degradation caused by limited SmartNIC resources. Magician also introduces a SmartNIC-oriented hotspot data update strategy that dynamically refreshes hotspot data with minimal overhead. Moreover, we design a server-centric data consistency mechanism to ensure data consistency under concurrent access. We implement Magician within the key-value store. Evaluation of the key-value store with and without Magician suggests that, in the presence of intra-host network congestion, Magician significantly mitigates intra-host network congestion, leading to improved performance of network applications.}
}


@inproceedings{DBLP:conf/iwqos/JiangHLWHW24,
	author = {Wanchun Jiang and
                  Yujie Hu and
                  Haoyang Li and
                  Kai Wang and
                  Jiawei Huang and
                  Jianxin Wang},
	title = {Analysis and Improvement of PowerTCP},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682942},
	doi = {10.1109/IWQOS61813.2024.10682942},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/JiangHLWHW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Nowadays, Congestion Control (CC) algorithms based on In-Network Telemetry (INT) are popular in datacenter networks, because INT is supported by many commercial devices and provides comprehensive information about network congestion. In this work, we analyze the recent INT-based CC algorithm PowerTCP and reveal its fairness and large delay issues under the conditions of a large number of flows. Inspired by the analytical results, we propose Trident, which enhances PowerTCP by accelerating the speed of converging to fairness and maintaining a low queuing delay with a small equilibrium point. Simulations based on the open source codes confirm that Trident outperforms existing INT-based CC algorithms HPCC, PowerTCP and Poseidon by 14.3%, 14.8%, and 63.5% in terms of FCT of short flows. Moreover, Trident outperforms existing CC algorithms such as Timely, DCQCN and DCTCP, benefiting from the advantages inherited from PowerTCP.}
}


@inproceedings{DBLP:conf/iwqos/GaoZQWYH24,
	author = {Fei Gao and
                  Yunfeng Zhao and
                  Chao Qiu and
                  Xiaofei Wang and
                  Haipeng Yao and
                  Qinghua Hu},
	title = {CP\({}^{\mbox{2}}\)GFed: Cross-granular and Personalized Prompt-based
                  Green Federated Tuning for Giant Models},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682866},
	doi = {10.1109/IWQOS61813.2024.10682866},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/GaoZQWYH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Giant models have transformed vision-language tasks by mastering consistent representations across text and images, highlighting the critical role of deploying such models in the expanding domain of edge scenarios, such as monitoring and segmentation. However, the deployment is challenged by device heterogeneity, limited computational resources, and privacy concerns. Federated learning (FL) presents itself as a viable solution, facilitating decentralized training on devices and preserving data confidentiality. Despite its potential, FL faces obstacles with fine-tuning efficiency, including complex granularity data, static personalized prompt generation, and high energy consumption. This paper introduces a cross-granular and personalized prompt-based green federated tuning (CP 2 GFed) approach, aiming to address these issues by enabling giant model deployment on devices. CP 2 GFed introduces a cross-granularity knowledge transfer mechanism to leverage semantic relationships across varying data granularities. Meanwhile, it pioneers in generating dynamic personalized prompts based on inter-device affinities to improve model performance. In addition, CP 2 GFed meticulously optimizes energy consumption, including model local learning and interaction, by setting local computing steps and selecting communication devices. Empirical results indicate that CP 2 GFed elevates accuracy by up to 6.64% on diverse datasets and reduces energy consumption by nearly 60% per unit of accuracy, achieving a superior tradeoff between model performance and energy consumption compared to baselines.}
}


@inproceedings{DBLP:conf/iwqos/DaiWYL24,
	author = {Xiangxiang Dai and
                  Zhiyong Wang and
                  Jiancheng Ye and
                  John C. S. Lui},
	title = {Quantifying the Merits of Network-Assist Online Learning in Optimizing
                  Network Protocols},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682895},
	doi = {10.1109/IWQOS61813.2024.10682895},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/DaiWYL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Optimizing network protocols is crucial for improving application performance. Recent research works use multi-armed bandit (MAB) online learning methods to address network optimization problems, aiming to improve cumulative payoffs such as network throughput. However, existing MAB frameworks are ineffective since they inherently assume the network environment is static, or they have high complexity in detecting environmental changes. In this work, we advocate using lightweight "network-assist" techniques together with online learning to optimize network protocols, and show it can effectively detect environmental changes and maximize network performance. Furthermore, optimizing network protocols often face two types of decision (or arm) spaces: discrete and continuous choices, while most prior MAB models only handle discrete settings. This paper proposes a framework capable of managing both spaces. To our best knowledge, we are the first to develop an MAB framework that incorporates network-assist signals in handling dynamic environments, while considering the distinct characteristics of discrete and continuous arm spaces. Our framework can achieve optimality by showing its sub-linear regret bound, matching the state-of-the-art results in several degenerate cases. We also illustrate how to apply our framework to two network applications: (1) wireless network channel selection, and (2) rate-based TCP congestion control. We demonstrate the merits of our algorithms via both numerical simulations and packet-level experiments.}
}


@inproceedings{DBLP:conf/iwqos/WuLHLCZW24,
	author = {Jiang Wu and
                  Xuezheng Liu and
                  Miao Hu and
                  Hongxu Lin and
                  Min Chen and
                  Yipeng Zhou and
                  Di Wu},
	title = {GazeFed: Privacy-Aware Personalized Gaze Prediction for Virtual Reality},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--6},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682864},
	doi = {10.1109/IWQOS61813.2024.10682864},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/WuLHLCZW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Gaze prediction is essential for enhancing user experiences of virtual reality (VR) applications. However, existing methods seldom considered the privacy nature of gaze data, which may reveal both psychological and physiological characteristics of VR users. Moreover, the commonly adopted one-sizefits-all prediction model cannot well capture behavioral patterns of different VR users. In this paper, we propose a privacyaware personalized gaze prediction framework called GazeFed, which can train a personalized gaze prediction model for each user in a collaborative manner. In GazeFed, only intermediate computations are exchanged between users and the server. The raw gaze data samples are locally preserved to protect user privacy. The global model is shared among all users, which can be further trained with local gaze data to generate a personalized prediction model for each individual user. We also propose a deep neural network tailored for VR gaze prediction called GazeNet, which can effectively extract features from VR contents, gaze data and other user behaviors, and improve the accuracy of gaze prediction. Moreover, the technique of differential privacy (DP) is also integrated to provide more privacy protection, and we theoretically prove that GazeFed can well converge and satisfy the requirement of differential privacy in the meanwhile. Last, we conduct extensive experiments to evaluate the effectiveness of our proposed GazeFed on real datasets and various VR scenarios. The experimental results demonstrate that GazeFed outperforms the state-of-the-art approaches.}
}


@inproceedings{DBLP:conf/iwqos/WuLTTLCX24,
	author = {Yebo Wu and
                  Li Li and
                  Chunlin Tian and
                  Chang Tao and
                  Chi Lin and
                  Wang Cong and
                  Cheng{-}Zhong Xu},
	title = {Heterogeneity-Aware Memory Efficient Federated Learning via Progressive
                  Layer Freezing},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682916},
	doi = {10.1109/IWQOS61813.2024.10682916},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/WuLTTLCX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated Learning (FL) emerges as a new learning paradigm that enables multiple devices to collaboratively train a shared model while preserving data privacy. However, intensive memory footprint during the training process severely bottlenecks the deployment of FL on resource-limited mobile devices in real-world cases. Thus, a framework that can effectively reduce the memory footprint while guaranteeing training efficiency and model accuracy is crucial for FL.In this paper, we propose SmartFreeze, a framework that effectively reduces the memory footprint by conducting the training in a progressive manner. Instead of updating the full model in each training round, SmartFreeze divides the shared model into blocks consisting of a specified number of layers. It first trains the front block with a well-designed output module, safely freezes it after convergence, and then triggers the training of the next one. This process iterates until the whole model has been successfully trained. In this way, the backward computation of the frozen blocks and the corresponding memory space for storing the intermediate outputs and gradients are effectively saved. Except for the progressive training framework, SmartFreeze consists of the following two core components: a pace controller and a participant selector. The pace controller is designed to effectively monitor the training progress of each block at runtime and safely freezes them after convergence while the participant selector selects the right devices to participate in the training for each block by jointly considering the memory capacity, the statistical and system heterogeneity. Extensive experiments are conducted to evaluate the effectiveness of SmartFreeze on both simulation and hardware testbeds. The results demonstrate that SmartFreeze effectively reduces average memory usage by up to 82%. Moreover, it simultaneously improves the model accuracy by up to 83.1% and accelerates the training process up to 2.02 ×.}
}


@inproceedings{DBLP:conf/iwqos/PengDGCX24,
	author = {Zhe Peng and
                  Jiamin Deng and
                  Shang Gao and
                  Helei Cui and
                  Bin Xiao},
	title = {vDID: Blockchain-Enabled Verifiable Decentralized Identity Management
                  for Web 3.0},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--2},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682610},
	doi = {10.1109/IWQOS61813.2024.10682610},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/PengDGCX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Web 3.0 has been proposed as a new generation of the Internet, which shifts towards system decentralization, improved data security, and self-sovereign identity. With the proliferation of networked entities, the proper management and verification of their identities play a vital role in Web 3.0. Decentralized identity is a promising paradigm to enhance data security and restore sovereignty over personal data to users. However, the data security in existing centralized solutions is often severely limited. In this paper, we propose vDID, a novel blockchain-enabled verifiable decentralized identity management system for Web 3.0. First, we design a generic verifiable DID structure, which is capable of capturing and expressing the inherent relationships between different entities with high granularity. Second, we develop an identity verification scheme to support efficient integrity verification for identities and their relationships in the decentralized framework. We implement vDID and conduct experiments to evaluate the system performance. Experimental results demonstrate the effectiveness of our proposed system.}
}


@inproceedings{DBLP:conf/iwqos/XingDHCLGASX24,
	author = {Huifeng Xing and
                  Yuyan Ding and
                  Huiru Huang and
                  Zixuan Chen and
                  Sen Liu and
                  Zehua Guo and
                  Muath Al{-}Hasan and
                  Mohamed Adel Serhani and
                  Yang Xu},
	title = {Hierarchical Sketch: An Efficient, Scalable and Latency-aware Content
                  Caching Design for Content Delivery Networks},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--6},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682952},
	doi = {10.1109/IWQOS61813.2024.10682952},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/XingDHCLGASX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Content Delivery Networks (CDNs) are designed to reduce user-perceived waiting times and alleviate backbone bandwidth pressure. Since CDN cache servers have limited storage capacity, effective cache replacement policies are needed. However, existing CDN cache replacement policies mainly focus on improving content hit rates. As a result, some content with long origin fetch latency may not be cached, resulting in the long tail latency and degrading user experience. In this paper, we present Hierarchical Sketch, an efficient, scalable, and latency-aware cache replacement algorithm. Our approach leverages hierarchical slicing and voting mechanisms on a modified sketch to optimize content caching, reducing sorting complexity from O(log n) to O(1) with minimal loss of hit rate. Extensive simulations on synthetic and real-life industry CDN traces demonstrate that Hierarchical Sketch outperforms other algorithms in four different scenarios, with up to a 15% improvement.}
}


@inproceedings{DBLP:conf/iwqos/GuWZSYLL24,
	author = {Xiaolin Gu and
                  Wenjia Wu and
                  Yusen Zhou and
                  Aibo Song and
                  Ming Yang and
                  Zhen Ling and
                  Junzhou Luo},
	title = {{CQP-RFFI:} Injecting a Communication-Quality Preserving {RF} Fingerprint
                  for Wi-Fi Device Identification},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682878},
	doi = {10.1109/IWQOS61813.2024.10682878},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/GuWZSYLL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recently, there has been an emerging radio frequency fingerprint identification (RFFI) technology that enhances fingerprint distinguishability by deliberately injecting I/Q imbalance into the device’s Wi-Fi baseband signal. Due to the additional injection of I/Q imbalance, this approach inevitably impacts the communication quality between devices, as it reduces the accuracy of channel estimation. To address this issue, we propose injecting the I/Q imbalance into a short training field (STF) instead of the entire baseband signal. Our findings indicate that this method can effectively preserve the quality of the original wireless communication. Building upon this, we introduce a fingerprinting scheme called CQP-RFFI that generates distinguishable fingerprints for a set of devices by injecting appropriate I/Q imbalance into the STF. Leveraging the short-term invariance of the channel, we design a practical I/Q imbalance extraction method based on the communication-quality preserving injection. Moreover, we design an optimal assignment method for I/Q imbalance to maximize the distinguishability of RF fingerprints for all devices. Finally, we implement the CQP-RFFI solution and conduct experiments in real-world scenarios. The experimental results demonstrate that CQP-RFFI achieves 96% precision, recall, and F1-score, and can consistently maintain good communication quality.}
}


@inproceedings{DBLP:conf/iwqos/ChenDWY24,
	author = {Yujie Chen and
                  Yuxin Ding and
                  Shanyue Wang and
                  Yubo Yan},
	title = {WiB-MAC: Collision-Avoidance Multiple Access for Wi-Fi Backscatter
                  Networks},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682888},
	doi = {10.1109/IWQOS61813.2024.10682888},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/ChenDWY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Wi-Fi backscatter communication is a passive wireless technology that relies on modulating Wi-Fi signals through reflection. However, due to the limited availability of interference-free channels, interference and collisions between tags can occur, especially as the number of tags increases. Existing solutions employ static channel allocation methods, which restrict scalability and result in higher data packet loss rates. To address these challenges, we propose WiB-MAC. WiB-MAC utilizes a request-and-allocation mechanism to prevent collisions, supports dynamic tag networks, and is scalable for large-scale backscatter communication. Our protocol efficiently utilizes the exciter channel for tag channel requests and employs a Bloom filter-inspired approach to resolve conflicts when multiple tags apply for channels simultaneously. Using this approach, we ensure that only one tag uses a channel at a time, thereby avoiding collisions between tags. We further enhance network throughput by implementing a priority-based scheduling algorithm that reduces the impact of errors caused by tags. Finally, we designed our tag and tested the scenario where three tags simultaneously apply for the channel, demonstrating the feasibility of the protocol. We also compare our protocol to current backscatter communication networks as a baseline. In a network with 64 tags, WiB-MAC achieves 2.75 times the throughput of the baseline. In a network with 500 tags, the baseline’s throughput drops to 0, while WiB-MAC’s throughput only decreases by 5%.}
}


@inproceedings{DBLP:conf/iwqos/WangZXW24,
	author = {Jingzhou Wang and
                  Gongming Zhao and
                  Hongli Xu and
                  Haibo Wang},
	title = {Leaf: Improving QoS for Reconfigurable Datacenters with Multiple Optical
                  Circuit Switches},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682931},
	doi = {10.1109/IWQOS61813.2024.10682931},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/WangZXW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Facing the huge volume of traffic and intensive traffic dynamics, the traditional datacenter architectures are behind the curve due to the fixed topology and the demand-oblivious nature. Driven by the traffic pattern, the reconfigurable technologies, like optical circuit switches (OCSes), are a promising alternative to further improve throughput when facing traffic dynamics, thanks to the high bandwidth and low reconfiguration time. However, existing works on OCSes are relatively elementary. Some of previous works only deploy single OCS which cannot adapt to large-scale datacenters, while others either cannot guarantee near-optimality or overlook practical issues like limited fiber capacity. These solutions may cause low throughput and long reconfiguration time, resulting in poor QoS. In this paper, we present Leaf to maximize throughput thus to further improve QoS, by deploying multiple OCSes to carry traffic in a cooperation manner. Furthermore, we also show its efficient reconfiguration ability and near-optimality. The formulated problem is a new k-weight limited matching problem and is proven to be N P-hard, which can be solved by a new proposed approximation algorithm with bounded approximation ratio. To evaluate our proposed solution, simulation experiments are conducted with both real-world and synthetic datasets. Compared with state-of-the-arts works, Leaf can improve throughput by 42.16%−68.92%, and reduce runnning time by 68.87%−78.72%.}
}


@inproceedings{DBLP:conf/iwqos/GaoLXMW24,
	author = {Xianjun Gao and
                  Jianchun Liu and
                  Hongli Xu and
                  Qianpiao Ma and
                  Lun Wang},
	title = {Towards Communication-Efficient Federated Graph Learning: An Adaptive
                  Client Selection Perspective},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682905},
	doi = {10.1109/IWQOS61813.2024.10682905},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/GaoLXMW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated graph learning (FGL) has been proposed to collaboratively train the increasing graph data with graph neural networks (GNNs) in a recommendation system, aggregating the features of graph nodes and edges among these nodes. Nevertheless, implementing an efficient recommendation system with FGL still faces two primary challenges, i.e., limited communication bandwidth and non-IID local graph data. Existing works typically reduce communication frequency or transmission amount, which may suffer significant performance degradation under non-IID settings. Furthermore, some researchers propose to share the underlying structure information among all clients, which brings massive communication cost. To this end, we propose an efficient FGL framework, named FedACS, which adaptively selects a subset of clients for model training, to alleviate communication overhead and non-IID issues simultaneously. In FedACS, the global GNN model can learn significant hidden edges and the structure of graph data among selected clients, enhancing recommendation efficiency. This capability distinguishes it from the traditional FL client selection methods. To optimize the client selection process, we introduce a multi-armed bandit (MAB) based algorithm to select participating clients according to the resource budgets and the training performance (i.e., RMSE) under different data distributions. Experimental results show that, given the same resource budget, FedACS achieves the RMSE improvement of 5.4% over the baselines. Besides, when achieving the same RMSE performance, FedACS saves up to approximately 70.7% communication cost, compared with the baselines.}
}


@inproceedings{DBLP:conf/iwqos/SuHLLZJW24,
	author = {Qichen Su and
                  Jiawei Huang and
                  Weihe Li and
                  Zhaoyi Li and
                  Tao Zhang and
                  Wanchun Jiang and
                  Jianxin Wang},
	title = {Achieving QoE Fairness in Video Streaming over Heterogeneous Congestion
                  Control Protocols},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682883},
	doi = {10.1109/IWQOS61813.2024.10682883},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/SuHLLZJW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the growing ubiquity of video streaming, ensuring a fair and high quality of experience (QoE) for users has emerged as a shared concern among video content providers. State-of-the-art video delivery systems achieve QoE fairness through bottleneck bandwidth allocation across multiple video streaming, all based on the assumption of a unified congestion control (CC) protocol. However, the widespread use of heterogeneous CC protocols on the Internet not only disrupts QoE fairness among video streaming but also poses challenges in achieving fast convergence under dynamic bandwidth. To address these issues, we propose a QoE-Fairness aware bandwidth allocation mechanism called Fabam, which establishes a unified QoE control plane across heterogeneous CC protocols. Fabam constructs independent virtual targets based on the real-time QoE of each video streaming to achieve QoE fairness, and offers rapid convergence for the underlying CC protocols to improve efficiency. We implement Fabam on QUIC and integrate it with Dash.js. The evaluation results demonstrate the significant superiority of Fabam over the state-of-the-art approaches, including an enhancement of 24.48% in QoE fairness and an improvement of 16.63% in QoE efficiency.}
}


@inproceedings{DBLP:conf/iwqos/WangHYDYL24,
	author = {Shanyue Wang and
                  Feiyu Han and
                  Yubo Yan and
                  Yuxin Ding and
                  Panlong Yang and
                  Xiang{-}Yang Li},
	title = {SlickScatter: Retrieve WiFi Backscatter Signal from Unknown Interference},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682943},
	doi = {10.1109/IWQOS61813.2024.10682943},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/WangHYDYL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {WiFi backscatter communication demonstrates significant potential for the upcoming era of low-power wireless networks. Nevertheless, due to the low-power requirement of backscatter tags, there are limitations in their capacity to eliminate conflicts, posing a significant challenge for WiFi backscatter communication in environments with ambient interference. To address that, we introduce SlickScatter, an interference-insensitive WiFi backscatter system that can retrieve WiFi backscatter signals even in the presence of unknown ambient interference. The core strategy of SlickScatter involves designating a portion of the tag data symbols as pilot symbols. This approach enables the detection of uninterfered subcarriers and the estimation of channel state information and phase errors for all symbols within a packet, facilitating the demodulation of packets affected by interference. We have prototyped and evaluated SlickScatter with 802.11g OFDM WiFi signals, demonstrating its robustness and effectiveness against unknown ambient interference. Compared with a state-of-the-art solution, SlickScatter significantly decreases the frame error rate by 50% and improves the throughput by 1.96× at a distance of 12 m.}
}


@inproceedings{DBLP:conf/iwqos/LiuHP24,
	author = {Yanbing Liu and
                  Jingqi Huang and
                  Chunyi Peng},
	title = {The Sky is Not the Limit: Unveiling Operational 5G Potentials in the
                  Sky},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682913},
	doi = {10.1109/IWQOS61813.2024.10682913},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/LiuHP24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this work, we present our measurement study to characterize and analyze operational 5G performance potentials for cellular-connected drones that fly in the low sky. We not only measure aerial performance observed over an operational 5G network (here, T-Mobile, one major 5G operator in the US), but also quantitively assess potentials missed in the sky. Different from prior measurement studies, we compare 5G performance potentials realized and missed in the low sky and on the ground. We have several new findings that have not been reported before: higher 5G performance potentials are realized in the sky than on the ground (say, faster data speed in the sky); But surprisingly, more performance potentials are also missed in the sky (namely, 5G can have been even much faster but such potentials are not fully utilized in the sky). We delve into root causes behind missed potentials and find that current 5G cell selection is designed for terrestrial scenarios and misses good candidate cells under aerial radio channel conditions. We thus devise a patch solution called 5Gair to pursue more 5G potentials in the low sky and validate its effectiveness over real-world traces (released at [1]).}
}


@inproceedings{DBLP:conf/iwqos/YinZWQSFL24,
	author = {Yuexi Yin and
                  Zirui Zhuang and
                  Jingyu Wang and
                  Qi Qi and
                  Haifeng Sun and
                  Xiaoyuan Fu and
                  Jianxin Liao},
	title = {Beyond Throughput-Optimal: Second-Order Smooth Backpressure Algorithm
                  for Reducing Jitter and Delay},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682945},
	doi = {10.1109/IWQOS61813.2024.10682945},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/YinZWQSFL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the imminent era of 6G, Quality of Service (QoS) emerges as a pivotal concern in wireless communications. The prescribed transmission rates and vast access demands mandated by 6G standards impose heightened requirements on network throughput and delay. However, the highly dynamic and often bursty nature of application demands presents challenges for routing and congestion control. The backpressure-based joint rate and routing control algorithm adaptively adjusts network traffic to achieve optimal throughput. However, varying traffic conditions hinder the algorithm’s convergence to ideal states. Additionally, relying solely on first-order backlog differences for forwarding can lead to poor convergence and high delays. In this study, we propose a Second-Order Smooth Backpressure (SoSBP) algorithm, leveraging second-order backlog metrics and dual-level queue mapping, to address throughput, delay, and jitter issues in dynamic network environments. We validate the efficacy of this novel backlog metric using Lyapunov optimization techniques. Simulation results demonstrate that our approach significantly reduces end-to-end delay and data jitter while preserving throughput and eliminating routing loops.}
}


@inproceedings{DBLP:conf/iwqos/XiaoCZZWMY24,
	author = {Yao Xiao and
                  Sitian Chen and
                  Amelie Chi Zhou and
                  Shuhao Zhang and
                  Yi Wang and
                  Rui Mao and
                  Xuan Yang},
	title = {Low-Latency Video Conferencing via Optimized Packet Routing and Reordering},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682858},
	doi = {10.1109/IWQOS61813.2024.10682858},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/XiaoCZZWMY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the face of rising global demand for video meetings, managing traffic across geographically distributed (geo-distributed) data centers presents a significant challenge due to the dynamic and limited nature of inter-DC network performance. Facing these issues, this paper introduces two novel techniques, VCRoute and WMJitter, to optimize the performance of geo-distributed video conferencing systems. VCRoute is a routing method designed for audio data packets of video conferences. It treats the routing problem as a Multi-Armed Bandit issue, and utilizes a tailored Thompson Sampling algorithm for resolution. Unlike traditional approaches, VCRoute considers transmitting latency and its variance simultaneously by using Thompson Sampling algorithm, which leads to effective end-to-end latency optimization. In conjunction with VCRoute, we present WMJitter, a watermark-based mechanism for managing network jitter, which can further reduce the end-to-end delay and keep an improved balance between latency and loss rate. Evaluations based on real geo-distributed network performance demonstrate the effectiveness and scalability of VCRoute and WMJitter, offering robust solutions for optimizing video conferencing systems in geo-distributed settings.}
}


@inproceedings{DBLP:conf/iwqos/ZhuCLZX24,
	author = {Bingzhu Zhu and
                  Shan Chang and
                  Guanghao Liang and
                  Hongzi Zhu and
                  Jie Xu},
	title = {Fed-CAD: Federated Learning with Correlation-aware Adaptive Local
                  Differential Privacy},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682944},
	doi = {10.1109/IWQOS61813.2024.10682944},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/ZhuCLZX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated Learning (FL) enables multiple participants to collaboratively train a globally shared model without the need of explicit data sharing. However, prior research indicates that local model updates released during the federated training may also jeopardize privacy of participants. To address this issue, local differential privacy (LDP) mechanism has been applied to FL systems. LDP provides privacy protection with rigorous mathematical proof by introducing random perturbations, e.g., Gaussian noise, to the released updates, however excessive noise compromises the utility of the updates. In this paper, we propose a novel Correlation-aware Adaptive LDP mechanism, Fed-CAD, for FL, which reduces the required scale of noise by leveraging the temporal correlation between consecutive local model updates belonging to the same participant, without increasing the privacy budgets (risks). We theoretically prove that Fed-CAD satisfies (ε, δ)-LDP as long as the difference between local models is smaller than the differential bound, and analyze the noise variance, a metric of utility. We implement Fed-CAD on image classification FL tasks. Experimental results demonstrate that Fed-CAD significantly outperforms the one-shot LDP baseline.}
}


@inproceedings{DBLP:conf/iwqos/YouLXWTL24,
	author = {Lizhao You and
                  Shuoling Liu and
                  Wenjun Xie and
                  Zhaorui Wang and
                  Yihua Tan and
                  Soung Chang Liew},
	title = {Improving Cooperative Wi-Fi Broadcast with Fine-Grained Channel Estimation},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682925},
	doi = {10.1109/IWQOS61813.2024.10682925},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/YouLXWTL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cooperative broadcast is an efficient approach to improve Wi-Fi broadcast performance in a crowded scenario with densely deployed access points (APs). However, the current concurrent transmission MAC protocols cannot synchronize multi-APs’ signals perfectly for all users. As a result, the superimposed signal from APs is time-varying at the users due to the multiple time-domain channels and carrier frequency offsets (CFOs) from multiple APs. The traditional channel estimation approach that estimates the superimposed channel as a whole is ill-suited for the superimposed signal. In this paper, we propose a fine-grained channel estimation approach to first estimate these channel parameters for each AP, and then reconstruct the superimposed channel. Specifically, we present a two-stage channel estimation algorithm that first estimates the CFOs by discretizing the CFO range and matching the most possible CFOs, and then computes the time-domain channels. Experiment and simulation results show the new channel estimation approach achieves much lower bit error rate (BER) and packet error rate (PER) than the traditional IEEE 802.11 approach. In addition, we propose a distributed mechanism to choose the master AP that initializes multi-APs’ simultaneous transmission, which the current concurrent transmission MAC protocols lack. Network-layer simulation results show that the proposed cooperative broadcast scheme improves the throughput by 64% to 82% compared with the traditional uncooperative broadcast scheme.}
}


@inproceedings{DBLP:conf/iwqos/JiangFHZXTLS24,
	author = {Jinghui Jiang and
                  Xiwen Fan and
                  Zhenpei Huang and
                  Kairui Zhou and
                  Qiao Xiang and
                  Lu Tang and
                  Qiang Li and
                  Jiwu Shu},
	title = {Reducing Write Tail Latency of Distributed Key-Value Stores Using
                  In-Network Chasing},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682891},
	doi = {10.1109/IWQOS61813.2024.10682891},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/JiangFHZXTLS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Multiple systems have explored how to use programmable switch ASICs to improve the performance of distributed systems. However, they focus on accelerating read operations and perform poorly under write-intensive workloads. In this paper, we present Gecko, a system that accelerates write operations in distributed key-value store systems using switch ASICs. The core idea of Gecko is to offload the client-side chasing mechanism, a technique deployed by production storage networks, to the programmable switch to simultaneously reduce the perceived and actual write-tail latency in distributed key-value stores. The perceived latency is the interval between the user sending a write request and the user receiving the write success, and there may be replicas that have not yet completed the write, but the actual latency requires all replicas to be successfully written. Gecko not only reduces the perceived write tail latency by deploying the chasing mechanism, but the actual write tail latency is also reduced by utilizing the capabilities of programmable switches. Specifically, Gecko’s in-network chasing design caches a write request at the switch data plane and reports success to the client when only m out of n (usually set to 2 and 3 in production networks, respectively) replicas have been successfully written to the server, and retries the cached write request if the remaining n − m replicas are not successfully written. In addition to caching the write request, Gecko also introduces novel designs to fully implement the chasing controller and a corresponding timer controller in the switch data plane, minimizing the interaction overhead between the switch control and data plane. Extensive experiments on a testbed of Barefoot Tofino switch and commodity servers show that Gecko not only substantially reduces the write tail latency by more than 2.16x caused by transient glitches at servers, but also maintains the same level of reliability as the classic three-replica write operation in distributed key-value stores.}
}


@inproceedings{DBLP:conf/iwqos/ZhaoHZBL24,
	author = {Liang Zhao and
                  Shuai Huang and
                  Huan Zhou and
                  Zilong Bai and
                  Victor C. M. Leung},
	title = {Game-Theoretic Dependent Task Offloading and Resource Pricing in Vehicular
                  Edge Computing},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--2},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682861},
	doi = {10.1109/IWQOS61813.2024.10682861},
	timestamp = {Mon, 14 Oct 2024 08:21:05 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/ZhaoHZBL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper proposes a Stacklberg game-based Dependent task Offloading and resource Pricing framework (SDOP), where vehicles partially offload their dependent substaks to the SDN controller and pays corresponding fees. Firstly, we model the interaction between the SDN controller and vehicles as a Stackelberg game, where both parties wish to maximize their utility. Then, we employ the backward induction approach to analyze the investigated problem, and prove the existence and uniqueness of Nash and Stackelberg equilibrium. Next, we propose a Gradient Ascent Plus Genetic algorithm (GAPG) to solve the considered problem. Finally, extensive simulation results show that the proposed GAPG outperforms other baseline schemes under various scenarios.}
}


@inproceedings{DBLP:conf/iwqos/DengLYL24,
	author = {Qian Deng and
                  Sihan Li and
                  Lingchen Yang and
                  Wenping Liu},
	title = {A Novel Approach for Integrated Optical Camera Communication and Sensing
                  Using Reflected Light},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--2},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682865},
	doi = {10.1109/IWQOS61813.2024.10682865},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/DengLYL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Optical camera communication (OCC) has gained much attention as it leverages the COTS cameras as receivers. While existing work mainly focus on direct light OCC, little has been done for refelcted light for OCC wiht complex background. As such, this paper studies the problem of OCC using reflected light by decoding the striped images captured by COTS devices and its coupled problem of background image reconstruction for scence sensing, and accordingly present a novel approach for integrated optical camera communication and sensing. To this end, we treat the decoding of images with dark and bright stipes as an object (i.e., dark or bright stripe) detection problem, and propose to modify the loss function of the state-of-the-art object detection model, i.e., YOLO V8, such that the width loss becomes more important. Based on the detected dark and bright stripes, we present an improved GAN model to reconstruct the background image by introducing dual-attention mechanism for feature fusion. The experiments show that our approach can accurately detect and decode the stripes in the striped images, and reconstruct the background images.}
}


@inproceedings{DBLP:conf/iwqos/MaDHZ24,
	author = {Tianye Ma and
                  Yukun Dong and
                  Yidan Hu and
                  Rui Zhang},
	title = {Privacy-Preserving Ridesharing via Probabilistic Matching},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--2},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682893},
	doi = {10.1109/IWQOS61813.2024.10682893},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/MaDHZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The widespread use of smartphones has made ridesharing a popular transportation option, connecting passengers with drivers seamlessly. However, existing ridesharing models raise privacy concerns as users must disclose their travel plans without assurance of a match. Previous privacy solutions are either impractical or insecure. To address this, we propose a novel privacy-preserving ridesharing mechanism based on probabilistic matching. Our approach ensures robust privacy protection for both drivers and riders while maintaining efficiency.}
}


@inproceedings{DBLP:conf/iwqos/JiangWYJYWFSS24,
	author = {Xuyan Jiang and
                  Zitong Wang and
                  Xiangrui Yang and
                  Yihao Jiao and
                  Tianci Yu and
                  Xinyue Wang and
                  Wenwen Fu and
                  Yinhan Sun and
                  Zhigang Sun},
	title = {Hebo: FPGA-based Transfer Time Planning for Volatile Traffic in {TSN}},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682946},
	doi = {10.1109/IWQOS61813.2024.10682946},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/JiangWYJYWFSS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Time-Sensitive Networking (TSN) is an advanced technology designed for real-time Ethernet communications, providing extremely low latency, minimal jitter, and lossless data transfer for time-sensitive critical traffic. Despite its benefits, TSN faces challenges with volatile traffic, where the time between frames constantly changes, leading to potential network performance issues. To tackle this issue, this paper introduces Hebo, a novel solution designed for zero frame loss and minimal latency of volatile traffic. Hebo employs a centralized controller, built with field-programmable gate array (FPGA), to dynamically plan the timing of volatile traffic in real-time. This approach ensures real-time data transmission across the network by efficiently allocating network resources. Our real-world and simulation experiments show that Hebo could significantly improve network performance, achieving less than 100 microseconds in end-to-end delay and eliminating nearly all frame loss (reducing it from approximately 80% to zero) in industrial automation scenarios.}
}


@inproceedings{DBLP:conf/iwqos/LiLAGSCLX24,
	author = {Xinyi Li and
                  Minglin Li and
                  Xin Ai and
                  Yongbo Gao and
                  Jiang Shao and
                  Zixuan Chen and
                  Sen Liu and
                  Yang Xu},
	title = {{R-PFC:} Enhancing {RDMA} Network With Restricted And Fine-grained
                  {PFC}},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682907},
	doi = {10.1109/IWQOS61813.2024.10682907},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/LiLAGSCLX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {RDMA over Converged Ethernet (RoCE) has been widely used in datacenter networks and it relies on Priority Flow Control (PFC) to ensure a lossless network. However, PFC brings certain side effects, such as Head-of-Line (HoL) blocking, congestion spreading, and deadlock. Existing solutions demonstrate inherent limitations: either fail to completely eliminate the adverse impacts of PFC or introduce extra challenges. In light of these observations, this paper proposes a novel and practical scheme, Restricted Priority Flow Control (R-PFC). R-PFC consists of two parts: one-hop PFC and Virtual Next Output Queue (VNOQ). Instead of passively regarding PFC as a tool to guarantee a lossless network, one-hop PFC proactively employs PFC in a restrictive manner to minimize packet loss while limiting the spread of congestion within one hop. To further enhance the one-hop PFC, the fine-grained VNOQ solves the HoL blocking issue. We theoretically prove that R-PFC does not lead to deadlock and evaluate the performance of R-PFC under typical datacenter network scenarios in ns3 simulations. The results show that R-PFC outperforms both lossless and lossy networks by 43.76% and 39.46% on average.}
}


@inproceedings{DBLP:conf/iwqos/ZhangWH24,
	author = {Yuchao Zhang and
                  Xiaotian Wang and
                  Xiaofeng He},
	title = {Nexus: Efficient and Conflict-Equivalent DAG-Based Permissioned Blockchain
                  Sharding},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--6},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682609},
	doi = {10.1109/IWQOS61813.2024.10682609},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/ZhangWH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Sharding is one of the most promising solutions to tackle the well-known scalability issue in blockchain by dividing the network into multiple parallel committees. However, inefficient and insecure handling of cross-shard transactions can lead to a decline in the system service quality. Existing permissioned blockchains are mainly based on the classic two-phase commit (2PC) and two-phase locking (2PL) from traditional distributed databases to implement cross-shard transactions with deterministic safety, but this also leads to issues such as decreased system throughput and frequent transaction aborts. In this paper, we introduce Nexus, an efficient and conflict-equivalent sharded permissioned blockchains to overcome the aforementioned challenges. The core idea of Nexus is to construct a directed acyclic graph (DAG) among all shards to establish a partial order of blocks, while leaving transaction dissemination and final ordering to be completed in parallel by each shard. Nexus alleviate the overhead of global ordering through a efficient consensus process, and ensure that all transactions with overlapping read and write sets can be committed in the same relative order across different shards. A prototype of Nexus is implemented and evaluated, and experimental results show that Nexus achieves approximately 70% and 50% throughput improvement over AHL and SharPer under default settings.}
}


@inproceedings{DBLP:conf/iwqos/YuHZLL24,
	author = {Haikuo Yu and
                  Jiahui Hou and
                  Lan Zhang and
                  Suyuan Liu and
                  Xiang{-}Yang Li},
	title = {Efficient Object-grained Video Inpainting with Personalized Recovery
                  and Permission Control},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682955},
	doi = {10.1109/IWQOS61813.2024.10682955},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/YuHZLL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Online video-centric service is an emerging application paradigm that enables users to access personalized video services using public equipment. However, it also brings many privacy and security issues, since the online videos might be accessed by different users. To protect the video content privacy against untrusted recipients, we need to take fine-grained control of access permissions to video content. The same video content might be accessible to certain recipients while being restricted to others. Traditional methods generate and encode multiple redacted versions of the same video, leading to substantial increases in storage, processing, and communication costs, which is difficult in adapting to the demands of the ubiquitous multimedia era. Enabling cost-effective, personalized, and fine-grained access control for video content presents a significant challenge.Video inpainting methods have gained popularity for their notable ability to remove objects with plausible pixels. In this work, we introduce the Object-grained Video Inpainting (OVI) framework for personalized access control – objects in videos are accessible only to authorized users and are visually coherently blocked for all others. OVI is efficient irrespective of user count. We implement the prototype and evaluate its performance via security study, reconstruction effectiveness, and efficiency. The experimental results show that OVI speeds up video sharing and reduces communication savings by a Θ(n) factor over the baselines when there are n different accessing groups.}
}


@inproceedings{DBLP:conf/iwqos/ZhengJXAWL24,
	author = {Ying Zheng and
                  Lei Jiao and
                  Yuedong Xu and
                  Bo An and
                  Xin Wang and
                  Zongpeng Li},
	title = {Scheduling Generative-AI Job DAGs with Model Serving in Data Centers},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--6},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682885},
	doi = {10.1109/IWQOS61813.2024.10682885},
	timestamp = {Thu, 17 Oct 2024 15:42:21 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/ZhengJXAWL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Scheduling generative-AI jobs in the edge computing environment faces multiple non-trivial challenges, including the Directed Acyclic Graph (DAG) dependency among tasks, the intrinsic intertwinement between task scheduling and model selection, and the dynamic unpredictable arrival of job DAGs. In this work, we capture all such challenges and formulate a non-linear integer program to optimize the long-term profit of the generative-AI service provider, i.e., service revenue of the admitted jobs minus system costs of executing the tasks contained in such job DAGs. This problem is NP-hard even in the offline setting. To solve it, we first reformulate it into an equivalent schedule selection problem using generated schedules to tackle complex constraints. Then, we design a new online scheduling method through the online primal-dual technique. Experimental results confirm that our approach can increase the total service profit by up to 41.2% compared to existing algorithms.}
}


@inproceedings{DBLP:conf/iwqos/FengWLLZLZW24,
	author = {Xingbo Feng and
                  Yi Wang and
                  Jiashuo Lin and
                  Weichao Li and
                  Shuangping Zhan and
                  Yan Liu and
                  Jin Zhang and
                  Jianping Wang},
	title = {RobustTSN: {A} Framework for Protecting Time-Sensitive Networking
                  against Unexpected Delays},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--6},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682834},
	doi = {10.1109/IWQOS61813.2024.10682834},
	timestamp = {Mon, 14 Oct 2024 08:21:04 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/FengWLLZLZW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Industrial networks require deterministic and reliable communication, which can be achieved by Time-Sensitive Networking (TSN), a set of standards that enable precise timing and synchronization of data transmission. However, TSN is susceptible to unexpected delays caused by device malfunction, interference or cyber attacks, which can have a domino effect and disrupt multiple data flows. To address this challenge, we propose RobustTSN, a framework that protects TSN against the domino effect of delayed frames and tolerates harmless accident frames using Per-Stream Filtering and Policing (PSFP) mechanism. We develop algorithms to calculate ingress filtering schedules based on local-safe delay and global-safe interval concepts, which decide whether to accept or discard out-of-schedule frames. We use a finite state machine to model the interaction between frames and evaluate frame safety. We build a software-defined networking based system to dynamically monitor network states and reconfigure device filtering after out-of-schedule transmission occurs. We conduct experiments on practical scenario topologies and large groups of random flows to demonstrate the effectiveness and efficiency of our framework.}
}


@inproceedings{DBLP:conf/iwqos/ChouCWWMML24,
	author = {Yi Ching Chou and
                  Long Chen and
                  Feng Wang and
                  Hengzhi Wang and
                  Xiaoqiang Ma and
                  Sami Ma and
                  Jiangchuan Liu},
	title = {Orchestrating Sustainable and Service-Differentiable Satellite Networking:
                  {A} Federated Cross-Orbit Approach},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682914},
	doi = {10.1109/IWQOS61813.2024.10682914},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/ChouCWWMML24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Satellite networks are believed to become an indispensable component in the forthcoming 6G network and beyond. The surging demands attract numerous satellite network operators into this market to compete, yet also cooperate via resource sharing for cost and performance improvement, which is similar to the growth trajectory of how the Internet becomes the network of networks. Hence, we envision a federated network of satellite networks (shortened as federated satellite network) in this paper, where satellite network operators will eventually federate with each other to achieve a win-win situation. However, the yet-to-come federated satellite network faces two unique challenges: sustainability and dynamic topology. As such, we propose a sustainable and service-differentiable framework named Federated Cross-orbit Satellite Network (FCSN). Different from most existing solutions which focused on the Internet or simple cooperation among satellites, the FCSN orchestrates network resources in the dynamic topology to improve sustainability, through service-differentiable offloading in the resource-limited scenario. We formulate the sustainability-oriented federated offloading problem based on the utility and cost models tailored for the FCSN and propose an efficient hardware-budget constrained auction algorithm with a bounded approximation ratio. Finally, we design a truthful and rational payment scheme to motivate the construction of the FCSN. Extensive simulation results based on real-world deployments show that our solution significantly improves sustainability and delay, making it one step further toward the vision of the federated network of satellite networks.}
}


@inproceedings{DBLP:conf/iwqos/HuangLMC24,
	author = {Yaodong Huang and
                  Jiahui Luo and
                  Changkang Mo and
                  Laizhong Cui},
	title = {{HTTP/3} over Information-Centric Networking},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--2},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682843},
	doi = {10.1109/IWQOS61813.2024.10682843},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/HuangLMC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {HTTP/3 is designed to enhance performance and security by utilizing QUIC as its underlying transport protocol. Integrating HTTP/3 and its features can expand the application scope of ICN. Through an analysis of critical elements of HTTP/3, we implement it on NDN forwarding daemons and run applications in browsers to assess its capabilities and potential benefits in ICN environments. Our system demonstration illustrates compatibility with mainstream browsers while supporting ICN-based transmissions.}
}


@inproceedings{DBLP:conf/iwqos/LuZWJL24,
	author = {Yadong Lu and
                  Huan Zhou and
                  Hengtao Wang and
                  Tingyao Jiang and
                  Victor C. M. Leung},
	title = {Online Trajectory Optimization and Resource Allocation in UAV-Assisted
                  {NOMA-MEC} Systems},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--2},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682901},
	doi = {10.1109/IWQOS61813.2024.10682901},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/LuZWJL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper investigates the joint trajectory optimization and resource allocation problem in an UAV-Assisted NOMA-MEC System, aiming to minimize the system overhead. First, considering user mobility and Non-Orthogonal Multiple Access (NOMA) technology, we transform UAV trajectory optimization and resource allocation problem as a dynamic coverage location problem. Second, we design a Low-complexity Online Trajectory optimization and Resource allocation Scheme based on Lyapunov and convex optimization (LOTRS) with the goal of minimizing the system overhead. Simulation results show that compared with other benchmark schemes, the proposed LOTRS performs best in terms of system overhead in various scenarios.}
}


@inproceedings{DBLP:conf/iwqos/ShiYW24,
	author = {Ruixin Shi and
                  Ming Yan and
                  Jie Wu},
	title = {Optimizing Inference Quality with SmartNIC for Recommendation System},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682873},
	doi = {10.1109/IWQOS61813.2024.10682873},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/ShiYW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Embedding-based recommendation systems are now widely used to recommend content for users, and have strict requirements on their latency and throughput. However, the latest recommendation models often exceed GPU HBM memory capacity, and the system is often deployed separately on computing nodes for GPU calculating and Parameter Servers for embedding tables’ storage. This architecture leads to a significant amount of network I/O during the inference process and reduces GPU utilization.In this paper, we propose SmartEmb, an inference framework that accelerates the network I/O of embedding table lookups through a specialized control plane of task reordering, prefetching and cache management. We offload these control planes on SmartNIC to avoid contention with the host CPU and gain better performance. We implemented the SmartEmb prototype on BlueField-2 and evaluated its performance. Our evaluation demonstrates that compared to the Nvidia HugeCTR HPS, SmartEmb can improve the quality of service by achieving up to 217% improvement in throughput and reducing latency by up to 190% of overall embedding layer look-ups in inference scenarios.}
}


@inproceedings{DBLP:conf/iwqos/TianQL24,
	author = {Chunlin Tian and
                  Xinpeng Qin and
                  Li Li},
	title = {GreenLLM: Towards Efficient Large Language Model via Energy-aware
                  Pruning},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--2},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682928},
	doi = {10.1109/IWQOS61813.2024.10682928},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/TianQL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper proposes GreenLLM, a framework that effectively deploys generative Large Language Models (LLMs) on resource-limited edge devices to well meet the memory and timing constraints with minimized energy consumption. Specifically, GreenLLM employs an energy estimation scheme based on physical hardware to guide a pruning-ratio generator incorporating space, weight, and power (SWaP) constraints for optimal pruning ratio. For each layer, we employ a dependency-aware energy-efficient Pruner in a task-agnostic manner, maximally preserving most of the LLM functionality. Finally, we use downstream datasets to fine-tune the pruned model to recover performance.}
}


@inproceedings{DBLP:conf/iwqos/LiuHWJHWX24,
	author = {Bingyi Liu and
                  Jingxiang Hao and
                  Enshu Wang and
                  Dongyao Jia and
                  Weizhen Han and
                  Libing Wu and
                  Shengwu Xiong},
	title = {Multi-Agent Reinforcement Learning Based Resource Allocation for Efficient
                  Message Dissemination in {C-V2X} Networks},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682924},
	doi = {10.1109/IWQOS61813.2024.10682924},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/LiuHWJHWX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In order to support diverse applications in intelligent transportation, intelligent connected vehicles (ICVs) need to send multiple types of messages, such as periodic messages and event-driven messages with different frame specifications. However, existing researches often concentrate on the transmission of single-message types, overlooking hybrid communication scenarios where multiple types of messages coexist, posing challenges in meeting the diverse transmission needs of different message types. To optimize the Quality of Service (QoS) in such scenarios, we take the perspective of ICVs and formulate their decision making as a multi-agent reinforcement learning problem. More specifically, we propose a cooperative individual rewards assisted multi-agent reinforcement learning (CIRA) framework. The transformer structure in CIRA is used to avoid mutual interference during the transmission of different vehicles. Besides, the introduction of individual rewards and the dual-layer architecture of CIRA contribute to providing ICVs with more forward-looking message dissemination scheme. Finally, we set up a simulator to create dynamic traffic scenarios reflecting different real-world conditions. We conduct extensive experiments to evaluate the proposed CIRA framework’s performance. The results show that CIRA can significantly improve the packet reception rates and ensure low communication delays in various scenarios.}
}


@inproceedings{DBLP:conf/iwqos/TaoCPLM24,
	author = {Xi Tao and
                  Weipeng Cao and
                  Yinghui Pan and
                  Ye Liu and
                  Zhong Ming},
	title = {Improving QoS of Workloads with {CPU} Pinning: {A} Deep Reinforcement
                  Learning Approach},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--2},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682839},
	doi = {10.1109/IWQOS61813.2024.10682839},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/TaoCPLM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In cloud computing, tenants tend to select predefined flavors with substantial resources that go beyond their needs, in order to avoid resource starvation. As a result, cloud service providers experience a high allocation ratio with a low utilization ratio of resources. To improve the resource utilization, cloud service providers offer lower-priced resources by building an overcommitted environment to reuse resources. However, the colocation interference of workloads in the overcommitted environment may cause performance anomalies and degrade quality of service (QoS). In this paper, we propose a real-time mechanism to pin a group of workloads to a certain subset of CPUs to increase resource utilization and minimize interference. To be specific, we leverage deep reinforcement learning (DRL) to automatically adjust the CPU pinning configuration in the overcommitted environment according to the performance of workloads.}
}


@inproceedings{DBLP:conf/iwqos/ChenSL24,
	author = {Sijia Chen and
                  Ningxin Su and
                  Baochun Li},
	title = {Relic: Federated Conditional Textual Inversion with Prototype Alignment},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--6},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682846},
	doi = {10.1109/IWQOS61813.2024.10682846},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/ChenSL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Text-to-image models can generate personalized images with unprecedented freedom by using a pseudo-word learned from a few images, using a novel technique called textual inversion. It is conceivable that, in the spirit of federated learning, multiple users wish to learn a pseudo-word based on their local images collaboratively. However, how a more effective pseudo-word can be trained in the context of federated learning remains unclear.In this paper, our experiments show that such federated textual inversion is neither secure nor feasible. First, once one client exposes its pseudo-word embedding to the server for aggregation, an attacker can directly generate similar images to this client. Second, training one shared pseudo-word without personalization hinders individuals from generating images that exhibit local characteristics. Finally, after global aggregation, the averaged pseudo-word embedding may lose learned concepts. Motivated by these insights, we propose Relic, a new framework that encompasses federated conditional textual inversion with prototype alignment. With privacy guarantees, Relic allows clients to learn personalized pseudo-words conditional on local samples while enforcing a globally consistent clustering of clients’ pseudo-words into discriminable prototypes instead of averaging. The experiments conducted on both i.i.d. and extreme non-i.i.d. data demonstrate that Relic is able to achieve state-of-the-art performance as compared to baseline approaches.}
}


@inproceedings{DBLP:conf/iwqos/LiuHXXH24,
	author = {Jianwei Liu and
                  Yinghui He and
                  Weiye Xu and
                  Yifan Xie and
                  Jinsong Han},
	title = {Manipulating Semantic Communication by Adding Adversarial Perturbations
                  to Wireless Channel},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682897},
	doi = {10.1109/IWQOS61813.2024.10682897},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/LiuHXXH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {To break through the transmission rate bottleneck of traditional communication, semantic communication is proposed to support emerging applications with extremely low latency requirements such as remote surgery and autonomous vehicle. Unlike the transmission of verbose symbols in traditional communication, mainstream semantic communications use deep learning technology to extract compact semantic information from data and convey it. However, the application of deep neural networks also poses security concerns, i.e., vulnerabilities to adversarial attacks. In this paper, we perform the first study on the security of semantic communication against both whitebox and black-box attacks by compromising the wireless channel between the transmitter and receiver. To launch practical and effective attacks, a systematic and universal attack framework is designed to craft content-agnostic, undetectable, robust whitebox perturbation signals as well as highly-transferable blackbox ones. Extensive experiments on two open-source datasets demonstrate that our attack framework can achieve over 87%, 99%, and 89% success rates in untargeted white-box, targeted white-box, and untargeted black-box attacks. This means that the proposed attack methods could severely threaten the quality of service of current semantic communications. We also propose two mitigation methods to resist such attacks.}
}


@inproceedings{DBLP:conf/iwqos/HuangXDSLGL24,
	author = {Hanlin Huang and
                  Ke Xu and
                  Xinle Du and
                  Yiyang Shao and
                  Jie Li and
                  Xiangyu Gao and
                  Tong Li},
	title = {Performant {TCP} over Wi-Fi Direct},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682911},
	doi = {10.1109/IWQOS61813.2024.10682911},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/HuangXDSLGL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Wi-Fi Direct has been serving a progressively wide range of applications such as device-to-device file sharing, face-to-face interactive gaming, and wireless projection. However, when TCP meets Wi-Fi Direct, we find that two independent control loops exist, i.e., the transport-layer control loop and the link-layer control loop. First, these functionally redundant loops result in spectrum inefficiency. Second, the lack of effective information interaction between layers results in local optimal. To tackle these issues, this paper proposes Wi-Fi Direct TCP (WDTCP), a performant TCP that provides a full protocol design of the acknowledgment de-redundancy and explicit-capacity-based congestion control. WDTCP tightly couples the two control loops by capturing the WiFi Direct’s key feature of one-hop communication. Evaluation results demonstrate that WDTCP can maximize bandwidth utilization while keeping low latency. For instance, compared to legacy TCP, WDTCP improves throughput by up to 49.2% and reduces average and 95th latency by up to 32.4% and 50.7%, respectively.}
}


@inproceedings{DBLP:conf/iwqos/YangM24,
	author = {Tao Yang and
                  Xuebin Ma},
	title = {AdaDP-CFL: Cluster Federated Learning with Adaptive Clipping Threshold
                  Differential Privacy},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682882},
	doi = {10.1109/IWQOS61813.2024.10682882},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/YangM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated learning is a distributed machine learning approach that enables multiple clients to train models collaboratively. As its data remains stored locally on each client, this approach significantly enhances the protection of private information. However, federated learning still faces privacy leakage risks in environments with data heterogeneity. Differential privacy mechanisms are widely utilized in federated learning to ensure privacy for clients, and the magnitude of the clipping threshold directly impacts model utility. The current research does not adequately address the impact of model accuracy and training loss on clipping thresholds and is challenged by excessive hyperparameter adjustments. In response to these challenges, we propose an adaptive clipping-based differential privacy federated learning algorithm named AdaDP-CFL. It achieves model personalization and facilitates knowledge sharing among different groups through clustering and regularization techniques. Subsequently, the algorithm addresses the issue of adaptive clipping for various clients, formulated as a Markov decision process, by utilizing a deep deterministic policy gradient model based on gradient differences across client groups. Experimental results demonstrate that our algorithm outperforms current algorithms in accuracy, effectively balancing privacy protection and model utility.}
}


@inproceedings{DBLP:conf/iwqos/ZhangZW24,
	author = {Jiajia Zhang and
                  Shuman Zhuang and
                  Yulin Wu},
	title = {Improving Real-Time Service Quality Through Parallel Monte Carlo Tree
                  Search},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--2},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682938},
	doi = {10.1109/IWQOS61813.2024.10682938},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/ZhangZW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we present a new algorithm named Distributed Multi-root Pipeline MCTS (DMP-MCTS), to improve real-time search efficiency in multi-machine scenarios. By utilizing root parallel technology with significance detection and pipeline pattern for parallel MCTS (3PMCTS), we not only reduce the repetitive computing tasks among subtrees but also allow for flexible operation time based resource allocation. The experiment shows this work achieves better computational performance under linear acceleration conditions, compared with other existing works.}
}


@inproceedings{DBLP:conf/iwqos/ChangLLZZW24,
	author = {Shan Chang and
                  Ye Liu and
                  Zhijian Lin and
                  Hongzi Zhu and
                  Bingzhu Zhu and
                  Cong Wang},
	title = {FedTrojan: Corrupting Federated Learning via Zero-Knowledge Federated
                  Trojan Attacks},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682906},
	doi = {10.1109/IWQOS61813.2024.10682906},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/ChangLLZZW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Decentralized and open features of federated learning provides opportunities for malicious participants to inject stealthy trojan functionality into deep learning models collusively. A successful trojan attack is desired to be effective, precise and imperceptible, which generally requires priori knowledge such as aggregation rules, tight cooperation between attackers, e.g. sharing data distributions, and the use of inconspicuous triggers. However, in realistic, attackers are typically lack of the knowledge and hardly to fully cooperate (for privacy and efficiency reasons), and out of scope triggers are easy to be detected by scanners. We propose FedTrojan, a zero-knowledge federated trojan attack. Each attacker independently trains a quasi-trojaned local model with a self-select trigger. The model behaves normally on both regular and trojaned inputs. When local models are aggregated on the server side, the corresponding quasi-trojans will be assembled into a complete trojan which can be activated by the global trigger. We choose existing benign features rather than artificial patches as hidden local triggers to guarantee imperceptibility, and introduce catalytic features to eliminate the impact of local trojan triggers on behaviors of local/global models. Extensive experiments show that the performance of FedTrojan is significantly better than that of existing trojan attacks under both the classic FedAvg and Byzantine-robust aggregation rules.}
}


@inproceedings{DBLP:conf/iwqos/HuangWLLC24,
	author = {Sijiang Huang and
                  Mowei Wang and
                  Yashe Liu and
                  Zhenhua Liu and
                  Yong Cui},
	title = {Iphicles: Tuning Parameters of Data Center Networks with Differentiable
                  Performance Model},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682926},
	doi = {10.1109/IWQOS61813.2024.10682926},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/HuangWLLC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Tuning parameters in Data Center Networks (DCN) has long been a nuisance and one of the reasons service providers are reluctant to deploy new mechanisms in their production environments. Despite the excessive time and resources devoted to finding better configurations, a "one-size-fits-all" solution remains elusive. Neither manual configuration by experts nor black-box optimization can address the challenges of network heterogeneity and dynamics. One essential factor impeding efficient and stable parameter optimization is the need to explore in real environments, which has a long convergence time alongside the risk of performance degradation. To address this problem, we build a twin performance model of the physical DCN that approximates the mapping from parameters to Quality of Service (QoS) metrics for fast and safe performance inference and present a DCN configuration framework called Iphicles. Leveraging gradients provided by differentiable performance models built with Graph Neural Networks (GNN), Iphicles can automatically recommend better parameters efficiently and stably. Experimental results based on extensive simulation demonstrate that in complex scenarios with mixed and dynamic traffic, Iphicles can deliver parameters that lead to evident improvements in flow completion time (FCT) for both mice and elephant flows simultaneously, with minimum convergence time while maintaining performance stability during the optimization process.}
}


@inproceedings{DBLP:conf/iwqos/ChenXGCLZ24,
	author = {Jiabin Chen and
                  Fei Xu and
                  Yikun Gu and
                  Li Chen and
                  Fangming Liu and
                  Zhi Zhou},
	title = {HarmonyBatch: Batching multi-SLO {DNN} Inference with Heterogeneous
                  Serverless Functions},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682915},
	doi = {10.1109/IWQOS61813.2024.10682915},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/ChenXGCLZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Deep Neural Network (DNN) inference on serverless functions is gaining prominence due to its potential for substantial budget savings. Existing works on serverless DNN inference solely optimize batching requests from one application with a single Service Level Objective (SLO) on CPU functions. However, production serverless DNN inference traces indicate that the request arrival rate of applications is surprisingly low, which inevitably causes a long batching time and SLO violations. Hence, there is an urgent need for batching multiple DNN inference requests with diverse SLOs (i.e., multi-SLO DNN inference) in serverless platforms. Moreover, the potential performance and cost benefits of deploying heterogeneous (i.e., CPU and GPU) functions for DNN inference have received scant attention.In this paper, we present HarmonyBatch, a cost-efficient resource provisioning framework designed to achieve predictable performance for multi-SLO DNN inference with heterogeneous serverless functions. Specifically, we construct an analytical performance and cost model of DNN inference on both CPU and GPU functions, by explicitly considering the GPU time-slicing scheduling mechanism and request arrival rate distribution. Based on such a model, we devise a two-stage merging strategy in HarmonyBatch to judiciously batch the multi-SLO DNN inference requests into application groups. It aims to minimize the budget of function provisioning for each application group while guaranteeing diverse performance SLOs of inference applications. We have implemented a prototype of HarmonyBatch on Alibaba Cloud Function Compute. Extensive prototype experiments with representative DNN inference workloads demonstrate that HarmonyBatch can provide predictable performance to serverless DNN inference workloads while reducing the monetary cost by up to 82.9% compared to the state-of-the-art methods.}
}


@inproceedings{DBLP:conf/iwqos/GuoLSW24,
	author = {Kejun Guo and
                  Fuliang Li and
                  Jiaxing Shen and
                  Xingwei Wang},
	title = {Advancing Sketch-Based Network Measurement: {A} General, Fine-Grained,
                  Bit-Adaptive Sliding Window Framework},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682923},
	doi = {10.1109/IWQOS61813.2024.10682923},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/GuoLSW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Network measurement plays a critical role in numerous network applications that rely on fundamental flow processing tasks such as frequency estimation, heavy hitter detection, and distribution estimation. Sketch has emerged as an efficient approach for network measurement due to its low overhead. However, most sketch-based solutions target static windows while enabling sliding window-based measurement remains an open challenge. This paper introduces two novel general frameworks applicable to diverse sketch models for sliding window-based network measurement: a traditional sliding window framework and a fine-grained flow-level framework. The traditional framework divides the window into parts and uses centralized flushing to remove expired parts. The flow-level framework tracks timestamps to maintain exact flow characteristics over one period, preventing truncation. To optimize memory usage, a bit-wise adaptive allocation algorithm allows dynamic borrowing of unused counter bits. The frameworks are evaluated on sketches for different flow processing tasks. Results show the frameworks are widely generalizable, reduce error substantially compared to existing approaches, and provide more efficient memory usage.}
}


@inproceedings{DBLP:conf/iwqos/HuangCLXG24,
	author = {Ruixue Huang and
                  Lianghua Cheng and
                  Zhenghan Li and
                  Chaocan Xiang and
                  Yulan Guo},
	title = {iPatrol: Illegal Roadside Parking Detection Leveraging On-road Vehicle
                  Crowdsensing},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682887},
	doi = {10.1109/IWQOS61813.2024.10682887},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/HuangCLXG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Illegal roadside parking is a common problem faced by large-scale cities, leading to traffic congestion & accidents, and hindering fire rescue. Traditional methods for detecting illegal parking rely highly on active human efforts and particular sensors, which are extremely cost-ineffective to cover large-scale cities. To this end, we consider employing massive on-road vehicles to collect the vehicular sensory data (including recording video of the surroundings and driving state information), thereby enabling a large-scale, fine-grained illegal parking detection at a low cost. However, the dynamic and complex movement of the sensing and target vehicles, coupled with complex traffic situations and environmental factors, presents challenges for achieving accurate detection. To address these challenges, we propose iPatrol, an illegal roadside parking detection system leveraging on-road vehicle crowdsensing, at the heart of which lies a key extension of the Doppler effect from the traditional acoustic scenarios to the vehicle-mounted video scenarios. Following the methodology of the Doppler effect and leveraging camera imaging theory, we establish a new vehicle speed estimation model, using video feature’s change to estimate the relative speed of the two vehicles. Furthermore, this model is utilized to identify the parking status of the target vehicle and estimate its position by utilizing the graph rigidity theory and the non-convex optimization scheme. We implement iPatrol on Android smartphones mounted behind the vehicle windshields and conduct on-road experiments covering 233 km roads in an urban area about 125 km 2 . The experimental results demonstrate that iPatrol detected a total of 162 illegal parking events while achieving a detection accuracy of 87.1% which outperforms three baselines by 21.9% on average.}
}


@inproceedings{DBLP:conf/iwqos/RaoZZYLDZC24,
	author = {Bo Rao and
                  Xiaoxi Zhang and
                  Tianxiang Zhu and
                  Yufei You and
                  Yihong Li and
                  Jingpu Duan and
                  Zhi Zhou and
                  Xu Chen},
	title = {Can You Do Both? Balancing Order Serving and Crowdsensing for Ride-Hailing
                  Vehicles},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--6},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682936},
	doi = {10.1109/IWQOS61813.2024.10682936},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/RaoZZYLDZC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Given the high mobility and sensor-carrying capability, vehicle crowdsensing (VCS) has become a significant part of urban crowdsensing tasks in the development of smart cities. Ride-hailing vehicles, which are widely distributed in cities, can be a powerful tool for carrying out VCS. However, dispatching the vehicles to jointly benefit VCS and order serving is challenging, as the goals of these two tasks may not be consistent or even conflict. The distribution of ride orders and the distribution of point-of-interests (PoIs) may not coincide in time and geography. In addition, these orders and data PoIs have distinct forms of timeliness: prolonged waiting makes orders invalid and data with a larger age-of-information (AoI) has lower utility. We propose an online framework by extending multi-agent reinforcement learning (MARL) with careful augmentation to optimize the profit of order-serving and the data utility of crowdsensing. A new quality-of-service (QoS) metric is designed to characterize the utility of the two joint tasks, and formal mathematical modeling drives our MARL design. In particular, we integrated graph neural networks (GNN) to enhance state representations and capture the graph-structured dependencies among vehicles. We developed a simulator and conducted extensive experiments utilizing the New York City Taxi dataset. Experimental results demonstrate the advantage of our method in QoS improvement.}
}


@inproceedings{DBLP:conf/iwqos/ChenLZXLC24,
	author = {Sisi Chen and
                  Weijie Liu and
                  Xiaoxi Zhang and
                  Hong Xu and
                  Wanyu Lin and
                  Xu Chen},
	title = {Adaptive Personalized Federated Learning for Non-IID Data with Continual
                  Distribution Shift},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--6},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682851},
	doi = {10.1109/IWQOS61813.2024.10682851},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/ChenLZXLC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated Learning (FL) has surged in popularity, allowing machine learning models to be collaboratively trained using decentralized client data, all while upholding privacy and security standards. However, leveraging locally-stored data introduces challenges related to data heterogeneity. While many past studies have addressed this non-IID problem, they often overlook the dynamic nature of each individual client’s data or disrupt its continuous shift. In this paper, our emphasis is on the challenges posed by temporal data distribution shift alongside non-IID data across clients, a more prevalent yet complex situation in real-world FL. We propose to analytically capture the evolving nature of each local data distribution, by modeling them as a time-varying composite of multiple latent Gaussian distributions. We then employ the expectation maximization (EM) algorithm to deduce the distribution model parameters based on the prevailing observed training data, ensuring that the learned mixture proportion weights mirror a consistent trajectory. Additionally, by embedding an adaptive data partitioning method into the EM algorithm and using each partition to train a distinct sub-model, we realize an intuitive and novel personalized FL paradigm. This refines the FL training by exploiting the heterogeneity and temporal shifts of clients’ datasets. We derive analytical results to guarantee the convergence of our training method. Comprehensive tests across diverse datasets and distribution configurations also underscore our enhanced efficacy compared to several state-of-the-art.}
}


@inproceedings{DBLP:conf/iwqos/LinLL24,
	author = {Changyao Lin and
                  Chengxiang Li and
                  Jie Liu},
	title = {A QoS-Aware Training Framework for ViT Compression, Partition, and
                  Distillation},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--2},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682862},
	doi = {10.1109/IWQOS61813.2024.10682862},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/LinLL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we jointly optimize compression, partition and distillation for visual Transformer. We analyze the relationship among the three modules and integrate them into a QoS-aware training framework. By coordinating the model compression, edge-cloud partition, and knowledge distillation during training, the model architecture and accuracy are optimized simultaneously. The framework considers the differences in computing power and memory between edge and cloud, and can trade off QoS metrics such as the memory overhead, end-to-end latency, accuracy at multiple granularities.}
}


@inproceedings{DBLP:conf/iwqos/XueX24,
	author = {Hai Xue and
                  Yun Xia},
	title = {Profit-aware Edge Server Placement based on All-pay Auction for Edge
                  Offloading},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--2},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682876},
	doi = {10.1109/IWQOS61813.2024.10682876},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/XueX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Mobile edge computing is a promising computing paradigm to enhance Quality of Service (QoS) for end devices (EDs), because it sinks the resources of cloud server to the network edge, which significantly mitigates the serious transmission delay to facilitate service response efficiency, and thus directly improves the QoS. However, edge servers are reluctant to offer service without satisfactory compensation. Therefore, auction-based resource pricing schemes are widely investigated to incentivize servers to serve EDs. In this work, we propose an edge server placement scheme based on all-pay auction mechanism, which determines the optimal server-user ratio to maximize service provider (SP) profit. Experimental simulations verified that the profit of SP is maximized while the server-user ratio is approximately 25%, which also provides the theoretical basis for real-world deployment.}
}


@inproceedings{DBLP:conf/iwqos/DuZLZ24,
	author = {Haiwen Du and
                  Rui Zhang and
                  Yixuan Lu and
                  Dongjie Zhu},
	title = {Optimizing Tail Latency by Critical Window-based Dynamic Cache Space
                  Allocation},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--2},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682852},
	doi = {10.1109/IWQOS61813.2024.10682852},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/DuZLZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Data read and write tail latency in distributed storage systems affects the quality of service of applications. In this paper, we focus on requests with latency around 99.99th tail latency and design a critical window. By analyzing the target storage device distribution of requests in the critical window, we design a simple but effective cache space allocation method to optimize tail latency. Unlike traditional methods, it schedules target cache space allocation instead of requests. Since it does not change the processing of requests and I/Os, it reduces the extra time consumption incurred by the scheduling algorithm. At the same time, it solves the problems of lag, tail latency fluctuation, and high resource consumption of the load balancing-based tail latency guarantee algorithm on request scheduling. Finally, we verify the optimization effect of the method’s tail-latency metrics.}
}


@inproceedings{DBLP:conf/iwqos/WuLCZRMWX24,
	author = {Meihan Wu and
                  Li Li and
                  Tao Chang and
                  Jie Zhou and
                  Eric Rigall and
                  Cui Miao and
                  Xiaodong Wang and
                  Chengzhong Xu},
	title = {PFed-DBA: Distribution Bias Aware Personalized Federated Learning
                  for Data Heterogeneity},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--6},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682940},
	doi = {10.1109/IWQOS61813.2024.10682940},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/WuLCZRMWX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Personalized Federated Learning (PFL) aims to learn a custom model for each distributed client while benefiting from collaborative training in order to overcome the detrimental impact of data heterogeneity. Despite the promising benefits, the existing approaches often compromise the generalization performance of personalized models, as they solely focus on enhancing the personalization capability of models or merely aim to strike a balance between personalization and generalization. Indeed, increasing the personalization capability while preserving the strong generalization performance enabled by collaborative training remains a challenge for PFL, as the two objectives seem to compete with each other. To tackle this challenge, we investigate the relationship between model generalization and personalization under different degrees of heterogeneity. We find that besides the client-specific data distribution, the distribution bias between the unique data distribution of each client and that of the whole population is another critical factor that prominently impacts these two performances. Motivated by the above finding, we propose PFed-DBA, a novel PFL framework that effectively perceives this distribution bias to guide the training process. Concretely, we design the PFL models as a skip-connection network between a shared module for learning the shared representations delivering the common distribution of data across all clients and a personalized module for learning the personalized representations of the heterogeneous distribution bias. Then, we devise corresponding loss functions, aggregation strategy, and updating strategy in order to make the two modules intelligently complement each other. Moreover, we conduct extensive experiments to evaluate the effectiveness of PFed-DBA. The results show that PFed-DBA improves model accuracy to 12.34% at best compared with the state-of-the-art.}
}


@inproceedings{DBLP:conf/iwqos/WangLLZW24,
	author = {Qiang Wang and
                  Laiyi Li and
                  Weile Luo and
                  Yijia Zhang and
                  Bingqiang Wang},
	title = {{DSO:} {A} {GPU} Energy Efficiency Optimizer by Fusing Dynamic and
                  Static Information},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--6},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682917},
	doi = {10.1109/IWQOS61813.2024.10682917},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/WangLLZW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Increased reliance on graphics processing units (GPUs) for high-intensity computing tasks raises challenges regarding energy consumption. To address this issue, dynamic voltage and frequency scaling (DVFS) has emerged as a promising technique for conserving energy while maintaining the quality of service (QoS) of GPU applications. However, existing solutions using DVFS are hindered by inefficiency or inaccuracy as they depend either on dynamic or static information respectively, which prevents them from being adopted to practical power management schemes. To this end, we propose a novel energy efficiency optimizer, called DSO, to explore a light weight solution that leverages both dynamic and static information to model and optimize the GPU energy efficiency. DSO firstly proposes a novel theoretical energy efficiency model which reflects the DVFS roofline phenomenon and considers the tradeoff between performance and energy. Then it applies machine learning techniques to predict the parameters of the above model with both GPU kernel runtime metrics and static code features. Experiments on modern DVFS-enabled GPUs indicate that DSO can enhance energy efficiency by 19% whilst maintaining performance within a 5% loss margin.}
}


@inproceedings{DBLP:conf/iwqos/ZhanZQ24,
	author = {Furong Zhan and
                  Yangming Zhao and
                  Chunming Qiao},
	title = {Towards High-performance Distributed Quantum Computing with Qubit
                  Placement and Provisioning},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682847},
	doi = {10.1109/IWQOS61813.2024.10682847},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/ZhanZQ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In Distributed Quantum Computing (DQC), quantum bits (qubits) used in a task may be distributed on multiple Quantum Computers (QCs) connected by a Quantum Data Network (QDN). When we have to perform a quantum gate operation involving two qubits on different QCs, an Entanglement Connection (EC) has to be established between these two QCs. Since quantum gate operations can be performed at the data speed, the completion time of a DQC task is dominated by the time to establish ECs.To minimize the DQC task completion time, we propose QuPEP to jointly optimize data qubit (i.e., dbit) placement (that determines the number of ECs we have to establish between each pair of QCs) and entangled qubit (i.e., ebit) provisioning (that minimizes the time to establish each EC). QuPEP has an offline algorithm to optimize the dbit placement based on Genetic Simulated Annealing (GSA) and an online algorithm to optimize ebit provisioning based on Lagrange’s relaxation and the stochastic gradient descent method. By setting the fitness of each chromosome in GSA as the minimum DQC task completion time that can be achieved by the proposed online ebit provisioning scheme, QuPEP joints dbit placement and ebit provisioning. Extensive simulations show that compared with only optimizing dbit placement or ebit provisioning, QuPEP can reduce the DQC task completion time by up to 38% and 95%, respectively.}
}


@inproceedings{DBLP:conf/iwqos/LiuHLLLJW24,
	author = {Jingling Liu and
                  Jiawei Huang and
                  Yijun Li and
                  Zhaoyi Li and
                  Wenjun Lyu and
                  Wenchao Jiang and
                  Jianxin Wang},
	title = {{SGC:} Similarity-Guided Gradient Compression for Distributed Deep
                  Learning},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--6},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682863},
	doi = {10.1109/IWQOS61813.2024.10682863},
	timestamp = {Thu, 24 Oct 2024 10:01:46 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/LiuHLLLJW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The collective communication has become the bottleneck of large-scale distributed deep learning due to the huge volume of gradients aggregated during the training process. Despite much recent progress in reducing traffic volume by compressing the stochastic gradients inside each training worker, how to share the inter-worker data redundancy to alleviate communication overhead has remained elusive. In this paper, we reveal that most gradients have a great similarity with close value among training workers. From this hypothesis, we propose a Similarity-guided Gradient Compression framework named SGC which skips aggregating the similar gradients among each worker which utilizes local one rather than average value to save communication expenses. Each worker utilizes local SGC firstly quantifies the similarity of gradients among workers, and then elaborately adjusts the aggregation frequency of similar gradients without hurting DNN model accuracy. Meanwhile, we theoretically analyze the convergency accuracy of SGC. The comprehensive evaluation demonstrates that SGC outperforms the state-of-the-art schemes by up to 47% in convergence time.}
}


@inproceedings{DBLP:conf/iwqos/WangLLL24,
	author = {Yikun Wang and
                  Hewu Li and
                  Zeqi Lai and
                  Jihao Li},
	title = {StarMaze: Ring-based Attack in Satellite Internet Constellations},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682867},
	doi = {10.1109/IWQOS61813.2024.10682867},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/WangLLL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent years, the rapid proliferation of satellite Internet constellations (SICs) operating in low-earth orbit (LEO) has attracted attention due to their charming merits. Despite the potential of LEO satellite networks, the security aspects of their operation have largely been neglected.Composed by a large number of satellites, these mega-constellation networks are considered to be performant and resilient. In this paper, however, we challenge this intuitive notion by proposing STARMAZE, an impactful ring-based attack which could lead to severe consequences such as network service disruption or causing routing detours. Unlike other existing attack methods, STARMAZE removes the extra assumptions of specific routing algorithms and has the periodicity which contribute to lower-cost yet long-lasting launch of attack. Simultaneously, we also introduce the concept of intentional gaps to emphasize our consideration of real-world attacks, where attackers may not always succeed in precisely targeting all links. Comprehensive evaluations, grounded in practical constellation insights, show that impairing just 2.5% of Inter-Satellite Links (ISLs) can markedly amplify the average propagation delay of chosen long-distance communication pairs by over 63%. Moreover, during more than 47% of the observation time, the value can even reach over 312%.}
}


@inproceedings{DBLP:conf/iwqos/ChenCWWZFMTKL24,
	author = {Long Chen and
                  Yi Ching Chou and
                  Hengzhi Wang and
                  Feng Wang and
                  Haoyuan Zhao and
                  Hao Fang and
                  Sami Ma and
                  Feilong Tang and
                  Linghe Kong and
                  Jiangchuan Liu},
	title = {{TASRI:} Toward Traffic-Aware, Sustainable and Reliable {ISL} Provisioning
                  for {LEO} Satellite Constellation Networking},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--6},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682947},
	doi = {10.1109/IWQOS61813.2024.10682947},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/ChenCWWZFMTKL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Inter-Satellite Links (ISLs) are key for worldwide communication and efficient use of space networks in the future 6G network. However, they face challenges in sustainability and reliability. Reducing ISLs saves energy and extends battery life, which is critical since satellite batteries are hard to replace. More ISLs, however, can make the system more reliable but at the cost of higher energy use, especially problematic when traffic is uneven, speeding up battery wear. To tackle this dilemma, we for the first time develop a Traffic-Aware, Sustainable and Reliable ISL provisioning (TASRI) framework for LEO satellite constellation networks. In TASRI, ISLs can be flexibly switched on and off to better accommodate various traffic conditions as well as reliability and sustainability. We formulate the ISL provisioning problem based on the sustainability-oriented weight model and then propose an on-demand topology evolving algorithm. Extensive real-world deployment-based simulation results show that, compared to the state-of-the-art, our TASRI can substantially reduce battery life consumption, while achieving comparable reliability with considerably fewer ISLs.}
}


@inproceedings{DBLP:conf/iwqos/LiangLGLZW24,
	author = {Yuzhu Liang and
                  Guo Li and
                  Jianxiong Guo and
                  Qin Liu and
                  Xi Zheng and
                  Tian Wang},
	title = {Efficient Request Scheduling in Cross-Regional Edge Collaboration
                  via Digital Twin Networks},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--6},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682932},
	doi = {10.1109/IWQOS61813.2024.10682932},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/LiangLGLZW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In cloud computing, user requests sent to centralized servers often encounter delay due to network unpredictability, impacting the Quality of Service (QoS) for time-sensitive applications. We propose edge collaboration, utilizing the coordination of edge nodes within regions to handle requests more efficiently and reduce latency. However, edge nodes across different regions struggle with lack of immediate data on resources cached elsewhere, complicating inter-regional request scheduling. To address it, we introduce a federated digital twin model that creates a network linking edge nodes to reflect and update resource statuses in real time. Additionally, we refine the Dijkstra algorithm to optimize routing to the nearest edge nodes based on current network conditions, thereby minimizing delay. Our analyses show that our method significantly lowers delay, enhancing effectiveness over baseline methods.}
}


@inproceedings{DBLP:conf/iwqos/WangLKTL24,
	author = {Rongrong Wang and
                  Duc Van Le and
                  Jikun Kang and
                  Rui Tan and
                  Xue Liu},
	title = {Incentive Temperature Control for Green Colocation Data Centers via
                  Reinforcement Learning},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--6},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682849},
	doi = {10.1109/IWQOS61813.2024.10682849},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/WangLKTL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Increasing supply air temperatures is a rule-of-thumb approach to reduce cooling energy usage of data centers (DCs). However, colocation DCs are short of incentive programs to move tenants from the current over-cooling strategy despite the expanding allowable temperature ranges of the computing equipment. This paper considers an essential incentive mechanism, in which the DC operator offers monetary incentives to offset tenants’ electricity payments. We propose an encoder-embedded multi-agent reinforcement learning solution to let the operator agent and tenant agents collaboratively find their policies for deciding the incentives and supply air temperatures, respectively, which are coupled in determining the DC’s total cooling power usage. The solution does not require the cooling power model, which is complex and in general unavailable in practice. Moreover, as each tenant agent learns in the other tenants’ latent state spaces defined by their pre-trained variational autoencoders, only encoded tenants’ states are exchanged, thereby mitigating information leakage concerns. Extensive trace-driven evaluation and comparison with three baselines show that our solution effectively incentivizes tenants to move from the over-cooling strategy and achieves substantial cooling power savings.}
}


@inproceedings{DBLP:conf/iwqos/YangZLGHDLL24,
	author = {Tianjian Yang and
                  Hao Zhou and
                  Shuo Liu and
                  Kaiwen Guo and
                  Yiwen Hou and
                  Haohua Du and
                  Zhi Liu and
                  Xiang{-}Yang Li},
	title = {{SGSM:} {A} Foundation-model-like Semi-generalist Sensing Model},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--6},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682922},
	doi = {10.1109/IWQOS61813.2024.10682922},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/YangZLGHDLL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The significance of intelligent sensing systems is growing in the realm of smart services. These systems extract relevant signal features and generate informative representations for particular tasks. However, building the feature extraction component for such systems requires extensive domain-specific expertise or data. The exceptionally rapid development of foundation models is likely to usher in newfound abilities in such intelligent sensing. We propose a new scheme for sensing model, which we refer to as semi-generalist sensing model (SGSM). SGSM is able to semiautomatically solve various tasks using relatively less task-specific labeled data compared to traditional systems. Built through the analysis of the common theoretical model, SGSM can depict different modalities, such as the acoustic and Wi-Fi signal. Experimental results on such two heterogeneous sensors illustrate that SGSM functions across a wide range of scenarios, thereby establishing its broad applicability. In some cases, SGSM even achieves better performance than sensor-specific specialized solutions. Wi-Fi evaluations indicate a 20% accuracy improvement when applying SGSM to an existing sensing model.}
}


@inproceedings{DBLP:conf/iwqos/GanCZZZZCG24,
	author = {Zuo Gan and
                  Chen Chen and
                  Jiayi Zhang and
                  Gaoxiong Zeng and
                  Yifei Zhu and
                  Jieru Zhao and
                  Quan Chen and
                  Minyi Guo},
	title = {{PAS:} Towards Accurate and Efficient Federated Learning with Parameter-Adaptive
                  Synchronization},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682875},
	doi = {10.1109/IWQOS61813.2024.10682875},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/GanCZZZZCG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated Learning (FL) is a distributed paradigm that supports collaborated model training while preserving data privacy, where clients periodically synchronize their local gradients once after multiple local iterations. Due to non-uniform data distribution and poor network condition, FL processes often suffer degraded training accuracy and efficiency. In this work, we analyze the microscopic parameter variation behaviors in FL, and find that an effective method to improve FL accuracy is to switch to more frequent synchronization at proper moments. Moreover, such moments can be detected from gradient characteristics, and are heterogeneous across different parameters. Motivated by such observations, we propose Parameter-Adaptive Synchronization (PAS), a FL scheme that adaptively tunes the synchronization period for each scalar parameter. The benefits of PAS are two-fold: By switching to more frequent synchronization when necessary, we can improve the FL training accuracy; by synchronizing different parameters independently, we can enable communication-computation overlapping and enhance the network utilization. We implemented PAS atop PyTorch, and extensive experiments show that it can substantially improve FL performance in both accuracy and communication efficiency.}
}


@inproceedings{DBLP:conf/iwqos/DuZTQ24,
	author = {Jingshun Du and
                  Chaokun Zhang and
                  Tao Tang and
                  Wenyu Qu},
	title = {Learning-Based Transport Control Adapted to Non-Stationarity for Real-Time
                  Communication},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682855},
	doi = {10.1109/IWQOS61813.2024.10682855},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/DuZTQ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The rapid development of real-time communications (RTC) has created many challenges for designing a proper transport control module, which determines how much media data can be sent in real time. Reinforcement learning (RL) -based transport control algorithms have shown great potential, but still face some unique challenges. For example, accurate bandwidth prediction is often necessary but it is difficult to guarantee accuracy due to bandwidth non-stationarity. In addition, how to alleviate the cold-start and overestimation problems of learning-based algorithms to achieve higher training efficiency is also a headache for researchers. In this work, we propose a new training framework that leverages the advanced Transformer model to capture the non-stationarity of the bandwidth sequence and improve the bandwidth prediction accuracy, while using knowledge distillation and transfer learning techniques to train the RL model efficiently and alleviate the cold-start problem of the model in the training environment. Besides, we employ the Double-Q learning mechanism to suppress the overestimation problem and further enhance the training efficiency. Based on this framework, we have trained a new RTC transport control algorithm NSAC and test it on our own platform. The experiments prove that NSAC adapts better to the unstable network environment than the state-of-the-art solutions. In conditions of weak network, the video throughput experiences a 14.11% increase, accompanied by reductions of 5.64%, 28.12%, and 25.86% in delay, loss rate, and stall rate, respectively. These improvements notably enhance the quality of user experience.}
}


@inproceedings{DBLP:conf/iwqos/WangLWLHFWSLX24,
	author = {Ye Wang and
                  Yunpeng Liu and
                  Ningtao Wang and
                  Peiyang Li and
                  Jiahao Hu and
                  Xing Fu and
                  Weiqiang Wang and
                  Kun Sun and
                  Qi Li and
                  Ke Xu},
	title = {Enhancing Fraud Transaction Detection via Unlabeled Suspicious Records},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682918},
	doi = {10.1109/IWQOS61813.2024.10682918},
	timestamp = {Mon, 14 Oct 2024 08:21:03 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/WangLWLHFWSLX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Deep learning-based classifiers have been widely used in the field of financial fraud transaction detection. However, training a high-performance classifier for fraud detection is challenging due to the lack of sufficient labeled fraud data. Particularly, it is difficult to detect stealthy fraud transactions that closely mimic benign user behaviors. We observe that the suspicious transactions identified by the online detection system can augment the feature space to improve the detection performance of machine learning-based models. In this paper, we propose a new framework GIANTESS to leverage suspicious transactions to augment the feature space and thus enhance the detection of stealthy fraud transactions. Our semi-supervised approach combines both labeled transactions and unlabeled suspicious transactions to train a detection model. Specifically, it first estimates pseudo labels of suspicious transactions and then combines the pseudo labels with ground truth labels to train the detection model. We conduct experiments on two real-world datasets to demonstrate the effectiveness of our proposed method on detecting stealthy fraud transactions. The experimental results show that GIANTESS successfully improves the recall by up to 6.3% at the fixed low false positive rate of 1%. We also perform a 9-week deployment test of our system in a real-world online payment platform to demonstrate the performance of GIANTESS.}
}


@inproceedings{DBLP:conf/iwqos/DengLL24,
	author = {Qian Deng and
                  Sihan Li and
                  Wenping Liu},
	title = {On Simultaneous Recognition and Locating of Contextual Objects with
                  Unmodulated Acoustic Signals Using Machine Learning},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--2},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682881},
	doi = {10.1109/IWQOS61813.2024.10682881},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/DengLL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper examines the problem of simultaneously recognizing and locating contextual objects via using unmodulated acoustic signals from the working contextual objects recorded by the COTS smartphones of users. We exploit the frequency and power features of these signals to build a Mel-frequency cepstral coefficients (MFCC) dataset for contextual objects, and constructs a classifier for contextual object recognition by using BiLSTM and a regression model for object-to-device distance computation by using LightGBM, which is then used for object locating with the help of user’s trace. Extensive experiments show that the proposed approach achieves high recognition accuracy and locating accuracy, even when there are ambient noises or the sampling time span of accoustic signals varies.}
}


@inproceedings{DBLP:conf/iwqos/MaTLX24,
	author = {Jialiang Ma and
                  Chunlin Tian and
                  Li Li and
                  Chengzhong Xu},
	title = {FedMG: {A} Federated Multi-Global Optimization Framework for Autonomous
                  Driving Control},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682844},
	doi = {10.1109/IWQOS61813.2024.10682844},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/MaTLX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Control is a critical module of autonomous driving systems, which ensures safety and enhances the human-machine interface. Due to the diverse control demands dictated by different driving scenarios, autonomous vehicles require a data-intensive, adaptive, and intelligent controller. To speed up the control process and improve the performance in different scenarios, we introduce a novelty federated learning framework FedMG, which efficiently coordinates diverse vehicles to train a collaboratively models while preserving data privacy to tune the control process. Through detailed analysis of driving scenarios, vehicles are clustered to different groups based on driving scenarios to seek a balance between data quality and communication efficiency. It enables the consolidation of several global models, each optimized for peak performance, thereby enhancing the overall system’s effectiveness. Extensive experiments with different numbers of vehicles and a variety of driving scenarios demonstrate the effectiveness of FedMG. The framework significantly reduces cumulative driving errors, achieving reductions ranging from 5.42% to 76.43%, while improving user comfort, with improvements ranging from 2.23% to 34.61% over baselines.}
}


@inproceedings{DBLP:conf/iwqos/ChenTLLYYLXYW24,
	author = {Long Chen and
                  Feilong Tang and
                  Xu Li and
                  Jiacheng Liu and
                  Yichuan Yu and
                  Yanqin Yang and
                  Jie Liu and
                  Wenchao Xu and
                  Han Yu and
                  Hengzhi Wang},
	title = {MobiShare: Efficient Decentralized Data Sharing for Mobile Devices},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--6},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682884},
	doi = {10.1109/IWQOS61813.2024.10682884},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/ChenTLLYYLXYW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Existing peer-to-peer data-sharing methods suffer from low data delivery efficiency and scalability due to the naive data request/response procedure and the high redundant data transmission rate. It becomes even worse in large-scale mobile networks considering the limited resources of mobile devices. To address this issue, this paper presents MobiShare, an efficient decentralized data-sharing approach for mobile devices, which allows users to not only share the data but also the data generation methods. To achieve MobiShare, we introduce a function block encoding method and a data request method to enhance sharing efficiency, minimizing costs for decentralized data sharing. We propose a credit payment mechanism where congested devices can send data vouchers instead of actual data, containing the expected transmission time. Based on the load and bandwidth of devices, we build the optimized dissemination tree with data vouchers in a decentralized way to improve scalability. Evaluation results show that MobiShare avoids redundant transmission. It greatly shortens transmission completion time and lowers energy consumption with limited network resources.}
}


@inproceedings{DBLP:conf/iwqos/ChenZZ24,
	author = {Chuyi Chen and
                  Zhe Zhang and
                  Yanchao Zhao},
	title = {Leave No One Behind: Unleashing Stragglers' Potential for Accurate
                  and Realtime Asynchronous Federated Learning},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682899},
	doi = {10.1109/IWQOS61813.2024.10682899},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/ChenZZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Asynchronous Federated Learning (AFL) is a promising technique to enable efficient and flexible distributed learning across heterogeneous devices. However, AFL faces the challenge of handling stragglers, i.e., devices that have high latency or low participation rate, which can degrade the convergence speed and accuracy of the global model. Existing solutions either discard or penalize the updates from stragglers, which may result in losing valuable information or introducing bias. In this paper, we propose FedVDA, a novel AFL framework that significantly improved the QoS of AFL in terms of model accuracy and training time cost by effectively utilizing and compensating for the updates from stragglers. Specifically, Fed-VDA introduced the dynamic window protocol that dynamically adjusts the server’s waiting time in each round based on the estimated completion time of the devices. We further designed a version control mechanism that corrects the stale gradients of the stragglers by supplementing the missing training rounds. Extensive experiments on three public datasets demonstrate that FedVDA achieves, on average, 2.7× faster convergence speed and 5.1% higher accuracy than state-of-the-art AFL methods. Moreover, we open-sourced FedVDA 1 and show that it is non-intrusive and highly scalable, which enables easy integration with other AFL algorithms and improves their QoS with no-pain in large-scale federated learning systems.}
}


@inproceedings{DBLP:conf/iwqos/LinL24,
	author = {Changyao Lin and
                  Jie Liu},
	title = {{COS:} Cross-Processor Operator Scheduling for Multi-Tenant Deep Learning
                  Inference},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682900},
	doi = {10.1109/IWQOS61813.2024.10682900},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/LinL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Multi-tenant inference, as a prevalent inference paradigm nowadays, requires deploying multiple deep learning models on the hardware platform to concurrently process inference tasks. Modern platforms are typically equipped with various heterogeneous processors, such as CPU-GPU platform. To reduce resource contention and improve Quality of Service (QoS) in the multi-tenant scenario, existing work has studied cross-processor inference at the model- and layer-level. However, coarse-grained scheduling cannot flexibly account for subtle resource fluctuations, which may lead to task blockages and incur significant processor switching overheads. Such work usually requires extensive modification and retraining of the models. Therefore, we propose a finer-grained operator-level cross-processor scheduling framework COS, which can more precisely divide the computational workloads and switching overheads for the tenants, without modifying or retraining. We introduce a novel intermediate representation to abstract and simplify the scheduling problem, and propose an efficient two-phase search algorithm. COS is automated and easy-to-scale, through experiments on various heterogeneous hardware platforms and models, we demonstrate that COS is more flexible and effective than layer-level scheduling, and achieves higher throughput than single-processor processing in the multi-tenant scenario. Furthermore, COS is an offline optimization method, and its overhead is highly acceptable.}
}


@inproceedings{DBLP:conf/iwqos/LinZYLZFSG24,
	author = {Xue Lin and
                  Zhibo Zhang and
                  Peining Yue and
                  Haoran Li and
                  Jin Zhang and
                  Baoyu Fan and
                  Huayou Su and
                  Xiaoli Gong},
	title = {SyncIntellects: Orchestrating {LLM} Inference with Progressive Prediction
                  and QoS-Friendly Control},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682949},
	doi = {10.1109/IWQOS61813.2024.10682949},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/LinZYLZFSG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Large Language Models (LLMs) have shown impressive capabilities, especially in the realm of Human-Machine Chat Systems. Nevertheless, these models entail significant computational expenses, particularly when generating tokens. As a remedy to enhance system throughput and hardware utilization, batch scheduling is commonly adopted. This method involves initiating a batch of inference requests concurrently and then waiting for their completion. A significant challenge encountered with task-batching is the need to group requests with similar response lengths. However, accurately predicting response length proves to be a daunting task, and the inherent variability in response length leads to suboptimal resource utilization.In this paper, we introduce SyncIntellects, a framework designed to orchestrate Large Language Model (LLM) Inference with fine-grained response length prediction and Quality of Service (QoS)-Friendly length control. Specifically, SyncIntellects enhances response length prediction by leveraging embedding information during token generation through a transformer-based model. Subsequently, a dynamic response length controller based on Prompt Engineering techniques is employed to ensure alignment of response lengths without compromising the QoS of the responses. We have implemented SyncIntellects and seamlessly integrated it with a chatbot engine based on the llama2 7B model. We conduct comprehensive experiments on an NVIDIA A100-based testbed, and the results demonstrate a significant reduction in latency by 17.76% on average, along with an increase in throughput by 9.34%.}
}


@inproceedings{DBLP:conf/iwqos/YanYSFY24,
	author = {Dawei Yan and
                  Panlong Yang and
                  Fei Shang and
                  Nikolaos M. Freris and
                  Yubo Yan},
	title = {Anteumbler: Non-Invasive Antenna Orientation Error Measurement for
                  WiFi APs},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682937},
	doi = {10.1109/IWQOS61813.2024.10682937},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/YanYSFY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The performance of WiFi-based localization systems is affected by the spatial accuracy of WiFi AP. Compared with the imprecision of AP location and antenna separation, the imprecision of AP’s or antenna’s orientation is more important in real scenarios, including AP rotation and antenna irregular tilt. In this paper, we propose Anteumbler that non-invasively, accurately and efficiently measures the orientation of each antenna in physical space. Based on the fact that the received power is maximized when a Tx-Rx antenna pair is perfectly aligned, we construct a spatial angle model that can obtain the antennas’ orientations without prior knowledge. However, the sampling points of traversing the spatial angle need to cover the entire space. We use the orthogonality of antenna directivity and polarization and adopt an iterative algorithm to reduce the sampling points by hundreds of times, which greatly improves the efficiency. To achieve the required antenna orientation accuracy, we eliminate the influence of propagation distance using a dual plane intersection model and filter out ambient noise. Our real-world experiments with six antenna types, two antenna layouts and two antenna separations show that Anteumbler achieves median errors below 6 ° for both elevation and azimuth angles, and is robust to NLoS and dynamic environments. Last but not least, for the reverse localization system, we deploy Anteumbler over LocAP and reduce the antenna separation error by 10 mm, while for the user localization system, we deploy Anteumbler over SpotFi and reduce the user localization error by more than 1 m.}
}


@inproceedings{DBLP:conf/iwqos/ChenLXZLH24,
	author = {Juehao Chen and
                  Shiyi Li and
                  Wen Xia and
                  Shuaipeng Zhang and
                  Qicong Lin and
                  Haojun Hu},
	title = {Greedy Transfer Planning Search For Improving Repair Throughput of
                  RDP-like Coded Storage Clusters},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682840},
	doi = {10.1109/IWQOS61813.2024.10682840},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/ChenLXZLH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the increasing scale of data and user demands for low latency, the development of large-scale clusters has become a trend. To ensure high availability of data in data clusters, XOR-based erasure code fault-tolerant technologies are widely used due to their low storage and computational overhead. Meanwhile, as the scale of clusters ranges from hundreds to thousands, the probability of multiple node failures is not negligible. This can lead to serious consequences, such as data loss, and should be recovered as soon as possible. However, codes such as RDP and EVENODD can easily lead to network congestion when recovering in the event of concurrent failures, making it challenging to recover quickly.To address this issue, we propose a novel network transfer plan search algorithm, Greedy Row-Diagonal Parity Search or GRS for short. GRS optimally allocates the network traffic generated during the repair process by greedily utilizing idle bandwidth and leveraging the commutative property of XOR operations, ensuring a more even distribution of traffic across the cluster network, which improves the repair throughput.We build a prototype in a distributed erasure-coded cluster and conduct experiment evaluation. The experimental results indicate that, compared to existing repair optimization methods, GRS improves repair throughput by 230%-880%.}
}


@inproceedings{DBLP:conf/iwqos/HeNTWYWYP24,
	author = {Guanglei He and
                  Xiaohui Nie and
                  Ruming Tang and
                  Kun Wang and
                  Zhaoyang Yu and
                  Xidao Wen and
                  Kanglin Yin and
                  Dan Pei},
	title = {Guardian of the Resiliency: Detecting Erroneous Software Changes Before
                  They Make Your Microservice System Less Fault-Resilient},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682951},
	doi = {10.1109/IWQOS61813.2024.10682951},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/HeNTWYWYP24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The microservice system’s resilience is crucial for ensuring the quality of service. Nowadays, software changes are frequent and error-prone, and erroneous software changes could reduce microservice systems’ resilience to handle faults, leading to service failures and negatively impacting user experience. To better understand erroneous software changes, we conducted an empirical study on 256 real-world incidents from four famous microservice systems. Our quantitative results indicate that 37.87% of erroneous software changes make the microservice systems less fault-resilient; that is, when a fault (e.g., network fluctuation, high CPU usage, etc.) happens in the system after the software change, the services are more likely to experience failures. We refer to these software changes as Erroneous Software Changes that Reduce fault Resilience(ESCR). Traditional methods struggle to detect ESCRs effectively because the occurrence of faults is unpredictable and can hardly be in their post-change monitoring windows. In this paper, we propose a novel framework named ResilienceGuardian, aiming to detect ESCRs before they make microservice systems less fault-resilient. The key idea is utilizing fault injection techniques to evaluate systems’ fault resilience in the staging environment and then training lightweight classifiers of KPI segment pairs to detect ESCRs. The performance of ResilienceGuardian is systematically evaluated on three datasets with various faults and erroneous software changes. The results show that ResilienceGuardian significantly outperforms all the baselines with a 0.9 F1-score in identifying ESCRs and reduces the training time by 56.23% to 97.53%. Besides, ResilienceGuardian can achieve minute-level ESCR detection in large-scale microservice systems.}
}


@inproceedings{DBLP:conf/iwqos/YangLCZ24,
	author = {Shu Yang and
                  Yaofeng Liu and
                  Laizhong Cui and
                  Runsu Zhu},
	title = {{MAEON:} An Efficient Weather-Aware Ocean Network Routing Scheme based
                  on Multi-Agent Reinforcement Learning},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682930},
	doi = {10.1109/IWQOS61813.2024.10682930},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/YangLCZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Ocean network communication is more and more important nowadays. However, it faces significant challenges due to its heterogeneity, low reliability, and narrow bandwidth. Compared with traditional networks, the problem worsens under severe weather conditions because communication channels, e.g., microwave links, may degrade badly due to weather changes. While many ocean applications put higher QoS (Quality of Service) requirements on communications, it is difficult to meet them due to fluctuating weather changes. Thus, it is more challenging to model and operate the ocean network as more factors may influence the performance.Currently, artificial intelligence opens up new possibilities to meet the challenges because it can adapt to the dynamic changes of the network. In this paper, we formulate the problem by establishing a model between network performance and weather conditions. We try to optimize network utility given the traffic matrix and important weather factors, such as rain, atmospheric absorption, and clouds. To solve the problem, we propose a two-stage and multi-agent optimization algorithm named MAEON (Multi-Agent Efficient Ocean Network). We conduct a comprehensive simulation using generated network topology traffic and real-world weather datasets. We also carry out a case study with datasets from a real-world scenario. The results show that MAEON can improve performance by 21.5% compared with traditional algorithms.}
}


@inproceedings{DBLP:conf/iwqos/ZengZJHYM24,
	author = {Yifan Zeng and
                  Ruiting Zhou and
                  Lei Jiao and
                  Ziyi Han and
                  Jieling Yu and
                  Yue Ma},
	title = {Efficient Online {DNN} Inference with Continuous Learning in Edge
                  Computing},
	booktitle = {32nd {IEEE/ACM} International Symposium on Quality of Service, IWQoS
                  2024, Guangzhou, China, June 19-21, 2024},
	pages = {1--10},
	publisher = {{IEEE}},
	year = {2024},
	url = {https://doi.org/10.1109/IWQoS61813.2024.10682835},
	doi = {10.1109/IWQOS61813.2024.10682835},
	timestamp = {Sat, 12 Oct 2024 00:13:11 +0200},
	biburl = {https://dblp.org/rec/conf/iwqos/ZengZJHYM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Compressed edge DNN models usually experience decreasing model accuracy when performing inference due to data drift. To maintain the inference accuracy, retraining models with continuous learning is usually employed in the edge. However, online edge DNN inference with continuous learning faces new challenges. First, introducing retraining jobs leads to resource competition with the existing edge inference tasks, which will affect the inference latency. Second, retraining jobs and inference tasks exhibit significant differences in workload and latency requirements. These two jobs cannot adopt the same scheduling policy. To overcome the challenges, we propose an Online scheduling algorithm for INference with Continuous learning (OINC). OINC minimizes the weighted sum of the latency of inference tasks and the completion time of retraining jobs with limited edge resources, while ensuring the satisfaction of the inference task’s service level objective (SLO) and meeting the deadlines of retraining jobs. OINC first reserves a portion of resources to complete all current inference tasks and allocates the remaining resources to retraining jobs. Subsequently, based on the reserved resource ratio, OINC invokes two sub-algorithms to select edges and allocate resources for each inference task and retraining job respectively. Compared with six state-of-the-art algorithms, OINC can reduce the weighted sum by up to 23.7%, and increase the success rate by up to 35.6%.}
}
