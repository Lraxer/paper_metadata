@inproceedings{DBLP:conf/sigmod/Ross21,
	author = {Kenneth A. Ross},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Utilizing (and Designing) Modern Hardware for Data-Intensive Computations:
                  The Role of Abstraction},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {1},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3460535},
	doi = {10.1145/3448016.3460535},
	timestamp = {Mon, 21 Jun 2021 11:48:44 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/Ross21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Modern information-intensive systems, including data management systems, operate on data that is mostly resident in RAM. As a result, the data management community has shifted focus from I/O optimization to addressing performance issues higher in the memory hierarchy. In this keynote, I will give a personal perspective of these developments, illustrated by work from my group at Columbia University. I will use the concept of abstraction as a lens through which various kinds of optimizations for modern hardware platforms can be understood and evaluated. Through this lens, some "cute implementation tricks" can be seen as much more than mere implementation details. I will discuss abstractions at various granularities, from single lines of code to whole programming/query languages. I will touch on software and hardware design for data-intensive computations. I will also discuss data processing in a conventional programming language, and how the data management community might contribute to the design of compilers.}
}


@inproceedings{DBLP:conf/sigmod/Tan21,
	author = {Wang{-}Chiew Tan},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Deep Data Integration},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3460534},
	doi = {10.1145/3448016.3460534},
	timestamp = {Mon, 21 Jun 2021 11:48:44 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/Tan21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We are witnessing the widespread adoption of deep learning techniques as avant-garde solutions to different computational problems in recent years. In data integration, the use of deep learning techniques has helped establish several state-of-the-art results in long standing problems, including information extraction, entity matching, data cleaning, and table understanding. In this talk, I will reflect on the strengths of deep learning and how that has helped move the needle in data integration. I will also discuss a few challenges associated with solutions based on deep learning techniques and describe some opportunities for the data management community.}
}


@inproceedings{DBLP:conf/sigmod/Crooks21,
	author = {Natacha Crooks},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {A Client-centric Approach to Transactional Datastores},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {3--5},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3461471},
	doi = {10.1145/3448016.3461471},
	timestamp = {Sun, 04 Aug 2024 19:37:28 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/Crooks21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Traditional brick-and-mortar services are increasingly moving online and companies rely on ever larger data analytics to optimise their business logic. Similarly, most medical practices favour electronic health records over paper documents: 84% of American hospitals store medical records electronically [19], an 8-fold increase since 2008. In this data-driven world, data is money. It must be collected efficiently, even as it spans multiple heterogeneous, geo-distributed sources. Data must be stored reliably, even in the presence of failures. As the sensitivity of the data being stored increases, so does the need to store it securely in the presence of human attacks. Data must also be accessed consistently, even under high load.}
}


@inproceedings{DBLP:conf/sigmod/Schleich21,
	author = {Maximilian Schleich},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Structure-Aware Machine Learning over Multi-Relational Databases},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {6--7},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3461670},
	doi = {10.1145/3448016.3461670},
	timestamp = {Sun, 19 Jan 2025 13:27:33 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/Schleich21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We consider the problem of computing machine learning models over multi-relational databases. The mainstream approach involves a costly repeated loop that data scientists have to deal with on a daily basis: select features from data residing in relational databases using feature extraction queries involving joins, projections, and aggregations; export the training dataset defined by such queries; convert this dataset into the format of an external learning tool; and learn the desired model using this tool. In this thesis, we advocate for an alternative approach that avoids this loop and instead tightly integrates the query and learning tasks into one unified solution. By integrating these two tasks, we can exploit structure in the data and the query to optimize the end-to-end learning problem. We provide a framework for structure-aware learning for a variety of commonly used machine learning models that achieves runtime guarantees that can be asymptotically faster than the mainstream approach that first constructs the training dataset. In practice, this asymptotic gap translates into several orders of magnitude performance improvements over state-of-the-art machine learning packages such as TensorFlow, MADlib, scikit-learn, and mlpack. The thesis is composed of three parts. First, we present the methodology and theoretical foundation of structure-aware learning. Then, we report on the design and implementation of LMFAO, an in-memory engine for structure-aware learning over databases. Finally, we present an extensive experimental evaluation. In following, we briefly highlight each of these three parts.}
}


@inproceedings{DBLP:conf/sigmod/Zamanian21,
	author = {Erfan Zamanian},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Scalable Distributed Transaction Processing on Modern RDMA-enabled
                  Networks},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {8},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3461469},
	doi = {10.1145/3448016.3461469},
	timestamp = {Sun, 19 Jan 2025 13:27:20 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/Zamanian21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The scalability of existing shared-nothing databases quickly degrades in the presence of distributed transactions with the networking being the main reason. When distributed databases were designed, networks had low bandwidth, high latency, and high CPU overhead per message because of the traditional network stack. As a result, distributed database were designed to avoid distributed transactions as much as possible. Yet, with the advent of next generation of high-speed RDMA-enabled networks, it is time to revisit this design mantra of distributed DBMSs. In my thesis, the main focus was thus on the redesign of distributed transaction processing systems by efficiently leveraging modern RDMA-enabled networks. With Remote Direct Memory Access (RDMA), it is possible to bypass the CPU when transferring data from one machine to another. Moreover, the current generation of these networks is already able to provide a bandwidth similar to that of the main memory. However, our first finding is that simply upgrading the network does not automatically yield scalability without redesigning the underlying distributed database. In the quest for building fast, scalable and highly available OLTP databases, my thesis revisited the design of distributed DBMSs for RDMA and made various core contributions to the DBMS community: 1- Do we need a new DBMS architecture? We propose a new abstraction called Network-Attached-Memory (NAM) which fully exploits RDMA for distributed DBMSs. The main idea is to decouple compute and storage to enable independent scalability, and allow compute nodes to access data on the storage nodes using RDMA operations. Using this architecture, physical co-location of compute and storage to improve performance becomes a second class design consideration, as opposed to being a necessity for scalability. 2- Do we need new transaction protocols? Using the NAM architecture, it is possible to design scalable OLTP systems which efficiently leverage low overhead RDMA. However, it requires revisiting existing data structures and transaction protocols as they were designed in the era of slow networks with high per message cost. To this end, we presented the design of our novel scalable OLTP engine called NAM-DB. It implements the very common Snapshot Isolation scheme but tailored for RDMA. For example, NAM-DB builds on a scalable timestamp generation algorithm which efficiently utilizes one-sided RDMA operations to decentralize this task. The experiments on NAM-DB show that distributed transactions can indeed scale, without an inherent bottleneck other than those imposed by the workload itself (as I will discuss next). 3- Do we need new partitioning strategies? The primary goal of existing partitioning techniques in distributed DBMSs is to minimize the number cross-partition transactions, simply because network used to be the dominant bottleneck. In modern networks, however, we found that the new bottleneck which hinders scalability is data contention, while minimizing network communication plays only a subordinate role. To this end, we developed a new solution called Chiller that extends NAM-DB in two directions: (1) a novel commit protocol based on re-ordering transaction operations with the goal of minimizing the lock duration for contended records, and (2) contention-aware partitioning so that the most critical records can be updated without additional coordination. 4- Do we need new high-availability protocols? Finally, we revisited high availability for NAM-DB. Same as for partitioning, the main goal of existing high availability approaches is to minimize the network overhead which is no longer a bottleneck with fast RDMA-enables networks. This calls also for new protocols to fully unleash the potential of RDMA networks for high availability. Hence, as a last contribution we present a novel strongly consistent replication scheme called Active-Memory. Our proposed primary-backup replication algorithm allows an RDMA-based OLTP system to maintain its high performance in the presence of failures through an efficient RDMA-based undo-logging scheme, achieving much better performance compared to the existing techniques.}
}


@inproceedings{DBLP:conf/sigmod/Zhang21,
	author = {Huanchen Zhang},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Memory-Efficient Search Trees for Database Management Systems},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {9},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3461470},
	doi = {10.1145/3448016.3461470},
	timestamp = {Sun, 19 Jan 2025 13:27:28 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/Zhang21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The growing cost gap between DRAM and storage together with increasing database sizes means that database management systems (DBMSs) now operate with a lower memory to storage size ratio than before. On the other hand, modern DBMSs rely on in-memory search trees (e.g., indexes and filters) to achieve high throughput and low latency. These search trees, however, consume a large portion of the total memory available to the DBMS. Existing compression techniques for search trees often rely on general-purpose block compression algorithms such as Snappy and LZ4. These algorithms, however, impose too much computational overhead for in-memory search trees because the DBMS is unable to operate directly on the index data without having to decompress it first. Simply getting rid of all or part of the search trees is also suboptimal because they are crucial to query performance. This dissertation seeks to address the challenge of building compact yet fast in-memory search trees to allow more efficient use of memory in data processing systems. We first present techniques to obtain maximum compression on fast static (i.e., read-optimized) search trees. We identified sources of memory waste in existing trees and designed new succinct data structures to show that we can push the memory consumption of a search tree to the theoretical limit without compromising its query performance. Next, we introduce the hybrid index architecture as a way to efficiently modifying the aforementioned static data structures with bounded and amortized cost in performance and space. Finally, instead of structural compression, we approach the problem from an orthogonal direction by compressing the actual keys. We built a fast string compressor that can encode arbitrary input keys while preserving their order so that search trees can serve range queries directly based on compressed keys. Together, these three pieces form a practical recipe for achieving memory-efficiency in search trees and in DBMSs.}
}


@inproceedings{DBLP:conf/sigmod/AkiliW21,
	author = {Samira Akili and
                  Matthias Weidlich},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {MuSE Graphs for Flexible Distribution of Event Stream Processing in
                  Networks},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {10--22},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457318},
	doi = {10.1145/3448016.3457318},
	timestamp = {Fri, 26 May 2023 07:40:33 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/AkiliW21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Complex event processing (CEP) enables reactive and predictive applications through the continuous evaluation of queries over streams of event data. In a network of event sources, efficient query evaluation is achieved through distribution: Queries are split into operators (query decomposition), which are then assigned to some of the nodes (operator placement). Yet, existing solutions limit the decomposition to the operator hierarchy of a query, ignoring possible rewritings of it, and place each operator at exactly one node in the network. That neglects optimizations based on pattern composition through multiple queries as results are always gathered at a single sink node. In this paper, we propose a new evaluation model for CEP, coined Multi-Sink Evaluation (MuSE) graphs. It incorporates arbitrary projections of queries for distribution and assigns them to potentially many nodes. We prove correctness of query evaluation with MuSE graphs and provide a cost model to assess its efficiency. Since the construction of cost-optimal MuSE graphs is intractable, we present an approximation algorithm and several pruning trategies. Our evaluation results show that MuSE graphs reduce network transmission costs by up to three orders of magnitude over baseline strategies.}
}


@inproceedings{DBLP:conf/sigmod/AlotaibiCDM21,
	author = {Rana Alotaibi and
                  Bogdan Cautis and
                  Alin Deutsch and
                  Ioana Manolescu},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {{HADAD:} {A} Lightweight Approach for Optimizing Hybrid Complex Analytics
                  Queries},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {23--35},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457311},
	doi = {10.1145/3448016.3457311},
	timestamp = {Mon, 21 Jun 2021 11:48:44 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/AlotaibiCDM21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Hybrid complex analytics workloads typically include (i) data management tasks (joins, selections, etc. ), easily expressed using relational algebra (RA)-based languages, and (ii) complex analytics tasks (regressions, matrix decompositions, etc.), mostly expressed in linear algebra (LA) expressions. Such workloads are common in many application areas, including scientific computing, web analytics, and business recommendation. Existing solutions for evaluating hybrid analytical tasks - ranging from LA-oriented systems, to relational systems (extended to handle LA operations), to hybrid systems - either optimize data management and complex tasks separately, exploit RA properties only while leaving LA-specific optimization opportunities unexploited, or focus heavily on physical optimization, leaving semantic query optimization opportunities unexplored. Additionally, they are not able to exploit precomputed (materialized) results to avoid recomputing (part of) a given mixed (RA and/or LA) computation. In this paper, we take a major step towards filling this gap by proposing HADAD, an extensible lightweight approach for optimizing hybrid complex analytics queries, based on a common abstraction that facilitates unified reasoning: a relational model endowed with integrity constraints. Our solution can be naturally and portably applied on top of pure LA and hybrid RA-LA platforms without modifying their internals. An extensive empirical evaluation shows that HADAD yields significant performance gains on diverse workloads, ranging from LA-centered to hybrid.}
}


@inproceedings{DBLP:conf/sigmod/AmagataOH21,
	author = {Daichi Amagata and
                  Makoto Onizuka and
                  Takahiro Hara},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Fast and Exact Outlier Detection in Metric Spaces: {A} Proximity Graph-based
                  Approach},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {36--48},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452782},
	doi = {10.1145/3448016.3452782},
	timestamp = {Sun, 02 Oct 2022 16:15:19 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/AmagataOH21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Distance-based outlier detection is widely adopted in many fields, e.g., data mining and machine learning, because it is unsupervised, can be employed in a generic metric space, and does not have any assumptions of data distributions. Data mining and machine learning applications face a challenge of dealing with large datasets, which requires efficient distance-based outlier detection algorithms. Due to the popularization of computational environments with large memory, it is possible to build a main-memory index and detect outliers based on it, which is a promising solution for fast distance-based outlier detection. Motivated by this observation, we propose a novel approach that exploits a proximity graph. Our approach can employ an arbitrary proximity graph and obtains a significant speed-up against state-of-the-art. However, designing an effective proximity graph raises a challenge, because existing proximity graphs do not consider efficient traversal for distance-based outlier detection. To overcome this challenge, we propose a novel proximity graph, MRPG. Our empirical study using real datasets demonstrates that MRPG detects outliers significantly faster than the state-of-the-art algorithms.}
}


@inproceedings{DBLP:conf/sigmod/AmagataH21,
	author = {Daichi Amagata and
                  Takahiro Hara},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Fast Density-Peaks Clustering: Multicore-based Parallelization Approach},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {49--61},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452781},
	doi = {10.1145/3448016.3452781},
	timestamp = {Mon, 21 Jun 2021 11:48:44 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/AmagataH21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Clustering multi-dimensional points is a fundamental task in many fields, and density-based clustering supports many applications as it can discover clusters of arbitrary shapes. This paper addresses the problem of Density-Peaks Clustering (DPC), a recently proposed density-based clustering framework. Although DPC already has many applications, its straightforward implementation incurs a quadratic time computation to the number of points in a given dataset, thereby does not scale to large datasets. To enable DPC on large datasets, we propose efficient algorithms for DPC. Specifically, we propose an exact algorithm, Ex-DPC, and two approximation algorithms, Approx-DPC and S-Approx-DPC. Under a reasonable assumption about a DPC parameter, our algorithms are sub-quadratic, i.e., break the quadratic barrier. Besides, Approx-DPC does not require any additional parameters and can return the same cluster centers as those of Ex-DPC, rendering an accurate clustering result. S-Approx-DPC requires an approximation parameter but can speed up its computational efficiency. We further present that their efficiencies can be accelerated by leveraging multicore processing. We conduct extensive experiments using synthetic and real datasets, and our experimental results demonstrate that our algorithms are efficient, scalable, and accurate.}
}


@inproceedings{DBLP:conf/sigmod/Amer-YahiaMY21,
	author = {Sihem Amer{-}Yahia and
                  Tova Milo and
                  Brit Youngmann},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Exploring Ratings in Subjective Databases},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {62--75},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457259},
	doi = {10.1145/3448016.3457259},
	timestamp = {Mon, 21 Jun 2021 11:48:44 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/Amer-YahiaMY21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Subjective data links people to content items and reflects who likes or dislikes what. The valuable information this data contains is virtually infinite and satisfies various information needs. Yet, as of today, dedicated tools to explore this data are lacking. In this paper, we develop a framework for Subjective Data Exploration (SDE). Our solution enables the joint exploration of items, people, and people's opinions on items, in a guided multi-step process where each step aggregates the most useful and diverse trends in the form of rating maps. Because of the large search space of possible rating maps, we leverage pruning strategies based on confidence intervals and multi-armed bandits. Our large-scale experiments with human subjects and real datasets, demonstrate the need for dedicated SDE frameworks and the effectiveness and efficiency of our approach.}
}


@inproceedings{DBLP:conf/sigmod/AmiriAA21,
	author = {Mohammad Javad Amiri and
                  Divyakant Agrawal and
                  Amr El Abbadi},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {SharPer: Sharding Permissioned Blockchains Over Network Clusters},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {76--88},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452807},
	doi = {10.1145/3448016.3452807},
	timestamp = {Sun, 19 Jan 2025 13:27:18 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/AmiriAA21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Scalability is one of the main roadblocks to business adoption of blockchain systems. Despite recent intensive research on using sharding techniques to enhance the scalability of blockchain systems, existing solutions do not efficiently address cross-shard transactions. In this paper, we introduce SharPer, a scalable permissioned blockchain system. In SharPer, nodes are clustered and each data shard is replicated on the nodes of a cluster. SharPer supports networks consisting of either crash-only or Byzantine nodes. In SharPer, the blockchain ledger is formed as a directed acyclic graph and each cluster maintains only a view of the ledger. SharPer incorporates decentralized flattened protocols to establish cross-shard consensus. The decentralized nature of the cross-shard consensus in SharPer enables parallel processing of transactions with nonoverlapping clusters. Furthermore, SharPer provides deterministic safety guarantees. The experimental results reveal the efficiency of SharPer in terms of performance and scalability especially in workloads with a low percentage of cross-shard transactions.}
}


@inproceedings{DBLP:conf/sigmod/ArasuCGGKPRRRSS21,
	author = {Arvind Arasu and
                  Badrish Chandramouli and
                  Johannes Gehrke and
                  Esha Ghosh and
                  Donald Kossmann and
                  Jonathan Protzenko and
                  Ravi Ramamurthy and
                  Tahina Ramananandro and
                  Aseem Rastogi and
                  Srinath T. V. Setty and
                  Nikhil Swamy and
                  Alexander van Renen and
                  Min Xu},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {FastVer: Making Data Integrity a Commodity},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {89--101},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457312},
	doi = {10.1145/3448016.3457312},
	timestamp = {Mon, 21 Jun 2021 11:48:44 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/ArasuCGGKPRRRSS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We present FastVer, a high-performance key-value store with strong data integrity guarantees. FastVer is built as an extension of FASTER, an open-source, high-performance key-value store. It offers the same key-value API as FASTER plus an additional verify() method that detects if an unauthorized attacker tampered with the database and checks whether results of all read operations are consistent with historical updates. FastVer is based on a novel approach that combines the advantages of Merkle trees and deferred memory verification. We show that this approach achieves one to two orders of magnitudes higher throughputs than traditional approaches based on either Merkle trees or memory verification. We have formally proven the correctness of our approach in a proof assistant, ensuring that verify() detects any inconsistencies, except if a collision can be found on a cryptographic hash.}
}


@inproceedings{DBLP:conf/sigmod/ArroyueloHNRRS21,
	author = {Diego Arroyuelo and
                  Aidan Hogan and
                  Gonzalo Navarro and
                  Juan L. Reutter and
                  Javiel Rojas{-}Ledesma and
                  Adri{\'{a}}n Soto},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Worst-Case Optimal Graph Joins in Almost No Space},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {102--114},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457256},
	doi = {10.1145/3448016.3457256},
	timestamp = {Sun, 19 Jan 2025 13:27:24 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/ArroyueloHNRRS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We present an indexing scheme that supports worst-case optimal (wco) joins over graphs within compact space. Supporting all possible wco joins using conventional data structures - based on B(+)-Trees, tries, etc. - requires 6 index orders in the case of graphs represented as triples. We rather propose a form of index, which we call a ring, that indexes each triple as a set of cyclic bidirectional strings of length 3. Rather than maintaining 6 orderings, we can use one ring to index them all. This ring replaces the graph and uses only sublinear extra space on top of the graph; in order words, the ring supports worst-case optimal graph joins in almost no space beyond storing the graph itself. We perform experiments using our representation to index a large graph (Wikidata) in memory, over which wco join algorithms are implemented. Our experiments show that the ring offers the best overall performance for query times while using only a small fraction of the space when compared with several state-of-the-art approaches.}
}


@inproceedings{DBLP:conf/sigmod/ArzamasovB21,
	author = {Vadim Arzamasov and
                  Klemens B{\"{o}}hm},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {{REDS:} Rule Extraction for Discovering Scenarios},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {115--128},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457301},
	doi = {10.1145/3448016.3457301},
	timestamp = {Mon, 21 Jun 2021 11:48:44 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/ArzamasovB21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Scenario discovery is the process of finding areas of interest, known as scenarios, in data spaces resulting from simulations. For instance, one might search for conditions, i.e., inputs of the simulation model, where the system is unstable. Subgroup discovery methods are commonly used for scenario discovery. They find scenarios in the form of hyperboxes, which are easy to comprehend. Given a computational budget, results tend to get worse as the number of inputs of the simulation model and the cost of simulations increase. We propose a new procedure for scenario discovery from few simulations, dubbed REDS. A key ingredient is using an intermediate machine learning model to label data for subsequent use by conventional subgroup discovery methods. We provide statistical arguments why this is an improvement. In our experiments, REDS reduces the number of simulations required by 50--75% on average, depending on the quality measure. It is also useful as a semi-supervised subgroup discovery method and for discovering better scenarios from third-party data, when a simulation model is not available.}
}


@inproceedings{DBLP:conf/sigmod/AsudehSJJ21,
	author = {Abolfazl Asudeh and
                  Nima Shahbazi and
                  Zhongjun Jin and
                  H. V. Jagadish},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Identifying Insufficient Data Coverage for Ordinal Continuous-Valued
                  Attributes},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {129--141},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457315},
	doi = {10.1145/3448016.3457315},
	timestamp = {Sun, 02 Oct 2022 16:15:20 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/AsudehSJJ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Appropriate training data is a requirement for building good machine-learned models. In this paper, we study the notion of coverage for ordinal and continuous-valued attributes, by formalizing the intuition that the learned model can accurately predict only at data points for which there are "enough" similar data points in the training data set. We develop an efficient algorithm to identify uncovered regions in low-dimensional attribute feature space, by making a connection to Voronoi diagrams. We also develop a randomized approximation algorithm for use in high-dimensional attribute space. We evaluate our algorithms through extensive experiments on real datasets.}
}


@inproceedings{DBLP:conf/sigmod/AugustineSER021,
	author = {Jees Augustine and
                  Suraj Shetiya and
                  Mohammadreza Esfandiari and
                  Senjuti Basu Roy and
                  Gautam Das},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {A Generalized Approach for Reducing Expensive Distance Calls for {A}
                  Broad Class of Proximity Problems},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {142--154},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457303},
	doi = {10.1145/3448016.3457303},
	timestamp = {Mon, 05 Feb 2024 20:26:56 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/AugustineSER021.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we revisit a suite of popular proximity problems (such as, KNN, clustering, minimum spanning tree) that repeatedly perform distance computations to compare distances during their execution. Our effort here is to design principled solutions to minimize distance computations for such problems in general metric spaces, especially for the scenarios where calling an expensive oracle to resolve unknown distances are the dominant cost of the algorithms for these problems. We present a suite of techniques, including a novel formulation of the problem, that studies how distance comparisons between objects could be modelled as a system of linear inequalities that assists in saving distance computations, multiple graph based solutions, as well as a practitioners guide to adopt our solution frameworks to proximity problems. We compare our designed solutions conceptually and empirically with respect to a broad range of existing works. We finally present a comprehensive set of experimental results using multiple large scale real-world datasets and a suite of popular proximity algorithms to demonstrate the effectiveness of our proposed approaches.}
}


@inproceedings{DBLP:conf/sigmod/BalakrishnanNKZ21,
	author = {Darshana Balakrishnan and
                  Carl Nuessle and
                  Oliver Kennedy and
                  Lukasz Ziarek},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {TreeToaster: Towards an IVM-Optimized Compiler},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {155--167},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3459244},
	doi = {10.1145/3448016.3459244},
	timestamp = {Sun, 19 Jan 2025 13:27:24 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/BalakrishnanNKZ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A compiler's optimizer operates over abstract syntax trees (ASTs), continuously applying rewrite rules to replace subtrees of the AST with more efficient ones. Especially on large source repositories, even simply finding opportunities for a rewrite can be expensive, as optimizer traverses the AST naively. In this paper, we leverage the need to repeatedly find rewrites, and explore options for making the search faster through indexing and incremental view maintenance (IVM). Concretely, we consider bolt-on approaches that make use of embedded IVM systems like DBToaster, as well as two new approaches: Label-indexing and TreeToaster, an AST-specialized form of IVM. We integrate these approaches into an existing just-in-time data structure compiler and show experimentally that TreeToaster can significantly improve performance with minimal memory overheads.}
}


@inproceedings{DBLP:conf/sigmod/BandleG021,
	author = {Maximilian Bandle and
                  Jana Giceva and
                  Thomas Neumann},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {To Partition, or Not to Partition, That is the Join Question in a
                  Real System},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {168--180},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452831},
	doi = {10.1145/3448016.3452831},
	timestamp = {Mon, 21 Jun 2021 11:48:44 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/BandleG021.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {An efficient implementation of a hash join has been a highly researched problem for decades. Recently, the radix join has been shown to have superior performance over the alternatives (e.g., the non-partitioned hash join), albeit on synthetic microbenchmarks. Therefore, it is unclear whether one can simply replace the hash join in an RDBMS or use the radix join as a performance booster for selected queries. If the latter, it is still unknown when one should rely on the radix join to improve performance. In this paper, we address these questions, show how to integrate the radix join in Umbra, a code-generating DBMS, and make it competitive for selective queries by introducing a Bloom-filter based semi-join reducer. We have evaluated how well it runs when used in queries from more representative workloads like TPC-H. Surprisingly, the radix join brings a noticeable improvement in only one out of all 59 joins in TPC-H. Thus, with an extensive range of microbenchmarks, we have isolated the effects of the most important workload factors and synthesized the range of values where partitioning the data for the radix join pays off. Our analysis shows that the benefit of data partitioning quickly diminishes as soon as we deviate from the optimal parameters, and even late materialization rarely helps in real workloads. We thus, conclude that integrating the radix join within a code-generating database rarely justifies the increase in code and optimizer complexity and advise against it for processing real-world workloads.}
}


@inproceedings{DBLP:conf/sigmod/BeedkarQM21,
	author = {Kaustubh Beedkar and
                  Jorge{-}Arnulfo Quian{\'{e}}{-}Ruiz and
                  Volker Markl},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Compliant Geo-distributed Query Processing},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {181--193},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3453687},
	doi = {10.1145/3448016.3453687},
	timestamp = {Sun, 19 Jan 2025 13:27:31 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/BeedkarQM21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we address the problem of compliant geo-distributed query processing. In particular, we focus on dataflow policies that impose restrictions on movement of data across geographical or institutional borders. Traditional ways to distributed query processing do not consider such restrictions and therefore in geo-distributed environments may lead to non-compliant query execution plans. For example, an execution plan for a query over data sources from Europe, North America, and Asia, which may otherwise be optimal, may not comply with dataflow policies as a result of shipping some restricted (intermediate) data. We pose this problem of compliance in the setting of geo-distributed query processing. We propose a compliance-based query optimizer that takes into account dataflow policies, which are declaratively specified using our policy expressions, to generate compliant geo-distributed execution plans. Our experimental study using a geo-distributed adaptation of the TPC-H benchmark data indicates that our optimization techniques are effective in generating efficient compliant plans and incur low overhead on top of traditional query optimizers.}
}


@inproceedings{DBLP:conf/sigmod/BhattacherjeeLH21,
	author = {Souvik Bhattacherjee and
                  Gang Liao and
                  Michael Hicks and
                  Daniel J. Abadi},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {BullFrog: Online Schema Evolution via Lazy Evaluation},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {194--206},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452842},
	doi = {10.1145/3448016.3452842},
	timestamp = {Sun, 06 Oct 2024 21:14:18 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/BhattacherjeeLH21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {BullFrog is a relational DBMS that supports single-step schema migrations --- even those that are backwards incompatible --- without downtime, and without need for advanced warning. When a schema migration is submitted, BullFrog initiates a logical switch to the new schema, but physically migrates affected data lazily, as it is accessed by incoming transactions. BullFrog's internal concurrency control algorithms and data structures enable concurrent processing of schema migration operations with post-migration transactions, while ensuring exactly-once migration of all old data into the physical layout required by the new schema. BullFrog is implemented as an open source extension to PostgreSQL. Experiments using this prototype over a TPC-C based workload (supplemented to include schema migrations) show that BullFrog can achieve zero-downtime migration to non-trivial new schemas with near-invisible impact on transaction throughput and latency.}
}


@inproceedings{DBLP:conf/sigmod/CaiZ0JOZ21,
	author = {Shaofeng Cai and
                  Kaiping Zheng and
                  Gang Chen and
                  H. V. Jagadish and
                  Beng Chin Ooi and
                  Meihui Zhang},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {ARM-Net: Adaptive Relation Modeling Network for Structured Data},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {207--220},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457321},
	doi = {10.1145/3448016.3457321},
	timestamp = {Mon, 03 Mar 2025 21:21:49 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/CaiZ0JOZ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Relational databases are the de facto standard for storing and querying structured data, and extracting insights from structured data requires advanced analytics. Deep neural networks (DNNs) have achieved super-human prediction performance in particular data types, e.g., images. However, existing DNNs may not produce meaningful results when applied to structured data. The reason is that there are correlations and dependencies across combinations of attribute values in a table, and these do not follow simple additive patterns that can be easily mimicked by a DNN. The number of possible such cross features is combinatorial, making them computationally prohibitive to model. Furthermore, the deployment of learning models in real-world applications has also highlighted the need for interpretability, especially for high-stakes applications, which remains another issue of concern to DNNs. In this paper, we present ARM-Net, an adaptive relation modeling network tailored for structured data, and a lightweight framework ARMOR based on ARM-Net for relational data analytics. The key idea is to model feature interactions with cross features selectively and dynamically, by first transforming the input features into exponential space, and then determining the interaction order and interaction weights adaptively for each cross feature. We propose a novel sparse attention mechanism to dynamically generate the interaction weights given the input tuple, so that we can explicitly model cross features of arbitrary orders with noisy features filtered selectively. Then during model inference, ARM-Net can specify the cross features being used for each prediction for higher accuracy and better interpretability. Our extensive experiments on real-world datasets demonstrate that ARM-Net consistently outperforms existing models and provides more interpretable predictions for data-driven decision making.}
}


@inproceedings{DBLP:conf/sigmod/ChackoMJ21,
	author = {Jeeta Ann Chacko and
                  Ruben Mayer and
                  Hans{-}Arno Jacobsen},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Why Do My Blockchain Transactions Fail?: {A} Study of Hyperledger
                  Fabric},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {221--234},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452823},
	doi = {10.1145/3448016.3452823},
	timestamp = {Sun, 19 Jan 2025 13:27:22 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/ChackoMJ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Permissioned blockchain systems promise to provide both decentralized trust and privacy. Hyperledger Fabric is currently one of the most wide-spread permissioned blockchain systems and is heavily promoted both in industry and academia. Due to its optimistic concurrency model, the transaction failure rates in Fabric can become a bottleneck. While there is active research to reduce failures, there is a lack of understanding on their root cause and, consequently, a lack of guidelines on how to configure Fabric optimally for different scenarios. To close this gap, in this paper, we first introduce a formal definition of the different types of transaction failures in Fabric. Then, we develop a comprehensive testbed and benchmarking system, HyperLedgerLab, along with four different chaincodes that represent realistic use cases and a chaincode/workload generator. Using HyperLedgerLab, we conduct exhaustive experiments to analyze the impact of different parameters of Fabric such as block size, endorsement policies, and others, on transaction failures. We further analyze three recently proposed optimizations from the literature, Fabric++, Streamchain and FabricSharp, and evaluate under which conditions they reduce the failure rates. Finally, based on our results, we provide recommendations for Fabric practitioners on how to configure the system and also propose new research directions.}
}


@inproceedings{DBLP:conf/sigmod/CharapkoAD21,
	author = {Aleksey Charapko and
                  Ailidani Ailijiang and
                  Murat Demirbas},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {PigPaxos: Devouring the Communication Bottlenecks in Distributed Consensus},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {235--247},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452834},
	doi = {10.1145/3448016.3452834},
	timestamp = {Sun, 19 Jan 2025 13:27:24 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/CharapkoAD21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Strongly consistent replication helps keep application logic simple and provides significant benefits for correctness and manageability. Unfortunately, the adoption of strongly-consistent replication protocols has been curbed due to their limited scalability and performance. To alleviate the leader bottleneck in strongly-consistent replication protocols, we introduce Pig, an in-protocol communication aggregation and piggybacking technique. Pig employs randomly selected nodes from follower subgroups to relay the leader's message to the rest of the followers in the subgroup, and to perform in-network aggregation of acknowledgments back from these followers. By randomly alternating the relay nodes across replication operations, Pig shields the relay nodes as well as the leader from becoming hotspots and improves throughput scalability. We showcase Pig in the context of classical Paxos protocols employed for strongly consistent replication by many cloud computing services and databases. We implement and evaluate PigPaxos, in comparison to Paxos and EPaxos protocols under various workloads over clusters of size 5 to 25 nodes. We show that the aggregation at the relay has little latency overhead, and PigPaxos can provide more than 3 folds improved throughput over Paxos and EPaxos with little latency deterioration. We support our experimental observations with the analytical modeling of the bottlenecks and show that the communication bottlenecks are minimized when employing only one randomly rotating relay node.}
}


@inproceedings{DBLP:conf/sigmod/ChenL00021,
	author = {Lu Chen and
                  Chengfei Liu and
                  Rui Zhou and
                  Jiajie Xu and
                  Jianxin Li},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Efficient Exact Algorithms for Maximum Balanced Biclique Search in
                  Bipartite Graphs},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {248--260},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3459241},
	doi = {10.1145/3448016.3459241},
	timestamp = {Tue, 21 Mar 2023 20:57:32 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/ChenL00021.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Given a bipartite graph, the maximum balanced biclique (MBB) problem, discovering a mutually connected while disjoint sets of equal size with the maximum cardinality, plays a significant role for mining the bipartite graph and has numerous applications. Despite the NP-hardness of the MBB problem, in this paper, we show that an exact MBB can be discovered extremely fast in bipartite graphs for real applications. We propose two exact algorithms dedicated for small dense and large sparse bipartite graphs respectively. For dense bipartite graphs, an O*(1.3803n) algorithm is proposed. This algorithm in fact can find an MBB very fast for small dense bipartite graphs that are common for applications such as VLSI design. This is because, using our proposed novel techniques, the search can fast converge to sufficiently dense bipartite graphs which we prove to be polynomial-time solvable. For large sparse bipartite graphs typical for applications such as biological data analysis, an O*(1.3803 δ) algorithm is proposed, where δ is only a few hundred for large sparse bipartite graphs with millions of vertices. The indispensible optimization that leads to this time complexity is: we transform a large sparse bipartite graph into a limited number of dense subgraphs such that each of the dense subgraphs has up to δ vertices and then apply our proposed algorithm for dense bipartite graphs on each of the subgraphs. To further speed up this algorithm, tighter upper bounds, faster heuristics and more effective reductions are proposed, allowing an MBB to be discovered within a few seconds for bipartite graphs with millions of vertices. Extensive experiments are conducted on synthetic and real large bipartite graphs to demonstrate the efficiency and effectiveness of our proposed algorithms and techniques.}
}


@inproceedings{DBLP:conf/sigmod/ChenCZL021,
	author = {Peiqing Chen and
                  Dong Chen and
                  Lingxiao Zheng and
                  Jizhou Li and
                  Tong Yang},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Out of Many We are One: Measuring Item Batch with Clock-Sketch},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {261--273},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452784},
	doi = {10.1145/3448016.3452784},
	timestamp = {Mon, 21 Jun 2021 11:48:44 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/ChenCZL021.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Item batch denotes a consecutive sequence of identical items that are close in time in a data stream. It is a useful data stream pattern in cache, burst detection, APT detection, \\etc Basic item batch measurement tasks include membership, cardinality, time span and size. Currently, there is no algorithm tailored for item batch measurement. The greatest challenge lies in accurately estimating the time gap between two consecutive identical items. In this paper, we propose Clock-sketch, a framework that introduces the well-known CLOCK algorithm into item batch measurement. The methodology of Clock-sketch is to clean outdated information as much as possible, while guaranteeing that the information of all items visited within the time window $\\mathcalT $ is preserved. We conduct experiments on three real-world datasets that feature in item batch pattern. We compare the accuracy and throughput performance of our Clock-sketch against the state-of-the-art and two naive approaches without using Clock-sketch technique. Results of item batch activeness show that Clock-sketch outperforms the state-of-the-art SWAMP in generating 50 times less false positive rate when memory is small. All source codes are open-sourced and released at Github.}
}


@inproceedings{DBLP:conf/sigmod/Chen021,
	author = {Xingguang Chen and
                  Sibo Wang},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Efficient Approximate Algorithms for Empirical Entropy and Mutual
                  Information},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {274--286},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457255},
	doi = {10.1145/3448016.3457255},
	timestamp = {Sun, 12 Nov 2023 02:07:18 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/Chen021.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Empirical entropy is a classic concept in data mining and the foundation of many other important concepts like mutual information. However, computing the exact empirical entropy/mutual information on large datasets can be expensive. Some recent research work explores sampling techniques on the empirical entropy/mutual information to speed up the top-k and filtering queries. However, their solution still aims to return the exact answers to the queries, resulting in high computational costs. Motivated by this, in this work, we present approximate algorithms for the top-k queries and filtering queries on empirical entropy and empirical mutual information. The approximate algorithm allows user-specified tunable parameters to control the trade-off between the query efficiency and accuracy. We design effective stopping rules to return the approximate answers with improved query time. We further present theoretical analysis and show that our proposed solutions achieve improved time complexity over previous solutions. We experimentally evaluate our proposed algorithms on real datasets with up to 31M records and 179 attributes. Our experimental results show that the proposed algorithm consistently outperforms the state of the art in terms of computational efficiency, by an order of magnitude in most cases, while providing the same accurate result.}
}


@inproceedings{DBLP:conf/sigmod/Chen0KY21,
	author = {Yueting Chen and
                  Xiaohui Yu and
                  Nick Koudas and
                  Ziqiang Yu},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Evaluating Temporal Queries Over Video Feeds},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {287--299},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452803},
	doi = {10.1145/3448016.3452803},
	timestamp = {Mon, 05 Feb 2024 20:26:57 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/Chen0KY21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recent advances in Computer Vision and Deep Learning have made possible the efficient extraction of structured information from frames of video feeds. As such, a stream of objects and their associated classes along with unique object identifiers derived via object tracking can be generated, providing unique objects as they are captured across frames. In this paper we initiate a study of temporal queries involving objects and their co-occurrences in video feeds. For example, queries that identify video segments during which the same two red cars and the same two humans appear jointly for five minutes are of interest to many applications ranging from law enforcement to security and safety. We take the first step and define such queries in a way that they incorporate certain physical aspects of video capture such as object occlusion. We present an architecture consisting of three layers, namely object detection/tracking, intermediate data generation, and query evaluation. We propose two techniques, Marked Frame Set (MFS) and Sparse State Graph (SSG), to organize all detected objects in the intermediate data generation layer, which effectively, given the queries, minimizes the number of objects and frames that have to be considered during query evaluation. We also introduce an algorithm called SSG-CM that processes incoming frames against the SSG and efficiently prunes objects and frames unrelated to query evaluation, while maintaining all states required for succinct query evaluation. We present the results of a thorough experimental evaluation utilizing both real and synthetic data, establishing the trade-offs between MFS and SSG. We stress various parameters of interest in our evaluation and demonstrate that the proposed query evaluation methodology coupled with the proposed algorithms is capable to evaluate temporal queries over video feeds efficiently, achieving orders of magnitude performance benefits.}
}


@inproceedings{DBLP:conf/sigmod/ChenX0MQZ21,
	author = {Zihao Chen and
                  Chen Xu and
                  Juan Soto and
                  Volker Markl and
                  Weining Qian and
                  Aoying Zhou},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Hybrid Evaluation for Distributed Iterative Matrix Computation},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {300--312},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452843},
	doi = {10.1145/3448016.3452843},
	timestamp = {Sun, 19 Jan 2025 13:27:33 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/ChenX0MQZ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Distributed matrix computation is common in large-scale data processing and machine learning applications. Existing systems that support distributed matrix computation already explore incremental evaluation for iterative-convergent algorithms. However, they are oblivious to the fact that non-zero increments are scattered in different blocks in a distributed environment. Additionally, we observe that incremental evaluation does not always outperform full evaluation. To address these issues, we propose matrix reorganization to optimize the physical layout upon the state-of-art optimized partition schemes, and thereby accelerate the incremental evaluation. More importantly, we propose a hybrid evaluation to efficiently interleave full and incremental evaluation during the iterative process. In particular, it employs a cost model to compare the overhead costs of two types of evaluations and a selective comparison mechanism to reduce the overhead incurred by comparison itself. To demonstrate the efficiency of our techniques, we implement HyMAC, a hybrid matrix computation system based on SystemML. Our experiments show that HyMAC reduces execution time on large datasets by 23% on average in comparison to the state-of-art optimization technique and consequently outperforms SystemML, ScaLAPACK, and SciDB by an order of magnitude.}
}


@inproceedings{DBLP:conf/sigmod/ChenFJ0Z21,
	author = {Zitong Chen and
                  Ada Wai{-}Chee Fu and
                  Minhao Jiang and
                  Eric Lo and
                  Pengfei Zhang},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {{P2H:} Efficient Distance Querying on Road Networks by Projected Vertex
                  Separators},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {313--325},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3459245},
	doi = {10.1145/3448016.3459245},
	timestamp = {Sun, 19 Jan 2025 13:27:34 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/ChenFJ0Z21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The most efficient known approach for shortest distance querying on road networks is via a tree decomposition based 2-hop labeling index. A major challenge here is how to reduce the query time by reducing the label size. To this end, we propose P2H with the novel ideas of projected vertex separators and optimized selection of vertex separators. We also introduce mechanisms for index maintenance for edge weight updating. Our experiments on multiple real road networks show that P2H can greatly reduce the effective label sizes and query time over existing algorithms. For larger datasets, P2H is around twice as efficient as the best known algorithm.}
}


@inproceedings{DBLP:conf/sigmod/ChodpathumwanTR21,
	author = {Yodsawalai Chodpathumwan and
                  Arash Termehchy and
                  Stephen A. Ramsey and
                  Aayam Shrestha and
                  Amy Glen and
                  Zheng Liu},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Structural Generalizability: The Case of Similarity Search},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {326--338},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457316},
	doi = {10.1145/3448016.3457316},
	timestamp = {Tue, 01 Apr 2025 19:09:24 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/ChodpathumwanTR21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Supervised and Unsupervised ML algorithms are widely used over graphs. They use the structural properties of the data to deliver effective results. It is known that the same information can be represented under various graph structures. Thus, these algorithms may be effective on some structural variations of the data and ineffective on others. One would like to have an algorithm that is effective and generalizes to all structural variations of a data graph. We define the concept of structural generalizability for algorithms over graphs. We focus on the problem of similarity search, which is a popular task and the building block of many ML algorithms on graphs, and propose a structurally generalizable similarity search algorithm. As this algorithm may require users to specify features in a rather complex language, we modify this algorithm so that it requires only simple guidance from the user. Our extensive empirical study show that our algorithms are structurally generalizable while being efficient and more effective than current algorithms.}
}


@inproceedings{DBLP:conf/sigmod/DaaseBBR21,
	author = {Bj{\"{o}}rn Daase and
                  Lars Jonas Bollmeier and
                  Lawrence Benson and
                  Tilmann Rabl},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Maximizing Persistent Memory Bandwidth Utilization for {OLAP} Workloads},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {339--351},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457292},
	doi = {10.1145/3448016.3457292},
	timestamp = {Sun, 19 Jan 2025 13:27:29 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/DaaseBBR21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Modern database systems for online analytical processing (OLAP) typically rely on in-memory processing. Keeping all active data in DRAM severely limits the data capacity and makes larger deployments much more expensive than disk-based alternatives. Byte-addressable persistent memory (PMEM) is an emerging storage technology that bridges the gap between slow-but-cheap SSDs and fast-but-expensive DRAM. Thus, research and industry have identified it as a promising alternative to pure in-memory data warehouses. However, recent work shows that PMEM's performance is strongly dependent on access patterns and does not always yield good results when simply treated like DRAM. To characterize PMEM's behavior in OLAP workloads, we systematically evaluate PMEM on a large, multi-socket server commonly used for OLAP workloads. Our evaluation shows that PMEM can be treated like DRAM for most read access but must be used differently when writing. To support our findings, we run the Star Schema Benchmark on PMEM and DRAM. We show that PMEM is suitable for large, read-heavy OLAP workloads with an average query runtime slowdown of 1.66x compared to DRAM. Following our evaluation, we present 7 best practices on how to maximize PMEM's bandwidth utilization in future system designs.}
}


@inproceedings{DBLP:conf/sigmod/DaiDHS21,
	author = {Zhenwei Dai and
                  Aditya Desai and
                  Reinhard Heckel and
                  Anshumali Shrivastava},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Active Sampling Count Sketch {(ASCS)} for Online Sparse Estimation
                  of a Trillion Scale Covariance Matrix},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {352--364},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457327},
	doi = {10.1145/3448016.3457327},
	timestamp = {Mon, 21 Jun 2021 11:48:44 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/DaiDHS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Estimating and storing the covariance (or correlation) matrix of high-dimensional data is computationally challenging because both memory and computational requirements scale quadratically with the dimension. Fortunately, high-dimensional covariance matrices as observed in text, click-through, meta-genomics datasets, etc are often sparse. In this paper, we consider the problem of efficient sparse estimation of covariance matrices with possibly trillions of entries. The size of the datasets we target requires the algorithm to be online, as more than one pass over the data is prohibitive. In this paper, we propose Active Sampling Count Sketch (ASCS), an online and one-pass sketching algorithm, that recovers the large entries of the covariance matrix accurately. Count Sketch (CS), and other sub-linear compressed sensing algorithms, offer a natural solution to the problem in theory. However, vanilla CS does not work well in practice due to a low signal-to-noise ratio (SNR). At the heart of our approach is a novel active sampling strategy that increases the SNR of classical CS. We demonstrate the practicality of our algorithm with synthetic data and real-world high dimensional datasets. ASCS significantly improves over vanilla CS, demonstrating the merit of our active sampling strategy.}
}


@inproceedings{DBLP:conf/sigmod/DayanT21,
	author = {Niv Dayan and
                  Moshe Twitto},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Chucky: {A} Succinct Cuckoo Filter for LSM-Tree},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {365--378},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457273},
	doi = {10.1145/3448016.3457273},
	timestamp = {Sun, 19 Jan 2025 13:27:29 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/DayanT21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Modern key-value stores typically rely on an LSM-tree in storage (SSD) to handle writes and Bloom filters in memory (DRAM) to optimize reads. With ongoing advances in SSD technology shrinking the performance gap between storage and memory devices, the Bloom filters are now emerging as a performance bottleneck. We propose Chucky, a new design that replaces the multiple Bloom filters by a single Cuckoo filter that maps each data entry to an auxiliary address of its location within the LSM-tree. We show that while such a design entails fewer memory accesses than with Bloom filters, its false positive rate off the bat is higher. The reason is that the auxiliary addresses occupy bits that would otherwise be used as parts of the Cuckoo filter's fingerprints. To address this, we harness techniques from information theory to succinctly encode the auxiliary addresses so that the fingerprints can stay large. As a result, Chucky achieves the best of both worlds: a modest access cost and a low false positive rate at the same time.}
}


@inproceedings{DBLP:conf/sigmod/DeutchFGM21,
	author = {Daniel Deutch and
                  Ariel Frankenthal and
                  Amir Gilad and
                  Yuval Moskovitch},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {On Optimizing the Trade-off between Privacy and Utility in Data Provenance},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {379--391},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452835},
	doi = {10.1145/3448016.3452835},
	timestamp = {Mon, 21 Jun 2021 11:48:44 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/DeutchFGM21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Organizations that collect and analyze data may wish or be mandated by regulation to justify and explain their analysis results. At the same time, the logic that they have followed to analyze the data, i.e., their queries, may be proprietary and confidential. Data provenance, a record of the transformations that data underwent, was extensively studied as means of explanations. In contrast, only a few works have studied the tension between disclosing provenance and hiding the underlying query. This tension is the focus of the present paper, where we formalize and explore for the first time the tradeoff between the utility of presenting provenance information and the breach of privacy it poses with respect to the underlying query. Intuitively, our formalization is based on the notion of provenance abstraction, where the representation of some tuples in the provenance expressions is abstracted in a way that makes multiple tuples indistinguishable. The privacy of a chosen abstraction is then measured based on how many queries match the obfuscated provenance, in the same vein as k-anonymity. The utility is measured based on the entropy of the abstraction, intuitively how much information is lost with respect to the actual tuples participating in the provenance. Our formalization yields a novel optimization problem of choosing the best abstraction in terms of this tradeoff. We show that the problem is intractable in general, but design greedy heuristics that exploit the provenance structure towards a practically efficient exploration of the search space. We experimentally prove the effectiveness of our solution using the TPC-H benchmark and the IMDB dataset.}
}


@inproceedings{DBLP:conf/sigmod/DiaoGMM21,
	author = {Yanlei Diao and
                  Pawel Guzewicz and
                  Ioana Manolescu and
                  Mirjana Mazuran},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Efficient Exploration of Interesting Aggregates in {RDF} Graphs},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {392--404},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457307},
	doi = {10.1145/3448016.3457307},
	timestamp = {Sun, 19 Jan 2025 13:27:20 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/DiaoGMM21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As large Open Data are increasingly shared as RDF graphs today, there is a growing demand to help users discover the most interesting facets of a graph, which are often hard to grasp without automatic tools. We consider the problem of automatically identifying the k most interesting aggregate queries that can be evaluated on an RDF graph, given an integer k and a user-specified interestingness function. Our problem departs from analytics in relational data warehouses in that (i) in an RDF graph we are not given but we must identify the facts, dimensions, and measures of candidate aggregates; (ii) the classical approach to efficiently evaluating multiple aggregates breaks in the face of multi-valued dimensions in RDF data. In this work, we propose an extensible end-to-end framework that enables the identification and evaluation of interesting aggregates based on a new RDF-compatible one-pass algorithm for efficiently evaluating a lattice of aggregates and a novel early-stop technique (with probabilistic guarantees) that can prune uninteresting aggregates. Experiments using both real and synthetic graphs demonstrate the ability of our framework to find interesting aggregates in a large search space, the efficiency of our algorithms (with up to 2.9x speedup over a similar pipeline based on existing algorithms), and scalability as the data size and complexity grow.}
}


@inproceedings{DBLP:conf/sigmod/DiestelkamperLH21,
	author = {Ralf Diestelk{\"{a}}mper and
                  Seokki Lee and
                  Melanie Herschel and
                  Boris Glavic},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {To Not Miss the Forest for the Trees - {A} Holistic Approach for Explaining
                  Missing Answers over Nested Data},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {405--417},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457249},
	doi = {10.1145/3448016.3457249},
	timestamp = {Sun, 19 Jan 2025 13:27:23 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/DiestelkamperLH21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Query-based explanations for missing answers identify which operators of a query are responsible for the failure to return a missing answer of interest. This type of explanations has proven useful, e.g., to debug complex analytical queries. Such queries are frequent in big data systems such as Apache Spark. We present a novel approach to produce query-based explanations. It is the first to support nested data and to consider operators that modify the schema and structure of the data (e.g., nesting, projections) as potential causes of missing answers. To efficiently compute explanations, we propose a heuristic algorithm that applies two novel techniques: (i) reasoning about multiple schema alternatives for a query and (ii) re-validating at each step whether an intermediate result can contribute to the missing answer. Using an implementation on Spark, we demonstrate that our approach is the first to scale to large datasets while often finding explanations that existing techniques fail to identify.}
}


@inproceedings{DBLP:conf/sigmod/DingMCWLLKGK21,
	author = {Jialin Ding and
                  Umar Farooq Minhas and
                  Badrish Chandramouli and
                  Chi Wang and
                  Yinan Li and
                  Ying Li and
                  Donald Kossmann and
                  Johannes Gehrke and
                  Tim Kraska},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Instance-Optimized Data Layouts for Cloud Analytics Workloads},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {418--431},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457270},
	doi = {10.1145/3448016.3457270},
	timestamp = {Thu, 15 Sep 2022 14:00:48 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/DingMCWLLKGK21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Today, businesses rely on efficiently running analytics on large amounts of operational and historical data to gain business insights and competitive advantage. Increasingly, such analytics are run using cloud-based data analytics services, such as Google BigQuery, Microsoft Azure Synapse, Amazon Redshift, and Snowflake. These services persist and process data in compressed, columnar formats, stored in large blocks, each of which contains thousands or millions of records. For these services, disk I/O from (remote) cloud storage is often one of the dominant costs for query processing. To reduce the amount of I/O, services often maintain per-block metadata, such as zone maps, which are used to skip blocks that are irrelevant to the query, leading to lower query execution times. However, the effectiveness of block skipping via zone maps is dependent on how the records are assigned to blocks. Recent work on instance-optimized data layouts aims to maximize block skipping by specializing the block assignment strategy to a specific dataset and workload. However, these existing approaches only optimize the layout for a single table. In this paper, we propose MTO, an instance-optimized data layout framework that determines the blocking strategy for all tables in a multi-table database in the presence of joins, such as in a star or snowflake schema common in real-world workloads. MTO takes advantage of sideways information passing through joins to jointly optimize the layout for all tables, which results in better block skipping and hence reduced query execution times. Experiments on a commercial cloud-based analytics service show that MTO achieves up to 93% reduction in blocks accessed and 75% reduction in end-to-end query times compared to alternative blocking strategies.}
}


@inproceedings{DBLP:conf/sigmod/Dong021,
	author = {Wei Dong and
                  Ke Yi},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Residual Sensitivity for Differentially Private Multi-Way Joins},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {432--444},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452813},
	doi = {10.1145/3448016.3452813},
	timestamp = {Fri, 23 Dec 2022 10:02:56 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/Dong021.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A general-purpose query engine that supports a large class of SQLs under differential privacy is the holy grail in privacy-preserving query release. The join operator presents a major difficulty towards realizing this goal, since a single tuple may affect a large number of query results, and the problem worsens as more relations are involved in the join. The traditional approach of global sensitivity fails to work as it assumes pessimistically that every pair of tuples from two different relations may join. To address the issue, instance-dependent sensitivity measures have been proposed, but so far none has met the following three desiderata for it to be truly practical: (1) the released answer should have low noise levels (i.e., high utility); (2) it can be computed efficiently; and (3) the method can be easily integrated into an existing relational database. This paper presents the first differentially private mechanism for multi-way joins that satisfies all three desiderata while supporting any number of private relations, moving us one step closer to a full-featured query engine for private relational data.}
}


@inproceedings{DBLP:conf/sigmod/DurnerL021,
	author = {Dominik Durner and
                  Viktor Leis and
                  Thomas Neumann},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {{JSON} Tiles: Fast Analytics on Semi-Structured Data},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {445--458},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452809},
	doi = {10.1145/3448016.3452809},
	timestamp = {Sun, 19 Jan 2025 13:27:34 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/DurnerL021.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Developers often prefer flexibility over upfront schema design, making semi-structured data formats such as JSON increasingly popular. Large amounts of JSON data are therefore stored and analyzed by relational database systems. In existing systems, however, JSON's lack of a fixed schema results in slow analytics. In this paper, we present JSON tiles, which, without losing the flexibility of JSON, enables relational systems to perform analytics on JSON data at native speed. JSON tiles automatically detects the most important keys and extracts them transparently - often achieving scan performance similar to columnar storage. At the same time, JSON tiles is capable of handling heterogeneous and changing data. Furthermore, we automatically collect statistics that enable the query optimizer to find good execution plans. Our experimental evaluation compares against state-of-the-art systems and research proposals and shows that our approach is both robust and efficient.}
}


@inproceedings{DBLP:conf/sigmod/Fan0XYYZ21,
	author = {Wenfei Fan and
                  Chao Tian and
                  Ruiqi Xu and
                  Qiang Yin and
                  Wenyuan Yu and
                  Jingren Zhou},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Incrementalizing Graph Algorithms},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {459--471},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452796},
	doi = {10.1145/3448016.3452796},
	timestamp = {Wed, 19 Mar 2025 21:16:27 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/Fan0XYYZ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Incremental algorithms are important to dynamic graph analyses, but are hard to write and analyze. Few incremental graph algorithms are in place, and even fewer offer performance guarantees. This paper approaches this by proposing to incrementalize existing batch algorithms. We identify a class of incrementalizable algorithms abstracted in a fixpoint model. We show how to deduce an incremental algorithm AΔ from such an algorithm A. Moreover, AΔ can be made bounded relative to A, i.e., its cost is determined by the sizes of changes to graphs and changes to the affected area that is necessarily checked by batch algorithm A. We provide generic conditions under which a deduced algorithm AΔ warrants to be correct and relatively bounded, by adopting the same logic and data structures of A, at most using timestamps as an additional auxiliary structure. Based on these, we show that a variety of graph-centric algorithms can be incrementalized with relative boundedness. Using real-life and synthetic graphs, we experimentally verify the scalability and efficiency of the incrementalized algorithms.}
}


@inproceedings{DBLP:conf/sigmod/FanLLL21,
	author = {Wenfei Fan and
                  Yuanhao Li and
                  Muyang Liu and
                  Can Lu},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Making Graphs Compact by Lossless Contraction},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {472--484},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452797},
	doi = {10.1145/3448016.3452797},
	timestamp = {Tue, 28 Mar 2023 16:27:38 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/FanLLL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper proposes a scheme to reduce big graphs to small graphs. It contracts obsolete parts, stars, cliques and paths into supernodes. The supernodes carry a synopsis S_Q for each query class Q to abstract key features of the contracted parts for answering queries of Q. The contraction scheme provides a compact graph representation and prioritizes up-to-date data. Better still, it is generic and lossless. We show that the same contracted graph is able to support multiple query classes at the same time, no matter whether their queries are label-based or not, local or non-local. Moreover, existing algorithms for these queries can be readily adapted to compute exact answers by using the synopses when possible, and decontracting the supernodes only when necessary. As a proof of concept, we show how to adapt existing algorithms for subgraph isomorphism, triangle counting and shortest distance to contracted graphs. We also provide an incremental contraction algorithm in response to updates. We experimentally verify that on average, the contraction scheme reduces graphs by 71.2%, and improves the evaluation of these queries by 1.53, 1.42 and 2.14 times, respectively.}
}


@inproceedings{DBLP:conf/sigmod/FarhatDQ21,
	author = {Omar Farhat and
                  Khuzaima Daudjee and
                  Leonardo Querzoni},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Klink: Progress-Aware Scheduling for Streaming Data Systems},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {485--498},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452794},
	doi = {10.1145/3448016.3452794},
	timestamp = {Mon, 03 Jan 2022 22:24:52 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/FarhatDQ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Modern stream processing engines (SPEs) process large volumes of events propagated at high velocity through multiple queries. To improve performance, existing SPEs generally aim to minimize query output latency by minimizing, in turn, the propagation delay of events in query pipelines. However, for queries containing commonly used blocking operators such as windows, this scheduling approach can be inefficient. Watermarks are events popularly utilized by SPEs to correctly process window operators. Watermarks are injected into the stream to signify that no events preceding their timestamp should be further expected. Through the design and development of Klink, we leverage these watermarks to robustly infer stream progress based on window deadlines and network delay, and to schedule query pipeline execution that reflects stream progress. Klink aims to unblock window operators and to rapidly propagate events to output operators while performing judicious memory management. We integrate Klink into the popular open source SPE Apache Flink and demonstrate that Klink delivers significant performance gains over existing scheduling policies on benchmark workloads for both scale-up and scale-out deployments.}
}


@inproceedings{DBLP:conf/sigmod/Fariha0RGM21,
	author = {Anna Fariha and
                  Ashish Tiwari and
                  Arjun Radhakrishna and
                  Sumit Gulwani and
                  Alexandra Meliou},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Conformance Constraint Discovery: Measuring Trust in Data-Driven Systems},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {499--512},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452795},
	doi = {10.1145/3448016.3452795},
	timestamp = {Mon, 05 Feb 2024 20:26:56 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/Fariha0RGM21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The reliability of inferences made by data-driven systems hinges on the data's continued conformance to the systems' initial settings and assumptions. When serving data (on which we want to apply inference) deviates from the profile of the initial training data, the outcome of inference becomes unreliable. We introduce conformance constraints, a new data profiling primitive tailored towards quantifying the degree of non-conformance, which can effectively characterize if inference over that tuple is untrustworthy. Conformance constraints are constraints over certain arithmetic expressions (called projections) involving the numerical attributes of a dataset, which existing data profiling primitives such as functional dependencies and denial constraints cannot model. Our key finding is that projections that incur low variance on a dataset construct effective conformance constraints. This principle yields the surprising result that low-variance components of a principal component analysis, which are usually discarded for dimensionality reduction, generate stronger conformance constraints than the high-variance components. Based on this result, we provide a highly scalable and efficient technique--linear in data size and cubic in the number of attributes--for discovering conformance constraints for a dataset. To measure the degree of a tuple's non-conformance with respect to a dataset, we propose a quantitative semantics that captures how much a tuple violates the conformance constraints of that dataset. We demonstrate the value of conformance constraints on two applications: trusted machine learning and data drift. We empirically show that conformance constraints offer mechanisms to (1) reliably detect tuples on which the inference of a machine-learned model should not be trusted, and (2) quantify data drift more accurately than the state of the art.}
}


@inproceedings{DBLP:conf/sigmod/FengML0ZHC21,
	author = {Guanyu Feng and
                  Zixuan Ma and
                  Daixuan Li and
                  Shengqi Chen and
                  Xiaowei Zhu and
                  Wentao Han and
                  Wenguang Chen},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {RisGraph: {A} Real-Time Streaming System for Evolving Graphs to Support
                  Sub-millisecond Per-update Analysis at Millions Ops/s},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {513--527},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457263},
	doi = {10.1145/3448016.3457263},
	timestamp = {Mon, 26 Jun 2023 20:43:17 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/FengML0ZHC21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Evolving graphs in the real world are large-scale and constantly changing, as hundreds of thousands of updates may come every second. Monotonic algorithms such as Reachability and Shortest Path are widely used in real-time analytics to gain both static and temporal insights and can be accelerated by incremental computing. Existing streaming systems adopt the incremental computing model and achieve either low latency or high throughput, but not both. However, both high throughput and low latency are required in real scenarios such as financial fraud detection. This paper presents RisGraph, a real-time streaming system that provides low-latency analysis for each update with high throughput. RisGraph addresses the challenge with localized data access and inter-update parallelism. We propose a data structure named Indexed Adjacency Lists and use sparse arrays and Hybrid Parallel Mode to enable localized data access. To achieve inter-update parallelism, we propose a domain-specific concurrency control mechanism based on the classification of safe and unsafe updates. Experiments show that RisGraph can ingest millions of updates per second for graphs with several hundred million vertices and billions of edges, and the P999 processing time latency is within 20 milliseconds. RisGraph achieves orders-of-magnitude improvement on throughput when analyses are executed for each update without batching and performs better than existing systems with batches of up to 20 million updates.}
}


@inproceedings{DBLP:conf/sigmod/FengGHK21,
	author = {Su Feng and
                  Boris Glavic and
                  Aaron Huber and
                  Oliver A. Kennedy},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Efficient Uncertainty Tracking for Complex Queries with Attribute-level
                  Bounds},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {528--540},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452791},
	doi = {10.1145/3448016.3452791},
	timestamp = {Sun, 12 Nov 2023 02:07:18 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/FengGHK21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Incomplete and probabilistic database techniques are principled methods for coping with uncertainty in data. Unfortunately, the class of queries that can be answered efficiently over such databases is severely limited, even when advanced approximation techniques are employed.We introduce attribute-annotated uncertain databases (AU-DBs), an uncertain data model that annotates tuples and attribute values with bounds to compactly approximate an incomplete database. AU-DBs are closed under relational algebra with aggregation using an efficient evaluation semantics. Using optimizations that trade accuracy for performance, our approach scales to complex queries and large datasets, and produces accurate results.}
}


@inproceedings{DBLP:conf/sigmod/FengD21,
	author = {Weiqi Feng and
                  Dong Deng},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Allign: Aligning All-Pair Near-Duplicate Passages in Long Texts},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {541--553},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457548},
	doi = {10.1145/3448016.3457548},
	timestamp = {Wed, 23 Jun 2021 12:10:10 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/FengD21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we study the problem of aligning all-pair near-duplicate passages in two long texts. A passage is a sequence of consecutive words in a text. It can begin and end with any word in the text, whether around a period or not. Due to the high computation cost of this problem, existing work all compromise to heuristic alignment methods, which can harm the recall of downstream applications, such as deduplication and plagiarism detection. To address this problem, in this paper, we propose a min-hash based method Allign to find all near-duplicate passage pairs in two long texts. Allign generates a few min-hash values for each passage in the texts and reports all the passage pairs sharing enough common min-hash values. However, for a pair of texts with n and m words, there are in total O(n2m2) passage pairs (each text contains O(n2) and O(m2) passages respectively). Thus it is prohibitively expensive to enumerate all passage pairs in two texts and count their common min-hash values. To address this issue, Allign packs a large number of nearby and overlapping passages with the same min-hash to a "compact window". In total, Allign generates O(n) compact windows to represent all the O(n2) passages in a text with n words. Next, a pair of compact windows in two texts are matched if they have the same min-hash. The rest of unmatched compact windows are removed. Finally, Allign reports all the passage pairs contained by enough number of matched compact window pairs, which must share the same enough number of min-hash values. In this way, Allign avoids enumerating the enormous number of passage pairs. Last but not least, to make the reported near-duplicate passages more relevant and Allign more efficient, we show how to support a few practical constraints efficiently, including reporting only longest near-duplicates and sentence-level near-duplicates. Experimental results on real-world datasets show that Allign significantly outperforms the state-of-the-art text alignment methods.}
}


@inproceedings{DBLP:conf/sigmod/FoufoulasSSI21,
	author = {Yannis Foufoulas and
                  Lefteris Sidirourgos and
                  Elefterios Stamatogiannakis and
                  Yannis E. Ioannidis},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Adaptive Compression for Fast Scans on String Columns},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {554--562},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452798},
	doi = {10.1145/3448016.3452798},
	timestamp = {Thu, 01 May 2025 20:25:58 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/FoufoulasSSI21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {State-of-the-art OLAP systems tend to use columnar data representations, as these are both suitable for analytics and amenable to compression. Local dictionary value encoding has been shown to achieve high compression rates for string columns while still allowing fast filtered scans. In this paper, we argue that the effectiveness and efficiency of local dictionary compression is limited by data repetition across file blocks and by dictionary look-ups inside each block during filtered scan execution. To address this problem, we introduce an adaptive compression technique that is based on differential dictionaries and targets both storage efficiency and query performance. The proposed scheme reduces dramatically the need to store repeated values across different file blocks and significantly accelerates read operations by reducing the time needed for dictionary look-ups. A preliminary set of experiments has given very promising results, showing that, in many cases, the proposed new dictionary compression scheme is much more efficient than existing techniques, occasionally up to an order of magnitude.}
}


@inproceedings{DBLP:conf/sigmod/FuSYJXT021,
	author = {Fangcheng Fu and
                  Yingxia Shao and
                  Lele Yu and
                  Jiawei Jiang and
                  Huanran Xue and
                  Yangyu Tao and
                  Bin Cui},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {VF\({}^{\mbox{2}}\)Boost: Very Fast Vertical Federated Gradient Boosting
                  for Cross-Enterprise Learning},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {563--576},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457241},
	doi = {10.1145/3448016.3457241},
	timestamp = {Sun, 19 Jan 2025 13:27:21 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/FuSYJXT021.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the ever-evolving concerns on privacy protection, vertical federated learning (FL), where participants own non-overlapping features for the same set of instances, is becoming a heated topic since it enables multiple enterprises to strengthen the machine learning models collaboratively with privacy guarantees. Nevertheless, to achieve privacy preservation, vertical FL algorithms involve complicated training routines and time-consuming cryptography operations, leading to slow training speed. This paper explores the efficiency of the gradient boosting decision tree (GBDT) algorithm under the vertical FL setting. Specifically, we introduce VF^2Boost, a novel and efficient vertical federated GBDT system. Significant solutions are developed to tackle the major bottlenecks. First, to handle the deficiency caused by frequent mutual-waiting in federated training, we propose a concurrent training protocol to reduce the idle periods. Second, to speed up the cryptography operations, we analyze the characteristics of the algorithm and propose customized operations. Empirical results show that our system can be 12.8-18.9 times faster than the existing vertical federated implementations and support much larger datasets.}
}


@inproceedings{DBLP:conf/sigmod/GalhotraPS21,
	author = {Sainyam Galhotra and
                  Romila Pradhan and
                  Babak Salimi},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Explaining Black-Box Algorithms Using Probabilistic Contrastive Counterfactuals},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {577--590},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3458455},
	doi = {10.1145/3448016.3458455},
	timestamp = {Mon, 21 Jun 2021 11:48:44 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/GalhotraPS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {There has been a recent resurgence of interest in explainable artificial intelligence (XAI) that aims to reduce the opaqueness of AI-based decision-making systems, allowing humans to scrutinize and trust them. Prior work in this context has focused on the attribution of responsibility for an algorithm's decisions to its inputs wherein responsibility is typically approached as a purely associational concept. In this paper, we propose a principled causality-based approach for explaining black-box decision-making systems that addresses limitations of existing methods in XAI. At the core of our framework lies probabilistic contrastive counterfactuals, a concept that can be traced back to philosophical, cognitive, and social foundations of theories on how humans generate and select explanations. We show how such counterfactuals can quantify the direct and indirect influences of a variable on decisions made by an algorithm, and provide actionable recourse for individuals negatively affected by the algorithm's decision. Unlike prior work, our system, LEWIS: (1)~can compute provably effective explanations and recourse at local, global and contextual levels; (2)~is designed to work with users with varying levels of background knowledge of the underlying causal model; and (3)~makes no assumptions about the internals of an algorithmic system except for the availability of its input-output data. We empirically evaluate LEWIS on four real-world datasets and show that it generates human-understandable explanations that improve upon state-of-the-art approaches in XAI, including the popular LIME and SHAP. Experiments on synthetic data further demonstrate the correctness of LEWIS's explanations and the scalability of its recourse algorithm.}
}


@inproceedings{DBLP:conf/sigmod/GaoXAY21,
	author = {Junyang Gao and
                  Yifan Xu and
                  Pankaj K. Agarwal and
                  Jun Yang},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Efficiently Answering Durability Prediction Queries},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {591--604},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457305},
	doi = {10.1145/3448016.3457305},
	timestamp = {Mon, 05 Jul 2021 13:48:35 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/GaoXAY21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We consider a class of queries called durability prediction queries that arise commonly in predictive analytics, where we use a given predictive model to answer questions about possible futures to inform our decisions. Examples of durability prediction queries include "what is the probability that this financial product will keep losing money over the next 12 quarters before turning in any profit?" and "what is the chance for our proposed server cluster to fail the required service-level agreement before its term ends?" We devise a general method called Multi-Level Splitting Sampling (MLSS) that can efficiently handle complex queries and complex models---including those involving black-box functions---as long as the models allow us to simulate possible futures step by step. Our method addresses the inefficiency of standard Monte Carlo (MC) methods by applying the idea of importance splitting to let one "promising" sample path prefix generate multiple "offspring" paths, thereby directing simulation efforts toward more promising paths. We propose practical techniques for designing splitting strategies, freeing users from manual tuning. Experiments show that our approach is able to achieve unbiased estimates and the same error guarantees as standard MC while offering an order-of-magnitude cost reduction.}
}


@inproceedings{DBLP:conf/sigmod/GevayQM21,
	author = {G{\'{a}}bor E. G{\'{e}}vay and
                  Jorge{-}Arnulfo Quian{\'{e}}{-}Ruiz and
                  Volker Markl},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {The Power of Nested Parallelism in Big Data Processing - Hitting Three
                  Flies with One Slap -},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {605--618},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457287},
	doi = {10.1145/3448016.3457287},
	timestamp = {Sun, 19 Jan 2025 13:27:23 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/GevayQM21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Many common data analysis tasks, such as performing hyperparameter optimization, processing a partitioned graph, and treating a matrix as a vector of vectors, offer natural opportunities for nested-parallel operations, i.e., launching parallel operations from inside other parallel operations. However, state-of-the-art dataflow engines, such as Spark and Flink, do not support nested parallelism. Users must implement workarounds, causing orders of magnitude slowdowns for their tasks, let alone the implementation effort. We present Matryoshka, a system that enables dataflow engines to support nested parallelism, even in the presence of control flow statements at inner nesting levels. Matryoshka achieves this via a novel two-phase flattening process, which translates nested-parallel programs to flat-parallel programs that can efficiently run on existing dataflow engines. The first phase introduces novel nesting primitives into the code, which allows for dynamic optimizations based on intermediate data characteristics in the second phase at runtime. We validate our system using several common data analysis tasks, such as PageRank and K-means.}
}


@inproceedings{DBLP:conf/sigmod/GiladPM21,
	author = {Amir Gilad and
                  Shweta Patwa and
                  Ashwin Machanavajjhala},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Synthesizing Linked Data Under Cardinality and Integrity Constraints},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {619--631},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457242},
	doi = {10.1145/3448016.3457242},
	timestamp = {Mon, 21 Jun 2021 11:48:44 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/GiladPM21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The generation of synthetic data is useful in multiple aspects, from testing applications to benchmarking to privacy preservation. Generating thelinks between relations, subject tocardinality constraints (CCs) andintegrity constraints (ICs) is an important aspect of this problem. Given instances of two relations, where one has a foreign key dependence on the other and is missing its foreign key ($FK$) values, and two types of constraints: (1) CCs that apply to the join view and (2) ICs that apply to the table with missing $FK$ values, our goal is to impute the missing $FK$ values such that the constraints are satisfied. We provide a novel framework for the problem based on declarative CCs and ICs. We further show that the problem is NP-hard and propose a novel two-phase solution that guarantees the satisfaction of the ICs. Phase I yields an intermediate solution accounting for the CCs alone, and relies on a hybrid approach based on CC types. For one type, the problem is modeled as an Integer Linear Program. For the others, we describe an efficient and accurate solution. We then combine the two solutions. Phase II augments this solution by incorporating the ICs and uses a coloring of the conflict hypergraph to infer the values of the $FK$ column. Our extensive experimental study shows that our solution scales well when the data and number of constraints increases. We further show that our solution maintains low error rates for the CCs.}
}


@inproceedings{DBLP:conf/sigmod/GkiniBKI21,
	author = {Orest Gkini and
                  Theofilos Belmpas and
                  Georgia Koutrika and
                  Yannis E. Ioannidis},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {An In-Depth Benchmarking of Text-to-SQL Systems},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {632--644},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452836},
	doi = {10.1145/3448016.3452836},
	timestamp = {Thu, 01 May 2025 20:25:58 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/GkiniBKI21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Text-to-SQL systems allow users to explore relational databases by posing free-form queries, alleviating the need for using structured languages, such as SQL. Although numerous systems have been developed so far, existing system evaluations lack in rigour. In this work, we build a text-to-SQL benchmark that covers different classes of queries, and we evaluate the effectiveness of several systems in the field. To evaluate system efficiency, we measure execution time and resource consumption for the different query classes. Our comprehensive evaluation aims at filling in a big gap in understanding the capabilities and boundaries of existing systems and it reveals several open challenges.}
}


@inproceedings{DBLP:conf/sigmod/Gou021,
	author = {Xiangyang Gou and
                  Lei Zou},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Sliding Window-based Approximate Triangle Counting over Streaming
                  Graphs with Duplicate Edges},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {645--657},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452800},
	doi = {10.1145/3448016.3452800},
	timestamp = {Mon, 21 Jun 2021 11:48:44 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/Gou021.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Streaming graph analysis is gaining importance in various fields due to the natural dynamicity in many real graph applications. However, approximately counting triangles in real-world streaming graphs with edge duplication and expiration remains an unsolved problem. In this paper, we propose SWTC algorithm to address approximate sliding-window triangle counting problem in streaming graphs with edge duplication. In SWTC, we propose a fixed-length slicing strategy that addresses both unbiased sampling and cardinality estimation issues with a bounded memory usage. We theoretically prove the superiority of our method in sample graph size and estimation accuracy under given memory upper bound. Extensive experiments also confirm that our approach has higher accuracy compared with the baseline method under the same memory usage.}
}


@inproceedings{DBLP:conf/sigmod/GuoWYY21,
	author = {Zhihan Guo and
                  Kan Wu and
                  Cong Yan and
                  Xiangyao Yu},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Releasing Locks As Early As You Can: Reducing Contention of Hotspots
                  by Violating Two-Phase Locking},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {658--670},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457294},
	doi = {10.1145/3448016.3457294},
	timestamp = {Mon, 21 Jun 2021 11:48:44 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/GuoWYY21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Hotspots, a small set of tuples frequently read/written by a large number of transactions, cause contention in a concurrency control protocol. While a hotspot may comprise only a small fraction of a transaction's execution time, conventional strict two-phase locking allows a transaction to release lock only after the transaction completes, which leaves significant parallelism unexploited. Ideally, a concurrency control protocol serializes transactions only for the duration of the hotspots, rather than the duration of transactions. We observe that exploiting such parallelism requires violating two-phase locking. In this paper, we propose Bamboo, a new concurrency control protocol that can enable such parallelism by modifying the conventional two-phase locking, while maintaining the same guarantees in correctness. We thoroughly analyzed the effect of cascading aborts involved in reading uncommitted data and discussed optimizations that can be applied to further improve the performance. Our evaluation on TPC-C shows a performance improvement up to 4x compared to the best of pessimistic and optimistic baseline protocols. On synthetic workloads that contain a single hotspot, Bamboo achieves a speedup up to 19x over baselines.}
}


@inproceedings{DBLP:conf/sigmod/0003W0CAL21,
	author = {Kai Han and
                  Benwei Wu and
                  Jing Tang and
                  Shuang Cui and
                  {\c{C}}igdem Aslay and
                  Laks V. S. Lakshmanan},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Efficient and Effective Algorithms for Revenue Maximization in Social
                  Advertising},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {671--684},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3459243},
	doi = {10.1145/3448016.3459243},
	timestamp = {Sun, 02 Oct 2022 16:15:19 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/0003W0CAL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We consider the revenue maximization problem in social advertising, where a social network platform owner needs to select seed users for a group of advertisers, each with a payment budget, such that the total expected revenue that the owner gains from the advertisers by propagating their ads in the network is maximized. Previous studies on this problem show that it is intractable and present approximation algorithms. We revisit this problem from a fresh perspective and develop novel efficient approximation algorithms, both under the setting where an exact influence oracle is assumed and under one where this assumption is relaxed. Our approximation ratios significantly improve upon the previous ones. Furthermore, we empirically show, using extensive experiments on four datasets, that our algorithms considerably outperform the existing methods on both the solution quality and computation efficiency.}
}


@inproceedings{DBLP:conf/sigmod/HaynesDHMBCC21,
	author = {Brandon Haynes and
                  Maureen Daum and
                  Dong He and
                  Amrita Mazumdar and
                  Magdalena Balazinska and
                  Alvin Cheung and
                  Luis Ceze},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {{VSS:} {A} Storage System for Video Analytics},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {685--696},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3459242},
	doi = {10.1145/3448016.3459242},
	timestamp = {Sun, 12 Nov 2023 02:07:18 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/HaynesDHMBCC21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We present a new video storage system (VSS) designed to decouple high-level video operations from the low-level details required to store and efficiently retrieve video data. VSS is designed to be the storage subsystem of a video data management system (VDBMS) and is responsible for: (1) transparently and automatically arranging the data on disk in an efficient, granular format; (2) caching frequently-retrieved regions in the most useful formats; and (3) eliminating redundancies found in videos captured from multiple cameras with overlapping fields of view. Our results suggest that VSS can improve VDBMS read performance by up to 54%, reduce storage costs by up to 45%, and enable developers to focus on application logic rather than video storage and retrieval.}
}


@inproceedings{DBLP:conf/sigmod/HertzschuchMLMW21,
	author = {Axel Hertzschuch and
                  Guido Moerkotte and
                  Wolfgang Lehner and
                  Norman May and
                  Florian Wolf and
                  Lars Fricke},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Small Selectivities Matter: Lifting the Burden of Empty Samples},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {697--709},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452805},
	doi = {10.1145/3448016.3452805},
	timestamp = {Tue, 04 Mar 2025 15:55:49 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/HertzschuchMLMW21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Every year more and more advanced approaches to cardinality estimation are published, using learned models or other data and workload specific synopses. In contrast, the majority of commercial in-memory systems still relies on sampling. It is arguably the most general and easiest estimator to implement. While most methods do not seem to improve much over sampling-based estimators in the presence of non-selective queries, sampling struggles with highly selective queries due to limitations of the sample size. Especially in situations where no sample tuple qualifies, optimizers fall back to basic heuristics that ignore attribute correlations and lead to large estimation errors. In this work, we present a novel approach, dealing with these 0-Tuple Situations. It is ready to use in any DBMS capable of sampling, showing a negligible impact on optimization time. Our experiments on real world and synthetic data sets demonstrate up to two orders of magnitude reduced estimation errors. Enumerating single filter predicates according to our estimates reveals 1.3 to 1.8 times faster query responses for complex filters.}
}


@inproceedings{DBLP:conf/sigmod/HilprechtB21,
	author = {Benjamin Hilprecht and
                  Carsten Binnig},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {ReStore - Neural Data Completion for Relational Databases},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {710--722},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457264},
	doi = {10.1145/3448016.3457264},
	timestamp = {Sun, 19 Jan 2025 13:27:22 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/HilprechtB21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Classical approaches for OLAP assume that the data of all tables is complete. However, in case of incomplete tables with missing tuples, classical approaches fail since the result of a SQL aggregate query might significantly differ from the results computed on the full dataset. Today, the only way to deal with missing data is to manually complete the dataset which causes not only high efforts but also requires good statistical skills to determine when a dataset is actually complete. In this paper, we propose an automated approach for relational data completion called ReStore using a new class of (neural) schema-structured completion models that are able to synthesize data which resembles the missing tuples. As we show in our evaluation, this efficiently helps to reduce the relative error of aggregate queries by up to 390% on real-world data compared to using the incomplete data directly for query answering.}
}


@inproceedings{DBLP:conf/sigmod/HirnG21,
	author = {Denis Hirn and
                  Torsten Grust},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {One {WITH} {RECURSIVE} is Worth Many GOTOs},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {723--735},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457272},
	doi = {10.1145/3448016.3457272},
	timestamp = {Tue, 07 May 2024 20:05:52 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/HirnG21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {PL/SQL integrates an imperative statement-by-statement style of programming with the plan-based evaluation of SQL queries. The disparity of both leads to friction at runtime, slowing PL/SQL execution down significantly. This work describes a compiler from PL/SQL UDFs to plain SQL queries. Post-compilation, evaluation entirely happens on the SQL side of the fence. With the friction gone, we observe execution times to improve by about a factor of 2, even for complex UDFs. The compiler builds on techniques long established by the programming language community. In particular, it uses trampolined style to compile arbitrarily nested iterative control flow in PL/SQL into SQL's recursive common table expressions.}
}


@inproceedings{DBLP:conf/sigmod/Hu0L21,
	author = {Lin Hu and
                  Lei Zou and
                  Yu Liu},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Accelerating Triangle Counting on {GPU}},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {736--748},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452815},
	doi = {10.1145/3448016.3452815},
	timestamp = {Wed, 10 Jul 2024 07:43:42 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/Hu0L21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Triangle counting is an important problem in graph mining, which has achieved great performance improvement on GPU in recent years. Instead of proposing a new GPU triangle counting algorithm, in this paper, we propose a novel lightweight graph preprocessing method to boost many state-of-the-art GPU triangle counting algorithms without changing their implementations and data structures. Specifically, we find common computing patterns in existing algorithms, and abstract two analytic models to measure how workload imbalance and diversity in these computing patterns affect performance exactly. Then, due to the NP-hardness of the model optimization, we propose approximate solutions by determining edge directions to balance workloads and reordering vertices to maximize the degree of parallelism within GPU blocks. Finally, extensive experiments confirm the significant performance improvement and high usability of our approach.}
}


@inproceedings{DBLP:conf/sigmod/HuangG21,
	author = {Haoyu Huang and
                  Shahram Ghandeharizadeh},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Nova-LSM: {A} Distributed, Component-based LSM-tree Key-value Store},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {749--763},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457297},
	doi = {10.1145/3448016.3457297},
	timestamp = {Sun, 19 Jan 2025 13:27:28 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/HuangG21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The cloud infrastructure motivates disaggregation of monolithic data stores into components that are assembled together based on an application's workload. This study investigates disaggregation of an LSM-tree key-value store into components that communicate using RDMA. These components separate storage from processing, enabling processing components to share storage bandwidth and space. The processing components scatter blocks of a file (SSTable) across an arbitrary number of storage components and balance load across them using power-of-d. They construct ranges dynamically at runtime to parallelize compaction and enhance performance. Each component has configuration knobs that control its scalability. The resulting component-based system, Nova-LSM, is elastic. It outperforms its monolithic counterparts, both LevelDB and RocksDB, by several orders of magnitude with workloads that exhibit a skewed pattern of access to data.}
}


@inproceedings{DBLP:conf/sigmod/HuangCBCZ21,
	author = {Kai Huang and
                  Huey{-}Eng Chua and
                  Sourav S. Bhowmick and
                  Byron Choi and
                  Shuigeng Zhou},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {{MIDAS:} Towards Efficient and Effective Maintenance of Canned Patterns
                  in Visual Graph Query Interfaces},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {764--776},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457251},
	doi = {10.1145/3448016.3457251},
	timestamp = {Mon, 03 Mar 2025 21:21:49 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/HuangCBCZ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Several visual graph query interfaces (a.k.a gui) expose a set of canned patterns (i.e., small subgraph patterns) to expedite subgraph query formulation by enabling pattern-at-a-time construction. Unfortunately, manual generation of canned patterns is not only labour intensive but also may lack diversity to support efficient visual formulation of a wide range of subgraph queries. Recent efforts have taken a data-driven approach to select high-quality canned patterns for a gui automatically from the underlying graph database. However, as the underlying database evolves, these selected patterns may become stale and adversely impact efficient query formulation. In this paper, we present a novel framework called Midas for efficient and effective maintenance of the canned patterns as the database evolves. Specifically, it adopts a selective maintenance strategy that guarantees progressive gain of coverage of the patterns without sacrificing their diversity and cognitive load. Experimental study with real-world datasets and visual graph interfaces demonstrates the effectiveness of Midas compared to static guis.}
}


@inproceedings{DBLP:conf/sigmod/HuangLT21,
	author = {Qiang Huang and
                  Yifan Lei and
                  Anthony K. H. Tung},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Point-to-Hyperplane Nearest Neighbor Search Beyond the Unit Hypersphere},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {777--789},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457240},
	doi = {10.1145/3448016.3457240},
	timestamp = {Sun, 25 Jul 2021 11:47:33 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/HuangLT21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Point-to-Hyperplane Nearest Neighbor Search (P2HNNS) is a fundamental yet challenging problem, and it has plenty of applications in various fields. Existing hyperplane hashing schemes enjoy sub-linear query time and achieve excellent performance on applications such as large-scale active learning with Support Vector Machines (SVMs). However, they only conditionally deal with this problem with a strong assumption that all of the data objects are normalized, located at the unit hypersphere. Those hyperplane hashing schemes may be arbitrarily bad without this assumption. In this paper, we introduce a new asymmetric transformation and develop the first two provable hyperplane hashing schemes, Nearest Hyperplane hashing (NH) and Furthest Hyperplane hashing (FH), for high-dimensional P2HNNS beyond the unit hypersphere. With this asymmetric transformation, we demonstrate that the hash functions of NH and FH are locality-sensitive to the hyperplane queries, and both of them enjoy quality guarantee on query results. Moreover, we propose a data-dependent multi-partition strategy to boost the search performance of FH. NH can perform the hyperplane queries in sub-linear time, while FH enjoys a better practical performance. We evaluate NH and FH over five real-life datasets and show that we are around $3 \\sim 100 \\times$ faster than the best competitor in four out of five datasets, especially for the recall in $[20%, 80%]$. Code is available at \\urlhttps://github.com/HuangQiang/P2HNNS.}
}


@inproceedings{DBLP:conf/sigmod/HuangTCLX21,
	author = {Yuming Huang and
                  Jing Tang and
                  Qianhao Cong and
                  Andrew Lim and
                  Jianliang Xu},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Do the Rich Get Richer? Fairness Analysis for Blockchain Incentives},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {790--803},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457285},
	doi = {10.1145/3448016.3457285},
	timestamp = {Mon, 03 Mar 2025 21:21:49 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/HuangTCLX21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Proof-of-Work (PoW) is the most widely adopted incentive model in current blockchain systems, which unfortunately is energy inefficient. Proof-of-Stake (PoS) is then proposed to tackle the energy issue. The rich-get-richer concern of PoS has been heavily debated in the blockchain community. The debate is centered around the argument that whether rich miners possessing more stakes will obtain higher staking rewards and further increase their potential income in the future. In this paper, we define two types of fairness, i.e., expectational fairness and robust fairness, that are useful for answering this question. In particular, expectational fairness illustrates that the expected income of a miner is proportional to her initial investment, indicating that the expected return on investment is a constant. To better capture the uncertainty of mining outcomes, robust fairness is proposed to characterize whether the return on investment concentrates to a constant with high probability as time evolves. Our analysis shows that the classical PoW mechanism can always preserve both types of fairness as long as the mining game runs for a sufficiently long time. Furthermore, we observe that current PoS blockchains implement various incentive models and discuss three representatives, namely ML-PoS, SL-PoS and C-PoS. We find that (i) ML-PoS (e.g., Qtum and Blackcoin) preserves expectational fairness but may not achieve robust fairness, (ii) SL-PoS (e.g., NXT) does not protect any type of fairness, and (iii) C-PoS (e.g., Ethereum 2.0) outperforms ML-PoS in terms of robust fairness while still maintaining expectational fairness. Finally, massive experiments on real blockchain systems and extensive numerical simulations are performed to validate our analysis.}
}


@inproceedings{DBLP:conf/sigmod/IzenovDRS21,
	author = {Yesdaulet Izenov and
                  Asoke Datta and
                  Florin Rusu and
                  Jun Hyung Shin},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {{COMPASS:} Online Sketch-based Query Optimization for In-Memory Databases},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {804--816},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452840},
	doi = {10.1145/3448016.3452840},
	timestamp = {Sun, 19 Jan 2025 13:27:22 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/IzenovDRS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cost-based query optimization remains a critical task in relational databases even after decades of research and industrial development. Query optimizers rely on a large range of statistical synopses for accurate cardinality estimation. As the complexity of selections and the number of join predicates increase, two problems arise. First, statistics cannot be incrementally composed to effectively estimate the cost of the sub-plans generated in plan enumeration. Second, small errors are propagated exponentially through joins, which can lead to severely sub-optimal plans. In this paper, we introduce COMPASS, a novel query optimization paradigm for in-memory databases based on a single type of statistics---Fast-AGMS sketches. In COMPASS, query optimization and execution are intertwined. Selection predicates and sketch updates are pushed-down and evaluated online during query optimization. This allows Fast-AGMS sketches to be computed only over the relevant tuples---which enhances cardinality estimation accuracy. Plan enumeration is performed over the query join graph by incrementally composing attribute-level sketches---not by building a separate sketch for every sub-plan. We prototype COMPASS in MapD -- an open-source parallel database -- and perform extensive experiments over the complete JOB benchmark. The results prove that COMPASS generates better execution plans -- both in terms of cardinality and runtime -- compared to four other database systems. Overall, COMPASS achieves a speedup ranging from 1.35X to 11.28X in cumulative query execution time over the considered competitors.}
}


@inproceedings{DBLP:conf/sigmod/JiJ21,
	author = {Shuping Ji and
                  Hans{-}Arno Jacobsen},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {A-Tree: {A} Dynamic Data Structure for Efficiently Indexing Arbitrary
                  Boolean Expressions},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {817--829},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457266},
	doi = {10.1145/3448016.3457266},
	timestamp = {Mon, 21 Jun 2021 11:48:44 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/JiJ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Efficiently evaluating a large number of arbitrary Boolean expressions is needed in many applications such as advertising exchanges, complex event processing, and publish/subscribe systems. However, most solutions can support only conjunctive Boolean expression matching. The limited number of solutions that can directly work on arbitrary Boolean expressions present performance and flexibility limitations. Moreover, normalizing arbitrary Boolean expressions into conjunctive forms and then using existing methods for evaluating such expressions is not effective because of the potential exponential increase in the size of the expressions. Therefore, we propose the A-Tree data structure to efficiently index arbitrary Boolean expressions. A-Tree is a multirooted tree, in which predicates and subexpressions from different arbitrary Boolean expressions are aggregated and shared. A-Tree employs dynamic self-adjustment policies to adapt itself as the workload changes. Moreover, A-Tree adopts different event matching optimizations. Our comprehensive experiments show that A-Tree-based matching outperforms existing arbitrary Boolean expression matching algorithms in terms of memory use, matching time, and index construction time by up to 71%, 99% and 75%, respectively. Even on conjunctive expression workloads, A-Tree achieves a lower matching time than state-of-the-art conjunctive expression matching algorithms.}
}


@inproceedings{DBLP:conf/sigmod/0004WZZQHDG21,
	author = {Peng Jia and
                  Pinghui Wang and
                  Junzhou Zhao and
                  Shuo Zhang and
                  Yiyan Qi and
                  Min Hu and
                  Chao Deng and
                  Xiaohong Guan},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Bidirectionally Densifying {LSH} Sketches with Empty Bins},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {830--842},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452833},
	doi = {10.1145/3448016.3452833},
	timestamp = {Mon, 21 Jun 2021 11:48:44 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/0004WZZQHDG21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As an efficient tool for approximate similarity computation and search, Locality Sensitive Hashing (LSH) has been widely used in many research areas including databases, data mining, information retrieval, and machine learning. Classical LSH methods typically require to perform hundreds or even thousands of hashing operations when computing the LSH sketch for each input item (e.g., a set or a vector); however, this complexity is still too expensive and even impractical for applications requiring processing data in real-time. To address this issue, several fast methods such as OPH and BCWS have been proposed to efficiently compute the LSH sketches; however, these methods may generate many sketches with empty bins, which may introduce large errors for similarity estimation and also limit their usage for fast similarity search. To solve this issue, we propose a novel densification method, i.e., BiDens. Compared with existing densification methods, our BiDens is more efficient to fill a sketch's empty bins with values of its non-empty bins in either the forward or backward directions. Furthermore, it also densifies empty bins to satisfy the densification principle (i.e., the LSH property). Theoretical analysis and experimental results on similarity estimation, fast similarity search, and kernel linearization using real-world datasets demonstrate that our BiDens is up to 106 times faster than state-of-the-art methods while achieving the same or even better accuracy.}
}


@inproceedings{DBLP:conf/sigmod/JiangLPCME21,
	author = {Hao Jiang and
                  Chunwei Liu and
                  John Paparrizos and
                  Andrew A. Chien and
                  Jihong Ma and
                  Aaron J. Elmore},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Good to the Last Bit: Data-Driven Encoding with CodecDB},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {843--856},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457283},
	doi = {10.1145/3448016.3457283},
	timestamp = {Mon, 04 Dec 2023 21:29:46 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/JiangLPCME21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Columnar databases rely on specialized encoding schemes to reduce storage requirements. These encodings also enable efficient in-situ data processing. Nevertheless, many existing columnar databases are encoding-oblivious. When storing the data, these systems rely on a global understanding of the dataset or the data types to derive simple rules for encoding selection. Such rule-based selection leads to unsatisfactory performance. Specifically, when performing queries, the systems always decode data into memory, ignoring the possibility of optimizing access to encoded data. We develop CodecDB, an encoding-aware columnar database, to demonstrate the benefit of tightly-coupling the database design with the data encoding schemes. CodecDB chooses in a principled manner the most efficient encoding for a given data column and relies on encoding-aware query operators to optimize access to encoded data. Storage-wise, CodecDB achieves on average 90% accuracy for selecting the best encoding and improves the compression ratio by up to 40% compared to the state-of-the-art encoding selection solution. Query-wise, CodecDB is on average one order of magnitude faster than the latest open-source and commercial columnar databases on the TPC-H benchmark, and on average 3x faster than a recent research project on the Star-Schema Benchmark (SSB).}
}


@inproceedings{DBLP:conf/sigmod/JiangGLWAKS0021,
	author = {Jiawei Jiang and
                  Shaoduo Gan and
                  Yue Liu and
                  Fanlin Wang and
                  Gustavo Alonso and
                  Ana Klimovic and
                  Ankit Singla and
                  Wentao Wu and
                  Ce Zhang},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Towards Demystifying Serverless Machine Learning Training},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {857--871},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3459240},
	doi = {10.1145/3448016.3459240},
	timestamp = {Mon, 03 Mar 2025 21:21:49 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/JiangGLWAKS0021.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The appeal of serverless (FaaS) has triggered a growing interest on how to use it in data-intensive applications such as ETL, query processing, or machine learning (ML). Several systems exist for training large-scale ML models on top of serverless infrastructures (e.g., AWS Lambda) but with inconclusive results in terms of their performance and relative advantage over "serverful" infrastructures (IaaS). In this paper we present a systematic, comparative study of distributed ML training over FaaS and IaaS. We present a design space covering design choices such as optimization algorithms and synchronization protocols, and implement a platform, LambdaML, that enables a fair comparison between FaaS and IaaS. We present experimental results using LambdaML, and further develop an analytic model to capture cost/performance tradeoffs that must be considered when opting for a serverless infrastructure. Our results indicate that ML training pays off in serverless only for models with efficient (i.e., reduced) communication and that quickly converge. In general, FaaS can be much faster but it is never significantly cheaper than IaaS.}
}


@inproceedings{DBLP:conf/sigmod/JinQZ21,
	author = {Wen Jin and
                  Weining Qian and
                  Aoying Zhou},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Efficient String Sort with Multi-Character Encoding and Adaptive Sampling},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {872--884},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457319},
	doi = {10.1145/3448016.3457319},
	timestamp = {Mon, 21 Jun 2021 11:48:44 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/JinQZ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Sorting plays a fundamental role in computer science. It has far reaching applications in database operations and data science tasks. An important class of sorting keys are strings and among all string sorting methods, radix sort is a simple but effective algorithm. Many works have been studied to accelerate radix string sort. One typical approach is to process multiple characters in each sorting pass. However, this approach incurs the crucial issue of the radix being too large. To address the problem, we introduce a novel multi-character encoding based method that can significantly reduce the radix. This new encoding scheme takes advantage of the sparse alphabet space usage as well as the sparsity of distinguishing prefixes of the inputs which are commonly seen in real-world datasets. Combining the effective encoding scheme with an adaptive sampling process to generate the encoding efficiently, our proposed sorting algorithm essentially blends radix sort with sample sort and achieves substantial improvement over other sorting approaches. The results on both real datasets and synthetic datasets show that our method yields an average 4.85× performance improvement over C++ STL sort[21], 1.47× improvement over the state-of-the-art Radix Sort on strings implementation[19] and 2.55× over the multikey quicksort[6]. Preliminary tests in a multi-core environment also show it is competitive or better than the most recent parallel string sorting algorithm pS5[8] which demonstrates the scalability of our method.}
}


@inproceedings{DBLP:conf/sigmod/KalamatianosFM21,
	author = {Georgios Kalamatianos and
                  Georgios John Fakas and
                  Nikos Mamoulis},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Proportionality in Spatial Keyword Search},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {885--897},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457309},
	doi = {10.1145/3448016.3457309},
	timestamp = {Thu, 14 Oct 2021 10:11:40 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/KalamatianosFM21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {More often than not, spatial objects are associated with some context, in the form of text, descriptive tags (e.g. points of interest, flickr photos), or linked entities in semantic graphs (e.g. Yago2, DBpedia). Hence, location-based retrieval should be extended to consider not only the locations but also the context of the objects, especially when the retrieved objects are too many and the query result is overwhelming. In this paper, we study the problem of selecting a subset of the query result, which is the most representative. We argue that objects with similar context and nearby locations should proportionally be represented in the selection. Proportionality dictates the pairwise comparison of all retrieved objects and hence bears a high cost. We propose novel algorithms which greatly reduce the cost of proportional object selection in practice. Extensive empirical studies on real datasets show that our algorithms are effective and efficient. A user evaluation verifies that proportional selection is more preferable than random selection and selection based on object diversification.}
}


@inproceedings{DBLP:conf/sigmod/KangJB21,
	author = {Donghe Kang and
                  Ruochen Jiang and
                  Spyros Blanas},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Jigsaw: {A} Data Storage and Query Processing Engine for Irregular
                  Table Partitioning},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {898--911},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457547},
	doi = {10.1145/3448016.3457547},
	timestamp = {Mon, 21 Jun 2021 11:48:44 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/KangJB21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The physical data layout significantly impacts performance when database systems access cold data. In addition to the traditional row store and column store designs, recent research proposes to partition tables hierarchically, starting from either horizontal or vertical partitions and then determining the best partitioning strategy on the other dimension independently for each partition. All these partitioning strategies naturally produce rectangular partitions. Coarse-grained rectangular partitioning reads unnecessary data when a table cannot be partitioned along one dimension for all queries. Fine-grained rectangular partitioning produces many small partitions which negatively impacts I/O performance and possibly introduces a high tuple reconstruction overhead. This paper introduces Jigsaw, a system that employs a novel partitioning strategy that creates partitions with arbitrary shapes, which we refer to as irregular partitions. The traditional tuple-at-a-time or operator-at-a-time query processing models cannot fully leverage the advantages of irregular partitioning, because they may repeatedly read a partition due to its irregular shape. Jigsaw introduces a partition-at-a-time evaluation strategy to avoid repeated accesses to an irregular partition. We implement and evaluate Jigsaw on the HAP and TPC-H benchmarks and find that irregular partitioning is up to 4.2×faster than a columnar layout for moderately selective queries. Compared with the columnar layout, irregular partitioning only transfers 21% of the data to complete the same query.}
}


@inproceedings{DBLP:conf/sigmod/KhuranaH21,
	author = {Kapil Khurana and
                  Jayant R. Haritsa},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Shedding Light on Opaque Application Queries},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {912--924},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457252},
	doi = {10.1145/3448016.3457252},
	timestamp = {Mon, 21 Jun 2021 11:48:44 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/KhuranaH21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We investigate a new query reverse-engineering problem of unmasking SQL queries hidden within database applications. The diverse use-cases for this problem range from resurrecting legacy code to query rewriting. As a first step in addressing the unmasking challenge, we present UNMASQUE, an active-learning extraction algorithm that can expose a basal class of hidden warehouse queries. A special feature of our design is that the extraction is non-invasive wrt the application, examining only the results obtained from repeated executions on databases derived with a combination of data mutation and data generation techniques. Further, potent optimizations are incorporated to minimize the extraction overheads. A detailed evaluation over applications hosting hidden SQL queries, or their imperative versions, demonstrates that UNMASQUE correctly and efficiently extracts these queries.}
}


@inproceedings{DBLP:conf/sigmod/KimCP0HH21,
	author = {Hyunjoon Kim and
                  Yunyoung Choi and
                  Kunsoo Park and
                  Xuemin Lin and
                  Seok{-}Hee Hong and
                  Wook{-}Shin Han},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Versatile Equivalences: Speeding up Subgraph Query Processing and
                  Subgraph Matching},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {925--937},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457265},
	doi = {10.1145/3448016.3457265},
	timestamp = {Thu, 27 Apr 2023 14:57:19 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/KimCP0HH21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Subgraph query processing (also known as subgraph search) and subgraph matching are fundamental graph problems in many application domains. A lot of efforts have been made to develop practical solutions for these problems. Despite the efforts, existing algorithms showed limited running time and scalability in dealing with large and/or many graphs. In this paper, we propose a new subgraph search algorithm using equivalences of vertices in order to reduce search space: (1) static equivalence of vertices in a query graph that leads to an efficient matching order of the vertices, and (2) dynamic equivalence of candidate vertices in a data graph, which enables us to capture and remove redundancies in search space. These techniques for subgraph search also lead to an improved algorithm for subgraph matching. Experiments show that our approach outperforms state-of-the-art subgraph search and subgraph matching algorithms by up to several orders of magnitude with respect to query processing time.}
}


@inproceedings{DBLP:conf/sigmod/KimKCYKJ21,
	author = {Jong{-}Bin Kim and
                  Kihwang Kim and
                  Hyunsoo Cho and
                  Jaeseon Yu and
                  Sooyong Kang and
                  Hyungsoo Jung},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Rethink the Scan in {MVCC} Databases},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {938--950},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452783},
	doi = {10.1145/3448016.3452783},
	timestamp = {Sun, 19 Jan 2025 13:27:18 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/KimKCYKJ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A scan is one of the fundamental operations in databases for retrieving tuples from tables, and research on access methods has been of importance to query optimization. However, our community is aware of the inconvenient truth that its performance may plummet amid steep increases in search costs when acting on MVCC databases since multi-versioning may forfeit all the benefits of using database indexes. An execution plan for a query on multi-versioned data often comprises a series of point lookup operations, of which each internally executes a linear traversal of record versions. Therefore, the generated plan is surprisingly worse than a full table (or version store) scan, mainly due to redundant access to database pages. To address such an all-or-nothing approach, we propose version weaver (vWeaver), a light-weight access method for record versions, that expedites a scan on record versions with each being augmented by just a few pointer fields. vWeaver incrementally constructs a version search structure over even an append-only version store (e.g., undo space) and allows a scan to traverse new version search structures for fast lookup. We applied vWeaver to in-memory and disk-based MVCC databases and demonstrated that the systems with vWeaver generally improved scan performance under various workloads with negligible space overhead.}
}


@inproceedings{DBLP:conf/sigmod/Kim21,
	author = {Jongik Kim},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Boosting Graph Similarity Search through Pre-Computation},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {951--963},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452780},
	doi = {10.1145/3448016.3452780},
	timestamp = {Mon, 21 Jun 2021 11:48:44 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/Kim21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graph similarity search is to retrieve all graphs from a graph database whose graph edit distance (GED) to a query graph is within a given threshold. As GED computation is NP-hard, existing solutions adopt the filtering-and-verification framework, where the main focus is on the filtering phase to reduce the number of GED verifications. However, existing filtering techniques have inherently limited filtering capabilities, and suffer from a large number of GED verifications. To address the problem, in this paper, we propose a fundamentally different approach that utilizes pre-computed GEDs between data graphs in the filtering phase. Based on the approach, we develop a novel search framework Nass, which substantially reduces the verification workload. Because the efficiency of GED computation is essential in GED pre-computation, not to mention the verification of candidate graphs, we also propose an efficient GED computation algorithm as a part of Nass. We conduct extensive experiments on real datasets, and show Nass significantly outperforms the state-of-the art solutions.}
}


@inproceedings{DBLP:conf/sigmod/KimKFH21,
	author = {Kyoungmin Kim and
                  Hyeonji Kim and
                  George Fletcher and
                  Wook{-}Shin Han},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Combining Sampling and Synopses with Worst-Case Optimal Runtime and
                  Quality Guarantees for Graph Pattern Cardinality Estimation},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {964--976},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457246},
	doi = {10.1145/3448016.3457246},
	timestamp = {Thu, 02 May 2024 17:06:40 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/KimKFH21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graph pattern cardinality estimation is the problem of estimating the number of embeddings of a query graph in a data graph. This fundamental problem arises, for example, during query planning in subgraph matching algorithms. There are two major approaches to solving the problem: sampling and synopsis. Synopsis (or summary)-based methods are fast and accurate if synopses capture information of graphs well. However, these methods suffer from large errors due to loss of information during summarization and inherent assumptions. Sampling-based methods are unbiased but suffer from large estimation variance due to large sample space. To address these limitations, we propose Alley, a hybrid method that combines both sampling and synopses. Alley employs 1) a novel sampling strategy, random walk with intersection, which effectively reduces the sample space, 2) branching to further reduce variance, and 3) a novel mining approach that extracts and indexes tangled patterns as synopses which are inherently difficult to estimate by sampling. By using them in the online estimation phase, we can effectively reduce the sample space while still ensuring unbiasedness. We establish that Alley has worst-case optimal runtime and approximation quality guarantees for any given error bound ε and required confidence μ. In addition to the theoretical aspect of Alley, our extensive experiments show that Alley outperforms the state-of-the-art methods by up to orders of magnitude higher accuracy with similar efficiency.}
}


@inproceedings{DBLP:conf/sigmod/KoLHLSSH21,
	author = {Seongyun Ko and
                  Taesung Lee and
                  Kijae Hong and
                  Wonseok Lee and
                  In Seo and
                  Jiwon Seo and
                  Wook{-}Shin Han},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {iTurboGraph: Scaling and Automating Incremental Graph Analytics},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {977--990},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457243},
	doi = {10.1145/3448016.3457243},
	timestamp = {Thu, 02 Mar 2023 22:13:02 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/KoLHLSSH21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the rise of streaming data for dynamic graphs, large-scale graph analytics meets a new requirement of Incremental Computation because the larger the graph, the higher the cost for updating the analytics results by re-execution. A dynamic graph consists of an initial graph G and graph mutation updates Δ G$ of edge insertions or deletions. Given a query Q, its results $Q(G)$, and updates for Δ G$ to G, incremental graph analytics computes updates Δ Q$ such that Q($G \\cup Δ G)$ = $Q(G)$ $\\cup$ Δ Q$ where $\\cup$ is a union operator. In this paper, we consider the problem of large-scale incremental neighbor-centric graph analytics (\\NGA ). We solve the limitations of previous systems: lack of usability due to the difficulties in programming incremental algorithms for \\NGA and limited scalability and efficiency due to the overheads in maintaining intermediate results for graph traversals in \\NGA. First, we propose a domain-specific language, ŁNGA, and develop its compiler for intuitive programming of \\NGA, automatic query incrementalization, and query optimizations. Second, we define Graph Streaming Algebra as a theoretical foundation for scalable processing of incremental \\NGA. We introduce a concept of Nested Graph Windows and model graph traversals as the generation of walk streams. Lastly, we present a system \\SystemName, which efficiently processes incremental \\NGA for large graphs. Comprehensive experiments show that it effectively avoids costly re-executions and efficiently updates the analytics results with reduced IO and computations.}
}


@inproceedings{DBLP:conf/sigmod/KohnL021,
	author = {Andr{\'{e}} Kohn and
                  Viktor Leis and
                  Thomas Neumann},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Building Advanced {SQL} Analytics From Low-Level Plan Operators},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {1001--1013},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457288},
	doi = {10.1145/3448016.3457288},
	timestamp = {Thu, 27 Jul 2023 08:32:09 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/KohnL021.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Analytical queries virtually always involve aggregation and statistics. SQL offers a wide range of functionalities to summarize data such as associative aggregates, distinct aggregates, ordered-set aggregates, grouping sets, and window functions. In this work, we propose a unified framework for advanced statistics that composes all flavors of complex SQL aggregates from low-level plan operators. These operators can reuse materialized intermediate results, which decouples monolithic aggregation logic and speeds up complex multi-expression queries. The contribution is therefore twofold: our framework modularizes aggregate implementations, and outperforms traditional systems whenever multiple aggregates are combined. We integrated our approach into the high-performance database system Umbra and experimentally show that we compute complex aggregates faster than the state-of-the-art HyPer system.}
}


@inproceedings{DBLP:conf/sigmod/Kang0TCSH21,
	author = {Johan Kok Zhi Kang and
                  Gaurav and
                  Sien Yi Tan and
                  Feng Cheng and
                  Shixuan Sun and
                  Bingsheng He},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Efficient Deep Learning Pipelines for Accurate Cost Estimations Over
                  Large Scale Query Workload},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {1014--1022},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457546},
	doi = {10.1145/3448016.3457546},
	timestamp = {Mon, 21 Jun 2021 11:48:44 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/Kang0TCSH21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The use of deep learning models for forecasting the resource consumption patterns of SQL queries have recently been a popular area of study. While these models have demonstrated promising accuracy, training them over large scale industry workloads are expensive. Space inefficiencies of encoding techniques over large numbers of queries and excessive padding used to enforce shape consistency across diverse query plans implies 1) longer model training time and 2) the need for expensive, scaled up infrastructure to support batched training. In turn, we developed Prestroid, a tree convolution based data science pipeline that accurately predicts resource consumption patterns of query traces, but at a much lower cost. We evaluated our pipeline over 19K Presto OLAP queries, on a data lake of more than 20PB of data from Grab. Experimental results imply that our pipeline outperforms benchmarks on predictive accuracy, contributing to more precise resource prediction for large-scale workloads, yet also reduces per-batch memory footprint by 13.5x and per-epoch training time by 3.45x. We demonstrate direct cost savings of up to 13.2x for large batched model training over Microsoft Azure VMs.}
}


@inproceedings{DBLP:conf/sigmod/KorberGS21,
	author = {Michael K{\"{o}}rber and
                  Nikolaus Glombiewski and
                  Bernhard Seeger},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Index-Accelerated Pattern Matching in Event Stores},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {1023--1036},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457245},
	doi = {10.1145/3448016.3457245},
	timestamp = {Mon, 21 Jun 2021 11:48:44 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/KorberGS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {IoT applications require a new type of database systems termed event stores for ingesting fast arriving event streams and efficiently supporting analytical ad-hoc queries over time. One of the most important operations in this regard is sequential pattern matching also known as Match\\_Recognize, which matches user defined predicates to subsequences of events. While Match\\_Recognize is well known in the field of event processing, it has only recently become part of the SQL standard. Despite of that, Match\\_Recognize has received little attention in the database area so far. We present a novel approach to speed up an important class of Match\\_Recognize queries on event stores by utilizing off-the-shelf secondary indexes on non-temporal attributes (e.g., B$^+$-trees, LSM-trees) and a cost model for selecting the most appropriate indexes. Our approach keeps temporal and sequential information in secondary indexes to prune large parts of the stream from further processing. However, simply using as many secondary indexes as available is not the right choice because the access cost for the index scans can exceed the processing time of the naï ve approach that scans the entire stream and replays it into an event processing system. In order to address this problem, we present a first cost model to estimate the total execution cost of a Match\\_Recognize query for a set of available indexes. Based on this cost model, we devise an efficient index selection strategy that avoids a full enumeration of index configurations. Prototypical implementations of our approach are available in our open-source research prototype, a commercial database system, and Apache Flink. In experiments with synthetic and real-world data sets, all our index-based implementations clearly outperform the naï ve replay strategy that is currently offered in commercial database systems and Flink.}
}


@inproceedings{DBLP:conf/sigmod/LaiHLZ0K21,
	author = {Ziliang Lai and
                  Chenxia Han and
                  Chris Liu and
                  Pengfei Zhang and
                  Eric Lo and
                  Ben Kao},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Top-K Deep Video Analytics: {A} Probabilistic Approach},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {1037--1050},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452786},
	doi = {10.1145/3448016.3452786},
	timestamp = {Mon, 21 Jun 2021 11:48:44 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/LaiHLZ0K21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The impressive accuracy of deep neural networks (DNNs) has created great demands on practical analytics over video data. Although efficient and accurate, the latest video analytic systems have not supported analytics beyond selection and aggregation queries. In data analytics, Top-K is a very important analytical operation that enables analysts to focus on the most important entities. In this paper, we present Everest, the first system that supports efficient and accurate Top-K video analytics. Everest ranks and identifies the most interesting frames/moments from videos with probabilistic guarantees. Everest is a system built with a careful synthesis of deep computer vision models, uncertain data management, and Top-K query processing. Evaluations on real-world videos and the latest Visual Road benchmark show that Everest achieves between 14.3x to 20.6x higher efficiency than baseline approaches with high result accuracy.}
}


@inproceedings{DBLP:conf/sigmod/LiMZGR21,
	author = {Chenjie Li and
                  Zhengjie Miao and
                  Qitian Zeng and
                  Boris Glavic and
                  Sudeepa Roy},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Putting Things into Context: Rich Explanations for Query Answers using
                  Join Graphs},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {1051--1063},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3459246},
	doi = {10.1145/3448016.3459246},
	timestamp = {Sun, 12 Nov 2023 02:07:18 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/LiMZGR21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In many data analysis applications there is a need to explain why a surprising or interesting result was produced by a query. Previous approaches to explaining results have directly or indirectly relied on data provenance, i.e., input tuples contributing to the result(s) of interest. However, some information that is relevant for explaining an answer may not be contained in the provenance. We propose a new approach for explaining query results by augmenting provenance with information from other related tables in the database. Using a suite of optimization techniques, we demonstrate experimentally using real datasets and through a user study that our approach produces meaningful results and is efficient.}
}


@inproceedings{DBLP:conf/sigmod/LiCCHC21,
	author = {Peng Li and
                  Xiang Cheng and
                  Xu Chu and
                  Yeye He and
                  Surajit Chaudhuri},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Auto-FuzzyJoin: Auto-Program Fuzzy Similarity Joins Without Labeled
                  Examples},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {1064--1076},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452824},
	doi = {10.1145/3448016.3452824},
	timestamp = {Fri, 23 May 2025 21:08:46 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/LiCCHC21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Fuzzy similarity join is an important database operator widely used in practice. So far the research community has focused exclusively on optimizing fuzzy joinscalability. However, practitioners today also struggle to optimize fuzzy-joinquality, because they face a daunting space of parameters (e.g., distance-functions, distance-thresholds, tokenization-options, etc.), and often have to resort to a manual trial-and-error approach to program these parameters in order to optimize fuzzy-join quality. This key challenge of automatically generating high-quality fuzzy-join programs has received surprisingly little attention thus far. In this work, we study the problem of "auto-program\'\' fuzzy-joins. Leveraging a geometric interpretation of distance-functions, we develop an unsupervised Auto-FuzzyJoin framework that can infer suitable fuzzy-join programs on given input tables, without requiring explicit human input such as labelled training data. Using Auto-FuzzyJoin, users only need to provide two input tables L and R, and a desired precision target τ (say 0.9). Auto-FuzzyJoin leverages the fact that one of the input is a reference table to automatically program fuzzy-joins that meet the precision target τ in expectation, while maximizing fuzzy-join recall (defined as the number of correctly joined records). Experiments on both existing benchmarks and a new benchmark with 50 fuzzy-join tasks created from Wikipedia data suggest that the proposed Auto-FuzzyJoin significantly outperforms existing unsupervised approaches, and is surprisingly competitive even against supervised approaches (e.g., Magellan and DeepMatcher) when 50% of ground-truth labels are used as training data. We have released our code and benchmark on GitHub\\footnote\\urlhttps://github.com/chu-data-lab/AutomaticFuzzyJoin to facilitate future research.}
}


@inproceedings{DBLP:conf/sigmod/LiWZZDYY21,
	author = {Rundong Li and
                  Pinghui Wang and
                  Jiongli Zhu and
                  Junzhou Zhao and
                  Jia Di and
                  Xiaofei Yang and
                  Kai Ye},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Building Fast and Compact Sketches for Approximately Multi-Set Multi-Membership
                  Querying},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {1077--1089},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452829},
	doi = {10.1145/3448016.3452829},
	timestamp = {Mon, 24 Feb 2025 22:56:33 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/LiWZZDYY21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Given a set S, Membership Querying (MQ) answers whether a query element $q\\in S$. It is a fundamental task in areas like database systems and computer networks. In this paper, we consider a more general problem, Multi-Set Multi-Membership Querying (MS-MMQ). Given n sets $S_0,łdots,S_n-1 $, MS-MMQ answers which sets contain element q. A direct way to address MS-MMQ is to build an MQ structure (e.g., Bloom Filter) for each set. However, the query and space complexities grow linearly with n and become prohibitive for a large n. To address this challenge, we propose a novel Circular Shift and Coalesce (CSC) framework to efficiently achieve approximate MS-MMQ. Instead of building an MQ data structure for each set, the CSC index encodes all n sets into a compact sketch and retrieves only a few bytes in the sketch for a query, which achieves high memory-efficiency and boosts the query speed by several times. CSC is compatible with mainstream data structures for Approximate MQ. We conduct experiments on real-world datasets and results demonstrate that our framework is up to 91.2 times faster and up to 48.9 times more accurate than state-of-the-art methods.}
}


@inproceedings{DBLP:conf/sigmod/LiCFMK21,
	author = {Tianyu Li and
                  Badrish Chandramouli and
                  Jose M. Faleiro and
                  Samuel Madden and
                  Donald Kossmann},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Asynchronous Prefix Recoverability for Fast Distributed Stores},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {1090--1102},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3458454},
	doi = {10.1145/3448016.3458454},
	timestamp = {Sun, 19 Jan 2025 13:27:26 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/LiCFMK21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Accessing and updating data sharded across distributed machines safely and speedily in the face of failures remains a challenging problem. Most prominently, applications that share state across different nodes want their writes to quickly become visible to others, without giving up recoverability guarantees in case a failure occurs. Current solutions of a fast cache backed by storage cannot support this use case easily. In this work, we design a distributed protocol, called Distributed Prefix Recovery (DPR) that builds on top of a sharded cache-store architecture with single-key operations, to provide cross-shard recoverability guarantees. With DPR, many clients can read and update shared state at sub-millisecond latency, while receiving periodic prefix durability guarantees. On failure, DPR quickly restores the system to a prefix-consistent state with a novel non-blocking rollback scheme. We added DPR to a key-value store (FASTER) and cache (Redis) and show that we can get high throughput and low latency similar to in-memory systems, while lazily providing durability guarantees similar to persistent stores.}
}


@inproceedings{DBLP:conf/sigmod/LiG21,
	author = {Yan Li and
                  Tingjian Ge},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Imminence Monitoring of Critical Events: {A} Representation Learning
                  Approach},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {1103--1115},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452804},
	doi = {10.1145/3448016.3452804},
	timestamp = {Sun, 19 Jan 2025 13:27:27 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/LiG21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Complex event monitoring is an important problem in data streams that has drawn much attention. Most previous work assumes that the user knows and provides a complex event pattern for the system to continuously monitor. However, we observe that in many real applications, such as healthcare, security, and businesses, there are heterogeneous substreams and a diverse set of attributes. Often there is no simple uniform pattern prior to a critical event; nor is there clean simple language to describe the pattern leading to the critical event. People often only know it after the fact -- e.g., when something undesirable happens. We propose a novel approach based on relational machine learning and representation learning. We propose and learn probabilistic state machine patterns, which are used to monitor and predict the imminence of critical events. Our experiments demonstrate the efficiency and effectiveness of our approach, as well as its clear superiority over the closest previous approaches such as IL-Miner and LSTM based early prediction.}
}


@inproceedings{DBLP:conf/sigmod/LiGGMP021,
	author = {Yin Li and
                  Dhrubajyoti Ghosh and
                  Peeyush Gupta and
                  Sharad Mehrotra and
                  Nisha Panwar and
                  Shantanu Sharma},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {{PRISM:} Private Verifiable Set Computation over Multi-Owner Outsourced
                  Databases},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {1116--1128},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452839},
	doi = {10.1145/3448016.3452839},
	timestamp = {Sun, 19 Jan 2025 13:27:18 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/LiGGMP021.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper proposes Prism, a secret sharing based approach to compute private set operations (i.e., intersection and union), as well as aggregates over outsourced databases belonging to multiple owners. Prism enables data owners to pre-load the data onto non-colluding servers and exploits the additive and multiplicative properties of secret-shares to compute the above-listed operations in (at most) two rounds of communication between the servers (storing the secret-shares) and the querier, resulting in a very efficient implementation. Also, Prism does not require communication among the servers and supports result verification techniques for each operation to detect malicious adversaries. Experimental results show that Prism scales both in terms of the number of data owners and database sizes, to which prior approaches do not scale.}
}


@inproceedings{DBLP:conf/sigmod/0002SSK21,
	author = {Xi Liang and
                  Stavros Sintos and
                  Zechao Shang and
                  Sanjay Krishnan},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Combining Aggregation and Sampling (Nearly) Optimally for Approximate
                  Query Processing},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {1129--1141},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457277},
	doi = {10.1145/3448016.3457277},
	timestamp = {Mon, 21 Jun 2021 11:48:44 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/0002SSK21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Sample-based approximate query processing (AQP) suffers from many pitfalls such as the inability to answer very selective queries and unreliable confidence intervals when sample sizes are small. Recent research presented an intriguing solution of combining materialized, pre-computed aggregates with sampling for accurate and more reliable AQP. We explore this solution in detail in this work and propose an AQP physical design called PASS, or Precomputation-Assisted Stratified Sampling. PASS builds a tree of partial aggregates that cover different partitions of the dataset. The leaf nodes of this tree form the strata for stratified samples. Aggregate queries whose predicates align with the partitions (or unions of partitions) are exactly answered with a depth-first search, and any partial overlaps are approximated with the stratified samples. We propose an algorithm for optimally partitioning the data into such a data structure with various practical approximation techniques.}
}


@inproceedings{DBLP:conf/sigmod/LinCZ21,
	author = {Xueling Lin and
                  Lei Chen and
                  Chaorui Zhang},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {{TENET:} Joint Entity and Relation Linking with Coherence Relaxation},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {1142--1155},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457280},
	doi = {10.1145/3448016.3457280},
	timestamp = {Sun, 19 Jan 2025 13:27:31 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/LinCZ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The joint entity and relation linking task aims to connect the noun phrases (resp., relational phrases) extracted from natural language documents to the entities (resp., predicates) in general knowledge bases (KBs). This task benefits numerous downstream systems, such as question answering and KB population. Previous works on entity and relation linking rely on the global coherence assumption, i.e., entities and predicates within the same document are highly correlated with each other. However, this assumption is not always valid in many real-world scenarios. Due to KB incompleteness or data sparsity, sparse coherence among the entities and predicates within the same document is common. Moreover, there may exist isolated entities or predicates that are not related to any other linked concepts. In this paper, we propose TENET, a joint entity and relation linking technique, which relaxes the coherence assumption in an unsupervised manner. Specifically, we formulate the joint entity and relation linking task as a minimum-cost rooted tree cover problem on the knowledge coherence graph constructed based on the document. We then propose effective approximation algorithms with pruning strategies to solve this problem and derive the linking results. Extensive experiments on real-world datasets demonstrate the superior effectiveness and efficiency of our method against the state-of-the-art techniques.}
}


@inproceedings{DBLP:conf/sigmod/LinTLCW21,
	author = {Yu{-}Shan Lin and
                  Ching Tsai and
                  Tz{-}Yu Lin and
                  Yun{-}Sheng Chang and
                  Shan{-}Hung Wu},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Don't Look Back, Look into the Future: Prescient Data Partitioning
                  and Migration for Deterministic Database Systems},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {1156--1168},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452827},
	doi = {10.1145/3448016.3452827},
	timestamp = {Sun, 19 Jan 2025 13:27:33 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/LinTLCW21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Deterministic database systems have been shown to significantly improve the availability and scalability of a distributed database system deployed on a shared-nothing architecture across WAN while ensuring strong consistency. However, their scalability and performance advantages highly depend on the quality of data partitioning due to the reduced flexibility in transaction processing. Although a deterministic database system can employ workload driven data (re-)partitioning and live data migration algorithms to partition data, we found that the effectiveness of these algorithms is limited in complex real-world environments due to the unpredictability of machine workloads. In this paper, we present Hermes, a deterministic database system prototype that, for the first time, does not rely on sophisticated data partitioning to achieve high scalability and performance. Hermes employs a novel transaction routing mechanism that jointly optimizes the balance of machine workloads, data (re-)partitioning, and live data migration by looking into the queued transactions to be executed in the near future. We conducted extensive experiments which show that Hermes is able to yield 29% to 137% increase in transaction throughput as compared to the state-of-the-art systems under complex real-world workloads.}
}


@inproceedings{DBLP:conf/sigmod/LinkW21,
	author = {Sebastian Link and
                  Ziheng Wei},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Logical Schema Design that Quantifies Update Inefficiency and Join
                  Efficiency},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {1169--1181},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3459238},
	doi = {10.1145/3448016.3459238},
	timestamp = {Mon, 21 Jun 2021 11:48:44 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/LinkW21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The goal of classical normalization is to maintain data consistency under updates, with a minimum level of effort. Given functional dependencies (FDs) alone, this goal is only achievable in the special case an FD-preserving Boyce-Codd Normal Form (BCNF) decomposition exists. As we show, in all other cases the level of effort can be neither controlled nor quantified. In response, we establish the l-Bounded Cardinality Normal Form, parameterized by a positive integer l. For every l, the normal form condition requires from every instance that every value combination over the left-hand side of every non-trivial FD does not occur in more than l tuples. BCNF is captured when l=1. We demonstrate that schemata in this normal form characterize the instances that are i) free from level l data redundancy and update inefficiency, and ii) permit level l join efficiency. We establish algorithms that compute schemata in l-Bounded Cardinality Normal Form for the smallest level l attainable across all FD-preserving decompositions. Additional algorithms i) attain even smaller levels of effort based on the loss of some FDs, and ii) decompose schemata based on prioritized FDs that cause high levels of effort. Our framework informs de-normalization already during logical design. In particular, level l quantifies both the incremental maintenance and join support of materialized views. Experiments with synthetic and real-world data illustrate which properties the schemata have that result from our algorithms, and how these properties predict the performance of update and query operations on instances over the schemata, without and with materialized views.}
}


@inproceedings{DBLP:conf/sigmod/LivshitsKTIKR21,
	author = {Ester Livshits and
                  Rina Kochirgan and
                  Segev Tsur and
                  Ihab F. Ilyas and
                  Benny Kimelfeld and
                  Sudeepa Roy},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Properties of Inconsistency Measures for Databases},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {1182--1194},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457310},
	doi = {10.1145/3448016.3457310},
	timestamp = {Sun, 19 Jan 2025 13:27:26 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/LivshitsKTIKR21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {How should we quantify the inconsistency of a database that violates integrity constraints? Proper measures are important for various tasks, such as progress indication and action prioritization in cleaning systems, and reliability estimation for new datasets. To choose an appropriate inconsistency measure, it is important to identify the desired properties in the application and understand which of these is guaranteed or at least expected in practice. For example, in some use cases, the inconsistency should reduce if constraints are eliminated; in others, it should be stable and avoid jitters and jumps in reaction to small changes in the database. We embark on a systematic investigation of properties for database inconsistency measures. We investigate a collection of basic measures that have been proposed in the past in both the Knowledge Representation and Database communities, analyze their theoretical properties, and empirically observe their behavior in an experimental study. We also demonstrate how the framework can lead to new inconsistency measures by introducing a new measure that, in contrast to the rest, satisfies all of the properties we consider and can be computed in polynomial time.}
}


@inproceedings{DBLP:conf/sigmod/LuYZ021,
	author = {Can Lu and
                  Jeffrey Xu Yu and
                  Zhiwei Zhang and
                  Hong Cheng},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Graph Iso/Auto-morphism: {A} Divide-{\&}-Conquer Approach},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {1195--1207},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452820},
	doi = {10.1145/3448016.3452820},
	timestamp = {Mon, 21 Jun 2021 11:48:44 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/LuYZ021.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The graph isomorphism is to determine whether two graphs are isomorphic. A closely related problem is graph automorphism (symmetry) detection, where an isomorphism between two graphs is a bijection between their vertex sets that preserves adjacency, and an automorphism is an isomorphism from a graph to itself. By graph automorphism, we deal with symmetric subgraph matching (SSM), which is to find all subgraphs in a graph G that are symmetric to a given subgraph q in G. To test two graphs for isomorphism, canonical labeling has been studied to relabel a graph in such a way that isomorphic graphs are identical after relabeling. Efficient canonical labeling algorithms are designed by individualization-refinement. They enumerate all permutations using a search tree, and select the minimum one as the canonical labeling. These algorithms face difficulties in handling massive graphs, and the search trees used are for pruning purposes which cannot answer symmetric subgraphs matching. In this paper, we design a new efficient canonical labeling algorithm DviCL based on the observation that we can use the k-th minimum permutation as the canonical labeling. Different from previous algorithms, we take a divide-and-conquer approach to partition a graph G. By partitioning G, an AutoTree is constructed, which preserves symmetric structures as well as the automorphism group of G. The canonical labeling for a tree node can be obtained by composing those of its child nodes, and the canonical labeling for the root is the one for G. Such AutoTree can also be effectively used to answer the automorphism group and symmetric subgraphs. We conducted extensive performance studies using 22 large graphs, and confirmed that DviCL is much more efficient and robust than the state-of-the-art.}
}


@inproceedings{DBLP:conf/sigmod/LuSP0H21,
	author = {Shengliang Lu and
                  Shixuan Sun and
                  Johns Paul and
                  Yuchen Li and
                  Bingsheng He},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Cache-Efficient Fork-Processing Patterns on Large Graphs},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {1208--1221},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457253},
	doi = {10.1145/3448016.3457253},
	timestamp = {Mon, 03 Jan 2022 22:24:52 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/LuSP0H21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As large graph processing emerges, we observe a costly fork-processing pattern (FPP) that is common in many graph algorithms. The unique feature of the FPP is that it launches many independent queries from different source vertices on the same graph. For example, an algorithm in analyzing the network community profile can execute Personalized PageRanks that start from tens of thousands of source vertices at the same time. We study the efficiency of handling FPPs in state-of-the-art graph processing systems on multi-core architectures, including Ligra, Gemini, and GraphIt. We find that those systems suffer from severe cache miss penalty because of the irregular and uncoordinated memory accesses in processing FPPs. In this paper, we propose ForkGraph, a cache-efficient FPP processing system on multi-core architectures. In order to improve the cache reuse, we divide the graph into partitions each sized of LLC (last-level cache) capacity, and the queries in an FPP are buffered and executed on the partition basis. We further develop efficient intra- and inter-partition execution strategies for efficiency. For intra-partition processing, since the graph partition fits into LLC, we propose to execute each graph query with efficient sequential algorithms (in contrast with parallel algorithms in existing parallel graph processing systems) and present an atomic-free query processing method by consolidating contending operations to cache-resident graph partition. For inter-partition processing, we propose two designs, yielding and priority-based scheduling, to reduce redundant work in processing. Besides, we theoretically prove that ForkGraph performs the same amount of work, to within a constant factor, as the fastest known sequential algorithms in FPP queries processing, which is work efficient. Our evaluations on real-world graphs show that ForkGraph significantly outperforms state-of-the-art graph processing systems (including Ligra, Gemini, and GraphIt) with two orders of magnitude speedups.}
}


@inproceedings{DBLP:conf/sigmod/LuoJYJ21,
	author = {Shangyu Luo and
                  Dimitrije Jankov and
                  Binhang Yuan and
                  Chris Jermaine},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Automatic Optimization of Matrix Implementations for Distributed Machine
                  Learning and Linear Algebra},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {1222--1234},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457317},
	doi = {10.1145/3448016.3457317},
	timestamp = {Sun, 19 Jan 2025 13:27:21 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/LuoJYJ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Machine learning (ML) computations are often expressed using vectors, matrices, or higher-dimensional tensors. Such data structures can have many different implementations, especially in a distributed environment: a matrix could be stored as row or column vectors, tiles of different sizes, or relationally, as a set of (rowIndex, colIndex, value) triples. Many other storage formats are possible. The choice of format can have a profound impact on the performance of a ML computation. In this paper, we propose a framework for automatic optimization of the physical implementation of a complex ML or linear algebra (LA) computation in a distributed environment, develop algorithms for solving this problem, and show, through a prototype on top of a distributed relational database system, that our ideas can radically speed up common ML and LA computations.}
}


@inproceedings{DBLP:conf/sigmod/Luo00CLQ21,
	author = {Yuyu Luo and
                  Nan Tang and
                  Guoliang Li and
                  Chengliang Chai and
                  Wenbo Li and
                  Xuedi Qin},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Synthesizing Natural Language to Visualization {(NL2VIS)} Benchmarks
                  from {NL2SQL} Benchmarks},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {1235--1247},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457261},
	doi = {10.1145/3448016.3457261},
	timestamp = {Mon, 04 Dec 2023 21:30:07 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/Luo00CLQ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Natural language (NL) is a promising interaction paradigm for data visualization (VIS). However, there are not any NL to VIS (NL2VIS) benchmarks available. Our goal is to provide the first NL2VIS benchmark to enable and push the field of NL2VIS, especially with deep learning technologies. In this paper, we propose a NL2VIS synthesizer (NL2SQL-to-NL2VIS) that synthesizes NL2VIS benchmarks by piggybacking NL2SQL benchmarks. The intuition is based on the semantic connection between SQL queries and VIS queries: SQL queries specify what data is needed and VIS queries additionally need to specify how to visualize. However, different from SQL that has well-defined syntax, VIS languages (e.g., Vega-Lite, VizQL, ggplot2) are syntactically very different. To provide NL2VIS benchmarks that can support many VIS languages, we use a unified intermediate representation, abstract syntax trees (ASTs), for both SQL and VIS queries. We can synthesize multiple VIS trees through adding/deleting nodes to/from an SQL tree. Each VIS tree can then be converted to (any) VIS language. The NL for VIS will be modified based on the NL for SQL to reflect corresponding tree edits. We produce the first NL2VIS benchmark (nvBench), by applying NL2SQL-to-NL2VIS on a popular NL2SQL benchmark Spider, which covers 105 domains, supports seven common types of visualizations, and contains 25,750 (NL, VIS) pairs. Our method reduces the man-hour to 5.7% of developing a NL2VIS benchmark from scratch (or building a NL2VIS benchmark from scratch takes 17.5× man-hours of our method). Extensive human validation, through 23 experts and 312 crowd workers, demonstrates the high-quality of nvBench. In order to verify that nvBench can enable learning-based approaches, we develop a SEQ2VIS model. Our experimental results show that SEQ2VIS works well and significantly outperforms the state-of-the-art methods of the NL2VIS task.}
}


@inproceedings{DBLP:conf/sigmod/0006ZJWBLMP21,
	author = {Lin Ma and
                  William Zhang and
                  Jie Jiao and
                  Wuwen Wang and
                  Matthew Butrovich and
                  Wan Shen Lim and
                  Prashanth Menon and
                  Andrew Pavlo},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {{MB2:} Decomposed Behavior Modeling for Self-Driving Database Management
                  Systems},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {1248--1261},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457276},
	doi = {10.1145/3448016.3457276},
	timestamp = {Tue, 01 Apr 2025 19:09:24 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/0006ZJWBLMP21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Database management systems (DBMSs) are notoriously difficult to deploy and administer. The goal of a self-driving DBMS is to remove these impediments by managing itself automatically. However, a critical problem in achieving full autonomy is how to predict the DBMS's runtime behavior and resource consumption. These predictions guide a self-driving DBMS's decision-making components to tune and optimize all aspects of the system. We present the ModelBot2 end-to-end framework for constructing and maintaining prediction models using machine learning (ML) in self-driving DBMSs. Our approach decomposes a DBMS's architecture into fine-grained operating units that make it easier to estimate the system's behavior for configurations that it has never seen before. ModelBot2 then provides an offline execution environment to exercise the system to produce the training data used to train its models. We integrated ModelBot2 in an in-memory DBMS and measured its ability to predict its performance for OLTP and OLAP workloads running in dynamic environments. We also compare ModelBot2 against state-of-the-art ML models and show that our models are up to 25x more accurate in multiple scenarios.}
}


@inproceedings{DBLP:conf/sigmod/00040HZ21,
	author = {Pingchuan Ma and
                  Rui Ding and
                  Shi Han and
                  Dongmei Zhang},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {MetaInsight: Automatic Discovery of Structured Knowledge for Exploratory
                  Data Analysis},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {1262--1274},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457267},
	doi = {10.1145/3448016.3457267},
	timestamp = {Wed, 22 Jun 2022 11:12:35 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/00040HZ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Automatic Exploratory Data Analysis (EDA) focuses on automatically discovering pieces of knowledge in the form of interesting data patterns. However, the conveyed knowledge by these suggested data patterns are disjointed or lack organization. Therefore, it is difficult for users to gain structured knowledge, and as the number of suggested patterns grows, these stand-alone patterns are less likely to motive users to conduct follow-up analysis, which hinders it from being effectively utilized to facilitate EDA. In this paper, we propose MetaInsight, a structured representation of knowledge extracted from multi-dimensional data aiming to facilitate EDA automatically and effectively. Specifically, we propose a novel formulation of basic data pattern to capture essential characteristics of raw data distribution to achieve knowledge extraction. Then based on the mined Homogeneous Data Patterns (HDP) and inter-pattern similarity, MetaInsight is identified by categorizing basic data patterns (within an HDP) into commonness(es) and exceptions thus achieving structured knowledge representation. The commonness(es) and exceptions concretize the knowledge obtained by induction and validation processes which are two typical analysis mechanisms conducted in EDA. We propose a novel scoring function to quantify the usefulness of MetaInsight, an effective and efficient mining procedure and a ranking algorithm to automatically discover high-quality MetaInsights from multi-dimensional data. We demonstrate the effectiveness and efficiency of MetaInsights (w.r.t. facilitating EDA) through evaluation on real-world datasets and user studies on both expert users and non-expert users.}
}


@inproceedings{DBLP:conf/sigmod/MarcusNMTAK21,
	author = {Ryan Marcus and
                  Parimarjan Negi and
                  Hongzi Mao and
                  Nesime Tatbul and
                  Mohammad Alizadeh and
                  Tim Kraska},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Bao: Making Learned Query Optimization Practical},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {1275--1288},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452838},
	doi = {10.1145/3448016.3452838},
	timestamp = {Mon, 26 Jun 2023 20:43:17 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/MarcusNMTAK21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recent efforts applying machine learning techniques to query optimization have shown few practical gains due to substantive training overhead, inability to adapt to changes, and poor tail performance. Motivated by these difficulties, we introduce Bao (the \\underlineBa ndit \\underlineo ptimizer). Bao takes advantage of the wisdom built into existing query optimizers by providing per-query optimization hints. Bao combines modern tree convolutional neural networks with Thompson sampling, a well-studied reinforcement learning algorithm. As a result, Bao automatically learns from its mistakes and adapts to changes in query workloads, data, and schema. Experimentally, we demonstrate that Bao can quickly learn strategies that improve end-to-end query execution performance, including tail latency, for several workloads containing long-running queries. In cloud environments, we show that Bao can offer both reduced costs and better performance compared with a commercial system.}
}


@inproceedings{DBLP:conf/sigmod/MayerJ21,
	author = {Ruben Mayer and
                  Hans{-}Arno Jacobsen},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Hybrid Edge Partitioner: Partitioning Large Power-Law Graphs under
                  Memory Constraints},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {1289--1302},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457300},
	doi = {10.1145/3448016.3457300},
	timestamp = {Sun, 19 Jan 2025 13:27:21 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/MayerJ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Distributed systems that manage and process graph-structured data internally solve a graph partitioning problem to minimize their communication overhead and query run-time. Besides computational complexity---optimal graph partitioning is NP-hard---another important consideration is the memory overhead. Real-world graphs often have an immense size, such that loading the complete graph into memory for partitioning is not economical or feasible. Currently, the common approach to reduce memory overhead is to rely on streaming partitioning algorithms. While the latest streaming algorithms lead to reasonable partitioning quality on some graphs, they are still not completely competitive to in-memory partitioners. In this paper, we propose a new system, Hybrid Edge Partitioner (HEP), that can partition graphs that fit partly into memory while yielding a high partitioning quality. HEP can flexibly adapt its memory overhead by separating the edge set of the graph into two sub-sets. One sub-set is partitioned by NE++, a novel, efficient in-memory algorithm, while the other sub-set is partitioned by a streaming approach. Our evaluations on large real-world graphs show that in many cases, HEP outperforms both in-memory partitioning and streaming partitioning at the same time. Hence, HEP is an attractive alternative to existing solutions that cannot fine-tune their memory overheads. Finally, we show that using HEP, we achieve a significant speedup of distributed graph processing jobs on Spark/GraphX compared to state-of-the-art partitioning algorithms.}
}


@inproceedings{DBLP:conf/sigmod/Miao0021,
	author = {Zhengjie Miao and
                  Yuliang Li and
                  Xiaolan Wang},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Rotom: {A} Meta-Learned Data Augmentation Framework for Entity Matching,
                  Data Cleaning, Text Classification, and Beyond},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {1303--1316},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457258},
	doi = {10.1145/3448016.3457258},
	timestamp = {Mon, 21 Jun 2021 11:48:44 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/Miao0021.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Deep Learning revolutionizes almost all fields of computer science including data management. However, the demand for high-quality training data is slowing down deep neural nets' wider adoption. To this end, data augmentation (DA), which generates more labeled examples from existing ones, becomes a common technique. Meanwhile, the risk of creating noisy examples and the large space of hyper-parameters make DA less attractive in practice. We introduce Rotom, a multi-purpose data augmentation framework for a range of data management and mining tasks including entity matching, data cleaning, and text classification. Rotom features InvDA, a new DA operator that generates natural yet diverse augmented examples by formulating DA as a seq2seq task. The key technical novelty of Rotom is a meta-learning framework that automatically learns a policy for combining examples from different DA operators, whereby combinatorially reduces the hyper-parameters space. Our experimental results show that Rotom effectively improves a model's performance by combining multiple DA operators, even when applying them individually does not yield performance improvement. With this strength, Rotom outperforms the state-of-the-art entity matching and data cleaning systems in the low-resource settings as well as two recently proposed DA techniques for text classification.}
}


@inproceedings{DBLP:conf/sigmod/MouratidisL021,
	author = {Kyriakos Mouratidis and
                  Keming Li and
                  Bo Tang},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Marrying Top-k with Skyline Queries: Relaxing the Preference Input
                  while Producing Output of Controllable Size},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {1317--1330},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457299},
	doi = {10.1145/3448016.3457299},
	timestamp = {Mon, 03 Jan 2022 22:24:52 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/MouratidisL021.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The two most common paradigms to identify records of preference in a multi-objective setting rely either on dominance (e.g., the skyline operator) or on a utility function defined over the records' attributes (typically, using a top-k query). Despite their proliferation, each of them has its own palpable drawbacks. Motivated by these drawbacks, we identify three hard requirements for practical decision support, namely, personalization, controllable output size, and flexibility in preference specification. With these requirements as a guide, we combine elements from both paradigms and propose two new operators, ORD and ORU. We perform a qualitative study to demonstrate how they work, and evaluate their performance against adaptations of previous work that mimic their output.}
}


@inproceedings{DBLP:conf/sigmod/MuhligT21,
	author = {Jan M{\"{u}}hlig and
                  Jens Teubner},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {MxTasks: How to Make Efficient Synchronization and Prefetching Easy},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {1331--1344},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457268},
	doi = {10.1145/3448016.3457268},
	timestamp = {Sun, 04 Aug 2024 19:37:27 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/MuhligT21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The hardware environment has changed rapidly in recent years: Many cores, multiple sockets, and large amounts of main memory have become a commodity. To benefit from these highly parallel systems, the software has to be adapted. Sophisticated latch-free data structures and algorithms are often meant to address the situation. But they are cumbersome to develop and may still not provide the desired scalability. As a remedy, we present MxTasking, a task-based framework that assists the design of latch-free and parallel data structures. MxTasking eases the information exchange between applications and the operating system, resulting in novel opportunities to manage resources in a truly hardware- and application-conscious way.}
}


@inproceedings{DBLP:conf/sigmod/NeutatzBA21,
	author = {Felix Neutatz and
                  Felix Biessmann and
                  Ziawasch Abedjan},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Enforcing Constraints for Machine Learning Systems via Declarative
                  Feature Selection: An Experimental Study},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {1345--1358},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457295},
	doi = {10.1145/3448016.3457295},
	timestamp = {Mon, 21 Jun 2021 11:48:44 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/NeutatzBA21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Responsible usage of Machine Learning (ML) systems in practice does not only require enforcing high prediction quality, but also accounting for other constraints, such as fairness, privacy, or execution time. One way to address multiple user-specified constraints on ML systems is feature selection. Yet, optimizing feature selection strategies for multiple metrics is difficult to implement and has been underrepresented in previous experimental studies. Here, we propose Declarative Feature Selection (DFS) to simplify the design and validation of ML systems satisfying diverse user-specified constraints. We benchmark and evaluate a representative series of feature selection algorithms. From our extensive experimental results, we derive concrete suggestions on when to use which strategy and show that a meta-learning-driven optimizer can accurately predict the right strategy for an ML task at hand. These results demonstrate that feature selection can help to build ML systems that meet combinations of user-specified constraints, independent of the ML methods used.}
}


@inproceedings{DBLP:conf/sigmod/Ni00021,
	author = {Wangze Ni and
                  Peng Cheng and
                  Lei Chen and
                  Xuemin Lin},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {When the Recursive Diversity Anonymity Meets the Ring Signature},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {1359--1371},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452825},
	doi = {10.1145/3448016.3452825},
	timestamp = {Mon, 26 Jun 2023 20:43:17 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/Ni00021.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In privacy-preserving blockchain systems, to protect a sender\'s identity of a transaction in privacy-preserving blockchain systems, ring signature (RS) schemes have been widely implemented, which allow users to obscure consumed tokens via including "mixin\'\' (i.e., chaff tokens). However, recent works point out that existing RS schemes are vulnerable to the "chain-reaction\'\' analysis, where adversaries eliminate mixins of RSs by utilizing the fact that each token can only be consumed in a RS. By "chain-reaction\'\' analysis, adversaries can find some definite token-RS pair sets (DTRSs) to confirm the sender\'s identity of a RS. Besides, the existing RS schemes do not consider the diversity of mixins when generating a RS. Moreover, since the transaction fee is proportional to the number of mixins, a use is motivated to use a RS with the minimum number of mixins. In this paper, we formally define the diversity-aware mixins selection (DA-MS) problem, which aims to generate a RS with the minimum number of mixins satisfying the constraints of its diversity and the anonymity of other RSs. We prove the DA-MS problem is $\\#P$ and propose a breadth-first search algorithm to get the optimal solution. Furthermore, to efficiently solve the DA-MS problem, we propose two practical configurations and two approximation algorithms with theoretic guarantees. Through comprehensive experiments on real data sets as well as synthetic data sets, we illustrate the effectiveness and the efficiency of our solutions.}
}


@inproceedings{DBLP:conf/sigmod/PandeyWXB21,
	author = {Prashant Pandey and
                  Brian Wheatman and
                  Helen Xu and
                  Aydin Bulu{\c{c}}},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Terrace: {A} Hierarchical Graph Container for Skewed Dynamic Graphs},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {1372--1385},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457313},
	doi = {10.1145/3448016.3457313},
	timestamp = {Mon, 03 Mar 2025 21:21:50 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/PandeyWXB21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Various applications model problems as streaming graphs, which need to quickly apply a stream of updates and run algorithms on the updated graph. Furthermore, many dynamic real-world graphs, such as social networks, follow a skewed distribution of vertex degrees, where there are a few high-degree vertices and many low-degree vertices. Existing static graph-processing systems optimized for graph skewness achieve high performance and low space usage by preprocessing a cache-efficient graph partitioning based on vertex degree. In the streaming setting, the whole graph is not available upfront, however, so finding an optimal partitioning is not feasible in the presence of updates. As a result, existing streaming graph-processing systems take a "one-size-fits-all" approach, leaving performance on the table. We present Terrace, a system for streaming graphs that uses a hierarchical data structure design to store a vertex\'s neighbors in different data structures depending on the degree of the vertex. This multi-level structure enables Terrace to dynamically partition vertices based on their degrees and adapt to skewness in the underlying graph. Our experiments show that Terrace supports faster batch insertions for batch sizes up to 1M when compared to Aspen, a state-of-the-art graph streaming system. On graph query algorithms, Terrace is between 1.7X--2.6X faster than Aspen and between 0.5X--1.3X as fast as Ligra, a state-of-the-art static graph-processing system.}
}


@inproceedings{DBLP:conf/sigmod/PandeyCDBFJ21,
	author = {Prashant Pandey and
                  Alex Conway and
                  Joe Durie and
                  Michael A. Bender and
                  Martin Farach{-}Colton and
                  Rob Johnson},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Vector Quotient Filters: Overcoming the Time/Space Trade-Off in Filter
                  Design},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {1386--1399},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452841},
	doi = {10.1145/3448016.3452841},
	timestamp = {Wed, 23 Oct 2024 08:55:28 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/PandeyCDBFJ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Today's filters, such as quotient, cuckoo, and Morton, have a trade-off between space and speed; even when moderately full (e.g., 50%-75% full), their performance degrades nontrivially. The result is that today's systems designers are forced to choose between speed and space usage. In this paper, we present the vector quotient filter (VQF). Locally, the VQF is based on Robin Hood hashing, like the quotient filter, but uses power-of-two-choices hashing to reduce the variance of runs, and thus offers consistent, high throughput across load factors. Power-of-two-choices hashing also makes it more amenable to concurrent updates, compared to the cuckoo filter and variants. Finally, the vector quotient filter is designed to exploit SIMD instructions so that all operations have O (1) cost, independent of the size of the filter or its load factor. We show that the vector quotient filter is 2× faster for inserts compared to the Morton filter (a cuckoo filter variant and state-of-the-art for inserts) and has similar lookup and deletion performance as the cuckoo filter (which is fastest for queries and deletes), despite having a simpler design and implementation. The vector quotient filter has minimal performance decline at high load factors, a problem that has plagued modern filters, including quotient, cuckoo, and Morton. Furthermore, we give a thread-safe version of the vector quotient filter and show that insertion throughput scales 3× with four threads compared to a single thread.}
}


@inproceedings{DBLP:conf/sigmod/PastorAB21,
	author = {Eliana Pastor and
                  Luca de Alfaro and
                  Elena Baralis},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Looking for Trouble: Analyzing Classifier Behavior via Pattern Divergence},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {1400--1412},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457284},
	doi = {10.1145/3448016.3457284},
	timestamp = {Mon, 05 Feb 2024 20:26:56 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/PastorAB21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Machine learning models may perform differently on different data subgroups, which we represent as itemsets (i.e., conjunctions of simple predicates). The identification of these critical data subgroups plays an important role in many applications, for example model validation and testing, or evaluation of model fairness. Typically, domain expert help is required to identify relevant (or sensitive) subgroups. We propose the notion of divergence over itemsets as a measure of different classification behavior on data subgroups, and the use of frequent pattern mining techniques for their identification. A quantification of the contribution of different attribute values to divergence, based on the mathematical foundations provided by Shapley values, allows us to identify both critical and peculiar behaviors of attributes. Extended experiments show the effectiveness of the approach in identifying critical subgroup behaviors.}
}


@inproceedings{DBLP:conf/sigmod/PaulLHL21,
	author = {Johns Paul and
                  Shengliang Lu and
                  Bingsheng He and
                  Chiew Tong Lau},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {MG-Join: {A} Scalable Join for Massively Parallel Multi-GPU Architectures},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {1413--1425},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457254},
	doi = {10.1145/3448016.3457254},
	timestamp = {Mon, 21 Jun 2021 11:48:44 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/PaulLHL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The recent scale-up of GPU hardware through the integration of multiple GPUs into a single machine and the introduction of higher bandwidth interconnects like NVLink 2.0 has enabled new opportunities of relational query processing on multiple GPUs. However, due to the unique characteristics of GPUs and the interconnects, existing hash join implementations spend up to 66% of their execution time moving the data between the GPUs and achieve lower than 50% utilization of the newer high bandwidth interconnects. This leads to extremely poor scalablity of hash join performance on multiple GPUs, which can be slower than the performance on a single GPU. In this paper, we propose MG-Join, a scalable partitioned hash join implementation on multiple GPUs of a single machine. In order to effectively improve the bandwidth utilization, we develop a novel multi-hop routing for cross-GPU communication that adaptively chooses the efficient route for each data flow to minimize congestion. Our experiments on the DGX-1 machine show that MG-Join helps significantly reduce the communication overhead and achieves up to 97% utilization of the bisection bandwidth of the interconnects, resulting in significantly better scalability. Overall, MG-Join outperforms the state-of-the-art hash join implementations by up to 2.5x. MG-Join further helps improve the overall performance of TPC-H queries by up to 4.5x over multi-GPU version of an open-source commercial GPU database Omnisci.}
}


@inproceedings{DBLP:conf/sigmod/PhaniR021,
	author = {Arnab Phani and
                  Benjamin Rath and
                  Matthias Boehm},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {{LIMA:} Fine-grained Lineage Tracing and Reuse in Machine Learning
                  Systems},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {1426--1439},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452788},
	doi = {10.1145/3448016.3452788},
	timestamp = {Mon, 21 Jun 2021 11:48:44 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/PhaniR021.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Machine learning (ML) and data science workflows are inherently exploratory. Data scientists pose hypotheses, integrate the necessary data, and run ML pipelines of data cleaning, feature engineering, model selection and hyper-parameter tuning. The repetitive nature of these workflows, and their hierarchical composition from building blocks exhibits high computational redundancy. Existing work addresses this redundancy with coarse-grained lineage tracing and reuse for ML pipelines. This approach allows using existing ML systems, but views entire algorithms as black boxes, and thus, fails to eliminate fine-grained redundancy and to handle internal non-determinism. In this paper, we introduce LIMA, a practical framework for efficient, fine-grained lineage tracing and reuse inside ML systems. Lineage tracing of individual operations creates new challenges and opportunities. We address the large size of lineage traces with multi-level lineage tracing and reuse, as well as lineage deduplication for loops and functions; exploit full and partial reuse opportunities across the program hierarchy; and integrate this framework with task parallelism and operator fusion. The resulting framework performs fine-grained lineage tracing with low overhead, provides versioning and reproducibility, and is able to eliminate fine-grained redundancy. Our experiments on a variety of ML pipelines show performance improvements up to 12.4x.}
}


@inproceedings{DBLP:conf/sigmod/PicadoTFPID21,
	author = {Jose Picado and
                  Arash Termehchy and
                  Alan Fern and
                  Sudhanshu Pathak and
                  Praveen Ilango and
                  John Davis},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Scalable and Usable Relational Learning With Automatic Language Bias},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {1440--1451},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457275},
	doi = {10.1145/3448016.3457275},
	timestamp = {Mon, 21 Jun 2021 11:48:44 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/PicadoTFPID21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A large body of machine learning and AI is focused on learning models composed of (probabilistic) logical rules, i.e., relational models, over relational databases and knowledge bases. To learn effective relational models over the huge space of possible ones efficiently, users of the current learning systems must restrict the structure of the candidate models using language bias. ML experts have to spend a long time inspecting the data and performing many rounds of trial and error to develop an effective language bias. We propose AutoBias, a system that leverages information in the underlying data to generate the language bias. As its induced language bias may not restrict the set of candidate models as tightly as the manually-written ones, learning may not scale to large datasets. Thus, we design novel and efficient methods to sample and learn effective relational models over large data. Our extensive empirical study shows that AutoBias delivers the same accuracy as using manually-written language bias by imposing only a slight overhead on the learning time.}
}


@inproceedings{DBLP:conf/sigmod/PoppeLMRR21,
	author = {Olga Poppe and
                  Chuan Lei and
                  Lei Ma and
                  Allison Rozet and
                  Elke A. Rundensteiner},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {To Share, or not to Share Online Event Trend Aggregation Over Bursty
                  Event Streams},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {1452--1464},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452785},
	doi = {10.1145/3448016.3452785},
	timestamp = {Mon, 05 Feb 2024 20:26:57 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/PoppeLMRR21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Complex event processing (CEP) systems continuously evaluate large workloads of pattern queries under tight time constraints. Event trend aggregation queries with Kleene patterns are commonly used to retrieve summarized insights about the recent trends in event streams. State-of-art methods are limited either due to repetitive computations or unnecessary trend construction. Existing shared approaches are guided by statically selected and hence rigid sharing plans that are often sub-optimal under stream fluctuations. In this work, we propose a novel framework Hamlet that is the first to overcome these limitations. Hamlet introduces two key innovations. First, Hamlet adaptively decides at run time whether to share or not to share computations depending on the current stream properties to harvest the maximum sharing benefit. Second, Hamlet is equipped with a highly efficient shared trend aggregation strategy that avoids trend construction. Our experimental study on both real and synthetic data sets demonstrates that Hamlet consistently reduces query latency by up to five orders of magnitude compared to state-of-the-art approaches.}
}


@inproceedings{DBLP:conf/sigmod/QiuWYLWZ21,
	author = {Yuan Qiu and
                  Yilei Wang and
                  Ke Yi and
                  Feifei Li and
                  Bin Wu and
                  Chaoqun Zhan},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Weighted Distinct Sampling: Cardinality Estimation for {SPJ} Queries},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {1465--1477},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452821},
	doi = {10.1145/3448016.3452821},
	timestamp = {Sat, 30 Sep 2023 09:56:34 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/QiuWYLWZ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {SPJ (select-project-join) queries form the backbone of many SQL queries used in practice. Accurate cardinality estimation of these queries is thus an important problem, with applications in query optimization, approximate query processing, and data analytics. However, this problem has not been rigorously addressed in the literature, despite the fact that cardinality estimation techniques of the three relational operators, selection, projection, and join, have each been extensively studied (but not when used in combination) in the past 30+ years. The major technical difficulty is that (distinct) projection seems to be difficult to combine with the other two operators when it comes to cardinality estimation. In this paper, we give the first formal study of cardinality estimation for SP queries. While it was studied in a prior work in 2001, there is no guarantee on its optimality. We define a class of algorithms, which we call weighted distinct sampling, for estimating SP query sizes, and show how to find a near-optimal sampling strategy that is away from the optimum only by a lower order term. We then extend it to handling SPJ queries, giving the first non-trivial solution for SPJ cardinality estimation. We have also performed an extensive experimental evaluation to complement our theoretical findings.}
}


@inproceedings{DBLP:conf/sigmod/0002LG21,
	author = {Weilong Ren and
                  Xiang Lian and
                  Kambiz Ghazinour},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Online Topic-Aware Entity Resolution Over Incomplete Data Streams},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {1478--1490},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457238},
	doi = {10.1145/3448016.3457238},
	timestamp = {Tue, 06 May 2025 16:06:34 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/0002LG21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In many real applications such as the data integration, social network analysis, and the Semantic Web, the entity resolution (ER) is an important and fundamental problem, which identifies and links the same real-world entities from various data sources. While prior works usually consider ER over static and complete data, in practice, application data are usually collected in a streaming fashion, and often incur missing attributes (due to the inaccuracy of data extraction techniques). Therefore, in this paper, we will formulate and tackle a novel problem, topic-aware entity resolution over incomplete data streams (TER-iDS), which online imputes incomplete tuples and detects pairs of topic-related matching entities from incomplete data streams. In order to effectively and efficiently tackle the TER-iDS problem, we propose an effective imputation strategy, carefully design effective pruning strategies, as well as indexes/synopsis, and develop an efficient TER-iDS algorithm via index joins. Extensive experiments have been conducted to evaluate the effectiveness and efficiency of our proposed TER-iDS approach over real data sets.}
}


@inproceedings{DBLP:conf/sigmod/RuanGWW21,
	author = {Boyu Ruan and
                  Junhao Gan and
                  Hao Wu and
                  Anthony Wirth},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Dynamic Structural Clustering on Graphs},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {1491--1503},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452828},
	doi = {10.1145/3448016.3452828},
	timestamp = {Sat, 30 Sep 2023 09:56:35 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/RuanGWW21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {\\em Structural Clustering ($\\strclu$) is one of the most popular graph clustering paradigms. In this paper, we consider $\\strclu$ under Jaccard similarity on a dynamic graph, G = (V, E), subject to edge insertions and deletions (updates). The goal is to maintain certain information under updates, so that the strclu clustering result on~G can be retrieved in O(|V| + |E|)$ time, upon request. The state-of-the-art worst-case cost is~O(|V|) per update; we improve this update-time bound \\em significantly with the ρ-approximate notion. Specifically, for a specified failure probability, δ^*, and \\em every sequence of~M updates (no need to know M\'s value in advance), our algorithm, $\\dynelm$, achieves~O(?og^2 |V| + og |V| \\cdot ?og \\fracM ?^* )$ amortized cost for each update, \\em at all times in linear space. Moreover, $\\dynelm$ provides a provable "sandwich\'\' guarantee on the clustering quality at all times after each update with probability at least 1 - ^*. We further develop dynelm into our ultimate algorithm, dynstr, which also supports \\em cluster-group-by queries. Given Q \\subseteq V, this puts the non-empty intersection of Q and each strclu cluster into a distinct group. dynstr not only achieves all the guarantees of dynelm, but also runs \\em cluster-group-by queries in~O(|Q|\\cdot og |V|) time. We demonstrate the performance of our algorithms via extensive experiments, on 15 real datasets. Experimental results confirm that our algorithms are up to three orders of magnitude more efficient than state-of-the-art competitors, and still provide quality structural clustering results.}
}


@inproceedings{DBLP:conf/sigmod/RuanDLZCLO21,
	author = {Pingcheng Ruan and
                  Tien Tuan Anh Dinh and
                  Dumitrel Loghin and
                  Meihui Zhang and
                  Gang Chen and
                  Qian Lin and
                  Beng Chin Ooi},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Blockchains vs. Distributed Databases: Dichotomy and Fusion},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {1504--1517},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452789},
	doi = {10.1145/3448016.3452789},
	timestamp = {Mon, 03 Mar 2025 21:21:50 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/RuanDLZCLO21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Blockchain has come a long way - a system that was initially proposed specifically for cryptocurrencies is now being adapted and adopted as a general-purpose transactional system. As blockchain evolves into another data management system, the natural question is how it compares against distributed database systems. Existing works on this comparison focus on high-level properties, such as security and throughput. They stop short of showing how the underlying design choices contribute to the overall differences. Our work fills this important gap. We perform a twin study of blockchains and distributed database systems as two types of transactional systems. We propose a taxonomy that illustrates the dichotomy across four dimensions, namely replication, concurrency, storage, and sharding. Within each dimension, we discuss how the design choices are driven by two goals: security for blockchains, and performance for distributed databases. We conduct an extensive and in-depth performance analysis of two blockchains, namely Quorum and Hyperledger Fabric, and three distributed databases, namely CockroachDB, TiDB, and etcd. Our analysis exposes the impact of different design choices on the overall performance. Concisely, our work provides a principled framework for analyzing the emerging trend of blockchain-database fusion.}
}


@inproceedings{DBLP:conf/sigmod/SahuS21,
	author = {Siddhartha Sahu and
                  Semih Salihoglu},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Graphsurge: Graph Analytics on View Collections Using Differential
                  Computation},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {1518--1530},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452837},
	doi = {10.1145/3448016.3452837},
	timestamp = {Mon, 21 Jun 2021 11:48:44 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/SahuS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper presents the design and implementation of a new open-source view-based graph analytics system called Graphsurge. Graphsurge is designed to support applications that analyze multiple snapshots or views of a large-scale graph. Users program Graphsurge through a declarative graph view definition language (GVDL) to create views over input graphs and a Differential Dataflow-based programming API to write analytics computations. A key feature of GVDL is the ability to organize views into view collections, which allows Graphsurge to automatically share computation across views, without users writing any incrementalization code, by performing computations differentially. We then introduce two optimization problems that naturally arise in our setting. First is the collection ordering problem to determine the order of views that leads to minimum differences across consecutive views. We prove this problem is NP-hard and show a constant-factor approximation algorithm drawn from literature. Second is the collection splitting problem to decide on which views to run computations differentially vs from scratch, for which we present an adaptive solution that makes decisions at runtime. We present extensive experiments to demonstrate the benefits of running computations differentially for view collections and our collection ordering and splitting optimizations.}
}


@inproceedings{DBLP:conf/sigmod/SantosBCMF21,
	author = {A{\'{e}}cio S. R. Santos and
                  Aline Bessa and
                  Fernando Chirigati and
                  Christopher Musco and
                  Juliana Freire},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Correlation Sketches for Approximate Join-Correlation Queries},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {1531--1544},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3458456},
	doi = {10.1145/3448016.3458456},
	timestamp = {Sun, 02 Oct 2022 16:15:22 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/SantosBCMF21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The increasing availability of structured datasets, from Web tables and open-data portals to enterprise data, opens up opportunities to enrich analytics and improve machine learning models through relational data augmentation. In this paper, we introduce a new class of data augmentation queries: join-correlation queries. Given a column Q and a join column KQ from a query table TQ, retrieve tables TX in a dataset collection such that TX is joinable with TQ on KQ and there is a column C ∈ TX such that Q is correlated with C. A naïve approach to evaluate these queries, which first finds joinable tables and then explicitly joins and computes correlations between Q and all columns of the discovered tables, is prohibitively expensive. To efficiently support correlated column discovery, we 1) propose a sketching method that enables the construction of an index for a large number of tables and that provides accurate estimates for join-correlation queries, and 2) explore different scoring strategies that effectively rank the query results based on how well the columns are correlated with the query. We carry out a detailed experimental evaluation, using both synthetic and real data, which shows that our sketches attain high accuracy and the scoring strategies lead to high-quality rankings.}
}


@inproceedings{DBLP:conf/sigmod/SchelterGD21,
	author = {Sebastian Schelter and
                  Stefan Grafberger and
                  Ted Dunning},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {HedgeCut: Maintaining Randomised Trees for Low-Latency Machine Unlearning},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {1545--1557},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457239},
	doi = {10.1145/3448016.3457239},
	timestamp = {Tue, 21 Mar 2023 20:57:31 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/SchelterGD21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Software systems that learn from user data with machine learning (ML) have become ubiquitous over the last years. Recent law such as the "General Data Protection Regulation" (GDPR) requires organisations that process personal data to delete user data upon request (enacting the "right to be forgotten"). However, this regulation does not only require the deletion of user data from databases, but also applies to ML models that have been learned from the stored data. We therefore argue that ML applications should offer users to unlearn their data from trained models in a timely manner. We explore how fast this unlearning can be done under the constraints imposed by real world deployments, and introduce the problem of low-latency machine unlearning: maintaining a deployed ML model in-place under the removal of a small fraction of training samples without retraining. We propose HedgeCut, a classification model based on an ensemble of randomised decision trees, which is designed to answer unlearning requests with low latency. We detail how to efficiently implement HedgeCut with vectorised operators for decision tree learning. We conduct an experimental evaluation on five privacy-sensitive datasets, where we find that HedgeCut can unlearn training samples with a latency of around 100 microseconds and answers up to 36,000 prediction requests per second, while providing a training time and predictive accuracy similar to widely used implementations of tree-based ML models such as Random Forests.}
}


@inproceedings{DBLP:conf/sigmod/00020T21,
	author = {Mo Sha and
                  Yuchen Li and
                  Kian{-}Lee Tan},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Self-adaptive Graph Traversal on GPUs},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {1558--1570},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457279},
	doi = {10.1145/3448016.3457279},
	timestamp = {Mon, 03 Jan 2022 22:24:52 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/00020T21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {GPU's massive computing power offers unprecedented opportunities to enable large graph analysis. Existing studies proposed various preprocessing approaches that convert the input graphs into dedicated structures for GPU-based optimizations. However, these dedicated approaches incur significant preprocessing costs as well as weak programmability to build general graph applications. In this paper, we introduce SAGE, a self-adaptive graph traversal on GPUs, which is free from preprocessing and operates on ubiquitous graph representations directly. We propose Tiled Partitioning and Resident Tile Stealing to fully exploit the computing power of GPUs in a runtime and self-adaptive manner. We also propose Sampling-based Reordering to further optimize the memory efficiency of SAGE through a lightweight and effective node reordering technique on the fly. Extensive experiments demonstrate that SAGE can achieve superior graph traversal performance over existing approaches under different architectural scenarios, i.e., single-GPU, out-of-core, and multi-GPU.}
}


@inproceedings{DBLP:conf/sigmod/ShafieinejadKI21,
	author = {Masoumeh Shafieinejad and
                  Florian Kerschbaum and
                  Ihab F. Ilyas},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {{PCOR:} Private Contextual Outlier Release via Differentially Private
                  Search},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {1571--1583},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452812},
	doi = {10.1145/3448016.3452812},
	timestamp = {Mon, 21 Jun 2021 11:48:44 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/ShafieinejadKI21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Outlier detection plays a significant role in various real world applications such as intrusion, malfunction, and fraud detection. Traditionally, outlier detection techniques are applied to find outliers in the context of the whole dataset. However, this practice neglects the data points, namely contextual outliers, that are not outliers in the whole dataset but in some specific neighborhoods. Contextual outliers are particularly important in data exploration and targeted anomaly explanation and diagnosis. In these scenarios, the data owner computes the following information: i) The attributes that contribute to the abnormality of an outlier (metric), ii) Contextual description of the outlier's neighborhoods (context), and iii) The utility score of the context, e.g. its strength in showing the outlier's significance, or in relation to a particular explanation for the outlier. However, revealing the outlier's context leaks information about the other individuals in the population as well, violating their privacy. We address the issue of population privacy violations in this paper. There are two main challenges in defining and applying privacy in contextual outlier release. In this setting, the data owner is required to release a valid context for the queried record, i.e. a context in which the record is an outlier. Hence, the first major challenge is that the privacy technique must preserve the validity of the context for each record. We propose techniques to protect the privacy of individuals through a relaxed notion of differential privacy to satisfy this requirement. The second major challenge is applying the proposed techniques efficiently, as they impose intensive computation to the base algorithm. To overcome this challenge, we propose a graph structure to map the contexts to, and introduce differentially private graph search algorithms as efficient solutions for the computation problem caused by differential privacy techniques.}
}


@inproceedings{DBLP:conf/sigmod/ShahLKY021,
	author = {Vraj Shah and
                  Jonathan Lacanlale and
                  Premanand Kumar and
                  Kevin Yang and
                  Arun Kumar},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Towards Benchmarking Feature Type Inference for AutoML Platforms},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {1584--1596},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457274},
	doi = {10.1145/3448016.3457274},
	timestamp = {Mon, 21 Jun 2021 11:48:44 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/ShahLKY021.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The paradigm of AutoML has created an opportunity to enable ML for the masses. Emerging industrial-scale cloud AutoML platforms aim to automate the end-to-end ML workflow. While many works have looked into automated feature engineering, model selection, or hyper-parameter search in AutoML, little work has studied a crucial step that serves as an entry point to this workflow: ML feature type inference. The semantic gap between attribute types (e.g., strings, numbers) in databases/files and ML feature types (e.g., Numeric, Categorical) necessitates type inference. In this work, we formalize and standardize this task by creating the first ever benchmark labeled dataset, which we use to objectively evaluate existing AutoML tools. Our dataset has 9921 examples and a 9-class label vocabulary. Our labeled data also offers an alternative approach to automate this task than existing rule-based or syntax-based approaches: use ML itself to predict feature types. We collate a benchmark suite of 30 classification and regression tasks to assess the importance of type inference for downstream models. Empirical comparison on our labeled data shows that an ML-based approach delivers a lift of an average 14% and up to 38% in accuracy for identifying feature types compared to prominent industrial tools. Our downstream benchmark suite reveals that the ML-based approach outperforms existing industrial-strength tools for 47 out of 60 downstream models. We release our labeled dataset, models, and downstream benchmarks in a public repository with a leaderboard.}
}


@inproceedings{DBLP:conf/sigmod/ShahvaraniJ21,
	author = {Amirhesam Shahvarani and
                  Hans{-}Arno Jacobsen},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Distributed Stream {KNN} Join},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {1597--1609},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457269},
	doi = {10.1145/3448016.3457269},
	timestamp = {Sun, 19 Jan 2025 13:27:22 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/ShahvaraniJ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {kNN join over data streams is an important operation for location-aware systems, which correlates events from different sources based on their occurrence locations. Combining the complexity of kNN join and the dynamicity of data streams, kNN join in streaming environments is a computationally intensive operator, and its performance can be greatly improved by utilizing the computational capabilities of modern non-uniform memory access (NUMA) computing platforms. However, the conventional approaches to kNN join for prestored datasets do not work efficiently with the kind of highly dynamic data found in streaming environments. Therefore, in this paper, we introduce an adaptive scalable stream kNN join, named ADS-kNN, to address the challenges of performing the kNN join operation on highly dynamic data. We propose a multistage kNN execution plan that enables high-performance kNN queries in distributed settings by overlapping the computation and communication stages. Moreover, we propose an adaptive data partitioning scheme that dynamically adjusts the load among the operators according to the changes in the input values. Combining these two techniques, ADS-kNN provides a scalable and adaptive kNN join operator for data streams. Our experiments using a 56-core system show that ADS-kNN achieves a maximum throughput that is 21 times higher than that of a single-threaded approach.}
}


@inproceedings{DBLP:conf/sigmod/ShanghooshabadK21,
	author = {Ali Mohammadi Shanghooshabad and
                  Meghdad Kurmanji and
                  Qingzhi Ma and
                  Michael Shekelyan and
                  Mehrdad Almasi and
                  Peter Triantafillou},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {PGMJoins: Random Join Sampling with Graphical Models},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {1610--1622},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457302},
	doi = {10.1145/3448016.3457302},
	timestamp = {Sun, 19 Jan 2025 13:27:32 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/ShanghooshabadK21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Modern databases face formidable challenges when called to join (several) massive tables. Joins (especially when entailing many-to-many joins) are very time- and resource-consuming, join results can be too big to keep in memory, and performing analytics/learning tasks over them costs dearly in terms of time, resources, and money (in the cloud). Moreover, although random sampling is a promising idea to mitigate the above problems, the current state of the art leaves lots of room for improvements. With this paper we contribute a principled solution, coined PGMJoins. PGMJoins adapts Probabilistic Graphical Models to deriving provably random samples of the join result for (n-way) key joins, many-to-many joins, and cyclic and acyclic joins. PGMJoins contributes optimizations both for deriving the structure of the graph and for PGM inference. It also contributes a novel Sum-Product Message Passing Algorithm (SP-MPA) to make a uniform sample of the joint distribution (join result) efficiently and a novel way to deal with cyclic joins. Despite the use of PGMs, the learned joint distribution is not approximated, and the uniform samples are drawn from the true distribution. Our experimentation using queries and datasets from TPC-H, JOB, TPC-DS, and Twitter shows PGMJoins to outperform the state of the art (by 2X-28X).}
}


@inproceedings{DBLP:conf/sigmod/ShiZP0P21,
	author = {Benwei Shi and
                  Zhuoyue Zhao and
                  Yanqing Peng and
                  Feifei Li and
                  Jeff M. Phillips},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {At-the-time and Back-in-time Persistent Sketches},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {1623--1636},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452802},
	doi = {10.1145/3448016.3452802},
	timestamp = {Mon, 04 Nov 2024 08:45:19 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/ShiZP0P21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the era of big data, more and more applications require the information of historical data to support rich analytics, learning, and mining operations. In these cases, it is highly desirable to retrieve information of previous versions of data. Traditionally, multi-version databases can be used to store all historical values of the data in order to support historical queries. However, storing all the historical data can be impractical due to its large space consumption. In this paper, we propose the concept of at-the-time persistent (ATTP) and back-in-time persistent (BITP) sketches, which are sketches that approximately answer queries on previous versions of data with small space. We then provide several implementations of ATTP/BITP sketches which are shown to be more efficient compared to existing state-of-the-art solutions in our empirical studies.}
}


@inproceedings{DBLP:conf/sigmod/SilvestreFSK21,
	author = {Pedro F. Silvestre and
                  Marios Fragkoulis and
                  Diomidis Spinellis and
                  Asterios Katsifodimos},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Clonos: Consistent Causal Recovery for Highly-Available Streaming
                  Dataflows},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {1637--1650},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457320},
	doi = {10.1145/3448016.3457320},
	timestamp = {Thu, 14 Oct 2021 10:11:37 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/SilvestreFSK21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Stream processing lies in the backbone of modern businesses, being employed for mission critical applications such as real-time fraud detection, car-trip fare calculations, traffic management, and stock trading. Large-scale applications are executed by scale-out stream processing systems on thousands of long-lived operators, which are subject to failures. Recovering from failures fast and consistently are both top priorities, yet they are only partly satisfied by existing fault tolerance methods due to the strong assumptions these make. In particular, prior solutions fail to address consistency in the presence of nondeterminism, such as calls to external services, asynchronous timers and processing-time windows. This paper describes Clonos, a fault tolerance approach that achieves fast, local operator recovery with exactly-once guarantees and high availability by instantly switching to passive standby operators. Clonos enforces causally consistent recovery, including output deduplication, by tracking nondeterminism within the system through causal logging. To implement Clonos we re-engineered many of the internal subsystems of a state of the art stream processor. We evaluate Clonos' overhead and recovery on the Nexmark benchmark against Apache Flink. Clonos achieves instant recovery with negligible overhead and, unlike previous work, does not make assumptions on the deterministic nature of operators.}
}


@inproceedings{DBLP:conf/sigmod/SioulasA21,
	author = {Panagiotis Sioulas and
                  Anastasia Ailamaki},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Scalable Multi-Query Execution using Reinforcement Learning},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {1651--1663},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452799},
	doi = {10.1145/3448016.3452799},
	timestamp = {Mon, 21 Jun 2021 11:48:44 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/SioulasA21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The growing demand for data-intensive decision support and the migration to multi-tenant infrastructures put databases under the stress of high analytical query load. The requirement for high throughput contradicts the traditional design of query-at-a-time databases that optimize queries for efficient serial execution. Sharing work across queries presents an opportunity to reduce the total cost of processing and therefore improve throughput with increasing query load. Systems can share work either by assessing all opportunities and restructuring batches of queries ahead of execution, or by inspecting opportunities in individual incoming queries at runtime: the former strategy scales poorly to large query counts, as it requires expensive sharing-aware optimization, whereas the latter detects only a subset of the opportunities. Both strategies fail to minimize the cost of processing for large and ad-hoc workloads. This paper presents RouLette, a specialized intelligent engine for multi-query execution that addresses, through runtime adaptation, the shortcomings of existing work-sharing strategies. RouLette scales by replacing sharing-aware optimization with adaptive query processing, and it chooses opportunities to explore and exploit by using reinforcement learning. RouLette also includes optimizations that reduce the adaptation overhead. RouLette increases throughput by 1.6-28.3x, compared to a state-of-the-art query-at-a-time engine, and up to 6.5x, compared to sharing-enabled prototypes, for multi-query workloads based on the schema of TPC-DS.}
}


@inproceedings{DBLP:conf/sigmod/SmagulovaD21,
	author = {Ainur Smagulova and
                  Alin Deutsch},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Vertex-centric Parallel Computation of {SQL} Queries},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {1664--1677},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457314},
	doi = {10.1145/3448016.3457314},
	timestamp = {Sun, 19 Jan 2025 13:27:28 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/SmagulovaD21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We present a scheme for parallel execution of SQL queries on top of any vertex-centric BSP graph processing engine. The scheme comprises a graph encoding of relational instances and a vertex program specification of our algorithm called TAG-join, which matches the theoretical communication and computation complexity of state-of-the-art join algorithms. When run on top of the vertex-centric TigerGraph database engine on a single multi-core server, TAG-join exploits thread parallelism and is competitive with (and often outperforms) reference RDBMSs on the TPC benchmarks they are traditionally tuned for. In a distributed cluster, TAG-join outperforms the popular Spark SQL engine.}
}


@inproceedings{DBLP:conf/sigmod/SongH21,
	author = {Jie Song and
                  Yeye He},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Auto-Validate: Unsupervised Data Validation Using Data-Domain Patterns
                  Inferred from Data Lakes},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {1678--1691},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457250},
	doi = {10.1145/3448016.3457250},
	timestamp = {Fri, 07 Feb 2025 20:27:05 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/SongH21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Complex data pipelines are increasingly common in diverse applications such as BI reporting and ML modeling. These pipelines often recur regularly (e.g., daily or weekly), as BI reports need to be refreshed, and ML models need to be retrained. However, it is widely reported that in complex production pipelines, upstream data feeds can change in unexpected ways, causing downstream applications to break silently that are expensive to resolve. Data validation has thus become an important topic, as evidenced by notable recent efforts from Google and Amazon, where the objective is to catch data quality issues early as they arise in the pipelines. Our experience on production data suggests, however, that on string-valued data, these existing approaches yield high false-positive rates and frequently require human intervention. In this work, we develop a corpus-driven approach to auto-validate machine-generated data by inferring suitable data-validation "patterns\'\' that accurately describe the underlying data-domain, which minimizes false-positives while maximizing data quality issues caught. Evaluations using production data from real data lakes suggest that \\sj is substantially more effective than existing methods. Part of this technology ships as an Auto-Tag feature in Microsoft Azure Purview.}
}


@inproceedings{DBLP:conf/sigmod/SongGHW21,
	author = {Shaoxu Song and
                  Fei Gao and
                  Ruihong Huang and
                  Yihan Wang},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {On Saving Outliers for Better Clustering over Noisy Data},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {1692--1704},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457271},
	doi = {10.1145/3448016.3457271},
	timestamp = {Mon, 03 Jan 2022 22:24:52 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/SongGHW21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Clustering is often distracted by errors, frequently observed in almost all areas, ranging from online questionnaire to sensor reading in IoT. The dirty data values not only make themselves (the corresponding tuples) outlying, but also mislead the clustering of remaining tuples, e.g., mistakenly splitting a cluster into two or distorting the cluster center. The reason is that the traditional clustering methods either simply ignore the outliers such as DBSCAN or assign them to the closest clusters anyway, e.g., in K-Means. In this paper, we propose to save the outliers for better clustering. The idea is to adjust the erroneous values (often minimally) of the outlier in order to make it appear normally. That is, the tuples after adjusting values are no longer outlying, and thus will be clustered without distracting others. The outlier saving by value adjustment is designed to work with any clustering methods (e.g., DBSCAN or K-Means). Our technical contributions include: (1) showing NPhardness of the outlier saving problem for clustering, (2) deriving lower and upper bounds of the optimal solutions, and (3) devising approximation algorithm with performance guarantees referring to the aforesaid bounds. Experiments on datasets with real-world outliers demonstrate the higher accuracy of our proposal, compared to the state-of-the-art approaches. Remarkably, we show that the adjusted data with outlier saving indeed improve significantly clustering, as well as other applications such as classification and record matching.}
}


@inproceedings{DBLP:conf/sigmod/SongHG021,
	author = {Shaoxu Song and
                  Ruihong Huang and
                  Yu Gao and
                  Jianmin Wang},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Why Not Match: On Explanations of Event Pattern Queries},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {1705--1717},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452818},
	doi = {10.1145/3448016.3452818},
	timestamp = {Sun, 19 Jan 2025 13:27:29 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/SongHG021.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Queries over event data are posed in a form of event patterns, for example, to retrieve the flights from IAH to LGA without a stopover. If the expected answer is not returned, one may ask why not, also known as explanations of non-answers. Analogous to the relational data, the explanations over event data lie in two aspects. (1) The pattern consistency explanation indicates that the patterns specified in the query are wrong (inconsistent), that is, there exists no tuple of events that can match the query. (2) The timestamp modification explanation speculates that the instance of event tuple is incorrect, for example, the timestamps of some events are imprecise and need modification. To the best of our knowledge, this is the first study on explaining non-answers over event data. We prove that both explanation problems are NP-complete. By encoding event patterns as a novel notation, we identify the special cases that can be efficiently solved or approximated. General cases are addressed by utilizing the solutions of special cases. Extensive experiments over real and synthetic datasets demonstrate both effectiveness and efficiency of our proposal.}
}


@inproceedings{DBLP:conf/sigmod/SpiegelbergYSK21,
	author = {Leonhard F. Spiegelberg and
                  Rahul Yesantharao and
                  Malte Schwarzkopf and
                  Tim Kraska},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Tuplex: Data Science in Python at Native Code Speed},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {1718--1731},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457244},
	doi = {10.1145/3448016.3457244},
	timestamp = {Sun, 19 Jan 2025 13:27:28 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/SpiegelbergYSK21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Today's data science pipelines often rely on user-defined functions (UDFs) written in Python. But interpreted Python code is slow, and Python UDFs cannot be compiled to machine code easily. We present Tuplex, a new data analytics framework that just in-time compiles developers' natural Python UDFs into efficient, end-to-end optimized native code. Tuplex introduces a novel dual-mode execution model that compiles an optimized fast path for the common case, and falls back on slower exception code paths for data that fail to match the fast path's assumptions. Dual-mode execution is crucial to making end-to-end optimizing compilation tractable: by focusing on the common case, Tuplex keeps the code simple enough to apply aggressive optimizations. Thanks to dual-mode execution, Tuplex pipelines always complete even if exceptions occur, and Tuplex's post-facto exception handling simplifies debugging. We evaluate Tuplex with data science pipelines over real-world datasets. Compared to Spark and Dask, Tuplex improves end-to-end pipeline runtime by 5-91x and comes within 1.1-1.7x of a hand-optimized C++ baseline. Tuplex outperforms other Python compilers by 6x and competes with prior, more limited query compilers. Optimizations enabled by dual-mode processing improve runtime by up to 3x, and Tuplex performs well in a distributed setting on serverless functions.}
}


@inproceedings{DBLP:conf/sigmod/SpothKLHL21,
	author = {William Spoth and
                  Oliver Kennedy and
                  Ying Lu and
                  Beda Christoph Hammerschmidt and
                  Zhen Hua Liu},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Reducing Ambiguity in Json Schema Discovery},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {1732--1744},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452801},
	doi = {10.1145/3448016.3452801},
	timestamp = {Thu, 01 May 2025 20:25:59 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/SpothKLHL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Ad-hoc data models like Json simplify schema evolution and enable multiplexing various data sources into a single stream. While useful when writing data, this flexibility makes Json harder to validate and query, forcing such tasks to rely on automated schema discovery techniques. Unfortunately, ambiguity in the schema design space forces existing schema discovery systems to make simplifying, data-independent assumptions about schema structure. When these assumptions are violated, most notably by APIs, the generated schemas are imprecise, creating numerous opportunities for false positives during validation. In this paper, we propose Jxplain, a Json schema discovery algorithm with heuristics that mitigate common forms of ambiguity. Although Jxplain is slightly slower than state of the art schema extractors, we show that it produces significantly more precise schemas.}
}


@inproceedings{DBLP:conf/sigmod/Sun0021,
	author = {Ji Sun and
                  Guoliang Li and
                  Nan Tang},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Learned Cardinality Estimation for Similarity Queries},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {1745--1757},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452790},
	doi = {10.1145/3448016.3452790},
	timestamp = {Thu, 01 May 2025 20:25:59 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/Sun0021.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we study the problem of using deep neural networks (DNNs) for estimating the cardinality of similarity queries. Intuitively, DNNs can capture the distribution of data points, and learn to predict the number of data points that are similar to one data point (a similarity search) or a set of data points (a similarity join). However, DNNs are data hungry; directly training a DNN often results in poor performance. We propose two strategies to improve the accuracy and reduce the size of training data: query segmentation and data segmentation. Query segmentation divides a query into query segments, trains a neural network for each query segment, and combines their outputs with subsequent DNNs to get the query embedding. Data segmentation groups similar data into data segments, train a local-model for each data segment, and learn a global-model to decide which local-models should be used for a given query. The estimates from selected local-models will be summed up as the final estimate.We also extend our model to support similarity joins, which trains a DNN to directly estimate the cumulative sum of objects that are similar to a set of queries. Experiments show that our methods can efficiently (i.e., with small training data) learn to estimate the cardinality of similarity searches/joins, and yield effective estimates (i.e., close to real cardinalities).}
}


@inproceedings{DBLP:conf/sigmod/SunCHH21,
	author = {Shixuan Sun and
                  Yuhang Chen and
                  Bingsheng He and
                  Bryan Hooi},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {PathEnum: Towards Real-Time Hop-Constrained s-t Path Enumeration},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {1758--1770},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457290},
	doi = {10.1145/3448016.3457290},
	timestamp = {Mon, 21 Jun 2021 11:48:44 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/SunCHH21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We study the hop-constrained s-t path enumeration (HcPE ) problem, which takes a graph G, two distinct vertices s,t and a hop constraint k as input, and outputs all paths from s to t whose length is at most k. The state-of-the-art algorithms suffer from severe performance issues caused by the costly pruning operations during enumeration for the workloads with the large search space. Consequently, these algorithms hardly meet the real-time constraints of many online applications. In this paper, we propose PathEnum, an efficient index-based algorithm towards real-time HcPE. For an input query, PathEnum first builds a light-weight index aiming to reduce the number of edges involved in the enumeration, and develops efficient index-based approaches for enumeration, one based on depth-first search and the other based on joins. We further develop a query optimizer based on a join-based cost model to optimize the search order. We conduct experiments with 15 real-world graphs. Our experiment results show that PathEnum outperforms the state-of-the-art approaches by orders of magnitude in terms of the query time, throughput and response time.}
}


@inproceedings{DBLP:conf/sigmod/TaeW21,
	author = {Ki Hyun Tae and
                  Steven Euijong Whang},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Slice Tuner: {A} Selective Data Acquisition Framework for Accurate
                  and Fair Machine Learning Models},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {1771--1783},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452792},
	doi = {10.1145/3448016.3452792},
	timestamp = {Sun, 19 Jan 2025 13:27:29 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/TaeW21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As machine learning becomes democratized in the era of Software 2.0, a serious bottleneck is acquiring enough data to ensure accurate and fair models. Recent techniques including crowdsourcing provide cost-effective ways to gather such data. However, simply acquiring data as much as possible is not necessarily an effective strategy for optimizing accuracy and fairness. For example, if an online app store has enough training data for certain slices of data (say American customers), but not for others, obtaining more American customer data will only bias the model training. Instead, we contend that one needs to selectively acquire data and propose Slice Tuner, which acquires possibly-different amounts of data per slice such that the model accuracy and fairness on all slices are optimized. This problem is different than labeling existing data (as in active learning or weak supervision) because the goal is obtaining the right amounts of new data. At its core, Slice Tuner maintains learning curves of slices that estimate the model accuracies given more data and uses convex optimization to find the best data acquisition strategy. The key challenges of estimating learning curves are that they may be inaccurate if there is not enough data, and there may be dependencies among slices where acquiring data for one slice influences the learning curves of others. We solve these issues by iteratively and efficiently updating the learning curves as more data is acquired. We evaluate Slice Tuner on real datasets using crowdsourcing for data acquisition and show that Slice Tuner significantly outperforms baselines in terms of model accuracy and fairness, even when the learning curves cannot be reliably estimated.}
}


@inproceedings{DBLP:conf/sigmod/0016MH21,
	author = {Bo Tang and
                  Kyriakos Mouratidis and
                  Mingji Han},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {On m-Impact Regions and Standing Top-k Influence Problems},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {1784--1796},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452832},
	doi = {10.1145/3448016.3452832},
	timestamp = {Mon, 03 Jan 2022 22:24:51 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/0016MH21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we study the m-impact region problem (mIR). In a context where users look for available products with top-k queries, mIR identifies the part of the product space that attracts the most user attention. Specifically, mIR determines the kind of attribute values that lead a (new or existing) product to the top-k result for at least a fraction of the user population. mIR has several applications, ranging from effective marketing to product improvement. Importantly, it also leads to (exact and efficient) solutions for standing top-k impact problems, which were previously solved heuristically only, or whose current solutions face serious scalability limitations. We experiment, among others, on data mined from actual user reviews for real products, and demonstrate the practicality and efficiency of our algorithms, both for mIR and for standing top-k impact problems.}
}


@inproceedings{DBLP:conf/sigmod/TangSMEK21,
	author = {Dixin Tang and
                  Zechao Shang and
                  William W. Ma and
                  Aaron J. Elmore and
                  Sanjay Krishnan},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Resource-efficient Shared Query Execution via Exploiting Time Slackness},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {1797--1810},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457282},
	doi = {10.1145/3448016.3457282},
	timestamp = {Mon, 03 Mar 2025 21:21:50 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/TangSMEK21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Shared query execution can reduce resource consumption by sharing common sub-expressions across concurrent queries. We show that this is not always the case when regularly querying a dataset under change. Depending on latency goals, how eagerly to incrementally process the new data differs. Naively sharing the execution of queries with different latency goals will push the whole shared plan to meet the lowest latency goal and execute more eagerly than each participating query. The overhead introduced by the eager execution can even offset the benefit of shared query execution. We propose an optimization framework iShare to exploit the benefit of shared execution and avoid the overhead of eager execution. iShare judiciously shares queries with different latency goals and selectively executes parts of the share plan lazily. iShare can significantly reduce resource consumption compared to eagerly executing share plans from the state-of-the-art multi-query optimizer or approaches that execute queries separately.}
}


@inproceedings{DBLP:conf/sigmod/TaranovGH21,
	author = {Konstantin Taranov and
                  Salvatore Di Girolamo and
                  Torsten Hoefler},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {CoRM: Compactable Remote Memory over {RDMA}},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {1811--1824},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452817},
	doi = {10.1145/3448016.3452817},
	timestamp = {Mon, 21 Jun 2021 11:48:44 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/TaranovGH21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Distributed memory systems are becoming increasingly important since they provide a system-scale abstraction where physically separated memories can be addressed as a single logical one. This abstraction enables memory disaggregation, allowing systems as in-memory databases, caching services, and ephemeral storage to be naturally deployed at large scales. While this abstraction effectively increases the memory capacity of these systems, it faces additional overheads for remote memory accesses. To narrow the difference between local and remote accesses, low latency RDMA networks are a key element for efficient memory disaggregation. However, RDMA acceleration poses new obstacles to efficient memory management and particularly to memory compaction: network controllers and CPUs can concurrently access memory, potentially leading to inconsistencies if memory management operations are not synchronized. To ensure consistency, most distributed memory systems do not provide memory compaction and are exposed to memory fragmentation. We introduce CoRM, an RDMA-accelerated shared memory system that supports memory compaction and ensures strict consistency while providing one-sided RDMA accesses. We show that CoRM sustains high read throughput during normal operations, comparable to similar systems not providing memory compaction while experiencing minimal overheads during compaction. CoRM never disrupts RDMA connections and can reduce applications' active memory up to 6x by performing memory compaction.}
}


@inproceedings{DBLP:conf/sigmod/ThostrupSJ0B21,
	author = {Lasse Thostrup and
                  Jan Skrzypczak and
                  Matthias Jasny and
                  Tobias Ziegler and
                  Carsten Binnig},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {{DFI:} The Data Flow Interface for High-Speed Networks},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {1825--1837},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452816},
	doi = {10.1145/3448016.3452816},
	timestamp = {Sun, 04 Aug 2024 19:37:27 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/ThostrupSJ0B21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we propose the Data Flow Interface (DFI) as a way to make it easier for data processing systems to exploit high-speed networks without the need to deal with the complexity of RDMA. By lifting the level of abstraction, DFI factors out much of the complexity of network communication and makes it easier for developers to declaratively express how data should be efficiently routed to accomplish a given distributed data processing task. As we show in our experiments, DFI is able to support a wide variety of data-centric applications with high performance at a low complexity for the applications.}
}


@inproceedings{DBLP:conf/sigmod/TingC21,
	author = {Daniel Ting and
                  Rick Cole},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Conditional Cuckoo Filters},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {1838--1850},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452811},
	doi = {10.1145/3448016.3452811},
	timestamp = {Mon, 21 Jun 2021 11:48:44 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/TingC21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Bloom filters, cuckoo filters, and other approximate set membership sketches have a wide range of applications. Oftentimes, expensive operations can be skipped if an item is not in a data set. These filters provide an inexpensive, memory efficient way to test if an item is in a set and avoid unnecessary operations. Existing sketches only allow membership testing for a single set. However, in some applications such as join processing, the relevant set is not fixed and is determined by a set of predicates. We propose the Conditional Cuckoo Filter, a simple modification of the cuckoo filter that allows for set membership testing given predicates on a pre-computed sketch. This filter also introduces a novel chaining technique that enables cuckoo filters to handle insertion of duplicate keys. We evaluate our methods on a join processing application and show that they significantly reduce the number of tuples that a join must process.}
}


@inproceedings{DBLP:conf/sigmod/TsengDS21,
	author = {Tom Tseng and
                  Laxman Dhulipala and
                  Julian Shun},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Parallel Index-Based Structural Graph Clustering and Its Approximation},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {1851--1864},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457278},
	doi = {10.1145/3448016.3457278},
	timestamp = {Mon, 05 Feb 2024 20:26:57 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/TsengDS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {SCAN (Structural Clustering Algorithm for Networks) is a well-studied, widely used graph clustering algorithm. For large graphs, however, sequential SCAN variants are prohibitively slow, and parallel SCAN variants do not effectively share work among queries with different SCAN parameter settings. Since users of SCAN often explore many parameter settings to find good clusterings, it is worthwhile to precompute an index that speeds up queries. This paper presents a practical and provably efficient parallel index-based SCAN algorithm based on GS*-Index, a recent sequential algorithm. Our parallel algorithm improves upon the asymptotic work of the sequential algorithm by using integer sorting. It is also highly parallel, achieving logarithmic span (parallel time) for both index construction and clustering queries. Furthermore, we apply locality-sensitive hashing (LSH) to design a novel approximate SCAN algorithm and prove guarantees for its clustering behavior. We present an experimental evaluation of our algorithms on large real-world graphs. On a 48-core machine with two-way hyper-threading, our parallel index construction achieves 50--151× speedup over the construction of GS*-Index. In fact, even on a single thread, our index construction algorithm is faster than GS*-Index. Our parallel index query implementation achieves 5--32× speedup over GS*-Index queries across a range of SCAN parameter values, and our implementation is always faster than ppSCAN, a state-of-the-art parallel SCAN algorithm. Moreover, our experiments show that applying LSH results in faster index construction while maintaining good clustering quality.}
}


@inproceedings{DBLP:conf/sigmod/VenturaKQM21,
	author = {Francesco Ventura and
                  Zoi Kaoudi and
                  Jorge{-}Arnulfo Quian{\'{e}}{-}Ruiz and
                  Volker Markl},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Expand your Training Limits! Generating Training Data for ML-based
                  Data Management},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {1865--1878},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457286},
	doi = {10.1145/3448016.3457286},
	timestamp = {Mon, 26 Jun 2023 20:43:17 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/VenturaKQM21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Machine Learning (ML) is quickly becoming a prominent method in many data management components, including query optimizers which have recently shown very promising results. However, the low availability of training data (i.e., large query workloads with execution time or output cardinality as labels) widely limits further advancement in research and compromises the technology transfer from research to industry. Collecting a labeled query workload has a very high cost in terms of time and money due to the development and execution of thousands of realistic queries/jobs. In this work, we face the problem of generating training data for data management components tailored to users' needs. We present DataFarm, an innovative framework for efficiently generating and labeling large query workloads. We follow a data-driven white-box approach to learn from pre-existing small workload patterns, input data, and computational resources. Our framework allows users to produce a large heterogeneous set of realistic jobs with their labels, which can be used by any ML-based data management component. We show that our framework outperforms the current state-of-the-art both in query generation and label estimation using synthetic and real datasets. It has up to 9x better labeling performance, in terms of R2 score. More importantly, it allows users to reduce the cost of getting labeled query workloads by 54x (and up to an estimated factor of 104x) compared to standard approaches.}
}


@inproceedings{DBLP:conf/sigmod/WagnerK021,
	author = {Benjamin Wagner and
                  Andr{\'{e}} Kohn and
                  Thomas Neumann},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Self-Tuning Query Scheduling for Analytical Workloads},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {1879--1891},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457260},
	doi = {10.1145/3448016.3457260},
	timestamp = {Thu, 27 Jul 2023 08:32:09 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/WagnerK021.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Most database systems delegate scheduling decisions to the operating system. While such an approach simplifies the overall database design, it also entails problems. Adaptive resource allocation becomes hard in the face of concurrent queries. Furthermore, incorporating domain knowledge to improve query scheduling is difficult. To mitigate these problems, many modern systems employ forms of task-based parallelism. The execution of a single query is broken up into small, independent chunks of work (tasks). Now, fine-grained scheduling decisions based on these tasks are the responsibility of the database system. Despite being commonplace, little work has focused on the opportunities arising from this execution model. In this paper, we show how task-based scheduling in database systems opens up new areas for optimization. We present a novel lock-free, self-tuning stride scheduler that optimizes query latencies for analytical workloads. By adaptively managing query priorities and task granularity, we provide high scheduling elasticity. By incorporating domain knowledge into the scheduling decisions, our system is able to cope with workloads that other systems struggle with. Even at high load, we retain near optimal latencies for short running queries. Compared to traditional database systems, our design often improves tail latencies by more than 10x.}
}


@inproceedings{DBLP:conf/sigmod/WangBNM21,
	author = {Chenghong Wang and
                  Johes Bater and
                  Kartik Nayak and
                  Ashwin Machanavajjhala},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {DP-Sync: Hiding Update Patterns in Secure Outsourced Databases with
                  Differential Privacy},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {1892--1905},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457306},
	doi = {10.1145/3448016.3457306},
	timestamp = {Sun, 19 Jan 2025 13:27:20 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/WangBNM21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we consider privacy-preserving update strategies for secure outsourced growing databases. Such databases allow appendonly data updates on the outsourced data structure while analysis is ongoing. Despite a plethora of solutions to securely outsource database computation, existing techniques do not consider the information that can be leaked via update patterns. To address this problem, we design a novel secure outsourced database framework for growing data, DP-Sync, which interoperate with a large class of existing encrypted databases and supports efficient updates while providing differentially-private guarantees for any single update. We demonstrate DP-Sync's practical feasibility in terms of performance and accuracy with extensive empirical evaluations on real world datasets.}
}


@inproceedings{DBLP:conf/sigmod/WangSMB21,
	author = {Sheng Wang and
                  Yuan Sun and
                  Christopher Musco and
                  Zhifeng Bao},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Public Transport Planning: When Transit Network Connectivity Meets
                  Commuting Demand},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {1906--1919},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457247},
	doi = {10.1145/3448016.3457247},
	timestamp = {Wed, 05 Jan 2022 16:54:21 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/WangSMB21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we make a first attempt to incorporate both commuting demand and transit network connectivity in bus route planning (CT-Bus), and formulate it as a constrained optimization problem: planning a new bus route with k edges over an existing transit network without building new bus stops to maximize a linear aggregation of commuting demand and connectivity of the transit network. We prove the NP-hardness of CT-Bus and propose an expansion-based greedy algorithm that iteratively scans potential candidate paths in the network. To boost the efficiency of computing the connectivity of new networks with candidate paths, we convert it to a matrix trace estimation problem and employ a Lanczos method to estimate the natural connectivity of the transit network with a guaranteed error bound. Furthermore, we derive upper bounds on the objective values and use them to greedily select candidates for expansion. Our experiments conducted on real-world transit networks in New York City and Chicago verify the efficiency, effectiveness, and scalability of our algorithms.}
}


@inproceedings{DBLP:conf/sigmod/WangWX21,
	author = {Weicheng Wang and
                  Raymond Chi{-}Wing Wong and
                  Min Xie},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Interactive Search for One of the Top-k},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {1920--1932},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457322},
	doi = {10.1145/3448016.3457322},
	timestamp = {Mon, 12 Aug 2024 18:35:46 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/WangWX21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {When a large dataset is given, it is not desirable for a user to read all tuples one-by-one in the whole dataset to find satisfied tuples. The traditional top-k query finds the best k tuples (i.e., the top-k tuples) w.r.t. the user's preference. However, in practice, it is difficult for a user to specify his/her preference explicitly. We study how to enhance the top-k query with user interaction. Specifically, we ask a user several questions, each of which consists of two tuples and asks the user to indicate which one s/he prefers. Based on the feedback, the user's preference is learned implicitly and one of the top-k tuples w.r.t. the learned preference is returned. Here, instead of directly following the top-k query to return all the top-k tuples, since it requires heavy user effort during the interaction (e.g., answering many questions), we reduce the output size to strike for a trade-off between the user effort and the output size. To achieve this, we present an algorithm 2D-PI which asks an asymptotically optimal number of questions in a 2-dimensional space, and two algorithms HD-PI and RH with provable performance guarantee in a d-dimensional space (d >= 2), where they focus on the number of questions asked and the execution time, respectively. Experiments were conducted on synthetic and real datasets, showing that our algorithms outperform existing ones by asking fewer questions within less time to return satisfied tuples.}
}


@inproceedings{DBLP:conf/sigmod/WangBLJLC21,
	author = {Weiguo Wang and
                  Sourav S. Bhowmick and
                  Hui Li and
                  Shafiq R. Joty and
                  Siyuan Liu and
                  Peng Chen},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Towards Enhancing Database Education: Natural Language Generation
                  Meets Query Execution Plans},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {1933--1945},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452822},
	doi = {10.1145/3448016.3452822},
	timestamp = {Sun, 19 Jan 2025 13:27:24 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/WangBLJLC21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The database systems course is offered as part of an undergraduate computer science degree program in many major universities. A key learning goal of learners taking such a course is to understand how sql queries are processed in a rdbms in practice. Since aquery execution plan (qep ) describes the execution steps of a query, learners can acquire the understanding by perusing the qep s generated by a rdbms. Unfortunately, in practice, it is often daunting for a learner to comprehend these qep s containing vendor-specific implementation details, hindering her learning process. In this paper, we present a novel, end-to-end,generic system called lantern that generates a natural language description of a qep to facilitate understanding of the query execution steps. It takes as input an sql query and its qep, and generates a natural language description of the execution strategy deployed by the underlying rdbms. Specifically, it deploys adeclarative framework called pool that enablessubject matter experts to efficiently create and maintain natural language descriptions of physical operators used in qep s. Arule-based framework called rule-lantern is proposed that exploits pool to generate natural language descriptions of qep s. Despite the high accuracy of rule-lantern, our engagement with learners reveal that, consistent with existing psychology theories, perusing such rule-based descriptions lead toboredom due to repetitive statements across different qep s. To address this issue, we present a noveldeep learning-based language generation framework called neural -lantern that infuses language variability in the generated description by exploiting a set ofparaphrasing tools andword embedding. Our experimental study with real learners shows the effectiveness of lantern in facilitating comprehension of qep s.}
}


@inproceedings{DBLP:conf/sigmod/WangWKL21,
	author = {Ye Wang and
                  Qing Wang and
                  Henning Koehler and
                  Yu Lin},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Query-by-Sketch: Scaling Shortest Path Graph Queries on Very Large
                  Networks},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {1946--1958},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452826},
	doi = {10.1145/3448016.3452826},
	timestamp = {Sun, 19 Jan 2025 13:27:29 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/WangWKL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Computing shortest paths is a fundamental operation in processing graph data. In many real-world applications, discovering shortest paths between two vertices empowers us to make full use of the underlying structure to understand how vertices are related in a graph, e.g. the strength of social ties between individuals in a social network. In this paper, we study the shortest-path-graph problem that aims to efficiently compute a shortest path graph containing exactly all shortest paths between any arbitrary pair of vertices on complex networks. Our goal is to design an exact solution that can scale to graphs with millions or billions of vertices and edges. To achieve high scalability, we propose a novel method, Query-by-Sketch (QbS), which efficiently leverages offline labelling (i.e., precomputed labels) to guide online searching through a fast sketching process that summarizes the important structural aspects of shortest paths in answering shortest-path-graph queries. We theoretically prove the correctness of this method and analyze its computational complexity. To empirically verify the efficiency of QbS, we conduct experiments on 12 real-world datasets, among which the largest dataset has 1.7 billion vertices and 7.8 billion edges. The experimental results show that QbS can answer shortest-path-graph queries in microseconds for million-scale graphs and less than half a second for billion-scale graphs.}
}


@inproceedings{DBLP:conf/sigmod/Wang021,
	author = {Yilei Wang and
                  Ke Yi},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Secure Yannakakis: Join-Aggregate Queries over Private Data},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {1969--1981},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452808},
	doi = {10.1145/3448016.3452808},
	timestamp = {Sat, 30 Sep 2023 09:56:35 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/Wang021.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we describe a secure version of the classical Yannakakis algorithm for computing free-connex join-aggregate queries. This protocol can be used in the secure two-party computation model, where the parties would like to evaluate a query without revealing their own data. Our protocol presents a dramatic improvement over the state-of-the-art protocol based on Yao's garbled circuit. In theory, its cost (both running time and communication) is linear in data size and polynomial in query size, whereas that of the garbled circuit is polynomial in data size and exponential in query size. This translates to a reduction in running time in practice from years to minutes, as tested on a number of TPC-H queries of varying complexity.}
}


@inproceedings{DBLP:conf/sigmod/WangY0S21,
	author = {Yiqiu Wang and
                  Shangdi Yu and
                  Yan Gu and
                  Julian Shun},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Fast Parallel Algorithms for Euclidean Minimum Spanning Tree and Hierarchical
                  Spatial Clustering},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {1982--1995},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457296},
	doi = {10.1145/3448016.3457296},
	timestamp = {Sun, 06 Aug 2023 20:52:01 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/WangY0S21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper presents new parallel algorithms for generating Euclidean minimum spanning trees and spatial clustering hierarchies (known as HDBSCAN*). Our approach is based on generating a well-separated pair decomposition followed by using Kruskal's minimum spanning tree algorithm and bichromatic closest pair computations. We introduce a new notion of well-separation to reduce the work and space of our algorithm for HDBSCAN*. We also give a new parallel divide-and-conquer algorithm for computing the dendrogram and reachability plots, which are used in visualizing clusters of different scale that arise for both EMST and HDBSCAN*. We show that our algorithms are theoretically efficient: they have work (number of operations) matching their sequential counterparts, and polylogarithmic depth (parallel time). We implement our algorithms and propose a memory optimization that requires only a subset of well-separated pairs to be computed and materialized, leading to savings in both space (up to 10x) and time (up to 8x). Our experiments on large real-world and synthetic data sets using a 48-core machine show that our fastest algorithms outperform the best serial algorithms for the problems by 11.13--55.89x, and existing parallel algorithms by at least an order of magnitude.}
}


@inproceedings{DBLP:conf/sigmod/WuGWZ21,
	author = {Hao Wu and
                  Junhao Gan and
                  Zhewei Wei and
                  Rui Zhang},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Unifying the Global and Local Approaches: An Efficient Power Iteration
                  with Forward Push},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {1996--2008},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457298},
	doi = {10.1145/3448016.3457298},
	timestamp = {Sun, 12 Feb 2023 18:48:33 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/WuGWZ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Personalized PageRank (PPR) is a critical measure of the importance of a node t to a source node s in a graph. The Single-Source PPR (SSPPR) query computes the PPR's of all the nodes with respect to s on a directed graph G with n nodes and m edges; and it is an essential operation widely used in graph applications. In this paper, we propose novel algorithms for answering two variants of SSPPR queries: (i) high-precision queries and (ii) approximate queries. For high-precision queries, Power Iteration (PowItr) and Forward Push (FwdPush) are two fundamental approaches. Given an absolute error threshold λ (which is typically set to as small as 10-8), the only known bound of FwdPush is O(m/λ), much worse than the O(m log 1/λ)-bound of PowItr. Whether FwdPush can achieve the same running time bound as PowItr does still remains an open question in the research community. We give a positive answer to this question. We show that the running time of a common implementation of FwdPush is actually bounded by O(m · log 1/λ). Based on this finding, we propose a new algorithm, called Power Iteration with Forward Push (PowerPush), which incorporates the strengths of both PowItr and FwdPush. For approximate queries (with a relative error ε), we propose a new algorithm, called SpeedPPR, with overall expected time bounded by $O(n · log n · log 1/ε) on scale-free graphs. This improves the state-of-the-art O((n · log n)/ε) bound. We conduct extensive experiments on six real datasets. The experimental results show that PowerPush outperforms the state-of-the-art high-precision algorithm BePi by up to an order of magnitude in both efficiency and accuracy. Furthermore, our SpeedPPR also outperforms the state-of-the-art approximate algorithm FORA by up to an order of magnitude in all aspects including query time, accuracy, pre-processing time as well as index size.}
}


@inproceedings{DBLP:conf/sigmod/WuC21,
	author = {Peizhi Wu and
                  Gao Cong},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {A Unified Deep Model of Learning from both Data and Queries for Cardinality
                  Estimation},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2009--2022},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452830},
	doi = {10.1145/3448016.3452830},
	timestamp = {Mon, 21 Jun 2021 11:48:44 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/WuC21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cardinality estimation is a fundamental problem in database systems. To capture the rich joint data distributions of a relational table, most of the existing work either uses data as unsupervised information or uses query workload as supervised information. Very little work has been done to use both types of information, and cannot fully make use of both types of information to learn the joint data distribution. In this work, we aim to close the gap between data-driven and query-driven methods by proposing a new unified deep autoregressive model, UAE, that learns the joint data distribution from both the data and query workload. First, to enable using the supervised query information in the deep autoregressive model, we develop differentiable progressive sampling using the Gumbel-Softmax trick. Second, UAE is able to utilize both types of information to learn the joint data distribution in a single model. Comprehensive experimental results demonstrate that UAE achieves single-digit multiplicative error at tail, better accuracies over state-of-the-art methods, and is both space and time efficient.}
}


@inproceedings{DBLP:conf/sigmod/0001PM021,
	author = {Dong Xie and
                  Jeff M. Phillips and
                  Michael Matheny and
                  Feifei Li},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Spatial Independent Range Sampling},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2023--2035},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452806},
	doi = {10.1145/3448016.3452806},
	timestamp = {Sun, 19 Jan 2025 13:27:25 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/0001PM021.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Thanks to the wide adoption of GPS-equipped devices, the volume of collected spatial data is exploding. To achieve interactive exploration and analysis over big spatial data, people are willing to trade off accuracy for performance through approximation. As a foundation in many approximate algorithms, data sampling now requires more flexibility and better performance. In this paper, we study the spatial independent range sampling (SIRS) problem aiming at retrieving random samples with independence over points residing in a query region. Specifically, we have designed concise index structures with careful data layout based on various space decomposition strategies. Moreover, we propose novel algorithms for both uniform and weighted SIRS queries with low theoretical cost and complexity as well as excellent practical performance. Last but not least, we demonstrate how to support data updates and trade-offs between different sampling methods in practice. According to comprehensive evaluations conducted on real-world datasets, our methods achieve orders of magnitude performance improvement against baselines derived by existing works.}
}


@inproceedings{DBLP:conf/sigmod/XuC21,
	author = {Zihuan Xu and
                  Lei Chen},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {{DIV:} Resolving the Dynamic Issues of Zero-knowledge Set Membership
                  Proof in the Blockchain},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2036--2048},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457248},
	doi = {10.1145/3448016.3457248},
	timestamp = {Sun, 19 Jan 2025 13:27:31 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/XuC21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Zero-knowledge set membership (ZKSM) proof is widely used in blockchain to enable private membership attestation. However, existing mechanisms do not fully consider dynamic issues in the blockchain scenario. Particularly, frequent addition/removal of set elements, not only brings the significant cost to keep public parameters up to date to provers and verifiers but also affects mechanism efficiency (e.g., generation time of the proof and verification, etc.). In this paper, we propose DIV to shard elements on blockchain into independent subsets with the same cardinality to reduce the effect of dynamic issues. However, due to the diverse proof frequency, an improper element-set assignment can result in frequently used elements being easily inferred and corrupted. Thus, we formalize the assignment problem under both element addition and removal cases as two optimization problems and prove their NP-hardness. For each problem, we consider two cases if each element proof frequency is known in advance by the set maintainer or not, and propose solutions with theoretical guarantees. We implement DIV on both Merkle tree and RSA-based ZKSM mechanisms to evaluate its efficiency and effectiveness and apply DIV on a ZKSMbased application named zkSync to demonstrate its applicability. Results show that DIV can achieve O(1) time/space cost on ZKSM under dynamic situations while protecting the information about frequently used elements. It also notably reduces the system latency of zkSync.}
}


@inproceedings{DBLP:conf/sigmod/YangL0H021,
	author = {Zhengyi Yang and
                  Longbin Lai and
                  Xuemin Lin and
                  Kongzhang Hao and
                  Wenjie Zhang},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {{HUGE:} An Efficient and Scalable Subgraph Enumeration System},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2049--2062},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457237},
	doi = {10.1145/3448016.3457237},
	timestamp = {Sun, 04 Aug 2024 19:37:28 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/YangL0H021.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Subgraph enumeration is a fundamental problem in graph analytics, which aims to find all instances of a given query graph on a large data graph. In this paper, we propose a system called HUGE to efficiently process subgraph enumeration at scale in the distributed context. HUGE features 1) an optimiser to compute an advanced execution plan without the constraints of existing works; 2) a hybrid communication layer that supports both pushing and pulling communication; 3) a novel two-stage execution mode with a lock-free and zero-copy cache design; 4) a BFS/DFS-adaptive scheduler to bound memory consumption; and 5) two-layer intra- and inter-machine load balancing. HUGE is generic such that all existing distributed subgraph enumeration algorithms can be plugged in to enjoy automatic speed up and bounded-memory execution.}
}


@inproceedings{DBLP:conf/sigmod/YoonS0L21,
	author = {Susik Yoon and
                  Yooju Shin and
                  Jae{-}Gil Lee and
                  Byung Suk Lee},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Multiple Dynamic Outlier-Detection from a Data Stream by Exploiting
                  Duality of Data and Queries},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2063--2075},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452810},
	doi = {10.1145/3448016.3452810},
	timestamp = {Thu, 01 Jun 2023 13:14:33 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/YoonS0L21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Real-time outlier detection from a data stream has become increasingly important in the current hyperconnected world. This paper focuses on an important yet unaddressed challenge in continuous outlier detection: the multiplicity and dynamicity of queries. This challenge arises from various contexts of outliers evolving over time, but the state-of-the-art algorithms cannot handle the challenge effectively, as they can only process a fixed set of outlier detection queries for each data point separately. In this paper, we propose a novel algorithm, abbreviated as MDUAL, based on a new idea called duality-based unified processing. The underlying rationale is to exploit the duality of data and queries so that a group of similar data points are processed together by a group of similar queries incrementally. Two main techniques embodying the idea, data-query grouping and prioritized group processing, are employed. Comprehensive experiments showed that MDUAL runs 216 to 221 times faster while consuming 11 to 13 times less memory than the state-of-the-art algorithms through its efficient and effective handling of the multiplicity-dynamicity challenge.}
}


@inproceedings{DBLP:conf/sigmod/ZhangCAN21,
	author = {Hantian Zhang and
                  Xu Chu and
                  Abolfazl Asudeh and
                  Shamkant B. Navathe},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {OmniFair: {A} Declarative System for Model-Agnostic Group Fairness
                  in Machine Learning},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2076--2088},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452787},
	doi = {10.1145/3448016.3452787},
	timestamp = {Fri, 23 May 2025 21:08:46 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/ZhangCAN21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Machine learning (ML) is increasingly being used to make decisions in our society. ML models, however, can be unfair to certain demographic groups (e.g., African Americans or females) according to various fairness metrics. Existing techniques for producing fair ML models either are limited to the type of fairness constraints they can handle (e.g., preprocessing) or require nontrivial modifications to downstream ML training algorithms (e.g., in-processing). We propose a declarative system OmniFair for supporting group fairness in ML. OmniFair features a declarative interface for users to specify desired group fairness constraints and supports all commonly used group fairness notions, including statistical parity, equalized odds, and predictive parity. OmniFair is also model-agnostic in the sense that it does not require modifications to a chosen ML algorithm. OmniFair also supports enforcing multiple user declared fairness constraints simultaneously while most previous techniques cannot. The algorithms in OmniFair maximize model accuracy while meeting the specified fairness constraints, and their efficiency is optimized based on the theoretically provable monotonicity property regarding the trade-off between accuracy and fairness that is unique to our system. We conduct experiments on commonly used datasets that exhibit bias against minority groups in the fairness literature. We show that OmniFair is more versatile than existing algorithmic fairness approaches in terms of both supported fairness constraints and downstream ML models. OmniFair reduces the accuracy loss by up to 94.8% compared with the second best method. OmniFair also achieves similar running time to preprocessing methods, and is up to 270x faster than in-processing methods.}
}


@inproceedings{DBLP:conf/sigmod/0001MHGZHMM21,
	author = {Shuhao Zhang and
                  Yancan Mao and
                  Jiong He and
                  Philipp M. Grulich and
                  Steffen Zeuch and
                  Bingsheng He and
                  Richard T. B. Ma and
                  Volker Markl},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Parallelizing Intra-Window Join on Multicores: An Experimental Study},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2089--2101},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452793},
	doi = {10.1145/3448016.3452793},
	timestamp = {Sun, 19 Jan 2025 13:27:32 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/0001MHGZHMM21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The intra-window join (IaWJ), i.e., joining two input streams over a single window, is a core operation in modern stream processing applications. This paper presents the first comprehensive study on parallelizing the IaWJ on modern multicore architectures. In particular, we classify IaWJ algorithms into lazy and eager execution approaches. For each approach, there are further design aspects to consider, including different join methods and partitioning schemes, leading to a large design space. Our results show that none of the algorithms always performs the best, and the choice of the most performant algorithm depends on: (i) workload characteristics, (ii) application requirements, and (iii) hardware architectures. Based on the evaluation results, we propose a decision tree that can guide the selection of an appropriate algorithm.}
}


@inproceedings{DBLP:conf/sigmod/ZhangWCJT0Z021,
	author = {Xinyi Zhang and
                  Hong Wu and
                  Zhuo Chang and
                  Shuowei Jin and
                  Jian Tan and
                  Feifei Li and
                  Tieying Zhang and
                  Bin Cui},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {ResTune: Resource Oriented Tuning Boosted by Meta-Learning for Cloud
                  Databases},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2102--2114},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457291},
	doi = {10.1145/3448016.3457291},
	timestamp = {Thu, 20 Mar 2025 20:54:44 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/ZhangWCJT0Z021.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Modern database management systems (DBMS) contain tens to hundreds of critical performance tuning knobs that determine the system runtime behaviors. To reduce the total cost of ownership, cloud database providers put in drastic effort to automatically optimize the resource utilization by tuning these knobs. There are two challenges. First, the tuning system should always abide by the service level agreement (SLA) while optimizing the resource utilization, which imposes strict constrains on the tuning process. Second, the tuning time should be reasonably acceptable since time-consuming tuning is not practical for production and online troubleshooting. In this paper, we design ResTune to automatically optimize the resource utilization without violating SLA constraints on the throughput and latency requirements. ResTune leverages the tuning experience from the history tasks and transfers the accumulated knowledge to accelerate the tuning process of the new tasks. The prior knowledge is represented from historical tuning tasks through an ensemble model. The model learns the similarity between the historical workloads and the target, which significantly reduces the tuning time by a meta-learning based approach. ResTune can efficiently handle different workloads and various hardware environments. We perform evaluations using benchmarks and real world workloads on different types of resources. The results show that, compared with the manually tuned configurations, ResTune reduces 65%, 87%, 39% of CPU utilization, I/O and memory on average, respectively. Compared with the state-of-the-art methods, ResTune finds better configurations with up to ~18x speedups.}
}


@inproceedings{DBLP:conf/sigmod/ZhangLBZJ21,
	author = {Yipeng Zhang and
                  Yuchen Li and
                  Zhifeng Bao and
                  Baihua Zheng and
                  H. V. Jagadish},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Minimizing the Regret of an Influence Provider},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2115--2127},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457257},
	doi = {10.1145/3448016.3457257},
	timestamp = {Sun, 19 Jan 2025 13:27:21 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/ZhangLBZJ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Influence maximization has been studied extensively from the perspective of the influencer. However, the influencer typically purchases influence from a provider, for example in the form of purchased advertising. In this paper, we study the problem from the perspective of the influence provider. Specifically, we focus on influence providers who sell Out-of-Home (OOH) advertising on billboards. Given a set of requests from influencers, how should an influence provider allocate resources to minimize regret, whether due to forgone revenue from influencers whose needs were not met or due to over-provisioning of resources to meet the needs of influencers? We formalize this as the \\underlineM inimizing \\underlineR egret for the \\underlineO OH \\underlineA dvertising \\underlineM arket problem (\\problem). We show that \\problem is both NP-hard and NP-hard to approximate within any constant factor. The regret function is neither monotone nor submodular, which renders any straightforward greedy approach ineffective. Therefore, we propose a randomized local search framework with two neighborhood search strategies, and prove that one of them ensures an approximation factor to a dual problem of \\problem. Experiments on real-world user movement and billboard datasets in New York City and Singapore show that on average our methods outperform the baselines in effectiveness by five times.}
}


@inproceedings{DBLP:conf/sigmod/0019ANNW21,
	author = {Bo Zhao and
                  Han van der Aa and
                  Thanh Tam Nguyen and
                  Quoc Viet Hung Nguyen and
                  Matthias Weidlich},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {{EIRES:} Efficient Integration of Remote Data in Event Stream Processing},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2128--2141},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457304},
	doi = {10.1145/3448016.3457304},
	timestamp = {Sun, 06 Oct 2024 21:14:18 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/0019ANNW21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {To support reactive and predictive applications, complex event processing (CEP) systems detect patterns in event streams based on predefined queries. To determine the events that constitute a query match, their payload data may need to be assessed together with data from remote sources. Such dependencies are problematic, since waiting for remote data to be fetched interrupts the processing of the stream. Yet, without event selection based on remote data, the query state to maintain may grow exponentially. In either case, the performance of the CEP system degrades drastically. To tackle these issues, we present EIRES, a framework for efficient integration of static data from remote sources in CEP. It employs a cost-model to determine when to fetch certain remote data elements and how long to keep them in a cache for future use. EIRES combines strategies for (i) prefetching that queries remote data based on anticipated use and (ii) lazy evaluation that postpones the event selection based on remote data without interrupting the stream processing. Our experiments indicate that the combination of these strategies improves the latency of query evaluation by up to 3,725x for synthetic data and 47x for real-world data.}
}


@inproceedings{DBLP:conf/sigmod/ZhaoYZLR21,
	author = {Kangfei Zhao and
                  Jeffrey Xu Yu and
                  Hao Zhang and
                  Qiyan Li and
                  Yu Rong},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {A Learned Sketch for Subgraph Counting},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2142--2155},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457289},
	doi = {10.1145/3448016.3457289},
	timestamp = {Thu, 30 Jan 2025 17:05:03 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/ZhaoYZLR21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Subgraph counting, as a fundamental problem in network analysis, is to count the number of subgraphs in a data graph that match a given query graph by either homomorphism or subgraph isomorphism. The importance of subgraph counting derives from the fact that it provides insights of a large graph, in particular a labeled graph, when a collection of query graphs with different sizes and labels are issued. The problem of counting is challenging. On one hand, exact counting by enumerating subgraphs is NP-hard. % On the other hand, approximate counting by subgraph isomorphism can only support 3/5-node query graphs over unlabeled graphs. % Another way for subgraph counting is to specify it as an \\SQL query and estimate the cardinality of the query in \\rdbm. Existing approaches for cardinality estimation can only support subgraph counting by homomorphism up to some extent, as it is difficult to deal with sampling failure when a query graph becomes large. A question that arises is if subgraph counting can be supported by machine learning (ML) and deep learning (DL). The existing DL approach for subgraph isomorphism can only support small data graphs. The ML/DL approaches proposed in \\rdbm context for approximate query processing and cardinality estimation cannot be used, as subgraph counting is to do complex self-joins over one relation, whereas existing approaches focus on multiple relations. In this paper, we propose an Active Learned Sketch for Subgraph Counting (\\ALSS) with two main components: a sketch learned (ŁSS) and an active learner (\\AL). The sketch is learned by a neural network regression model, and the active learner is to perform model updates based on new arrival test query graphs. % We conduct extensive experimental studies to confirm the effectiveness and efficiency of \\ALSS using large real labeled graphs. Moreover, we show that \\ALSS can assist query optimizers to find a better query plan for complex multi-way self-joins.}
}


@inproceedings{DBLP:conf/sigmod/Zheng0HNOG21,
	author = {Kaiping Zheng and
                  Gang Chen and
                  Melanie Herschel and
                  Kee Yuan Ngiam and
                  Beng Chin Ooi and
                  Jinyang Gao},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {{PACE:} Learning Effective Task Decomposition for Human-in-the-loop
                  Healthcare Delivery},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2156--2168},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457281},
	doi = {10.1145/3448016.3457281},
	timestamp = {Sun, 06 Oct 2024 21:14:20 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/Zheng0HNOG21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Human-in-the-loop data analysis involves both machine learning models and humans in analytic tasks. In healthcare applications, human-in-the-loop data analysis is crucial in that the model can handle "easy" tasks and hand over "hard" ones to medical experts for assistance and medical judgment, where easy tasks are the ones for which the model can provide high accuracy and hard tasks vice versa. In this process, how to decompose tasks in an effective manner is an important stage. To achieve task decomposition, classification with a reject option is a solution. However, existing studies either directly implement a reject option or dive into the theoretical details of the rejection mechanism. Different from such studies, we aim to optimize general classifiers with a reject option and hence, optimize task decomposition for healthcare applications. To this end, we first introduce task decomposition for healthcare applications, which is a crucial stage in human-in-the-loop healthcare delivery. We then devise a framework PACE to learn effective task decomposition concentrating on delivering high performance on the easy tasks. PACE is two-level: on the macro level, PACE employs the Self-Paced Learning method to select easy tasks for each training iteration; on the micro level, PACE adapts the weights of selected tasks through its weighted loss revision strategy. Experimental results in two real-world healthcare datasets show that PACE outperforms baselines in terms of their performance on the easy tasks which are expected to be solved by the learning model.}
}


@inproceedings{DBLP:conf/sigmod/0010ANHW21,
	author = {Qi Zhou and
                  Joy Arulraj and
                  Shamkant B. Navathe and
                  William Harris and
                  Jinpeng Wu},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {{SIA:} Optimizing Queries using Learned Predicates},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2169--2181},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457262},
	doi = {10.1145/3448016.3457262},
	timestamp = {Mon, 21 Jun 2021 11:48:44 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/0010ANHW21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Predicate-centric rules for rewriting queries is a key technique in optimizing queries. These include pushing down the predicate below the join and aggregation operators, or optimizing the order of evaluating predicates. However, many of these rules are only applicable when the predicate uses a certain set of columns. For example, to move the predicate below the join operator, the predicate must only use columns from one of the joined tables. By generating a predicate that satisfies these column constraints and preserves the semantics of the original query, the optimizer may leverage additional predicate-centric rules that were not applicable before. Researchers have proposed syntax-driven rewrite rules and machine learning algorithms for inferring such predicates. However, these techniques suffer from two limitations. First, they do not let the optimizer constrain the set of columns that may be used in the learned predicate. Second, machine learning algorithms do not guarantee that the learned predicate preserves semantics. In this paper, we present SIA, a system for learning predicates while being guided by counter-examples and a verification technique, that addresses these limitations. The key idea is to leverage satisfiability modulo theories to generate counter-examples and use them to iteratively learn a valid, optimal predicate. We formalize this problem by proving the key properties of synthesized predicates. We implement our approach in SIA and evaluate its efficacy and efficiency. We demonstrate that it synthesizes a larger set of valid predicates compared to prior approaches. On a collection of 200 queries derived from the TPC-H benchmark, SIA successfully rewrites 114 queries with learned predicates. 66 of these rewritten queries exhibit more than 2X speed up.}
}


@inproceedings{DBLP:conf/sigmod/ZhouCPWM021,
	author = {Wenchao Zhou and
                  Yifan Cai and
                  Yanqing Peng and
                  Sheng Wang and
                  Ke Ma and
                  Feifei Li},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {VeriDB: An SGX-based Verifiable Database},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2182--2194},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457308},
	doi = {10.1145/3448016.3457308},
	timestamp = {Sun, 19 Jan 2025 13:27:22 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/ZhouCPWM021.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The emergence of trusted hardwares (such as Intel SGX) provides a new avenue towards verifiable database. Such trust hardwares act as an additional trust anchor, allowing great simplification and, in turn, performance improvement in the design of verifiable databases. In this paper, we introduce the design and implementation of VeriDB, an SGX-based verifiable database that supports relational tables, multiple access methods and general SQL queries. Built on top of write-read consistent memory, VeriDB provides verifiable page-structured storage, where results of storage operations can be efficiently verified with low, constant overhead. VeriDB further provides verifiable query execution that supports general SQL queries. Through a series of evaluation using practical workload, we demonstrate that VeriDB incurs low overhead for achieving verifiability: an overhead of 1-2 microseconds for read/write operations, and a 9% - 39% overhead for representative analytical workloads.}
}


@inproceedings{DBLP:conf/sigmod/ZhouAPC21,
	author = {Xinjing Zhou and
                  Joy Arulraj and
                  Andrew Pavlo and
                  David E. Cohen},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Spitfire: {A} Three-Tier Buffer Manager for Volatile and Non-Volatile
                  Memory},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2195--2207},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452819},
	doi = {10.1145/3448016.3452819},
	timestamp = {Sun, 19 Jan 2025 13:27:29 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/ZhouAPC21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The design of the buffer manager in database management systems (DBMSs) is influenced by the performance characteristics of volatile memory (i.e., DRAM) and non-volatile storage (e.g., SSD). The key design assumptions have been that the data must be migrated to DRAM for the DBMS to operate on it and that storage is orders of magnitude slower than DRAM. But the arrival of new non-volatile memory (NVM) technologies that are nearly as fast as DRAM invalidates these previous assumptions. Researchers have recently designed Hymem, a novel buffer manager for a three-tier storage hierarchy comprising of DRAM, NVM, and SSD. Hymem supports cache-line-grained loading and an NVM-aware data migration policy. While these optimizations improve its throughput, Hymem suffers from two limitations. First, it is a single-threaded buffer manager. Second, it is evaluated on an NVM emulation platform. These limitations constrain the utility of the insights obtained using Hymem. In this paper, we present Spitfire, a multi-threaded, three-tier buffer manager that is evaluated on Optane Persistent Memory Modules, an NVM technology that is now being shipped by Intel. We introduce a general framework for reasoning about data migration in a multi-tier storage hierarchy. We illustrate the limitations of the optimizations used in Hymem on Optane and then discuss how Spitfire circumvents them. We demonstrate that the data migration policy has to be tailored based on the characteristics of the devices and the workload. Given this, we present a machine learning technique for automatically adapting the policy for an arbitrary workload and storage hierarchy. Our experiments show that Spitfire works well across different workloads and storage hierarchies.}
}


@inproceedings{DBLP:conf/sigmod/Cui0ZCLO21,
	author = {Can Cui and
                  Wei Wang and
                  Meihui Zhang and
                  Gang Chen and
                  Zhaojing Luo and
                  Beng Chin Ooi},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {AlphaEvolve: {A} Learning Framework to Discover Novel Alphas in Quantitative
                  Investment},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2208--2216},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457324},
	doi = {10.1145/3448016.3457324},
	timestamp = {Mon, 03 Mar 2025 21:21:49 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/Cui0ZCLO21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Alphas are stock prediction models capturing trading signals in a stock market. A set of effective alphas can generate weakly correlated high returns to diversify the risk. Existing alphas can be categorized into two classes: Formulaic alphas are simple algebraic expressions of scalar features, and thus can generalize well and be mined into a weakly correlated set. Machine learning alphas are data-driven models over vector and matrix features. They are more predictive than formulaic alphas, but are too complex to mine into a weakly correlated set. In this paper, we introduce a new class of alphas to model scalar, vector, and matrix features which possess the strengths of these two existing classes. The new alphas predict returns with high accuracy and can be mined into a weakly correlated set. In addition, we propose a novel alpha mining framework based on AutoML, called AlphaEvolve, to generate the new alphas. To this end, we first propose operators for generating the new alphas and selectively injecting relational domain knowledge to model the relations between stocks. We then accelerate the alpha mining by proposing a pruning technique for redundant alphas. Experiments show that AlphaEvolve can evolve initial alphas into the new alphas with high returns and weak correlations.}
}


@inproceedings{DBLP:conf/sigmod/GalhotraGT21,
	author = {Sainyam Galhotra and
                  Behzad Golshan and
                  Wang{-}Chiew Tan},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Adaptive Rule Discovery for Labeling Text Data},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2217--2225},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457334},
	doi = {10.1145/3448016.3457334},
	timestamp = {Mon, 21 Jun 2021 11:48:44 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/GalhotraGT21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Creating and collecting labeled data is one of the major bottlenecks in machine learning pipelines and the emergence of automated feature generation techniques such as deep learning, which typically requires a lot of training data, has further exacerbated the problem. While weak-supervision techniques have circumvented this bottleneck, existing frameworks either require users to write a set of diverse, high-quality rules to label data (e.g., Snorkel), or require a labeled subset of the data to automatically mine rules (e.g., Snuba). The process of manually writing rules can be tedious and time consuming. At the same time, creating a labeled subset of the data can be costly and even infeasible in imbalanced settings. To address these shortcomings, we present DARWIN, an interactive system designed to alleviate the task of writing rules for labeling text data in weakly-supervised settings. Given an initial labeling rule, DARWIN automatically generates a set of candidate rules for the labeling task at hand, and utilizes the annotator's feedback to adapt the candidate rules. We describe how DARWIN is scalable and versatile. It can operate over large text corpora (i.e., more than 1 million sentences) and supports a wide range of labeling functions (i.e., any function that can be specified using a context free grammar). Finally, we demonstrate with a suite of experiments over five real-world datasets that DARWIN enables annotators to generate weakly-supervised labels efficiently and with a small cost. In fact, our experiments show that rules discovered by DARWIN on average identify 40% more positive instances compared to Snuba even when it is provided with 1000 labeled instances.}
}


@inproceedings{DBLP:conf/sigmod/GuptaYCKEMTS21,
	author = {Gaurav Gupta and
                  Minghao Yan and
                  Benjamin Coleman and
                  Bryce Kille and
                  Ryan A. Leo Elworth and
                  Tharun Medini and
                  Todd J. Treangen and
                  Anshumali Shrivastava},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Fast Processing and Querying of 170TB of Genomics Data via a Repeated
                  And Merged BloOm Filter {(RAMBO)}},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2226--2234},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457333},
	doi = {10.1145/3448016.3457333},
	timestamp = {Mon, 21 Jun 2021 11:48:44 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/GuptaYCKEMTS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {DNA sequencing, especially of microbial genomes and metagenomes, has been at the core of recent research advances in large-scale comparative genomics. The data deluge has resulted in exponential growth in genomic datasets over the past years and has shown no sign of slowing down. Several recent attempts have been made to tame the computational burden of sequence search on these terabyte and petabyte-scale datasets, including raw reads and assembled genomes. However, no known implementation provides both fast query and construction time, keeps the low false-positive requirement, and offers cheap storage of the data structure. We propose a data structure for search called RAMBO (Repeated And Merged BloOm Filter) which is significantly faster in query time than state-of-the-art genome indexing methods- COBS (Compact bit-sliced signature index), Sequence Bloom Trees, HowDeSBT, and SSBT. Furthermore, it supports insertion and query process parallelism, cheap updates for streaming inputs, has a zero false-negative rate, a low false-positive rate, and a small index size. RAMBO converts the search problem into set membership testing among K documents. Interestingly, it is a count-min sketch type arrangement of a membership testing utility (Bloom Filter in our case). The simplicity of the algorithm and embarrassingly parallel architecture allows us to stream and index a 170TB whole-genome sequence dataset in a mere 9 hours on a cluster of 100 nodes while competing methods require weeks.}
}


@inproceedings{DBLP:conf/sigmod/HasaniTK021,
	author = {Sona Hasani and
                  Saravanan Thirumuruganathan and
                  Nick Koudas and
                  Gautam Das},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Shahin: Faster Algorithms for Generating Explanations for Multiple
                  Predictions},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2235--2243},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457332},
	doi = {10.1145/3448016.3457332},
	timestamp = {Mon, 05 Feb 2024 20:26:56 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/HasaniTK021.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Machine learning (ML) models have achieved widespread adoption in the last few years. Generating concise and accurate explanations often increases user trust and understanding of the model prediction. Usually, the implementations of popular explanation algorithms are highly optimized for a single prediction. In practice, explanations often have to be generated in a batch for multiple predictions at a time. To the best of our knowledge, there has been no work for efficiently generating explanations for more than one prediction. While one could use multiple machines to generate explanations in parallel, this approach is sub-optimal as it does not leverage higher-level optimizations that are available in a batch setting. We propose a principled and lightweight approach for identifying redundant computations and several effective heuristics for dramatically speeding up explanation generation. Our techniques are general and could be applied to a wide variety of perturbation based explanation algorithms. We demonstrate this over a diverse set of algorithms including, LIME, Anchor, and SHAP. Our empirical experiments show that our methods impose very little overhead and require minimal modification to the explanation algorithms. They achieve significant speedup over baseline approaches that generate explanations in a sequential manner.}
}


@inproceedings{DBLP:conf/sigmod/KimC21,
	author = {Hakbin Kim and
                  Dong{-}Wan Choi},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Pool of Experts: Realtime Querying Specialized Knowledge in Massive
                  Neural Networks},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2244--2252},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457326},
	doi = {10.1145/3448016.3457326},
	timestamp = {Mon, 21 Jun 2021 11:48:44 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/KimC21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In spite of the great success of deep learning technologies, training and delivery of a practically serviceable model is still a highly time-consuming process. Furthermore, a resulting model is usually too generic and heavyweight, and hence essentially goes through another expensive model compression phase to fit in a resource-limited device like embedded systems. Inspired by the fact that a machine learning task specifically requested by mobile users is often much simpler than it is supported by a massive generic model, this paper proposes a framework, called Pool of Experts (PoE), that instantly builds a lightweight and task-specific model without any training process. For a realtime model querying service, PoE first extracts a pool of primitive components, called experts, from a well-trained and sufficiently generic network by exploiting a novel conditional knowledge distillation method, and then performs our train-free knowledge consolidation to quickly combine necessary experts into a lightweight network for a target task. Thanks to this train-free property, in our thorough empirical study, PoE can build a fairly accurate yet compact model in a realtime manner, whereas it takes a few minutes per query for the other training methods to achieve a similar level of the accuracy.}
}


@inproceedings{DBLP:conf/sigmod/Liu0W0YY21,
	author = {Yinan Liu and
                  Wei Shen and
                  Yuanfei Wang and
                  Jianyong Wang and
                  Zhenglu Yang and
                  Xiaojie Yuan},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Joint Open Knowledge Base Canonicalization and Linking},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2253--2261},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452776},
	doi = {10.1145/3448016.3452776},
	timestamp = {Sun, 19 Jan 2025 13:27:28 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/Liu0W0YY21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Open Information Extraction (OIE) methods extract a large number of OIE triples (noun phrase, relation phrase, noun phrase) from text, which compose large Open Knowledge Bases (OKBs). However, noun phrases (NPs) and relation phrases (RPs) in OKBs are not canonicalized and often appear in different paraphrased textual variants, which leads to redundant and ambiguous facts. To address this problem, there are two related tasks: OKB canonicalization (i.e., convert NPs and RPs to canonicalized form) and OKB linking (i.e., link NPs and RPs with their corresponding entities and relations in a curated Knowledge Base (e.g., DBPedia). These two tasks are tightly coupled, and one task can benefit significantly from the other. However, they have been studied in isolation so far. In this paper, we explore the task of joint OKB canonicalization and linking for the first time, and propose a novel framework JOCL based on factor graph model to make them reinforce each other. JOCL is flexible enough to combine different signals from both tasks, and able to extend to fit any new signals. A thorough experimental study over two large scale OIE triple data sets shows that our framework outperforms all the baseline methods for the task of OKB canonicalization (OKB linking) in terms of average F1 (accuracy).}
}


@inproceedings{DBLP:conf/sigmod/MiaoNSYJM021,
	author = {Xupeng Miao and
                  Xiaonan Nie and
                  Yingxia Shao and
                  Zhi Yang and
                  Jiawei Jiang and
                  Lingxiao Ma and
                  Bin Cui},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Heterogeneity-Aware Distributed Machine Learning Training via Partial
                  Reduce},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2262--2270},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452773},
	doi = {10.1145/3448016.3452773},
	timestamp = {Sun, 19 Jan 2025 13:27:33 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/MiaoNSYJM021.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {All-reduce is the key communication primitive used in distributed data-parallel training due to the high performance in the homogeneous environment. However, All-reduce is sensitive to stragglers and communication delays as deep learning has been increasingly deployed on the heterogeneous environment like cloud. In this paper, we propose and analyze a novel variant of all-reduce, called partial-reduce, which provides high heterogeneity tolerance and performance by decomposing the synchronous all-reduce primitive into parallel-asynchronous partial-reduce operations. We provide theoretical guarantees, proving that partial-reduce converges to a stationary point at the similar sub-linear rate as distributed SGD. To enforce the convergence of the partial-reduce primitive, we further propose a dynamic staleness-aware distributed averaging algorithm and implement a novel group generation mechanism to prevent possible update isolation in heterogeneous environments. We build a prototype system in the real production cluster and validate its performance under different workloads. The experiments show that it is 1.21x-2x faster than other state-of-the-art baselines.}
}


@inproceedings{DBLP:conf/sigmod/PengWLBYXCRW21,
	author = {Jinglin Peng and
                  Weiyuan Wu and
                  Brandon Lockhart and
                  Song Bian and
                  Jing Nathan Yan and
                  Linghao Xu and
                  Zhixuan Chi and
                  Jeffrey M. Rzeszotarski and
                  Jiannan Wang},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {DataPrep.EDA: Task-Centric Exploratory Data Analysis for Statistical
                  Modeling in Python},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2271--2280},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457330},
	doi = {10.1145/3448016.3457330},
	timestamp = {Fri, 24 Nov 2023 11:42:46 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/PengWLBYXCRW21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Exploratory Data Analysis (EDA) is a crucial step in any data science project. However, existing Python libraries fall short in supporting data scientists to complete common EDA tasks for statistical modeling. Their API design is either too low level, which is optimized for plotting rather than EDA, or too high level, which is hard to specify more fine-grained EDA tasks. In response, we propose DataPrep.EDA, a novel task-centric EDA system in Python. DataPrep.EDA allows data scientists to declaratively specify a wide range of EDA tasks in different granularity with a single function call. We identify a number of challenges to implement DataPrep.EDA, and propose effective solutions to improve the scalability, usability, customizability of the system. In particular, we discuss some lessons learned from using Dask to build the data processing pipelines for EDA tasks and describe our approaches to accelerate the pipelines. We conduct extensive experiments to compare DataPrep.EDA with Pandas-profiling, the state-of-the-art EDA system in Python. The experiments show that DataPrep.EDA significantly outperforms Pandas-profiling in terms of both speed and user experience. DataPrep.EDA is open-sourced as an EDA component of DataPrep: https://github.com/sfu-db/dataprep.}
}


@inproceedings{DBLP:conf/sigmod/QiuD0P021,
	author = {Jiezhong Qiu and
                  Laxman Dhulipala and
                  Jie Tang and
                  Richard Peng and
                  Chi Wang},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {LightNE: {A} Lightweight Graph Processing System for Network Embedding},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2281--2289},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457329},
	doi = {10.1145/3448016.3457329},
	timestamp = {Mon, 21 Jun 2021 11:48:44 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/QiuD0P021.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We propose LightNE, a cost-effective, scalable, and high quality network embedding system that scales to graphs with hundreds of billions of edges on a single machine. In contrast to the mainstream belief that distributed architecture and GPUs are needed for large-scale network embedding with good quality, we prove that we can achieve higher quality, better scalability, lower cost and faster runtime with shared-memory, CPU-only architecture. LightNE combines two theoretically grounded embedding methods NetSMF and ProNE. We introduce the following techniques to network embedding for the first time: (1) a newly proposed downsampling method to reduce the sample complexity of NetSMF while preserving its theoretical advantages; (2) a high-performance parallel graph processing stack GBBS to achieve high memory efficiency and scalability; (3) sparse parallel hash table to aggregate and maintain the matrix sparsifier in memory; and (4) Intel MKL for efficient randomized SVD and spectral propagation.}
}


@inproceedings{DBLP:conf/sigmod/Sagadeeva021,
	author = {Svetlana Sagadeeva and
                  Matthias Boehm},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {SliceLine: Fast, Linear-Algebra-based Slice Finding for {ML} Model
                  Debugging},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2290--2299},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457323},
	doi = {10.1145/3448016.3457323},
	timestamp = {Mon, 21 Jun 2021 11:48:44 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/Sagadeeva021.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Slice finding---a recent work on debugging machine learning (ML) models---aims to find the top-K data slices (e.g., conjunctions of predicates such as gender female and degree PhD), where a trained model performs significantly worse than on the entire training/test data. These slices may be used to acquire more data for the problematic subset, add rules, or otherwise improve the model. In contrast to decision trees, the general slice finding problem allows for overlapping slices. The resulting search space is huge as it covers all subsets of features and their distinct values. Hence, existing work primarily relies on heuristics and focuses on small datasets that fit in memory of a single node. In this paper, we address these scalability limitations of slice finding in a holistic manner from both algorithmic and system perspectives. We leverage monotonicity properties of slice sizes, errors and resulting scores to facilitate effective pruning. Additionally, we present an elegant linear-algebra-based enumeration algorithm, which allows for fast enumeration and automatic parallelization on top of existing ML systems. Experiments with different real-world regression and classification datasets show that effective pruning and efficient sparse linear algebra renders exact enumeration feasible, even for datasets with many features, correlations, and data sizes beyond single node memory.}
}


@inproceedings{DBLP:conf/sigmod/Thirumuruganathan21,
	author = {Saravanan Thirumuruganathan and
                  Michael Simpson and
                  Laks V. S. Lakshmanan},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {To Intervene or Not To Intervene: Cost based Intervention for Combating
                  Fake News},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2300--2309},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452778},
	doi = {10.1145/3448016.3452778},
	timestamp = {Thu, 09 Mar 2023 13:30:01 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/Thirumuruganathan21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Social media platforms provide valuable and powerful means with which users can share content, comment, and communicate. They also suffer from abuse through the dissemination of fake news and misinformation. While a fair amount of work has been done on detecting fake news, on the complementary problem of limiting its propagation, progress has been modest. Once an item is detected as fake, a social media company can intervene on the item and take an appropriate action, including hard intervention (e.g., removing an account) and soft intervention (e.g., labeling the item as "suspicious"). Given that fake news detectors are not 100% reliable, we study the problem of developing a cost aware intervention policy which decides whether to intervene based on the truthiness and popularity of the item. Our solution, Solomon, consists of three modular components - truthiness estimation, popularity estimation (with and without intervention), and intervention policy. Our extensive experiments on real and fake news from multiple domains show that Solomon can perform effective intervention.}
}


@inproceedings{DBLP:conf/sigmod/Vretinaris0EQO21,
	author = {Alina Vretinaris and
                  Chuan Lei and
                  Vasilis Efthymiou and
                  Xiao Qin and
                  Fatma {\"{O}}zcan},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Medical Entity Disambiguation Using Graph Neural Networks},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2310--2318},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457328},
	doi = {10.1145/3448016.3457328},
	timestamp = {Sun, 02 Oct 2022 16:15:22 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/Vretinaris0EQO21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Medical knowledge bases (KBs), distilled from biomedical literature and regulatory actions, are expected to provide high-quality information to facilitate clinical decision making. Entity disambiguation (also referred to as entity linking) is considered as an essential task in unlocking the wealth of such medical KBs. However, existing medical entity disambiguation methods are not adequate due to word discrepancies between the entities in the KB and the text snippets in the source documents. Recently, graph neural networks (GNNs) have proven to be very effective and provide state-of-the-art results for many real-world applications with graph-structured data. In this paper, we introduce ED-GNN based on three representative GNNs (GraphSAGE, R-GCN, and MAGNN) for medical entity disambiguation. We develop two optimization techniques to fine-tune and improve ED-GNN. First, we introduce a novel strategy to represent entities that are mentioned in text snippets as a query graph. Second, we design an effective negative sampling strategy that identifies hard negative samples to improve the model's disambiguation capability. Compared to the best performing state-of-the-art solutions, our ED-GNN offers an average improvement of 7.3% in terms of F1 score on five real-world datasets.}
}


@inproceedings{DBLP:conf/sigmod/WangXQ0O00I21,
	author = {Yaoshu Wang and
                  Chuan Xiao and
                  Jianbin Qin and
                  Rui Mao and
                  Makoto Onizuka and
                  Wei Wang and
                  Rui Zhang and
                  Yoshiharu Ishikawa},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Consistent and Flexible Selectivity Estimation for High-Dimensional
                  Data},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2319--2327},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452772},
	doi = {10.1145/3448016.3452772},
	timestamp = {Mon, 03 Mar 2025 21:21:50 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/WangXQ0O00I21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Selectivity estimation aims at estimating the number of database objects that satisfy a selection criterion. Answering this problem accurately and efficiently is essential to many applications, such as density estimation, outlier detection, query optimization, and data integration. The estimation problem is especially challenging for large-scale high-dimensional data due to the curse of dimensionality, the large variance of selectivity across different queries, and the need to make the estimator consistent (i.e., the selectivity is non-decreasing in the threshold). We propose a new deep learning-based model that learns a query-dependent piecewise linear function as selectivity estimator, which is flexible to fit the selectivity curve of any distance function and query object, while guaranteeing that the output is non-decreasing in the threshold. To improve the accuracy for large datasets, we propose to partition the dataset into multiple disjoint subsets and build a local model on each of them. We perform experiments on real datasets and show that the proposed model consistently outperforms state-of-the-art models in accuracy in an efficient way and is useful for real applications.}
}


@inproceedings{DBLP:conf/sigmod/WenH0ZKX21,
	author = {Qingsong Wen and
                  Kai He and
                  Liang Sun and
                  Yingying Zhang and
                  Min Ke and
                  Huan Xu},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {RobustPeriod: Robust Time-Frequency Mining for Multiple Periodicity
                  Detection},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2328--2337},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452779},
	doi = {10.1145/3448016.3452779},
	timestamp = {Sun, 06 Oct 2024 21:14:20 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/WenH0ZKX21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Periodicity detection is a crucial step in time series tasks, including monitoring and forecasting of metrics in many areas, such as IoT applications and self-driving database management system. In many of these applications, multiple periodic components exist and are often interlaced with each other. Such dynamic and complicated periodic patterns make the accurate periodicity detection difficult. In addition, other components in the time series, such as trend, outliers and noises, also pose additional challenges for accurate periodicity detection. In this paper, we propose a robust and general framework for multiple periodicity detection. Our algorithm applies maximal overlap discrete wavelet transform to transform the time series into multiple temporal-frequency scales such that different periodic components can be isolated. We rank them by wavelet variance, and then at each scale detect single periodicity by our proposed Huber-periodogram and Huber-ACF robustly. We rigorously prove the theoretical properties of Huber-periodogram and justify the use of Fisher's test on Huber-periodogram for periodicity detection. To further refine the detected periods, we compute unbiased autocorrelation function based on Wiener-Khinchin theorem from Huber-periodogram for improved robustness and efficiency. Experiments on synthetic and real-world datasets show that our algorithm outperforms other popular ones for both single and multiple periodicity detection.}
}


@inproceedings{DBLP:conf/sigmod/0001H21,
	author = {An Yan and
                  Bill Howe},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {EquiTensors: Learning Fair Integrations of Heterogeneous Urban Data},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2338--2347},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452777},
	doi = {10.1145/3448016.3452777},
	timestamp = {Mon, 21 Jun 2021 11:48:44 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/0001H21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Neural methods are state-of-the-art for urban prediction problems such as transportation resource demand, accident risk, crowd mobility, and public safety. Model performance can be improved by integrating exogenous features from open data repositories (e.g., weather, housing prices, traffic, etc.), but these uncurated sources are often too noisy, incomplete, and biased to use directly. We propose to learn integrated representations, called EquiTensors, from heterogeneous datasets that can be reused across a variety of tasks. We align datasets to a consistent spatio-temporal domain, then describe an unsupervised model based on convolutional denoising autoencoders to learn shared representations. We extend this core integrative model with adaptive weighting to prevent certain datasets from dominating the signal. To combat discriminatory bias, we use adversarial learning to remove correlations with a sensitive attribute (e.g., race or income). Experiments with 23 input datasets and 4 real applications show that EquiTensors could help mitigate the effects of the sensitive information embodied in the biased data. Meanwhile, applications using EquiTensors outperform models that ignore exogenous features and are competitive with "oracle" models that use hand-selected datasets.}
}


@inproceedings{DBLP:conf/sigmod/YeLHLS21,
	author = {Chang Ye and
                  Yuchen Li and
                  Bingsheng He and
                  Zhao Li and
                  Jianling Sun},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {GPU-Accelerated Graph Label Propagation for Real-Time Fraud Detection},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2348--2356},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452774},
	doi = {10.1145/3448016.3452774},
	timestamp = {Fri, 02 Sep 2022 08:42:24 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/YeLHLS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Fraud detection is a pressing challenge for most financial and commercial platforms. In this paper, we study the processing pipeline of fraud detection in a large e-commerce platform of TaoBao. Graph label propagation (LP) is a core component in this pipeline to detect suspicious clusters from the user-interaction graph.Furthermore, the run-time of the LP component occupies 75% overhead of TaoBao's automated detection pipeline. To enable real-time fraud detection, we propose a GPU-based framework, called GLP, to support large-scale LP workloads in enterprises.We have identified two key challenges when integrating GPU acceleration into TaoBao's data processing pipeline: (1)programmability for evolving fraud detection logics; (2)demand for real-time performance. Motivated by these challenges, we offer a set of expressive APIs that data engineers can customize and deploy efficient LP algorithms on GPUs with ease. We propose novel GPU-centric optimizations by leveraging the community as well as power-law properties of large graphs. Extensive experiments have confirmed the effectiveness of our proposed optimizations. With a single GPU, GLP supports a real billion-scale graph workload from the fraud detection pipeline of TaoBao and achieves 8.2x speedup to the current in-house distributed solution running on high-end multicore machines.}
}


@inproceedings{DBLP:conf/sigmod/YongH0T21,
	author = {Quinton Yong and
                  Mahdi Hajiabadi and
                  Venkatesh Srinivasan and
                  Alex Thomo},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Efficient Graph Summarization using Weighted {LSH} at Billion-Scale},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2357--2365},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457331},
	doi = {10.1145/3448016.3457331},
	timestamp = {Mon, 21 Jun 2021 11:48:44 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/YongH0T21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Summarizing graphs is of paramount importance due to diverse applications of large-scale graph analysis. A popular family of summarization methods is the group-based approach. The general idea consists of merging nodes of the original graph into supernodes of the summary graph, encoding original edges into superedges/correction set edges, and dropping certain superedges or correction set edges (for lossy summarization). The current state of the art has several steps in its computation that are serious bottlenecks in terms of running time and scalability. In this work, we propose algorithm LDME, a correction set based graph summarization algorithm that produces compact output representations in a fast and scalable manner. To achieve this, we introduce (1) weighted locality sensitive hashing to drastically reduce the number comparisons required to find good node merges, (2) an efficient way to compute the best quality merges that produces more compact outputs, and (3) a new sort-based encoding algorithm that is faster and more robust. More interestingly, our algorithm provides performance tuning settings to allow the option of trading compression for running time. On high compression settings, LDME achieves compression equal to or better than the state of the art with up to 53x speedup in running time. On high speed settings, LDME achieves up to two orders of magnitude speedup with only slightly lower compression.}
}


@inproceedings{DBLP:conf/sigmod/ZhangSLCY021,
	author = {Wentao Zhang and
                  Yu Shen and
                  Yang Li and
                  Lei Chen and
                  Zhi Yang and
                  Bin Cui},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {{ALG:} Fast and Accurate Active Learning Framework for Graph Convolutional
                  Networks},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2366--2374},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457325},
	doi = {10.1145/3448016.3457325},
	timestamp = {Tue, 11 Feb 2025 20:50:07 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/ZhangSLCY021.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graph Convolutional Networks (GCNs) have become state-of-the-art methods in many supervised and semi-supervised graph representation learning scenarios. In order to achieve satisfactory performance, GCNs require a sufficient amount of labeled data. However, in real-world scenarios, labeled data is often expensive to obtain. Therefore, we propose ALG, a novel Active Learning framework for GCNs, which employs domain-specific intelligence to achieve much higher performance and efficiency compared to the generic AL frameworks. First, by decoupling GCN models, ALG serves as an effective and efficient AL framework for measuring and combining node representativeness and informativeness. Second, by exploiting the characteristic of the reception field in GCNs, ALG considers both the importance and correlation of nodes by proposing a new node selection metric that maximizes the effective reception field (ERF). We prove that this ERF maximization problem is NP-hard and provide an efficient algorithm accompanied with a provable approximation guarantee. The empirical studies on four public datasets demonstrate that ALG can significantly improve both the performance and efficiency of active learning for GCNs.}
}


@inproceedings{DBLP:conf/sigmod/ZhongYLT0021,
	author = {Zheng Zhong and
                  Shen Yan and
                  Zikun Li and
                  Decheng Tan and
                  Tong Yang and
                  Bin Cui},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {BurstSketch: Finding Bursts in Data Streams},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2375--2383},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452775},
	doi = {10.1145/3448016.3452775},
	timestamp = {Sat, 09 Apr 2022 12:40:53 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/ZhongYLT0021.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Burst is a common pattern in data streams which is characterized by a sudden increase in terms of arrival rate followed by a sudden decrease. Burst detection has attracted extensive attention from the research community. In this paper, we propose a novel sketch, namely BurstSketch, to detect bursts accurately in real time. BurstSketch first uses the technique Running Track to select potential burst items efficiently, and then monitors the potential burst items and capture the key features of burst pattern by a technique called Snapshotting. Experimental results show that our sketch achieves a 1.75 times higher recall rate than the strawman solution.}
}


@inproceedings{DBLP:conf/sigmod/BessaCRSSDF21,
	author = {Aline Bessa and
                  Sonia Castelo and
                  R{\'{e}}mi Rampin and
                  A{\'{e}}cio S. R. Santos and
                  Michael Shoemate and
                  Vito D'Orazio and
                  Juliana Freire},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {An Ecosystem of Applications for Modeling Political Violence},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2384--2388},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457235},
	doi = {10.1145/3448016.3457235},
	timestamp = {Sat, 30 Sep 2023 09:56:32 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/BessaCRSSDF21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Conflict researchers face many challenges, including (1) how to model conflicts, (2) how to measure them, (3) how to manage their spatio-temporal character, and (4) how to handle a potential abundance of information and explanation. In this paper, we describe an ecosystem of tools designed for use by subject matter experts that addresses these challenges. Three case studies show workflows that are facilitated by this ecosystem.}
}


@inproceedings{DBLP:conf/sigmod/PengXWHXC21,
	author = {Zhe Peng and
                  Cheng Xu and
                  Haixin Wang and
                  Jinbin Huang and
                  Jianliang Xu and
                  Xiaowen Chu},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {P\({}^{\mbox{2}}\)B-Trace: Privacy-Preserving Blockchain-based Contact
                  Tracing to Combat Pandemics},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2389--2393},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3459237},
	doi = {10.1145/3448016.3459237},
	timestamp = {Tue, 01 Apr 2025 19:09:25 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/PengXWHXC21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The eruption of a pandemic, such as COVID-19, can cause an unprecedented global crisis. Contact tracing, as a pillar of communicable disease control in public health for decades, has shown its effectiveness on pandemic control. Despite intensive research on contact tracing, existing schemes are vulnerable to attacks and can hardly simultaneously meet the requirements of data integrity and user privacy. The design of a privacy-preserving contact tracing framework to ensure the integrity of the tracing procedure has not been sufficiently studied and remains a challenge. In this paper, we propose P2B-Trace, a privacy-preserving contact tracing initiative based on blockchain. First, we design a decentralized architecture with blockchain to record an authenticated data structure of the user's contact records, which prevents the user from intentionally modifying his local records afterward. Second, we develop a zero-knowledge proximity verification scheme to further verify the user's proximity claim while protecting user privacy. We implement P2B-Trace and conduct experiments to evaluate the cost of privacy-preserving tracing integrity verification. The evaluation results demonstrate the effectiveness of our proposed system.}
}


@inproceedings{DBLP:conf/sigmod/RavindraG21,
	author = {Vikram Ravindra and
                  Ananth Grama},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {De-anonymization Attacks on Neuroimaging Datasets},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2394--2398},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457234},
	doi = {10.1145/3448016.3457234},
	timestamp = {Mon, 21 Jun 2021 11:48:44 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/RavindraG21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Advances in imaging technologies, combined with inexpensive storage, have led to an explosion in the volume of publicly available neuroimaging datasets. Effective analyses of these images hold the potential for uncovering mechanisms that govern functioning of the human brain, and understanding various neurological diseases and disorders. The potential significance of these studies notwithstanding, a growing concern relates to the protection of privacy and confidentiality of subjects who participate in these studies. In this paper, we present a de-anonymization attack rooted in the innate uniqueness of the structure and function of the human brain. We show that the attack reveals not only the identity of an individual, but also the efficacy with which they performing cognitive tasks. Our attack relies on novel matrix analyses techniques that are used to extract discriminating features in neuroimages. These features correspond to individual-specific signatures that can be matched across datasets for highly accurate identification. We present data preprocessing, signature extraction, and matching techniques that are computationally inexpensive, and can scale to large datasets. We characterize the efficacy of our de-anonymization attacks on publicly available databases. Finally, we discuss implications of the attack and challenges associated with defending against such attacks.}
}


@inproceedings{DBLP:conf/sigmod/Zalipynis21,
	author = {Ramon Antonio Rodriges Zalipynis},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Convergence of Array {DBMS} and Cellular Automata: {A} Road Traffic
                  Simulation Case},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2399--2403},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3458457},
	doi = {10.1145/3448016.3458457},
	timestamp = {Sat, 09 Apr 2022 12:40:54 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/Zalipynis21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Array DBMSs manage big N-d arrays, are not yet widely known, but are experiencing an R&D surge due to the rapid growth of array volumes. Cellular automata (CA) operate on a discrete lattice of cells that can be modeled by an N-d array. CA are successfully applied to model fire spread, land cover change, road traffic, and other processes. We made traffic CA simulations possible by array DBMS due to novel components: native UDF language, proactive exec plans, convolution operator, retiling strategy, array versioning, locks, virtual axes, etc. A database approach to CA brings powerful parallelization, data fusion, array processing, and interoperability to name a few. To our best knowledge, our work is the first to run end-to-end CA simulations completely inside array DBMS: we enable array DBMS to simulate the physical world for the first time. Paper homepage: http://sigmod2021.gis.gg/}
}


@inproceedings{DBLP:conf/sigmod/XuLZSHL021,
	author = {Zhiqiang Xu and
                  Dong Li and
                  Weijie Zhao and
                  Xing Shen and
                  Tianbo Huang and
                  Xiaoyun Li and
                  Ping Li},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Agile and Accurate {CTR} Prediction Model Training for Massive-Scale
                  Online Advertising Systems},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2404--2409},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457236},
	doi = {10.1145/3448016.3457236},
	timestamp = {Sun, 19 Jan 2025 13:27:29 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/XuLZSHL021.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Deep neural network has been adopted as the standard model to predict ads click-through rate (CTR) for commercial online advertising systems. Deploying an industrial scale ads system requires to overcome numerous challenges, e.g., hundreds or thousands of billions of input features and also hundreds of billions of training samples, which under the cost budget can cause fundamental issues on storage, communication, or the model training speed. In this work, we present Baidu's industrial-scale practices on how to apply the system and machine learning techniques to address these issues and increase the revenue. In particular, we focus on the strategy for developing GPU-based CTR models combined with quantization techniques to build a compact and agile system which noticeably improves the revenue. With quantization, we are able to effectively increase the model (embedding layer) size without increasing the storage cost. This brings an increase in prediction accuracy and yields a 1% revenue increase and 1.8% higher relative click-through rate in the real sponsored search production environment.}
}


@inproceedings{DBLP:conf/sigmod/AbouzourABDMRSS21,
	author = {Mohammed Abouzour and
                  G{\"{u}}nes Alu{\c{c}} and
                  Ivan T. Bowman and
                  Xi Deng and
                  Nandan Marathe and
                  Sagar Ranadive and
                  Muhammed Sharique and
                  John C. Smirnios},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Bringing Cloud-Native Storage to {SAP} {IQ}},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2410--2422},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457563},
	doi = {10.1145/3448016.3457563},
	timestamp = {Mon, 21 Jun 2021 11:48:44 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/AbouzourABDMRSS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we describe our journey of transforming SAP IQ into a relational database management system (RDBMS) that utilizes cheap, elastically scalable object stores on the cloud. SAP IQ is a three-decade old, disk-based, columnar RDBMS that is optimized for complex online analytical processing (OLAP) workloads. Traditionally, SAP IQ has been designed to operate on shared storage devices with strong consistency guarantees (e.g., high-caliber storage area network devices). Therefore, deploying SAP IQ on the cloud, as is, would have meant utilizing storage solutions such as NetApp or AWS EFS that provide a POSIX compliant file interface and strong consistency guarantees, but at a much higher monetary cost. These costs can accumulate easily to diminish the economies of scale that one would expect on the cloud, which can be undesirable. Instead, we have enhanced the design of SAP IQ to operate on cloud object stores such as AWS S3 and Azure Blob Storage. Object stores rely on a weaker consistency model, and potentially have higher latency; however, because of these design trade-offs, they are able to offer (i) better pricing, (ii) enhanced durability, (iii) improved elasticity, and (iv) higher throughput. By enhancing SAP IQ to operate under these design trade-offs, we have unlocked many of the opportunities offered by object stores. More specifically, we have extended SAP IQ's buffer manager and transaction manager, and have introduced a new caching layer that utilizes instance storage on AWS EC2. Experiments using the TPC-H benchmark demonstrate that we can gain an order of magnitude reduction in data-at rest storage costs while improving query and load performance.}
}


@inproceedings{DBLP:conf/sigmod/AnglesBDFHHLLLM21,
	author = {Renzo Angles and
                  Angela Bonifati and
                  Stefania Dumbrava and
                  George Fletcher and
                  Keith W. Hare and
                  Jan Hidders and
                  Victor E. Lee and
                  Bei Li and
                  Leonid Libkin and
                  Wim Martens and
                  Filip Murlak and
                  Josh Perryman and
                  Ognjen Savkovic and
                  Michael Schmidt and
                  Juan F. Sequeda and
                  Slawek Staworko and
                  Dominik Tomaszuk},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {PG-Keys: Keys for Property Graphs},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2423--2436},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457561},
	doi = {10.1145/3448016.3457561},
	timestamp = {Wed, 07 Dec 2022 23:08:47 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/AnglesBDFHHLLLM21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We report on a community effort between industry and academia to shape the future of property graph constraints. The standardization for a property graph query language is currently underway through the ISO Graph Query Language (GQL) project. Our position is that this project should pay close attention to schemas and constraints, and should focus next on key constraints. The main purposes of keys are enforcing data integrity and allowing the referencing and identifying of objects. Motivated by use cases from our industry partners, we argue that key constraints should be able to have different modes, which are combinations of basic restriction that require the key to be exclusive, mandatory, and singleton. Moreover, keys should be applicable to nodes, edges, and properties since these all can represent valid real-life entities. Our result is PG-Keys, a flexible and powerful framework for defining key constraints, which fulfills the above goals. PG-Keys is a design by the Linked Data Benchmark Council's Property Graph Schema Working Group, consisting of members from industry, academia, and ISO GQL standards group, intending to bring the best of all worlds to property graph practitioners. PG-Keys aims to guide the evolution of the standardization efforts towards making systems more useful, powerful, and expressive.}
}


@inproceedings{DBLP:conf/sigmod/AntonopoulosKKA21,
	author = {Panagiotis Antonopoulos and
                  Raghav Kaushik and
                  Hanuma Kodavalla and
                  Sergio Rosales Aceves and
                  Reilly Wong and
                  Jason Anderson and
                  Jakub Szymaszek},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {{SQL} Ledger: Cryptographically Verifiable Data in Azure {SQL} Database},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2437--2449},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457558},
	doi = {10.1145/3448016.3457558},
	timestamp = {Sun, 19 Jan 2025 13:27:24 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/AntonopoulosKKA21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {SQL Ledger is a new technology that allows cryptographically verifying the integrity of relational data stored in Azure SQL Database and SQL Server. This is achieved by maintaining all historical data in the database and persisting its cryptographic (SHA-256) digests in an immutable, tamper-evident ledger. Digests representing the overall state of the ledger can then be extracted and stored outside of the RDBMS to protect the data from any attacker or high privileged user, including DBAs, system and cloud administrators. The ledger and the historical data are managed transparently, offering protection without any application changes. Historical data is maintained in a relational form to support SQL queries for auditing, forensics and other purposes. SQL Ledger provides cryptographic data integrity guarantees while maintaining the power, flexibility and performance of a commercial RDBMS. In contrast to Blockchain solutions that aim for full integrity, SQL Ledger offers a form of integrity protection known as Forward Integrity. The proposed technology is significantly cheaper and more secure than traditional solutions that establish trust based on audits or mediators, but also has substantial advantages over Blockchain solutions that are complex to deploy, lack data management capabilities and suffer in terms of performance due to their decentralized nature.}
}


@inproceedings{DBLP:conf/sigmod/Baunsgaard0CDGG21,
	author = {Sebastian Baunsgaard and
                  Matthias Boehm and
                  Ankit Chaudhary and
                  Behrouz Derakhshan and
                  Stefan Gei{\ss}els{\"{o}}der and
                  Philipp M. Grulich and
                  Michael Hildebrand and
                  Kevin Innerebner and
                  Volker Markl and
                  Claus Neubauer and
                  Sarah Osterburg and
                  Olga Ovcharenko and
                  Sergey Redyuk and
                  Tobias Rieger and
                  Alireza Rezaei Mahdiraji and
                  Sebastian Benjamin Wrede and
                  Steffen Zeuch},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {ExDRa: Exploratory Data Science on Federated Raw Data},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2450--2463},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457549},
	doi = {10.1145/3448016.3457549},
	timestamp = {Thu, 01 May 2025 20:25:58 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/Baunsgaard0CDGG21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Data science workflows are largely exploratory, dealing with under-specified objectives, open-ended problems, and unknown business value. Therefore, little investment is made in systematic acquisition, integration, and pre-processing of data. This lack of infrastructure results in redundant manual effort and computation. Furthermore, central data consolidation is not always technically or economically desirable or even feasible (e.g., due to privacy, and/or data ownership). The ExDRa system aims to provide system infrastructure for this exploratory data science process on federated and heterogeneous, raw data sources. Technical focus areas include (1) ad-hoc and federated data integration on raw data, (2) data organization and reuse of intermediates, and (3) optimization of the data science lifecycle, under awareness of partially accessible data. In this paper, we describe use cases, the overall system architecture, selected features of SystemDS' new federated backend (for federated linear algebra programs, federated parameter servers, and federated data preparation), as well as promising initial results. Beyond existing work on federated learning, ExDRa focuses on enterprise federated ML and related data pre-processing challenges. In this context, federated ML has the potential to create a more fine-grained spectrum of data ownership and thus, even new markets.}
}


@inproceedings{DBLP:conf/sigmod/CaoFLZGZ021,
	author = {Wei Cao and
                  Xiaojie Feng and
                  Boyuan Liang and
                  Tianyu Zhang and
                  Yusong Gao and
                  Yunyang Zhang and
                  Feifei Li},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {LogStore: {A} Cloud-Native and Multi-Tenant Log Database},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2464--2476},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457565},
	doi = {10.1145/3448016.3457565},
	timestamp = {Sun, 19 Jan 2025 13:27:18 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/CaoFLZGZ021.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the prevalence of cloud computing, more and more enterprises are migrating applications to cloud infrastructures. Logs are the key to helping customers understand the status of their applications running on the cloud. They are vital for various scenarios, such as service stability assessment, root cause analysis and user activity profiling. Therefore, it is essential to manage the massive amount of logs collected on the cloud and tap their value. Although various log storages have been widely used in the past few decades, it is still a non-trivial problem to design a cost-effective log storage for cloud applications. It faces challenges of heavy write throughput of tens of millions of log records per second, retrieval on PB-level logs and massive hundreds of thousands of tenants. Traditional log processing systems cannot satisfy all these requirements. To address these challenges, we propose the cloud-native log database LogStore. It combines shared-nothing and shared-data architecture, and utilizes highly scalable and low-cost cloud object storage, while overcoming the bandwidth limitations and high latency of using remote storage when writing a large number of logs. We also propose a multi-tenant management method that physically isolates tenant data to ensure compliance and flexible data expiration policies, and uses a novel traffic scheduling algorithm to mitigate the impact of traffic skew and hotspots among tenants. In addition, we design an efficient column index structure LogBlock to support queries with full-text search, and combined several query optimization techniques to reduce query latency on cloud object storage. LogStore has been deployed in Alibaba Cloud on a large scale (more than 500 machines), processing logs of more than 100 GB per second, and has been running stably for more than two years.}
}


@inproceedings{DBLP:conf/sigmod/CaoZYLWHCCLFWWS21,
	author = {Wei Cao and
                  Yingqiang Zhang and
                  Xinjun Yang and
                  Feifei Li and
                  Sheng Wang and
                  Qingda Hu and
                  Xuntao Cheng and
                  Zongzhi Chen and
                  Zhenjun Liu and
                  Jing Fang and
                  Bo Wang and
                  Yuhui Wang and
                  Haiqing Sun and
                  Ze Yang and
                  Zhushi Cheng and
                  Sen Chen and
                  Jian Wu and
                  Wei Hu and
                  Jianwei Zhao and
                  Yusong Gao and
                  Songlu Cai and
                  Yunyang Zhang and
                  Jiawang Tong},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {PolarDB Serverless: {A} Cloud Native Database for Disaggregated Data
                  Centers},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2477--2489},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457560},
	doi = {10.1145/3448016.3457560},
	timestamp = {Sun, 19 Jan 2025 13:27:33 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/CaoZYLWHCCLFWWS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {\\beginabstract The trend in the DBMS market is to migrate to the cloud for elasticity, high availability, and lower costs. The traditional, monolithic database architecture is difficult to meet these requirements. With the development of high-speed network and new memory technologies, disaggregated data center has become a reality: it decouples various components from monolithic servers into separated resource pools (e.g., compute, memory, and storage) and connects them through a high-speed network. The next generation cloud native databases should be designed for disaggregated data centers. In this paper, we describe the novel architecture of \\name, which follows thedisaggregation design paradigm: the CPU resource on compute nodes is decoupled from remote memory pool and storage pool. Each resource pool grows or shrinks independently, providing \\revon-demand provisoning at multiple dimensions while improving reliability. We also design our system to mitigate the inherent penalty brought by resource disaggregation, and introduce optimizations such as optimistic locking and index awared prefetching. Compared to the architecture that uses local resources, \\name achieves better dynamic resource provisioning capabilities and 5.3 times faster failure recovery speed, while achieving comparable performance. \\endabstract}
}


@inproceedings{DBLP:conf/sigmod/CubukcuEPSS21,
	author = {Umur Cubukcu and
                  Ozgun Erdogan and
                  Sumedh Pathak and
                  Sudhakar Sannakkayala and
                  Marco Slot},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Citus: Distributed PostgreSQL for Data-Intensive Applications},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2490--2502},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457551},
	doi = {10.1145/3448016.3457551},
	timestamp = {Mon, 21 Jun 2021 11:48:44 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/CubukcuEPSS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Citus is an open source distributed database engine for PostgreSQL that is implemented as an extension. Citus gives users the ability to distribute data, queries, and transactions in PostgreSQL across a cluster of PostgreSQL servers to handle the needs of data-intensive applications. The development of Citus has largely been driven by conversations with companies looking to scale PostgreSQL beyond a single server and their workload requirements. This paper describes the requirements of four common workload patterns and how Citus addresses those requirements. It also shares benchmark results demonstrating the performance and scalability of Citus in each of the workload patterns and describes how Microsoft uses Citus to address one of its most challenging data problems.}
}


@inproceedings{DBLP:conf/sigmod/FuS21,
	author = {Yupeng Fu and
                  Chinmay Soman},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Real-time Data Infrastructure at Uber},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2503--2516},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457552},
	doi = {10.1145/3448016.3457552},
	timestamp = {Sun, 19 Jan 2025 13:27:34 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/FuS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Uber's business is highly real-time in nature. PBs of data is continuously being collected from the end users such as Uber drivers, riders, restaurants, eaters and so on everyday. There is a lot of valuable information to be processed and many decisions must be made in seconds for a variety of use cases such as customer incentives, fraud detection, machine learning model prediction. In addition, there is an increasing need to expose this ability to different user categories, including engineers, data scientists, executives and operations personnel which adds to the complexity. In this paper, we present the overall architecture of the real-time data infrastructure and identify three scaling challenges that we need to continuously address for each component in the architecture. At Uber, we heavily rely on open source technologies for the key areas of the infrastructure. On top of those open-source software, we add significant improvements and customizations to make the open-source solutions fit in Uber's environment and bridge the gaps to meet Uber's unique scale and requirements. We then highlight several important use cases and show their real-time solutions and tradeoffs. Finally, we reflect on the lessons we learned as we built, operated and scaled these systems.}
}


@inproceedings{DBLP:conf/sigmod/Lev-AriTSDFABDG21,
	author = {Kfir Lev{-}Ari and
                  Yizuo Tian and
                  Alexander Shraer and
                  Chris Douglas and
                  Hao Fu and
                  Andrey Andreev and
                  Kevin Beranek and
                  Scott Dugas and
                  Alec Grieser and
                  Jeremy Hemmo},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {QuiCK: {A} Queuing System in CloudKit},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2517--2529},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457567},
	doi = {10.1145/3448016.3457567},
	timestamp = {Mon, 21 Jun 2021 11:48:44 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/Lev-AriTSDFABDG21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We present QuiCK, a queuing system built for managing asynchronous tasks in CloudKit, Apple's storage backend service. QuiCK stores queued messages along with user data in CloudKit, and supports CloudKit's tenancy model including isolation, fair resource allocation, observability, and tenant migration. QuiCK is built on the FoundationDB Record Layer, an open source transactional DBMS. It employs massive two-level sharding, with tens of billions of queues on the first level (separately storing the queued items for each user of every CloudKit app), and hundreds of queues on a second level (one per FoundationDB cluster used by CloudKit). Our evaluation demonstrates that QuiCK scales linearly with additional consumer resources, effectively avoids contention, provides fairness across CloudKit tenants, and executes deferred tasks with low latency.}
}


@inproceedings{DBLP:conf/sigmod/LyuZXGWCPYGWLAY21,
	author = {Zhenghua Lyu and
                  Huan Hubert Zhang and
                  Gang Xiong and
                  Gang Guo and
                  Haozhou Wang and
                  Jinbao Chen and
                  Asim Praveen and
                  Yu Yang and
                  Xiaoming Gao and
                  Alexandra Wang and
                  Wen Lin and
                  Ashwin Agrawal and
                  Junfeng Yang and
                  Hao Wu and
                  Xiaoliang Li and
                  Feng Guo and
                  Jiang Wu and
                  Jesse Zhang and
                  Venkatesh Raghavan},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Greenplum: {A} Hybrid Database for Transactional and Analytical Workloads},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2530--2542},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457562},
	doi = {10.1145/3448016.3457562},
	timestamp = {Sun, 19 Jan 2025 13:27:20 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/LyuZXGWCPYGWLAY21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Demand for enterprise data warehouse solutions to support real-time Online Transaction Processing (OLTP) queries as well as long-running Online Analytical Processing (OLAP) workloads is growing. Greenplum database is traditionally known as an OLAP data warehouse system with limited ability to process OLTP workloads. In this paper, we augment Greenplum into a hybrid system to serve both OLTP and OLAP workloads. The challenge we address here is to achieve this goal while maintaining the ACID properties with minimal performance overhead. In this effort, we identify the engineering and performance bottlenecks such as the under-performing restrictive locking and the two-phase commit protocol. Next we solve the resource contention issues between transactional and analytical queries. We propose a global deadlock detector to increase the concurrency of query processing. When transactions that update data are guaranteed to reside on exactly one segment we introduce one-phase commit to speed up query processing. Our resource group model introduces the capability to separate OLAP and OLTP workloads into more suitable query processing mode. Our experimental evaluation on the TPC-B and CH-benCHmark benchmarks demonstrates the effectiveness of our approach in boosting the OLTP performance without sacrificing the OLAP performance.}
}


@inproceedings{DBLP:conf/sigmod/MoellerYLL21,
	author = {Justin Moeller and
                  Zi Ye and
                  Katherine Lin and
                  Willis Lang},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Toto - Benchmarking the Efficiency of a Cloud Service},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2543--2556},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457555},
	doi = {10.1145/3448016.3457555},
	timestamp = {Mon, 21 Jun 2021 11:48:44 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/MoellerYLL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Microsoft aims to increase the efficiency of Azure SQL DB by maximizing the number of databases that can be hosted in a cluster. However, resource contention among customers increases when changing the configurations, policies, and features that control database co-location on cluster nodes. Tuning and evaluating the efficiency and customer impact of these variables in a scientific manner in production, with a dynamic system and customer workloads, is difficult or infeasible. Here, we present Toto, a benchmark framework for evaluating the efficiency of any cloud service that leverages orchestrators like Service Fabric or Kubernetes. Toto allows for reliable and repeatable specification of a benchmarking scenario of arbitrary scale, complexity, and time-length. An implementation of Toto is deployed in all SQL DB staging clusters and is used to evaluate system efficiency and behaviors. As an example of Toto's capabilities, we present a study to explore the balance between cluster database density and quality of service.}
}


@inproceedings{DBLP:conf/sigmod/NegiIMAKFJ21,
	author = {Parimarjan Negi and
                  Matteo Interlandi and
                  Ryan Marcus and
                  Mohammad Alizadeh and
                  Tim Kraska and
                  Marc T. Friedman and
                  Alekh Jindal},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Steering Query Optimizers: {A} Practical Take on Big Data Workloads},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2557--2569},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457568},
	doi = {10.1145/3448016.3457568},
	timestamp = {Sat, 30 Sep 2023 09:56:34 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/NegiIMAKFJ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent years, there has been tremendous interest in research that applies machine learning to database systems. Being one of the most complex components of a DBMS, query optimizers could benefit from adaptive policies that are learned systematically from the data and the query workload. Recent research has brought up novel ideas towards a learned query optimizer, however these ideas have not been evaluated on a commercial query processor or on large scale, real-world workloads. In this paper, we take the approach used by Marcus et al. in Bao and adapt it to SCOPE, a big data system used internally at Microsoft. Along the way, we solve multiple new challenges: we define how optimizer rules affect final query plans by introducing the concept of a rule signature, we devise a pipeline computing interesting rule configurations for recurring jobs, and we define a new learning problem allowing us to apply such interesting rule configurations to previously unseen jobs. We evaluate the efficacy of the approach on production workloads that include 150K daily jobs. Our results show that alternative rule configurations can generate plans with lower costs, and this can translate to runtime latency savings of 7-30% on average and up to 90% for a non trivial subset of the workload.}
}


@inproceedings{DBLP:conf/sigmod/PangLCWXW21,
	author = {Zhu Pang and
                  Qingda Lu and
                  Shuo Chen and
                  Rui Wang and
                  Yikang Xu and
                  Jiesheng Wu},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {ArkDB: {A} Key-Value Engine for Scalable Cloud Storage Services},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2570--2583},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457553},
	doi = {10.1145/3448016.3457553},
	timestamp = {Fri, 02 Feb 2024 10:56:16 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/PangLCWXW21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Persistent key-value stores play a crucial role in enabling internet-scale services. At Alibaba Cloud, scale-out cloud storage services including Object Storage Service, File Storage Service and Tablestore are built on distributed key-value stores. Key challenges in the design of the underlying key-value engine for these services lie in utilization of disaggregated storage, supporting write and range query-heavy workloads, and balancing of scalability, availability and resource usage. This paper presents ArkDB, a key-value engine designed to address these challenges by combining advantages of both LSM tree and Bw-tree, and leveraging advances in hardware technologies. Built on top of Pangu, an append-only distributed file system, ArkDB's innovations include shrinkable page mapping table, clear separation of system and user states for fast recovery, write amplification reduction, efficient garbage collection and lightweight partition split and merge. Experimental results demonstrate ArkDB's improvements over existing designs. Compared with Bw-tree, ArkDB efficiently stabilizes the mapping table size despite continuous write working set growth. Compared with RocksDB, an LSM tree-based key-value engine, ArkDB increases ingestion throughput by 2.16x, while reducing write amplification by 3.1x. It outperforms RocksDB by 52% and 37% respectively on a write-heavy workload and a range query-intensive workload of the Yahoo! Cloud Serving Benchmark. Experiments running in Tablestore in a cluster environment further demonstrate ArkDB's performance on Pangu and its efficient partition split/merge support.}
}


@inproceedings{DBLP:conf/sigmod/ShahPVDCKSWBGGV21,
	author = {Syed Yousaf Shah and
                  Dhaval Patel and
                  Long Vu and
                  Xuan{-}Hong Dang and
                  Bei Chen and
                  Peter Kirchner and
                  Horst Samulowitz and
                  David Wood and
                  Gregory Bramble and
                  Wesley M. Gifford and
                  Giridhar Ganapavarapu and
                  Roman Vacul{\'{\i}}n and
                  Petros Zerfos},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {AutoAI-TS: AutoAI for Time Series Forecasting},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2584--2596},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457557},
	doi = {10.1145/3448016.3457557},
	timestamp = {Mon, 15 Nov 2021 08:49:16 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/ShahPVDCKSWBGGV21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A large number of time series forecasting models including traditional statistical models, machine learning models and more recently deep learning have been proposed in the literature. However, choosing the right model along with good parameter values that performs well on a given data is still challenging. Automatically providing a good set of models to users for a given dataset saves both time and effort from using trial-and-error approaches with a wide variety of available models along with parameter optimization. We present AutoAI for Time Series Forecasting (AutoAI-TS) that provides users with a zero configuration (zero-conf) system to efficiently train, optimize and choose best forecasting model among various classes of models for the given dataset. With its flexible zero-conf design, AutoAI-TS automatically performs all the data preparation, model creation, parameter optimization, training and model selection for users and provides a trained model that is ready to use. For given data, AutoAI-TS utilizes a wide variety of models including classical statistical models, Machine Learning (ML) models, statistical-ML hybrid models and deep learning models along with various transformations to create forecasting pipelines. It then evaluates and ranks pipelines using the proposed T-Daub mechanism to choose the best pipeline. The paper describe in detail all the technical aspects of AutoAI-TS along with extensive benchmarking on a variety of real world data sets for various use-cases. Benchmark results show that AutoAI-TS, with no manual configuration from the user, automatically trains and selects pipelines that on average outperform existing state-of-the-art time series forecasting toolkits.}
}


@inproceedings{DBLP:conf/sigmod/TangLLCYZ21,
	author = {Yingtian Tang and
                  Han Lu and
                  Xijun Li and
                  Lei Chen and
                  Mingxuan Yuan and
                  Jia Zeng},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Learning-Aided Heuristics Design for Storage System},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2597--2601},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457554},
	doi = {10.1145/3448016.3457554},
	timestamp = {Sun, 19 Jan 2025 13:27:29 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/TangLLCYZ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Computer systems such as storage systems normally require transparent white-box algorithms that are interpretable for human experts. In this work, we propose a learning-aided heuristic design method, which automatically generates human-readable strategies from Deep Reinforcement Learning (DRL) agents. This method benefits from the power of deep learning but avoids the shortcoming of its black-box property. Besides the white-box advantage, experiments in our storage production's resource allocation scenario also show that this solution outperforms the system's default settings and the elaborately handcrafted strategy by human experts.}
}


@inproceedings{DBLP:conf/sigmod/WangCDGCSRBCMMR21,
	author = {Guozhang Wang and
                  Lei Chen and
                  Ayusman Dikshit and
                  Jason Gustafson and
                  Boyang Chen and
                  Matthias J. Sax and
                  John Roesler and
                  Sophie Blee{-}Goldman and
                  Bruno Cadonna and
                  Apurva Mehta and
                  Varun Madan and
                  Jun Rao},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Consistency and Completeness: Rethinking Distributed Stream Processing
                  in Apache Kafka},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2602--2613},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457556},
	doi = {10.1145/3448016.3457556},
	timestamp = {Mon, 21 Jun 2021 11:48:44 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/WangCDGCSRBCMMR21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {An increasingly important system requirement for distributed stream processing applications is to provide strong correctness guarantees under unexpected failures and out-of-order data so that its results can be authoritative (not needing complementary batch results). Although existing systems have put a lot of effort into addressing some specific issues, such as consistency and completeness, how to enable users to make flexible and transparent trade-off decisions among correctness, performance, and cost still remains a practical challenge. Specifically, similar mechanisms are usually applied to tackle both consistency and completeness, which can result in unnecessary performance penalties. We present Apache Kafka's core design for stream processing, which relies on its persistent log architecture as the storage and inter-processor communication layers to achieve correctness guarantees. Kafka Streams, a scalable stream processing client library in Apache Kafka, defines the processing logic as read-process-write cycles in which all processing state updates and result outputs are captured as log appends. Idempotent and transactional write protocols are utilized to guarantee exactly-once semantics. Furthermore, revision-based speculative processing is employed to emit results as soon as possible while handling out-of-order data. We also demonstrate how Kafka Streams behaves in practice with large-scale deployments and performance insights exhibiting its flexible and low-overhead trade-offs.}
}


@inproceedings{DBLP:conf/sigmod/WangYGJXLWGLXYY21,
	author = {Jianguo Wang and
                  Xiaomeng Yi and
                  Rentong Guo and
                  Hai Jin and
                  Peng Xu and
                  Shengjun Li and
                  Xiangyu Wang and
                  Xiangzhou Guo and
                  Chengming Li and
                  Xiaohai Xu and
                  Kun Yu and
                  Yuxing Yuan and
                  Yinghao Zou and
                  Jiquan Long and
                  Yudong Cai and
                  Zhenxiang Li and
                  Zhifeng Zhang and
                  Yihua Mo and
                  Jun Gu and
                  Ruiyi Jiang and
                  Yi Wei and
                  Charles Xie},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Milvus: {A} Purpose-Built Vector Data Management System},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2614--2627},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457550},
	doi = {10.1145/3448016.3457550},
	timestamp = {Sun, 19 Jan 2025 13:27:22 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/WangYGJXLWGLXYY21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recently, there has been a pressing need to manage high-dimensional vector data in data science and AI applications. This trend is fueled by the proliferation of unstructured data and machine learning (ML), where ML models usually transform unstructured data into feature vectors for data analytics, e.g., product recommendation. Existing systems and algorithms for managing vector data have two limitations: (1) They incur serious performance issue when handling large-scale and dynamic vector data; and (2) They provide limited functionalities that cannot meet the requirements of versatile applications. This paper presents Milvus, a purpose-built data management system to efficiently manage large-scale vector data. Milvus supports easy-to-use application interfaces (including SDKs and RESTful APIs); optimizes for the heterogeneous computing platform with modern CPUs and GPUs; enables advanced query processing beyond simple vector similarity search; handles dynamic data for fast updates while ensuring efficient query processing; and distributes data across multiple nodes to achieve scalability and availability. We first describe the design and implementation of Milvus. Then we demonstrate the real-world use cases supported by Milvus. In particular, we build a series of 10 applications (e.g., image/video search, chemical structure analysis, COVID-19 dataset search, personalized recommendation, biological multi-factor authentication, intelligent question answering) on top of Milvus. Finally, we experimentally evaluate Milvus with a wide range of systems including two open source systems (Vearch and Microsoft SPTAG) and three commercial systems. Experiments show that Milvus is up to two orders of magnitude faster than the competitors while providing more functionalities. Now Milvus is deployed by hundreds of organizations worldwide and it is also recognized as an incubation-stage project of the LF AI & Data Foundation. Milvus is open-sourced at https://github.com/milvus-io/milvus.}
}


@inproceedings{DBLP:conf/sigmod/WangLLXYWWCYSG21,
	author = {Xuhong Wang and
                  Ding Lyu and
                  Mengjian Li and
                  Yang Xia and
                  Qi Yang and
                  Xinwen Wang and
                  Xinguang Wang and
                  Ping Cui and
                  Yupu Yang and
                  Bowen Sun and
                  Zhenyu Guo},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {{APAN:} Asynchronous Propagation Attention Network for Real-time Temporal
                  Graph Embedding},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2628--2638},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457564},
	doi = {10.1145/3448016.3457564},
	timestamp = {Sun, 02 Oct 2022 16:15:22 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/WangLLXYWWCYSG21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {To capture higher-order structural features, most GNN-based algorithms learn node representations incorporating k-hop neighbors' information. Due to the high time complexity of querying k-hop neighbors, most graph algorithms cannot be deployed in a giant dense temporal network to execute millisecond-level inference. This problem dramatically limits the potential of applying graph algorithms in certain areas, especially financial fraud detection. Therefore, we propose Asynchronous Propagation Attention Network, an asynchronous continuous time dynamic graph algorithm for real-time temporal graph embedding. Traditional graph models usually execute two serial operations: first graph querying and then model inference. Different from previous graph algorithms, we decouple model inference and graph computation to alleviate the damage of the heavy graph query operation to the speed of model inference. Extensive experiments demonstrate that the proposed method can achieve competitive performance while greatly improving the inference speed. The source code is published at a Github repository.}
}


@inproceedings{DBLP:conf/sigmod/XinMPP21,
	author = {Doris Xin and
                  Hui Miao and
                  Aditya G. Parameswaran and
                  Neoklis Polyzotis},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Production Machine Learning Pipelines: Empirical Analysis and Optimization
                  Opportunities},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2639--2652},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457566},
	doi = {10.1145/3448016.3457566},
	timestamp = {Sun, 02 Oct 2022 16:15:22 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/XinMPP21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Machine learning (ML) is now commonplace, powering data-driven applications in various organizations. Unlike the traditional perception of ML in research, ML production pipelines are complex, with many interlocking analytical components beyond training, whose sub-parts are often run multiple times on overlapping subsets of data. However, there is a lack of quantitative evidence regarding the lifespan, architecture, frequency, and complexity of these pipelines to understand how data management research can be used to make them more efficient, effective, robust, and reproducible. To that end, we analyze the provenance graphs of 3000 production ML pipelines at Google, comprising over 450,000 models trained, spanning a period of over four months, in an effort to understand the complexity and challenges underlying production ML. Our analysis reveals the characteristics, components, and topologies of typical industry-strength ML pipelines at various granularities. Along the way, we introduce a specialized data model for representing and reasoning about repeatedly run components in these ML pipelines, which we call model graphlets. We identify several rich opportunities for optimization, leveraging traditional data management ideas. We show how targeting even one of these opportunities, i.e., identifying and pruning wasted computation that does not translate to model deployment, can reduce wasted computation cost by 50% without compromising the model deployment cadence.}
}


@inproceedings{DBLP:conf/sigmod/ZhouXSNMTABSLRD21,
	author = {Jingyu Zhou and
                  Meng Xu and
                  Alexander Shraer and
                  Bala Namasivayam and
                  Alex Miller and
                  Evan Tschannen and
                  Steve Atherton and
                  Andrew J. Beamon and
                  Rusty Sears and
                  John Leach and
                  Dave Rosenthal and
                  Xin Dong and
                  Will Wilson and
                  Ben Collins and
                  David Scherer and
                  Alec Grieser and
                  Young Liu and
                  Alvin Moore and
                  Bhaskar Muppana and
                  Xiaoge Su and
                  Vishesh Yadav},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {FoundationDB: {A} Distributed Unbundled Transactional Key Value Store},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2653--2666},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457559},
	doi = {10.1145/3448016.3457559},
	timestamp = {Sun, 19 Jan 2025 13:27:31 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/ZhouXSNMTABSLRD21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {FoundationDB is an open source transactional key value store created more than ten years ago. It is one of the first systems to combine the flexibility and scalability of NoSQL architectures with the power of ACID transactions (a.k.a. NewSQL). FoundationDB adopts an unbundled architecture that decouples an in-memory transaction management system, a distributed storage system, and a built-in distributed configuration system. Each sub-system can be independently provisioned and configured to achieve the desired scalability, high-availability and fault tolerance properties. FoundationDB uniquely integrates a deterministic simulation framework, used to test every new feature of the system under a myriad of possible faults. This rigorous testing makes FoundationDB extremely stable and allows developers to introduce and release new features in a rapid cadence. FoundationDB offers a minimal and carefully chosen feature set, which has enabled a range of disparate systems (from semi-relational databases, document and object stores, to graph databases and more) to be built as layers on top. FoundationDB is the underpinning of cloud infrastructure at Apple, Snowflake and other companies, due to its consistency, robustness and availability for storing user data, system metadata and configuration, and other critical information.}
}


@inproceedings{DBLP:conf/sigmod/ZhuKKTPMKZMJSDI21,
	author = {Yiwen Zhu and
                  Subru Krishnan and
                  Konstantinos Karanasos and
                  Isha Tarte and
                  Conor Power and
                  Abhishek Modi and
                  Manoj Kumar and
                  Deli Zhang and
                  Kartheek Muthyala and
                  Nick Jurgens and
                  Sarvesh Sakalanaga and
                  Sudhir Darbha and
                  Minu Iyer and
                  Ankita Agarwal and
                  Carlo Curino},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {{KEA:} Tuning an Exabyte-Scale Data Infrastructure},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2667--2680},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457569},
	doi = {10.1145/3448016.3457569},
	timestamp = {Sun, 19 Jan 2025 13:27:19 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/ZhuKKTPMKZMJSDI21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Microsoft\'s internal big-data infrastructure is one of the largest in the world---with over 300k machines running billions of tasks from over 0.6M daily jobs. Operating this infrastructure is a costly and complex endeavor, and efficiency is paramount. In fact, for over 15 years, a dedicated engineering team has tuned almost every aspect of this infrastructure, achieving state-of-the-art efficiency (>60% average CPU utilization across all clusters). Despite rich telemetry and strong expertise, faced with evolving hardware/software/workloads this manual tuning approach had reached its limit---we had plateaued. In this paper, we present KEA, a multi-year effort to automate our tuning processes to be fully data/model-driven. KEA leverages a mix of domain knowledge and principled data science to capture the essence of our cluster dynamic behavior in a set of machine learning (ML) models based on collected system data. These models power automated optimization procedures for parameter tuning, and inform our leadership in critical decisions around engineering and capacity management (such as hardware and data center design, software investments, etc.). We combine "observational\'\' tuning (i.e., using models to predict system behavior without direct experimentation) with judicious use of "flighting\'\' (i.e., conservative testing in production). This allows us to support a broad range of applications that we discuss in this paper. KEA continuously tunes our cluster configurations and is on track to save Microsoft tens of millions of dollars per year. At the best of our knowledge, this paper is the first to discuss research challenges and practical learnings that emerge when tuning an exabyte-scale data infrastructure.}
}


@inproceedings{DBLP:conf/sigmod/ChatziantoniouK21,
	author = {Damianos Chatziantoniou and
                  Verena Kantere},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {DataMingler: {A} Novel Approach to Data Virtualization},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2681--2685},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452752},
	doi = {10.1145/3448016.3452752},
	timestamp = {Mon, 21 Jun 2021 11:48:44 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/ChatziantoniouK21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A Data Virtual Machine (DVM) is a novel graph-based conceptual model, similar to the entity-relationship model, representing existing data (persistent, transient, derived) of an organization. A DVM can be built quickly, agilely, offering schematic flexibility to data engineers. Data scientists can visually define complex dataframe queries in an intuitive and simple manner, which are evaluated within an algebraic framework. A DVM can be easily materialized in any logical data model and can be "reoriented\'\' around any node, offering a "single view of any entity\'\'. In this paper we demonstrate DataMingler, a tool implementing DVMs. We argue that DVMs can have a significant practical impact in analytics environments.}
}


@inproceedings{DBLP:conf/sigmod/ChenH21,
	author = {Yiru Chen and
                  Silu Huang},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {TSExplain: Surfacing Evolving Explanations for Time Series},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2686--2690},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452769},
	doi = {10.1145/3448016.3452769},
	timestamp = {Mon, 21 Jun 2021 11:48:44 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/ChenH21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Understanding the underlying explanations for what has happened is more and more crucial in today\'s business decision-making processes. Existing explanation engines focus on explaining the difference between two given sets. However, for time-series, the explanations usually evolve as time advances. Thus, only considering two end timestamps would miss all explanations in between. To mitigate this, we demonstrate TSExplain, a system to help users understand the underlying evolving explanations for any aggregated time-series. Internally, TSExplain models the explanation problem as a segmentation problem over the time dimension and uses existing works on two-sets diff as building blocks. In our demonstration, conference attendees will be able to easily and interactively explore the evolving explanations and visualize how these explanations contribute to the overall changes in various datasets: COVID-19, S&P500, Iowa Liquor Sales. Questions-like "which states make COVID-19 total confirmed case number go up dramatically during the past year?", "which stocks drive the dramatic crashes of S&P500 in Mar and the quick rebound later?", and "how does Liquor sales trend look like from January 2020 till now and why"-can all get well-answered by TSExplain.}
}


@inproceedings{DBLP:conf/sigmod/ChowDS021,
	author = {Ka Ho Chow and
                  Umesh Deshpande and
                  Sangeetha Seshadri and
                  Ling Liu},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {{SRA:} Smart Recovery Advisor for Cyber Attacks},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2691--2695},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452766},
	doi = {10.1145/3448016.3452766},
	timestamp = {Mon, 05 Feb 2024 20:26:57 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/ChowDS021.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Continuous Data Protection (CDP) is becoming instrumental in recovering applications from crypto-ransomware attacks. It enables fine-grained recovery through journaling, allowing the applications (its volumes) to recover to any previous state. While zero data loss can be achieved during recovery with CDP, the timestamp of the desired restore point, i.e., the one just prior to the attack, needs to be provided to reconstruct the volume. Such information is often unavailable in practice, and system administrators can only adopt a trial-and-error strategy to narrow down the time range of desired restore points by making multiple time-consuming recovery attempts. The recovery systems offer little guidance in pointing to the restore points containing a valid application state and reducing data loss. To address this problem, we equip the CDP-based recovery with machine intelligence. This demonstration showcases Smart Recovery Advisor (SRA), which offers interpretable, data-driven, and feedback-aware restore point recommendations that reduce the number of recovery attempts while minimizing data loss.}
}


@inproceedings{DBLP:conf/sigmod/BuonoPSI021,
	author = {Francesco Del Buono and
                  Matteo Paganelli and
                  Paolo Sottovia and
                  Matteo Interlandi and
                  Francesco Guerra},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Transforming {ML} Predictive Pipelines into {SQL} with {MASQ}},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2696--2700},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452771},
	doi = {10.1145/3448016.3452771},
	timestamp = {Mon, 03 Mar 2025 21:21:49 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/BuonoPSI021.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Inference of Machine Learning (ML) models, i.e. the process of obtaining predictions from trained models, is often an overlooked problem. Model inference is however one of the main contributors of both technical debt in ML applications and infrastructure complexity. MASQ is a framework able to run inference of ML models directly on DBMSs. MASQ not only averts expensive data movements for those predictive scenarios where data resides on a database, but it also naturally exploits all the "Enterprise-grade" features such as governance, security and auditability which make DBMSs the cornerstone of many businesses. MASQ compiles trained models and ML pipelines implemented in scikit-learn directly into standard SQL: no UDFs nor vendor-specific syntax are used, and therefore queries can be readily executed on any DBMS. In this demo, we will showcase MASQ\'s capabilities through a GUI allowing attendees to: (1) train ML pipelines composed of data featurizers and ML models; (2) compile the trained pipelines into SQL, and deploy them on different DBMSs (MySQL and SQLServer in the demo); and (3) compare the related performance under different configurations (e.g., the original pipeline on the ML framework against the SQL implementations).}
}


@inproceedings{DBLP:conf/sigmod/DixitK21,
	author = {Akhil A. Dixit and
                  Phokion G. Kolaitis},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {CAvSAT: Answering Aggregation Queries over Inconsistent Databases
                  via {SAT} Solving},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2701--2705},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452749},
	doi = {10.1145/3448016.3452749},
	timestamp = {Sun, 19 Jan 2025 13:27:28 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/DixitK21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Consistent Query Answering (CQA) is a rigorous and principled approach to answering queries posed against inconsistent databases. Computing consistent answers to a Select-Project-Join (SPJ) query or an SPJ query with aggregation operators on a given inconsistent database can be an intractable problem. We demonstrate CAvSAT, a system for CQA that leverages a set of natural reductions from a given CQA instance to boolean Satisfiability (SAT) and its optimization variants. CAvSAT is the first system that is capable of handling unions of SPJ queries with aggregation operators SUM and COUNT, and databases that are inconsistent w.r.t. key constraints, functional dependencies, and denial constraints.}
}


@inproceedings{DBLP:conf/sigmod/Fariha0MRG21,
	author = {Anna Fariha and
                  Ashish Tiwari and
                  Alexandra Meliou and
                  Arjun Radhakrishna and
                  Sumit Gulwani},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {CoCo: Interactive Exploration of Conformance Constraints for Data
                  Understanding and Data Cleaning},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2706--2710},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452750},
	doi = {10.1145/3448016.3452750},
	timestamp = {Mon, 05 Feb 2024 20:26:56 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/Fariha0MRG21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Data profiling refers to the task of extracting technical metadata or profiles and has numerous applications such as data understanding, validation, integration, and cleaning. While a number of data profiling primitives exist in the literature, most of them are limited to categorical attributes. A few techniques consider numerical attributes; but, they either focus on simple relationships involving a pair of attributes (e.g., correlations) or convert the continuous semantics of numerical attributes to a discrete semantics, which results in information loss. To capture more complex relationships involving the numerical attributes, we developed a new data-profiling primitive called conformance constraints, which can model linear arithmetic relationships involving multiple numerical attributes. We present CoCo, a system that allows interactive discovery and exploration of Conformance Constraints for understanding trends involving the numerical attributes of a dataset, with a particular focus on the application of data cleaning. Through a simple interface, CoCo enables the user to guide conformance constraint discovery according to their preferences. The user can examine to what extent a new, possibly dirty, dataset satisfies or violates the discovered conformance constraints. Further, CoCo provides useful suggestions for cleaning dirty data tuples, where the user can interactively alter cell values, and verify by checking change in conformance constraint violation due to the alteration. We demonstrate how CoCo can help in understanding trends in the data and assist the users in interactive data cleaning, using conformance constraints.}
}


@inproceedings{DBLP:conf/sigmod/GalhotraFSS21,
	author = {Sainyam Galhotra and
                  Donatella Firmani and
                  Barna Saha and
                  Divesh Srivastava},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {{BEER:} Blocking for Effective Entity Resolution},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2711--2715},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452747},
	doi = {10.1145/3448016.3452747},
	timestamp = {Mon, 21 Jun 2021 11:48:44 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/GalhotraFSS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Blocking is a key component of Entity Resolution (ER) that aims to improve efficiency by quickly pruning out non-matching record pairs. However, depending on the noise in the dataset and the distribution of entity cluster sizes, existing techniques can be either (a) too aggressive, such that they help scale but can adversely affect the ER effectiveness, or (b) too permissive, potentially harming ER efficiency. We propose a new methodology of progressive blocking that enables both efficient and effective ER and works across different entity cluster size distributions without manual fine tuning. In this paper, we demonstrate BEER (Blocking for Effective Entity Resolution), the first end-to-end system that leverages intermediate ER output in a feedback loop to refine the blocking result in a data-driven fashion, thereby enabling effective entity resolution. BEER allows the user to explore the different components of the ER pipeline, analyze the effectiveness of alternative blocking techniques and understand the interaction between blocking and ER. BEER supports visualization of the different entities present in a block, explains the change in blocking output with every round of feedback and allows the end-user to interactively compare different techniques. BEER has been developed as open-source software; the code and the demonstration video are available at beer-system.github.io.}
}


@inproceedings{DBLP:conf/sigmod/GaoLCSMFS21,
	author = {Peng Gao and
                  Xiaoyuan Liu and
                  Edward Choi and
                  Bhavna Soman and
                  Chinmaya Mishra and
                  Kate Farris and
                  Dawn Song},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {A System for Automated Open-Source Threat Intelligence Gathering and
                  Management},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2716--2720},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452745},
	doi = {10.1145/3448016.3452745},
	timestamp = {Wed, 08 Sep 2021 16:17:48 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/GaoLCSMFS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {To remain aware of the fast-evolving cyber threat landscape, open-source Cyber Threat Intelligence (OSCTI) has received growing attention from the community. Commonly, knowledge about threats is presented in a vast number of OSCTI reports. Despite the pressing need for high-quality OSCTI, existing OSCTI gathering and management platforms, however, have primarily focused on isolated, low-level Indicators of Compromise. On the other hand, higher-level concepts (e.g., adversary tactics, techniques, and procedures) and their relationships have been overlooked, which contain essential knowledge about threat behaviors that is critical to uncovering the complete threat scenario. To bridge the gap, we propose SecurityKG, a system for automated OSCTI gathering and management. SecurityKG collects OSCTI reports from various sources, uses a combination of AI and NLP techniques to extract high-fidelity knowledge about threat behaviors, and constructs a security knowledge graph. SecurityKG also provides a UI that supports various types of interactivity to facilitate knowledge graph exploration.}
}


@inproceedings{DBLP:conf/sigmod/GeorgiouPOPSH21,
	author = {Michael A. Georgiou and
                  Michael Panayiotou and
                  Lambros Odysseos and
                  Aristodemos Paphitis and
                  Michael Sirivianos and
                  Herodotos Herodotou},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Attaining Workload Scalability and Strong Consistency for Replicated
                  Databases with Hihooi},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2721--2725},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452746},
	doi = {10.1145/3448016.3452746},
	timestamp = {Sun, 19 Jan 2025 13:27:28 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/GeorgiouPOPSH21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Database replication can be employed for scaling transactional workloads while maintaining strong consistency semantics. However, past approaches suffer from various issues such as limited scalability, performance versus consistency tradeoffs, and requirements for database or application modifications. Hihooi is a new replication-based master-slave middleware system that is able to overcome the aforementioned limitations. The novelty of Hihooi lies in its modern architecture as well as its replication and transaction routing algorithms. In particular, Hihooi replicates all write statements asynchronously and applies them in parallel at the replica nodes, while ensuring replica consistency. At the same time, a fine-grained transaction routing algorithm ensures that all read transactions are load balanced to the replicas consistently. This demonstration will showcase the key functionalities of Hihooi, including (i) practical management of system components and databases (e.g., add a new replica node), (ii) increased scalability compared to state-of-the-art approaches, and (iii) support for elasticity by suspending and resuming database replicas online without service interruption.}
}


@inproceedings{DBLP:conf/sigmod/GlasbergenWD21,
	author = {Brad Glasbergen and
                  Fangyu Wu and
                  Khuzaima Daudjee},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Dendrite: Bolt-on Adaptivity for Data Systems},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2726--2730},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452755},
	doi = {10.1145/3448016.3452755},
	timestamp = {Mon, 21 Jun 2021 11:48:44 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/GlasbergenWD21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Client application workloads for data systems are known to vary in load and access patterns over time. This variability can place undue stress on data systems, tying up resources and degrading performance. To meet this challenge, systems must adapt by adjusting resource allocation and processing techniques to ameliorate contention and to deliver stable performance. We demonstrate Dendrite, a system designed to bootstrap adaptivity for data systems through its widely-applicable approach for extracting metrics, developing adaption rules, and applying them through user-defined functions to effect system behaviour changes. We highlight Dendrite's features and capabilities through a proof-of-concept implementation with the popular PostgreSQL database system.}
}


@inproceedings{DBLP:conf/sigmod/GlenisK21,
	author = {Apostolos Glenis and
                  Georgia Koutrika},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {PyExplore: Query Recommendations for Data Exploration without Query
                  Logs},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2731--2735},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452762},
	doi = {10.1145/3448016.3452762},
	timestamp = {Mon, 21 Jun 2021 11:48:44 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/GlenisK21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Helping users explore data becomes increasingly more important as databases get larger and more complex. In this demo, we present PyExplore, a data exploration tool aimed at helping end users formulate queries over new datasets. PyExplore takes as input an initial query from the user along with some parameters and provides interesting queries by leveraging data correlations and diversity.}
}


@inproceedings{DBLP:conf/sigmod/GrafbergerGSS21,
	author = {Stefan Grafberger and
                  Shubha Guha and
                  Julia Stoyanovich and
                  Sebastian Schelter},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {{MLINSPECT:} {A} Data Distribution Debugger for Machine Learning Pipelines},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2736--2739},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452759},
	doi = {10.1145/3448016.3452759},
	timestamp = {Mon, 26 Jun 2023 20:43:17 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/GrafbergerGSS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Machine Learning (ML) is increasingly used to automate impactful decisions, and the risks arising from this wide-spread use are garnering attention from policymakers, scientists, and the media. ML applications are often very brittle with respect to their input data, which leads to concerns about their reliability, accountability, and fairness. While bias detection cannot be fully automated, computational tools can help pinpoint particular types of data issues. We recently proposed mlinspect, a library that enables lightweight lineage-based inspection of ML preprocessing pipelines. In this demonstration, we show how mlinspect can be used to detect data distribution bugs in a representative pipeline. In contrast to existing work, mlinspect operates on declarative abstractions of popular data science libraries like estimator/transformer pipelines, can handle both relational and matrix data, and does not require manual code instrumentation. The library is publicly available at https://github.com/stefan-grafberger/mlinspect.}
}


@inproceedings{DBLP:conf/sigmod/HoPW21,
	author = {Vinh Thinh Ho and
                  Koninika Pal and
                  Gerhard Weikum},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {QuTE: Answering Quantity Queries from Web Tables},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2740--2744},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452763},
	doi = {10.1145/3448016.3452763},
	timestamp = {Sun, 19 Jan 2025 13:27:18 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/HoPW21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Quantities are financial, technological, physical and other measures that denote relevant properties of entities, such as revenue of companies, energy efficiency of cars or distance and brightness of stars and galaxies. Queries with filter conditions on quantities are an important building block for downstream analytics, and pose challenges when the content of interest is spread across a huge number of web tables and other ad-hoc datasets. Search engines support quantity lookups, but largely fail on quantity filters. The QuTE system presented in this paper aims to overcome these problems. It comprises methods for automatically extracting entity-quantity facts from web tables, as well as methods for online query processing, with new techniques for query matching and answer ranking.}
}


@inproceedings{DBLP:conf/sigmod/IssaBT21,
	author = {Ousmane Issa and
                  Angela Bonifati and
                  Farouk Toumani},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {{INCA:} Inconsistency-Aware Data Profiling and Querying},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2745--2749},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452760},
	doi = {10.1145/3448016.3452760},
	timestamp = {Wed, 07 Dec 2022 23:08:46 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/IssaBT21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {When exploring and querying inconsistent data, inconsistency measures referring to constraint violations can help the user to quantify the quality of the underlying data and query results. We showcase INCA, a system that allows the user to execute data profiling and query answering tasks in an inconsistency-aware fashion. By using data instances annotated with novel inconsistency measures based on why-provenance and polynomial provenance, it becomes possible to visualize the share of the data which is consistent or inconsistent with respect to one or multiple denial constraints. Furthermore, data exploration by constraint or by subset of constraints allows to inspect the tuple violations according to multifaceted criteria. Finally, query profiling allows to enable inconsistency-aware query results accounting for most (in-)consistent top-k and threshold query results. To the best of our knowledge, INCA is the first system to allow such an inconsistency-driven analysis of both data and query results. Such an analysis is especially fruitful for enabling selective constraint-based data cleaning and inconsistency-aware ranking of query results in data science pipelines, thus leading to more explainable outputs of those processes.}
}


@inproceedings{DBLP:conf/sigmod/LeeQKO21,
	author = {Doris Jung Lin Lee and
                  Abdul Quamar and
                  Eser Kandogan and
                  Fatma {\"{O}}zcan},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Boomerang: Proactive Insight-Based Recommendations for Guiding Conversational
                  Data Analysis},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2750--2754},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452748},
	doi = {10.1145/3448016.3452748},
	timestamp = {Mon, 21 Jun 2021 11:48:44 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/LeeQKO21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Natural-language interfaces are gaining popularity due to their potential to democratize access to data and insights by making the interaction with data more natural and accessible for a wide range of business users. To fully embrace the goal of democratization, it is also necessary to provide effective and continuous guidance support for data exploration. Conversational interfaces enable exploration of the data and insights search space in small incremental steps as the conversation with the data progresses. In this demo, we describe Boomerang, a system that recommends data-driven insights to guide exploration of datasets through a conversational interface. Boomerang aggregates recommendations from a variety of statistical, collaborative, and content-based recommenders, and selects insights that match closely to the user's current state of data exploration, represented as the \\em conversational context. Boomerang combines various metrics, such as \\em relevance, \\em interestingness and \\em timeliness, to rank the insights and recommends the insights based on current conversational context. In the demo, we will show how Boomerang enables guided data exploration on a sales dataset, containing information about products, retailers, sales, orders, inventory levels and regions.}
}


@inproceedings{DBLP:conf/sigmod/LiYCS021,
	author = {Yue Li and
                  Shiyu Yang and
                  Muhammad Aamir Cheema and
                  Zhou Shao and
                  Xuemin Lin},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {IndoorViz: {A} Demonstration System for Indoor Spatial Data Management},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2755--2759},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452761},
	doi = {10.1145/3448016.3452761},
	timestamp = {Mon, 21 Jun 2021 11:48:44 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/LiYCS021.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Due to the growing popularity of indoor location-based services, indoor data management has received significant research attention in the past few years. However, we observe that the existing indexing and query processing techniques for the indoor space do not fully exploit the properties of the indoor space. Consequently, they provide below par performance which makes them unsuitable for large indoor venues with high query workloads. In this demonstration, we present IndoorViz, a new indoor spatial data management system that integrates three novel index structures proposed in [4] and [6] with well designed query processing algorithms and 3D visualization functions. The IndoorViz is able to support indoor spatial object indexing, efficient query processing and interactive 3D display.}
}


@inproceedings{DBLP:conf/sigmod/MaroulisBPVV21,
	author = {Stavros Maroulis and
                  Nikos Bikakis and
                  George Papastefanatos and
                  Panos Vassiliadis and
                  Yannis Vassiliou},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {RawVis: {A} System for Efficient In-situ Visual Analytics},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2760--2764},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452764},
	doi = {10.1145/3448016.3452764},
	timestamp = {Mon, 05 Feb 2024 20:26:56 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/MaroulisBPVV21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In-situ processing has received a great deal of attention in recent years. In in-situ scenarios, big raw data files which do not fit in main memory, must be efficiently handled on-the-fly using commodity hardware, without the overhead of a preprocessing phase or the loading of data into a database system. This paper presents RawVis, an open source data visualization system for in-situ visual exploration and analytics over big raw data. RawVis implements novel indexing schemes and adaptive processing techniques allowing users to perform efficient visual and analytics operations directly over the data files. RawVis provides real-time interaction, reporting low response time, over large data files, using commodity hardware.}
}


@inproceedings{DBLP:conf/sigmod/NoceraCTKKS21,
	author = {Luciano Nocera and
                  George Constantinou and
                  Luan V. Tran and
                  Seon Ho Kim and
                  Gabriel Kahn and
                  Cyrus Shahabi},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Crosstown Foundry: {A} Scalable Data-driven Journalism Platform for
                  Hyper-local News},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2765--2769},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452751},
	doi = {10.1145/3448016.3452751},
	timestamp = {Sun, 19 Jan 2025 13:27:29 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/NoceraCTKKS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Generating hyper-local news at scale is challenging because publicly available data is not provided at the desired spatial and temporal granularity. Besides, there is a lack of automated analytical and publishing tools. Crosstown Foundry, which is being actively developed and used by engineers and journalists, is a novel data-driven system that leverages a massive multi-modal dataset to generate personalized newsletters for Los Angeles County readers.}
}


@inproceedings{DBLP:conf/sigmod/QiCZJZZX21,
	author = {Xiaodong Qi and
                  Zhihao Chen and
                  Zhao Zhang and
                  Cheqing Jin and
                  Aoying Zhou and
                  Haizhen Zhuo and
                  Quangqing Xu},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {A Byzantine Fault Tolerant Storage for Permissioned Blockchain},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2770--2774},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452744},
	doi = {10.1145/3448016.3452744},
	timestamp = {Sun, 19 Jan 2025 13:27:33 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/QiCZJZZX21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The full-replication data storage mechanism, as commonly utilized in existing blockchains, suffers from poor scalability, since it requires every node to preserve a complete copy of the whole block data locally to tolerant potential Byzantine failures. In a hostile environment, the malicious node may discard or tamper data deliberately. Thus, existing distributed storage method, which partitions data into multiple parts and distributes them over all nodes, cannot suit for blockchains. This demonstration showcases BFT-Store, a novel distributed storage engine for blockchains to break full-replication by integrating erasure coding with Byzantine Fault Tolerance (BFT) consensus protocol. This demonstration will (\\romannumeral1) allow audience members to see how BFT-Store partitions block data over all nodes to reduce the storage occupation of system, and (\\romannumeral2) allow audience members to see how BFT-Store recovers blocks under distributed scenario even with Byzantine failure.}
}


@inproceedings{DBLP:conf/sigmod/SchuleSBK021,
	author = {Maximilian E. Sch{\"{u}}le and
                  Josef Schmei{\ss}er and
                  Thomas Blum and
                  Alfons Kemper and
                  Thomas Neumann},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {TardisDB: Extending {SQL} to Support Versioning},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2775--2778},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452767},
	doi = {10.1145/3448016.3452767},
	timestamp = {Sun, 19 Jan 2025 13:27:18 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/SchuleSBK021.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Online encyclopaedias such as Wikipedia implement their own version control above database systems to manage multiple revisions of the same page. In contrast to temporal databases that restrict each tuple's validity to a time range, a version affects multiple tuples. To overcome the need for a separate version layer, we have created TardisDB, the first database system with incorporated data versioning across multiple relations. This paper presents the interface for TardisDB with an extended SQL to manage and query data from different branches. We first give an overview of TardisDB's architecture that includes an extended table scan operator: a branch bitmap indicates a tuple's affiliation to a branch and a chain of tuples tracks the different versions. This is the first database system that combines chains for multiversion concurrency control with a bitmap for each branch to enable versioning. Afterwards, we describe our proposed SQL extension to create, query and modify tables across different, named branches. In our demonstration setup, we allow users to interactively create and edit branches and display the lineage of each branch.}
}


@inproceedings{DBLP:conf/sigmod/SongMLW21,
	author = {Qi Song and
                  Hanchao Ma and
                  Peng Lin and
                  Yinghui Wu},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {{GRIP:} Constraint-based Explanation of Missing Answers for Graph
                  Queries},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2779--2783},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452758},
	doi = {10.1145/3448016.3452758},
	timestamp = {Tue, 21 Jan 2025 10:28:44 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/SongMLW21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A useful feature in graph query engines is to clarify "Why certain entities (nodes, attribute values or edges) are missing" in query answers. This task is even more challenging when the relevant data is already missing in the underlying data source. Missing data, on the other hand, can be inferred by enforcing data constraints for graphs. We demonstrate GRIP, a system that exploits data constraints to clarify missing answers for graph queries. (1) Constraint-based ex- planation. Given a desired yet missing entity in the query answer, GRIP ensures to generate finite and minimal sequences of data constraints (an "explanation") that should be consecutively enforced to to ensure its occurrence for the same query. (2) Answering ?why" and "how" questions. Users can query GRIP with both "Why" ("Why" the element is missing) and "How" questions ("How" to refine the graph to include the missing answer). GRIP engine supports run- time generation of explanations by incrementally maintaining a set of bi-directional search trees. (3) Interactive exploration. GRIP provides user-friendly GUI to support interactive ad visual exploration of explanations, including both automated generation and step-by-step inspection of graph manipulations.}
}


@inproceedings{DBLP:conf/sigmod/TianoBN21,
	author = {Donato Tiano and
                  Angela Bonifati and
                  Raymond T. Ng},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {FeatTS: Feature-based Time Series Clustering},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2784--2788},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452757},
	doi = {10.1145/3448016.3452757},
	timestamp = {Wed, 18 Dec 2024 14:00:09 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/TianoBN21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Clustering time series is a recurrent problem in real-life applications involving data science and data analytics pipelines. Existing time series clustering algorithms are ineffective for feature-rich real-world time series since they only compare the time series based on raw data or use a fixed set of features for determining the similarity. In this paper, we showcase FeatTS, a feature-based semi-supervised clustering framework addressing the above issues for variable-length and heterogeneous time series. Specifically, FeatTS leverages a graph encoding of the time series that is obtained by considering a high number of significant extracted features. It then employs community detection and builds upon a Co-Occurrence matrix in order to unify all the best clustering results. We let the user explore the various steps of FeatTS by visualizing the initial data, its graph encoding and its division into communities along with the obtained clusters. We show how the user can interact with the process for the choice of the features and for varying the percentage of input labels and the various parameters. In view of its characteristics, FeatTS outperforms the state of the art clustering methods and is the first to be able to digest domain-specific time series such as healthcare time series, while still being robust and scalable.}
}


@inproceedings{DBLP:conf/sigmod/TroullinouKLM21,
	author = {Georgia Troullinou and
                  Haridimos Kondylakis and
                  Matteo Lissandrini and
                  Davide Mottin},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {{SOFOS:} Demonstrating the Challenges of Materialized View Selection
                  on Knowledge Graphs},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2789--2793},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452765},
	doi = {10.1145/3448016.3452765},
	timestamp = {Sun, 19 Jan 2025 13:27:18 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/TroullinouKLM21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Analytical queries over RDF data are becoming prominent as a result of the proliferation of knowledge graphs. Yet, RDF databases are not optimized to perform such queries efficiently, leading to long processing times. A well known technique to improve the performance of analytical queries is to exploit materialized views.Although popular in relational databases, view materialization for RDF and SPARQL has not yet transitioned into practice, due to the non-trivial application to the RDF graph model. Motivated by a lack of understanding of the impact of view materialization alternatives for RDF data, we demonstrate Sofos, a system that implements and compares several cost models for view materialization. Sofos is, to the best of our knowledge, the first attempt to adapt cost models, initially studied in relational data, to the generic RDF setting, and to propose new ones, analyzing their pitfalls and merits. Sofos takes an RDF dataset and an analytical query for some facet in the data, and compares and evaluates alternative cost models, displaying statistics and insights about time, memory consumption, and query characteristics.}
}


@inproceedings{DBLP:conf/sigmod/WangTB21,
	author = {Junxiong Wang and
                  Immanuel Trummer and
                  Debabrota Basu},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Demonstrating {UDO:} {A} Unified Approach for Optimizing Transaction
                  Code, Physical Design, and System Parameters via Reinforcement Learning},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2794--2797},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452754},
	doi = {10.1145/3448016.3452754},
	timestamp = {Mon, 21 Jun 2021 11:48:44 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/WangTB21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {UDO is a versatile tool for offline tuning of database systems for specific workloads. UDO can consider a variety of tuning choices, reaching from picking transaction code variants over index selections up to database system parameter tuning. UDO uses reinforcement learning to converge to near-optimal configurations, creating and evaluating different configurations via actual query executions (instead of relying on simplifying cost models). To cater to different parameter types, UDO distinguishes heavy parameters (which are expensive to change, e.g. physical design parameters) from light parameters. Specifically for optimizing heavy parameters, UDO uses reinforcement learning algorithms that allow delaying the point at which reward feedback becomes available. This gives us the freedom to optimize the point in time and the order in which different configurations are created and evaluated (by benchmarking a workload sample). UDO uses a cost-based planner to minimize configuration switching overheads. For instance, it aims to amortize the creation of expensive data structures by consecutively evaluating configurations using them. We demonstrate UDO on Postgres as well as MySQL and on TPC-H as well as TPC-C, optimizing a variety of light and heavy parameters concurrently.}
}


@inproceedings{DBLP:conf/sigmod/WeiTA21,
	author = {Ziyun Wei and
                  Immanuel Trummer and
                  Connor Anderson},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Demonstrating Robust Voice Querying with {MUVE:} Optimally Visualizing
                  Results of Phonetically Similar Queries},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2798--2802},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452753},
	doi = {10.1145/3448016.3452753},
	timestamp = {Wed, 30 Nov 2022 07:34:31 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/WeiTA21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recently proposed voice query interfaces translate voice input into SQL queries. Unreliable speech recognition on top of the intrinsic challenges of text-to-SQL translation makes it hard to reliably interpret user input. We present MUVE (Multiplots for Voice quEries), a system for robust voice querying. MUVE reduces the impact of ambiguous voice queries by filling the screen with multiplots, capturing results of phonetically similar queries. It maps voice input to a probability distribution over query candidates, executes a selected subset of queries, and visualizes their results in a multiplot. Our goal is to maximize probability to show the correct query result. Also, we want to optimize the visualization (e.g., by coloring a subset of likely results) in order to minimize expected time until users find the correct result. Via a user study, we validate a simple cost model estimating the latter overhead. The resulting optimization problem is NP-hard. We propose an exhaustive algorithm, based on integer programming, as well as a greedy heuristic. As shown in a corresponding user study, MUVE enables users to identify accurate results faster, compared to prior work.}
}


@inproceedings{DBLP:conf/sigmod/WuGJC0YCTY21,
	author = {Yidi Wu and
                  Yuntao Gui and
                  Tatiana Jin and
                  James Cheng and
                  Xiao Yan and
                  Peiqi Yin and
                  Yufei Cai and
                  Bo Tang and
                  Fan Yu},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Vertex-Centric Visual Programming for Graph Neural Networks},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2803--2807},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452770},
	doi = {10.1145/3448016.3452770},
	timestamp = {Sun, 19 Jan 2025 13:27:27 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/WuGJC0YCTY21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graph neural networks (GNNs) have achieved remarkable performance in many graph analytics tasks such as node classification, link prediction and graph clustering. Existing GNN systems (e.g., PyG and DGL) adopt a tensor-centric programming model and train GNNs with manually written operators. Such design results in poor usability due to the large semantic gap between the API and the GNN models, and suffers from inferior efficiency because of high memory consumption and massive data movement. We demonstrateSeastar, a novel GNN training framework that adopts avertex-centric programming paradigm and supportsautomatic kernel generation, to simplify model development and improve training efficiency. We will (i) show how to express GNN models succinctly using a visual "drag-and-drop\'\' interface or Seastar\'s vertex-centric python API; (ii) demonstrate the performance advantage of Seastar over existing GNN systems in convergence speed, training throughput and memory consumption; and (iii) illustrate how Seastar\'s optimizations (e.g., operator fusion and constant folding) improve training efficiency by profiling the run-time performance.}
}


@inproceedings{DBLP:conf/sigmod/XiaCKHT021,
	author = {Siyuan Xia and
                  Beizhen Chang and
                  Karl Knopf and
                  Yihan He and
                  Yuchao Tao and
                  Xi He},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {DPGraph: {A} Benchmark Platform for Differentially Private Graph Analysis},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2808--2812},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3452756},
	doi = {10.1145/3448016.3452756},
	timestamp = {Wed, 01 Dec 2021 16:24:35 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/XiaCKHT021.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Differential privacy has become an appealing choice for analyzing sensitive data while offering strong privacy protection, even for complex data types like graphs. Despite a decade of academic efforts in designing differentially private algorithms for graph analysis, few works have been used in practice. This is due to their complexity in the choice of privacy guarantees and parameter/environmental configurations, or due to their scalability issues for large datasets. To bridge the gap between theory and practice, we present DPGraph, a web-based end-to-end benchmark platform built for researchers and practitioners to evaluate private algorithms on graph data. This platform supports a rich set of tunable algorithms for popular graph statistics, such as degree distribution and subgraph counting, with different differential privacy guarantees. A general framework for these algorithms has also been designed for users to tune the algorithms, by changing the sub-algorithms or re-distributing the privacy budget among the sub-algorithms. This enables users to understand the trade-off between privacy, accuracy, and performance of existing work and discover suitable algorithms for their applications.}
}


@inproceedings{DBLP:conf/sigmod/AmiriAA21a,
	author = {Mohammad Javad Amiri and
                  Divyakant Agrawal and
                  Amr El Abbadi},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Permissioned Blockchains: Properties, Techniques and Applications},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2813--2820},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457539},
	doi = {10.1145/3448016.3457539},
	timestamp = {Sun, 19 Jan 2025 13:27:27 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/AmiriAA21a.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The unique features of blockchains such as immutability, transparency, provenance, and authenticity have been used by many large-scale data management systems to deploy a wide range of distributed applications including supply chain management, healthcare, and crowdworking in permissioned settings. Unlike permissionless settings, e.g., Bitcoin, where the network is public, and anyone can participate without a specific identity, a permissioned blockchain system consists of a set of known, identified nodes that might not fully trust each other. While the characteristics of permissioned blockchains are appealing to a wide range of largescale data management systems, these systems, have to satisfy four main requirements: confidentiality, verifiability, performance, and scalability. Various approaches have been developed in industry and academia to satisfy these requirements with varying assumptions and costs. The focus of this tutorial is on presenting many of these techniques while highlighting the trade-offs among them. We demonstrate the practicality of such techniques in real-life by presenting three different applications, i.e., supply chain management, large-scale databases, and multi-platform crowdworking environments, and show how those techniques can be utilized to meet the requirements of such applications.}
}


@inproceedings{DBLP:conf/sigmod/ArenasGS21,
	author = {Marcelo Arenas and
                  Claudio Gutierrez and
                  Juan F. Sequeda},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Querying in the Age of Graph Databases and Knowledge Graphs},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2821--2828},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457545},
	doi = {10.1145/3448016.3457545},
	timestamp = {Mon, 03 Mar 2025 21:21:49 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/ArenasGS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graphs have become the best way we know of representing knowledge. The computing community has investigated and developed the support for managing graphs by means of digital technology. Graph databases and knowledge graphs surface as the most successful solutions to this program. This tutorial will provide a conceptual map of the data management tasks underlying these developments, paying particular attention to data models and query languages for graphs}
}


@inproceedings{DBLP:conf/sigmod/FangW0021,
	author = {Yixiang Fang and
                  Kai Wang and
                  Xuemin Lin and
                  Wenjie Zhang},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Cohesive Subgraph Search over Big Heterogeneous Information Networks:
                  Applications, Challenges, and Solutions},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2829--2838},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457538},
	doi = {10.1145/3448016.3457538},
	timestamp = {Sun, 12 Nov 2023 02:07:18 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/FangW0021.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the advent of a wide spectrum of recent applications, querying heterogeneous information networks (HINs) has received a great deal of attention from both academic and industrial societies. HINs involve objects (vertices) and links (edges) that are classified into multiple types; examples include bibliography networks, knowledge networks, and user-item networks in E-business. An important component of these HINs is the cohesive subgraph, or a subgraph containing vertices that are densely connected internally. Searching cohesive subgraphs over HINs has found many real applications, such as community search, product recommendation, fraud detection, and so on. Consequently, how to design effective cohesive subgraph models and how to efficiently search cohesive subgraphs on large HINs become important research topics in the era of big data. In this tutorial, we first highlight the importance of cohesive subgraph search over HINs in various applications and the unique challenges that need to be addressed. Subsequently, we conduct a thorough review of existing works of cohesive subgraph search over HINs. Then, we analyze and compare the models and solutions in these works. Finally, we point out new research directions. We believe that this tutorial not only helps researchers to have a better understanding of existing cohesive subgraph search models and solutions, but also provides them insights for future study.}
}


@inproceedings{DBLP:conf/sigmod/0001RBMW021,
	author = {Xi He and
                  Jennie Rogers and
                  Johes Bater and
                  Ashwin Machanavajjhala and
                  Chenghong Wang and
                  Xiao Wang},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Practical Security and Privacy for Database Systems},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2839--2845},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457544},
	doi = {10.1145/3448016.3457544},
	timestamp = {Sun, 19 Jan 2025 13:27:24 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/0001RBMW021.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Computing technology has enabled massive digital traces of our personal lives to be collected and stored. These datasets play an important role in numerous real-life applications and research analysis, such as contact tracing for COVID 19, but they contain sensitive information about individuals. When managing these datasets, privacy is usually addressed as an afterthought, engineered on top of a database system optimized for performance and usability. This has led to a plethora of unexpected privacy attacks in the news. Specialized privacy-preserving solutions usually require a group of privacy experts and they are not directly transferable to other domains. There is an urgent need for a generally trustworthy database system that offers end-to-end security and privacy guarantees. In this tutorial, we will first describe the security and privacy requirements for database systems in different settings and cover the state-of-the-art tools that achieve these requirements. We will also show challenges in integrating these techniques together and demonstrate the design principles and optimization opportunities for these security and privacy-aware database systems. This is designed to be a three hour tutorial.}
}


@inproceedings{DBLP:conf/sigmod/Katsogiannis-Meimarakis21,
	author = {George Katsogiannis{-}Meimarakis and
                  Georgia Koutrika},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {A Deep Dive into Deep Learning Approaches for Text-to-SQL Systems},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2846--2851},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457543},
	doi = {10.1145/3448016.3457543},
	timestamp = {Sun, 19 Jan 2025 13:27:27 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/Katsogiannis-Meimarakis21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Data is a prevalent part of every business and scientific domain,but its explosive volume and increasing complexity make data querying challenging even for experts. For this reason, numerous text-to-SQL systems have been developed that enable querying relational databases using natural language. The recent advances on deep neural networks along with the creation of two large datasets specifically made for training text-to-SQL systems, have paved the path for a novel and very promising research area. The purpose of this tutorial is a deep dive into this area, covering state-of-the-art techniques for natural language representation in neural networks,benchmarks that sparked research and competition, recent text-to-SQL systems using deep learning techniques, as well as open problems and research opportunities.}
}


@inproceedings{DBLP:conf/sigmod/LernerB21,
	author = {Alberto Lerner and
                  Philippe Bonnet},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Not your Grandpa's {SSD:} The Era of Co-Designed Storage Devices},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2852--2858},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457540},
	doi = {10.1145/3448016.3457540},
	timestamp = {Sun, 19 Jan 2025 13:27:27 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/LernerB21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Gone is the time when a Solid-State Drive (SSD) was just a fast drop-in replacement for a Hard-Disk Drive (HDD). Thanks to the NVMe ecosystem, nowadays, SSDs are accessed through specific interfaces and modern I/O frameworks. SSDs have also grown versatile with time and can now support various use cases ranging from cold, high-density storage to hot, low-latency ones. The body of knowledge about building such different devices is mostly available, but it is less than accessible to non-experts. Finding which device variation can better support a given workload also requires deep domain knowledge. This tutorial's first goal is to make these tasks--understanding the design of SSDs and pairing them with the data-intensive workloads they support well--more inviting. The tutorial goes further, however, in that it suggests that a new kind of SSD plays an essential role in post-Moore computer systems. These devices can be co-designed to align their capabilities to an application's requirements. A salient feature of these devices is that they can run application logic besides just storing data. They can thus gracefully scale processing capabilities with the volume of data stored. The tutorial's second goal is thus to establish the design space for co-designed SSDs and show the tools available to hardware, systems, and databases researchers that wish to explore this space.}
}


@inproceedings{DBLP:conf/sigmod/0001ZC21,
	author = {Guoliang Li and
                  Xuanhe Zhou and
                  Lei Cao},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {{AI} Meets Database: {AI4DB} and {DB4AI}},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2859--2866},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457542},
	doi = {10.1145/3448016.3457542},
	timestamp = {Sun, 19 Jan 2025 13:27:20 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/0001ZC21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Database and Artificial Intelligence (AI) can benefit from each other. On one hand, AI can make database more intelligent (AI4DB). For example, traditional empirical database optimization techniques (e.g., cost estimation, join order selection, knob tuning, index and view advisor) cannot meet the high-performance requirement for large-scale database instances, various applications and diversified users, especially on the cloud. Fortunately, learning-based techniques can alleviate this problem. On the other hand, database techniques can optimize AI models (DB4AI). For example, AI is hard to deploy, because it requires developers to write complex codes and train complicated models. Database techniques can be used to reduce the complexity of using AI models, accelerate AI algorithms and provide AI capability inside databases. DB4AI and AI4DB have been extensively studied recently. In this tutorial, we review existing studies on AI4DB and DB4AI. For AI4DB, we review the techniques on learning-based database configuration, optimization, design, monitoring, and security. For DB4AI, we review AI-oriented declarative language, data governance, training acceleration, and inference acceleration. Finally, we provide research challenges and future directions in AI4DB and DB4AI.}
}


@inproceedings{DBLP:conf/sigmod/WasayCI21,
	author = {Abdul Wasay and
                  Subarna Chatterjee and
                  Stratos Idreos},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Deep Learning: Systems and Responsibility},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2867--2875},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457541},
	doi = {10.1145/3448016.3457541},
	timestamp = {Mon, 21 Jun 2021 11:48:44 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/WasayCI21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Deep learning enables numerous applications across diverse areas. Data systems researchers are also increasingly experimenting with deep learning to enhance data systems performance. We present a tutorial on deep learning, highlighting the data systems nature of neural networks as well as research opportunities for advancements through data management techniques. We focus on three critical aspects: (1) classic design tradeoffs in neural networks which we can enrich through a systems and data management perspective, e.g., thinking critically about storage, data movement, and computation; (2) classic design problems in data systems which we can reconsider with neural networks as a viable design option, e.g., to replace or help system components that make complex decisions such as database optimizers; and (3) essential considerations for responsible application of neural networks in critical human-facing problems in society and how these also link to data management and performance considerations. While these are seemingly a diverse set of rich topics, they are strongly interconnected through data management, and their combination offers rich opportunities for future research.}
}


@inproceedings{DBLP:conf/sigmod/Amer-YahiaR21,
	author = {Sihem Amer{-}Yahia and
                  Senjuti Basu Roy},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Data Management to Social Science and Back in the Future of Work},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2876--2877},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457536},
	doi = {10.1145/3448016.3457536},
	timestamp = {Mon, 21 Jun 2021 11:48:44 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/Amer-YahiaR21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {How will we work, live, and thrive in the post-pandemic future? The rapid mushrooming of online job markets has been transforming the definition of work and workplaces. After the pandemic, as we "cope with the new normal", the future world of work may change forever and become predominantly virtual. This makes an unprecedented pool of talent available at our beck and calls to work on "gigs" that disband when the job is over; this also is the time of destabilization and changing nature of job security. As scientists, we have a big responsibility and a tremendous opportunity in shaping the Future of Work (FoW) post pandemic, by designing effective platforms that support productive employment, mitigate social costs, and provide an effective and safe learning environment. A research agenda for FoW must mobilize the participation of various scientific, regulatory and miscellaneous stakeholders [10]. We will ask the questions: what is the role of Data Management (DM) in shaping research on FoW? Is now a ripe time to get Economics, Labor Theory, Psychology of Work and AI to help put DM research and technology at the center of research on FoW? Are we at all interested? The panelists will debate two complementary views: A pessimistic view on whether FoW will tend to see humans as machines, robots, or low-level agents and use them in the service of broader AI goals vs. a more optimistic view, where AI and Social Science will help DM to develop technologies that empower humans for future workforce and workplaces.}
}


@inproceedings{DBLP:conf/sigmod/Kumar21,
	author = {Arun Kumar},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Automation of Data Prep, ML, and Data Science: New Cure or Snake Oil?},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2878--2880},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3457537},
	doi = {10.1145/3448016.3457537},
	timestamp = {Thu, 02 Sep 2021 10:55:58 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/Kumar21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As machine learning (ML), artificial intelligence (AI), and Data Science grow in practical importance, a large part of the ML/AI software industry claims to have built tools and platforms to automate the entire workflow of ML. That includes vexing problems of data preparation (prep), studied intensively by the database (DB) community for decades, with basically no resolution so far. Such claims by the ML/AI industry face a stunning lack of scientific scrutiny from the DB and ML research worlds, largely due to the lack of meaningful, large, and objective benchmarks. As such tools rapidly gain adoption among enterprises and other customers, this panel will debate whether the new ML/AI industry is basically selling "snake oil" to such users, how to evolve away from the status quo by instituting meaningful new benchmarks, creating new partnerships between industry and academia for this, and other pressing questions in this important arena. We aim to spur vigorous conversations that will hopefully lead to genuine new cures for an age-old affliction in Data Science.}
}


@inproceedings{DBLP:conf/sigmod/Alipourlangouri21,
	author = {Morteza Alipour Langouri},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Temporal Dependencies for Graphs},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2881--2883},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3450586},
	doi = {10.1145/3448016.3450586},
	timestamp = {Sun, 19 Jan 2025 13:27:17 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/Alipourlangouri21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graphs are increasingly being used to model information about entities, their properties, and relationships between entities. Examples include relationships between customers, their product purchases, and inter-relationships between products. Many of these graphs are not static, and operate in dynamic data environments. Large-scale knowledge bases such as DBpedia, Yago, Wikidata, and Amazon product graphs operate in such dynamic environments, where Entities in these temporal graphs are constantly changing. Having accurate and complete information is critical for downstream decision making and fact checking. Data dependencies help us to preserve accuracy of the data and have been well studied for relational data and static graphs. However, the need for FDs is also evident for temporal graphs since they specify the semantic of the data to detect inconsistencies.}
}


@inproceedings{DBLP:conf/sigmod/Helal21,
	author = {Ahmed Helal},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Data Lakes Empowered by Knowledge Graph Technologies},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2884--2886},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3450584},
	doi = {10.1145/3448016.3450584},
	timestamp = {Sun, 19 Jan 2025 13:27:21 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/Helal21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the emergence of open data, governments [19, 25], Kaggle [13], OpenML [26], and organizations [2, 20] have started making data available on the web. This data represents an opportunity for Artificial Intelligence (AI) practitioners to accomplish their tasks including but not limited to improving the performance of models in Machine Learning or predicting insights about the future in Scenario Planning. However with the proliferation of available data, finding the most relevant one is time-consuming and cumbersome. Practitioners tend to spend considerable time looking for data to enrich their existing datasets to accomplish their tasks. For instance, in Deep Learning, engineers need a lot of data to train their models [27]. Moreover, they face several problems such as increasing the size of their datasets with similar data or including more features that can contribute to better results [3, 8, 27]. These problems emerge because data lakes are schema-agnostic repositories [30].}
}


@inproceedings{DBLP:conf/sigmod/Jahangiri21,
	author = {Shiva Jahangiri},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Wisconsin Benchmark Data Generator: To {JSON} and Beyond},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2887--2889},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3450577},
	doi = {10.1145/3448016.3450577},
	timestamp = {Sun, 19 Jan 2025 13:27:19 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/Jahangiri21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Benchmarks have always been one of the greatest assets in evaluating a Data Management System (DBMS) performance and providing a standard way to compare different DBMSs from various angles. As DBMSs evolve over time, new benchmarks are created, and the older ones need to advance and adapt in order to continue to be a valid and capable comparison tool. Many of the standard benchmarks use synthetic data and as such may not be able to capture the complexity of real data and its relationships correctly. The Wisconsin Benchmark was one of the first and main benchmarking tools made four decades ago by Dewitt et al at the University of Wisconsin. One of the most powerful features of this benchmark is that its relations are designed so their structure and distribution of attributes is easy to understand and control. While the Wisconsin Benchmark was a very powerful and widely-used benchmark years ago, it is given less attention in current studies. We believe that the Wisconsin Benchmark and its carefully designed relations can be utilized and provide capabilities that are unique and useful. In this paper, we present a flexible, easy-to-use and scalable JSON Data Generator implemented in java based on the Wisconsin Benchmark Data Generator description, with more advanced features to provide relations and attributes closer to real-world data. Attribute skewness and variable length records using different size distributions are some of these newly added features. It is a ready-to-use, parameterized, and scalable data generator tool that since its development has been used in several AsterixDB's [4] performance benchmarking and publications [13,14,17,18], and we believe that can be useful to many others. The source code and more information are provided at [1].}
}


@inproceedings{DBLP:conf/sigmod/Knopf21,
	author = {Karl Knopf},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Framework for Differentially Private Data Analysis with Multiple Accuracy
                  Requirements},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2890--2892},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3450587},
	doi = {10.1145/3448016.3450587},
	timestamp = {Mon, 21 Jun 2021 11:48:44 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/Knopf21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Organizations who collect sensitive data, such as hospitals or governments, may want to share the data with others. There could be multiple applications or analysts that want to use this data. Directly releasing the data could violate the privacy of individual data contributors. To address this privacy concern, differential privacy [1,2] has arisen as a popular technique for allow for sensitive data analysis. It frequently works through the addition of randomized noise to the output of the analysis, which is controlled through the privacy parameter or budget ε. This noise affects the utility of the analyses, where a smaller budget allocation results in larger noise values, and some applications may set accuracy requirements on the output to restrict the amount of noise added [3,9,10]. The total privacy loss of a sequence of differentially private mechanisms can be composed by summing up the privacy budgets they use, under the property of sequential composition [2]. Hence, if we intend to run multiple applications or analyses on the same dataset, given a total privacy budget, we can support each application by splitting the privacy budget evenly among them. However, if there are many applications, the privacy budget received per application could be very small, resulting in poor overall utility.}
}


@inproceedings{DBLP:conf/sigmod/Kosyfaki21,
	author = {Chrysanthi Kosyfaki},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Flow Provenance in Temporal Interaction Networks},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2893--2895},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3450581},
	doi = {10.1145/3448016.3450581},
	timestamp = {Tue, 21 Mar 2023 20:57:32 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/Kosyfaki21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In temporal interaction networks, such as financial transaction networks, vertices model entities which exchange quantities (e.g., money) over time. We study the problem of identifying the origin of the quantities that flow into the vertices of the network over time. We consider various models of flow relay, which are related to different application scenarios and develop corresponding techniques for flow provenance.}
}


@inproceedings{DBLP:conf/sigmod/Lai21,
	author = {Ziliang Lai},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Efficient Deterministic Concurrency Control Under Practical Isolation
                  Levels},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2896--2898},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3450580},
	doi = {10.1145/3448016.3450580},
	timestamp = {Mon, 21 Jun 2021 11:48:44 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/Lai21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Deterministic databases are able to run transactions efficiently in a distributed setting with minimal coordination. Research has shown many benefits from having determinism, from more lightweight database replication, to no/cheaper distributed commit, to high throughput during live migration. Besides those known applications, permissioned blockchain can also be viewed as an application of the deterministic database with security added. A permissioned blockchain maintains a fully-replicated database, where each replica is synchronized by getting blocks of updates. Early permissioned blockchains run a consensus protocol (e.g., PBFT) to agree on the input and rely on the replicas to execute the transactions serially to uphold determinism. Fabric allows concurrent transaction executions but rely on running consensus to agree on the read-write-sets and broadcasting them, which incurs an excessive volume of network traffic. Deterministic concurrency control combines the best of both worlds. It enables solving consensus on the small input, and each replica is able to execute transactions independently with high concurrency. Although powerful, contemporary deterministic databases are still primitive because they support only one isolation level -- Serializable. Furthermore, many deterministic concurrency control schemes are overly pessimistic and cause many unnecessary transaction aborts. These factors motivate us to design DCC, a suite of better deterministic concurrency control schemes, not only for Serializable but also for practical isolation levels beyond Serializable.}
}


@inproceedings{DBLP:conf/sigmod/Li21,
	author = {Side Li},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Grouped Learning: Group-By Model Selection Workloads},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2899--2901},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3450576},
	doi = {10.1145/3448016.3450576},
	timestamp = {Mon, 21 Jun 2021 11:48:44 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/Li21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Machine Learning (ML) is gaining popularity in many applications. Increasingly, companies prefer more targeted models for different subgroups of the population like locations, which helps improve accuracy. This practice is comparable to Group-By aggregation in SQL; we call it learning over groups. A smaller group means the data distribution is more straightforward than the whole population. So, a group-level model may offer more accuracy in many cases. Non-technical business needs, such as privacy and regulatory compliance, may also necessitate group-level models. For instance, online advertising platforms would need to build disaggregated partner-specific ML models, where all partner groups' training data are aggregated together in one data pipeline.}
}


@inproceedings{DBLP:conf/sigmod/Shanghooshabad21,
	author = {Ali Mohammadi Shanghooshabad},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {XLJoins},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2902--2904},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3450582},
	doi = {10.1145/3448016.3450582},
	timestamp = {Mon, 21 Jun 2021 11:48:44 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/Shanghooshabad21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In many analytic settings join operations are fundamental as data is dispersed across different data sets (SQL or NoSQL tables, .csv files recording logs, click streams, KPIs from system/network monitoring, IoT telemetry, etc). However, in the era of big data the join operation can become exorbitantly expensive in terms of execution times and/or memory/space footprints.}
}


@inproceedings{DBLP:conf/sigmod/Singla21,
	author = {Samriddhi Singla},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Raptor: Large Scale Processing of Big Raster + Vector Data},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2905--2907},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3450585},
	doi = {10.1145/3448016.3450585},
	timestamp = {Mon, 21 Jun 2021 11:48:44 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/Singla21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {There has been an increase in the amount of spatial data in the recent years due to the advancements in remote sensing technology and the widespread use of smart phones and GPS technology. This has resulted in petabytes of satellite imagery as well as highly accurate geographical features such as city boundaries, roads, and others being made publicly available. Spatial data can generally be modeled in two representations: raster and vector. Satellite imagery is an example of raster data and is usually represented in form of multi-dimensional arrays. Vector data is represented as a set of points, lines, and polygons, and is used to represent geographical features such as regional boundaries. The growth of geospatial data has helped in new scientific discoveries in a wide range of applications that require combining raster and vector data. However, traditional systems implement algorithms that work with either raster or vector data. This paper proposes a novel approach for the concurrent processing of raster and vector data.}
}


@inproceedings{DBLP:conf/sigmod/Zhao21,
	author = {Zhanhao Zhao},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Efficiently Supporting Adaptive Multi-Level Serializability Models
                  in Distributed Database Systems},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2908--2910},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3450579},
	doi = {10.1145/3448016.3450579},
	timestamp = {Sun, 19 Jan 2025 13:27:26 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/Zhao21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Informally, serializability means that transactions appear to have occurred in some total order. In this paper, we show that only the serializability guarantee with some total order is not enough for many real applications. As a complement, extra partial orders of transactions, like real-time order and program order, need to be introduced. Motivated by this observation, we present a framework that models serializable transactions by adding extra partial orders, namely multi-level serializability models. Following this framework, we propose a novel concurrency control algorithm, called bi-directionally timestamp adjustment (BDTA), to supporting multi-level serializability models in distributed database systems. We integrate the framework and BDTA into Greenplum and Deneva to show the benefits of our work. Our experiments show the performance gaps among serializability levels and confirm BDTA achieves up to 1.7× better than state-of-the-art concurrency control algorithms.}
}


@inproceedings{DBLP:conf/sigmod/Zheng21,
	author = {Zheng Zheng},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Contextual Data Cleaning with Ontology FDs},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2911--2913},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3450583},
	doi = {10.1145/3448016.3450583},
	timestamp = {Mon, 03 Mar 2025 21:21:51 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/Zheng21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Functional Dependencies (FDs) define attribute relationships based on syntactic equality, and, when used in data cleaning, they erroneously label syntactically different but semantically equivalent values as errors. We motivate the need to include context in data cleaning in order to account for the subjective nature of data quality. We enhance dependency-based data cleaning with Ontology Functional Dependencies (OFDs), which express semantic attribute relationships such as synonyms and is-a hierarchies defined by an ontology. We study the data and ontology repair problem for a set of OFDs, and propose an algorithm that finds the best ontological interpretation of the data that minimizes the number of repairs.}
}


@inproceedings{DBLP:conf/sigmod/Zhu21,
	author = {Xuliang Zhu},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Data Summarization with Hierarchical Taxonomy},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2914--2916},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3450578},
	doi = {10.1145/3448016.3450578},
	timestamp = {Sun, 02 Oct 2022 16:15:22 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/Zhu21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Data summarization has wide applications in real world, e.g. attributes filter, image set labeling and personalized recommendation. In this work, we study a new problem HSD to summarize a dataset using k concepts in a hierarchical taxonomy. Different from the existed works of whole hierarchy summarization, we focus on the accurate coverage of the given query set Q. The objective is to cover more items in Q and less items not in Q. To tackle it, we first propose a dynamic programming based algorithm on the tree hierarchy, which is a simple instance of HSD problem. Furthermore, we propose a heuristic method to assign the vertex to one of its in-neighbors for HDAGs and apply the tree algorithm on it. The experimental results confirm the quality of our methods on both tree and HDAG datasets.}
}


@inproceedings{DBLP:conf/sigmod/Edian21,
	author = {Ikraduya Edian},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Accelerating Product Quantization Query Execution Runtime},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2917--2919},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3450574},
	doi = {10.1145/3448016.3450574},
	timestamp = {Mon, 21 Jun 2021 11:48:44 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/Edian21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Product Quantization is a method for approximate nearest neighbor search. I review and analyze two recent SIMD-based query acceleration techniques and propose an algorithmic solution agnostic to the underlying hardware. This new method is competitive in terms of runtime to the SIMD-based methods and alleviates their drawbacks: reduced accuracy and limited encoding bit budget configurations.}
}


@inproceedings{DBLP:conf/sigmod/Gemawat21,
	author = {Advitya Gemawat},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {GraphGem: Optimized Scalable System for Graph Convolutional Networks},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2920--2922},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3450573},
	doi = {10.1145/3448016.3450573},
	timestamp = {Mon, 21 Jun 2021 11:48:44 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/Gemawat21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Deep Learning (DL), especially Graph Convolutional Networks (GCNs) have revolutionized several domains and applications dealing with unstructured data with non-euclidean and graphical relationships. Constructing large-scale Deep GCNs, however, are bottlenecked by glaring systems issues due to memory blow-ups, runtime slowdowns with random access, and I/O costs. This research abstract identifies various systems and scalability issues and proposes a novel system called GraphGem to handle GCN-centric DL tasks end-to-end. GraphGem tackles the bottlenecks by elevating entire GCN workloads for convenient input declarations by the user, and is inspired by lessons from the databases and machine learning systems worlds. This abstract also highlights the bigger picture of the potential research impact alongside tacking systems constraints and what it may mean for data science and deep learning practitioners going forward.}
}


@inproceedings{DBLP:conf/sigmod/Guo21,
	author = {Demi Guo},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Learning Algorithms for Automatic Data Structure Design},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2923--2925},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3450570},
	doi = {10.1145/3448016.3450570},
	timestamp = {Mon, 21 Jun 2021 11:48:44 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/Guo21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We present practical learning-based search algorithms that make it possible to automatically design key-value data structures. Our work allows searching within a space of 10100 possible designs for the optimal data structure. The input is a workload specification and the output is an abstract syntax tree which can be absorbed by modern code-generation techniques. Given the vast design space our solution is based on learning and we show that it can find the close to optimal data structure design in a matter of a few seconds.}
}


@inproceedings{DBLP:conf/sigmod/LiPW21,
	author = {Zhaoheng Li and
                  Xinyu Pi and
                  Mingyuan Wu},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Subteam Replacement: Problem Definition and Fast Solution},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2926--2928},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3450575},
	doi = {10.1145/3448016.3450575},
	timestamp = {Sun, 19 Jan 2025 13:27:32 +0100},
	biburl = {https://dblp.org/rec/conf/sigmod/LiPW21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In settings such as corporate management where team structure is highly volatile and large-scale personnel changes are commonplace, the ability to simultaneously replace multiple team members in a team is highly appreciated. We define the problem of Subteam Replacement to address this observation: given a team of people embedded in a social network to complete a certain task, and a subset of members - subteam - in this team which has become unavailable, find another set of people which can perform the subteam's role in the larger team. We propose a holistic evaluation metric and scalable solution for Subteam Replacement with strong theoretical guarantees and perform quantitative evaluations on both generated and real datasets.}
}


@inproceedings{DBLP:conf/sigmod/Nagrecha21,
	author = {Kabir Nagrecha},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Model-Parallel Model Selection for Deep Learning Systems},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2929--2931},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3450571},
	doi = {10.1145/3448016.3450571},
	timestamp = {Mon, 21 Jun 2021 11:48:44 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/Nagrecha21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As deep learning becomes more expensive, both in terms of time and compute, inefficiencies in machine learning training prevent practical usage of state-of-the-art models for most users. The newest model architectures are simply too large to be fit onto a single processor. To address the issue, many ML practitioners have turned to model parallelism as a method of distributing the computational requirements across several devices. Unfortunately, the sequential nature of neural networks causes very low efficiency and device utilization in model parallel training jobs. We propose a new form of "shard parallelism" combining task parallelism and model parallelism, and package it into a framework we name Hydra. Hydra recasts the problem of model parallelism in the multi-model context to produce a fine-grained parallel workload of independent model shards, rather than independent models. This new parallel design promises dramatic speedups relative to the traditional model parallelism paradigm.}
}


@inproceedings{DBLP:conf/sigmod/Pocol21,
	author = {Sergiu Pocol},
	editor = {Guoliang Li and
                  Zhanhuai Li and
                  Stratos Idreos and
                  Divesh Srivastava},
	title = {Index-Based Join Size Estimation Using Adaptive Sampling},
	booktitle = {{SIGMOD} '21: International Conference on Management of Data, Virtual
                  Event, China, June 20-25, 2021},
	pages = {2932--2933},
	publisher = {{ACM}},
	year = {2021},
	url = {https://doi.org/10.1145/3448016.3450572},
	doi = {10.1145/3448016.3450572},
	timestamp = {Mon, 21 Jun 2021 11:48:44 +0200},
	biburl = {https://dblp.org/rec/conf/sigmod/Pocol21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cost-based query optimizers rely on cardinality estimates of intermediate results to avoid suboptimal query execution plans. However, when confronted with ad-hoc queries on big data, said optimizers can produce large estimation errors, resulting in drastic decreases in overall performance. Such errors occur because many estimation algorithms for joins make use of strong independence and uniformity assumptions. Moreover, equi-joins on skewed data with filter predicates tend to cause the aforementioned assumptions to fail [2]. Since the cardinality estimate of a result with many joins depends on estimates of the underlying joins, it has been shown that improving the accuracy of join size estimates in a "bottom-up" order can significantly improve performance [2]. Thus, our research aims at improving the estimation of two-table join sizes. Certain join size estimation approaches that use offline samples fare poorly with filtering and can suffer from insufficient sample size [2]. Alternatively, query optimizers may make use of persisted histograms. However, the associated storage space is a large deterrent, as is the case with persisting offline samples [4]. In turn, algorithms have been presented wherein adaptive, block-level sampling is conducted during query optimization [5]. To the best of our knowledge, there is no algorithm for two-table join size estimation that 1) samples filtered base tables, 2) makes use exclusively of persisted counts in B+-tree indexes and 3) attempts to provide statistical confidence on estimates. In this paper, we present and evaluate a novel join size estimation algorithm prototyped on SAP IQ. Our algorithm can be easily incorporated into query optimizers that utilize bottom-up enumeration and evaluate filter predicates prior to optimization. In contrast with existing machine learning based approaches [1], the algorithm is simpler to implement or derive from existing support for sampling. Join size estimates are produced using a combination of variance-based calculations from Oracle 12c [5] along with the usage of persisted counts in indexes from index-based sampling [2]. In doing so, the amount of sampling conducted is minimized until either a parameterized budget is surpassed or there is sufficient statistical confidence in an estimate. On a subset of industry-standard benchmark queries involving joins on skewed data, our method improved the overall execution time by 16%. Amongst queries with execution plans altered by our estimates, the mean percentage improvement in individual execution time was 34%.}
}
