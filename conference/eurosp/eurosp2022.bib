@inproceedings{DBLP:conf/eurosp/MooreCLNS22,
	author = {Kristen Moore and
                  Cody James Christopher and
                  David Liebowitz and
                  Surya Nepal and
                  Renee Selvey},
	title = {Modelling direct messaging networks with multiple recipients for cyber
                  deception},
	booktitle = {7th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2022, Genoa, Italy, June 6-10, 2022},
	pages = {1--19},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/EuroSP53844.2022.00009},
	doi = {10.1109/EUROSP53844.2022.00009},
	timestamp = {Sun, 12 Feb 2023 18:48:35 +0100},
	biburl = {https://dblp.org/rec/conf/eurosp/MooreCLNS22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cyber deception is the practice of deliberately introducing fake or misleading artefacts into cyber systems. It is emerging as a promising approach to defending networks and systems against attackers and data thieves. However, despite being relatively cheap to deploy [1], the generation of realistic content at scale is very costly when it is hand-crafted. With recent improvements in Machine Learning, we now have the opportunity to bring scale and automation to the creation of realistic and enticing simulated content. In this work, we propose a framework to automate the generation of email and instant messaging-style group communications at scale. Such messaging platforms within organisations contain a lot of valuable information inside private communications and document attachments, making them an enticing target for an adversary. The presence of an active messaging platform also enhances the realism of a deceptive network simulation, contributing both traffic and message artefacts. We address two key aspects of simulating this type of system: modelling when and with whom participants communicate, and generating topical, multi-party text to populate simulated conversation threads. We present the LogNormMix-Net Temporal Point Process as an approach to the first of these, building upon the intensity-free modeling approach of Shchur et al. [2] to create a generative model for unicast and multi-cast communications. We demonstrate the use of fine-tuned, pretrained language models to generate convincing multi-party conversation threads. A live email server is simulated by uniting our LogNormMix-Net TPP (to generate the communication timestamp, sender and recipients) with the language model, which generates the contents of the multi-party email threads. We evaluate the generated content with respect to a number of realism-based properties, that encourage a model to learn to generate content that will engage the attention of an adversary to achieve a deception outcome. Our simulations run in real time, making them suitable for deployment in cyber deception as a honeypot in its own right, or as part of a larger deception environment.}
}


@inproceedings{DBLP:conf/eurosp/ApruzzeseLT22,
	author = {Giovanni Apruzzese and
                  Pavel Laskov and
                  Aliya Tastemirova},
	title = {SoK: The Impact of Unlabelled Data in Cyberthreat Detection},
	booktitle = {7th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2022, Genoa, Italy, June 6-10, 2022},
	pages = {20--42},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/EuroSP53844.2022.00010},
	doi = {10.1109/EUROSP53844.2022.00010},
	timestamp = {Wed, 07 Dec 2022 23:07:47 +0100},
	biburl = {https://dblp.org/rec/conf/eurosp/ApruzzeseLT22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Machine learning (ML) has become an important paradigm for cyberthreat detection (CTD) in the recent years. A substantial research effort has been invested in the development of specialized algorithms for CTD tasks. From the operational perspective, however, the progress of ML-based CTD is hindered by the difficulty in obtaining the large sets of labelled data to train ML detectors. A potential solution to this problem are semisupervised learning (SsL) methods, which combine small labelled datasets with large amounts of unlabelled data. This paper is aimed at systematization of existing work on SsL for CTD and, in particular, on understanding the utility of unlabelled data in such systems. To this end, we analyze the cost of labelling in various CTD tasks and develop a formal cost model for SsL in this context. Building on this foundation, we formalize a set of requirements for evaluation of SsL methods, which elucidates the contribution of unlabelled data. We review the state-of-the-art and observe that no previous work meets such requirements. To address this problem, we propose a framework for assessing the benefits of unlabelled data in SsL. We showcase an application of this framework by performing the first benchmark evaluation that highlights the tradeoffs of 9 existing SsL methods on 9 public datasets. Our findings verify that, in some cases, unlabelled data provides a small, but statistically significant, performance gain. This paper highlights that SsL in CTD has a lot of room for improvement, which should stimulate future research in this field.}
}


@inproceedings{DBLP:conf/eurosp/LeeTTYRD22,
	author = {Jehyun Lee and
                  Farren Tang and
                  Phyo May Thet and
                  Desmond Yeoh and
                  Mitch Rybczynski and
                  Dinil Mon Divakaran},
	title = {{SIERRA:} Ranking Anomalous Activities in Enterprise Networks},
	booktitle = {7th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2022, Genoa, Italy, June 6-10, 2022},
	pages = {44--59},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/EuroSP53844.2022.00011},
	doi = {10.1109/EUROSP53844.2022.00011},
	timestamp = {Wed, 29 Jun 2022 16:03:24 +0200},
	biburl = {https://dblp.org/rec/conf/eurosp/LeeTTYRD22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {An enterprise today deploys multiple security middleboxes such as firewalls, IDS, IPS, etc. in its network to collect different kinds of events related to threats and attacks. These events are streamed into a SIEM (Security Information and Event Management) system for analysts to investigate and respond quickly with appropriate actions. However, the number of events collected for a single enterprise can easily run into hundreds of thousands per day, much more than what analysts can investigate under a given budget constraint (time). In this work, we look into the problem of prioritizing suspicious events or anomalies to analysts for further investigation. We develop SIERRA, a system that processes event logs from multiple and diverse middleboxes to detect and rank anomalous activities. SIERRA takes an unsupervised approach and therefore has no dependence on ground truth data. Different from other works, SIERRA defines contexts, that help it to provide visual explanations of highly-ranked anomalous points to analysts, despite employing unsupervised models. We evaluate SIERRA using months of logs from multiple security middleboxes of an enterprise network. The evaluations demonstrate the capability of SIERRA to detect top anomalies in a network while outperforming naive application of existing anomaly detection algorithms as well as a state-of-the-art SIEM-based anomaly detection solution.}
}


@inproceedings{DBLP:conf/eurosp/CochardPDH22,
	author = {Victor Cochard and
                  Damian Pfammatter and
                  Chi Thang Duong and
                  Mathias Humbert},
	title = {Investigating Graph Embedding Methods for Cross-Platform Binary Code
                  Similarity Detection},
	booktitle = {7th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2022, Genoa, Italy, June 6-10, 2022},
	pages = {60--73},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/EuroSP53844.2022.00012},
	doi = {10.1109/EUROSP53844.2022.00012},
	timestamp = {Wed, 29 Jun 2022 16:03:24 +0200},
	biburl = {https://dblp.org/rec/conf/eurosp/CochardPDH22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {IoT devices are increasingly present, both in the industry and in consumer markets, but their security remains weak, which leads to an unprecedented number of attacks against them. In order to reduce the attack surface, one approach is to analyze the binary code of these devices to early detect whether they contain potential security vulnerabilities. More specifically, knowing some vulnerable function, we can determine whether the firmware of an IoT device contains some security flaw by searching for this function. However, searching for similar vulnerable functions is in general challenging due to the fact that the source code is often not openly available and that it can be compiled for different architectures, using different compilers and compilation settings. In order to handle these varying settings, we can compare the similarity between the graph embeddings derived from the binary functions. In this paper, inspired by the recent advances in deep learning, we propose a new method – GESS (graph embeddings for similarity search) – to derive graph embeddings, and we compare it with various state-of-the-art methods. Our empirical evaluation shows that GESS reaches an AUC of 0.979, thereby outperforming the best known approach. Furthermore, for a fixed low false positive rate, GESS provides a true positive rate (or recall) about 36% higher than the best previous approach. Finally, for a large search space, GESS provides a recall between 50% and 60% higher than the best previous approach.}
}


@inproceedings{DBLP:conf/eurosp/HeJH22,
	author = {Haoyu He and
                  Yuede Ji and
                  H. Howie Huang},
	title = {Illuminati: Towards Explaining Graph Neural Networks for Cybersecurity
                  Analysis},
	booktitle = {7th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2022, Genoa, Italy, June 6-10, 2022},
	pages = {74--89},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/EuroSP53844.2022.00013},
	doi = {10.1109/EUROSP53844.2022.00013},
	timestamp = {Wed, 29 Jun 2022 16:03:24 +0200},
	biburl = {https://dblp.org/rec/conf/eurosp/HeJH22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graph neural networks (GNNs) have been utilized to create multi-layer graph models for a number of cybersecurity applications from fraud detection to software vulnerability analysis. Unfortunately, like traditional neural networks, GNNs also suffer from a lack of transparency, that is, it is challenging to interpret the model predictions. Prior works focused on specific factor explanations for a GNN model. In this work, we have designed and implemented Illuminati, a comprehensive and accurate explanation framework for cybersecurity applications using GNN models. Given a graph and a pre-trained GNN model, Illuminati is able to identify the important nodes, edges, and attributes that are contributing to the prediction while requiring no prior knowledge of GNN models. We evaluate Illuminati in two cybersecurity applications, i.e., code vulnerability detection and smart contract vulnerability detection. The experiments show that Illuminati achieves more accurate explanation results than state-of-the-art methods, specifically, 87.6% of subgraphs identified by Illuminati are able to retain their original prediction, an improvement of 10.3% over others at 77.3%. Furthermore, the explanation of Illuminati can be easily understood by the domain experts, suggesting the significant usefulness for the development of cybersecurity applications.}
}


@inproceedings{DBLP:conf/eurosp/KamaraKMSTY22,
	author = {Seny Kamara and
                  Abdelkarim Kati and
                  Tarik Moataz and
                  Thomas Schneider and
                  Amos Treiber and
                  Michael Yonli},
	title = {SoK: Cryptanalysis of Encrypted Search with {LEAKER} - {A} framework
                  for LEakage AttacK Evaluation on Real-world data},
	booktitle = {7th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2022, Genoa, Italy, June 6-10, 2022},
	pages = {90--108},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/EuroSP53844.2022.00014},
	doi = {10.1109/EUROSP53844.2022.00014},
	timestamp = {Sun, 02 Oct 2022 16:00:59 +0200},
	biburl = {https://dblp.org/rec/conf/eurosp/KamaraKMSTY22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {An encrypted search algorithm (ESA) allows a user to encrypt its data while preserving the ability to search over it. As all practical solutions leak some information, cryptanalysis plays an important role in the area of encrypted search. Starting with the work of Islam et al. (NDSS'12), many attacks have been proposed that exploit different leakage profiles under various assumptions. While these attacks improve our understanding of leakage, it can sometimes be difficult to draw definite conclusions about their practical performance. This is due to several reasons, including a lack of open-source implementations (which are needed to reproduce results), empirical evaluations that are conducted on restricted datasets, and in some cases reliance on relatively strong assumptions that can significantly affect accuracy. In this work, we address these limitations. First, we design and implement LEAKER, an open-source framework that evaluates the major leakage attacks against any dataset and that we hope will serve the community as a common way to evaluate leakage attacks. We identify new real-world datasets that capture different use cases for ESAs and, for the first time, include real-world user queries. Finally, we use LEAKER to systematically evaluate known attacks on our datasets, uncovering sometimes unexpected properties that increase or diminish accuracy. Our evaluation shows that some attacks work better on real-world data than previously thought and that others perform worse.}
}


@inproceedings{DBLP:conf/eurosp/YangHKD22,
	author = {Yibin Yang and
                  David Heath and
                  Vladimir Kolesnikov and
                  David Devecsery},
	title = {{EZEE:} Epoch Parallel Zero Knowledge for {ANSI} {C}},
	booktitle = {7th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2022, Genoa, Italy, June 6-10, 2022},
	pages = {109--123},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/EuroSP53844.2022.00015},
	doi = {10.1109/EUROSP53844.2022.00015},
	timestamp = {Thu, 25 Apr 2024 07:39:21 +0200},
	biburl = {https://dblp.org/rec/conf/eurosp/YangHKD22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recent work has produced interactive Zero Knowledge (ZK) proof systems that can express proofs as arbitrary C programs (Heath et al., 2021, henceforth referred to as ZEE); these programs can be executed by a simulated ZK processor that runs in the 10KHz range. In this work, we demonstrate that such proof systems are amenable to high degrees of parallelism. Our epoch parallelism-based approach allows the prover and verifier to divide the ZK proof into pieces such that each piece can be executed on a different machine. These proof snippets can then be glued together, and the glued parallel proofs are equivalent to the original sequential proof. We implemented and we experimentally evaluate an epoch parallel version of the ZEE proof system. By running the prover and verifier each across 31 2-core machines, we achieve a ZK processor that runs at up to 394KHz. This allowed us to run a benchmark involving the Linux program bzip2, which would have required at least 11 days with the former ZEE system, in only 8.5 hours.}
}


@inproceedings{DBLP:conf/eurosp/AlmashaqbehS22,
	author = {Ghada Almashaqbeh and
                  Ravital Solomon},
	title = {SoK: Privacy-Preserving Computing in the Blockchain Era},
	booktitle = {7th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2022, Genoa, Italy, June 6-10, 2022},
	pages = {124--139},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/EuroSP53844.2022.00016},
	doi = {10.1109/EUROSP53844.2022.00016},
	timestamp = {Wed, 29 Jun 2022 16:03:24 +0200},
	biburl = {https://dblp.org/rec/conf/eurosp/AlmashaqbehS22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Privacy is a huge concern for cryptocurrencies and blockchains as most of these systems log everything in the clear. This has resulted in several academic and industrial initiatives to address privacy. Starting with the UTXO model of Bitcoin, initial works brought confidentiality and anonymity to payments. Recent works have expanded to support more generalized forms of private computation. Such solutions tend to be highly involved as they rely on advanced cryptographic primitives and creative techniques to handle issues related to dealing with private records (e.g. concurrency and double spending). This situation makes it hard to comprehend the current state-of-the-art, much less build on top of it. To address these challenges, we develop a systematization of knowledge for privacy-preserving solutions in blockchain. To the best of our knowledge, our work is the first of its kind. After motivating design challenges, we devise two systematization frameworks-the first as a stepping stone to the second- and use them to study the state-of-the-art. For our first framework, we study the zero-knowledge proof systems used in surveyed solutions, based on their key features and limitations. Our second is for privacy-preserving solutions; we define several dimensions to categorize the surveyed schemes and, in doing so, identify two major paradigms employed to achieve private computation. We go on to provide insights to guide solutions' adoption and development. Finally, we touch upon challenges related to limited functionality and accommodating new developments.}
}


@inproceedings{DBLP:conf/eurosp/FangBLZPP22,
	author = {Vivian Fang and
                  Lloyd Brown and
                  William Lin and
                  Wenting Zheng and
                  Aurojit Panda and
                  Raluca Ada Popa},
	title = {CostCO: An automatic cost modeling framework for secure multi-party
                  computation},
	booktitle = {7th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2022, Genoa, Italy, June 6-10, 2022},
	pages = {140--153},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/EuroSP53844.2022.00017},
	doi = {10.1109/EUROSP53844.2022.00017},
	timestamp = {Wed, 29 Jun 2022 16:03:24 +0200},
	biburl = {https://dblp.org/rec/conf/eurosp/FangBLZPP22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The last decade has seen an explosion in the number of new secure multi-party computation (MPC) protocols that enable collaborative computation on sensitive data. No single MPC protocol is optimal for all types of computation. As a result, researchers have created hybrid-protocol compilers that translate a program into a hybrid protocol that mixes different MPC protocols. Hybrid-protocol compilers crucially rely on accurate cost models, which are handwritten by the compilers' developers, to choose the correct schedule of protocols. In this paper, we propose CostCO, the first automatic MPC cost modeling framework. CostCO develops a novel API to interface with a variety of MPC protocols, and leverages domain-specific properties of MPC in order to enable efficient and automatic cost-model generation for a wide range of MPC protocols. CostCO employs a two-phase experiment design to efficiently synthesize cost models of the MPC protocol's runtime as well as its memory and network usage. We verify CostCO's modeling accuracy for several full circuits, characterize the engineering effort required to port existing MPC protocols, and demonstrate how hybrid-protocol compilers can leverage CostCO's cost models.}
}


@inproceedings{DBLP:conf/eurosp/PatersonR22,
	author = {Kenneth G. Paterson and
                  Mathilde Raynal},
	title = {HyperLogLog: Exponentially Bad in Adversarial Settings},
	booktitle = {7th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2022, Genoa, Italy, June 6-10, 2022},
	pages = {154--170},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/EuroSP53844.2022.00018},
	doi = {10.1109/EUROSP53844.2022.00018},
	timestamp = {Wed, 29 Jun 2022 16:03:24 +0200},
	biburl = {https://dblp.org/rec/conf/eurosp/PatersonR22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Computing the count of distinct elements in large data sets is a common task but naive approaches are memory-expensive. The HyperLogLog (HLL) algorithm (Flajolet et al., 2007) estimates a data set's cardinality while using significantly less memory than a naive approach, at the cost of some accuracy. This trade-off makes the HLL algorithm very attractive for a wide range of applications such as database management and network monitoring, where an exact count may not be needed. The HLL algorithm and variants of it are implemented in systems such as Redis and Google Big Query. Recently, the HLL algorithm has started to be proposed for use in scenarios where the inputs may be adversarially generated, for example counting social network users or detection of network scanning attacks. This prompts an examination of the performance of the HLL algorithm in the face of adversarial inputs. We show that in such a setting, the HLL algorithm's estimate of cardinality can be exponentially bad: when an adversary has access to the internals of the HLL algorithm and has some flexibility in choosing what inputs will be recorded, it can manipulate the cardinality estimate to be exponentially smaller than the true cardinality. We study both the original HLL algorithm and a more modern version of it (Ertl, 2017) that is used in Redis. We present experimental results confirming our theoretical analysis. Finally, we consider attack prevention: we show how to modify HLL in a simple way that provably prevents cardinality estimate manipulation attacks.}
}


@inproceedings{DBLP:conf/eurosp/XuYWLHMDZL22,
	author = {Huikai Xu and
                  Miao Yu and
                  Yanhao Wang and
                  Yue Liu and
                  Qinsheng Hou and
                  Zhenbang Ma and
                  Haixin Duan and
                  Jianwei Zhuge and
                  Baojun Liu},
	title = {Trampoline Over the Air: Breaking in IoT Devices Through {MQTT} Brokers},
	booktitle = {7th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2022, Genoa, Italy, June 6-10, 2022},
	pages = {171--187},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/EuroSP53844.2022.00019},
	doi = {10.1109/EUROSP53844.2022.00019},
	timestamp = {Wed, 29 Jun 2022 16:03:24 +0200},
	biburl = {https://dblp.org/rec/conf/eurosp/XuYWLHMDZL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {MQTT is widely adopted by IoT devices because it allows for the most efficient data transfer over a variety of communication lines. The security of MQTT has received increasing attention in recent years, and several studies have demonstrated the configurations of many MQTT brokers are insecure. Adversaries are allowed to exploit vulnerable brokers and publish malicious messages to subscribers. However, little has been done to understanding the security issues on the device side when devices handle unauthorized MQTT messages. To fill this research gap, we propose a fuzzing framework named ShadowFuzzer to find client-side vulnerabilities when processing incoming MQTT messages. To avoiding ethical issues, ShadowFuzzer redirects traffic destined for the actual broker to a shadow broker under the control to monitor vulnerabilities. We select 15 IoT devices communicating with vulnerable brokers and leverage ShadowFuzzer to find vulnerabilities when they parse MQTT messages. For these devices, ShadowFuzzer reports 34 zero-day vulnerabilities in 11 devices. We evaluated the exploitability of these vulnerabilities and received a total of 44,000 USD bug bounty rewards. And 16 CVE/CNVD/CN-NVD numbers have been assigned to us.}
}


@inproceedings{DBLP:conf/eurosp/ChangCLL22,
	author = {Deliang Chang and
                  Joann Qiongna Chen and
                  Zhou Li and
                  Xing Li},
	title = {Hide and Seek: Revisiting DNS-based User Tracking},
	booktitle = {7th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2022, Genoa, Italy, June 6-10, 2022},
	pages = {188--205},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/EuroSP53844.2022.00020},
	doi = {10.1109/EUROSP53844.2022.00020},
	timestamp = {Sat, 30 Sep 2023 09:40:48 +0200},
	biburl = {https://dblp.org/rec/conf/eurosp/ChangCLL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Domain name system (DNS) is the address book of the Internet and domain names are queried before almost every network activity. Since the entities like recursive resolvers can monitor users' DNS queries, privacy concerns such as user tracking arise. Though a number of prior works have looked into this issue, they all focus on the closed-world setting, which means that victim users must be known to the adversary. We argue that it does not reflect the adversary's true capabilities. Moreover, there lacks an effective approach to defend against DNS-based user tracking. In this work, we revisit these issues by investigating the attack surface in both open-world and closed-world settings and studying how to protect users. First, we introduce a new tracking mechanism DSCorr which incorporates domain-based word embedding to capture the fine-grained distance between domain names, and automatic threshold generation for fine-tuning the attack outcome. The evaluation result on a real-world DNS dataset shows DSCorr is able to outperform the existing works by a large margin especially in the open-world setting. On the defense side, we develop a system called LDPResolve, which incorporates a recently proposed differential privacy notion ULDP (Utility-optimized Local Differential Privacy) and a new technique named parallel domain resolving, to provide privacy guarantees without damaging the utility of legitimate applications. The evaluation result on the same dataset shows the DNS-based user tracking can be effectively curbed, e.g., tracking accuracy degraded from 93% to 10.1%.}
}


@inproceedings{DBLP:conf/eurosp/SprecherKK22,
	author = {Steven Sprecher and
                  Christoph Kerschbaumer and
                  Engin Kirda},
	title = {SoK: All or Nothing - {A} Postmortem of Solutions to the Third-Party
                  Script Inclusion Permission Model and a Path Forward},
	booktitle = {7th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2022, Genoa, Italy, June 6-10, 2022},
	pages = {206--222},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/EuroSP53844.2022.00021},
	doi = {10.1109/EUROSP53844.2022.00021},
	timestamp = {Wed, 29 Jun 2022 16:03:24 +0200},
	biburl = {https://dblp.org/rec/conf/eurosp/SprecherKK22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The web execution model allows third-party JavaScript to be leveraged in a single execution context. Access control for these scripts is currently all or nothing. It has been this way for over a decade despite the knowledge that this model allows for privacy violations and even user data exfiltration. Consequently, users have little to no control over which third-parties operate on their Personally Identifying Information (PII) when interacting with a web application. In this work we aim to explain the lack of solutions to this problem, and to suggest more promising future directions. We first survey past proposed solutions and their trade-offs. We then create a monitoring system in the Firefox browser which captures third-party script access to user supplied PII in HTML Form Elements. We proceed to inspect 100,000 websites with our Monitor and custom web crawler to highlight the complexity of use cases of third-party scripts operating on user PII. Our findings inform the creation of a grading rubric and systematization for solutions in this space, which we then apply to many previous works. The complexity exposed through this effort allows us to start a discussion around why current technological and policy solutions fail adoption. Ultimately we propose a research direction that allows web applications to take advantage of the interoperability of the web execution model while also respecting an end user's privacy and security.}
}


@inproceedings{DBLP:conf/eurosp/DionysiouA22,
	author = {Antreas Dionysiou and
                  Elias Athanasopoulos},
	title = {Lethe: Practical Data Breach Detection with Zero Persistent Secret
                  State},
	booktitle = {7th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2022, Genoa, Italy, June 6-10, 2022},
	pages = {223--235},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/EuroSP53844.2022.00022},
	doi = {10.1109/EUROSP53844.2022.00022},
	timestamp = {Tue, 21 Mar 2023 20:57:33 +0100},
	biburl = {https://dblp.org/rec/conf/eurosp/DionysiouA22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Honeywords are false passwords associated with each user account. Using a honeyword to login sets off an alarm as a data breach has been detected. Existing approaches for detecting data breaches using honeywords suffer from the need of a trusted component to tell honey-words from the valid password. Once this trusted component is compromised, then honeywords can offer no assistance for mitigating or detecting a data breach. In this paper, we present Lethe, a honeywords-based data-breach detection system that requires no trusted components, other than a trusted bootstrap, and keeps limited transient state for verifying login attempts. Lethe is based on two fundamental principles. First, Lethe generates honeywords using a Machine Learning (ML) model, which constantly evolves. This means that an attacker that compromises the Honeyword Generation Technique (HGT) cannot reproduce the same set of honeywords, and thus cannot tell which password was used as the initial generator. In particular, Lethe is the first system that allows an attacker to fully compromise the HGT without affecting the security of already generated honeywords. Second, Lethe is not aware of the valid password. In fact, for Lethe the only one that knows the actual password is the user that selected it in the first place. Lethe records login events, but without storing anywhere the password used. These login events can be further replayed in another server, which can check if, for a particular user, there were at least two different passwords used and therefore detect a data breach. Lethe allows the detection of a data breach deterministically and not probabilistically as similar approaches do. Additionally, Lethe allows detecting data breaches that are associated with rarely used accounts. Lethe can signal an alarm even if a user account that has logged in just once with the system is compromised. This is in contrast to other efforts that require legitimate users to authenticate with the system, after the attacker has done so, for detecting the breach. To demonstrate the effectiveness of Lethe, we provide a fully functional prototype, along with the ML-based HGT, and assess the provided security with a set of diverse attackers.}
}


@inproceedings{DBLP:conf/eurosp/KleinBBSJ22,
	author = {David Klein and
                  Thomas Barber and
                  Souphiane Bensalim and
                  Ben Stock and
                  Martin Johns},
	title = {Hand Sanitizers in the Wild: {A} Large-scale Study of Custom JavaScript
                  Sanitizer Functions},
	booktitle = {7th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2022, Genoa, Italy, June 6-10, 2022},
	pages = {236--250},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/EuroSP53844.2022.00023},
	doi = {10.1109/EUROSP53844.2022.00023},
	timestamp = {Tue, 28 May 2024 16:28:36 +0200},
	biburl = {https://dblp.org/rec/conf/eurosp/KleinBBSJ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Despite the considerable amounts of resources invested into securing the Web, Cross-Site Scripting (XSS) is still widespread. This is especially true for Client-Side XSS as, unlike server-side application frameworks, Web browsers do not ship with standard protection routines, so-called sanitizers. Web developers, therefore, have to either resort to third-party libraries or write their own sanitizers to stop XSS in its tracks. Such custom sanitizer routines – dubbed hand sanitizers in the following – are notoriously difficult to implement securely. In this paper, we present a technique to automatically detect, extract, analyze, and validate JavaScript sanitizer functions using a combination of taint tracking and symbolic string analysis. While existing work evaluates server-side sanitizers using a small number of applications, we present the first large-scale study of client-side JavaScript sanitizers. Of the most popular 20,000 websites, our method detects 705 unique sanitizers across 1,415 domains, of which 12.5% are insecure. Of the vulnerable sanitizers, we were able to automatically generate circumventing exploits for 51.3% of them, highlighting the dangers of manual sanitization attempts. Interestingly, vulnerable sanitizers are present across the entire range of website rankings considered, and we find that most sanitizers are not generic enough to thwart XSS if used in just a slightly different context. Finally, we explore the origins of vulnerable sanitizers to motivate adopting a standardized sanitization API available directly in the browser.}
}


@inproceedings{DBLP:conf/eurosp/AlhanahnahJRJR22,
	author = {Mohannad Alhanahnah and
                  Rithik Jain and
                  Vaibhav Rastogi and
                  Somesh Jha and
                  Thomas W. Reps},
	title = {Lightweight, Multi-Stage, Compiler-Assisted Application Specialization},
	booktitle = {7th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2022, Genoa, Italy, June 6-10, 2022},
	pages = {251--269},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/EuroSP53844.2022.00024},
	doi = {10.1109/EUROSP53844.2022.00024},
	timestamp = {Wed, 29 Jun 2022 16:03:24 +0200},
	biburl = {https://dblp.org/rec/conf/eurosp/AlhanahnahJRJR22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Program debloating aims to enhance the performance and reduce the attack surface of bloated applications. Several techniques have been recently proposed to specialize programs. These approaches are either based on unsound strategies or demanding techniques, leading to unsafe results or a high-overhead debloating process. In this paper, we address these limitations by applying partial-evaluation principles to generate specialized applications. Our approach relies on a simple observation that an application typically consists of configuration logic, followed by the main logic of the program. The configuration logic specifies what functionality in the main logic should be executed. LMCAS performs partial interpretation to capture a precise program state of the configuration logic based on the supplied inputs. LMCAS then applies partial-evaluation optimizations to generate a specialized program by propagating the constants in the captured partial state, eliminating unwanted code, and preserving the desired functionalities. Our evaluation of LMCAS-on commonly used benchmarks and real-world applications-shows that it successfully removes unwanted features while preserving the functionality and robustness of the debloated programs, runs faster than prior tools, and reduces the attack surface of specialized programs. LMCAS runs 1500x, 4.6x, and 1.2x faster than the state-of-the-art debloating tools CHISEL, RAZOR, and OCCAM, respectively; achieves 25% reduction in the binary size; demonstrates favorable gadgets elimination trade-off; and eliminates 87.5% of the known CVE vulnerabilities in our test corpus.}
}


@inproceedings{DBLP:conf/eurosp/SideYZ22,
	author = {Mert Side and
                  Fan Yao and
                  Zhenkai Zhang},
	title = {LockedDown: Exploiting Contention on Host-GPU PCIe Bus for Fun and
                  Profit},
	booktitle = {7th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2022, Genoa, Italy, June 6-10, 2022},
	pages = {270--285},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/EuroSP53844.2022.00025},
	doi = {10.1109/EUROSP53844.2022.00025},
	timestamp = {Wed, 29 Jun 2022 16:03:24 +0200},
	biburl = {https://dblp.org/rec/conf/eurosp/SideYZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The deployment of modern graphics processing units (GPUs) has grown rapidly in both traditional and cloud computing. Nevertheless, the potential security issues brought forward by this extensive deployment have not been thoroughly investigated. In this paper, we disclose a new exploitable side-channel vulnerability that ubiquitously exists in systems equipped with modern GPUs. This vulnerability is due to measurable contention caused on the host-GPU PCIe bus. To demonstrate the exploitability of this vulnerability, we conduct two case studies. In the first case study, we exploit the vulnerability to build a cross-VM covert channel that works on virtualized NVIDIA GPUs. To the best of our knowledge, this is the first work that explores covert channel attacks under the circumstances of virtualized GPUs. The covert channel can reach a speed up to 90 kbps with a considerably low error rate. In the second case study, we exploit the vulnerability to mount a website fingerprinting attack that can accurately infer which web pages are browsed by a user. The attack is evaluated against popular browsers like Chrome and Firefox on both Windows and Linux, and the results show that this fingerprinting method can achieve up to 95.2% accuracy. In addition, the attack is evaluated against Tor browser, and up to 90.6% accuracy can be achieved.}
}


@inproceedings{DBLP:conf/eurosp/MantovaniFB22,
	author = {Alessandro Mantovani and
                  Andrea Fioraldi and
                  Davide Balzarotti},
	title = {Fuzzing with Data Dependency Information},
	booktitle = {7th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2022, Genoa, Italy, June 6-10, 2022},
	pages = {286--302},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/EuroSP53844.2022.00026},
	doi = {10.1109/EUROSP53844.2022.00026},
	timestamp = {Wed, 29 Jun 2022 16:03:24 +0200},
	biburl = {https://dblp.org/rec/conf/eurosp/MantovaniFB22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recent advances in fuzz testing have introduced several forms of feedback mechanisms, motivated by the fact that for a large range of programs and libraries, edgecoverage alone is insufficient to reveal complicated bugs. Inspired by this line of research, we examined existing program representations looking for a match between expressiveness of the structure and adaptability to the context of fuzz testing. In particular, we believe that data dependency graphs (DDGs) represent a good candidate for this task, as the set of information embedded by this data structure is potentially useful to find vulnerable constructs by stressing combinations of def-use pairs that would be difficult for a traditional fuzzer to trigger. Since some portions of the dependency graph overlap with the control flow of the program, it is possible to reduce the additional instrumentation to cover only “interesting” data-flow dependencies, those that help the fuzzer to visit the code in a distinct way compared to standard methodologies. To test these observations, in this paper we propose DDFuzz, a new approach that rewards the fuzzer not only with code coverage information, but also when new edges in the data dependency graph are hit. Our results show that the adoption of data dependency instrumentation in coverage-guided fuzzing is a promising solution that can help to discover bugs that would otherwise remain unexplored by standard coverage approaches. This is demonstrated by the 72 different vulnerabilities that our data-dependency driven approach can identify when executed on 38 target programs from three different datasets.}
}


@inproceedings{DBLP:conf/eurosp/ThudiDCP22,
	author = {Anvith Thudi and
                  Gabriel Deza and
                  Varun Chandrasekaran and
                  Nicolas Papernot},
	title = {Unrolling {SGD:} Understanding Factors Influencing Machine Unlearning},
	booktitle = {7th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2022, Genoa, Italy, June 6-10, 2022},
	pages = {303--319},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/EuroSP53844.2022.00027},
	doi = {10.1109/EUROSP53844.2022.00027},
	timestamp = {Wed, 29 Jun 2022 16:03:24 +0200},
	biburl = {https://dblp.org/rec/conf/eurosp/ThudiDCP22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Machine unlearning is the process through which a deployed machine learning model is made to forget about some of its training data points. While naively retraining the model from scratch is an option, it is almost always associated with large computational overheads for deep learning models. Thus, several approaches to approximately unlearn have been proposed along with corresponding metrics that formalize what it means for a model to forget about a data point. In this work, we first taxonomize approaches and metrics of approximate unlearning. As a result, we identify verification error, i.e., the \\ell_{2}\ndifference between the weights of an approximately unlearned and a naively retrained model, as an approximate unlearning metric that should be optimized for as it subsumes a large class of other metrics. We theoretically analyze the canonical training algorithm, stochastic gradient descent (SGD), to surface the variables which are relevant to reducing the verification error of approximate unlearning for SGD. From this analysis, we first derive an easy-to-compute proxy for verification error (termed unlearning error). The analysis also informs the design of a new training objective penalty that limits the overall change in weights during SGD and as a result facilitates approximate unlearning with lower verification error. We validate our theoretical work through an empirical evaluation on learning with CIFAR-10, CIFAR-100, and IMDB sentiment analysis.}
}


@inproceedings{DBLP:conf/eurosp/BattisP22,
	author = {Verena Battis and
                  Alexander Penner},
	title = {Transformer-based Extraction of Deep Image Models},
	booktitle = {7th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2022, Genoa, Italy, June 6-10, 2022},
	pages = {320--336},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/EuroSP53844.2022.00028},
	doi = {10.1109/EUROSP53844.2022.00028},
	timestamp = {Wed, 29 Jun 2022 16:03:24 +0200},
	biburl = {https://dblp.org/rec/conf/eurosp/BattisP22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Model extraction attacks pose a threat to the security of ML models and to the privacy of the data used for training. Previous research has shown that such attacks can be either monetarily motivated to gain an edge over competitors or maliciously in order to mount subsequent attacks on the extracted model. In this paper, recent advances in the field of transformers are exploited to propose an attack tailored to the task of image classification that allows stealing complex convolutional neural network models without any knowledge of their architecture. The attack was performed on a range of datasets and target architectures to evaluate the robustness of the proposed attack. With only 100k queries, we were able to recover up to 99.2% of the black-box target network's accuracy on the test set. We conclude that it is possible to effectively steal complex neural networks with relatively little expertise and conventional means – even without knowledge of the target's architecture. Recently proposed defences have also been examined for their effectiveness in preventing the attack proposed in this paper.}
}


@inproceedings{DBLP:conf/eurosp/PatwariHWHSC22,
	author = {Kartik Patwari and
                  Syed Mahbub Hafiz and
                  Han Wang and
                  Houman Homayoun and
                  Zubair Shafiq and
                  Chen{-}Nee Chuah},
	title = {{DNN} Model Architecture Fingerprinting Attack on {CPU-GPU} Edge Devices},
	booktitle = {7th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2022, Genoa, Italy, June 6-10, 2022},
	pages = {337--355},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/EuroSP53844.2022.00029},
	doi = {10.1109/EUROSP53844.2022.00029},
	timestamp = {Wed, 29 Jun 2022 16:03:24 +0200},
	biburl = {https://dblp.org/rec/conf/eurosp/PatwariHWHSC22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Embedded systems for edge computing are getting more powerful, and some are equipped with a GPU to enable on-device deep neural network (DNN) learning tasks such as image classification and object detection. Such DNN-based applications frequently deal with sensitive user data, and their architectures are considered intellectual property to be protected. We investigate a potential avenue of fingerprinting attack to identify the (running) DNN model architecture family (out of state-of-the-art DNN categories) on CPU-GPU edge devices. We exploit a stealthy analysis of aggregate system-level side-channel information such as memory, CPU, and GPU usage available at the user-space level. To the best of our knowledge, this is the first attack of its kind that does not require physical access and/or sudo access to the victim device and only collects the system traces passively, as opposed to most of the existing reverse-engineering-based DNN model architecture extraction attacks. We perform feature selection analysis and supervised machine learning-based classification to detect the model architecture. With a combination of RAM, CPU, and GPU features and a Random Forest-based classifier, our proposed attack classifies a known DNN model into its model architecture family with 99% accuracy. Also, the introduced attack is so transferable that it can detect an unknown DNN model into the right DNN architecture category with 87.2% accuracy. Our rigorous feature analysis illustrates that memory usage (RAM) is a critical feature for such fingerprinting. Furthermore, we successfully replicate this attack on two different CPU-GPU platforms and observe similar experimental results that exhibit the capability of platform portability of the attack. Also, we investigate the robustness of the proposed attack to varying background noises and a modified DNN pipeline. Besides, we exhibit that the leakage of model architecture family information from this stealthy attack can strengthen an adversarial attack against a victim DNN model by 2×.}
}


@inproceedings{DBLP:conf/eurosp/SunWWW22,
	author = {Haipei Sun and
                  Kun Wu and
                  Ting Wang and
                  Wendy Hui Wang},
	title = {Towards Fair and Robust Classification},
	booktitle = {7th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2022, Genoa, Italy, June 6-10, 2022},
	pages = {356--376},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/EuroSP53844.2022.00030},
	doi = {10.1109/EUROSP53844.2022.00030},
	timestamp = {Mon, 05 Feb 2024 20:31:17 +0100},
	biburl = {https://dblp.org/rec/conf/eurosp/SunWWW22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Robustness and fairness are two equally important issues for machine learning systems. Despite the active research on robustness and fairness of ML recently, these efforts focus on either fairness or robustness, but not both. To bridge this gap, in this paper, we design Fair and Robust Classification (FRoC) models that equip the classification models with both fairness and robustness. Meeting both fairness and robustness constraints is not trivial due to the tension between them. The trade-off between fairness, robustness, and model accuracy also introduces additional challenge. To address these challenges, we design two FRoC methods, namely FRoC-PRE that modifies the input data before model training, and FRoC-IN that modifies the model with an adversarial objective function to address both fairness and robustness during training. FRoC-IN is suitable to the settings where the users (e.g., ML service providers) only have the access to the model but not the original data, while FRoC-PRE works for the settings where the users (e.g., data owners) have the access to both data and a surrogate model that may have similar architecture as the target model. Our extensive experiments on real-world datasets demonstrate that both FRoC-IN and FRoC-PRE can achieve both fairness and robustness with insignificant accuracy loss of the target model.}
}


@inproceedings{DBLP:conf/eurosp/SturgessESM22,
	author = {Jack Sturgess and
                  Simon Eberz and
                  Ivo Sluganovic and
                  Ivan Martinovic},
	title = {WatchAuth: User Authentication and Intent Recognition in Mobile Payments
                  using a Smartwatch},
	booktitle = {7th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2022, Genoa, Italy, June 6-10, 2022},
	pages = {377--391},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/EuroSP53844.2022.00031},
	doi = {10.1109/EUROSP53844.2022.00031},
	timestamp = {Wed, 29 Jun 2022 16:03:24 +0200},
	biburl = {https://dblp.org/rec/conf/eurosp/SturgessESM22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we show that the tap gesture, performed when a user ‘taps’ a smartwatch onto an NFC-enabled terminal to make a payment, is a biometric capable of implicitly authenticating the user and simultaneously recognising intent-to-pay. The proposed system can be deployed purely in software on the watch without requiring updates to payment terminals. It is agnostic to terminal type and position and the intent recognition portion does not require any training data from the user. To validate the system, we conduct a user study (n=16) to collect wrist motion data from users as they interact with payment terminals and to collect long-term data from a subset of them (\nn=9\n) as they perform daily activities. Based on this data, we identify optimum gesture parameters and develop authentication and intent recognition models, for which we achieve EERs of 0.08 and 0.04, respectively.}
}


@inproceedings{DBLP:conf/eurosp/RodriguezFPEG22,
	author = {Elsa Turcios Rodriguez and
                  Max Fukkink and
                  Simon Parkin and
                  Michel van Eeten and
                  Carlos Ga{\~{n}}{\'{a}}n},
	title = {Difficult for Thee, But Not for Me: Measuring the Difficulty and User
                  Experience of Remediating Persistent IoT Malware},
	booktitle = {7th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2022, Genoa, Italy, June 6-10, 2022},
	pages = {392--409},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/EuroSP53844.2022.00032},
	doi = {10.1109/EUROSP53844.2022.00032},
	timestamp = {Wed, 17 Jan 2024 10:29:48 +0100},
	biburl = {https://dblp.org/rec/conf/eurosp/RodriguezFPEG22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Consumer IoT devices may suffer malware attacks, and be recruited into botnets or worse. There is evidence that generic advice to device owners to address IoT malware can be successful, but this does not account for emerging forms of persistent IoT malware. Less is known about persistent malware, which resides on persistent storage, requiring targeted manual effort to remove it. This paper presents a field study on the removal of persistent IoT malware by consumers. We partnered with an ISP to contrast remediation times of 760 customers across three malware categories: Windows malware, non-persistent IoT malware, and persistent IoT malware. We also contacted ISP customers identified as having persistent IoT malware on their network-attached storage devices, specifically QSnatch. We found that persistent IoT malware exhibits a mean infection duration many times higher than Windows or Mirai malware; QSnatch has a survival probability of 30% after 180 days, whereby most if not all other observed malware types have been removed. For interviewed device users, QSnatch infections lasted longer, so are apparently more difficult to get rid of, yet participants did not report experiencing difficulty in following notification instructions. We see two factors driving this paradoxical finding: First, most users reported having high technical competency. Also, we found evidence of planning behavior for these tasks and the need for multiple notifications. Our findings demonstrate the critical nature of interventions from outside for persistent malware, since automatic scan of an AV tool or a power cycle, like we are used to for Windows malware and Mirai infections, will not solve persistent IoT malware infections.}
}


@inproceedings{DBLP:conf/eurosp/HumbertDCH22,
	author = {Mathias Humbert and
                  Didier Dupertuis and
                  Mauro Cherubini and
                  K{\'{e}}vin Huguenin},
	title = {{KGP} Meter: Communicating Kin Genomic Privacy to the Masses},
	booktitle = {7th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2022, Genoa, Italy, June 6-10, 2022},
	pages = {410--429},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/EuroSP53844.2022.00033},
	doi = {10.1109/EUROSP53844.2022.00033},
	timestamp = {Mon, 26 Jun 2023 20:47:22 +0200},
	biburl = {https://dblp.org/rec/conf/eurosp/HumbertDCH22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Direct-to-consumer genetic testing services are gaining momentum: As of today, companies such as 23andMe or AncestryDNA have already attracted 26 million customers. These services raise privacy concerns, exacerbated by the fact that their customers can then share their genomic data on platforms such as GEDmatch. Notwithstanding their right to learn about their genetic background or to share their genomic data, it is paramount that individuals realize that such a behavior damages their relatives' privacy (i.e., kin genomic privacy). In this paper, we present KGP Meter, a new online tool that provides means for raising awareness in the general public about the privacy risks of genomic data sharing. Our tool features various properties that makes it highly interactive, privacy-preserving (i.e., not requiring access to the actual genomic data), and user-friendly. It explores possible configurations in an optimized way and combines well-established graphical models with an entropy-based metric to compute kin genomic privacy scores. Our experiments show that KGP Meter is very responsive. We design and implement an interface that enables users to draw their family trees and indicate which of their relatives' genomes are known, and that communicates the resulting privacy scores to the users. We then analyze the usage of the tool and survey users to better understand users' perceptions towards these risks and evaluate our tool. We observe that most of them find the privacy score worrisome, and that the large majority of them find KGP Meter useful.}
}


@inproceedings{DBLP:conf/eurosp/HossenH22,
	author = {Md. Imran Hossen and
                  Xiali Hei},
	title = {aaeCAPTCHA: The Design and Implementation of Audio Adversarial {CAPTCHA}},
	booktitle = {7th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2022, Genoa, Italy, June 6-10, 2022},
	pages = {430--447},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/EuroSP53844.2022.00034},
	doi = {10.1109/EUROSP53844.2022.00034},
	timestamp = {Sat, 30 Sep 2023 09:40:48 +0200},
	biburl = {https://dblp.org/rec/conf/eurosp/HossenH22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {CAPTCHAs are designed to prevent malicious bot programs from abusing websites. Most online service providers deploy audio CAPTCHAs as an alternative to text and image CAPTCHAs for visually impaired users. However, prior research investigating the security of audio CAPTCHAs found them highly vulnerable to automated attacks using Automatic Speech Recognition (ASR) systems. To improve the robustness of audio CAPTCHAs against automated abuses, we present the design and implementation of an audio adversarial CAPTCHA (aaeCAPTCHA) system in this paper. The aaeCAPTCHA system exploits audio adversarial examples as CAPTCHAs to prevent the ASR systems from automatically solving them. Furthermore, we conducted a rigorous security evaluation of our new audio CAPTCHA design against five state-of-the-art DNN-based ASR systems and three commercial Speech-to-Text (STT) services. Our experimental evaluations demonstrate that aaeCAPTCHA is highly secure against these speech recognition technologies, even when the attacker has complete knowledge of the current attacks against audio adversarial examples. We also conducted a usability evaluation of the proof-of-concept implementation of the aaeCAPTCHA scheme. Our results show that it achieves high robustness at a moderate usability cost compared to normal audio CAPTCHAs. Finally, our extensive analysis highlights that aaeCAPTCHA can significantly enhance the security and robustness of traditional audio CAPTCHA systems while maintaining similar usability.}
}


@inproceedings{DBLP:conf/eurosp/AhmadianB22,
	author = {Amir M. Ahmadian and
                  Musard Balliu},
	title = {Dynamic Policies Revisited},
	booktitle = {7th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2022, Genoa, Italy, June 6-10, 2022},
	pages = {448--466},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/EuroSP53844.2022.00035},
	doi = {10.1109/EUROSP53844.2022.00035},
	timestamp = {Wed, 29 Jun 2022 16:03:24 +0200},
	biburl = {https://dblp.org/rec/conf/eurosp/AhmadianB22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Information flow control and dynamic policies is a difficult relationship yet to be fully understood. While dynamic policies are a natural choice in many real-world applications that downgrade and upgrade the sensitivity of information, understanding the meaning of security in this setting is challenging. In this paper we revisit the knowledge-based security conditions to reinstate a simple and intuitive security condition for dynamic policies: A program is secure if at any point during the execution the attacker's knowledge is in accordance with the active security policy at that execution point. Our key observation is the new notion of policy consistency to prevent policy changes whenever an attacker is already in possession of the information that the new policy intends to protect. We use this notion to study a range of realistic attackers including the perfect recall attacker, bounded attackers, and forgetful attackers, and their relationship. Importantly, our new security condition provides a clean connection between the dynamic policy and the underlying attacker model independently of the specific use case. We illustrate this by considering the different facets of dynamic policies in our framework. On the verification side, we design and implement DynCoVer, a tool for checking dynamic information-flow policies for Java programs via symbolic execution and SMT solving. Our verification operates by first extracting a graph of program dependencies and then visiting the graph to check dynamic policies for a range of attackers. We evaluate the effectiveness and efficiency of DyncoVeron a benchmark of use cases from the literature and designed by ourselves, as well as the case study of a social network. The results show that DynCoVer can analyze small but intricate programs indicating that it can help verify security-critical parts of Java applications. We release Dyncover publicly to support open science and encourage researchers to explore the topic further.}
}


@inproceedings{DBLP:conf/eurosp/McCallBJ22,
	author = {McKenna McCall and
                  Abhishek Bichhawat and
                  Limin Jia},
	title = {Compositional Information Flow Monitoring for Reactive Programs},
	booktitle = {7th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2022, Genoa, Italy, June 6-10, 2022},
	pages = {467--486},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/EuroSP53844.2022.00036},
	doi = {10.1109/EUROSP53844.2022.00036},
	timestamp = {Mon, 26 Jun 2023 20:47:21 +0200},
	biburl = {https://dblp.org/rec/conf/eurosp/McCallBJ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {To prevent applications from leaking users' private data to attackers, researchers have developed runtime information flow control (IFC) mechanisms. Most existing approaches are either based on taint tracking or multi-execution, and the same technique is used to protect the entire application. However, today's applications are typically composed of multiple components from heterogenous and unequally trusted sources. The goal of this paper is to develop a framework to enable the flexible composition of IFC enforcement mechanisms. More concretely, we focus on reactive programs, which is an abstract model for event-driven programs including web and mobile applications. We formalize the semantics of existing IFC enforcement mechanisms with well-defined interfaces for composition, define knowledge-based security guarantees that can precisely quantify the effect of implicit leaks from taint tracking, and prove sound all composed systems that we instantiate the framework with. We identify requirements for future enforcement mechanisms to be securely composed in our framework. Finally, we implement a prototype in OCaml and compare the effects of different compositions.}
}


@inproceedings{DBLP:conf/eurosp/LiuKB22,
	author = {Jason Liu and
                  Anant Kandikuppa and
                  Adam Bates},
	title = {Transparent {DIFC:} Harnessing Innate Application Event Logging for
                  Fine-Grained Decentralized Information Flow Control},
	booktitle = {7th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2022, Genoa, Italy, June 6-10, 2022},
	pages = {487--501},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/EuroSP53844.2022.00037},
	doi = {10.1109/EUROSP53844.2022.00037},
	timestamp = {Tue, 07 May 2024 20:06:33 +0200},
	biburl = {https://dblp.org/rec/conf/eurosp/LiuKB22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Information flow control is a canonical approach to access control in systems, allowing administrators to assure confidentiality and integrity through restricting the flow of data. Decentralized Information Flow Control (DIFC) harnesses application-layer semantics to allow more precise and accurate mediation of data. Unfortunately, past approaches to DIFC have depended on dedicated instrumentation efforts or developer buy-in. Thus, while DIFC has existed for decades, it has seen little-to-no adoption in commodity systems; the requirement for complete redesign or retrofitting of programs has proven too high a barrier. In this work, we make the surprising observation that developers have already unwittingly performed the instrumentation efforts required for DIFC — application event logging, a software development best practice used for telemetry and debugging, often contains the information needed to identify application-layer event processes that DIFC mediates. We present T-difc, a kernel-layer reference monitor framework that leverages the insights of application event logs to perform precise decentralized flow control. T-difc identifies and extracts these application events as they are created by monitoring application I/O to log files, then references an administrator-specified security policy to assign data labels and mediate the flow of data through the system. To our knowledge, T-difc is the first approach to DIFC that does not require developer support or custom instrumentation. In a survey of 15 popular open source applications, we demonstrate that T-difc works seamlessly on a variety of popular open source programs while imposing negligible runtime overhead on realistic policies and workloads. Thus, T-difc demonstrates a transparent and non-invasive path forward for the dissemination of decentralized information flow controls.}
}


@inproceedings{DBLP:conf/eurosp/BernhardRHD22,
	author = {Lukas Bernhard and
                  Michael Rodler and
                  Thorsten Holz and
                  Lucas Davi},
	title = {xTag: Mitigating Use-After-Free Vulnerabilities via Software-Based
                  Pointer Tagging on Intel x86-64},
	booktitle = {7th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2022, Genoa, Italy, June 6-10, 2022},
	pages = {502--519},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/EuroSP53844.2022.00038},
	doi = {10.1109/EUROSP53844.2022.00038},
	timestamp = {Tue, 26 Jul 2022 14:23:16 +0200},
	biburl = {https://dblp.org/rec/conf/eurosp/BernhardRHD22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Memory safety in complex applications implemented in unsafe programming languages such as C/C++ is still an unresolved problem in practice. Such applications were often developed in an ad-hoc, security-ignorant fashion, and thus they contain many types of security issues. Many different types of defenses have been proposed in the past to mitigate these problems, some of which are even widely used in practice. However, advanced attacks are still able to circumvent these defenses, and the arms race is not (yet) over. On the defensive side, the most promising next step is a tighter integration of the hardware and software level: modern mitigation techniques are either accelerated using hardware extensions or implemented in the hardware by extensions of the instruction set architecture (ISA). In particular, memory tagging, as proposed by ARM or SPARC, promises to solve many issues for practical memory safety. Unfortunately, Intel x86-64, which represents the most important ISA for both the desktop and server domain, lacks support for hardware-accelerated memory tagging, so memory tagging is not considered practical for this platform. In this paper, we present the design and implementation of an efficient, software-only pointer tagging scheme for Intel x86-64 based on a novel metadata embedding scheme. The basic idea is to alias multiple virtual pages to one physical page so that we can efficiently embed tag bits into a pointer. Furthermore, we introduce several optimizations that significantly reduce the performance impact of this approach to memory tagging. Based on this scheme, we propose a novel use-after-free mitigation scheme, called xTag, that offers better performance and strong security properties compared to state-of-the-art methods. We also show how double-free vulnerabilities can be mitigated. Our approach is highly compatible, allowing pointers to be passed back and forth between instrumented and non-instrumented code without losing metadata, and it is even compatible with inline assembly. We conclude that building exploit mitigation mechanisms on top of our memory tagging scheme is feasible on Intel x86-64, as demonstrated by the effective prevention of use-after-free bugs in the Firefox web browser.}
}


@inproceedings{DBLP:conf/eurosp/ShiGLZCZ22,
	author = {Jiameng Shi and
                  Le Guan and
                  Wenqiang Li and
                  Dayou Zhang and
                  Ping Chen and
                  Ning Zhang},
	title = {{HARM:} Hardware-Assisted Continuous Re-randomization for Microcontrollers},
	booktitle = {7th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2022, Genoa, Italy, June 6-10, 2022},
	pages = {520--536},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/EuroSP53844.2022.00039},
	doi = {10.1109/EUROSP53844.2022.00039},
	timestamp = {Sun, 12 Mar 2023 00:57:46 +0100},
	biburl = {https://dblp.org/rec/conf/eurosp/ShiGLZCZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Microcontroller-based embedded systems have become ubiquitous with the emergence of IoT technology. Given its critical roles in many applications, its security is becoming increasingly important. Unfortunately, MCU devices are especially vulnerable. Code reuse attacks are particularly noteworthy since the memory address of firmware code is static. This work seeks to combat code reuse attacks, including ROP and more advanced JIT-ROP via continuous randomization. Previous proposals are geared towards full-fledged OSs with rich runtime environments, and therefore cannot be applied to MCUs. We propose the first solution for ARM-based MCUs. Our system, named HARM, comprises a secure runtime and a binary analysis tool with rewriting module. The secure runtime, protected inside the secure world, proactively triggers and performs non-bypassable randomization to the firmware running in a sandbox in the normal world. Our system does not rely on any firmware feature, and therefore is generally applicable to both bare-metal and RTOS-powered firmware. We have implemented a prototype on a development board. Our evaluation results indicate that HARM can effectively thaw code reuse attacks while keeping the performance and energy overhead low.}
}


@inproceedings{DBLP:conf/eurosp/WalkerS22,
	author = {Payton Walker and
                  Nitesh Saxena},
	title = {Laser Meager Listener: {A} Scientific Exploration of Laser-based Speech
                  Eavesdropping in Commercial User Space},
	booktitle = {7th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2022, Genoa, Italy, June 6-10, 2022},
	pages = {537--554},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/EuroSP53844.2022.00040},
	doi = {10.1109/EUROSP53844.2022.00040},
	timestamp = {Wed, 29 Jun 2022 16:03:24 +0200},
	biburl = {https://dblp.org/rec/conf/eurosp/WalkerS22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Human speech signals produce sound waves that induce vibrations on objects that they encounter. Such vibrations can be measured via laser vibrometers and possibly used in speech eavesdropping attacks. However, there is still much to learn about when this attack is feasible. In this paper, we aim to broaden our understanding of the viability of laser eavesdropping attacks to compromise speech in the commercial user space. In our study, we design experiments to measure the subtle vibrations induced on commonly-available objects by nearby speech, using commercially sold, high-precision laser vibrometers. To observe idealized success rates of the attack, we maintain certain physical parameters in favorable conditions that represent best case scenarios for an attacker. We test three primary attack scenarios considering different relative positions to the target object. Additionally, we consider many important experimental parameters to understand the generalizability of the attack, including: speech sources, loudness levels, vibration propagation media, and object materials. Our vibrometer recorded signals were analyzed via a two-pronged methodology including, (1) time domain, frequency spectrum, cross correlation, and speech intelligibility metric analyses and (2) an information extraction analysis using both human listeners and automated recognition tools. Our results suggest that eavesdropping attacks using a laser vibrometer may be practical in some situations and parameter settings (i.e., intelligence missions). However, we find that live aerial human speech and machine-rendered speech at a normal conversational loudness level does not show signs of significant leakage in our analysis.}
}


@inproceedings{DBLP:conf/eurosp/SubramaniJKP22,
	author = {Karthika Subramani and
                  Jordan Jueckstock and
                  Alexandros Kapravelos and
                  Roberto Perdisci},
	title = {SoK: Workerounds - Categorizing Service Worker Attacks and Mitigations},
	booktitle = {7th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2022, Genoa, Italy, June 6-10, 2022},
	pages = {555--571},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/EuroSP53844.2022.00041},
	doi = {10.1109/EUROSP53844.2022.00041},
	timestamp = {Wed, 29 Jun 2022 16:03:24 +0200},
	biburl = {https://dblp.org/rec/conf/eurosp/SubramaniJKP22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Service Workers (SWs) are a powerful feature at the core of Progressive Web Apps, namely web applications that can continue to function when the user's device is offline and that have access to device sensors and capabilities previously accessible only by native applications. During the past few years, researchers have found a number of ways in which SWs may be abused to achieve different malicious purposes. For instance, SWs may be abused to build a web-based botnet, launch DDoS attacks, or perform cryptomining; they may be hijacked to create persistent cross-site scripting (XSS) attacks; they may be leveraged in the context of side-channel attacks to compromise users' privacy; or they may be abused for phishing or social engineering attacks using web push notifications-based malvertising. In this paper, we reproduce and analyze known attack vectors related to SWs and explore new abuse paths that have not previously been considered. We systematize the attacks into different categories, and then analyze whether, how, and estimate when these attacks have been published and mitigated by different browser vendors. Then, we discuss a number of open SW security problems that are currently unmitigated, and propose SW behavior monitoring approaches and new browser policies that we believe should be implemented by browsers to further improve SW security. Furthermore, we implement a proof-of-concept version of several policies in the Chromium code base, and also measure the behavior of SWs used by highly popular web applications with respect to these new policies. Our measurements show that it should be feasible to implement and enforce stricter SW security policies without a significant impact on most legitimate production SWs.}
}


@inproceedings{DBLP:conf/eurosp/ElgharabawyKMBW22,
	author = {Mounir Elgharabawy and
                  Blas Kojusner and
                  Mohammad Mannan and
                  Kevin R. B. Butler and
                  Byron Williams and
                  Amr M. Youssef},
	title = {{SAUSAGE:} Security Analysis of Unix domain Socket usAGE in Android},
	booktitle = {7th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2022, Genoa, Italy, June 6-10, 2022},
	pages = {572--586},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/EuroSP53844.2022.00042},
	doi = {10.1109/EUROSP53844.2022.00042},
	timestamp = {Wed, 29 Jun 2022 16:03:24 +0200},
	biburl = {https://dblp.org/rec/conf/eurosp/ElgharabawyKMBW22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Android operating system is currently the most popular mobile operating system in the world. Android is based on Linux and therefore inherits its features including its Inter-Process Communication (IPC) mechanisms. These mechanisms are used by processes to communicate with one another and are extensively used in Android. While Android-specific IPC mechanisms have been studied extensively, Unix domain sockets have not been examined comprehensively, despite playing a crucial role in the IPC of highly privileged system daemons. In this paper, we propose Sausage, an efficient novel static analysis framework to study the security properties of these sockets. Sausage considers access control policies implemented in the Android security model, as well as authentication checks implemented by the daemon binaries. It is a fully static analysis framework, specifically designed to analyze Unix domain socket usage in Android system daemons, at scale. We use this framework to analyze 200 Android images across eight popular smartphone vendors spanning Android versions 7–9. As a result, we uncover multiple access control misconfigurations and insecure authentication checks. Our notable findings include a permission bypass in highly privileged Qualcomm system daemons and an unprotected socket that allows an untrusted app to set the scheduling priority of other processes running on the system, despite the implementation of mandatory SELinux policies. Ultimately, the results of our analysis are worrisome; all vendors except the Android Open Source Project (AOSP) have access control issues, allowing an untrusted app to communicate to highly privileged daemons through Unix domain sockets introduced by hardware manufacturer or vendor customization.}
}


@inproceedings{DBLP:conf/eurosp/YuanCR22,
	author = {Dandan Yuan and
                  Shujie Cui and
                  Giovanni Russello},
	title = {We Can Make Mistakes: Fault-tolerant Forward Private Verifiable Dynamic
                  Searchable Symmetric Encryption},
	booktitle = {7th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2022, Genoa, Italy, June 6-10, 2022},
	pages = {587--605},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/EuroSP53844.2022.00043},
	doi = {10.1109/EUROSP53844.2022.00043},
	timestamp = {Wed, 29 Jun 2022 16:03:24 +0200},
	biburl = {https://dblp.org/rec/conf/eurosp/YuanCR22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Verifiable Dynamic Searchable Symmetric Encryption (VDSSE) enables users to securely outsource databases (document sets) to cloud servers and perform searches and updates. The verifiability property prevents users from accepting incorrect search results returned by a malicious server. However, we discover that the community currently only focuses on preventing malicious behavior from the server but ignores incorrect updates from the client, which are very likely to happen since there is no record on the client to check. Indeed most existing VDSSE schemes are not sufficient to tolerate incorrect updates from the client. For instance, deleting a nonexistent keyword-identifier pair can break their correctness and soundness. In this paper, we demonstrate the vulnerabilities of a type of existing VDSSE schemes that fail them to ensure correctness and soundness properties on incorrect updates. We propose an efficient fault-tolerant solution that can consider any DSSE scheme as a black-box and make them into a fault-tolerant VDSSE in the malicious model. Forward privacy is an important property of DSSE that prevents the server from linking an update operation to previous search queries. Our approach can also make any forward secure DSSE scheme into a fault-tolerant VDSSE without breaking the forward security guarantee. In this work, we take FAST [1] (TDSC 2020), a forward secure DSSE, as an example, implement a prototype of our solution, and evaluate its performance. Even when compared with the previous fastest forward private construction that does not support fault tolerance, the experiments show that our construction saves 9× client storage and has better search and update efficiency.}
}


@inproceedings{DBLP:conf/eurosp/ManevichA22,
	author = {Yacov Manevich and
                  Adi Akavia},
	title = {Cross Chain Atomic Swaps in the Absence of Time via Attribute Verifiable
                  Timed Commitments},
	booktitle = {7th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2022, Genoa, Italy, June 6-10, 2022},
	pages = {606--625},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/EuroSP53844.2022.00044},
	doi = {10.1109/EUROSP53844.2022.00044},
	timestamp = {Wed, 29 Jun 2022 16:03:24 +0200},
	biburl = {https://dblp.org/rec/conf/eurosp/ManevichA22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A Hash Time Lock Contract (HTLC) is a protocol that is commonly used to exchange payments across different blockchains. Using HTLC as a building block for cross blockchain atomic swaps has its drawbacks: The notion of time is handled differently in each blockchain, be it private or public. Additionally, if the swap ends up aborted, the funds are locked in escrow until the safety timeout expires. In this work we formulate a new cryptographic primitive: Attribute Verifiable Timed Commitment which enables to prove that a timed commitment commits to a value which possesses certain attributes. Using our cryptographic primitive, we describe a new cross chain atomic swap protocol that operates without blockchain derived time and unlike the state of the art, all parties can instantly abort the swap without waiting for the safety timeouts to expire. In order to prove in zero knowledge that a secret committed to using a timed commitment has a claimed hash value, we employ the “MPC in the head” technique by Ishai et al. and implement our zero-knowledge proof protocol and evaluate its performance. As part of our techniques, we develop a novel and efficient procedure for integer Lower-Than validation in arithmetic circuits which may be of independent interest.}
}


@inproceedings{DBLP:conf/eurosp/CasacubertaHL22,
	author = {S{\'{\i}}lvia Casacuberta and
                  Julia Hesse and
                  Anja Lehmann},
	title = {SoK: Oblivious Pseudorandom Functions},
	booktitle = {7th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2022, Genoa, Italy, June 6-10, 2022},
	pages = {625--646},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/EuroSP53844.2022.00045},
	doi = {10.1109/EUROSP53844.2022.00045},
	timestamp = {Mon, 05 Feb 2024 20:31:17 +0100},
	biburl = {https://dblp.org/rec/conf/eurosp/CasacubertaHL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent years, oblivious pseudorandom functions (OPRFs) have become a ubiquitous primitive used in cryptographic protocols and privacy-preserving technologies. The growing interest in OPRFs, both theoretical and applied, has produced a vast number of different constructions and functionality variations. In this paper, we provide a systematic overview of how to build and use OPRFs. We first categorize existing OPRFs into essentially four families based on their underlying PRF (Naor-Reingold, Dodis-Yampolskiy, Hashed Diffie-Hellman, and generic constructions). This categorization allows us to give a unified presentation of all oblivious evaluation methods in the literature, and to understand which properties OPRFs can (or cannot) have. We further demonstrate the theoretical and practical power of OPRFs by visualizing them in the landscape of cryptographic primitives, and by providing a comprehensive overview of how OPRFs are leveraged for improving the privacy of internet users. Our work systematizes 15 years of research on OPRFs and provides inspiration for new OPRF constructions and applications thereof.}
}


@inproceedings{DBLP:conf/eurosp/IslamMSSS22,
	author = {Saad Islam and
                  Koksal Mus and
                  Richa Singh and
                  Patrick Schaumont and
                  Berk Sunar},
	title = {Signature Correction Attack on Dilithium Signature Scheme},
	booktitle = {7th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2022, Genoa, Italy, June 6-10, 2022},
	pages = {647--663},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/EuroSP53844.2022.00046},
	doi = {10.1109/EUROSP53844.2022.00046},
	timestamp = {Wed, 29 Jun 2022 16:03:24 +0200},
	biburl = {https://dblp.org/rec/conf/eurosp/IslamMSSS22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Motivated by the rise of quantum computers, existing public-key cryptosystems are expected to be replaced by post-quantum schemes in the next decade in billions of devices. To facilitate the transition, NIST is running a standardization process which is currently in its final Round. Only three digital signature schemes are left in the competition, among which Dilithium and Falcon are the ones based on lattices. Besides security and performance, significant attention has been given to resistance against implementation attacks that target side-channel leakage or fault injection response. Classical fault attacks on signature schemes make use of pairs of faulty and correct signatures to recover the secret key which only works on deterministic schemes. To counter such attacks, Dilithium offers a randomized version which makes each signature unique, even when signing identical messages. In this work, we introduce a novel Signature Correction Attack which not only applies to the deterministic version but also to the randomized version of Dilithium and is effective even on constant-time implementations using AVX2 instructions. The Signature Correction Attack exploits the mathematical structure of Dilithium to recover the secret key bits by using faulty signatures and the public-key. It can work for any fault mechanism which can induce single bit-flips. For demonstration, we are using Rowhammer induced faults. Thus, our attack does not require any physical access or special privileges, and hence could be also implemented on shared cloud servers. Using Rowhammer attack, we inject bit flips into the secret key s1 of Dilithium, which results in incorrect signatures being generated by the signing algorithm. Since we can find the correct signature using our Signature Correction algorithm, we can use the difference between the correct and incorrect signatures to infer the location and value of the flipped bit without needing a correct and faulty pair. To quantify the reduction in the security level, we perform a thorough classical and quantum security analysis of Dilithium and successfully recover 1,851 bits out of 3,072 bits of secret key $s_{1}$ for security level 2. Fully recovered bits are used to reduce the dimension of the lattice whereas partially recovered coefficients are used to to reduce the norm of the secret key coefficients. Further analysis for both primal and dual attacks shows that the lattice strength against quantum attackers is reduced from 2 128 to 2 81 while the strength against classical attackers is reduced from 2141 to 2 89 . Hence, the Signature Correction Attack may be employed to achieve a practical attack on Dilithium (security level 2) as proposed in Round 3 of the NIST post-quantum standardization process.}
}


@inproceedings{DBLP:conf/eurosp/FengMCFJP22,
	author = {Ryan Feng and
                  Neal Mangaokar and
                  Jiefeng Chen and
                  Earlence Fernandes and
                  Somesh Jha and
                  Atul Prakash},
	title = {{GRAPHITE:} Generating Automatic Physical Examples for Machine-Learning
                  Attacks on Computer Vision Systems},
	booktitle = {7th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2022, Genoa, Italy, June 6-10, 2022},
	pages = {664--683},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/EuroSP53844.2022.00047},
	doi = {10.1109/EUROSP53844.2022.00047},
	timestamp = {Mon, 05 Feb 2024 20:31:17 +0100},
	biburl = {https://dblp.org/rec/conf/eurosp/FengMCFJP22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper investigates an adversary's ease of attack in generating adversarial examples for real-world scenarios. We address three key requirements for practical attacks for the real-world: 1) automatically constraining the size and shape of the attack so it can be applied with stickers, 2) transform-robustness, i.e., robustness of a attack to environmental physical variations such as viewpoint and lighting changes, and 3) supporting attacks in not only white-box, but also black-box hard-label scenarios, so that the adversary can attack proprietary models. In this work, we propose GRAPHITE, an efficient and general framework for generating attacks that satisfy the above three key requirements. GRAPHITE takes advantage of transform-robustness, a metric based on expectation over transforms (EoT), to automatically generate small masks and optimize with gradient-free optimization. GRAPHITE is also flexible as it can easily trade-off transform-robustness, perturbation size, and query count in black-box settings. On a GTSRB model in a hard-label black-box setting, we are able to find attacks on all possible 1,806 victim-target class pairs with averages of 77.8% transform-robustness, perturbation size of 16.63% of the victim images, and 126K queries per pair. For digital-only attacks where achieving transform-robustness is not a requirement, GRAPHITE is able to find successful small-patch attacks with an average of only 566 queries for 92.2% of victim-target pairs. GRAPHITE is also able to find successful attacks using perturbations that modify small areas of the input image against PatchGuard, a recently proposed defense against patch-based attacks.}
}


@inproceedings{DBLP:conf/eurosp/PangZGXJCLW22,
	author = {Ren Pang and
                  Zheng Zhang and
                  Xiangshan Gao and
                  Zhaohan Xi and
                  Shouling Ji and
                  Peng Cheng and
                  Xiapu Luo and
                  Ting Wang},
	title = {TrojanZoo: Towards Unified, Holistic, and Practical Evaluation of
                  Neural Backdoors},
	booktitle = {7th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2022, Genoa, Italy, June 6-10, 2022},
	pages = {684--702},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/EuroSP53844.2022.00048},
	doi = {10.1109/EUROSP53844.2022.00048},
	timestamp = {Wed, 29 Jun 2022 16:03:24 +0200},
	biburl = {https://dblp.org/rec/conf/eurosp/PangZGXJCLW22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Neural backdoors represent one primary threat to the security of deep learning systems. The intensive research has produced a plethora of backdoor attacks/defenses, resulting in a constant arms race. However, due to the lack of evaluation benchmarks, many critical questions remain under-explored: (i) what are the strengths and limitations of different attacks/defenses? (ii) what are the best practices to operate them? and (iii) how can the existing attacks/defenses be further improved? To bridge this gap, we design and implement TROJAN-ZOO, the first open-source platform for evaluating neural backdoor attacks/defenses in a unified, holistic, and practical manner. Thus far, focusing on the computer vision domain, it has incorporated 8 representative attacks, 14 state-of-the-art defenses, 6 attack performance metrics, 10 defense utility metrics, as well as rich tools for in-depth analysis of the attack-defense interactions. Leveraging TROJANZOO, we conduct a systematic study on the existing attacks/defenses, unveiling their complex design spectrum: both manifest intricate trade-offs among multiple desiderata (e.g., the effectiveness, evasiveness, and transferability of attacks). We further explore improving the existing attacks/defenses, leading to a number of interesting findings: (i) one-pixel triggers often suffice; (ii) training from scratch often outperforms perturbing benign models to craft trojan models; (iii) optimizing triggers and trojan models jointly greatly improves both attack effectiveness and evasiveness; (iv) individual defenses can often be evaded by adaptive attacks; and (v) exploiting model interpretability significantly improves defense robustness. We envision that TROJANZOO will serve as a valuable platform to facilitate future research on neural backdoors.}
}


@inproceedings{DBLP:conf/eurosp/SalemWBMZ22,
	author = {Ahmed Salem and
                  Rui Wen and
                  Michael Backes and
                  Shiqing Ma and
                  Yang Zhang},
	title = {Dynamic Backdoor Attacks Against Machine Learning Models},
	booktitle = {7th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2022, Genoa, Italy, June 6-10, 2022},
	pages = {703--718},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/EuroSP53844.2022.00049},
	doi = {10.1109/EUROSP53844.2022.00049},
	timestamp = {Tue, 24 Jan 2023 18:43:22 +0100},
	biburl = {https://dblp.org/rec/conf/eurosp/SalemWBMZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Machine learning (ML) has made tremendous progress during the past decade and is being adopted in various critical real-world applications. However, recent research has shown that ML models are vulnerable to multiple security and privacy attacks. In particular, backdoor attacks against ML models have recently raised a lot of awareness. A successful backdoor attack can cause severe consequences, such as allowing an adversary to bypass critical authentication systems. Current backdooring techniques rely on adding static triggers (with fixed patterns and locations) on ML model inputs which are prone to detection by the current backdoor detection mechanisms. In this paper, we propose the first class of dynamic backdooring techniques against deep neural networks (DNN), namely Random Backdoor, Backdoor Generating Network (BaN), and conditional Backdoor Generating Network (c-BaN). Triggers generated by our techniques can have random patterns and locations, which reduce the efficacy of the current backdoor detection mechanisms. In particular, BaN and c-BaN based on a novel generative network are the first two schemes that algorithmically generate triggers. Moreover, c-BaN is the first conditional backdooring technique that given a target label, it can generate a target-specific trigger. Both BaN and c-BaN are essentially a general framework which renders the adversary the flexibility for further customizing backdoor attacks. We extensively evaluate our techniques on three benchmark datasets: MNIST, CelebA, and CIFAR-10. Our techniques achieve almost perfect attack performance on back-doored data with a negligible utility loss. We further show that our techniques can bypass current state-of-the-art defense mechanisms against backdoor attacks, including ABS, Februus, MNTD, Neural Cleanse, and STRIP.}
}


@inproceedings{DBLP:conf/eurosp/TsingenopoulosP22,
	author = {Ilias Tsingenopoulos and
                  Davy Preuveneers and
                  Lieven Desmet and
                  Wouter Joosen},
	title = {Captcha me if you can: Imitation Games with Reinforcement Learning},
	booktitle = {7th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2022, Genoa, Italy, June 6-10, 2022},
	pages = {719--735},
	publisher = {{IEEE}},
	year = {2022},
	url = {https://doi.org/10.1109/EuroSP53844.2022.00050},
	doi = {10.1109/EUROSP53844.2022.00050},
	timestamp = {Wed, 07 Dec 2022 23:07:47 +0100},
	biburl = {https://dblp.org/rec/conf/eurosp/TsingenopoulosP22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Since their inception, Captchas have been widely used as reverse Turing tests for combating bot proliferation on the web. This has resulted in an arms race between bot developers that automate Captcha solvers and Captcha services that adjust the challenges accordingly or come up with new ones altogether. Ultimately, older generations could be bypassed consistently, and thus in the third version of reCAPTCHA, Google offers zero user friction. The intent in the new system is not only to avoid interrupting user experience but to also obfuscate the nature of the challenge itself, being much less prominent than a text or image recognition task. We introduce a methodology that learns through interaction how to evade detection, while collecting and analyzing reCAPTCHA v3 scores over fifteen months and various web environments. With reinforcement learning as the backbone, we build models that can simulate human-like web browsing behaviour by using the returned score as an informative signal. Our study exposes an important vulnerability: while the score is influenced by a multitude of undisclosed factors, it is easily accessible and it enables adversaries to learn and perfect evasive models. Notably, we demonstrate that our automation models, which integrate general web browsing capabilities, transfer between websites with an evasion rate up to 99.6%.}
}
