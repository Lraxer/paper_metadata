@inproceedings{DBLP:conf/eurosp/RuggiaPMNA23,
	author = {Antonio Ruggia and
                  Andrea Possemato and
                  Alessio Merlo and
                  Dario Nisi and
                  Simone Aonzo},
	title = {Android, Notify Me When It Is Time To Go Phishing},
	booktitle = {8th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2023, Delft, Netherlands, July 3-7, 2023},
	pages = {1--17},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/EuroSP57164.2023.00010},
	doi = {10.1109/EUROSP57164.2023.00010},
	timestamp = {Mon, 07 Aug 2023 15:56:23 +0200},
	biburl = {https://dblp.org/rec/conf/eurosp/RuggiaPMNA23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A mobile banking app just started up, and the notification "App updated, click here to restart" appears. The graphic theme is the same as the bank. Can we trust it? What if we cannot even trust that tapping an app actually loads the original one? More generally, what if Android notifies an attacker when her victim has just launched the target app of her phishing campaign so that she could cast the hook at the perfect moment?In this paper, we abuse inotify APIs, a mechanism for monitoring file system events, to mount a state inference-based phishing attack from a malicious app installed on the victim\'s smartphone. We also verified the novelty of our work analyzing 10,000 recent Android malware, and although we found some cases where malware uses inotify for their petty purposes, our attack seems to be publicly unknown.However, since Android constantly evolves year after year, we studied its feasibility over different Android versions and attacker\'s capabilities. By analyzing 4, 863 of the most popular apps, the most disconcerting finding is that if the attacker knows the installation path of the target app, all Android apps are vulnerable, regardless of the system version. Getting the installation path of an app is a capability that is only protected by a normal permission, and to make matters worse, there are workarounds to get it even without such permission.Even if this capability is denied, we propose different attack models under which this attack is still possible; however, at the end of our work, we provide the remediation to eradicate once and for all these attacks. Through this work, we reported three vulnerabilities to Google. Two were acknowledged as bugs of moderate severity, while the last one was already known but not public.}
}


@inproceedings{DBLP:conf/eurosp/LiuPVP23,
	author = {Jienan Liu and
                  Pooja Pun and
                  Phani Vadrevu and
                  Roberto Perdisci},
	title = {Understanding, Measuring, and Detecting Modern Technical Support Scams},
	booktitle = {8th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2023, Delft, Netherlands, July 3-7, 2023},
	pages = {18--38},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/EuroSP57164.2023.00011},
	doi = {10.1109/EUROSP57164.2023.00011},
	timestamp = {Mon, 07 Aug 2023 15:56:23 +0200},
	biburl = {https://dblp.org/rec/conf/eurosp/LiuPVP23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Technical support scams (TSS) are social engineering attacks that aim to exploit users that have limited knowledge about technology, such as the elderly, causing significant financial loss to vulnerable citizens. The security community has attempted to respond to these web-based scams with different countermeasures. However, to the best of our knowledge, no robust countermeasures have been proposed thus far to defend against modern TSS campaigns that abuse web search engines to inflate their rankings in search results and lure many potential victims.To defend against these TSS attacks, in this paper we first study the TSS ecosystem, with particular focus on how modern TSS campaigns are operated and promoted on the web. Then, we capitalize on our findings by proposing a novel detection system named TASR that can be used to differentiate TSS websites from legitimate technical support websites in a topic-agnostic way, by leveraging features that capture key traits of how TSS web pages are promoted. Our cross-validation tests show that TASR can detect 94.5% of the TSS links in web search results at a false positive rate of less than 1%, significantly outperforming previous work.}
}


@inproceedings{DBLP:conf/eurosp/ChenWE23,
	author = {Wentao Chen and
                  Fuzhou Wang and
                  Matthew Edwards},
	title = {Active Countermeasures for Email Fraud},
	booktitle = {8th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2023, Delft, Netherlands, July 3-7, 2023},
	pages = {39--55},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/EuroSP57164.2023.00012},
	doi = {10.1109/EUROSP57164.2023.00012},
	timestamp = {Sat, 30 Sep 2023 09:40:48 +0200},
	biburl = {https://dblp.org/rec/conf/eurosp/ChenWE23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As a major component of online crime, email-based fraud is a threat that causes substantial economic losses every year. To counteract these scammers, volunteers called scam-baiters play the roles of victims, reply to scammers, and try to waste their time and attention with long and unproductive conversations. To curb email fraud and magnify the effectiveness of scam-baiting, we developed and deployed an expandable scam-baiting mailserver that can conduct scam-baiting activities automatically. We implemented three reply strategies using three different models and conducted a one-month-long experiment during which we elicited 150 messages from 130 different scammers. We compare the performance of each strategy at attracting and holding the attention of scammers, finding tradeoffs between human-written and automatically-generated response strategies. We also demonstrate that scammers can be engaged concurrently by multiple servers deploying these strategies in a second experiment, which used two server instances to contact 92 different scammers over 12 days. We release both our platform and a dataset containing conversations between our automatic scam-baiters and real human scammers, to support future work in preventing online fraud.}
}


@inproceedings{DBLP:conf/eurosp/NairS23,
	author = {Vivek Nair and
                  Dawn Song},
	title = {Multi-Factor Credential Hashing for Asymmetric Brute-Force Attack
                  Resistance},
	booktitle = {8th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2023, Delft, Netherlands, July 3-7, 2023},
	pages = {56--72},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/EuroSP57164.2023.00013},
	doi = {10.1109/EUROSP57164.2023.00013},
	timestamp = {Mon, 07 Aug 2023 15:56:23 +0200},
	biburl = {https://dblp.org/rec/conf/eurosp/NairS23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Since the introduction of bcrypt in 1999, adaptive password hashing functions, whereby brute-force resistance increases symmetrically with computational difficulty for legitimate users, have been our most powerful post-breach countermeasure against credential disclosure. Unfortunately, the relatively low tolerance of users to added latency places an upper bound on the deployment of this technique in most applications. In this paper, we present a multi-factor credential hashing function (MFCHF) that incorporates the additional entropy of multi-factor authentication into password hashes to provide asymmetric resistance to brute-force attacks. MFCHF provides full backward compatibility with existing authentication software (e.g., Google Authenticator) and hardware (e.g., YubiKeys), with support for common usability features like factor recovery. The result is a 10 6 to 10 48 times increase in the difficulty of cracking hashed credentials, with little added latency or usability impact.}
}


@inproceedings{DBLP:conf/eurosp/NatarajanLDD23,
	author = {Deepika Natarajan and
                  Andrew D. Loveless and
                  Wei Dai and
                  Ronald G. Dreslinski},
	title = {Chex-Mix: Combining Homomorphic Encryption with Trusted Execution
                  Environments for Oblivious Inference in the Cloud},
	booktitle = {8th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2023, Delft, Netherlands, July 3-7, 2023},
	pages = {73--91},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/EuroSP57164.2023.00014},
	doi = {10.1109/EUROSP57164.2023.00014},
	timestamp = {Mon, 07 Aug 2023 15:56:23 +0200},
	biburl = {https://dblp.org/rec/conf/eurosp/NatarajanLDD23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Data, when coupled with state-of-the-art machine learning models, can enable remarkable applications. But, there exists an underlying tension: users wish to keep their data private, and model providers wish to protect their intellectual property. Homomorphic encryption (HE) and multi-party computation (MPC) techniques have been proposed as solutions to this problem; however, both techniques require model providers to fully trust the server performing the machine learning computation. This limits the scale of inference applications, since it prevents model providers from leveraging shared public cloud infrastructures.In this work, we present Chex-Mix, a solution to the problem of privacy-preserving machine learning between two mutually distrustful parties in an untrusted cloud setting. Chex-Mix relies on a combination of HE and trusted execution environments (TEEs), using HE to provide clients with confidentiality guarantees, and TEEs to provide model providers with confidentiality guarantees and protect the integrity of computation from malicious cloud adversaries. Unlike prior solutions to this problem, such as multi-key HE, single-key HE, MPC, or TEE-only techniques, our solution assumes that both the client and the cloud can be malicious, makes no collusion assumptions, and frees model providers from needing to maintain private online infrastructures. Our results show that Chex-Mix can execute at high efficiency, with low communication cost, while providing security guarantees unaddressed by prior work. Compared to a recent multi-key HE work that allows partial cloud offload, for example, Chex-Mix achieves a 3× lower communication cost and a 3× faster computation time.}
}


@inproceedings{DBLP:conf/eurosp/MillwoodPPMGK23,
	author = {Owen Millwood and
                  Meltem Kurt Pehlivanoglu and
                  Aryan Mohammadi Pasikhani and
                  Jack Miskelly and
                  Prosanta Gope and
                  Elif Bilge Kavun},
	title = {A Generic Obfuscation Framework for Preventing ML-Attacks on Strong-PUFs
                  through Exploitation of DRAM-PUFs},
	booktitle = {8th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2023, Delft, Netherlands, July 3-7, 2023},
	pages = {92--106},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/EuroSP57164.2023.00015},
	doi = {10.1109/EUROSP57164.2023.00015},
	timestamp = {Tue, 07 May 2024 20:06:33 +0200},
	biburl = {https://dblp.org/rec/conf/eurosp/MillwoodPPMGK23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Considering the limited power and computational resources available, designing sufficiently secure systems for low-power devices is a difficult problem to tackle. With the ubiquitous adoption of the Internet of Things (IoT) not appearing to be slowing any time soon, resource-constrained security is more important than ever. Physical Unclonable Functions (PUFs) have gained momentum in recent years for their potential to enable strong security through the generation of unique identifiers based on entropy derived from unique manufacturing variations. Strong-PUFs, which are desirable for authentication protocols, have often been shown to be insecure to Machine Learning Modelling Attacks (ML-MA). Recently, some schemes have been proposed to enhance security against ML-MA through post-processing of the PUF; however, often, security is not sufficiently upheld, the scheme requires too large an additional overhead or key data must be insecurely stored in Non-Volatile Memory. In this work, we propose a generic framework for securing Strong-PUFs against ML-MA through obfuscation of challenge and response data by exploiting a DRAM-PUF to supplement a One-Way Function (OWF) which can be implemented using the available resources on an FPGA platform. Our proposed scheme enables reconfigurability, strong security and one-wayness. We conduct ML-MA using various classifiers to thoroughly evaluate the performance of our scheme across multiple 16-bit and 32-bit Arbiter-PUF (APUF) variants, showing our scheme reduces model accuracy to around 50% for each PUF (random guessing) and evaluate the properties of the final responses, demonstrating that ideal uniformity and uniqueness are maintained. Even though we demonstrate our proposal through a DRAM-PUF, our scheme can be extended to work with memory-based PUFs in general.}
}


@inproceedings{DBLP:conf/eurosp/ChevalMR23,
	author = {Vincent Cheval and
                  Jos{\'{e}} Moreira and
                  Mark Ryan},
	title = {Automatic verification of transparency protocols},
	booktitle = {8th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2023, Delft, Netherlands, July 3-7, 2023},
	pages = {107--121},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/EuroSP57164.2023.00016},
	doi = {10.1109/EUROSP57164.2023.00016},
	timestamp = {Mon, 07 Aug 2023 15:56:23 +0200},
	biburl = {https://dblp.org/rec/conf/eurosp/ChevalMR23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Transparency protocols are protocols whose actions can be publicly monitored by observers (such observers may include regulators, rights advocacy groups, or the general public). The observed actions are typically usages of private keys such as decryptions, and signings. Examples of transparency protocols include certificate transparency, cryptocurrency, transparent decryption, and electronic voting. These protocols usually pose a challenge for automatic verification, because they involve sophisticated data types that have strong properties, such as Merkle trees, that allow compact proofs of data presence and tree extension.We address this challenge by introducing new features in ProVerif, and a methodology for using them. With our methodology, it is possible to describe the data type quite abstractly, using ProVerif axioms, and prove the correctness of the protocol using those axioms as assumptions. Then, in separate steps, one can define one or more concrete implementations of the data type, and again use ProVerif to show that the implementations satisfy the assumptions that were coded as axioms. This helps make compositional proofs, splitting the proof burden into several manageable pieces. We illustrate the methodology and features by providing the first formal verification of the transparent decryption and certificate transparency protocols with a precise modelling of the Merkle tree data structure.}
}


@inproceedings{DBLP:conf/eurosp/ErnstbergerLEZSCMGS23,
	author = {Jens Ernstberger and
                  Jan Lauinger and
                  Fatima Elsheimy and
                  Liyi Zhou and
                  Sebastian Steinhorst and
                  Ran Canetti and
                  Andrew Miller and
                  Arthur Gervais and
                  Dawn Song},
	title = {SoK: Data Sovereignty},
	booktitle = {8th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2023, Delft, Netherlands, July 3-7, 2023},
	pages = {122--143},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/EuroSP57164.2023.00017},
	doi = {10.1109/EUROSP57164.2023.00017},
	timestamp = {Tue, 07 May 2024 20:06:33 +0200},
	biburl = {https://dblp.org/rec/conf/eurosp/ErnstbergerLEZSCMGS23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Society appears to be on the verge of recognizing the need for control over sensitive data in modern web applications. Recently, many systems claim to give control to individuals, promising the preeminent goal of data sovereignty. However, despite recent attention, research and industry efforts are fragmented and lack a holistic system overview. In this paper, we provide the first transecting systematization of data sovereignty by drawing from a dispersed body of knowledge. We clarify the field by identifying its three main areas: (i) decentralized identity, (ii) decentralized access control and (iii) policy-compliant decentralized computation. We find that literature lacks a cohesive set of formal definitions. Each area is considered in isolation, and priorities in industry and academia are not aligned due to a lack of clarity regarding user control. To solve this issue, we propose formal definitions for each sub-area. By highlighting that data sovereignty transcends the domain of decentralized identity, we aim to guide future works to embrace a broader perspective on user control. In each section, we augment our definition with security and privacy properties, discuss the state of the art and proceed to identify open challenges. We conclude by highlighting synergies between areas, emphasizing the real-world benefit obtained by further developing data sovereign systems.}
}


@inproceedings{DBLP:conf/eurosp/IslamPMBN23,
	author = {Nafis Tanveer Islam and
                  Gonzalo De La Torre Parra and
                  Dylan Manuel and
                  Elias Bou{-}Harb and
                  Peyman Najafirad},
	title = {An Unbiased Transformer Source Code Learning with Semantic Vulnerability
                  Graph},
	booktitle = {8th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2023, Delft, Netherlands, July 3-7, 2023},
	pages = {144--159},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/EuroSP57164.2023.00018},
	doi = {10.1109/EUROSP57164.2023.00018},
	timestamp = {Mon, 07 Aug 2023 15:56:23 +0200},
	biburl = {https://dblp.org/rec/conf/eurosp/IslamPMBN23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Over the years, open-source software systems have become prey to threat actors. Even highly-adopted software has been crippled by unforeseeable attacks, leaving millions of devices exposed. Even as open-source communities act quickly to patch the breach, code vulnerability screening should be an integral part of agile software development from the beginning. Unfortunately, current vulnerability screening techniques are ineffective at identifying novel vulnerabilities or providing developers with code vulnerability and classification. Furthermore, the datasets used for vulnerability learning often exhibit distribution shifts from the real-world testing distribution due to novel attack strategies deployed by adversaries and as a result, the machine learning model’s performance may be hindered or biased. To address these issues, we propose a joint interpolated multitasked unbiased vulnerability classifier comprising a transformer "RoBERTa" and graph convolution neural network (GCN). We present a training process utilizing a semantic vulnerability graph (SVG) representation from source code, created by integrating edges from a sequential flow, control flow, and data flow, as well as a novel flow dubbed Poacher Flow (PF). Poacher flow edges reduce the gap between dynamic and static program analysis and handle complex long-range dependencies. Moreover, our approach reduces biases of classifiers regarding unbalanced datasets by integrating Focal Loss objective function along with SVG. Remarkably, experimental results show that our classifier outperforms state-of-the-art results on vulnerability detection with fewer false negatives and false positives. After testing our model across multiple datasets, it shows an improvement of at least 2.41% and 18.75% in the best-case scenario. Evaluations using N-day program samples demonstrate that our proposed approach achieves a 93% accuracy and was able to detect 4, zero-day vulnerabilities from popular GitHub repositories. Our code and data are available at https://github.com/pial08/SemVulDet}
}


@inproceedings{DBLP:conf/eurosp/EspositoSB23,
	author = {Sergio Esposito and
                  Daniele Sgandurra and
                  Giampaolo Bella},
	title = {Protecting Voice-Controllable Devices Against Self-Issued Voice Commands},
	booktitle = {8th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2023, Delft, Netherlands, July 3-7, 2023},
	pages = {160--174},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/EuroSP57164.2023.00019},
	doi = {10.1109/EUROSP57164.2023.00019},
	timestamp = {Mon, 07 Aug 2023 15:56:23 +0200},
	biburl = {https://dblp.org/rec/conf/eurosp/EspositoSB23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Self-issued voice commands leverage the voice-controllable device’s internal speaker to issue malicious voice commands to the device itself. These attacks are a class of voice spoofing attacks particularly challenging to protect from, as it is very hard for a countermeasure solution to infer whether the command comes from an external entity or from the device itself. In this paper, we propose a countermeasure against self-issued voice commands by training a Twin Neural Network to recognise the differences between what is being played and what is being recorded by the voice-controllable device. In fact, these audios are very similar in case of voice command self-issue attacks and different in case of legitimate commands. We start with a security and usability trade-off analysis of countermeasures against voice spoofing attacks, by describing different classes of synthesised voice commands that need to be blocked or allowed, depending on the necessities of the user. Then, we present our solution to protect voice-controllable devices from self-issued commands and show that it correctly classifies commands in the benign (real-user) and malign (self-issued) categories 97% of the times on average. We compare this result with state-of-the-art anomaly detection techniques as a baseline and show that our solution outperforms them. Furthermore, we instantiate our countermeasure on three different classes of devices to measure its performance, and we find that the additional overhead is negligible. Finally, we measure the usability impact of our solution when users interact with the tested device under different conditions, showing that our solution is resistant to environmental changes and regardless of the identity of the user issuing the commands.}
}


@inproceedings{DBLP:conf/eurosp/BoenischDSSSP23,
	author = {Franziska Boenisch and
                  Adam Dziedzic and
                  Roei Schuster and
                  Ali Shahin Shamsabadi and
                  Ilia Shumailov and
                  Nicolas Papernot},
	title = {When the Curious Abandon Honesty: Federated Learning Is Not Private},
	booktitle = {8th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2023, Delft, Netherlands, July 3-7, 2023},
	pages = {175--199},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/EuroSP57164.2023.00020},
	doi = {10.1109/EUROSP57164.2023.00020},
	timestamp = {Mon, 07 Aug 2023 15:56:23 +0200},
	biburl = {https://dblp.org/rec/conf/eurosp/BoenischDSSSP23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In federated learning (FL), data does not leave personal devices when they are jointly training a machine learning model. Instead, these devices share gradients, parameters, or other model updates, with a central party (e.g., a company) coordinating the training. Because data never "leaves" personal devices, FL is often presented as privacy-preserving. Yet, recently it was shown that this protection is but a thin facade, as even a passive, honest-but-curious attacker observing gradients can reconstruct data of individual users contributing to the protocol.In this work, we show a novel data reconstruction attack which allows an active and dishonest central party to efficiently extract user data from the received gradients. While prior work on data reconstruction in FL relies on solving computationally expensive optimization problems or on making easily detectable modifications to the shared model’s architecture or parameters, in our attack the central party makes inconspicuous changes to the shared model’s weights before sending them out to the users. We call the modified weights of our attack trap weights.Our active attacker is able to recover user data perfectly, i.e., with zero error, even when this data stems from the same class. Recovery comes with near-zero costs: the attack requires no complex optimization objectives. Instead, our attacker exploits inherent data leakage from model gradients and simply amplifies this effect by maliciously altering the weights of the shared model through the trap weights. These specificities enable our attack to scale to fully-connected and convolutional deep neural networks trained with large mini-batches of data. For example, for the high-dimensional vision dataset ImageNet, we perfectly reconstruct more than 50% of the training data points from mini-batches as large as 100 data points. In textual tasks, such as IMDB sentiment analysis, more than 65% of data points from mini-batches containing 100 data points can be perfectly reconstructed.}
}


@inproceedings{DBLP:conf/eurosp/QuLW23,
	author = {Wenjie Qu and
                  Youqi Li and
                  Binghui Wang},
	title = {A Certified Radius-Guided Attack Framework to Image Segmentation Models},
	booktitle = {8th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2023, Delft, Netherlands, July 3-7, 2023},
	pages = {200--220},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/EuroSP57164.2023.00021},
	doi = {10.1109/EUROSP57164.2023.00021},
	timestamp = {Mon, 07 Aug 2023 15:56:23 +0200},
	biburl = {https://dblp.org/rec/conf/eurosp/QuLW23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Image segmentation is an important problem in many safety-critical applications such as medical imaging and autonomous driving. Recent studies show that modern image segmentation models are vulnerable to adversarial perturbations, while existing attack methods mainly follow the idea of attacking image classification models. We argue that image segmentation and classification have inherent differences, and design an attack framework specially for image segmentation models. Our goal is to thoroughly explore the vulnerabilities of modern segmentation models, i.e., aiming to misclassify as many pixels as possible under a perturbation budget in both white-box and black-box settings.Our attack framework is inspired by certified radius, which was originally used by defenders to defend against adversarial perturbations to classification models. We are the first, from the attacker perspective, to leverage the properties of certified radius and propose a certified radius guided attack framework against image segmentation models. Specifically, we first adapt randomized smoothing, the state-of-the-art certification method for classification models, to derive the pixel’s certified radius. A larger certified radius of a pixel means the pixel is theoretically more robust to adversarial perturbations. This observation inspires us to focus more on disrupting pixels with relatively smaller certified radii. Accordingly, we design a pixel-wise certified radius guided loss, when plugged into any existing white-box attack, yields our certified radius-guided white-box attack.Next, we propose the first black-box attack to image segmentation models via bandit. A key challenge is no gradient information is available. To address it, we design a novel gradient estimator, based on bandit feedback, which is query-efficient and provably unbiased and stable. We use this gradient estimator to design a projected bandit gradient descent (PBGD) attack. We further use pixels’ certified radii and design a certified radius-guided PBGD (CR-PBGD) attack. We prove our PBGD and CR-PBGD attacks can achieve asymptotically optimal attack performance with an optimal rate. We evaluate our certified-radius guided white-box and black-box attacks on multiple modern image segmentation models and datasets. Our results validate the effectiveness of our certified radius-guided attack framework.}
}


@inproceedings{DBLP:conf/eurosp/NadeemVCPDBV23,
	author = {Azqa Nadeem and
                  Dani{\"{e}}l Vos and
                  Clinton Cao and
                  Luca Pajola and
                  Simon Dieck and
                  Robert Baumgartner and
                  Sicco Verwer},
	title = {SoK: Explainable Machine Learning for Computer Security Applications},
	booktitle = {8th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2023, Delft, Netherlands, July 3-7, 2023},
	pages = {221--240},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/EuroSP57164.2023.00022},
	doi = {10.1109/EUROSP57164.2023.00022},
	timestamp = {Mon, 07 Aug 2023 15:56:23 +0200},
	biburl = {https://dblp.org/rec/conf/eurosp/NadeemVCPDBV23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Explainable Artificial Intelligence (XAI) aims to improve the transparency of machine learning (ML) pipelines. We systematize the increasingly growing (but fragmented) microcosm of studies that develop and utilize XAI methods for defensive and offensive cybersecurity tasks. We identify 3 cybersecurity stakeholders, i.e., model users, designers, and adversaries, who utilize XAI for 4 distinct objectives within an ML pipeline, namely 1) XAI-enabled user assistance, 2) XAI-enabled model verification, 3) explanation verification & robustness, and 4) offensive use of explanations. Our analysis of the literature indicates that many of the XAI applications are designed with little understanding of how they might be integrated into analyst workflows – user studies for explanation evaluation are conducted in only 14% of the cases. The security literature sometimes also fails to disentangle the role of the various stakeholders, e.g., by providing explanations to model users and designers while also exposing them to adversaries. Additionally, the role of model designers is particularly minimized in the security literature. To this end, we present an illustrative tutorial for model designers, demonstrating how XAI can help with model verification. We also discuss scenarios where interpretability by design may be a better alternative. The systematization and the tutorial enable us to challenge several assumptions, and present open problems that can help shape the future of XAI research within cybersecurity.}
}


@inproceedings{DBLP:conf/eurosp/BoenischDSSSP23a,
	author = {Franziska Boenisch and
                  Adam Dziedzic and
                  Roei Schuster and
                  Ali Shahin Shamsabadi and
                  Ilia Shumailov and
                  Nicolas Papernot},
	title = {Reconstructing Individual Data Points in Federated Learning Hardened
                  with Differential Privacy and Secure Aggregation},
	booktitle = {8th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2023, Delft, Netherlands, July 3-7, 2023},
	pages = {241--257},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/EuroSP57164.2023.00023},
	doi = {10.1109/EUROSP57164.2023.00023},
	timestamp = {Mon, 07 Aug 2023 15:56:23 +0200},
	biburl = {https://dblp.org/rec/conf/eurosp/BoenischDSSSP23a.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated learning (FL) is a framework for users to jointly train a machine learning model. FL is promoted as a privacy-enhancing technology (PET) that provides data minimization: data never "leaves" personal devices and users share only model updates with a server (e.g., a company) coordinating the distributed training. While prior work showed that in vanilla FL a malicious server can extract users’ private data from the model updates, in this work we take it further and demonstrate that a malicious server can reconstruct user data even in hardened versions of the protocol. More precisely, we propose an attack against FL protected with distributed differential privacy (DDP) and secure aggregation (SA). Our attack method is based on the introduction of sybil devices that deviate from the protocol to expose individual users’ data for reconstruction by the server. The underlying root cause for the vulnerability to our attack is a power imbalance: the server orchestrates the whole protocol and users are given little guarantees about the selection of other users participating in the protocol. Moving forward, we discuss requirements for privacy guarantees in FL. We conclude that users should only participate in the protocol when they trust the server or they apply local primitives such as local DP, shifting power away from the server. Yet, the latter approaches come at significant overhead in terms of performance degradation of the trained model, making them less likely to be deployed in practice.}
}


@inproceedings{DBLP:conf/eurosp/JainGPM23,
	author = {Vijayanta Jain and
                  Sepideh Ghanavati and
                  Sai Teja Peddinti and
                  Collin McMillan},
	title = {Towards Fine-Grained Localization of Privacy Behaviors},
	booktitle = {8th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2023, Delft, Netherlands, July 3-7, 2023},
	pages = {258--277},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/EuroSP57164.2023.00024},
	doi = {10.1109/EUROSP57164.2023.00024},
	timestamp = {Sun, 12 Nov 2023 02:15:27 +0100},
	biburl = {https://dblp.org/rec/conf/eurosp/JainGPM23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Privacy labels help developers communicate their application’s privacy behaviors (i.e., how and why an application uses personal information) to users. But, studies show that developers face several challenges in creating them and the resultant labels are often inconsistent with their application’s privacy behaviors. In this paper, we create a novel methodology called fine-grained localization of privacy behaviors to locate individual statements in source code which encode privacy behaviors and predict their privacy labels. We design and develop an attention-based multi-head encoder model which creates individual representations of multiple methods and uses attention to identify relevant statements that implement privacy behaviors. These statements are then used to predict privacy labels for the application’s source code and can help developers write privacy statements that can be used as notices. Our quantitative analysis shows that our approach can achieve high accuracy in identifying privacy labels, with the lowest accuracy of 91.41% and the highest of 98.45%. We also evaluate the efficacy of our approach with six software professionals from our university. The results demonstrate that our approach reduces the time and mental effort required by developers to create high-quality privacy statements and can finely localize statements in methods that implement privacy behaviors.}
}


@inproceedings{DBLP:conf/eurosp/hammeGPJ23,
	author = {Tim Van hamme and
                  Giuseppe Garofalo and
                  Davy Preuveneers and
                  Wouter Joosen},
	title = {Masterkey attacks against free-text keystroke dynamics and security
                  implications of demographic factors},
	booktitle = {8th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2023, Delft, Netherlands, July 3-7, 2023},
	pages = {278--291},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/EuroSP57164.2023.00025},
	doi = {10.1109/EUROSP57164.2023.00025},
	timestamp = {Sun, 12 Nov 2023 02:15:27 +0100},
	biburl = {https://dblp.org/rec/conf/eurosp/hammeGPJ23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper presents and systematically evaluates the first masterkey attack against free-text keystroke dynamics. A masterkey is a typing sequence that matches, hence successfully impersonates, a large part of the population. Therefore, masterkeys are effective tools for an adversary who aims to impersonate someone without knowledge of their typing behavior. On top of the attack itself, we present a new unifying evaluation framework for masterkey attacks that allow for the comparison with knowledge-based authentication factors. In other words, we unify the evaluation of password security with that of masterkey attacks and demonstrate that typing biometrics is approximately 20 times less secure than passwords and approximately two times less secure than a 4-digit pin. Lastly, we study the effect of demographics on typing biometrics, which, among others, provides novel insights into the effect of being a well-versed typist on security.}
}


@inproceedings{DBLP:conf/eurosp/TiemannBEL23,
	author = {Thore Tiemann and
                  Sebastian Berndt and
                  Thomas Eisenbarth and
                  Maciej Liskiewicz},
	title = {"Act natural!": Exchanging Private Messages on Public Blockchains},
	booktitle = {8th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2023, Delft, Netherlands, July 3-7, 2023},
	pages = {292--308},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/EuroSP57164.2023.00026},
	doi = {10.1109/EUROSP57164.2023.00026},
	timestamp = {Sun, 12 Nov 2023 02:15:27 +0100},
	biburl = {https://dblp.org/rec/conf/eurosp/TiemannBEL23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Messengers have become an essential means of interpersonal interaction. Yet untraceable private communication remains an elusive goal, as most messengers hide content, but not communication patterns. The knowledge of communication patterns can by itself reveal too much, as happened, e. g., in the context of the Arab Spring. Subliminal channels in cryptographic systems enable untraceable private communication in plain sight. In this context, bulletin boards in the form of blockchains are a natural object for subliminal communication: accessing them is innocuous, as they rely on distributed access for verification and extension. At the same time, blockchain users generate hundreds of thousands of transactions per day that are individually signed and placed on the blockchain. Thus blockchains may serve as innocuous repository for publicly accessible cryptographic transactions where subliminal channels can be placed. In this paper, we propose a public-key subliminal channel using secret-recoverable splittable signature schemes on blockchains and prove that our construction is undetectable in the random oracle model under common cryptographic assumptions. Our approach is applicable to any secret-recoverable splittable signature scheme and introduces a constant overhead of a single signature per message. Such schemes are used by 98 of the top 100 cryptocurrencies. We also analyze the applicability of our approach to the Bitcoin, Monero, and RippleNet networks and present proof of concept implementations for Bitcoin and RippleNet.}
}


@inproceedings{DBLP:conf/eurosp/SolomonWA23,
	author = {Ravital Solomon and
                  Rick Weber and
                  Ghada Almashaqbeh},
	title = {smartFHE: Privacy-Preserving Smart Contracts from Fully Homomorphic
                  Encryption},
	booktitle = {8th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2023, Delft, Netherlands, July 3-7, 2023},
	pages = {309--331},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/EuroSP57164.2023.00027},
	doi = {10.1109/EUROSP57164.2023.00027},
	timestamp = {Mon, 07 Aug 2023 15:56:23 +0200},
	biburl = {https://dblp.org/rec/conf/eurosp/SolomonWA23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Despite the great potential and flexibility of smart contract-enabled blockchains, building privacy-preserving applications using these platforms remains an open question. Existing solutions fall short since they ask end users to coordinate and perform the computation off-chain themselves. While such an approach reduces the burden of the miners of the system, it largely limits the ability of lightweight users to enjoy privacy since performing the actual computation on their own and attesting to its correctness is expensive even with state-of-the-art proof systems.To address this limitation, we propose smartFHE, a framework to support private smart contracts using fully homomorphic encryption (FHE). To the best of our knowledge, smartFHE is the first to use FHE in the blockchain model; moreover, it is the first to support arbitrary privacy-preserving applications for lightweight users under the same computation-on-demand model pioneered by Ethereum. smartFHE does not overload the user since miners are instead responsible for performing the private computation. This is achieved by employing FHE so miners can compute over encrypted data and account balances. Users are only responsible for proving well-formedness of their private inputs using efficient zero-knowledge proof systems (ZKPs). We formulate a notion for a privacy-preserving smart contract (PPSC) scheme and show a concrete instantiation of our smartFHE framework. We address challenges resulting from using FHE in the blockchain setting—including concurrency and dealing with leveled schemes. We also show how to choose suitable FHE and ZKP schemes to instantiate our framework, since naively choosing these will lead to poor performance in practice. We formally prove correctness and security of our construction. Finally, we conduct experiments to evaluate its efficiency, including comparisons with a state-of-the-art scheme and testing several private smart contract applications. We have open-sourced our (highly optimized) ZKP library, which could be of independent interest.}
}


@inproceedings{DBLP:conf/eurosp/ChenWZDTWL23,
	author = {Jiaqi Chen and
                  Yibo Wang and
                  Yuxuan Zhou and
                  Wanning Ding and
                  Yuzhe Tang and
                  XiaoFeng Wang and
                  Kai Li},
	title = {Understanding the Security Risks of Decentralized Exchanges by Uncovering
                  Unfair Trades in the Wild},
	booktitle = {8th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2023, Delft, Netherlands, July 3-7, 2023},
	pages = {332--351},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/EuroSP57164.2023.00028},
	doi = {10.1109/EUROSP57164.2023.00028},
	timestamp = {Mon, 05 Feb 2024 20:31:17 +0100},
	biburl = {https://dblp.org/rec/conf/eurosp/ChenWZDTWL23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {DEX, or decentralized exchange, is a prominent class of decentralized finance (DeFi) applications on blockchains, attracting a total locked value worth tens of billions of USD today.This paper presents the first large-scale empirical study that uncovers unfair trades on popular DEX services on Ethereum and Binance Smart Chain (BSC). By joining and analyzing 60 million transactions, we find 671, 400 unfair trades on all six measured DEXes, including Uniswap, Balancer, and Curve. Out of these unfair trades, we attribute 55, 000 instances, with high confidence, to token thefts that cause a value loss of more than 3.88 million USD. Furthermore, the measurement study uncovers previously unknown causes of extractable value and real-world adaptive strategies to these causes. Finally, we propose countermeasures to redesign secure DEX protocols and to harden deployed services against the discovered security risks.}
}


@inproceedings{DBLP:conf/eurosp/XuYZF23,
	author = {Rongwu Xu and
                  Sen Yang and
                  Fan Zhang and
                  Zhixuan Fang},
	title = {{MISO:} Legacy-compatible Privacy-preserving Single Sign-on using
                  Trusted Execution Environments},
	booktitle = {8th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2023, Delft, Netherlands, July 3-7, 2023},
	pages = {352--372},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/EuroSP57164.2023.00029},
	doi = {10.1109/EUROSP57164.2023.00029},
	timestamp = {Thu, 12 Oct 2023 13:32:35 +0200},
	biburl = {https://dblp.org/rec/conf/eurosp/XuYZF23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Single sign-on (SSO) allows users to authenticate to third-party applications through a central identity provider. Despite their wide adoption, deployed SSO systems suffer from privacy problems such as user tracking by the identity provider. While numerous solutions have been proposed by academic papers, none were adopted because they require modifying identity providers, a significant adoption barrier in practice. Solutions do get deployed, however, fail to eliminate major privacy issues.Leveraging Trusted Execution Environments (TEEs), we propose MISO, the first privacy-preserving SSO system that is completely compatible with existing identity providers (such as Google and Facebook). This means MISO can be easily integrated into existing SSO ecosystem today and benefit end users. MI SO also enables new functionality that standard SSO cannot offer: MISO allows users to leverage multiple identity providers in a single SSO workflow, potentially in a threshold fashion, to better protect user accounts. We fully implemented MISO based on Intel SGX. Our evaluation shows that MISO can handle high user concurrency with practical performance.}
}


@inproceedings{DBLP:conf/eurosp/LiuAJMHVS23,
	author = {Enze Liu and
                  Gautam Akiwate and
                  Mattijs Jonker and
                  Ariana Mirian and
                  Grant Ho and
                  Geoffrey M. Voelker and
                  Stefan Savage},
	title = {Forward Pass: On the Security Implications of Email Forwarding Mechanism
                  and Policy},
	booktitle = {8th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2023, Delft, Netherlands, July 3-7, 2023},
	pages = {373--391},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/EuroSP57164.2023.00030},
	doi = {10.1109/EUROSP57164.2023.00030},
	timestamp = {Tue, 07 May 2024 20:06:33 +0200},
	biburl = {https://dblp.org/rec/conf/eurosp/LiuAJMHVS23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The critical role played by email has led to a range of extension protocols (e.g., SPF, DKIM, DMARC) designed to protect against the spoofing of email sender domains. These protocols are complex as is, but are further complicated by automated email forwarding — used by individual users to manage multiple accounts and by mailing lists to redistribute messages. In this paper, we explore how such email forwarding and its implementations can break the implicit assumptions in widely deployed anti-spoofing protocols. Using large-scale empirical measurements of 20 email forwarding services (16 leading email providers and four popular mailing list services), we identify a range of security issues rooted in forwarding behavior and show how they can be combined to reliably evade existing anti-spoofing controls. We further show how these issues allow attackers to not only deliver spoofed email messages to prominent email providers (e.g., Gmail, Microsoft Outlook, and Zoho), but also reliably spoof email on behalf of tens of thousands of popular domains including sensitive domains used by organizations in government (e.g., state.gov), finance (e.g., transunion.com), law (e.g., perkinscoie.com) and news (e.g., washingtonpost.com) among others.}
}


@inproceedings{DBLP:conf/eurosp/AkimotoFAS23,
	author = {Yoshimasa Akimoto and
                  Kazuto Fukuchi and
                  Youhei Akimoto and
                  Jun Sakuma},
	title = {Privformer: Privacy-preserving Transformer with {MPC}},
	booktitle = {8th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2023, Delft, Netherlands, July 3-7, 2023},
	pages = {392--410},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/EuroSP57164.2023.00031},
	doi = {10.1109/EUROSP57164.2023.00031},
	timestamp = {Mon, 07 Aug 2023 15:56:23 +0200},
	biburl = {https://dblp.org/rec/conf/eurosp/AkimotoFAS23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Transformer is a deep learning architecture that processes sequence data. The Transformer attains the state-of-the-art in several tasks of sequence data analysis, and its variants, such as BERT and GPT-3, are used as a defacto-standard for solving general tasks in natural language processing (NLP). This work presents a 3-party multi-party computation (MPC) protocol for secure inference of the Transfomer in the honest majority setting. The attention layer is the most time-consuming part when implementing an MPC protocol for the Transformer with existing building blocks. The attention mechanism is a core component of the Transformer that captures and exploits complex dependencies among elements in the input sequences. The attention mechanism invokes the exponentiation function O(S 2 ) times, which becomes a major bottleneck when implementing the Transformer with existing MPC primitives. To deal with this, we employ the Performer [11], a variant of the Transformer where the sigmoid function that invokes the exponentiation function is replaced with the ReLU function, a more MPC-friendly nonlinear function. Also, by introducing a kernel-based approximation of the attention matrix with random orthogonal matrices, we show that the attention layer can be processed with O(S) times calls of the ReLU function. We investigate the efficiency of the proposed method by an end-to-end implementation of the Transformer with 3-party MPC. Experimental evaluation shows that, for translating a sequence where the output sequence length is 64, the entire computation time takes about 19 minutes in the LAN environment.}
}


@inproceedings{DBLP:conf/eurosp/RenY23,
	author = {Mengxia Ren and
                  Chuan Yue},
	title = {Coverage and Secure Use Analysis of Content Security Policies via
                  Clustering},
	booktitle = {8th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2023, Delft, Netherlands, July 3-7, 2023},
	pages = {411--428},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/EuroSP57164.2023.00032},
	doi = {10.1109/EUROSP57164.2023.00032},
	timestamp = {Mon, 07 Aug 2023 15:56:23 +0200},
	biburl = {https://dblp.org/rec/conf/eurosp/RenY23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Content Security Policy (CSP) is a standardized leading technique for protecting webpages against attacks such as Cross Site Scripting (XSS). However, it is often hard to properly deploy CSPs on webpages, and the deployed CSPs often contain security issues or errors. In this paper, we take the unsupervised clustering approach to analyze the security levels of the deployed CSPs from the directive coverage and secure use perspectives. To effectively protect a webpage, a deployed CSP should cover all types of resources needed on the webpage by using different directive names (or some default directive names if available), and should avoid using unsafe directive values which will allow harmful resources to be loaded into a webpage. We implemented a Google Chrome extension, designed policy features, designed a Contrastive Spectral Clustering (CSC) algorithm, and visited the Alexa top 100K websites to analyze the CSPs deployed on them. From the 13,317 homepages that deployed CSPs under the enforcement mode, we categorized their policies into 16 clusters with different characteristics. We found that 15 clusters are at the low level on the coverage and five clusters are at the low level on the secure use of directives; meanwhile, no cluster is at the high level on the coverage of directives, and nine clusters are at the high level on the secure use of directives. These results indicate that most deployed CSPs do not sufficiently protect webpages, and more importantly, clustering helps identify the corresponding common or different reasons from the directive coverage and secure use perspectives. In addition, by analyzing 110,718 subpages of the 13,317 CSP-deployed homepages, we found that most of them deployed the same CSP as in their homepages. Overall, our approach and results can be helpful for promoting the proper deployment of CSPs.}
}


@inproceedings{DBLP:conf/eurosp/ErwigFRS23,
	author = {Andreas Erwig and
                  Sebastian Faust and
                  Siavash Riahi and
                  Tobias St{\"{o}}ckert},
	title = {CommiTEE : An Efficient and Secure Commit-Chain Protocol using TEEs},
	booktitle = {8th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2023, Delft, Netherlands, July 3-7, 2023},
	pages = {429--448},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/EuroSP57164.2023.00033},
	doi = {10.1109/EUROSP57164.2023.00033},
	timestamp = {Fri, 11 Aug 2023 09:21:40 +0200},
	biburl = {https://dblp.org/rec/conf/eurosp/ErwigFRS23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Permissionless blockchain systems such as Bitcoin or Ethereum are slow and expensive, since transactions are processed in a distributed network by a large set of parties. To improve on these shortcomings, a prominent approach is given by so-called 2nd-layer protocols. In these protocols parties process transactions off-chain directly between each other, thereby drastically reducing the costly and slow interaction with the blockchain. In particular, in the optimistic case, when parties behave honestly, no interaction with the blockchain is needed. One of the most popular off-chain solutions are Plasma protocols (often also called commit-chains). These protocols are orchestrated by a so-called operator that maintains the system and processes transactions between parties. Importantly, the operator is trustless, i.e., even if it is malicious users of the system are guaranteed to not lose funds. To achieve this guarantee, Plasma protocols are highly complex and rely on involved and expensive dispute resolution processes. This has significantly slowed down development and deployment of these systems.In this work we propose CommiTEE – a simple and efficient Plasma system leveraging the power of trusted execution environments (TEE). Besides its simplicity, our protocol requires minimal interaction with the blockchain, thereby drastically reducing costs and improving efficiency. An additional benefit of our solution is that it allows for switching between operators, in case the main operator goes offline due to system failure, or behaving maliciously. We implemented and evaluated our system over Ethereum and show that it is at least 2 times (and in some cases more than 16 times) cheaper in terms of communication complexity when compared to existing Plasma implementations. Moreover, for protocols using zero-knowledge proofs (like NOCUST-ZKP), CommiTEE decreases the on-chain gas cost by a factor ≈ 19 compared to prior solution.}
}


@inproceedings{DBLP:conf/eurosp/RodlerPLBHKD23,
	author = {Michael Rodler and
                  David Paa{\ss}en and
                  Wenting Li and
                  Lukas Bernhard and
                  Thorsten Holz and
                  Ghassan Karame and
                  Lucas Davi},
	title = {EF{\unicode{8623}}CF: High Performance Smart Contract Fuzzing for
                  Exploit Generation},
	booktitle = {8th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2023, Delft, Netherlands, July 3-7, 2023},
	pages = {449--471},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/EuroSP57164.2023.00034},
	doi = {10.1109/EUROSP57164.2023.00034},
	timestamp = {Mon, 07 Aug 2023 15:56:23 +0200},
	biburl = {https://dblp.org/rec/conf/eurosp/RodlerPLBHKD23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Smart contracts are increasingly being used to manage large numbers of high-value cryptocurrency accounts. There is a strong demand for automated, efficient, and comprehensive methods to detect security vulnerabilities in a given contract. While the literature features a plethora of analysis methods for smart contracts, the existing proposals do not address the increasing complexity of contracts. Existing analysis tools suffer from false alarms and missed bugs in today’s smart contracts that are increasingly defined by complexity and interdependencies. To scale accurate analysis to modern smart contracts, we introduce EF↯CF, a high-performance fuzzer for Ethereum smart contracts. In contrast to previous work, EF↯CF efficiently and accurately models complex smart contract interactions, such as reentrancy and cross-contract interactions, at a very high fuzzing throughput rate. To achieve this, EF↯CF transpiles smart contract bytecode into native C++ code, thereby enabling the reuse of existing, optimized fuzzing toolchains. Furthermore, EF↯CF increases fuzzing efficiency by employing a structure-aware mutation engine for smart contract transaction sequences and using a contract’s ABI to generate valid transaction inputs. In a comprehensive evaluation, we show that EF↯CF scales better—without compromising accuracy—to complex contracts compared to state-of-the-art approaches, including other fuzzers, symbolic/concolic execution, and hybrid approaches. Moreover, we show that EF↯CF can automatically generate transaction sequences that exploit reentrancy bugs to steal Ether.}
}


@inproceedings{DBLP:conf/eurosp/KhanZKXBT23,
	author = {Arslan Khan and
                  Muqi Zou and
                  Kyungtae Kim and
                  Dongyan Xu and
                  Antonio Bianchi and
                  Dave Jing Tian},
	title = {Fuzzing {SGX} Enclaves via Host Program Mutations},
	booktitle = {8th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2023, Delft, Netherlands, July 3-7, 2023},
	pages = {472--488},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/EuroSP57164.2023.00035},
	doi = {10.1109/EUROSP57164.2023.00035},
	timestamp = {Mon, 07 Aug 2023 15:56:23 +0200},
	biburl = {https://dblp.org/rec/conf/eurosp/KhanZKXBT23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Intel Software Guard eXtension (SGX) is the cornerstone of Confidential Computing, enabling runtime code and data integrity and confidentiality via enclaves. Unfortunately, memory-unsafe and type-unsafe programming languages, such as C/C++, are commonly used to develop enclave implementations. As a result, a memory corruption or a data race within enclaves could lead to different attacks against the enclaves, such as Return-Of-Programming (ROP) and data leakage, breaking the hardware security guarantee provided by SGX. To automatically identify these issues in existing enclave implementations, in this paper, we propose FuzzSGX, an input and program mutation-based fuzzer for Intel SGX enclave implementations. FuzzSGX provides an enclave fuzzing runtime, FuzzSGX Runtime, a drop-in library for Intel SGX SDK, enabling code coverage and sanitization within enclaves. To explore the host app-enclave boundary, FuzzSGX conducts static analysis and symbolic execution on existing host apps and enclave implementations to generate promising fuzzing programs, fuzzing both ECALLs and OCALLs. We evaluate FuzzSGX using 30 popular SGX applications and enclave implementations and find 93 bugs among these SGX projects, including data races, null pointer dereferences, out-of-bound accesses, division-by-zero, etc. FuzzSGX achieves 3.2x higher code coverage and finds 48.2% more bugs by directly targeting the host appenclave boundary by using program mutations, compared to state-of-the-art fuzzers.}
}


@inproceedings{DBLP:conf/eurosp/DunlapTER23,
	author = {Trevor Dunlap and
                  Seaver Thorn and
                  William Enck and
                  Bradley Reaves},
	title = {Finding Fixed Vulnerabilities with Off-the-Shelf Static Analysis},
	booktitle = {8th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2023, Delft, Netherlands, July 3-7, 2023},
	pages = {489--505},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/EuroSP57164.2023.00036},
	doi = {10.1109/EUROSP57164.2023.00036},
	timestamp = {Mon, 05 Feb 2024 20:31:17 +0100},
	biburl = {https://dblp.org/rec/conf/eurosp/DunlapTER23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Software depends on upstream projects that regularly fix vulnerabilities, but the documentation of those vulnerabilities is often unreliable or unavailable. Automating the collection of existing vulnerability fixes is essential for downstream projects to reliably update their dependencies due to the sheer number of dependencies in modern software. Prior efforts rely solely on incomplete databases or imprecise or inaccurate statistical analysis of upstream repositories. In this paper, we introduce Differential Alert Analysis (DAA) to discover vulnerability fixes in software projects. In contrast to statistical analysis, DAA leverages static analysis security testing (SAST) tools, which reason over code context and semantics. We provide a language-independent implementation of DAA and show that for Python and Java based projects, DAA has high precision for a ground-truth dataset of vulnerability fixes — even with noisy and low-precision SAST tools. We then use DAA in two large-scale empirical studies covering several prominent ecosystems, finding hundreds of resolved alerts, including many never publicly disclosed. DAA thus provides a powerful, accurate primitive for software projects, code analysis tools, vulnerability databases, and researchers to characterize and enhance the security of software supply chains.}
}


@inproceedings{DBLP:conf/eurosp/SunejaZZLMK23,
	author = {Sahil Suneja and
                  Yufan Zhuang and
                  Yunhui Zheng and
                  Jim Laredo and
                  Alessandro Morari and
                  Udayan Khurana},
	title = {Code Vulnerability Detection via Signal-Aware Learning},
	booktitle = {8th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2023, Delft, Netherlands, July 3-7, 2023},
	pages = {506--523},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/EuroSP57164.2023.00037},
	doi = {10.1109/EUROSP57164.2023.00037},
	timestamp = {Mon, 07 Aug 2023 15:56:23 +0200},
	biburl = {https://dblp.org/rec/conf/eurosp/SunejaZZLMK23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Machine Learning-based modeling of source code understanding tasks has been gaining popularity. Accompanying their rapid proliferation is an emerging scrutiny over the models’ reliability. Concerns have been raised regarding the models not actually learning task-relevant source code features, but fitting other correlated data. To improve model trustworthiness, in this work, we explore data-driven approaches for enhancing model signal awareness, i.e., learning the relevant signals in the input for making predictions. We do so by incorporating the notion of code complexity during model training, both (i) explicitly via curriculum learning, and (ii) implicitly by augmenting the training dataset with simplified signal-preserving programs. With our techniques, we achieve up to 4.8x improvement in signal awareness of vulnerability detection models. Using the notion of code complexity, we present a novel interpretation of the model learning behaviour from the perspective of the dataset. We use it to introspect model learning difficulties, and analyze the learning enhancements achieved with our approaches.}
}


@inproceedings{DBLP:conf/eurosp/GanzRHR23,
	author = {Tom Ganz and
                  Philipp Rall and
                  Martin H{\"{a}}rterich and
                  Konrad Rieck},
	title = {Hunting for Truth: Analyzing Explanation Methods in Learning-based
                  Vulnerability Discovery},
	booktitle = {8th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2023, Delft, Netherlands, July 3-7, 2023},
	pages = {524--541},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/EuroSP57164.2023.00038},
	doi = {10.1109/EUROSP57164.2023.00038},
	timestamp = {Mon, 07 Aug 2023 15:56:23 +0200},
	biburl = {https://dblp.org/rec/conf/eurosp/GanzRHR23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recent research has developed a series of methods for finding vulnerabilities in software using machine learning. While the proposed methods provide a remarkable performance in controlled experiments, their practical application is hampered by their black-box nature: A security practitioner cannot tell how these methods arrive at a decision and what code structures contribute to a reported security flaw. Explanation methods for machine learning may overcome this problem and guide the practitioner to relevant code. However, there exist a variety of competing explanation methods, each highlighting different code regions when given the same finding. So far, this inconsistency has made it impossible to select a suitable explanation method for practical use.In this paper, we address this problem and develop a method for analyzing and comparing explanations for learning-based vulnerability discovery. Given a predicted vulnerability, our approach uses directed fuzzing to create local ground-truth around code regions marked as relevant by an explanation method. This local ground-truth enables us to assess the veracity of the explanation. As a result, we can qualitatively compare different explanation methods and determine the most accurate one for a particular learning setup. In an empirical evaluation with different discovery and explanation methods, we demonstrate the utility of this approach and its capabilities in making learning-based vulnerability discovery more transparent.}
}


@inproceedings{DBLP:conf/eurosp/MillerBWSZ23,
	author = {Rhys Miller and
                  Ioana Boureanu and
                  Stephan Wesemeyer and
                  Zhili Sun and
                  Hemant Zope},
	title = {Systematic Improvement of Access-Stratum Security in Mobile Networks},
	booktitle = {8th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2023, Delft, Netherlands, July 3-7, 2023},
	pages = {542--557},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/EuroSP57164.2023.00039},
	doi = {10.1109/EUROSP57164.2023.00039},
	timestamp = {Mon, 07 Aug 2023 15:56:23 +0200},
	biburl = {https://dblp.org/rec/conf/eurosp/MillerBWSZ23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In mobile networks, the User Equipment (UE) secures some of the communication with its serving Radio Access Network (RAN) node ("base station") via a set of keys known as Access Stratum (AS) keys. Unfortunately, the level of secrecy of these keys varies with the mobile procedures re-establishing them. To improve the secrecy of the AS keys, we propose minimal changes to 5G & 4G handovers, i.e., the main AS-key establishment procedures. We show the minimality of our changes also via an implementation of one of our protocols in the 3GPP-compliant Open5GCore 5G testbed. We also systematically cross-compare standard handovers with our amended handovers using MobTrustCom: a framework to quantify especially trust but also communication complexity in mobile networks. Moreover, we use Tamarin, a formal security-protocol verification tool, to prove no loss of "classical" security yet an increase in AS-keys\' secrecy brought by our improvements to handovers.}
}


@inproceedings{DBLP:conf/eurosp/BushartR23,
	author = {Jonas Bushart and
                  Christian Rossow},
	title = {Anomaly-based Filtering of Application-Layer DDoS Against {DNS} Authoritatives},
	booktitle = {8th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2023, Delft, Netherlands, July 3-7, 2023},
	pages = {558--575},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/EuroSP57164.2023.00040},
	doi = {10.1109/EUROSP57164.2023.00040},
	timestamp = {Mon, 07 Aug 2023 15:56:23 +0200},
	biburl = {https://dblp.org/rec/conf/eurosp/BushartR23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Authoritative DNS infrastructures are at the core of the Internet ecosystem. But how resilient are typical authoritative DNS name servers against application-layer Denial-of-Service attacks? In this paper, with the help of a large country-code TLD operator, we assess the expected attack load and DoS countermeasures. We find that standard botnets or even single-homed attackers can overload the computational resources of authoritative name servers—even if redundancy such as anycast is in place. To prevent the resulting devastating DNS outages, we assess how effective upstream filters can be as a last resort. We propose an anomaly detection defense that allows both, well-behaving high-volume DNS resolvers as well as low-volume clients to continue name lookups—while blocking most of the attack traffic. Upstream ISPs or IXPs can deploy our scheme and drop attack traffic to reasonable query loads at or below 100k queries per second at a false positive rate of 1.2% to 5.7% (median 2.4%).}
}


@inproceedings{DBLP:conf/eurosp/NawrockiKHKSW23,
	author = {Marcin Nawrocki and
                  John Kristoff and
                  Raphael Hiesgen and
                  Chris Kanich and
                  Thomas C. Schmidt and
                  Matthias W{\"{a}}hlisch},
	title = {SoK: {A} Data-driven View on Methods to Detect Reflective Amplification
                  DDoS Attacks Using Honeypots},
	booktitle = {8th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2023, Delft, Netherlands, July 3-7, 2023},
	pages = {576--591},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/EuroSP57164.2023.00041},
	doi = {10.1109/EUROSP57164.2023.00041},
	timestamp = {Sat, 30 Sep 2023 09:40:49 +0200},
	biburl = {https://dblp.org/rec/conf/eurosp/NawrockiKHKSW23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we revisit the use of honeypots for detecting reflective amplification attacks. These measurement tools require careful design of both data collection and data analysis including cautious threshold inference. We survey common amplification honeypot platforms as well as the underlying methods to infer attack detection thresholds and to extract knowledge from the data. By systematically exploring the threshold space, we find most honeypot platforms produce comparable results despite their different configurations. Moreover, by applying data from a large-scale honeypot deployment, network telescopes, and a real-world baseline obtained from a leading DDoS mitigation provider, we question the fundamental assumption of honeypot research that convergence of observations can imply their completeness. Conclusively we derive guidance on precise, reproducible honeypot research, and present open challenges.}
}


@inproceedings{DBLP:conf/eurosp/ApruzzeseLS23,
	author = {Giovanni Apruzzese and
                  Pavel Laskov and
                  Johannes Schneider},
	title = {SoK: Pragmatic Assessment of Machine Learning for Network Intrusion
                  Detection},
	booktitle = {8th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2023, Delft, Netherlands, July 3-7, 2023},
	pages = {592--614},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/EuroSP57164.2023.00042},
	doi = {10.1109/EUROSP57164.2023.00042},
	timestamp = {Mon, 05 Feb 2024 20:31:17 +0100},
	biburl = {https://dblp.org/rec/conf/eurosp/ApruzzeseLS23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Machine Learning (ML) has become a valuable asset to solve many real-world tasks. For Network Intrusion Detection (NID), however, scientific advances in ML are still seen with skepticism by practitioners. This disconnection is due to the intrinsically limited scope of research papers, many of which primarily aim to demonstrate new methods "outperforming" prior work—oftentimes overlooking the practical implications for deploying the proposed solutions in real systems. Unfortunately, the value of ML for NID depends on a plethora of factors, such as hardware, that are often neglected in scientific literature.This paper aims to reduce the practitioners’ skepticism towards ML for NID by changing the evaluation methodology adopted in research. After elucidating which factors influence the operational deployment of ML in NID, we propose the notion of pragmatic assessment, which enable practitioners to gauge the real value of ML methods for NID. Then, we show that the state-of-research hardly allows one to estimate the value of ML for NID. As a constructive step forward, we carry out a pragmatic assessment. We re-assess existing ML methods for NID, focusing on the classification of malicious network traffic, and consider: hundreds of configuration settings; diverse adversarial scenarios; and four hardware platforms. Our large and reproducible evaluations enable estimating the quality of ML for NID. We also validate our claims through a user-study with security practitioners.}
}


@inproceedings{DBLP:conf/eurosp/AgiolloBCLLO23,
	author = {Andrea Agiollo and
                  Enkeleda Bardhi and
                  Mauro Conti and
                  Riccardo Lazzeretti and
                  Eleonora Losiouk and
                  Andrea Omicini},
	title = {{GNN4IFA:} Interest Flooding Attack Detection With Graph Neural Networks},
	booktitle = {8th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2023, Delft, Netherlands, July 3-7, 2023},
	pages = {615--630},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/EuroSP57164.2023.00043},
	doi = {10.1109/EUROSP57164.2023.00043},
	timestamp = {Sun, 12 Nov 2023 02:15:27 +0100},
	biburl = {https://dblp.org/rec/conf/eurosp/AgiolloBCLLO23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the context of Information-Centric Networking, Interest Flooding Attacks (IFAs) represent a new and dangerous sort of distributed denial of service. Since existing proposals targeting IFAs mainly focus on local information, in this paper we propose GNN4IFA as the first mechanism exploiting complex non-local knowledge for IFA detection by leveraging Graph Neural Networks (GNNs) handling the overall network topology.In order to test GNN4IFA, we collect SPOTIFAI, a novel dataset filling the current lack of available IFA datasets by covering a variety of IFA setups, including ~40 heterogeneous scenarios over three network topologies. We show that GNN4IFA performs well on all tested topologies and setups, reaching over 99% detection rate along with a negligible false positive rate and small computational costs. Overall, GNN4IFA overcomes state-of-the-art detection mechanisms both in terms of raw detection and flexibility, and – unlike all previous solutions in the literature – also enables the transfer of its detection on network topologies different from the one used in its design phase.}
}


@inproceedings{DBLP:conf/eurosp/HoltrydMS23,
	author = {Nadja Ramh{\"{o}}j Holtryd and
                  Madhavan Manivannan and
                  Per Stenstr{\"{o}}m},
	title = {SoK: Analysis of Root Causes and Defense Strategies for Attacks on
                  Microarchitectural Optimizations},
	booktitle = {8th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2023, Delft, Netherlands, July 3-7, 2023},
	pages = {631--650},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/EuroSP57164.2023.00044},
	doi = {10.1109/EUROSP57164.2023.00044},
	timestamp = {Mon, 07 Aug 2023 15:56:23 +0200},
	biburl = {https://dblp.org/rec/conf/eurosp/HoltrydMS23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Microarchitectural optimizations are expected to play a crucial role in ensuring performance scalability in the post-Moore era. However, recent attacks have demonstrated that these optimizations, which were assumed to be secure, can be exploited. Moreover, new attacks surface at a rapid pace limiting the scope of existing defenses. These developments prompt the need to review microarchitectural optimizations with an emphasis on security, so as to understand the attack landscape and the potential defense strategies.We provide a framework to analyze attacks on a wide range of microarchitectural optimizations and use that to systematize both transient and non-transient attacks and defenses, while highlighting the similarities and differences. We identify four root causes of timing-based side-channel attacks: determinism, sharing, access violation and information flow, through our systematic analysis. Leveraging our framework, we systematize existing defenses and show that they target these root causes in the different attack steps. We believe that our framework can assist in understanding the attack and defense landscape and provide guidance for designing secure microarchitectural optimizations.}
}


@inproceedings{DBLP:conf/eurosp/BognarWBP23,
	author = {Marton Bognar and
                  Hans Winderix and
                  Jo Van Bulck and
                  Frank Piessens},
	title = {MicroProfiler: Principled Side-Channel Mitigation through Microarchitectural
                  Profiling},
	booktitle = {8th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2023, Delft, Netherlands, July 3-7, 2023},
	pages = {651--670},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/EuroSP57164.2023.00045},
	doi = {10.1109/EUROSP57164.2023.00045},
	timestamp = {Sun, 12 Nov 2023 02:15:27 +0100},
	biburl = {https://dblp.org/rec/conf/eurosp/BognarWBP23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Preventing information leakage through microarchitectural side channels is notoriously challenging and, as a result, an important research question. Recent work has shown the viability of compiler-assisted instruction balancing for small, embedded processors with deterministic timing behavior. However, even in such small processors, more subtle microarchitectural side channels continue to be discovered, complicating mitigation efforts.We propose a methodology for augmenting an existing instruction set architecture (ISA) specification with instruction-specific microarchitectural leakage traces obtained through principled microarchitectural profiling. Building on this augmented ISA, it becomes possible to construct software tools to detect and mitigate certain side-channel vulnerabilities. As a case study, we instantiate our methodology on a recently uncovered microarchitectural side channel, which is based on cycle-level timing differences of direct memory access (DMA) requests on 16-bit openMSP430 processors. Using the augmented ISA obtained for this side channel through microarchitectural profiling, we develop practical attack scenarios and extend a state-of-the-art compiler-based mitigation and a binary validation tool, both of which originally targeted a coarser-grained, instruction-granular side channel. Our benchmarks show that our extended compiler mitigation, while still mitigating the instruction-granular leakage, also eliminates the cycle-accurate DMA information leakage without incurring any additional overhead.}
}


@inproceedings{DBLP:conf/eurosp/MilburnSK23,
	author = {Alyssa Milburn and
                  Ke Sun and
                  Henrique Kawakami},
	title = {You Cannot Always Win the Race: Analyzing mitigations for branch target
                  prediction attacks},
	booktitle = {8th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2023, Delft, Netherlands, July 3-7, 2023},
	pages = {671--686},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/EuroSP57164.2023.00046},
	doi = {10.1109/EUROSP57164.2023.00046},
	timestamp = {Mon, 07 Aug 2023 15:56:23 +0200},
	biburl = {https://dblp.org/rec/conf/eurosp/MilburnSK23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Many recent attacks such as Branch Target Injection (BTI, aka Spectre v2) take advantage of speculative execution in modern processors, and in particular the inherent race condition between transient execution of code at the predicted target of a branch and the architectural resolution of the branch. This can create a speculation window in which code can be transiently executed at an unintended target, and mitigations for these attacks often focus on minimizing or removing such windows. By investigating the potential sources of latency that may contribute to such a speculation window, such as pipeline contention and simultaneous multithreading (SMT) activity, we show that an attacker can "win the race" despite the adoption of widely-used mitigations, on a variety of different x86 CPUs. We also show that such speculation windows may be present for predictions of direct branches. This enables a new class of BTI-style attacks that do not depend on indirect branches, and bypass the majority of previous mitigations against such attacks.}
}


@inproceedings{DBLP:conf/eurosp/ErataPMS23,
	author = {Ferhat Erata and
                  Ruzica Piskac and
                  V{\'{\i}}ctor Mateu and
                  Jakub Szefer},
	title = {Towards Automated Detection of Single-Trace Side-Channel Vulnerabilities
                  in Constant-Time Cryptographic Code},
	booktitle = {8th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2023, Delft, Netherlands, July 3-7, 2023},
	pages = {687--706},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/EuroSP57164.2023.00047},
	doi = {10.1109/EUROSP57164.2023.00047},
	timestamp = {Mon, 07 Aug 2023 15:56:23 +0200},
	biburl = {https://dblp.org/rec/conf/eurosp/ErataPMS23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Although cryptographic algorithms may be mathematically secure, it is often possible to leak secret information from the implementation of the algorithms. Timing and power side-channel vulnerabilities are some of the most widely considered threats to cryptographic algorithm implementations. Timing vulnerabilities may be easier to detect and exploit, and all high-quality cryptographic code today should be written in constant-time style. However, this does not prevent power side-channels from existing. With constant time code, potential attackers can resort to power side-channel attacks to try leaking secrets. Detecting potential power side-channel vulnerabilities is a tedious task, as it requires analyzing code at the assembly level and needs reasoning about which instructions could be leaking information based on their operands and their values. To help make the process of detecting potential power side-channel vulnerabilities easier for cryptographers, this work presents Pascal: Power Analysis Side Channel Attack Locator, a tool that introduces novel symbolic register analysis techniques for binary analysis of constant-time cryptographic algorithms, and verifies locations of potential power side-channel vulnerabilities with high precision. Pascal is evaluated on a number of implementations of post-quantum cryptographic algorithms, and it is able to find dozens of previously reported single-trace power side-channel vulnerabilities in these algorithms, all in an automated manner.}
}


@inproceedings{DBLP:conf/eurosp/BragaKSFB23,
	author = {Daniel De Almeida Braga and
                  Natalia Kulatova and
                  Mohamed Sabt and
                  Pierre{-}Alain Fouque and
                  Karthikeyan Bhargavan},
	title = {From Dragondoom to Dragonstar: Side-channel Attacks and Formally Verified
                  Implementation of {WPA3} Dragonfly Handshake},
	booktitle = {8th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2023, Delft, Netherlands, July 3-7, 2023},
	pages = {707--723},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/EuroSP57164.2023.00048},
	doi = {10.1109/EUROSP57164.2023.00048},
	timestamp = {Tue, 07 May 2024 20:06:33 +0200},
	biburl = {https://dblp.org/rec/conf/eurosp/BragaKSFB23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {It is universally acknowledged that Wi-Fi communications are important to secure. Thus, the Wi-Fi Alliance published WPA3 in 2018 with a distinctive security feature: it leverages a Password-Authenticated Key Exchange (PAKE) protocol to protect users’ passwords from offline dictionary attacks. Unfortunately, soon after its release, several attacks were reported against its implementations, in response to which the protocol was updated in a best-effort manner.In this paper, we show that the proposed mitigations are not enough, especially for a complex protocol to implement even for savvy developers. Indeed, we present Dragondoom, a collection of side-channel vulnerabilities of varying strength allowing attackers to recover users’ passwords in widely deployed Wi-Fi daemons, such as hostap in its default settings. Our findings target both password conversion methods, namely the default probabilistic hunting-and-pecking and its newly standardized deterministic alternative based on SSWU. We successfully exploit our leakage in practice through microarchitectural mechanisms, and overcome the limited spatial resolution of Flush+Reload. Our attacks outperform previous works in terms of required measurements.Then, driven by the need to end the spiral of patch-and-hack in Dragonfly implementations, we propose Dragonstar, an implementation of Dragonfly leveraging a formally verified implementation of the underlying mathematical operations, thereby removing all the related leakage vector. Our implementation relies on HACL*, a formally verified crypto library guaranteeing secret-independence. We design Dragonstar, so that its integration within hostap requires minimal modifications to the existing project. Our experiments show that the performance of HACL*-based hostap is comparable to OpenSSL-based, implying that Dragonstar is both efficient and proved to be leakage-free.}
}


@inproceedings{DBLP:conf/eurosp/AbadiMZ23,
	author = {Aydin Abadi and
                  Steven J. Murdoch and
                  Thomas Zacharias},
	title = {Recurring Contingent Service Payment},
	booktitle = {8th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2023, Delft, Netherlands, July 3-7, 2023},
	pages = {724--756},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/EuroSP57164.2023.00049},
	doi = {10.1109/EUROSP57164.2023.00049},
	timestamp = {Sun, 12 Nov 2023 02:15:27 +0100},
	biburl = {https://dblp.org/rec/conf/eurosp/AbadiMZ23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Fair exchange protocols let two mutually distrustful parties exchange digital data in a way that neither party can cheat. They have various applications such as the exchange of digital items, or the exchange of digital coins and digital services between a buyer/client and seller/server.In this work, we formally define and propose a generic blockchain-based construction called "Recurring Contingent Service Payment" (RC-S-P). It (i) lets a fair exchange of digital coins and verifiable service reoccur securely between clients and a server while ensuring that the server is paid if and only if it delivers a valid service, and (ii) ensures the parties’ privacy is preserved. RC-S-P supports arbitrary verifiable services, such as "Proofs of Retrievability" (PoR) or verifiable computation and imposes low on-chain over-heads. Our formal treatment and construction, for the first time, consider the setting where either client or server is malicious.We also present a concrete efficient instantiation of RC-S-P when the verifiable service is PoR. We implemented the concrete instantiation and analysed its cost. When it deals with a 4-GB outsourced file, a verifier can check a proof in only 90 milliseconds, and a dispute between a prover and verifier is resolved in 0.1 milliseconds.At CCS 2017, two blockchain-based protocols were proposed to support the fair exchange of digital coins and a certain verifiable service; namely, PoR. In this work, we show that these protocols (i) are susceptible to a free-riding attack which enables a client to receive the service without paying the server, and (ii) are not suitable for cases where parties’ privacy matters, e.g., when the server’s proof status or buyer’s file size must remain private from the public. RC-S-P simultaneously mitigates the above attack and preserves the parties’ privacy.}
}


@inproceedings{DBLP:conf/eurosp/YuLKM23,
	author = {Albert Yu and
                  Donghang Lu and
                  Aniket Kate and
                  Hemanta K. Maji},
	title = {{SIM:} Secure Interval Membership Testing and Applications to Secure
                  Comparison},
	booktitle = {8th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2023, Delft, Netherlands, July 3-7, 2023},
	pages = {757--772},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/EuroSP57164.2023.00050},
	doi = {10.1109/EUROSP57164.2023.00050},
	timestamp = {Mon, 07 Aug 2023 15:56:23 +0200},
	biburl = {https://dblp.org/rec/conf/eurosp/YuLKM23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The offline-online model is a leading paradigm for practical secure multi-party computation (MPC) protocol design that has successfully reduced the overhead for several prevalent privacy-preserving computation functionalities common to diverse application domains. However, the prohibitive overheads associated with secure comparison – one of these vital functionalities – often bottlenecks current and envisioned MPC solutions. Indeed, an efficient secure comparison solution has the potential for significant real-world impact through its broad applications.This work identifies and presents SIM, a secure protocol for the functionality of interval membership testing. This security functionality, in particular, facilitates secure less-than-zero testing and, in turn, secure comparison. A key technical challenge is to support a fast online protocol for testing in large integer rings while keeping the precomputation tractable. Motivated by the map-reduce paradigm, this work introduces the innovation of (1) computing a sequence of intermediate functionalities on a partition of the input into input blocks and (2) securely aggregating the output from these intermediate outputs. This innovation allows controlling the size of the precomputation through a granularity parameter representing these input blocks’ size – enabling application-specific automated compiler optimizations.To demonstrate our protocols’ efficiency, we implement and test their performance in a high-demand application: privacy-preserving machine learning. The benchmark results show that switching to our protocols yields significant performance improvement, which indicates that using our protocol in a plug-and-play fashion can improve the performance of various security applications. Our new paradigm of protocol design may be of independent interest because of its potential for extensions to other functionalities of practical interest.}
}


@inproceedings{DBLP:conf/eurosp/GuntherM23,
	author = {Felix G{\"{u}}nther and
                  Marc Ilunga Tshibumbu Mukendi},
	title = {Careful with MAc-then-SIGn: {A} Computational Analysis of the {EDHOC}
                  Lightweight Authenticated Key Exchange Protocol},
	booktitle = {8th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2023, Delft, Netherlands, July 3-7, 2023},
	pages = {773--796},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/EuroSP57164.2023.00051},
	doi = {10.1109/EUROSP57164.2023.00051},
	timestamp = {Mon, 07 Aug 2023 15:56:23 +0200},
	biburl = {https://dblp.org/rec/conf/eurosp/GuntherM23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {EDHOC is a lightweight authenticated key exchange protocol for IoT communication, currently being standardized by the IETF. Its design is a trimmed-down version of similar protocols like TLS 1.3, building on the SIGn-then-MAc (SIGMA) rationale. In its trimming, however, EDHOC notably deviates from the SIGMA design by sending only short, non-unique credential identifiers, and letting recipients perform trial verification to determine the correct communication partner. Done naively, this can lead to identity misbinding attacks when an attacker can control some of the user keys, invalidating the original SIGMA security analysis and contesting the security of EDHOC.In this work, we formalize a multi-stage key exchange security model capturing the potential attack vectors introduced by non-unique credential identifiers. We show that EDHOC, in its draft version 17, indeed achieves session key security and user authentication even in a strong model where the adversary can register malicious keys with colliding identifiers, given that the employed signature scheme provides so-called exclusive ownership. Through our security result, we confirm cryptographic improvements integrated by the IETF working group in recent draft versions of EDHOC based on recommendations from our and others’ analysis.}
}


@inproceedings{DBLP:conf/eurosp/FangJTYCDCP23,
	author = {Congyu Fang and
                  Hengrui Jia and
                  Anvith Thudi and
                  Mohammad Yaghini and
                  Christopher A. Choquette{-}Choo and
                  Natalie Dullerud and
                  Varun Chandrasekaran and
                  Nicolas Papernot},
	title = {Proof-of-Learning is Currently More Broken Than You Think},
	booktitle = {8th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2023, Delft, Netherlands, July 3-7, 2023},
	pages = {797--816},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/EuroSP57164.2023.00052},
	doi = {10.1109/EUROSP57164.2023.00052},
	timestamp = {Mon, 07 Aug 2023 15:56:23 +0200},
	biburl = {https://dblp.org/rec/conf/eurosp/FangJTYCDCP23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Proof-of-Learning (PoL) proposes that a model owner logs training checkpoints to establish a proof of having expended the computation necessary for training. The authors of PoL forego cryptographic approaches and trade rigorous security guarantees for scalability to deep learning. They empirically argued the benefit of this approach by showing how spoofing—computing a proof for a stolen model—is as expensive as obtaining the proof honestly by training the model. However, recent work has provided a counter-example and thus has invalidated this observation.In this work we demonstrate, first, that while it is true that current PoL verification is not robust to adversaries, recent work has largely underestimated this lack of robustness. This is because existing spoofing strategies are either unreproducible or target weakened instantiations of PoL—meaning they are easily thwarted by changing hyperparameters of the verification. Instead, we introduce the first spoofing strategies that can be reproduced across different configurations of the PoL verification and can be done for a fraction of the cost of previous spoofing strategies. This is possible because we identify key vulnerabilities of PoL and systematically analyze the underlying assumptions needed for robust verification of a proof. On the theoretical side, we show how realizing these assumptions reduces to open problems in learning theory. We conclude that one cannot develop a provably robust PoL verification mechanism without further understanding of optimization in deep learning.}
}


@inproceedings{DBLP:conf/eurosp/PletinckxNFKV23,
	author = {Stijn Pletinckx and
                  Thanh{-}Dat Nguyen and
                  Tobias Fiebig and
                  Christopher Kruegel and
                  Giovanni Vigna},
	title = {Certifiably Vulnerable: Using Certificate Transparency Logs for Target
                  Reconnaissance},
	booktitle = {8th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2023, Delft, Netherlands, July 3-7, 2023},
	pages = {817--831},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/EuroSP57164.2023.00053},
	doi = {10.1109/EUROSP57164.2023.00053},
	timestamp = {Mon, 07 Aug 2023 15:56:23 +0200},
	biburl = {https://dblp.org/rec/conf/eurosp/PletinckxNFKV23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Web PKI ecosystem provides an underlying layer of security to many Internet protocols used today. By relying on Certificate Authorities (CAs), communication can be authenticated and encrypted based on a chain of trust. Unfortunately, this chain of trust has been broken in the past. For instance, in 2011, adversaries managed to issue fraudulent certificates on behalf of the DigiNotar CA, resulting in a loss of trust in DigiNotar. To better detect fraudulent certificates, Google introduced the concept of Certificate Transparency (CT), which is based on append-only logs that allow one to monitor and detect wrongly issued X.509 certificates.In this work, we investigate the potential of these logs as a data source for target reconnaissance. Concretely, we divide our study into two parts: First, we deploy several honeypot web servers over a period of 200 days to study the effect on incoming scanning traffic after pushing a certificate to one or more CT logs. We find that adding a certificate to a CT log leads to incoming network probes, just seconds after publishing the entry. This suggests that CT logs are used as input for web scans. In the IPv6 address space, our web server received 2,700 packets after pushing our certificate to a CT log, compared to 0 packets in our control group.Second, we use large-scale active measurements to find potentially vulnerable domains from CT log data. Using certificate issuance and renewal patterns, we identify websites that are either at the beginning or at the end of their life cycle. Our results show that freshly deployed websites are not more likely to contain a known CVE compared to websites that just renewed their certificate. On the other side of the spectrum, however, we find that websites with an expired certificate, yet still deployed in the wild, tend to contain more outdated software, and hence more known CVEs. As such, CT logs can indeed function as a data source for target reconnaissance.}
}


@inproceedings{DBLP:conf/eurosp/MorenoVT23,
	author = {Jos{\'{e}} Miguel Moreno and
                  Narseo Vallina{-}Rodriguez and
                  Juan Tapiador},
	title = {Chrowned by an Extension: Abusing the Chrome DevTools Protocol through
                  the Debugger {API}},
	booktitle = {8th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2023, Delft, Netherlands, July 3-7, 2023},
	pages = {832--846},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/EuroSP57164.2023.00054},
	doi = {10.1109/EUROSP57164.2023.00054},
	timestamp = {Sat, 30 Sep 2023 09:40:49 +0200},
	biburl = {https://dblp.org/rec/conf/eurosp/MorenoVT23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Chromium open-source project has become a fundamental piece of the Web as we know it today, with multiple vendors offering browsers based on its codebase. One of its most popular features is the possibility of altering or enhancing the browser functionality through third-party programs known as browser extensions. Extensions have access to a wide range of capabilities through the use of APIs exposed by Chromium. The Debugger API—arguably the most powerful of such APIs—allows extensions to use the Chrome DevTools Protocol (CDP), a capability-rich tool for debugging and instrumenting the browser. In this paper, we describe several vulnerabilities present in the Debugger API and in the granting of capabilities to extensions that can be used by an attacker to take control of the browser, escalate privileges, and break context isolation. We demonstrate their impact by introducing six attacks that allow an attacker to steal user information, monitor network traffic, modify site permissions (e.g., access to camera or microphone), bypass security interstitials without user intervention, and change the browser settings. Our attacks work in all major Chromium-based browsers as they are rooted at the core of the Chromium project. We reported our findings to the Chromium Development Team, who already fixed some of them and are currently working on fixing the remaining ones. We conclude by discussing how questionable design decisions, lack of public specifications, and an overpowered Debugger API have contributed to enabling these attacks, and propose mitigations.}
}


@inproceedings{DBLP:conf/eurosp/KirkmanVW23,
	author = {Daniel Kirkman and
                  Kami Vaniea and
                  Daniel W. Woods},
	title = {DarkDialogs: Automated detection of 10 dark patterns on cookie dialogs},
	booktitle = {8th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2023, Delft, Netherlands, July 3-7, 2023},
	pages = {847--867},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/EuroSP57164.2023.00055},
	doi = {10.1109/EUROSP57164.2023.00055},
	timestamp = {Mon, 05 Feb 2024 20:31:17 +0100},
	biburl = {https://dblp.org/rec/conf/eurosp/KirkmanVW23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In theory, consent dialogs allow users to express privacy preferences regarding how a website and its partners process the user’s personal data. In reality, dialogs often employ subtle design techniques known as dark patterns that nudge users towards accepting more data processing than the user would otherwise accept. Dark patterns undermine user autonomy and can violate privacy laws. We build a system, DarkDialogs, that automatically extracts arbitrary consent dialogs from a website and detects the presence of 10 dark patterns. Evaluating DarkDialogs against a hand-labelled dataset reveals it extracts dialogs with an accuracy of 98.7% and correctly classifies 99% of the studied dark patterns. We deployed DarkDialogs on a sample of 10,992 websites, where it successfully collected 2,417 consent dialogs and found 3,744 different dark patterns automatically present on the consent dialogs. We then test whether dark pattern prevalence is associated with each of: the website’s popularity, the presence of a third-party consent management provider, and the number of ID-like cookies.}
}


@inproceedings{DBLP:conf/eurosp/SinghalLPTKSN23,
	author = {Mohit Singhal and
                  Chen Ling and
                  Pujan Paudel and
                  Poojitha Thota and
                  Nihal Kumarswamy and
                  Gianluca Stringhini and
                  Shirin Nilizadeh},
	title = {SoK: Content Moderation in Social Media, from Guidelines to Enforcement,
                  and Research to Practice},
	booktitle = {8th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2023, Delft, Netherlands, July 3-7, 2023},
	pages = {868--895},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/EuroSP57164.2023.00056},
	doi = {10.1109/EUROSP57164.2023.00056},
	timestamp = {Mon, 07 Aug 2023 15:56:23 +0200},
	biburl = {https://dblp.org/rec/conf/eurosp/SinghalLPTKSN23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Social media platforms have been establishing content moderation guidelines and employing various moderation policies to counter hate speech and misinformation. The goal of this paper is to study these community guidelines and moderation practices, as well as the relevant research publications, to identify the research gaps, differences in moderation techniques, and challenges that should be tackled by the social media platforms and the research community. To this end, we study and analyze fourteen most popular social media content moderation guidelines and practices, and consolidate them. We then introduce three taxonomies drawn from this analysis as well as covering over two hundred interdisciplinary research papers about moderation strategies. We identify the differences between the content moderation employed in mainstream and fringe social media platforms. Finally, we have in-depth applied discussions on both research and practical challenges and solutions.}
}


@inproceedings{DBLP:conf/eurosp/MaC23,
	author = {Jack P. K. Ma and
                  Sherman S. M. Chow},
	title = {{SMART} Credentials in the Multi-queue of Slackness (or Secure Management
                  of Anonymous Reputation Traits without Global Halting)},
	booktitle = {8th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2023, Delft, Netherlands, July 3-7, 2023},
	pages = {896--912},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/EuroSP57164.2023.00057},
	doi = {10.1109/EUROSP57164.2023.00057},
	timestamp = {Mon, 05 Feb 2024 20:31:17 +0100},
	biburl = {https://dblp.org/rec/conf/eurosp/MaC23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Anonymous credentials encourage online communication without fear of surveillance, but may invite misbehavior like hate speech. Previous updatable anonymous credentials keep a chronological queue of authenticated sessions and a global pointer to the last chunk of judged sessions. This design allows efficient authentication for proving over only a subset of sessions. However, complications in subjective evaluation often introduce hard-to-judge sessions, which halt all users since sessions that come after the global pointer cannot be redeemed, eventually exceeding the queue size that limits the creation of bad sessions. Such a global-halting loophole may also make judgments overly harsh and hasty.We propose SMART (slack management of anonymous reputation traits), maintaining multiple queues so the server could issue interim judgments many times before finalization. Such slackness removes the binary judgment of old methods and mitigates the global-halting issue. Prior schemes only allow score upgrades (WPES ’14) or require proving against a global session list since the last checkpoint (S&P ’22). Our authentication time is linear in the number of queues or sessions in a designated queue for immediate revocation.}
}


@inproceedings{DBLP:conf/eurosp/IoannouA23,
	author = {Pantelina Ioannou and
                  Elias Athanasopoulos},
	title = {Been Here Already? Detecting Synchronized Browsers in the Wild},
	booktitle = {8th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2023, Delft, Netherlands, July 3-7, 2023},
	pages = {913--927},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/EuroSP57164.2023.00058},
	doi = {10.1109/EUROSP57164.2023.00058},
	timestamp = {Mon, 07 Aug 2023 15:56:23 +0200},
	biburl = {https://dblp.org/rec/conf/eurosp/IoannouA23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Browsers have become the most popular and used platform for accessing the web. Their wide and exclusive usage as a medium for doing several tasks in the Internet comes with serious security and privacy risks for the users. For example, it has been shown that web sites can employ browser fingerprinting and cross-device tracking techniques to de-anonymizing or profiling a user’s browser. On the other hand, browsers become richer in functionality by the years. One very convenient feature, introduced recently and being available to most major web browsers, is synchronizing the browsers on different devices. Browser synchronization allows users to share settings and preferences of their browser running on multiple devices (e.g., on their laptop and smartphone).In this paper, we are the first to deliver a framework that can be used by web site operators to detect if different HTTP requests, issued from different browsers, are actually requests performed by the same user through multiple synchronized browsers running on different devices. For detecting this, we reconstruct different sessions based on their requested resources, timestamps and cookies. In addition, we evaluate our methodology by conducting a user study that collects anonymized HTTP requests from several users, and we prove that the detection of synchronized sessions is possible with a success rate higher than 75%. Our results indicate a serious implication to users’ privacy that has not been studied before.}
}


@inproceedings{DBLP:conf/eurosp/FrymannGM23,
	author = {Nick Frymann and
                  Daniel Gardham and
                  Mark Manulis},
	title = {Asynchronous Remote Key Generation for Post-Quantum Cryptosystems
                  from Lattices},
	booktitle = {8th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2023, Delft, Netherlands, July 3-7, 2023},
	pages = {928--941},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/EuroSP57164.2023.00059},
	doi = {10.1109/EUROSP57164.2023.00059},
	timestamp = {Tue, 07 May 2024 20:06:33 +0200},
	biburl = {https://dblp.org/rec/conf/eurosp/FrymannGM23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Asynchronous Remote Key Generation (ARKG), introduced by Frymann et al. at CCS 2020, allows for the generation of unlinkable public keys by third parties, for which corresponding private keys may be later learned only by the key pair’s legitimate owner. These key pairs can then be used in common public-key cryptosystems, including signatures, PKE, KEMs, and schemes supporting delegation, such as proxy signatures. The only known instance of ARKG generates discrete-log-based keys.In this paper, we introduce new ARKG constructions for lattice-based cryptosystems. The key pairs generated using our ARKG scheme can be applied to lattice-based signatures and KEMs, which have recently been selected for standardisation in the NIST PQ process, or as alternative candidates.In particular, we address challenges associated with the noisiness of lattice hardness assumptions, which requires a new generalised definition of ARKG correctness, whilst preserving the security and privacy properties of the former instantiation. Our ARKG construction uses key encapsulation techniques by Brendel et al. (SAC 2020) coined Split KEMs. As an additional contribution, we also show that Kyber (Bos et al., EuroS&P 2018) can be used to construct a Split KEM. The security of our protocol is based on standard LWE assumptions. We also discuss its use with selected candidates from the NIST process and provide an implementation and benchmarks.}
}


@inproceedings{DBLP:conf/eurosp/ArxTV23,
	author = {Theo von Arx and
                  Muoi Tran and
                  Laurent Vanbever},
	title = {Revelio: {A} Network-Level Privacy Attack in the Lightning Network},
	booktitle = {8th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2023, Delft, Netherlands, July 3-7, 2023},
	pages = {942--957},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/EuroSP57164.2023.00060},
	doi = {10.1109/EUROSP57164.2023.00060},
	timestamp = {Sat, 30 Sep 2023 09:40:48 +0200},
	biburl = {https://dblp.org/rec/conf/eurosp/ArxTV23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Lightning Network (LN) is a widely-adopted off-chain protocol that not only addresses Bitcoin’s scaling problem but also enables anonymous payments. Prior attacks have shown that an adversary controlling several peers at the central position of the network (e.g., by hijacking payment routes) can deanonymize such payments. However, these attacks are highly observable or require many parties to collude.This paper presents Revelio, a stealthier, passive network-level privacy attack against LN that exploits its joint centralization at the application and the network layers. Indeed, network-level adversaries can see most of the LN traffic (e.g., five autonomous systems can see up to 80 % of all observable communication channels) despite the encrypted communication between LN nodes and the widespread usage of Tor. This comprehensive view allows Revelio adversaries not only to estimate the payment amount but also to effectively reduce the anonymity size of its endpoints. We show that the Revelio attack is practical: it perfectly deanonymizes the senders or the receiver in almost one-third of tested payments in today’s LN and underlying network topologies.}
}


@inproceedings{DBLP:conf/eurosp/TalapatraPM23,
	author = {Debadrita Talapatra and
                  Sikhar Patranabis and
                  Debdeep Mukhopadhyay},
	title = {Conjunctive Searchable Symmetric Encryption from Hard Lattices},
	booktitle = {8th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2023, Delft, Netherlands, July 3-7, 2023},
	pages = {958--978},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/EuroSP57164.2023.00061},
	doi = {10.1109/EUROSP57164.2023.00061},
	timestamp = {Mon, 07 Aug 2023 15:56:23 +0200},
	biburl = {https://dblp.org/rec/conf/eurosp/TalapatraPM23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Searchable Symmetric Encryption (SSE) supports efficient keyword searches over encrypted outsourced document collections while minimizing information leakage. All practically efficient SSE schemes supporting conjunctive queries rely crucially on quantum-broken cryptographic assumptions (such as discrete-log hard groups) to achieve compact storage and fast query processing. On the other hand, quantum-safe SSE schemes based on purely symmetric-key cryptoprimitives either do not support conjunctive searches, or are practically inefficient. In particular, there exists no quantum-safe yet practically efficient conjunctive SSE scheme from lattice-based hardness assumptions.We solve this open question by proposing Oblivious Post-Quantum Secure Cross Tags (OQXT) – the first lattice-based practically efficient and highly scalable conjunctive SSE scheme. The technical centerpiece of OQXT is a novel oblivious cross-tag generation protocol with provable security guarantees derived from lattice-based hardness assumptions. We prove the post-quantum simulation security of OQXT with respect to a rigorously defined and thoroughly analyzed leakage profile. We then present a prototype implementation of OQXT and experimentally validate its practical efficiency and scalability over extremely large real-world databases. Our experiments show that OQXT has competitive end-to-end search latency when compared with the best (quantum-broken) conjunctive SSE schemes.}
}


@inproceedings{DBLP:conf/eurosp/CastellanosMCSZ23,
	author = {John Henry Castellanos and
                  Mohamed Maghenem and
                  Alvaro A. C{\'{a}}rdenas and
                  Ricardo G. Sanfelice and
                  Jianying Zhou},
	title = {Provable Adversarial Safety in Cyber-Physical Systems},
	booktitle = {8th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2023, Delft, Netherlands, July 3-7, 2023},
	pages = {979--1012},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/EuroSP57164.2023.00062},
	doi = {10.1109/EUROSP57164.2023.00062},
	timestamp = {Sat, 30 Sep 2023 09:40:48 +0200},
	biburl = {https://dblp.org/rec/conf/eurosp/CastellanosMCSZ23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Most proposals for securing control systems are heuristic in nature, and while they increase the protection of their target, the security guarantees they provide are unclear. This paper proposes a new way of modeling the security guarantees of a Cyber-Physical System (CPS) against arbitrary false command attacks. As our main case study, we use the most popular testbed for control systems security. We first propose a detailed formal model of this testbed and then show how the original configuration is vulnerable to a single-actuator attack. We then propose modifications to the control system and prove that our modified system is secure against arbitrary, single-actuator attacks.}
}


@inproceedings{DBLP:conf/eurosp/ChakrabortiR23,
	author = {Anrin Chakraborti and
                  Michael K. Reiter},
	title = {Privately Evaluating Region Overlaps with Applications to Collaborative
                  Sensor Output Validation},
	booktitle = {8th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2023, Delft, Netherlands, July 3-7, 2023},
	pages = {1013--1029},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/EuroSP57164.2023.00063},
	doi = {10.1109/EUROSP57164.2023.00063},
	timestamp = {Mon, 07 Aug 2023 15:56:23 +0200},
	biburl = {https://dblp.org/rec/conf/eurosp/ChakrabortiR23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Advances in computer vision have made it possible to accurately map objects as regions in 3-dimensional space using LIDAR point clouds. These systems are key building blocks of several emerging technologies including autonomous vehicles. Comparing and validating the output of sensors at different vantage points observing the same scenery can enable these systems to detect faults, identify common obstacles, and improve decision making. However sharing sensor outputs among mutually untrusting parties can leak unwanted information, e.g., model parameters or relative location of the sensors. This work initiates the study of cryptographic protocols that enable two parties observing regions (or objects) in an arbitrary-dimension Euclidean space to privately detect if the regions overlap and approximate the volume of the overlapping region. The protocols rely only on cheap symmetric-key primitives and feature reasonable communication costs and compute times. As applications, the protocols have been benchmarked on data generated from the CARLA autonomous driving simulator and the ScanNet 3D image dataset; they outperform a 2PC garbled-circuit baseline in communication volume and compute time. For instance it takes roughly 0.5 seconds to approximate the volume of the overlapping region of two 3D boxes with low error probability.}
}


@inproceedings{DBLP:conf/eurosp/LeWYFHST23,
	author = {Tu Le and
                  Alan Wang and
                  Yaxing Yao and
                  Yuanyuan Feng and
                  Arsalan Heydarian and
                  Norman M. Sadeh and
                  Yuan Tian},
	title = {Exploring Smart Commercial Building Occupants' Perceptions and Notification
                  Preferences of Internet of Things Data Collection in the United States},
	booktitle = {8th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2023, Delft, Netherlands, July 3-7, 2023},
	pages = {1030--1046},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/EuroSP57164.2023.00064},
	doi = {10.1109/EUROSP57164.2023.00064},
	timestamp = {Tue, 07 May 2024 20:06:33 +0200},
	biburl = {https://dblp.org/rec/conf/eurosp/LeWYFHST23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Data collection through the Internet of Things (IoT) devices, or smart devices, in commercial buildings enables possibilities for increased convenience and energy efficiency. However, such benefits face a large perceptual challenge when being implemented in practice, due to the different ways occupants working in the buildings understand and trust in the data collection. The semi-public, pervasive, and multi-modal nature of data collection in smart buildings points to the need to study occupants’ understanding of data collection and notification preferences. We conduct an online study with 492 participants in the US who report working in smart commercial buildings regarding: 1) awareness and perception of data collection in smart commercial buildings, 2) privacy notification preferences, and 3) potential factors for privacy notification preferences. We find that around half of the participants are not fully aware of the data collection and use practices of IoT even though they notice the presence of IoT devices and sensors. We also discover many misunderstandings around different data practices. The majority of participants want to be notified of data practices in smart buildings, and they prefer push notifications to passive ones such as websites or physical signs. Surprisingly, mobile app notification, despite being a popular channel for smart homes, is the least preferred method for smart commercial buildings.}
}


@inproceedings{DBLP:conf/eurosp/IbrahimCB23,
	author = {Muhammad Ibrahim and
                  Andrea Continella and
                  Antonio Bianchi},
	title = {AoT - Attack on Things: {A} security analysis of IoT firmware updates},
	booktitle = {8th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2023, Delft, Netherlands, July 3-7, 2023},
	pages = {1047--1064},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/EuroSP57164.2023.00065},
	doi = {10.1109/EUROSP57164.2023.00065},
	timestamp = {Sun, 12 Nov 2023 02:15:27 +0100},
	biburl = {https://dblp.org/rec/conf/eurosp/IbrahimCB23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {IoT devices implement firmware update mechanisms to fix security issues and deploy new features. These mechanisms are often triggered and mediated by mobile companion apps running on the users’ smartphones. While it is crucial to update devices, these mechanisms may cause critical security flaws if they are not implemented correctly. Given their relevance, in this paper, we perform a systematic security analysis of the firmware update mechanisms adopted by IoT devices via their companion apps. First, we define a threat model for IoT firmware updates, and we categorize the different potential security issues affecting them. Then, we analyze 23 popular IoT devices (and corresponding companion apps) to identify vulnerable devices and the SDKs that such devices use to implement the update functionality. Our analysis reveals that 6 popular SDKs present dangerous security flaws. Additionally, we fingerprint each vulnerable SDK and we leverage our fingerprints to perform a large-scale analysis of companion apps from the Google Play Store. Our results show that 61 popular devices and 1,356 apps rely on vulnerable SDKs, thus, they potentially adopt an insecure firmware update mechanism.}
}


@inproceedings{DBLP:conf/eurosp/BaderSLSVHFPH23,
	author = {Lennart Bader and
                  Martin Serror and
                  Olav Lamberts and
                  {\"{O}}mer Sen and
                  Dennis van der Velde and
                  Immanuel Hacker and
                  Julian Filter and
                  Elmar Padilla and
                  Martin Henze},
	title = {Comprehensively Analyzing the Impact of Cyberattacks on Power Grids},
	booktitle = {8th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2023, Delft, Netherlands, July 3-7, 2023},
	pages = {1065--1081},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/EuroSP57164.2023.00066},
	doi = {10.1109/EUROSP57164.2023.00066},
	timestamp = {Sat, 30 Sep 2023 09:40:48 +0200},
	biburl = {https://dblp.org/rec/conf/eurosp/BaderSLSVHFPH23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The increasing digitalization of power grids and especially the shift towards IP-based communication drastically increase the susceptibility to cyberattacks, potentially leading to blackouts and physical damage. Understanding the involved risks, the interplay of communication and physical assets, and the effects of cyberattacks are paramount for the uninterrupted operation of this critical infrastructure. However, as the impact of cyberattacks cannot be researched in real-world power grids, current efforts tend to focus on analyzing isolated aspects at small scales, often covering only either physical or communication assets. To fill this gap, we present Wattson, a comprehensive research environment that facilitates reproducing, implementing, and analyzing cyberattacks against power grids and, in particular, their impact on both communication and physical processes. We validate Wattson’s accuracy against a physical testbed and show its scalability to realistic power grid sizes. We then perform authentic cyberattacks, such as Industroyer, within the environment and study their impact on the power grid’s energy and communication side. Besides known vulnerabilities, our results reveal the ripple effects of susceptible communication on complex cyber-physical processes and thus lay the foundation for effective countermeasures.}
}


@inproceedings{DBLP:conf/eurosp/XuHDLLZ23,
	author = {Yuan Xu and
                  Xingshuo Han and
                  Gelei Deng and
                  Jiwei Li and
                  Yang Liu and
                  Tianwei Zhang},
	title = {SoK: Rethinking Sensor Spoofing Attacks against Robotic Vehicles from
                  a Systematic View},
	booktitle = {8th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2023, Delft, Netherlands, July 3-7, 2023},
	pages = {1082--1100},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/EuroSP57164.2023.00067},
	doi = {10.1109/EUROSP57164.2023.00067},
	timestamp = {Mon, 07 Aug 2023 15:56:23 +0200},
	biburl = {https://dblp.org/rec/conf/eurosp/XuHDLLZ23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Robotic Vehicles (RVs) have gained great popularity over the past few years. Meanwhile, they are also demonstrated to be vulnerable to sensor spoofing attacks. Although a wealth of research works have presented various attacks, some key questions remain unanswered: are these existing works complete enough to cover all the sensor spoofing threats? If not, how many attacks are not explored, and how difficult is it to realize them?This paper answers the above questions by comprehensively systematizing the knowledge of sensor spoofing attacks against RVs. Our contributions are threefold. (1) We identify seven common attack paths in an RV system pipeline. We categorize and assess existing spoofing attacks from the perspectives of spoofer property, operation, victim characteristic and attack goal. Based on this systematization, we identify 4 interesting insights about spoofing attack designs. (2) We propose a novel action flow model to systematically describe robotic function executions and unexplored sensor spoofing threats. With this model, we successfully discover 103 spoofing attack vectors, 26 of which have been verified by prior works, while 77 attacks are never considered. (3) We design two novel attack methodologies to verify the feasibility of newly discovered spoofing attack vectors.}
}


@inproceedings{DBLP:conf/eurosp/CasselWJ23,
	author = {Darion Cassel and
                  Wai Tuck Wong and
                  Limin Jia},
	title = {NodeMedic: End-to-End Analysis of Node.js Vulnerabilities with Provenance
                  Graphs},
	booktitle = {8th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2023, Delft, Netherlands, July 3-7, 2023},
	pages = {1101--1127},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/EuroSP57164.2023.00068},
	doi = {10.1109/EUROSP57164.2023.00068},
	timestamp = {Sat, 30 Sep 2023 09:40:48 +0200},
	biburl = {https://dblp.org/rec/conf/eurosp/CasselWJ23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Packages in the Node.js ecosystem often suffer from serious vulnerabilities such as arbitrary command injection and code execution. Existing taint analysis tools fall short in providing an end-to-end infrastructure for automatically detecting and triaging these vulnerabilities.We develop NodeMedic, an end-to-end analysis infrastructure that automates test driver creation, performs precise yet scalable dynamic taint propagation via algorithmically tuned propagation policies, and exposes taint provenance information as a provenance graph. Using provenance graphs we develop two post-detection analyses: automated constraint-based exploit synthesis to confirm vulnerabilities; Attack-defense-tree–based rating of flow exploitability.We demonstrate the effectiveness of NodeMedic through a large-scale evaluation of 10,000 Node.js packages. Our evaluation uncovers 155 vulnerabilities, of which 152 are previously undisclosed, and 108 were confirmed with automatically synthesized exploits. We have open-sourced NodeMedic and a suite of 589 taint precision unit tests.}
}


@inproceedings{DBLP:conf/eurosp/JacobWBS23,
	author = {Hans Niklas Jacob and
                  Christian Werling and
                  Robert Buhren and
                  Jean{-}Pierre Seifert},
	title = {faulTPM: Exposing {AMD} fTPMs' Deepest Secrets},
	booktitle = {8th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2023, Delft, Netherlands, July 3-7, 2023},
	pages = {1128--1142},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/EuroSP57164.2023.00069},
	doi = {10.1109/EUROSP57164.2023.00069},
	timestamp = {Mon, 07 Aug 2023 15:56:23 +0200},
	biburl = {https://dblp.org/rec/conf/eurosp/JacobWBS23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Trusted Platform Modules (TPMs) constitute an integral building block of modern security features. Moreover, as Windows 11 made a TPM 2.0 mandatory, they are subject to an ever-increasing academic challenge. While discrete TPMs (dTPMs) – as found in higher-end systems – have been susceptible to attacks on their exposed communication interface, more common firmware TPMs (fTPMs) are immune to this attack vector as they do not communicate with the CPU via an exposed bus.In this paper, we analyze a new class of attacks against fTPMs: Attacking their Trusted Execution Environment (TEE) can lead to a full TPM state compromise. We experimentally verify this attack by compromising the AMD Secure Processor (AMD-SP), which constitutes the TEE for AMD’s fTPMs. In contrast to previous dTPM sniffing attacks, this vulnerability exposes the complete internal TPM state of the fTPM. It allows us to extract any cryptographic material stored or sealed by the fTPM regardless of authentication mechanisms such as Platform Configuration Register (PCR) validation or passphrases with anti-hammering protection. First, we demonstrate the impact of our findings by – to the best of our knowledge – enabling the first attack against Full Disk Encryption (FDE) solutions backed by an fTPM. Furthermore, we lay out how any application relying solely on the security properties of the TPM – like Bitlocker’s TPM-only protector – can be defeated by an attacker with 2-3 hours of physical access to the target device. Lastly, we analyze the impact of our attack on FDE solutions protected by a TPM and PIN strategy. While a naive implementation also leaves the disk completely unprotected, we find that BitLocker’s FDE implementation withholds some protection depending on the complexity of the used PIN. Our results show that when an fTPM’s internal state is compromised, a TPM and PIN strategy for FDE is less secure than TPM-less protection with a reasonable passphrase.}
}


@inproceedings{DBLP:conf/eurosp/StrydonckNJDVOPD23,
	author = {Thomas Van Strydonck and
                  Job Noorman and
                  Jennifer Jackson and
                  Leonardo Alves Dias and
                  Robin Vanderstraeten and
                  David F. Oswald and
                  Frank Piessens and
                  Dominique Devriese},
	title = {CHERI-TrEE: Flexible enclaves on capability machines},
	booktitle = {8th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2023, Delft, Netherlands, July 3-7, 2023},
	pages = {1143--1159},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/EuroSP57164.2023.00070},
	doi = {10.1109/EUROSP57164.2023.00070},
	timestamp = {Sat, 30 Sep 2023 09:40:49 +0200},
	biburl = {https://dblp.org/rec/conf/eurosp/StrydonckNJDVOPD23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper studies the integration of two successful hardware-supported security mechanisms: capabilities and enclaved execution. Capabilities are a powerful and flexible security mechanism for implementing fine-grained memory access control and compartmentalizing untrusted or buggy software components. Capabilities have a long history but have gained significant momentum recently, as evidenced by ARM’s experimental Morello processor that supports the Capability Hardware Enhanced RISC Instructions (CHERI). Enclaved execution is a popular mechanism for dynamically creating Trusted Execution Environments (TEEs), called enclaves. Enclaves are isolated execution contexts that protect the integrity and confidentiality of software in the enclave (even against compromised system software) and that support attestation.Integrating capabilities and enclaved execution in a single processor is challenging because they overlap partially in their security objectives, and a clean integration should unify the way in which these overlapping objectives are achieved. In addition, it is not obvious how attestation should interact with capabilities. In this paper, we propose CHERI-TrEE: a novel design for a processor that cleanly integrates support for both capabilities and enclaved execution. CHERI-TrEE targets low-end embedded systems without virtual memory. We show that CHERI-TrEE is greater than the sum of its parts by showing how it naturally supports useful features that have traditionally been hard to support in enclaved execution, like dynamically growing and shrinking enclaves, non-contiguous and nested enclaves, sharing of memory between enclaves etc. We implement our proposal both in hardware on a RISC-V processor, as well as in a small software hypervisor on top of ARM Morello, and evaluate impact on performance and hardware resources.}
}


@inproceedings{DBLP:conf/eurosp/AhsanRA23,
	author = {Muhammad Ahsan and
                  Muhammad Haris Rais and
                  Irfan Ahmed},
	title = {{SOK:} Side Channel Monitoring for Additive Manufacturing - Bridging
                  Cybersecurity and Quality Assurance Communities},
	booktitle = {8th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2023, Delft, Netherlands, July 3-7, 2023},
	pages = {1160--1178},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/EuroSP57164.2023.00071},
	doi = {10.1109/EUROSP57164.2023.00071},
	timestamp = {Sat, 30 Sep 2023 09:40:48 +0200},
	biburl = {https://dblp.org/rec/conf/eurosp/AhsanRA23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Additive Manufacturing (AM) is critical for the fourth industrial revolution (i.e., Industry 4.0). It involves printing a 3D object layer-by-layer from scratch. Fused filament fabrication (FFF), one of the most widely used AM technology, has been adopted by commercial and domestic consumers. With the recent addition of metal filaments, FFF caters to a broad spectrum of manufacturing industry requirements. Cybersecurity and Quality Assurance (QA) of the FFF process is an active research area. Like any other cyber-physical system, FFF exhibits many side channels (SCs), including acoustic and thermal emissions, vibrations, etc. Researchers in the QA domain use SCs to predict defects in the printed parts. Cybersecurity researchers, on the other hand, utilize SCs to identify malicious anomalies in the process. While the aims are different, there are definite overlaps in both communities’ acquisition and analysis methodologies. As the two communities bring distinct skill sets and expertise, we find an opportunity to bring them closer through a systematic study of available work and identifying the commonalities and distinctions to motivate the consumption of cross-domain knowledge. Our approach to systematizing the knowledge is based on identifying the available SC, the acquisition and analysis methodologies, performance statistics, associated challenges, and future research directions. This knowledge consolidation and systematization exercise will not only help the new researchers aiming to explore SCs in the FFF process but also highlight collaboration opportunities between QA and cybersecurity communities.}
}


@inproceedings{DBLP:conf/eurosp/XuKEP23,
	author = {Jing Xu and
                  Stefanos Koffas and
                  Oguzhan Ersoy and
                  Stjepan Picek},
	title = {Watermarking Graph Neural Networks based on Backdoor Attacks},
	booktitle = {8th {IEEE} European Symposium on Security and Privacy, EuroS{\&}P
                  2023, Delft, Netherlands, July 3-7, 2023},
	pages = {1179--1197},
	publisher = {{IEEE}},
	year = {2023},
	url = {https://doi.org/10.1109/EuroSP57164.2023.00072},
	doi = {10.1109/EUROSP57164.2023.00072},
	timestamp = {Sat, 30 Sep 2023 09:40:49 +0200},
	biburl = {https://dblp.org/rec/conf/eurosp/XuKEP23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graph Neural Networks (GNNs) have achieved promising performance in various real-world applications. Building a powerful GNN model is not a trivial task, as it requires a large amount of training data, powerful computing resources, and human expertise. Moreover, with the development of adversarial attacks, e.g., model stealing attacks, GNNs raise challenges to model authentication. To avoid copyright infringement on GNNs, verifying the ownership of the GNN models is necessary.This paper presents a watermarking framework for GNNs for both graph and node classification tasks. We 1) design two strategies to generate watermarked data for the graph classification task and one for the node classification task, 2) embed the watermark into the host model through training to obtain the watermarked GNN model, and 3) verify the ownership of the suspicious model in a black-box setting. The experiments show that our framework can verify the ownership of GNN models with a very high probability (up to 99%) for both tasks. We also explore our watermarking mechanism against an adaptive attacker with access to partial knowledge of the watermarked data. Finally, we experimentally show that our watermarking approach is robust against a state-of-the-art model extraction technique and four state-of-the-art defenses against backdoor attacks.}
}
