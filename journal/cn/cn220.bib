@article{DBLP:journals/cn/WanD23,
	author = {Zheng Wan and
                  Xiaogang Dong},
	title = {Computation power maximization for mobile edge computing enabled dense
                  network},
	journal = {Comput. Networks},
	volume = {220},
	pages = {109458},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2022.109458},
	doi = {10.1016/J.COMNET.2022.109458},
	timestamp = {Sun, 15 Jan 2023 18:31:44 +0100},
	biburl = {https://dblp.org/rec/journals/cn/WanD23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {High-density connection is among the natures of next-generation wireless communication systems. Meanwhile, various computation-intensive smart applications are becoming growing popularity with the technology boom. Thus, strong computation power will become a crucial requirement for wireless communication systems. Mobile edge computing provides a promising solution to this requirement by pushing a cloud-like computation capacity to the network edge. This study aims to maximize the computation power of a mobile edge computing enabled dense network. To this end, a computation bits maximization problem is formulated by jointly optimizing offloading decision and resource allocation. The problem is a mixed-variable nonlinear programming problem. First, by analyzing the feasibility of computation modes and constructing a user distribution strategy, the original problem is decoupled into two sub-problems, i.e., the assignment of the offloading users and resource allocation. The offloading users’ assignment is modeled as a restricted multiple knapsack problem, and a profit density is defined to maximize the overall profits of multiple knapsacks. Then, an improved differential evolution algorithm is developed to address the knapsack problem, in which mutation and repair operators are designed according to the profit density. Based on the optimal solution to the knapsack problem, the resource allocation sub-problem is solved by the corresponding calculation. Finally, extensive experiments are conducted to evaluate the performance of our scheme. Results show that: (1) our scheme provides superior computation power compared to that of benchmark schemes; (2) the performance gain of our scheme over benchmark schemes expands with growing connection density. Therefore, our scheme is an effective computation power optimization scheme.}
}


@article{DBLP:journals/cn/AvanzatoBR23,
	author = {Roberta Avanzato and
                  Francesco Beritelli and
                  Corrado Rametta},
	title = {An DL-based approach for Packet Error Compensation using radio mobile
                  network quality parameters in a rainfall scenario},
	journal = {Comput. Networks},
	volume = {220},
	pages = {109463},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2022.109463},
	doi = {10.1016/J.COMNET.2022.109463},
	timestamp = {Sun, 15 Jan 2023 18:31:44 +0100},
	biburl = {https://dblp.org/rec/journals/cn/AvanzatoBR23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This study proposes a new approach to guarantee the Quality of Service of mobile radio links via Packet Error Rate (PER) compensation at varying levels of rainfall. Compared to traditional radio channel degradation estimation methods, the proposed study uses a different set of parameters mainly related to the cell selection and handover mechanisms, more appropriate for rainfall scenarios. By means of a new model based on a Convolutional Neural Network (CNN), the proposed technique estimates the PER on two different radio links in such a way as to dynamically adapt the weights of a VPN (Virtual Private Network) Bonding algorithm based on a dual Subscriber Identity Module (SIM) system belonging to two different telephone operators. This guarantees a halved adaptation frequency when compared to traditional cellular bonding methods and avoids saturating the channel band during the estimation of the weights. The experimental results carried out in video surveillance applications for smart road scenarios show that it is possible to dynamically improve the radio link with an enhancement in the quality perceived by the user of about 200%.}
}


@article{DBLP:journals/cn/AneddaFGPG23,
	author = {Matteo Anedda and
                  Mauro Fadda and
                  Roberto Girau and
                  Giovanni Pau and
                  Daniele D. Giusto},
	title = {A social smart city for public and private mobility: {A} real case
                  study},
	journal = {Comput. Networks},
	volume = {220},
	pages = {109464},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2022.109464},
	doi = {10.1016/J.COMNET.2022.109464},
	timestamp = {Sun, 12 Nov 2023 02:17:56 +0100},
	biburl = {https://dblp.org/rec/journals/cn/AneddaFGPG23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Nowadays, smart city paradigm plays a primary role in the fulfillment of sustainable solutions in the field of urban mobility, both public and private. At the same time, the Internet of Things (IoT) is allowing the development of increasingly advanced solutions for real-time management of collected information related to the management and coexistence of vehicles (i.e., buses, cars, trains, bicycles, etc.) immersed in urban and sub-urban traffic. The Social IoT (SIoT) paradigm adds a relational connotation between objects typical of human relationships. Objects operate as equals and request/provide information among them in the perspective of providing IoT services to users while maintaining their individuality. Social object relationship enables the design of solutions aiming to improve the exchange of information among network nodes in terms of security from malicious attacks external to the so-called social network of objects. In this context, a new SIoT smart city solution is presented in this article: private and public vehicles together with pedestrians are involved in a real-time collection of data to improve the viability of the city in order to suggest new directions and information to citizens to better organize how to live the city. The developed architecture presented in this article is equipped with an artificial intelligence that process collected traffic data and, thanks to machine learning techniques, evaluate the directions and flows undertaken by vehicles and pedestrians on a daily basis. The authors are also presenting an application that allow both citizens to live the city in a better way and municipal authorities to promptly manage traffic flows. The proposed system was installed in a specific area of Cagliari (Italy) and the traffic flows have been compared with daily traffic data monitored before the installation, observing an average gain of up to 35 percent in daily traffic reduction.}
}


@article{DBLP:journals/cn/BaidasAA23,
	author = {Mohammed W. Baidas and
                  Ahmed M. AbdelGhaffar and
                  Emad Alsusa},
	title = {Network-coded uplink clustered {NOMA} relay networks: Models and performance
                  comparisons},
	journal = {Comput. Networks},
	volume = {220},
	pages = {109465},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2022.109465},
	doi = {10.1016/J.COMNET.2022.109465},
	timestamp = {Sun, 15 Jan 2023 18:31:44 +0100},
	biburl = {https://dblp.org/rec/journals/cn/BaidasAA23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, network sum-rate maximization (NSR-MAX) for network-coded (NC) uplink clustered non-orthogonal multiple-access (NOMA) relay networks is considered. In particular, the goal is to maximize network sum-rate via optimal power allocation, where the user clusters communicate with the base-station over an amplify-and-forward relay, subject to quality-of-service (QoS) constraints. Two NC-NOMA transmission models – namely NC-NOMA-I and NC-NOMA-II – are proposed, where in the first model, network-coding is applied at the relay only, while the second model applies network-coding for user clusters’ transmissions and at the relay to further minimize the transmission delay. The formulated NSR-MAX problem happens to be non-convex, and hence, is computationally-intensive. Thus, a low-complexity iterative two-layer algorithm (ITLA) is devised, which decouples the formulated problem and efficiently solves its over two-layers. Specifically, the inner-layer solves the NSR-MAX problem to obtain the optimal relay transmit power, while the outer-layer determines the optimal users’ transmit powers. Numerical results are presented, which illustrate that the proposed ITLA yields near-optimal solutions for all transmission models, in comparison to the formulated NSR-MAX problem (solved via global optimization package) as well as outperforming its OMA-based counterparts. Not only that, but the NC-NOMA-II is shown to be superior to the other NOMA and OMA schemes, while demonstrating resilience to timing offsets as well as successive interference cancellation (SIC) and channel state information (CSI) errors.}
}


@article{DBLP:journals/cn/LuxemburkC23,
	author = {Jan Luxemburk and
                  Tom{\'{a}}s Cejka},
	title = {Fine-grained {TLS} services classification with reject option},
	journal = {Comput. Networks},
	volume = {220},
	pages = {109467},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2022.109467},
	doi = {10.1016/J.COMNET.2022.109467},
	timestamp = {Tue, 28 Feb 2023 10:48:05 +0100},
	biburl = {https://dblp.org/rec/journals/cn/LuxemburkC23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The recent success and proliferation of machine learning and deep learning have provided powerful tools, which are also utilized for encrypted traffic analysis, classification, and threat detection in computer networks. These methods, neural networks in particular, are often complex and require a huge corpus of training data. Therefore, this paper focuses on collecting a large up-to-date dataset with almost 200 fine-grained service labels and 140 million network flows extended with packet-level metadata. The number of flows is three orders of magnitude higher than in other existing public labeled datasets of encrypted traffic. The number of service labels, which is important to make the problem hard and realistic, is four times higher than in the public dataset with the most class labels. The published dataset is intended as a benchmark for identifying services in encrypted traffic. Service identification can be further extended with the task of “rejecting” unknown services, i.e., the traffic not seen during the training phase. Neural networks offer superior performance for tackling this more challenging problem. To showcase the dataset’s usefulness, we implemented a neural network with a multi-modal architecture, which is the state-of-the-art approach, and achieved 97.04% classification accuracy and detected 91.94% of unknown services with 5% false positive rate.}
}


@article{DBLP:journals/cn/PDBD23,
	author = {Sharvari N. P and
                  Dibakar Das and
                  Jyotsna Bapat and
                  Debabrata Das},
	title = {Connectivity and collision constrained opportunistic routing for emergency
                  communication using {UAV}},
	journal = {Comput. Networks},
	volume = {220},
	pages = {109468},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2022.109468},
	doi = {10.1016/J.COMNET.2022.109468},
	timestamp = {Sun, 15 Jan 2023 18:31:44 +0100},
	biburl = {https://dblp.org/rec/journals/cn/PDBD23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Emergency communication is essential for search and rescue operations in the aftermath of natural disasters. Unmanned Aerial Vehicle (UAV)-assisted networking is emerging as a promising method for establishing emergency communication. UAVs can intelligently self-adjust their positions, communicate while moving at high speeds, and effectively capture and relay disaster site information to a Terrestrial Base Station (TBS). However, data forwarding from the UAVs to TBS is challenging because of the former’s dynamic network topology, high mobility and resource constraints. Designing efficient routing protocols is crucial in the context of these challenges. To the best of our knowledge, none of the previous works have integratively addressed the post-disaster routing concerns like coverage requirements, inter-UAV collision avoidance and reliable multi-hop routing in the absence of trajectory planning. This paper proposes a novel Multi-hop Opportunistic 3D Routing (MO3DR) algorithm for post-disaster data dissemination. The MO3DR algorithm employs coverage and inter-UAV collision constraints for selecting the next forwarding node to maximize the expected progress of data towards the TBS. Simulations validate the numerical results from closed-form analytical models. Results reveal that operating UAVs within the threshold inter-UAV distance meets the coverage and collision constraints while maximizing the expected progress of data towards the TBS.}
}


@article{DBLP:journals/cn/DarbandehS23,
	author = {Foroozan Ghosairi Darbandeh and
                  Masoumeh Safkhani},
	title = {{SAPWSN:} {A} Secure Authentication Protocol for Wireless Sensor Networks},
	journal = {Comput. Networks},
	volume = {220},
	pages = {109469},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2022.109469},
	doi = {10.1016/J.COMNET.2022.109469},
	timestamp = {Sun, 15 Jan 2023 18:31:44 +0100},
	biburl = {https://dblp.org/rec/journals/cn/DarbandehS23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the advancement of RFID systems, there is a need for secure RFID authentication that can provide security against a variety of attacks, so designing a perfectly safe protocol has become a security challenge. The most remarkable security challenges may be information leakage, traceability, and tag impersonation. Several researchers have attempted to address this security demand by proposing ultra-lightweight solutions that use only very low-cost operations such as bit-wise operations. However, approximately all of the presented previous ultra-lightweight authentication schemes are vulnerable to a variety of attacks. For this purpose, Chiou and Chang recently proposed an EPC Class 1 Gen-2-based RFID authentication protocol and claimed it is resistant against replay attacks and also other known active and passive attacks. They also stated that their proposed protocol does not require features such as a secure channel, time parameters, or virtual IDs. In this paper, we will investigate the security of the Chiou and Chang authentication scheme and demonstrate that it is completely insecure. Specifically, we will present the security faults of this scheme. In addition, we will present an enhanced protocol called SAPWSN. The proposed protocol presents precise authentication and highly secure transfers. We demonstrate the proposed protocol’s security in the formal and informal methods. In the formal method, we use the Compromise version of Scyther tool.}
}


@article{DBLP:journals/cn/JiHXSS23,
	author = {Xiaolan Ji and
                  Biao Han and
                  Cao Xu and
                  Congxi Song and
                  Jinshu Su},
	title = {Adaptive QoS-aware multipath congestion control for live streaming},
	journal = {Comput. Networks},
	volume = {220},
	pages = {109470},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2022.109470},
	doi = {10.1016/J.COMNET.2022.109470},
	timestamp = {Sat, 30 Sep 2023 10:07:03 +0200},
	biburl = {https://dblp.org/rec/journals/cn/JiHXSS23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Nowadays, the popularization of live streaming bring challenges in providing customized Quality of Service (QoS) and satisfying diverse Quality of Experience (QoE) requirements. Multipath TCP (MPTCP), designed for bandwidth and reliability in aggregating transmission, has the potential to improve live streaming performance with multiple simultaneously transmitting paths. However, the existing multipath congestion control algorithms (CCAs) of MPTCP fail to adapt to diverse network environments and different QoS requirements. We study the problem with extensive experiments to observe the limitations of current multipath CCAs. To tackle these problems and support stable and customized live streaming, we propose ACCeSS, an adaptive QoS-aware multipath congestion control framework. ACCeSS is able to promptly adapt to network changes and QoS requirements with a novel control policy optimization phase. In order to adjust and stimulate improvement on the preferred performance metric, ACCeSS exploits Random Forest Regressing (RFR) method to perform QoS-specific utility function optimization. Besides, ACCeSS is implemented and deployed in a multipath live streaming system. We compare it with other multipath CCAs in the Linux kernel and evaluate their performance in both emulated and real-world networks. It is revealed that ACCeSS outperforms classic multipath CCAs and the state-of-the-art learning-based multipath CCA, with better environment adaptive capability of QoS and higher QoE for live streaming.}
}


@article{DBLP:journals/cn/PerdicesVGP23,
	author = {Daniel Perdices and
                  Jorge E. L{\'{o}}pez de Vergara and
                  Iv{\'{a}}n Gonz{\'{a}}lez and
                  Luis de Pedro},
	title = {Web browsing privacy in the deep learning era: Beyond VPNs and encryption},
	journal = {Comput. Networks},
	volume = {220},
	pages = {109471},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2022.109471},
	doi = {10.1016/J.COMNET.2022.109471},
	timestamp = {Sun, 19 Jan 2025 14:22:29 +0100},
	biburl = {https://dblp.org/rec/journals/cn/PerdicesVGP23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Web browsing privacy is a matter of paramount importance for the Internet users. While they try to protect themselves from being monitored by getting advantage of encryption or VPNs, users’ privacy is still unaccomplished, even taking into account the tangled web, with several domains visited at the same time in a single web page, or IP addresses of a cloud provider shared by several sites. In this work, we provide a novel approach to identify user web browsing that only takes into account the IP addresses that the user has connected to and without performing any DNS reverse resolutions. We use this sequence of addresses as an input of different state-of-the-art deep learning models, such as multi-layer perceptron and transformers, which are able to accurately identify which was the website actually visited among Alexa’s World Top 500 most visited domains. Moreover, we have also studied other factors, such as the dependence on the DNS server used to resolve the visited IP addresses, the accuracy for the top domains (e.g., Google, YouTube, Facebook, etc.), data augmentation by packet sampling simulation to improve our results, the impact on packet sampling and the fine-tuning and possible impact of model parameters or the scalability of our approach. We conclude that, using only a 10% of the packets, we can identify the visited website with an accuracy and F1 score between 94% and 95%.}
}


@article{DBLP:journals/cn/XuSH23,
	author = {Zhilin Xu and
                  Hao Sun and
                  Weibin Han},
	title = {A collaboration-driven mechanism for {AI} diagnose with multiple requesters
                  under incomplete information},
	journal = {Comput. Networks},
	volume = {220},
	pages = {109472},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2022.109472},
	doi = {10.1016/J.COMNET.2022.109472},
	timestamp = {Sun, 15 Jan 2023 18:31:44 +0100},
	biburl = {https://dblp.org/rec/journals/cn/XuSH23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we design a collaboration-driven mechanism with multiple requesters cooperating together to collect massive accurate data and minimize costs in AI diagnose. Under the process of this incentive mechanism, two issues, the accuracy level of data and how to encourage requesters to cooperate, has been solved. A novel payment policy, with which the most accurate data gets the highest payment, is presented to assure the accuracy level of data. A Stackelberg game, which describes the interactions between requesters and workers, is put forward to stimulate multiple requesters jointly collect data. Considering requesters’ selfishness, Stackelberg equilibrium with multiple leaders are presented to maximize both requesters’ and workers’ utilities simultaneously. A cost allocation method inspired by separable costs remaining benefits method is proposed to ensure the increase of requesters’ utilities when collecting data as a team. However, since the worker’s (mobile device users’) privacy information is unknown, the game mentioned above is incomplete information dynamic MCS game. Hence, Q-learning is used to learn from historical data to estimate the unknown private data of workers. Several simulations are presented to prove that Q-learning can obtain theoretical solutions independent of parameters in the case of incomplete information.}
}


@article{DBLP:journals/cn/CastroJVV23,
	author = {Igor C. F. e Castro and
                  Eduardo P. M. C{\^{a}}mara J{\'{u}}nior and
                  Marcos A. M. Vieira and
                  Luiz Filipe M. Vieira},
	title = {{UW-GRE:} Underwater Greedy Geographic Routing by Network Embedding},
	journal = {Comput. Networks},
	volume = {220},
	pages = {109473},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2022.109473},
	doi = {10.1016/J.COMNET.2022.109473},
	timestamp = {Sun, 15 Jan 2023 18:31:44 +0100},
	biburl = {https://dblp.org/rec/journals/cn/CastroJVV23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper presents the novel routing protocol called Underwater Greedy Geographic Routing by Network Embedding (UW-GRE) for underwater wireless networks. Geographic routing is a promising network routing protocol strategy for wireless networks because it is stateless. However, this routing strategy faces various problems in the underwater environment. This is caused by some challenging characteristics of this environment, such as its 3D nature and the no propagation of GPS signal due to high radio frequency signal attenuation. Accurate localization, void regions, and guaranteed delivery are then some of the problems faced by this routing strategy in this environment. In this paper, we solve those problems efficiently by using geographic routing over virtual coordinates obtained through a network embedding in an\nn\n-dimensional (\nn\n≥\n2) Euclidean virtual space. By properly embedding the network in this virtual Euclidean space, no geographic information is needed. We implemented the protocol on ns-3. Our results show that, when compared to a conventional geographic routing protocol with perfect localization information, our protocol improves the number of transmissions and energy consumption by up to or higher than 30%, end-to-end delay by up to 28%, while achieving similar network throughput.}
}


@article{DBLP:journals/cn/ForoughiBR23,
	author = {Parisa Foroughi and
                  Frank Brockners and
                  Jean{-}Louis Rougier},
	title = {{ADT:} AI-Driven network Telemetry processing on routers},
	journal = {Comput. Networks},
	volume = {220},
	pages = {109474},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2022.109474},
	doi = {10.1016/J.COMNET.2022.109474},
	timestamp = {Tue, 10 Jan 2023 23:00:18 +0100},
	biburl = {https://dblp.org/rec/journals/cn/ForoughiBR23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Network monitoring is a pivotal part of network management and operations. It is responsible for monitoring the behavior of the network to assure its functionality within expectation and to guarantee a smooth-running environment for enabling of various services. Therefore, operators are interested in gaining a comprehensive assessment of their network elements and tracking operational changes to facilitate timely correction of any deviation. Commonly, this assessment is achieved by performing regular manual checks of different operational counters and defining expert rules from known root causes. The common approach requires the maintenance of a regularly updated set of rules and only goes as far as the operator’s pre-gained knowledge of the system. With the growing complexity of the networks as well as the availability of more data, a more efficient monitoring approach is necessary to address the emerging network monitoring requirements.}
}


@article{DBLP:journals/cn/ZhangY23,
	author = {Shengyu Zhang and
                  Kwan L. Yeung},
	title = {Location constrained virtual optical network embedding in space-division
                  multiplexing elastic optical networks},
	journal = {Comput. Networks},
	volume = {220},
	pages = {109475},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2022.109475},
	doi = {10.1016/J.COMNET.2022.109475},
	timestamp = {Sun, 15 Jan 2023 18:31:44 +0100},
	biburl = {https://dblp.org/rec/journals/cn/ZhangY23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Virtual optical network embedding (VONE) involves two processes, node mapping, and link mapping. Node mapping decides which data center to place the virtual nodes (VNs). Link mapping decides how to route virtual links between placed VNs. In location constrained VONE (LC-VONE), each VN can be mapped only to some substrate nodes. In this paper, we study the problem of LC-VONE in space-division multiplexing elastic optical networks (SDM-EONs). Aiming at load balancing, we formulate the first integer linear programming (ILP) to solve the static LC-VONE problem, where the set of VON requests is given. To achieve scalability, an integrated framework is devised to jointly conduct node and link mappings for each VON request. Three cost metrics are designed for finding the least-cost VON solution. Combining them with the integrated framework, three LC-VONE algorithms are proposed: minimum spectrum consumption (MSC), bottleneck link avoidance (BLA), and lowest traffic load (LTL). By applying them to solve both static and dynamic LC-VONE problems, we found that LTL always outperforms MSC and BLA.}
}


@article{DBLP:journals/cn/EncisoS23,
	author = {Alberto Robles Enciso and
                  Antonio F. Skarmeta},
	title = {A multi-layer guided reinforcement learning-based tasks offloading
                  in edge computing},
	journal = {Comput. Networks},
	volume = {220},
	pages = {109476},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2022.109476},
	doi = {10.1016/J.COMNET.2022.109476},
	timestamp = {Tue, 28 Feb 2023 10:48:05 +0100},
	biburl = {https://dblp.org/rec/journals/cn/EncisoS23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The breakthrough in Machine Learning (ML) techniques and the popularity of the Internet of Things (IoT) has increased interest in applying Artificial Intelligence (AI) techniques to the new paradigm of Edge Computing. One of the challenges in edge computing architectures is the optimal distribution of the generated tasks between the devices in each layer (i.e., cloud-fog-edge). In this paper, we propose to use Reinforcement Learning (RL) to solve the Task Assignment Problem (TAP) at the edge layer and then we propose a novel multi-layer extension of RL (ML-RL) techniques that allows edge agents to query an upper-level agent with more knowledge to improve the performance in complex and uncertain situations. We first formulate the task assignment process considering the trade-off between energy consumption and execution time. We then present a greedy solution as a baseline and implement our multi-layer RL proposal in the PureEdgeSim simulator. Finally several simulations of each algorithm are evaluated with different numbers of devices to verify scalability. The simulation results show that reinforcement learning solutions outperformed the heuristic-based solutions and our multi-layer approach can significantly improve performance in high device density scenarios.}
}


@article{DBLP:journals/cn/MehmoodKP23,
	author = {Kashif Mehmood and
                  Katina Kralevska and
                  David Palma},
	title = {Intent-driven autonomous network and service management in future
                  cellular networks: {A} structured literature review},
	journal = {Comput. Networks},
	volume = {220},
	pages = {109477},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2022.109477},
	doi = {10.1016/J.COMNET.2022.109477},
	timestamp = {Sat, 30 Sep 2023 10:07:03 +0200},
	biburl = {https://dblp.org/rec/journals/cn/MehmoodKP23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Intent-driven networks are an essential stepping stone in the evolution of network and service management towards a truly autonomous paradigm. User centric intents provide an abstracted means of impacting the design, provisioning, deployment and assurance of network infrastructure and services with the help of service level agreements and minimum network capability exposure. The concept of Intent Based Networking (IBN) poses several challenges in terms of the contextual definition of intents, role of different stakeholders, and a generalized architecture. In this review, we provide a comprehensive analysis of the state-of-the-art in IBN including the intent description models, intent lifecycle management, significance of IBN and a generalized architectural framework along with challenges and prospects for IBN in future cellular networks. An analytical study is performed on the data collected from relevant studies primarily focusing on the inter-working of IBN with softwarized networking based on NFV/SDN infrastructures. Critical functions required in the IBN management and service model design are explored with different abstract modeling techniques and a converged architectural framework is proposed. The key findings include: (1) benefits and role of IBN in autonomous networking, (2) improvements needed to integrate intents as fundamental policies for service modeling and network management, (3) need for appropriate representation models for intents in domain agnostic abstract manner, and (4) need to include learning as a fundamental function in autonomous networks. These observations provide the basis for in-depth investigation and standardization efforts for IBN as a fundamental network management paradigm in beyond 5G cellular networks.}
}


@article{DBLP:journals/cn/LiraAC23,
	author = {Clayton J. N. de Lira and
                  Raul C. Almeida Jr. and
                  Daniel A. R. Chaves},
	title = {Spectrum allocation using multiparameter optimization in elastic optical
                  networks},
	journal = {Comput. Networks},
	volume = {220},
	pages = {109478},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2022.109478},
	doi = {10.1016/J.COMNET.2022.109478},
	timestamp = {Sun, 15 Jan 2023 18:31:44 +0100},
	biburl = {https://dblp.org/rec/journals/cn/LiraAC23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Min Slot-Continuity Capacity Loss (MSCL) algorithm is listed in the literature as a powerful algorithm to solve the spectrum assignment (SA) problem in elastic optical networks (EONs). The MSCL presents, in its structure, characteristics that allow it to consider several unique network parameters that impact the network performance during the decision of the spectral allocation, such as: the evaluation of the impact of a spectral allocation in both the candidate route and in its interfering routes and the evaluation of the impact of a spectral allocation on the network’s capacity to successfully allocate future demands. However, other interesting features can be still added to the MSCL. Thus, in this paper we propose a framework that enables a systematic design of heuristics SA algorithms based on the MSCL principles. The main building blocks of the framework are the MSCL principles, the inclusion of new metrics and how to associate them, a generic function expanded in a series of functions and the utilization of a methaheuristic optimization algorithm. We apply the proposed framework to design two new SA heuristics named as MPAO-Wj and MPAO-WLj. These heuristics use the particle swarm optimization as optimization engine. We carried out computational simulations to assess the performance of the proposed algorithms and we compared them against five other benchmark heuristics from the literature. The simulation results indicate that, in the considered scenarios, the proposed algorithms are able to achieve superior network performance (in terms of blocking probability) than the investigated benchmark algorithms.}
}


@article{DBLP:journals/cn/BiomoKS23,
	author = {Jean{-}Daniel Medjo Me Biomo and
                  Thomas Kunz and
                  Marc St{-}Hilaire},
	title = {A novel routing protocol for reducing packet delay with multi-beam
                  antennas},
	journal = {Comput. Networks},
	volume = {220},
	pages = {109479},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2022.109479},
	doi = {10.1016/J.COMNET.2022.109479},
	timestamp = {Sun, 15 Jan 2023 18:31:44 +0100},
	biburl = {https://dblp.org/rec/journals/cn/BiomoKS23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Ad hoc networks are infrastructureless networks consisting of static and/or mobile nodes. These networks are deployed for a wide range of applications. Having an efficient routing protocol for communication between the nodes can be critical. Our goal in this paper is to design a routing protocol that capitalizes on Multi-Beam directional Antennas (MBAs) to significantly reduce the end-to-end (E2E) delay in multi-hop ad hoc networks that service multiple traffic flows. Previously, we proposed a multi-beam directional antenna MAC protocol, and a Mixed Integer Linear Programming model that exploits MBAs’ capabilities for delay minimization. Solving this model showed that the routes that are selected for different flows need to have certain key characteristics that depart from the traditional shortest-route philosophy. Based on these characteristics, we design, in this paper, an MBA-Delay-Reducing Routing protocol (MBA-DRR) that fully harnesses the benefits of MBAs for delay reduction. The benefits of this protocol apply to all types of multi-hop MBA-based ad hoc networks, both mobile and static. The evaluation on a multi-flow static scenario shows that MBA-DRR, with a delay of just 4.4 ms, gets very close to the optimal solution with a delay of 2.5 ms. Comparatively, Reactive-Geographic hybrid Routing, a shortest-route protocol, has a delay of 48 ms. An evaluation on a representative multi-flow mobile scenario shows that, while a single-beam directional MAC reduces the E2E delay from 700 ms to 40 ms, and a multi-beam directional MAC halves this to 20 ms, our proposed routing protocol further cuts it to 9 ms.}
}


@article{DBLP:journals/cn/QiTCC23,
	author = {Liuling Qi and
                  Junfeng Tian and
                  Mengjia Chai and
                  Hongyun Cai},
	title = {LightPoW: {A} trust based time-constrained PoW for blockchain in internet
                  of things},
	journal = {Comput. Networks},
	volume = {220},
	pages = {109480},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2022.109480},
	doi = {10.1016/J.COMNET.2022.109480},
	timestamp = {Tue, 10 Jan 2023 23:00:18 +0100},
	biburl = {https://dblp.org/rec/journals/cn/QiTCC23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Blockchain has been widely used in the Internet of Things (IoT) to address security problems such as DDoS and Sybil. However, how to design a lightweight Proof-of-Work (PoW) for the IoT without compromising security is still a problem. To solve this problem, we propose a lightweight PoW for blockchain in IoT. Firstly, we present Heterogeneity Considered Trust Mechanism (HCTM) for IoT nodes, which evaluates the trust value according to capacity and quality, and makes the trust evaluation more reasonable. Then, we present Trust based Time-Constrained PoW (TBTC-PoW). We allocate reasonable time windows to the consensus nodes according to the computing resources, trust values and mining difficulty, which reduces the energy consumption and improves the security of PoW. Theoretical analysis and experimental results show that our method has a lower energy consumption and higher security.}
}


@article{DBLP:journals/cn/AriemmaDLCB23,
	author = {Lorenzo Ariemma and
                  Alessandro Dell'Orco and
                  Simone Liotta and
                  Massimo Candela and
                  Giuseppe Di Battista},
	title = {Long-lasting sequences of {BGP} updates},
	journal = {Comput. Networks},
	volume = {220},
	pages = {109481},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2022.109481},
	doi = {10.1016/J.COMNET.2022.109481},
	timestamp = {Sun, 15 Jan 2023 18:31:44 +0100},
	biburl = {https://dblp.org/rec/journals/cn/AriemmaDLCB23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Border Gateway Protocol (BGP) is the protocol that makes the various networks composing the Internet communicate to each other. Routers speaking BGP exchange updates to keep the routing up-to-date and allow such communication. This usually is done to reflect changes in the routing configurations or as a consequence of link failures. In the Internet as a whole it is normal that BGP updates are continuously exchanged, but for any specific IP prefix, these updates are supposed to be concentrated in a short time interval that is needed to react to a network change. On the contrary, in this paper we show that there are many IP prefixes involved in quite long sequences consisting of a large number of BGP updates. Namely, examining\n∼\n30\nbillion updates collected by 172 observation points distributed worldwide, we estimate that almost 30% of them belong to sequences lasting more than one week. Such sequences involve\n222\n285\ndistinct IP prefixes, approximately one fourth of the number of announced prefixes. We detect such sequences using a method based on the Discrete Wavelet Transform. We publish an online tool for the exploration and visualization of such sequences, which is open to the scientific community for further research. We group together sequences that exhibit common behaviours. For this purpose, we devise a clusterization algorithm able to group the sequences based on their similarity in time. We highlight four categories of clusters, which are attributable to different types of Internet events. Our online tool allows also to explore and to visualize the computed clusters.}
}


@article{DBLP:journals/cn/LiuCYCY23,
	author = {Zhixin Liu and
                  Xi Chen and
                  Yi Yang and
                  Kit Yan Chan and
                  Yazhou Yuan},
	title = {Joint cell zooming and sleeping strategy in ultra dense heterogeneous
                  networks},
	journal = {Comput. Networks},
	volume = {220},
	pages = {109482},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2022.109482},
	doi = {10.1016/J.COMNET.2022.109482},
	timestamp = {Mon, 06 Feb 2023 08:52:27 +0100},
	biburl = {https://dblp.org/rec/journals/cn/LiuCYCY23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {To optimize the ultra dense distribution of base stations (BSs) which consist of micro BS and macro BS, balancing the tradeoff between user communication quality and energy saving is essential. In this paper, a joint cell zooming and sleeping strategy is proposed for the downlink two-tier heterogeneous network under the Poisson Point Process (PPP) model, in order to balance the user benefits and communication system operating cost. First, the cell zooming scheme is presented based on game theory, where the association probability of each base station is achieved by adjusting the cell zooming factor (CZF). With the improved BS association probability, more users can benefit with better network experience by connecting to micro BS instead of macro BS. Then a two-step sleeping strategy is put forward, by applying the cell zooming. The first step is to ascertain which BSs are kept based on the analysis of the energy consumption of candidates. The second step is used to measure the overall overlapping degree of each BS and provide different sleep decisions according to the radius of the area covered by MBS. The proposed sleeping scheme is able to stimulate the BS with a high overlapping degree to be slept to achieve more energy saving. Through the proposed joint schemes, the service efficiency of communication system is improved, when the users connect to micro BS instead of macro BS and some micro BSs with low utility are turned off. Simulation results indicate the improved performance in terms of the user experiences and energy saving.}
}


@article{DBLP:journals/cn/KazemiGKO23,
	author = {Seyed Mojtaba Kazemi and
                  Shamsollah Ghanbari and
                  Manochehr Kazemi and
                  Mohamed Othman},
	title = {Optimum scheduling in fog computing using the Divisible Load Theory
                  {(DLT)} with linear and nonlinear loads},
	journal = {Comput. Networks},
	volume = {220},
	pages = {109483},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2022.109483},
	doi = {10.1016/J.COMNET.2022.109483},
	timestamp = {Sun, 15 Jan 2023 18:31:44 +0100},
	biburl = {https://dblp.org/rec/journals/cn/KazemiGKO23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Fog computing has been proposed to reduce the latency of cloud computing. One of the most common challenges in fog computing is scheduling. Suitable scheduling increases the efficiency of fog computing. There is a wide range of methods of scheduling that have been presented by the researchers each with its strengths and weaknesses. This paper presents a novel scheduling method for fog computing based on the Divisible Load Theory (DLT). The proposed method has significant benefits for loads that are arbitrarily divisible and for huge and intense data. First, the proposed method is modeled, and then, based on DLT, the related closed form is proposed for both linear and nonlinear modes. Subsequently, the closed forms are solved, and based on that, an innovative algorithm for the partitioning and distribution of fractions of an arbitrary divisible load among nodes in a fog environment is proposed. The performance of the proposed method is compared with existing algorithms. The simulated results show that using the DLT method significantly optimizes the performance a minimum of seven times. It reduces the finish time (about eight times in linear and eighty-five times in nonlinear loads) and increases the speedup (about seven times in linear and one hundred thirty times in nonlinear loads).}
}


@article{DBLP:journals/cn/JiangB23,
	author = {Wenhao Jiang and
                  Yuebin Bai},
	title = {{APGNN} : Alarm Propagation Graph Neural Network for fault detection
                  and alarm root cause analysis},
	journal = {Comput. Networks},
	volume = {220},
	pages = {109485},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2022.109485},
	doi = {10.1016/J.COMNET.2022.109485},
	timestamp = {Tue, 10 Jan 2023 23:00:18 +0100},
	biburl = {https://dblp.org/rec/journals/cn/JiangB23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Telecommunication network plays an important role in our daily life. Fault detection and alarm root cause analysis are the keys to ensure the normal operation of the network. To reduce the burden on operators, numerous methods are employed to analyse root cause of faults. However, there still remain a large amount of non-essential or transient alarms after root cause analysis. A simple Rule-based method may help ease the problems. But it needs prior expert knowledge and the diversity of alarm pattern makes the rules redundant and complicated. Moreover, it cannot accurately cover all true faults and need manual methods as complement. In this work, we propose Alarm Propagation Graph Neural Network(APGNN), a novel data-driven propagation-based root cause analysis and fault detection approach.It first associates alarms and extracts root-derived graph based on Bayesian Network. Then it constructs alarm propagation graphs(APG). We refine the repair orders to obtain actual fault information. At last, Graph Neural Network is used to extract features and learn the mapping from APG to the true fault. Our method not only detects the true fault from large volume of original alarms, but also analyses the root cause alarms. We evaluate our approach both on the offline and online environment of the real-world IP Radio Access Network. Experiments show that our model outperforms the state-of-art approach by 4.6% in F1-score on average.}
}


@article{DBLP:journals/cn/MaWSCMXC23,
	author = {Dongchao Ma and
                  Pengyu Wang and
                  Lihua Song and
                  Wenlong Chen and
                  Li Ma and
                  Mingwei Xu and
                  Laizhong Cui},
	title = {A lightweight deployment of {TD} routing based on SD-WANs},
	journal = {Comput. Networks},
	volume = {220},
	pages = {109486},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2022.109486},
	doi = {10.1016/J.COMNET.2022.109486},
	timestamp = {Sun, 15 Jan 2023 18:31:44 +0100},
	biburl = {https://dblp.org/rec/journals/cn/MaWSCMXC23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Multipath routing conforms to the evolution principle of network development and is a trend of routing architectures. It can not only meet the needs but also enhance the performance and security of a network. However, deploying multipath routing further increases the scale of the forwarding information base (FIB) and the cost of forwarding devices. Therefore, to realize the lightweight deployment of multipath routing with a distributed architecture, this paper takes two-dimensional routing (TD routing) as an example to provide a solution. We propose a distributed storage mechanism of TD routing in combination with SRv6 (TDSR) and the corresponding SRv6 header (SRH) compression (CARD) method. The main methods are as follows: Inspired by a software-defined wide area network (SD-WAN), this paper introduces segment routing (SR) in the data plane, which can disperse TD-FIBs in different ingress nodes. The ingress routers push path information into the stack, and the intermediate routers forward the packets according to the SRH. Second, for the bandwidth waste of the SRH, compression is attempted by comparing the difference between the the shortest path first (SPF) path and the SRv6 path. Only a few hops in the TD path that are different from those in the one-dimensional (OD) path are kept. Finally, we sort out several typical application scenes of multipath routing and discuss several simplification algorithms. The experimental results show that the TDSR can reduce TD entries by 69%, and the average compression rate of CARD can reach 70%. In addition, CARD can be combined with existing methods to improve their effect.}
}


@article{DBLP:journals/cn/Venkateswararao23,
	author = {Kuna Venkateswararao and
                  Pravati Swain and
                  Shashi Shekhar Jha and
                  Iacovos Ioannou and
                  Andreas Pitsillides},
	title = {A novel power consumption optimization framework in 5G heterogeneous
                  networks},
	journal = {Comput. Networks},
	volume = {220},
	pages = {109487},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2022.109487},
	doi = {10.1016/J.COMNET.2022.109487},
	timestamp = {Sat, 30 Sep 2023 10:07:05 +0200},
	biburl = {https://dblp.org/rec/journals/cn/Venkateswararao23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The fifth-generation (5G) mobile networks have the capacity to handle the dynamic traffic demands of the user equipment (UE). One approach is the dense deployment of small base stations (s-BSs), which can control the dynamic traffic demands. We consider s-BSs which are interconnected through the mmWave backhaul (BH) link to transfer traffic from the s-BS to the core network through the macro base station (MBS). In this setting, the network power consumption is affected by the way UEs are connected to the base stations and the traffic routes through the BH links. The main objective of this paper is to minimize the power consumption of the heterogeneous network (HetNet) with the intelligent backhauling and s-BS/BH link sleeping (IBSBS) framework. The proposed framework provides the minimized power consumption in HetNets through UE association, backhauling, and sleep s-BS/BH links. The UE association and backhauling uses a heuristic function based intelligent backhauling algorithm to assess the minimum power consumption from the s-BS to the MBS while considering the power and capacity constraints of the network. The load sharing based s-BS sleeping algorithm dynamically changes the states (active/sleep) of the s-BSs according to their loads without compromising UE demands. Different distributions of UEs and different data rates over the HetNets architecture are considered for performance evaluation. The evaluation results of the proposed framework outperform the state-of-the-art algorithms in terms of network energy efficiency, power consumption, and the number of active s-BSs/BH links.}
}


@article{DBLP:journals/cn/DengHLZG23,
	author = {Hanqiang Deng and
                  Jian Huang and
                  Quan Liu and
                  Cong Zhou and
                  Jialong Gao},
	title = {{BGSD:} {A} {SBERT} and GAT-based Service Discovery Framework for
                  Heterogeneous Distributed IoT},
	journal = {Comput. Networks},
	volume = {220},
	pages = {109488},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2022.109488},
	doi = {10.1016/J.COMNET.2022.109488},
	timestamp = {Sun, 15 Jan 2023 18:31:44 +0100},
	biburl = {https://dblp.org/rec/journals/cn/DengHLZG23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Collaboration between heterogeneous IoT (Internet of Things) devices can enrich the capabilities of the system. In scenarios where network infrastructure or cloud platforms are unavailable, enabling devices to collaborate autonomously in a distributed manner can improve the scalability and invulnerability of the system. A distributed service architecture with semantic services can enable more flexible collaboration among IoT devices, while the efficiency and accuracy of current methods on devices with poor computing and storage capacity need to be improved. Therefore, this paper proposes a SBERT (Sentence Bidirectional Encoder Representations from Transformers) and GAT (Graph Attention Networks) based Service Discovery method, called BGSD. SBERT is used to extract deep semantic features of services during offline to improve the discriminability of semantic features and reduce performance requirements for IoT devices, and GAT is used to perceive the local topology environment to improve the network navigability of service search. To evaluate the method, we generate a heterogeneous IoT topology dataset based on OWLS-TC4. The simulation results of service discovery show that BGSD has advantages in search efficiency, matching accuracy and computational cost, and can support the collaboration of IoT devices in heterogeneous distributed scenarios, which verifies the rationality of this method.}
}


@article{DBLP:journals/cn/WangXXJL23,
	author = {Zhiyuan Wang and
                  Hongli Xu and
                  Yang Xu and
                  Zhida Jiang and
                  Jianchun Liu},
	title = {CoopFL: Accelerating federated learning with {DNN} partitioning and
                  offloading in heterogeneous edge computing},
	journal = {Comput. Networks},
	volume = {220},
	pages = {109490},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2022.109490},
	doi = {10.1016/J.COMNET.2022.109490},
	timestamp = {Sun, 15 Jan 2023 18:31:44 +0100},
	biburl = {https://dblp.org/rec/journals/cn/WangXXJL23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated learning (FL), a novel distributed machine learning (DML) approach, has been widely adopted to train deep neural networks (DNNs), over massive data in edge computing. However, the existing FL systems often lead to a long training time due to resource limitation and system heterogeneity (e.g., computing, communication and memory) in edge computing. To this end, we design and implement an FL system, called CoopFL, which trains DNNs through the cooperation between devices and edge servers. Specifically, we implement DNN partitioning and offloading techniques in CoopFL, which enables each device to train a partial DNN model and offload the intermediate data outputted by some hidden layers to proper edge servers for cooperative training. However, some empirical partitioning and offloading strategies in previous works may not exploit the system resource well or even slow down the training procedure. To this end, we give a problem definition considering the resource constraints and system heterogeneity, and then propose an efficient algorithm to solve this problem so as to accelerate the training procedure by the developed DNN partitioning and offloading strategy. Extensive experiments on the classical models and datasets show the high effectiveness of our system. For example, CoopFL achieves a speedup of 2.3–4.9×, compared with the baselines, including hierarchical federated learning system (HFL), typical federated learning system (TFL), and two systems with empirical DNN partitioning, i.e., FedMEC and HFLP.}
}


@article{DBLP:journals/cn/SharmaRNPX23,
	author = {Rohit Sharma and
                  Danda B. Rawat and
                  Amiya Nayak and
                  Sheng{-}Lung Peng and
                  Qin Xin},
	title = {Introduction to the special section on survivability analysis of wireless
                  networks with performance evaluation (VSI-networks survivability)},
	journal = {Comput. Networks},
	volume = {220},
	pages = {109498},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2022.109498},
	doi = {10.1016/J.COMNET.2022.109498},
	timestamp = {Sun, 12 Nov 2023 02:17:56 +0100},
	biburl = {https://dblp.org/rec/journals/cn/SharmaRNPX23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{DBLP:journals/cn/VrindKPD23,
	author = {Tushar Vrind and
                  Chandan Kumar and
                  Lalit Pathak and
                  Debabrata Das},
	title = {Feedback-based algorithm for aerial cell's trajectory using deep learning
                  for efficient performance in 6G},
	journal = {Comput. Networks},
	volume = {220},
	pages = {109499},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2022.109499},
	doi = {10.1016/J.COMNET.2022.109499},
	timestamp = {Sun, 15 Jan 2023 18:31:44 +0100},
	biburl = {https://dblp.org/rec/journals/cn/VrindKPD23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Sixth (6th) Generation (6G) wireless communication proposes Non-Terrestrial aerial Network (NTN) architecture to support dynamic scaling of both coverage and capacity. In this paper, we discuss Low Altitude Platform (LAP) based aerial cell for NTN which augments the terrestrial cell through Dual Connectivity (DC) or Carrier Aggregation (CA) on an independent and non-interfering frequency carrier. The determination of an optimal trajectory for a LAP based aerial cell is critical in the deployment for improving its resource utilization within the given flight time. The available literature on selecting trajectory for drone cell have independently considered the data traffic requirements or the mobility of the User Equipment (UE) while improving the throughput or coverage respectively. We propose for the first time; a novel Zone-based Drone Positioning and Trajectory algorithm for selecting UEs to be served by a drone cell as well as for choosing the position and trajectory of the LAP based aerial cell. The proposed algorithm utilizes a new feedback quantity from the UE called Feedback for Aerial Cell Trajectory (FACT), which contains UE's predicted data traffic, traffic preference, and mobility state. The algorithm and FACT are presented mathematically with a combination of closed-form equations with a deep learning (Long Short-Term Memory (LSTM)) model and evaluated through extensive simulations. The simulation shows improvement by 44% in spectrum resource utilization of an aerial cell and a 27% improvement in user throughput over available schemes in the literature.}
}


@article{DBLP:journals/cn/YuLXZWD23,
	author = {Jiayi Yu and
                  Anfeng Liu and
                  Neal N. Xiong and
                  Shaobo Zhang and
                  Tian Wang and
                  Mianxiong Dong},
	title = {Employing Social Participants for Timely Data Collection Using Pub/sub
                  Solutions in Dynamic IoT Systems},
	journal = {Comput. Networks},
	volume = {220},
	pages = {109501},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2022.109501},
	doi = {10.1016/J.COMNET.2022.109501},
	timestamp = {Mon, 21 Aug 2023 15:51:19 +0200},
	biburl = {https://dblp.org/rec/journals/cn/YuLXZWD23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In Mobile Crowd Sensing (MCS), the platform publishes sensing tasks with the requirements of location, time and data attributes and hires participants to perform sensing tasks, thus it can collect and process mass of sensing data to construct various applications and publish them to service requesters, which is a low cost and effective method for large-scale data processing. However, most of the existing studies do not consider the value of tasks with time-discount property and insufficient participation, which results in delayed task completion and low task completed ratio. In this paper, we propose data collection mechanisms in offline and online scenario considering both of these factors to collect data timely and increase the benefit of the platform effectively. We propose a multi-tiered spreading task structure, in which participants act as agents to recruit their social neighbors to perform tasks, and the social neighbors can be recruited as new agents to spread tasks so that there is a sufficient number of participants in the platform to be selected to perform tasks. In winner and agent selection of online mechanism, we change the allocation of budget in multi-stage sampling accepting process based on real-time task completed ratio. We proved that the proposed mechanisms achieve computational efficiency, truthfulness, individual rationality and budget feasibility, and after extensive experiments, we proved the proposed mechanisms are superior to previous strategies.}
}


@article{DBLP:journals/cn/BonatiPDBM23,
	author = {Leonardo Bonati and
                  Michele Polese and
                  Salvatore D'Oro and
                  Stefano Basagni and
                  Tommaso Melodia},
	title = {OpenRAN Gym: {AI/ML} development, data collection, and testing for
                  {O-RAN} on {PAWR} platforms},
	journal = {Comput. Networks},
	volume = {220},
	pages = {109502},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2022.109502},
	doi = {10.1016/J.COMNET.2022.109502},
	timestamp = {Mon, 05 Feb 2024 20:24:11 +0100},
	biburl = {https://dblp.org/rec/journals/cn/BonatiPDBM23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Open Radio Access Network (RAN) architectures will enable interoperability, openness and programmable data-driven control in next generation cellular networks. However, developing and testing efficient solutions that generalize across heterogeneous cellular deployments and scales, and that optimize network performance in such diverse environments is a complex task that is still largely unexplored. In this paper, we present OpenRAN Gym, a unified, open, and O-RAN-compliant experimental toolbox for data collection, design, prototyping and testing of end-to-end data-driven control solutions for next generation Open RAN systems. OpenRAN Gym extends and combines into a unique solution several software frameworks for data collection of RAN statistics and RAN control, and a lightweight O-RAN near-real-time RAN Intelligent Controller (RIC) tailored to run on experimental wireless platforms. We first provide an overview of the various architectural components of OpenRAN Gym and describe how it is used to collect data and design, train and test artificial intelligence and machine learning O-RAN-compliant applications (xApps) at scale. We then describe in detail how to test the developed xApps on softwarized RANs and provide an example of two xApps developed with OpenRAN Gym that are used to control a network with 7 base stations and 42 users deployed on the Colosseum testbed. Finally, we show how solutions developed with OpenRAN Gym on Colosseum can be exported to real-world, heterogeneous wireless platforms, such as the Arena testbed and the POWDER and COSMOS platforms of the PAWR program. OpenRAN Gym and its software components are open-source and publicly-available to the research community. By guiding the readers from instantiating the components of OpenRAN Gym, to running experiments in a softwarized RAN with an O-RAN-compliant near-RT RIC and xApps, we aim at providing a key reference for researchers and practitioners working on experimental Open RAN systems.}
}


@article{DBLP:journals/cn/EsubontengR23,
	author = {Paa Kwesi Esubonteng and
                  Roberto Rojas{-}Cessa},
	title = {Effect of the incident angle of a transmitting laser light on the
                  coverage of a {NLOS-FSO} network},
	journal = {Comput. Networks},
	volume = {220},
	pages = {109504},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2022.109504},
	doi = {10.1016/J.COMNET.2022.109504},
	timestamp = {Sun, 15 Jan 2023 18:31:44 +0100},
	biburl = {https://dblp.org/rec/journals/cn/EsubontengR23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we propose a model of the coverage and achievable data rates in No Line-of-Sight Free-Space Optical Communications (NLOS-FSOC) as a function of the angle of incidence. NLOS-FSOC uses diffuse reflected light to establish communication between two or more stations that are with or without line-of-sight to each other. Different from free-space optical communications (FSOC), NLOS-FSOC uses a diffuse reflector (DR) between a transmitter and a receiver so that LOS is not required between them but between the station and the DR. Unlike a mirror, the DR reflects the incident light to all directions but to itself and that reflection broadcast the optical channel to all receivers within LOS. The optical broadcast channel establishes a true optical local area network (OLAN). However, the reflected power and the coverage of an OLAN largely depend on the angle of incidence of transmitted laser beam. Therefore, the planning and building of an OLAN with NLOS-FSOC must consider this angle to optimize coverage, to set range, or to estimate the achievable communication data rates.}
}


@article{DBLP:journals/cn/SunZPLL23,
	author = {Sheng Sun and
                  Zengqi Zhang and
                  Quyang Pan and
                  Min Liu and
                  Zhongcheng Li},
	title = {Vehicle-cluster-based opportunistic relays for data collection in
                  intelligent transportation systems},
	journal = {Comput. Networks},
	volume = {220},
	pages = {109509},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2022.109509},
	doi = {10.1016/J.COMNET.2022.109509},
	timestamp = {Tue, 10 Jan 2023 23:00:18 +0100},
	biburl = {https://dblp.org/rec/journals/cn/SunZPLL23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Intelligent transportation system (ITS) is envisioned to greatly improve traffic and enhance safety on roads. ITS relies on a huge amount of data generated from roadside sensor devices to make decisions. Due to the limited channel resources, the base station (BS) that connects with an ITS server can only collect data from parts of sensor devices at a time. To improve the number of device associations, we regard vehicle clusters as relays to collect data, which can avoid high capital expenditure and operating expenses from dedicated relays. Due to the frequently varying channel interference and the limited communication coverage of a vehicle cluster relay (VCR), it is challenging to guarantee the transmission rates and the fairness of sensor devices, which will affect the decisions of ITS. For this reason, we propose a Movement- and Fairness-Aware Heuristic (MFAH) algorithm to tackle the above challenges. MFAH sequentially conducts two novel channel allocation schemes, i.e., exclusive channel allocation scheme and compatible channel allocation scheme, to fast allocate channels and improve the channel utilization, which increases the number of device associations while guaranteeing the transmission rates. Regarding the fairness of each device’s associations, we propose a device association scheme based on the cumulative number of device associations and the distance from the target VCR to select appropriate sensor devices to upload data. We theoretically analyze the lower bound of the obtained network utility. Extensive simulations show that compared with benchmarks, the proposed MFAH algorithm converges fast and effectively improves the network utility (i.e., increasing the number of device associations while guaranteeing the fairness of device associations).}
}


@article{DBLP:journals/cn/XiongLZXL23,
	author = {Runqun Xiong and
                  Chuan Liang and
                  Huajun Zhang and
                  Xiangyu Xu and
                  Junzhou Luo},
	title = {FlyingLoRa: Towards energy efficient data collection in UAV-assisted
                  LoRa networks},
	journal = {Comput. Networks},
	volume = {220},
	pages = {109511},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2022.109511},
	doi = {10.1016/J.COMNET.2022.109511},
	timestamp = {Thu, 31 Oct 2024 08:09:25 +0100},
	biburl = {https://dblp.org/rec/journals/cn/XiongLZXL23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Energy efficiency is an increasingly crucial consideration due to the battery-powered end devices in LoRa networks. With the adoption of chirp spread spectrum modulation, end devices far apart from the gateway have to use a high spreading factor and transmit power to send uplink packets, which causes longer transmission time and higher energy consumption compared to the end devices near the gateway, and further causes unfairness issues on energy efficiency. To tackle this problem, we investigate a novel energy-efficient data collection scheme named FlyingLoRa, where an unmanned aerial vehicle carrying one gateway is dispatched to harvest packets from end devices. The goal of FlyingLoRa is to minimize the energy consumption of end devices for packet transmission by jointly optimizing the 3D UAV trajectory, scheduling strategies, and transmission parameters of end devices. We formulate our design as a mixed-integer non-convex optimization problem and propose an efficient iterative algorithm to find a sub-optimal solution. The proposed approach is numerically simulated and the results show that FlyingLoRa improves energy efficiency by 16.13\n×\non average compared with the existing fixed gateway schemes. In addition, we realize FlyingLoRa in real scenarios and evaluate its performance by presenting the actual packet reception rate (PRR) and transmission energy consumption, which shows its effectiveness.}
}


@article{DBLP:journals/cn/YanZL23,
	author = {Yan Yan and
                  Baoxian Zhang and
                  Cheng Li},
	title = {A networked multi-agent reinforcement learning approach for cooperative
                  FemtoCaching assisted wireless heterogeneous networks},
	journal = {Comput. Networks},
	volume = {220},
	pages = {109513},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2022.109513},
	doi = {10.1016/J.COMNET.2022.109513},
	timestamp = {Sun, 15 Jan 2023 18:31:44 +0100},
	biburl = {https://dblp.org/rec/journals/cn/YanZL23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {To meet the explosive growth of mobile traffic requirement in the 5th generation (5 G) mobile system, FemtoCaching at the network edge has been regarded as a promising technique for the 5 G mobile system. In this paper, we focus on studying the cooperative FemtoCaching problem in wireless heterogeneous networks (HetNets), which is aimed to minimize the overall fetching delays of all users. Owing to the NP-hardness of the problem, we formulate the cooperative FemtoCaching problem as a Networked Multi-Agent Reinforcement Learning (NMARL) problem and accordingly propose a Soft Attentional Networked Multi-Agent Actor-Critic (SAN-AC) Reinforcement Learning algorithm. Simulation results demonstrate that the proposed algorithm can significantly increase the overall performance compared with existing work.}
}
