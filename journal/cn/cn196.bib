@article{DBLP:journals/cn/ArceSPG21,
	author = {Pau Arce and
                  David Salvo and
                  Gema Pi{\~{n}}ero and
                  Alberto Gonz{\'{a}}lez},
	title = {{FIWARE} based low-cost wireless acoustic sensor network for monitoring
                  and classification of urban soundscape},
	journal = {Comput. Networks},
	volume = {196},
	pages = {108199},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108199},
	doi = {10.1016/J.COMNET.2021.108199},
	timestamp = {Wed, 01 Sep 2021 12:45:12 +0200},
	biburl = {https://dblp.org/rec/journals/cn/ArceSPG21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This work presents a wireless acoustic sensor network (WASN) that monitors urban environments by recognizing a given set of sound events or classes. The nodes of the WASN are Raspberry Pi devices that not only record the ambient sound, but also detect and recognize different sound events. All the signal processing tasks, from the recording to the classification carried out by a convolutional neural network (CNN), are run on Raspberry Pi devices. Due to the low cost of the proposed acoustic nodes, the system exhibits a very high potential scalability. Regarding the underlying WASN, it has been designed according to the open standard FIWARE, thus the whole system can be deployed without the need of proprietary software. Regarding the performance of the sound classifier, the proposed WASN achieves similar accuracy compared to other WASNs that make use of cloud computing. However, the proposed WASN significantly minimizes the network traffic since it does not exchange audio signals, but only contextual information in form of labels. On the other hand, most of the time the class reported by the WASN nodes is the “background” soundscape, which usually contains no event of interest. This is the case when monitoring the soundscape of big avenues, where four events have been identified: “traffic”, “siren”, “horn” and “noisy vehicles”, being the “traffic” class associated to the background soundscape. In this paper, the use of a simple pre-detection stage prior to the CNN classification is proposed, with the aim of saving computation and power consumption at the nodes. The pre-detection stage is able to differentiate the other three relevant sounds from the “traffic” and activates the classifier only when some of these three events is likely occurring. The proposed pre-detection stage has been validated through data recorded in the city of Valencia (Spain), achieving a reduction of the Raspberry Pi CPU’s usage by a factor of six.}
}


@article{DBLP:journals/cn/ChaddaSBBL21,
	author = {Amel Chadda and
                  Marija Stojanova and
                  Thomas Begin and
                  Anthony Busson and
                  Isabelle Gu{\'{e}}rin Lassous},
	title = {Assigning channels in WLANs with channel bonding: {A} fair and robust
                  strategy},
	journal = {Comput. Networks},
	volume = {196},
	pages = {108200},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108200},
	doi = {10.1016/J.COMNET.2021.108200},
	timestamp = {Sun, 06 Oct 2024 21:22:02 +0200},
	biburl = {https://dblp.org/rec/journals/cn/ChaddaSBBL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The ever-growing popularity of WLANs has lead to a numerous and highly diverse set of solutions for increasing the available link data rates. Amongst these solutions, channel bonding offers the possibility to use wider channels and increase the data rates by a factor of two, four, or eight. The issue of properly selecting the channels and their width remains a complex problem. In this paper, we present a fast, scalable, and fully graph-centric strategy for choosing a channel width and assignment for the APs of an IEEE 802.11-based WLAN. It typically outperforms strategies consisting of selecting the channel width regardless of the WLAN topology by 15% in fairness and 20% in throughput.}
}


@article{DBLP:journals/cn/Dermany21,
	author = {Mohammad Khalily Dermany},
	title = {Transmission power assignment in network-coding-based-multicast-wireless-sensor
                  networks},
	journal = {Comput. Networks},
	volume = {196},
	pages = {108203},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108203},
	doi = {10.1016/J.COMNET.2021.108203},
	timestamp = {Wed, 01 Sep 2021 12:45:12 +0200},
	biburl = {https://dblp.org/rec/journals/cn/Dermany21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The advantages of both transmission-power assignment and network-coding-based multicast in wireless sensor networks, in reducing the complexity (medium access control and routing), saving energy, and prolonging network lifetime, are well known. To improve the network efficiency, this paper proposes a Memetic ant colony algorithm that combines the transmission power assignment with the network-coding-based-multicast routing. The proposed algorithm stores the solution in a memory and maintains diversity among the population list to accelerate finding the solutions in the dynamic networks. In the proposed algorithm, energy consumption for receiving, the irregular shape of transmission domain, the discrete transmitting power levels of sensors, and dynamical changes in the network features are of concern. The results of the assessments run through simulations indicate that the proposed algorithm could obtain the optimal or near-optimal satisfactory transmission power levels and multicast routes. In addition, the runtime of proposed algorithm is reduced greatly compared to existing methods.}
}


@article{DBLP:journals/cn/PustokhinaPLES21,
	author = {Irina Valeryevna Pustokhina and
                  Denis Alexandrovich Pustokhin and
                  E. Laxmi Lydia and
                  Mohamed Elhoseny and
                  K. Shankar},
	title = {Energy Efficient Neuro-Fuzzy Cluster based Topology Construction with
                  Metaheuristic Route Planning Algorithm for Unmanned Aerial Vehicles},
	journal = {Comput. Networks},
	volume = {196},
	pages = {108214},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108214},
	doi = {10.1016/J.COMNET.2021.108214},
	timestamp = {Sat, 06 Jul 2024 18:16:41 +0200},
	biburl = {https://dblp.org/rec/journals/cn/PustokhinaPLES21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {At present times, unmanned aerial vehicles (UAVs) received significant attention among several application areas and services in both defense and civilian domains. The existence of many UAVs performs difficult process effectually when they are arranged in an adhoc way. The restricted battery capacity of the UAVs, rapid mobility, and high dynamic nature of the UAVs necessities the design of energy efficient clustering and routing protocols. With its motivation, this paper develops an Energy Efficient Neuro-Fuzzy Cluster based Topology Construction with Metaheuristic Route Planning (EENFC-MRP) algorithm for UAVs. The presented model involves EENFC based clustering and MRP based routing processes. The EENFC model make use of three input parameters namely Residual Energy in UAV, Average Distance to Nearby UAVs, and UAV Degree for the cluster construction. In addition, Quantum Ant Lion Optimization (QALO) based MRP is applied to choose an optimal set of routes for intercluster UAV communication. In order to investigate the energy efficient outcome of the EENFC-MRP algorithm, a series of simulation processes were carried out and the results are examined under several aspects. The resultant experimental values ensured the betterment of the EENFC-MRP algorithm over the existing models interms of energy efficiency, throughput, network lifetime, and average delay.}
}


@article{DBLP:journals/cn/KhanKKAA21,
	author = {Ammar Ahmed Khan and
                  Muhammad Mubashir Khan and
                  Kashif Mehboob Khan and
                  Junaid Arshad and
                  Farhan Ahmad},
	title = {A blockchain-based decentralized machine learning framework for collaborative
                  intrusion detection within UAVs},
	journal = {Comput. Networks},
	volume = {196},
	pages = {108217},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108217},
	doi = {10.1016/J.COMNET.2021.108217},
	timestamp = {Wed, 01 Sep 2021 12:45:13 +0200},
	biburl = {https://dblp.org/rec/journals/cn/KhanKKAA21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {UAVs have numerous emerging applications in various domains of life. However, it is extremely challenging to gain the required level of public acceptance of UAVs without proving safety and security for human life. Conventional UAVs mostly depend upon the centralized server to perform data processing with complex machine learning algorithms. In fact, all the conventional cyber attacks are applicable on the transmission and storage of data in UAVs. While their impact is extremely serious because UAVs are highly dependent on smart systems that extensively utilize machine learning techniques in order to take decisions in human absence. In this regard, we propose to enhance the performance of UAVs with a decentralized machine learning framework based on blockchain. The proposed framework has the potential to significantly enhance the integrity and storage of data for intelligent decision making among multiple UAVs. We present the use of blockchain to achieve decentralized predictive analytics and present a framework that can successfully apply and share machine learning models in a decentralized manner. We evaluate our system using collaborative intrusion detection as a case-study in order to highlight the feasibility and effectiveness of using blockchain based decentralized machine learning approach in UAVs and other similar applications.}
}


@article{DBLP:journals/cn/DhananjayZMISR21,
	author = {Aditya Dhananjay and
                  Kai Zheng and
                  Marco Mezzavilla and
                  Lorenzo Iotti and
                  Dennis E. Shasha and
                  Sundeep Rangan},
	title = {Pi-Radio v1: Calibration techniques to enable fully-digital beamforming
                  at 60 GHz},
	journal = {Comput. Networks},
	volume = {196},
	pages = {108220},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108220},
	doi = {10.1016/J.COMNET.2021.108220},
	timestamp = {Sun, 06 Oct 2024 21:22:03 +0200},
	biburl = {https://dblp.org/rec/journals/cn/DhananjayZMISR21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Pi-Radio v1 software-defined radio (SDR) platform incorporates a 4-channel fully-digital transceiver board that operates in the 57–64 GHz band and connects to the powerful Xilinx RFSoC-based ZCU111 evaluation board. This paper illustrates various calibration procedures that have been implemented to avoid relying on expensive laboratory equipment and infrastructure like spectrum analyzers, signal generators, or even anechoic chambers. We conclude this paper with a demonstration of beamforming enabled through geometrically determined beamforming weights, thereby demonstrating that the SDR nodes have been calibrated correctly.}
}


@article{DBLP:journals/cn/BayazeedKA21,
	author = {Adnan Bayazeed and
                  Khaldoun Khorzom and
                  Mohamad Aljnidi},
	title = {A survey of self-coordination in self-organizing network},
	journal = {Comput. Networks},
	volume = {196},
	pages = {108222},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108222},
	doi = {10.1016/J.COMNET.2021.108222},
	timestamp = {Thu, 19 Aug 2021 09:13:39 +0200},
	biburl = {https://dblp.org/rec/journals/cn/BayazeedKA21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Self-organizing network (SON) is a well-known approach to reduce the complexity and the cost of cellular network management. It aims at replacing the manual configuration and optimization with the functionalities of self-configuration, self-optimization and self-healing. Due to the important role of SON, the problem of conflicts between SON functions has been seriously considered over the last decade. In order to resolve this problem, 3GPP has introduced the functionality of self-coordination which is responsible for conflict avoidance and resolution. However, the conflict-free execution of SON functions remains a challenge as it requires the coordination mechanisms to address all potential interactions between SON functionalities, anticipate their impact on the network and evaluate their execution results. Self-coordination in SON is therefore considered as an open research field since it directly affects the performance of SON functionalities and as a result affects the network stability. In this paper, we provide a survey of SON conflicts and self-coordination methodologies that can be used for conflicts avoidance and resolution, and review the recent solutions to state-of-the-art, including papers in this research area. Finally, we point out major challenges and research issues to be addressed in the future.}
}


@article{DBLP:journals/cn/WangTSS21,
	author = {Dongsheng Wang and
                  Prayag Tiwari and
                  Mohammad Shorfuzzaman and
                  Ingo Schmitt},
	title = {Deep neural learning on weighted datasets utilizing label disagreement
                  from crowdsourcing},
	journal = {Comput. Networks},
	volume = {196},
	pages = {108227},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108227},
	doi = {10.1016/J.COMNET.2021.108227},
	timestamp = {Sun, 19 Jan 2025 14:22:21 +0100},
	biburl = {https://dblp.org/rec/journals/cn/WangTSS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Experts and crowds can work together to generate high-quality datasets, but such collaboration is limited to a large-scale pool of data. In other words, training on a large-scale dataset depends more on crowdsourced datasets with aggregated labels than expert intensively checked labels. However, the limited amount of high-quality dataset can be used as an objective test dataset to build a connection between disagreement and aggregated labels. In this paper, we claim that the disagreement behind an aggregated label indicates more semantics (e.g. ambiguity or difficulty) of an instance than just spam or error assessment. We attempt to take advantage of the informativeness of disagreement to assist learning neural networks by computing a series of disagreement measurements and incorporating disagreement with distinct mechanisms. Experiments on two datasets demonstrate that the consideration of disagreement, treating training instances differently, can promisingly result in improved performance.}
}


@article{DBLP:journals/cn/PaguadaBA21,
	author = {Servio Paguada and
                  Lejla Batina and
                  Igor Armendariz},
	title = {Toward practical autoencoder-based side-channel analysis evaluations},
	journal = {Comput. Networks},
	volume = {196},
	pages = {108230},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108230},
	doi = {10.1016/J.COMNET.2021.108230},
	timestamp = {Wed, 01 Sep 2021 12:45:13 +0200},
	biburl = {https://dblp.org/rec/journals/cn/PaguadaBA21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the field of side-channel analysis, profiled attacks are one of the most powerful types of attacks. Nevertheless, major issues with profiled attacks are in sensitivity to noise and the high-dimensional nature of the signals used for training, generating a less efficient classifier to conduct the attack phase. Consequently, evaluating the security of cryptographic implementation in hardware devices like IoT becomes more complex as side-channel analysis evaluation easily falls into false-positive results. This paper assesses the efficacy of applying a feature reduction process to deal with high-dimensional signals. We propose a practical procedure to conduct feature reduction using autoencoders for profiled side-channel leakage evaluations. Two autoencoder architectures are compared while performing feature reduction showing that our proposed architecture keeps most of the relevant information. Our proposal is tested on the ASCAD random key database with a high desynchronization value and produced results that outperform other state-of-the-art techniques. The guessing entropy value converges to 1 after around 500 leakage traces.}
}


@article{DBLP:journals/cn/NayakPB21,
	author = {Sabuzima Nayak and
                  Ripon Patgiri and
                  Angana Borah},
	title = {A survey on the roles of Bloom Filter in implementation of the Named
                  Data Networking},
	journal = {Comput. Networks},
	volume = {196},
	pages = {108232},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108232},
	doi = {10.1016/J.COMNET.2021.108232},
	timestamp = {Thu, 14 Oct 2021 09:09:04 +0200},
	biburl = {https://dblp.org/rec/journals/cn/NayakPB21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Today is the era of smart devices. Through smart devices, people remain connected with each other across the globe. But, it led the current Internet towards scalability issues. Therefore, leaving IP-based Internet behind, the world is moving to the Future Internet Architecture, called Named Data Networking (NDN). Currently, the number of nodes connected to the Internet is in the billions. Coupled with, the number of requests sent is in millions per second. NDN handles such huge numbers by modifying the existing IP architecture to meet the current requirements. NDN is scalable, generates less traffic, saves bandwidth, efficiently utilizes multiple network interfaces, provides high-level security, etc., which are essential for current communication technology. Correspondingly, Bloom Filter is a simple data structure capable of enhancing the performance of NDN. It is a probabilistic data structure for the membership query. Bloom Filter is deployed in various modules of NDN to handle the enormous number of packets. This article presents a detailed discussion on the role of Bloom Filter in implementing NDN. Moreover, the article includes a detailed discussion about Bloom Filter and the NDN architecture’s main components: Packet, Content Store, Forwarding Information Base, and Pending Interest Table. The article also provides many tables to increase the understanding of the topics.}
}


@article{DBLP:journals/cn/PaulGSCM21,
	author = {Rourab Paul and
                  Nimisha Ghosh and
                  Suman Sau and
                  Amlan Chakrabarti and
                  Prasant Mohapatra},
	title = {Blockchain based secure smart city architecture using low resource
                  IoTs},
	journal = {Comput. Networks},
	volume = {196},
	pages = {108234},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108234},
	doi = {10.1016/J.COMNET.2021.108234},
	timestamp = {Mon, 05 Feb 2024 20:24:11 +0100},
	biburl = {https://dblp.org/rec/journals/cn/PaulGSCM21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Internet of Things (IoT) is growing exponentially in research and industry. Although, many standard and conventional security solutions have been provided for IoT, it suffers from many privacy and security concerns. Standard security protocols are not suitable for majority of IoT devices because of its decentralized topology and resource-constraints. Blockchain (BC) finds its efficient application in IoT to preserve the five basic cryptographic primitives, such as confidentiality, authenticity, integrity, availability and non-repudiation. Adoption of conventional BC in IoT causes high energy consumption, delay and computational overheads which are not appropriate for various resource constrained IoT devices. To mitigate these problems, this work proposes a smart access control framework in a public and a private BC for a smart city application which makes it more efficient and secure as compared to the existing IoT applications. The proposed IoT based smart city architecture adopts BC technology for preserving all the cryptographic security and privacy issues. Moreover, proposed BC has minimal overhead as well. This work investigates the existing threat models and critical access control issues which handle multiple permissions of various processing nodes of IoT environment and detects relevant inconsistencies. Comparison in terms of all security issues with existing literature shows that the proposed architecture is competitively efficient in terms of security access control. The primary goal of this research article is to explore the possibility of BC as an alternative to standard security solutions for low resource IoT applications.}
}


@article{DBLP:journals/cn/SunZL21,
	author = {Rong Sun and
                  Huihui Zheng and
                  Jingwei Liu},
	title = {Coded caching design for fog-aided networks},
	journal = {Comput. Networks},
	volume = {196},
	pages = {108237},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108237},
	doi = {10.1016/J.COMNET.2021.108237},
	timestamp = {Sat, 30 Sep 2023 10:07:05 +0200},
	biburl = {https://dblp.org/rec/journals/cn/SunZL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Coded caching for fog-aided networks is an inspiring technology in the next-generation wireless networks. We study the cache placement and delivery problems for fog networks which can be considered as the two-hop networks. A novel centralized caching scheme and a novel decentralized caching scheme are proposed for two-hop networks of one server, multiple relays and users. Based on the file splitting method and the maximum distance separable (MDS) codes, the coded placement and delivery procedures for two-hop networks are designed. Numerical evaluations show that the proposed schemes can decrease the transmission load and alleviate network congestion. The impact of the cache memories to the transmission time for the parallel delivery and successive delivery is analyzed in detail. We prove that the centralized scheme always outperforms the decentralized scheme for both the parallel delivery and the successive delivery. The parallel delivery is much more effective than successive delivery for centralized as well as decentralized caching schemes considering the delivery latency. With the increase in memories of relays and users, the transmission load decreases gradually. Moreover, when the total memory of the user and its connected relays is able to store the file library, there is no need for the server in the delivery phase.}
}


@article{DBLP:journals/cn/BruschiPTBB21,
	author = {Valerio Bruschi and
                  Salvatore Pontarelli and
                  Jerome Tollet and
                  David Barach and
                  Giuseppe Bianchi},
	title = {FlowFight: High performance-low memory top-k spreader detection},
	journal = {Comput. Networks},
	volume = {196},
	pages = {108239},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108239},
	doi = {10.1016/J.COMNET.2021.108239},
	timestamp = {Wed, 01 Sep 2021 12:45:12 +0200},
	biburl = {https://dblp.org/rec/journals/cn/BruschiPTBB21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A recurring task in security monitoring/anomaly detection applications consists in finding the so-called top “spreaders” (“scanners”), for instance hosts which connect to a large number of distinct destinations or hit different ports. Estimating the top\nk\nscanners, and their cardinality, using the least amount of memory meanwhile running at multi-Gbps speed, is a non trivial task, as it requires to “remember” the destinations or ports already contacted in the past by each specific host. This paper proposes and assesses an innovative design, called FlowFight. As the name implies, our approach revolves on the idea of deploying a relatively small number of per-flow HyperLogLog approximate counters — only slightly superior to the target\nk\n— and involve the potentially huge number of concurrent flows in a sort of dynamic randomized “competition” for entering such set. The algorithm has been tested and integrated in a full-fledged software router such as Vector Packet Processor. Using either synthetic or real traffic traces, we show that FlowFight is able to estimate the top-\nk\ncardinality flows with an accuracy of more than 95%, while retaining a processing throughput of around 8 Mpps on a single core. We further show that FlowFight achieves same accuracy of the state of the art competitor SpreadSketch using 10x times less memory with 1.2x times higher throughput.}
}


@article{DBLP:journals/cn/BeheraD21,
	author = {Sadananda Behera and
                  Goutam Das},
	title = {Penalty-method based impairment-aware performance of Elastic Optical
                  Networks with spectrum conversion},
	journal = {Comput. Networks},
	volume = {196},
	pages = {108240},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108240},
	doi = {10.1016/J.COMNET.2021.108240},
	timestamp = {Wed, 04 Dec 2024 07:33:31 +0100},
	biburl = {https://dblp.org/rec/journals/cn/BeheraD21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In Elastic Optical Networks (EONs), fragmentation is a major bottleneck which affects the spectral efficiency significantly. Many defragmentation techniques have been proposed to tackle this issue and often, these schemes involve complex operations at the controllers and various sophisticated devices. Moreover, the amount of defragmentation achieved is also limited. In this regard, recently, spectrum conversion is gaining attention as a potential solution for the fragmentation issue in EONs. On the other hand, physical-layer impairments such as non-linear interference, amplified spontaneous emission (ASE) noise, beat noises due to coherent detection, etc. aggravate the fragmentation issue significantly. In this paper, we propose a novel impairment-aware routing and spectrum allocation (RSA) scheme with allowable spectrum conversion at intermediate nodes. We also propose a novel node architecture involving spectrum conversion with full switching flexibility. We first formulate a mixed integer linear program (MILP) optimization framework based on the proposed architecture in presence of impairments for a sample network and propose a penalty-method-based heuristic algorithm for realistic networks. Within our optimization framework, we ensure that a minimum end-to-end bit error rate (BER) for each demand is provisioned.}
}


@article{DBLP:journals/cn/AghaeiTKK21,
	author = {Abdollah Aghaei and
                  Javad Akbari Torkestani and
                  Hamidreza R. Kermajani and
                  Abbas Karimi},
	title = {LA-Trickle: {A} novel algorithm to reduce the convergence time of
                  the wireless sensor networks},
	journal = {Comput. Networks},
	volume = {196},
	pages = {108241},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108241},
	doi = {10.1016/J.COMNET.2021.108241},
	timestamp = {Mon, 30 Dec 2024 20:28:00 +0100},
	biburl = {https://dblp.org/rec/journals/cn/AghaeiTKK21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Wireless sensor networks (WSNs) are very important to realize the Internet of Things by connecting physical objects to the Internet. RPL (Routing Protocol for Low Power and Lossy Networks) has been provided by the IETF (Internet Engineering Task Force) for routing on wireless sensor networks. RPL uses the Trickle algorithm to schedule the transmission of control messages. The environment of WSNs is often highly variable and the environmental conditions for nodes are different. If network nodes are equipped with a learning automaton, network convergence time can be reduced. The use of learning automata allows each network node to adjust its parameters to environmental conditions by receiving environmental feedback to perform better. The main aim of this article is to reduce the network convergence time. We equipped the Trickle algorithm with a learning automaton, which determines how many times the algorithm is repeated with the minimum interval to resolve the inconsistency, based on environmental conditions. Since repeating the Trickle algorithm with the minimum interval increases the local repair speed and reduces the network convergence time. We simulated a large number of networks of different sizes and densities. According to the simulation results, we observed that in the proposed method, the network convergence time was reduced compared with the other methods. Also, due to fewer changes in network topology, energy consumption for network reconstruction was reduced.}
}


@article{DBLP:journals/cn/AchroufeneCB21,
	author = {Achour Achroufene and
                  Mourad Chelik and
                  Nassima Bouadem},
	title = {Modified {CSMA/CA} protocol for real-time data fusion applications
                  based on clustered {WSN}},
	journal = {Comput. Networks},
	volume = {196},
	pages = {108243},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108243},
	doi = {10.1016/J.COMNET.2021.108243},
	timestamp = {Wed, 01 Sep 2021 12:45:12 +0200},
	biburl = {https://dblp.org/rec/journals/cn/AchroufeneCB21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The large amount of data generated by the Internet of Things (IoT) is exploited by the data fusion process to improve the quality of services (QoS) requested by the user. Data fusion systems typically collect and fuse data from various sensor nodes to achieve better data quality (more precision, accuracy, or global view) on the field of interest. For the specific case of the wireless sensor network (WSN) based on cluster-tree topology, the data transmission between nodes and the intermediate data fusion node (DFN) depends primarily on the channel access often managed by the Carrier-Sens Multiple Access with Collision Avoidance (CSMA/CA) protocol. In this article, a modified CSMA/CA is proposed to meet the requirements of the WSN real-time data fusion applications and, in particular, to ensure better management of the transmission channel. It takes into account a transmission time-delay, schedules the retransmission dynamically, and eliminates data packets scheduled beyond the predefined time-delay, thereby releasing the channel to the benefit of other nodes. Moreover, before proceeding with the fusion at the DFN level, it optimizes the probability of receiving data from each node in the specified time-delay. The proposed solution is implemented under the Contiki operating system; it aims to collect data from all nodes within a given time-delay. The results of simulations and experiments show increasing in the data received within time-delay, collisions reduction, and saving energy in the WSN. Moreover, two real-time data fusion applications, namely mobile localization and majority decision-making, are also simulated to support the found results. Compared to the use of CSMA/CA as implemented in Contiki, using the proposed modified CSMA/CA in both data fusion applications improves QoS.}
}


@article{DBLP:journals/cn/GaurKGBGL21,
	author = {Kuntal Gaur and
                  Anshuman Kalla and
                  Jyoti Grover and
                  Mohammad Borhani and
                  Andrei V. Gurtov and
                  Madhusanka Liyanage},
	title = {A Survey of Virtual Private {LAN} Services {(VPLS):} Past, Present
                  and Future},
	journal = {Comput. Networks},
	volume = {196},
	pages = {108245},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108245},
	doi = {10.1016/J.COMNET.2021.108245},
	timestamp = {Thu, 23 Sep 2021 11:46:00 +0200},
	biburl = {https://dblp.org/rec/journals/cn/GaurKGBGL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Virtual Private LAN services (VPLS) is a Layer 2 Virtual Private Network (L2VPN) service that has gained immense popularity due to a number of its features, such as protocol independence, multipoint-to-multipoint mesh connectivity, robust security, low operational cost (in terms of optimal resource utilization), and high scalability. In addition to the traditional VPLS architectures, novel VPLS solutions have been designed leveraging new emerging paradigms, such as Software Defined Networking (SDN) and Network Function Virtualization (NFV), to keep up with the increasing demand. These emerging solutions help in enhancing scalability, strengthening security, and optimizing resource utilization. This paper aims to conduct an in-depth survey of various VPLS architectures and highlight different characteristics through insightful comparisons. Moreover, the article discusses numerous technical aspects such as security, scalability, compatibility, tunnel management, operational issues, and complexity, along with the lessons learned. Finally, the paper outlines future research directions related to VPLS. To the best of our knowledge, this paper is the first to furnish a detailed survey of VPLS.}
}


@article{DBLP:journals/cn/TsengCH21,
	author = {Yuh{-}Min Tseng and
                  Jian{-}Lun Chen and
                  Sen{-}Shan Huang},
	title = {A Lightweight Leakage-Resilient Identity-Based Mutual Authentication
                  and Key Exchange Protocol for Resource-limited Devices},
	journal = {Comput. Networks},
	volume = {196},
	pages = {108246},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108246},
	doi = {10.1016/J.COMNET.2021.108246},
	timestamp = {Thu, 19 Aug 2021 09:13:39 +0200},
	biburl = {https://dblp.org/rec/journals/cn/TsengCH21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Identity (ID)-based mutual authentication and key exchange (IDMAKE) protocol for client-server environments is a critical cryptographic primitive. Recently, several leakage-resilient IDMAKE (LR-IDMAKE) protocols have been proposed to withstand a new type of attacks, named side-channel attacks. However, the existing LR-IDMAKE protocols have several drawbacks, especially, the performance problem for low-power clients. In this paper, a lightweight LR-IDMAKE protocol well-suited for resource-limited devices is proposed. As compared with the previously proposed LR-IDMAKE protocols, our protocol has the following merits: (1) It is the first lightweight LR-IDMAKE protocol without on-line pairing operation for clients; (2) During life cycle of the proposed protocol, it is resilient to continuous key leakage and has totally unbounded leakage property; (3) Security analysis is formally made to demonstrate that it is strongly secure against adversaries in the continuous-leakage extended-Canetti–Krawczyk (CLeCK) model. Eventually, performance experiences on an IoT device with low-computing power, i.e., the Raspberry PI, are conducted to demonstrate that our protocol is well-suited for resource-limited devices.}
}


@article{DBLP:journals/cn/ZhangDFD21,
	author = {Bibo Zhang and
                  Francesco Devoti and
                  Ilario Filippini and
                  Danilo De Donno},
	title = {Resource allocation in mmWave 5G {IAB} networks: {A} reinforcement
                  learning approach based on column generation},
	journal = {Comput. Networks},
	volume = {196},
	pages = {108248},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108248},
	doi = {10.1016/J.COMNET.2021.108248},
	timestamp = {Wed, 01 Sep 2021 12:45:12 +0200},
	biburl = {https://dblp.org/rec/journals/cn/ZhangDFD21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Millimeter wave (mmWave) communications have been introduced in the 5G standardization process due to their attractive potential to provide a huge capacity extension to traditional sub-6 GHz technologies. However, such high-frequency communications are characterized by harsh propagation conditions, thus requiring base stations to be densely deployed. Integrated access and backhaul (IAB) network architecture proposed by 3GPP is gaining momentum as the most promising and cost-effective solution to this need of network densification.}
}


@article{DBLP:journals/cn/ChenLCJM21,
	author = {Xin Chen and
                  Xu Liu and
                  Ying Chen and
                  Libo Jiao and
                  Geyong Min},
	title = {Deep Q-Network based resource allocation for UAV-assisted Ultra-Dense
                  Networks},
	journal = {Comput. Networks},
	volume = {196},
	pages = {108249},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108249},
	doi = {10.1016/J.COMNET.2021.108249},
	timestamp = {Wed, 08 Mar 2023 13:04:19 +0100},
	biburl = {https://dblp.org/rec/journals/cn/ChenLCJM21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the rapid development of the fifth-generation (5G) wireless communications, the number of users is increasing dramatically and Ultra-Dense Networks (UDN) are becoming more important for supporting numerous users and emerging mission-critical applications. In order to conquer the communication restrictions caused by natural disasters, an emergency communication system using Unmanned Aerial Vehicles (UAV) as a flying base station (BS) to assist UDN is proposed. By virtue of the resource allocation scheme of UAV-assisted UDN systems, communication resources can be reasonably and effectively allocated to improve the quality of user experience. Firstly, aiming to maximize the system energy efficiency (EE), a UDN system model including the BS selection is constructed. Secondly, Markov Decision Process (MDP) theory is applied to transform the system model into a stochastic optimization problem. Finally, by using deep reinforcement learning (DRL) technique, we propose a Deep Q-Network (DQN) based resource allocation scheme to maximize the system energy efficiency. Simulation results exhibit that the proposed DQN-based resource allocation scheme can significantly improve the system EE compared with the legacy Q-Learning, random and maximum resource allocation algorithms.}
}


@article{DBLP:journals/cn/ZambiancoV21,
	author = {Marco Zambianco and
                  Giacomo Verticale},
	title = {Intelligent multi-branch allocation of spectrum slices for inter-numerology
                  interference minimization},
	journal = {Comput. Networks},
	volume = {196},
	pages = {108254},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108254},
	doi = {10.1016/J.COMNET.2021.108254},
	timestamp = {Wed, 01 Sep 2021 12:45:13 +0200},
	biburl = {https://dblp.org/rec/journals/cn/ZambiancoV21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Network slicing and mixed-numerology access schemes cover a central role to enable the flexible multi-service connectivity that characterizes 5G radio access networks (RAN). However, the interference generated by the simultaneous multiplexing of radio slices having heterogeneous subcarrier spacing can hinder the isolation of the different slices sharing the RAN and their effectiveness in meeting the application requirements. To overcome these issues, we design a radio resource allocation scheme that accounts for the inter-numerology interference and maximizes the aggregate network throughput. To overcome the computationally complexity of the optimal formulation, we leverage deep reinforcement learning (DRL) to design an agent capable of approximating the optimal solution exploiting a model-free environment formulation. We propose a multi-branch agent architecture, based on Branching Dueling Q-networks (BDQ), which ensures the agent scalability as the number of spectrum resources and network slices increases. In addition, we augment the agent learning performance by including an action mapping procedure designed to enforce the selection of feasible actions. We compare the agent performance to several benchmarks schemes. Results show that the proposed solution provides a good approximation of the optimal allocation in most scenarios.}
}


@article{DBLP:journals/cn/Uddin21,
	author = {Md. Forkan Uddin},
	title = {Downlink performance analysis of a {CSMA} based {WLAN} under physical
                  interference model},
	journal = {Comput. Networks},
	volume = {196},
	pages = {108255},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108255},
	doi = {10.1016/J.COMNET.2021.108255},
	timestamp = {Wed, 01 Sep 2021 12:45:12 +0200},
	biburl = {https://dblp.org/rec/journals/cn/Uddin21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A significant amount of research work has been done on throughput and energy efficiency analysis of IEEE 802.11 based wireless local area networks (WLANs) under the simplistic protocol interference model. However, very little work has been done on analytical modelling and analysing the downlink throughput and energy efficiency of WLANs under the realistic physical interference model. In this paper, we study the downlink throughput and energy efficiency of a carrier sense multiple access (CSMA) based WLAN under the physical interference model in presence of path loss, Rayleigh fading and log-normal shadowing. For this purpose, we develop analytical models to compute the downlink throughput and energy efficiency of a CSMA based WLAN under a saturation traffic condition. We then validate the analytical models via simulation. By computing throughput and energy efficiency with the developed analytical models, we demonstrate that the downlink throughput and energy efficiency obtained by the physical interference model significantly differ from those are obtained by the widely used protocol interference model. We also find that, in a CSMA MAC protocol based WLAN, RTS/CTS channel access mode provides significant benefits over the basic channel access mode in increasing downlink throughput and energy efficiency. Further, we study the effect of node transmit power, data transmission rate, data packet size, and channel access rate of the access point (AP) and the users on throughput and energy efficiency performance of WLANs and provide various engineering insights on WLAN downlink performance and better configurations of WLAN parameters.}
}


@article{DBLP:journals/cn/WanXXA21,
	author = {Zhilan Wan and
                  Ding Xu and
                  Dahu Xu and
                  Ishtiaq Ahmad},
	title = {Joint computation offloading and resource allocation for NOMA-based
                  multi-access mobile edge computing systems},
	journal = {Comput. Networks},
	volume = {196},
	pages = {108256},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108256},
	doi = {10.1016/J.COMNET.2021.108256},
	timestamp = {Mon, 30 Jan 2023 21:00:58 +0100},
	biburl = {https://dblp.org/rec/journals/cn/WanXXA21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Due to explosive growth of computation-intensive applications, multi-access mobile edge computing (MEC) has been proposed as an efficient technology to relieve the burden on mobile users by offloading computation tasks to MEC servers. Meanwhile, nonorthogonal multiple access (NOMA) has been proposed to improve spectrum efficiency by allowing multiple users transmitting on the same time and spectrum resource. Thus, NOMA can be naturally adopted by the MEC systems to improve the offloading performance. In this paper, we consider a NOMA-based multi-access MEC system with multiple MEC servers and multiple users. It is assumed that each user has multiple computation tasks, where each task shall be offloaded to one MEC server for computing. NOMA is applied for uploading multiple tasks to MEC servers as well as downloading multiple task results. The problem of jointly optimizing the MEC server allocation, the transmit power allocation of the users, the transmit power allocation of the MEC servers, the computation resource allocation of the MEC servers, the time allocation and the channel allocation, for minimizing the overall delay of all tasks is investigated. We then propose a heuristic algorithm to solve the problem, where the computation resource allocation of the MEC servers and the time allocation are optimized by the bisection search method, the transmit power allocations are obtained in closed-form, and the MEC server allocation and the channel allocation are optimized by the swap matching algorithm. Extensive simulations demonstrate that the proposed algorithm significantly outperforms various benchmark algorithms.}
}


@article{DBLP:journals/cn/AurizziRRFC21,
	author = {Matteo Maria Aurizzi and
                  Tommaso Rossi and
                  Emanuele Raso and
                  Ludovico Funari and
                  Ernestina Cianca},
	title = {An SDN-based traffic handover control procedure and {SGD} management
                  logic for {EHF} satellite networks},
	journal = {Comput. Networks},
	volume = {196},
	pages = {108260},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108260},
	doi = {10.1016/J.COMNET.2021.108260},
	timestamp = {Wed, 01 Sep 2021 12:45:13 +0200},
	biburl = {https://dblp.org/rec/journals/cn/AurizziRRFC21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Smart Gateway Diversity (SGD) is a fundamental concept introduced to maintain high service availability in High Throughput Satellites (HTS) working at frequency bands above Ka-band. This paper proposes a novel approach for the SGD management logic that takes into account the “graceful degradation” of the link for triggering a handover of traffic among gateways (GWs.) Moreover, the paper proposes a Software Defined Network (SDN) implementation of the handover control procedure and an algorithm for building the flows matrices of the SDN switches that guarantees a fair balancing of traffic among the gateways, thus allowing a better exploitation of resources and maximization of the overall operational capacity of the HTS system. The SDN paradigm, by allowing efficient network programmability and real time re-configuration of the flow tables, enables the possibility to implement dynamic and granular resource allocation; this is a fundamental requirement for the proposed novel SGD network management approach, where re-configuration is triggered by smaller and more frequent signal-to-noise ratio (SNR) fluctuations. The performance of the proposed handover control procedures have been evaluated over real Q/V band link by using the experimental data collected through the TDP5 “Aldo Paraboni” payload embarked on the Alphasat satellite. Performance results show a gain of 40% in terms of aggregated capacity of the system with respect to the case of using an on–off SGD management logic.}
}


@article{DBLP:journals/cn/TangLLSWQ21,
	author = {Yutao Tang and
                  Yue Li and
                  Qun Li and
                  Kun Sun and
                  Haining Wang and
                  Zhengrui Qin},
	title = {User input enrichment via sensing devices},
	journal = {Comput. Networks},
	volume = {196},
	pages = {108262},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108262},
	doi = {10.1016/J.COMNET.2021.108262},
	timestamp = {Tue, 18 Jun 2024 20:16:46 +0200},
	biburl = {https://dblp.org/rec/journals/cn/TangLLSWQ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Nowadays a user may have many electronic devices. However, these devices suffer from different resource and usage constraints. On one hand, mobile devices, such as smartphones, have short battery life, limited computing power, and small-sized display. On the other hand, more powerful devices such as desktops or smart TVs are bulky and lack motion-related input data. In this paper, we aim to integrate these two types of devices into one computing platform when both devices are accessible to a user, in which their individual advantages are combined for users’ convenience. To this end, we develop a new user-centric paradigm on computing systems, called Application Execution with Sensing Input (AESIP), which can transparently inject sensing data to a powerful yet stationary device using an auxiliary mobile device. Not requiring any modification on the mobile device’s OS and applications, AESIP supports all mobile-specific input data sources, such as touchscreen, gyroscope, and accelerometer. As one design goal of AESIP is to maximize the user’s Quality of Experience (QoE), we tackle several usability challenges and enable richer functionality. We implement a prototype of AESIP on a Nexus 5, a Raspberry Pi and a desktop machine. Our performance evaluation shows that AESIP induces little latency and negligible bandwidth usage, and it significantly increases the battery life of a mobile device. We further conduct a user study to evaluate the usability of AESIP.}
}


@article{DBLP:journals/cn/TouatiCSK21,
	author = {Haifa Touati and
                  Amira Chriki and
                  Hichem Snoussi and
                  Farouk Kamoun},
	title = {Cognitive Radio and Dynamic {TDMA} for efficient UAVs swarm communications},
	journal = {Comput. Networks},
	volume = {196},
	pages = {108264},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108264},
	doi = {10.1016/J.COMNET.2021.108264},
	timestamp = {Wed, 01 Sep 2021 12:45:12 +0200},
	biburl = {https://dblp.org/rec/journals/cn/TouatiCSK21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the last decades, under technological progress in electronic and avionics systems, Unmanned Aerial Vehicles (UAVs) have known an increasing use in several military and civilian missions. Multiple UAVs can cooperatively carry out dangerous applications for human operators or missions where human intervention is not needed, such as surveillance and monitoring of areas of interest and physical infrastructures. Due to the lack of proper communication rules and standards, communication remains one of the most crucial design issues for UAVs swarm. Furthermore, UAVs generally operate in frequency bands shared with other users. Hence, these spectral bands become overcrowded and UAVs may face a spectrum scarcity issue. To address the above challenges, it is essential to define a reliable communication architecture for multiple UAVs coordination and efficient bandwidth sharing. A promising technology that can satisfy the spectrum requirements of the emerging UAVs Networks is Cognitive Radio Network (CRN). The goal is to opportunistically use spectral bands with minimum interference to other users or applications, i.e., primary users. In this paper, we consider the problem of spectrum scarcity encountered by UAVs. We present a centralized CRN-based communication approach for UAVs-Ground Control Station (GCS) communication. The GCS is used as a central coordinator to handle bandwidth usage for the UAVs swarm in its coverage zone. It selects, allocates, and shares available frequencies using CRN and Software Defined Radio (SDR). To share the available CRN-frequency between the different UAVs in its scope, the GCS uses dynamic Time Division Multiple Access (TDMA) technique. The performance of the proposed communication approach is evaluated in a surveillance context in terms of the total time required to transfer UAVs data, the total number of packets sent, and the achieved throughput.}
}


@article{DBLP:journals/cn/XieLJ21,
	author = {Guorui Xie and
                  Qing Li and
                  Yong Jiang},
	title = {Self-attentive deep learning method for online traffic classification
                  and its interpretability},
	journal = {Comput. Networks},
	volume = {196},
	pages = {108267},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108267},
	doi = {10.1016/J.COMNET.2021.108267},
	timestamp = {Wed, 01 Sep 2021 12:45:13 +0200},
	biburl = {https://dblp.org/rec/journals/cn/XieLJ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Traffic classification is one of the fundamental tasks in computer networking. This task aims to associate network traffic to a specific class according to the requirements (e.g., QoS provisioning). Online classification, which refers to the situations where flows need to be classified in real time, is an essential technique for this topic. In recent academic research, traffic classification methods based on machine learning (ML) or deep learning (DL) have been proposed. However, most of these methods take flow-level data as input, which requires observing the entire or large portion of a flow and violates the restrictions of online classification. Furthermore, the DL-based methods scarcely discuss the interpretability (e.g., which features are learned by DL, where is the discrimination power from). The lack of interpretability makes people question their reliability and may hinder their further applications. In this paper, we propose a self-attentive method (SAM) for traffic classification. We properly design a neural network whose input can be more fine-grained (i.e., packet-level). This neural network outputs classification results (\n∼\n2\nm\ns\nper packet) and consequently satisfies the requirements of online classification. Furthermore, a new technique called self-attention mechanism is utilized for interpretability exploration. By assigning attentive weights to different parts of the input, the self-attention mechanism allows us to understand how the DL model learns discriminative features from the input. According to experimental results, SAM outperforms the current state-of-the-art schemes, improving classification accuracy by\n∼\n8\n%\n(protocol classification),\n∼\n5\n%\n(application classification), and\n∼\n13\n%\n(traffic type classification). The code is available at https://github.com/xgr19/SAM-for-Traffic-Classification.}
}


@article{DBLP:journals/cn/KrishnamurthyKK21,
	author = {Prashanth Krishnamurthy and
                  Farshad Khorrami and
                  Rahul Kumar},
	title = {An approximate factorization approach to multi-jammer location and
                  range estimation from peer-to-peer connectivity measurements},
	journal = {Comput. Networks},
	volume = {196},
	pages = {108268},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108268},
	doi = {10.1016/J.COMNET.2021.108268},
	timestamp = {Mon, 28 Aug 2023 21:39:18 +0200},
	biburl = {https://dblp.org/rec/journals/cn/KrishnamurthyKK21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The localization (i.e., location and range) of communication jammers in an area of operation of mobile agents is considered. The jammers are operated by adversaries to disrupt/jam communications among mobile agents to degrade mission performance. In comparison with prior results, we address estimation of jammer locations and ranges based purely on observed time series of peer-to-peer agent communication connectivities and corresponding agent locations. Jamming effects and communication connectivity are characterized by stochastic models. The agents are not assumed to have any additional sensors to measure received signal strength or to have any visual or other perception to “see” jammers. The fundamental algorithmic challenge is the inherent empirical ambiguity as to which agent was jammed when a loss of communication is detected. For this purpose, we develop an algorithmic framework based on approximate factorization, spatial local density-based filtering, and maximum likelihood estimation. We show efficacy of the proposed approach through simulation studies with large numbers of mobile agents in multiple simulated scenarios.}
}


@article{DBLP:journals/cn/KianiK21,
	author = {Mohsen Kiani and
                  Mohammad Reza Khayyambashi},
	title = {A network-aware and power-efficient virtual machine placement scheme
                  in cloud datacenters based on chemical reaction optimization},
	journal = {Comput. Networks},
	volume = {196},
	pages = {108270},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108270},
	doi = {10.1016/J.COMNET.2021.108270},
	timestamp = {Thu, 24 Aug 2023 21:03:29 +0200},
	biburl = {https://dblp.org/rec/journals/cn/KianiK21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the present article, we propose a virtual machine placement (VMP) algorithm for reducing power consumption in heterogeneous cloud data centers. We propose a novel model for the estimation of power consumption of datacenter’s network. The proposed model is employed to estimate power consumption of a Fat-Tree network. It calculates the traffic of each network layer and uses the results to estimate the average power consumption of each switch in the network, which is used for network power calculation. Further, we employ the chemical reaction optimization (CRO) algorithm as a meta-heuristic algorithm to obtain a power-efficient mapping of virtual machines (VMs) to physical machines (PMs). Moreover, two kinds of solution encoding schemes, namely permutation-based and grouping-based encoding schemes, were utilized for representing individuals in CRO. For each encoding scheme, we designed proper operators required by the CRO for manipulating the molecules in search of more optimal solution candidates. Additionally, we modeled VMs with east–west and north–south communications, and PMs with constrained CPU, memory, and bandwidth capacity. Our network power model is integrated into the CRO algorithms to enable the estimation of both PMs and network power consumption. We compared our proposed methods with a number of similar methods. The evaluation results indicate that the proposed methods perform well and the CRO algorithm with the grouping-based encoding outperforms the rest of the methods in terms of power consumption. The evaluation results also show the significance of network power consumption.}
}
