@article{DBLP:journals/cn/FarquharKHJJ23,
	author = {Collin Farquhar and
                  Swatantra Kafle and
                  Kian Hamedani and
                  Anu Jagannath and
                  Jithin Jagannath},
	title = {Marconi-Rosenblatt Framework for Intelligent Networks (MR-iNet Gym):
                  For Rapid Design and Implementation of Distributed Multi-agent Reinforcement
                  Learning Solutions for Wireless Networks},
	journal = {Comput. Networks},
	volume = {222},
	pages = {109489},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2022.109489},
	doi = {10.1016/J.COMNET.2022.109489},
	timestamp = {Tue, 28 Mar 2023 19:51:08 +0200},
	biburl = {https://dblp.org/rec/journals/cn/FarquharKHJJ23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We present the Marconi-Rosenblatt Framework for Intelligent Networks (MR-iNet Gym) an open-source architecture designed for accelerating research and development of novel reinforcement learning applied to distributed wireless networks. To ensure an end-to-end architecture, we leverage the existing work of ns3-gym, a software package that allows for using ns-3, a wireless network simulator, as an environment within the OpenAI Gym framework for RL. In addition to this, we have implemented the first known custom CDMA module for ns-3 as well as a framework for RL models with a core suite of implemented algorithms. The software framework capturing the interaction between wireless transceiver (agent) and RL decision engine has been designed to maximize the ease-of-use when testing different RL algorithms and models. In the rest of the paper, we describe these new software components and demonstrate some of the results and capabilities that can be achieved when used in conjunction with the existing open-source ecosystem.}
}


@article{DBLP:journals/cn/LiuC23,
	author = {Xiuwen Liu and
                  Yanjiao Chen},
	title = {Group effect-based privacy-preserving data aggregation for mobile
                  crowdsensing},
	journal = {Comput. Networks},
	volume = {222},
	pages = {109507},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2022.109507},
	doi = {10.1016/J.COMNET.2022.109507},
	timestamp = {Tue, 21 Mar 2023 21:08:27 +0100},
	biburl = {https://dblp.org/rec/journals/cn/LiuC23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In mobile crowdsensing systems, the public crowd are required to report data with actual locations under location privacy vulnerabilities. Moreover, even sensing data itself further deepens location privacy breaches. Existing works allow each worker to consider his own privacy, but the accumulated privacy budget will lower down group data privacy of each sensing region. Moreover, multi-region spatial data correlations indicate that multi-group correlated data privacy may be leaked from each other. To this end, we develop a novel MCS framework, called GDA-Crowd(Group effect-based Data Aggregation), which consists of three parts: location obfuscation and aggregation, group effect-based data privacy and aggregation, and incentive mechanism. We start from individual location privacy guarantee and propose a location aggregation method to cluster workers into groups. Then, we exploit intra-group effect, i.e., data privacy interdependence under the judicious selection of workers’ participation, to enhance privacy-accuracy balance. Moreover, multi-group global histogram incorporates inter-group effect, i.e., correlated privacy loss from spatial data correlations, into inter-group data aggregation. Finally, we design a truthful, individually rational and computationally efficient incentive mechanism for participant selection. The synopsis of contributions includes dual privacy protection, dual group effect for desirable privacy-accuracy tradeoff, synergies among incentive mechanism, privacy-preserving data aggregation for approximate optimality. Theoretical analysis and extensive experiments validate our effectiveness and superiority.}
}


@article{DBLP:journals/cn/BenllochCaballeroWC23,
	author = {Pablo Benlloch{-}Caballero and
                  Qi Wang and
                  Jos{\'{e}} M. Alcaraz Calero},
	title = {Distributed dual-layer autonomous closed loops for self-protection
                  of 5G/6G IoT networks from distributed denial of service attacks},
	journal = {Comput. Networks},
	volume = {222},
	pages = {109526},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2022.109526},
	doi = {10.1016/J.COMNET.2022.109526},
	timestamp = {Wed, 24 Apr 2024 14:55:55 +0200},
	biburl = {https://dblp.org/rec/journals/cn/BenllochCaballeroWC23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Internet of Things (IoT) is a major application area of the Fifth-Generation (5G) and beyond capable of providing massive machine-type communications (mMTC) at a large scale. It enables a wide range of applications such as smart cities, smart grids, smart factories and so on. In light of the huge number of devices involved, it is prohibitive to manage the massive large-scale cyber security scenarios manually. Therefore, closed automation loops are essential to automate such management. This paper proposes a new cognitive closed loop system to offer distributed dual-layer self-protection capabilities to battle against Distributed Denial of Service (DDoS) attacks. The proposed system features the novel usage of concurrent autonomous closed-loops for the different stakeholders’ business roles: Digital Service Providers (DSPs) and Infrastructure Service Providers (ISPs) respectively, suitable to provide a multi-layer self-protection defence mechanisms across multiple administrative domains. It has been designed, implemented and experimentally validated. Empirical results have shown that there is a high potential in the collaboration between the stakeholders to achieve the common goal of self-protection of infrastructures. It makes a major difference in the performance of the whole infrastructure for detecting, analysing and mitigating the threat when the proposed distributed dual-layer loops are applied instead of a standalone loop. The system has achieved a 78.12% of effectiveness compared with a 4.73% of the standalone counterpart, for a large scale attack when stopping 256 infected devices. Also, the proposed system has achieved a response time of 18 s whereas the standalone has required 57 s, achieving an optimization of performance of 316%.}
}


@article{DBLP:journals/cn/ShashinBKK23,
	author = {Aleksei Shashin and
                  Andrey Belogaev and
                  Artem N. Krasilov and
                  Evgeny M. Khorov},
	title = {Adaptive parameters selection for uplink grant-free {URLLC} transmission
                  in 5G systems},
	journal = {Comput. Networks},
	volume = {222},
	pages = {109527},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2022.109527},
	doi = {10.1016/J.COMNET.2022.109527},
	timestamp = {Sat, 30 Sep 2023 10:07:04 +0200},
	biburl = {https://dblp.org/rec/journals/cn/ShashinBKK23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Ultra-Reliable Low-Latency Communications (URLLC) is a key service of 5G systems that imposes very strict Quality of Service (QoS) requirements. Typically, URLLC applications require successful delivery of at least 99.999% of packets with a packet delivery time below 1 ms. To satisfy these requirements for uplink URLLC traffic, 5G specifications introduce a grant-free channel access method. It allows a base station (gNB) to select transmission parameters for each User Equipment (UE) in advance. The algorithm for transmission parameters selection shall take into account the following factors: (i) various UEs may have significantly different channel conditions that can change with time; (ii) if several UEs share common channel resources, their transmissions can interfere with each other; (iii) the gNB can use sophisticated decoding mechanisms, such as Successive Interference Cancellation (SIC), to mitigate the interference problem. In contrast to the existing studies that take into account only some of these factors, this paper proposes an algorithm that considers all three factors and adaptively selects the transmission parameters for each UE based on the desired signal and interference measurements available at the gNB. Numerical results obtained with NS-3 show that the developed algorithm significantly increases the network capacity for both periodic and sporadic URLLC traffic compared with the state-of-the-art algorithms.}
}


@article{DBLP:journals/cn/XieJGJJC23,
	author = {Yi Xie and
                  Xianliang Jiang and
                  Guanghui Gong and
                  Ziyi Jiang and
                  Guang Jin and
                  Haiming Chen},
	title = {Yinker: {A} flexible {BBR} to achieve the high-throughput and low-latency
                  data transmission over Wi-Fi and 5G networks},
	journal = {Comput. Networks},
	volume = {222},
	pages = {109530},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2022.109530},
	doi = {10.1016/J.COMNET.2022.109530},
	timestamp = {Fri, 17 Mar 2023 14:56:58 +0100},
	biburl = {https://dblp.org/rec/journals/cn/XieJGJJC23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The popularization and development of Wi-Fi and 5G networks have introduced new applications requiring high data rates and low latency. However, the vast random packet loss caused by mobility and channel conditions in wireless networks can worsen the performance of traditional TCP congestion control algorithms. Therein, BBR  [1] was proposed in 2016, and claims to operate at the optimum point. BBR strives to match the congestion window to the bandwidth-delay product, calculated from the measured bottleneck bandwidth and round trip times. Through simulations, we found that BBR suffers from different degrees of throughput degradation for different loss rates. The improved BBR, Yinker, is proposed to address this issue. Precisely, we dynamically adjust BBR’s pacing_gain based on the network conditions, including loss rate and congestion degree. We have evaluated Yinker in both real-world environments and trace-based emulations and compared its performance with different BBR variants and state-of-the-art schemes, including Cubic, Verus, and Copa. On average, TCP D*, BBR v2, Copa, and BBR have 4.24\n×\n, 2.34\n×\n, 2.01\n×\n, and 1.48\n×\nlower throughput compared to Yinker, respectively. This outstanding delay performance comes at little cost in latency. For instance, compared to TCP D* (which achieves the lowest latency), Yinker’s latency is only about 3% more.}
}


@article{DBLP:journals/cn/YuPTW23,
	author = {Mengxin Yu and
                  Yibo Pi and
                  Aimin Tang and
                  Xudong Wang},
	title = {Coordinated parallel resource allocation for integrated access and
                  backhaul networks},
	journal = {Comput. Networks},
	volume = {222},
	pages = {109533},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2022.109533},
	doi = {10.1016/J.COMNET.2022.109533},
	timestamp = {Tue, 28 Mar 2023 19:51:08 +0200},
	biburl = {https://dblp.org/rec/journals/cn/YuPTW23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The architecture of integrated access and backhaul (IAB) endows 5G and beyond networks with the capabilities of both centralized and distributed resource management: a centralized node, IAB-donor, can efficiently coordinate resources with a network-wide view, and other distributed nodes, IAB-nodes, can quickly react to local traffic bursts multiple hops away from the IAB-donor. However, existing efforts on IAB networking mostly focus on either the centralized or distributed capability of IAB networks and lack the studies on handling bursty traffic. In this paper, a Coordinated Parallel Resource allocation scheme (CPReal) is developed to handle both bursty and non-bursty traffic. Its key feature is that it consists of both a centralized scheme at the IAB-donor for efficient coordination of resource allocation and a distributed scheme at each IAB-node for quick response to short-term bursty traffic. CPReal is standard-compliant and considers the strict parent-to-child relation between IAB-nodes specified in 5G standards. In CPReal, with the assistance from their parent nodes, IAB-nodes can quickly reach an agreement on resource allocation in a distributed and conflict-free way for traffic bursts. Extensive simulations show that CPReal outperforms existing schemes in throughput by 67.3% under bursty traffic and in end-to-end delay by up to 34.4% under various scenarios.}
}


@article{DBLP:journals/cn/BakH23,
	author = {Charn{-}Doh Bak and
                  Seung{-}Jae Han},
	title = {Contention alleviation in WiFi networks by using light-weight machine
                  learning model},
	journal = {Comput. Networks},
	volume = {222},
	pages = {109534},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2022.109534},
	doi = {10.1016/J.COMNET.2022.109534},
	timestamp = {Fri, 17 Mar 2023 14:56:58 +0100},
	biburl = {https://dblp.org/rec/journals/cn/BakH23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The random access MAC (e.g., CSMA/CA) is known to be vulnerable to heavy collisions when the transmission contention level is high. Heavy collisions have typically been mitigated by adjusting the length of the waiting interval imposed before individual transmission attempts, called ’backoff time’. For example, there exist a large body of studies to enhance the efficiency of the WiFi backoff mechanism. In this paper, we propose a novel scheme that inserts a configurable non-random duration, called\no\nf\nf\ns\ne\nt\n, before the beginning of the conventional CSMA/CA backoff. Since the existing backoff mechanism is untouched, the proposed scheme is compatible with all legacy and future WiFi standards. The size of\no\nf\nf\ns\ne\nt\nis dynamically determined at run time by using a lightweight machine learning model. While machine learning models have been applied to the problem of contention alleviation in WiFi networks, the proposed scheme is unique in its flexibility and low overhead for model training and inferencing. Our scheme employs a simple lightweight DNN (Deep Neural Network) model which does not require a large amount of training data. The complexity of our machine learning model does not increase even if the number of the devices in the WiFi networks increases. Furthermore, the proposed scheme is executed in a distributed fashion, so that (near) real-time adaptation to dynamic change of traffic condition is possible at each end device that is not equipped with high computing resource (i.e., on-device DNN model execution).}
}


@article{DBLP:journals/cn/ZhouMTQDLLZL23,
	author = {Jianer Zhou and
                  Zengxie Ma and
                  Weijian Tu and
                  Xinyi Qiu and
                  Jingpu Duan and
                  Zhenyu Li and
                  Qing Li and
                  Xinyi Zhang and
                  Weichao Li},
	title = {Cable: {A} framework for accelerating 5G {UPF} based on eBPF},
	journal = {Comput. Networks},
	volume = {222},
	pages = {109535},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2022.109535},
	doi = {10.1016/J.COMNET.2022.109535},
	timestamp = {Wed, 31 Jul 2024 08:04:11 +0200},
	biburl = {https://dblp.org/rec/journals/cn/ZhouMTQDLLZL23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {An increasing number of 5G core network modules are being implemented in the X86 cloud environment. Improving the modules’ packet processing ability can accelerate the 5G data plane. EBPF is a promising way to reduce the packet processing consumption in the Linux kernel. In this paper, we propose Cable, a framework to accelerate the 5G data plane by using eBPF. Cable can not only reduce the packet processing time in a single UPF, but also schedule PDU sessions to suitable UPFs by the monitoring information. We implemented Cable in the open source 5G core project Free5GC and made it publicly available. Evaluation in a simulation environment shows that Cable can reduce packet processing time in a single UPF by over 30% and improve the whole system’s UPF usage by 25%.}
}


@article{DBLP:journals/cn/JhaPDKP23,
	author = {Rakesh Kumar Jha and
                  Mittal K. Pedhadiya and
                  Anutusha Dogra and
                  Haneet Kour and
                  Puja},
	title = {Joint resource and power allocation for 5G enabled {D2D} networking
                  with {NOMA}},
	journal = {Comput. Networks},
	volume = {222},
	pages = {109536},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2022.109536},
	doi = {10.1016/J.COMNET.2022.109536},
	timestamp = {Sat, 30 Sep 2023 10:07:03 +0200},
	biburl = {https://dblp.org/rec/journals/cn/JhaPDKP23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Paramount data transfer among users in social groups and concerts imposes enormous traffic at the base station (BS), depleting the available resources and forcing fifth-generation (5G) researchers to seek communion with alternative technologies. Non-Orthogonal Multiple Access (NOMA) is determined as a potential technology for supporting multiple users on the same sub-channels using power domain multiplexing. Integration of NOMA with a Device-to-Device (D2D) communication technology provides lower latency for supporting proximity communication. Significant research has been carried out till date in device pairing for resource allocation in NOMA and D2D. This paper proposes a joint resource and power allocation in the NOMA (JRPAN) algorithm for resource and power allocation to cellular and D2D users. Resources and power are adaptively assigned to the users depending upon the user's application. A proposal of group formation for resource reuse in NOMA with prioritized user application is established. The Simulations have been performed to ascertain the fair allocation of resources to the users in conformity to the application. The proposed algorithm helps in conserving power as compared to orthogonal frequency division multiplexing (OFDMA) with the Hidden Markov Model (HMM). The results demonstrate that JRPAN achieves higher system throughput and saves power while ensuring the requirement of Quality of Experience and Quality of service in comparison to OFDMA-HMM and proportional algorithm.}
}


@article{DBLP:journals/cn/LiMC23,
	author = {David Chunhu Li and
                  Muhamad Rizka Maulana and
                  Li{-}Der Chou},
	title = {NNSplit-S{\O}REN: Supporting the model implementation of large neural
                  networks in a programmable data plane},
	journal = {Comput. Networks},
	volume = {222},
	pages = {109537},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2022.109537},
	doi = {10.1016/J.COMNET.2022.109537},
	timestamp = {Tue, 28 Mar 2023 19:51:08 +0200},
	biburl = {https://dblp.org/rec/journals/cn/LiMC23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Embedding neural network (NN) models in the data plane is one of the very promising and attractive ways to leverage the computational power of computer network switches. This method became possible with the advent of the P4 language controlling the programmable data plane. However, most data planes today have some constraints, such as a limited set of operations and limited memory size. The computational cost of training large-scale NNs is high. In addition, while complex large-scale NN architectures are often used to improve prediction accuracy, they affect the functional performance of the data plane because of factors such as numerous input parameters and complex model design. Therefore, determining how to reduce the performance cost incurred by implementing large NN models in the data plane is a critical issue that needs to be addressed. This research proposes a technique called Neural Network Split (NNSplit) to solve the performance problems of embedding a large NN in a data plane by splitting the NN layers across multiple data planes. To support layer splitting, a new protocol called SuppORting ComplEx Computation in the Network (SØREN) is also proposed. The SØREN protocol header carries the activation value and bridges the NN layers in all switches. A multi-class classification use case of network traffic is used as the context for the experimental analysis. Experimental results show that compared to non-splitting NN architectures, NNSplit can reduce memory usage by nearly 50% and increase network traffic throughput with the cost of a 14% increase in round-trip time. In addition, when the SØREN protocol is encapsulated into data packets, the average processing time of the switch is 773 µs, which has very little impact on the processing time of the packets. Experimental results also show that the proposed NNSplit–SØREN can support large NN models on the data plane with a small performance cost.}
}


@article{DBLP:journals/cn/LiuDSF23,
	author = {Yongbo Liu and
                  Yongqiang Dong and
                  Jun Shen and
                  Chong Feng},
	title = {{MAYA:} Exploring multiform attributes of node to align {YANG} data
                  models},
	journal = {Comput. Networks},
	volume = {222},
	pages = {109538},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2022.109538},
	doi = {10.1016/J.COMNET.2022.109538},
	timestamp = {Fri, 17 Mar 2023 14:56:58 +0100},
	biburl = {https://dblp.org/rec/journals/cn/LiuDSF23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Nowadays Network Configuration Protocol (NETCONF) has become an essential part of network management for its flexibility and scalability. Vendors intend to use NETCONF to replace Command-Line Interface (CLI) and Simple Network Management Protocol (SNMP) to manage devices. Yet Another Next Generation (YANG) models are tailored to model NETCONF protocol messages. However, there exists heterogeneity issue with YANG models as a consequence of vendors proposing proprietary YANG models which differ from each other in structure or content. Thus, managing network devices from different vendors requires expert knowledge and plenty of resources. In this paper, we present MAYA, a solution to automatically accomplish alignment of YANG models from different vendors or organizations by exploring multiform node attributes. In MAYA, different semantic similarity techniques are used to measure distance between different attributes, such as name, description and type, in nodes from various YANG models. A customized SMP based matching algorithm for YANG models alignment is proposed to generate mapping relations between models based on the semantic similarity. The real cases analysis and experiments show that MAYA is able to meet the demands in production on the problem of YANG model alignment.}
}


@article{DBLP:journals/cn/SethBD23,
	author = {Abhay Deep Seth and
                  Santosh Biswas and
                  Amit Kumar Dhar},
	title = {{DADCNF:} Diagnoser design for Duplicate Address Detection threat
                  using Conjunctive Normal Form},
	journal = {Comput. Networks},
	volume = {222},
	pages = {109539},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2022.109539},
	doi = {10.1016/J.COMNET.2022.109539},
	timestamp = {Tue, 28 Mar 2023 19:51:08 +0200},
	biburl = {https://dblp.org/rec/journals/cn/SethBD23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Duplicate Address Detection is the protocol that confirms the uniqueness of an IPv6 host\n′\ns identification when it joins a new network. DAD scheme is susceptible to neighbor advertisement and neighbor solicitation spoofing attacks because ICMPv6 control messages lack in authentication. Existing strategies against the DAD attack have major drawbacks, e.g., high computation, non-scalability, requirement of protocol modification etc. This paper presents a strategy for detecting DAD attack using Conjunctive Normal Form-based Discrete Event System diagnoser. DES-based intrusion detection system have shown effective results in terms of features, like no change in protocol, low overhead etc. against network attacks.}
}


@article{DBLP:journals/cn/TianTX23,
	author = {Junfeng Tian and
                  Jin Tian and
                  Hongwei Xu},
	title = {{TSBFT:} {A} scalable and efficient leaderless byzantine consensus
                  for consortium blockchain},
	journal = {Comput. Networks},
	volume = {222},
	pages = {109541},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2022.109541},
	doi = {10.1016/J.COMNET.2022.109541},
	timestamp = {Sun, 06 Oct 2024 21:22:05 +0200},
	biburl = {https://dblp.org/rec/journals/cn/TianTX23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we present a high-performance, scalable Byzantine fault tolerance (BFT) protocol TSBFT for the consortium blockchains that does not rely on expensive leader-driven communication. It overcomes the challenges faced by the existing BFT protocol in three aspects: single-point failure, huge total message sizes, and limited by the slowest nodes. The proposed protocol secretly selects block proposers and uses threshold signature as a multi-round voting mechanism to confirm the validity of the proposed block. We adopt transmission pipelining to improve the network utilization while optimizing the gossip communication scheme to reduce the total message sizes. Finally, our protocol guarantees the security and liveness of the system. Experimental results show that, compared with other related BFT protocols (e.g., PBFT), TSBFT can effectively solve these three challenges. In addition, our experiments also show how the different optimization ingredients of TSBFT contribute to its performance and scalability. The results show that compared with the traditional BFT protocol, it can scale from dozens of nodes to hundreds of nodes.}
}


@article{DBLP:journals/cn/FuZQMH23,
	author = {Yanming Fu and
                  Xian Zhang and
                  Xiaoqiong Qin and
                  Qingwen Meng and
                  Bocheng Huang},
	title = {Data collection of multi-player cooperative game based on edge computing
                  in mobile crowd sensing},
	journal = {Comput. Networks},
	volume = {222},
	pages = {109551},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2022.109551},
	doi = {10.1016/J.COMNET.2022.109551},
	timestamp = {Mon, 26 Jun 2023 20:51:11 +0200},
	biburl = {https://dblp.org/rec/journals/cn/FuZQMH23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As the number and type of mobile crowd sensing (MCS) data collection increases, more and more computation and processing are required, resulting in higher service cost and service delay, posing a huge challenge to traditional MCS. Currently, edge computing is being introduced to MCS to collect data to reduce service cost and service latency. In the offline mode, there are two issues that need to be addressed with the edge computing-based MCS data collection. First, for large-scale, multi-player, and multiple types of task data, edge servers are limited in computational resources and need to address issues such as task offloading and service cache scheduling. Second, in traditional MCS data collection, workers usually carry in a single type of task data, but it has now been proposed that workers need to carry multiple types of task data. To address the above problems, this paper proposes a joint optimization strategy for edge computing based on multi-player cooperative game and greedy differential evolution algorithm (MCG-GDE) to improve the service rate of edge servers and minimize the service cost and service latency in the data collection. We build a mathematical optimization problem for edge computing based on MCS data collection. The formulation of the optimization problem proves to be a NP-hard problem, so this optimization strategy constructs a task propagation scheme for multi-player cooperative games (MCG), where tasks carried by workers are reassigned to effectively reduce problem complexity and produce sub-optimal solutions to the mathematical model. Then, on the basis of the suboptimal solution, the optimal solution of the problem is obtained by the greedy differential evolution algorithm (GDE). Simulation results demonstrate that MCG-GDE outperforms other baseline strategies.}
}


@article{DBLP:journals/cn/NeiraKN23,
	author = {Anderson Bergamini de Neira and
                  Burak Kantarci and
                  Michele Nogueira},
	title = {Distributed denial of service attack prediction: Challenges, open
                  issues and opportunities},
	journal = {Comput. Networks},
	volume = {222},
	pages = {109553},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2022.109553},
	doi = {10.1016/J.COMNET.2022.109553},
	timestamp = {Tue, 28 Mar 2023 19:51:08 +0200},
	biburl = {https://dblp.org/rec/journals/cn/NeiraKN23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Distributed Denial of Service (DDoS) attack is one of the biggest cyber threats. DDoS attacks have evolved in quantity and volume to evade detection and increase damage. Changes during the COVID-19 pandemic have left traditional perimeter-based security measures vulnerable to attackers that have diversified their activities by targeting health services, e-commerce, and educational services. DDoS attack prediction searches for signals of attack preparation to warn about the imminence of the attack. Prediction is necessary to handle high-volumetric DDoS attacks and to increase the time to defend against them. This survey article presents the classification of studies from the literature comprising the current state-of-the-art on DDoS attack prediction. It highlights the results of this extensive literature review categorizing the works by prediction time, architecture, employed methodology, and the type of data utilized to predict attacks. Further, this survey details each identified study and, finally, it emphasizes the research opportunities to evolve the DDoS attack prediction state-of-the-art.}
}


@article{DBLP:journals/cn/ZhaiMYHL23,
	author = {Dong Zhai and
                  Xiangru Meng and
                  Zhenhua Yu and
                  Hang Hu and
                  Yuan Liang},
	title = {A migration method for service function chain based on failure prediction},
	journal = {Comput. Networks},
	volume = {222},
	pages = {109554},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2022.109554},
	doi = {10.1016/J.COMNET.2022.109554},
	timestamp = {Fri, 17 Mar 2023 14:56:58 +0100},
	biburl = {https://dblp.org/rec/journals/cn/ZhaiMYHL23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the deep application of network technologies in different industries, the demand for network services is becoming more and more diversified. Network operation and maintenance are facing severe challenges, which can be solved by network function virtualization (NFV). NFV technology provides services for users through deploying service function chain (SFC) on servers and substrate links. However, once a server fails, the services it hosts will be affected or even interrupted. Therefore, it is very important to predict failures and migrate SFCs in advance according to predicted results. In this paper, we propose a failure prediction method based on the improved long short-term memory neural network (PMILSTM), which employs LSTM to predict failures. To further improve prediction accuracy, the simulated annealing particle swarm optimization algorithm is adopted to optimize the number of neurons in each long short-term memory layer and the time window length. A server may host multiple SFCs. When a server fails, in order to reduce the impact on users, it is necessary to simultaneously migrate all the SFCs hosted by the server. We propose an improved sparrow search algorithm (ISSA) and a service function chain migration method based on the ISSA (MMISSA). The ISSA introduces tent chaos, opposition-based learning, dynamic weight factor, and mutation operation into SSA to achieve the better global optimization ability. The MMISSA method adopts the ISSA to migrate SFCs so that it can simultaneously search for migration servers for all the virtual network functions deployed on a soon-to-fail server. The better global optimization ability of the ISSA enables better migration results. Therefore, the migration success ratio is improved. Moreover, the fitness function simultaneously considers the average migration cost and migration time. As a result, the MMISSA method effectively reduces the migration cost and migration time.}
}


@article{DBLP:journals/cn/ZhangD23,
	author = {Le Zhang and
                  Ye Du},
	title = {Resilience enhancement scheme for gateway placement in space information
                  networks},
	journal = {Comput. Networks},
	volume = {222},
	pages = {109555},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2022.109555},
	doi = {10.1016/J.COMNET.2022.109555},
	timestamp = {Fri, 17 Mar 2023 14:56:58 +0100},
	biburl = {https://dblp.org/rec/journals/cn/ZhangD23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Space information networks provide users with network services anytime and anywhere through satellites and gateways. Gateways are the main part of the terrestrial facilities of the space information networks, and their placement poses an important issue that will significantly affect the network performance. At the same time, the low security of gateways makes them vulnerable to cyber attacks, increasing the end-to-end delay of users. Therefore, it is critical to place gateways in suitable locations to maintain the availability of communications in malicious scenarios. Accordingly, this paper introduces resilience into the gateway placement problem for the first time, considering a scenario involving malicious users, a low earth orbit satellite constellation, and terrestrial networks with limited communications. Malicious users may launch simultaneous distributed denial of service attacks against arbitrary gateways. An optimization model is proposed to simultaneously optimize the average network delay in normal services and potentially malicious scenarios. In order to improve the solution efficiency of the gateway layout, an improved cuckoo search algorithm is proposed, and the comparison results show that its performance is better than the existing algorithms. The results of the case study show that the proposed optimization model can significantly enhance the ability of the space information networks to absorb malicious attacks. When 90% of the gateways are attacked, the end-to-end delay of users can be reduced by up to 82%.}
}


@article{DBLP:journals/cn/WangWSWMH23,
	author = {Xueyi Wang and
                  Xingwei Wang and
                  Ying Shi and
                  Dongkuo Wu and
                  Lianbo Ma and
                  Min Huang},
	title = {Core-selecting auction-based mechanisms for service function chain
                  provisioning and pricing in {NFV} markets},
	journal = {Comput. Networks},
	volume = {222},
	pages = {109557},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109557},
	doi = {10.1016/J.COMNET.2023.109557},
	timestamp = {Fri, 17 Mar 2023 14:56:58 +0100},
	biburl = {https://dblp.org/rec/journals/cn/WangWSWMH23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the rapid development of network function virtualization (NFV), an ever-increasing number of enterprises, businesses and operators are resorting to network service provisioning by means of the service function chains (SFCs). Toward this trend, NFV markets are emerging, where users rent SFCs from the network service provider (NSP) to execute their tasks, and the NSP uses the computation resources across geo-distributed clouds to construct various SFCs. Such NFV markets need well-designed pricing mechanisms for SFCs since the users have motivations to strategize around their payments. The Vickrey–Clarke–Groves (VCG) mechanism is a natural fit here, which can ensure that truthful bidding is a dominant strategy. However, VCG mechanism is susceptible to the problems of collusion and shill bidding. To address these problems, in this paper, we design a core-selecting auction-based mechanism (CSAM) for SFC provisioning and pricing in the NFV market. This mechanism considers dynamic provisioning, flexible deployment and reservation prices across geo-distributed clouds. Specifically, we first formulate the core of NFV auction, and prove that an in-core outcome can prevent collusion and shill bidding. Next, we use a couple of correlated linear program (LP) and quadratic program (QP) to design an in-core VCG-nearest payment algorithm, aiming to acquire an in-core outcome and minimize users’ incentives to bid untruthfully. Simulation results verify the strict theoretical analysis, and validate the effectiveness and efficiency of our proposed CSAM.}
}


@article{DBLP:journals/cn/AugelloGSSS23,
	author = {Alessandro Augello and
                  Pierluigi Gallo and
                  Eleonora Riva Sanseverino and
                  Gaetano Sciabica and
                  Giuseppe Scium{\`{e}}},
	title = {Certifying battery usage for {V2G} and second life with a blockchain-based
                  framework},
	journal = {Comput. Networks},
	volume = {222},
	pages = {109558},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109558},
	doi = {10.1016/J.COMNET.2023.109558},
	timestamp = {Tue, 12 Sep 2023 07:58:35 +0200},
	biburl = {https://dblp.org/rec/journals/cn/AugelloGSSS23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper describes a blockchain-based approach for sharing data among all the actors involved in Vehicle-to-Grid programs. The shared information is used both for monitoring the health status of the vehicle’s battery and for remuneration in Vehicle-to-Grid programs. A blockchain platform and a set of appropriate smart contracts have been developed for supporting the interactions among the different actors and for creating battery usage profiles. To protect sensitive data, we limit the visibility scope of such data only to subsets of actors using blockchain channels. This approach preserves the privacy of the car owner on one hand and guarantees the compliance to correct charging and discharging modes, on the other hand, by using dedicated smart contracts to manage data for each of the channels. The approach here described proposes and develops a blockchain-based ecosystem for efficiently managing electric vehicles especially when these are called to provide electrical grid services, such as it happens for Vehicle-to-Grid programs. In this case, it is indeed possible that the battery undergoes an accelerated aging and thus certified recording of charging data for legal liability is one of the issues here dealt with. When possible, data are collected from multiple sources (e.g. the charging station and the Electric Vehicle) and from different parties with conflicting interests for validating data and breaking data silos that are within the car, the charging stations and the Battery Management System.}
}


@article{DBLP:journals/cn/YoshinakaTKH23,
	author = {Yutaro Yoshinaka and
                  Junji Takemasa and
                  Yuki Koizumi and
                  Toru Hasegawa},
	title = {Design and analysis of lightweight anonymity protocol for host- and
                  AS-level anonymity},
	journal = {Comput. Networks},
	volume = {222},
	pages = {109559},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109559},
	doi = {10.1016/J.COMNET.2023.109559},
	timestamp = {Sat, 30 Sep 2023 10:07:05 +0200},
	biburl = {https://dblp.org/rec/journals/cn/YoshinakaTKH23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Lightweight anonymity protocols in the network layer are promising in terms of high throughput and low latency. The realistic and weak assumption of local adversaries deletes the need for hop-by-hop encryption of onion routing, and this contributes to high throughput and low latency. Among them, PHI and its successor dPHI are promising due to the fact that path-setup packets for anonymous paths are forwarded according to IP routing. This feature enables easy deployment of the protocol on the Internet infrastructure. However, PHI and dPHI are vulnerable to adversaries such as malicious ASes who compromise servers for path setup, called helpers, and malicious ASes who leverage topological information and routing policies of the IP network. The paper resolves the vulnerabilities in the two steps. In the first step, we design attacks that leverage the vulnerabilities to break anonymity. In the second step, we extend dPHI to mitigate such attacks by adding a new server called a guard. The extended protocol is called gPHI, and gPHI is resilient against adversaries who perform such attacks. This paper designs gPHI and validates its resilience through formal proof and simulation.}
}


@article{DBLP:journals/cn/HirschDGF23,
	author = {Christian Hirsch and
                  Luca Davoli and
                  Radu Grosu and
                  Gianluigi Ferrari},
	title = {DynGATT: {A} dynamic GATT-based data synchronization protocol for
                  {BLE} networks},
	journal = {Comput. Networks},
	volume = {222},
	pages = {109560},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109560},
	doi = {10.1016/J.COMNET.2023.109560},
	timestamp = {Fri, 23 Jun 2023 22:30:57 +0200},
	biburl = {https://dblp.org/rec/journals/cn/HirschDGF23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Bluetooth Low Energy (BLE) is a wireless communication technology for power-constrained Internet of Things (IoT) applications. BLE data can be transmitted via either the IPv6 or the Generic ATTribute (GATT) Profile protocol, with the former supporting dynamic IoT structures and the latter being application-friendly. In fact, GATT requires the data layout to be known in advance by peer devices, in order to properly interpret the received data. In this paper, we introduce DynGATT, a protocol that achieves the benefits of both IPv6 and GATT, by extending GATT in a seamless fashion to support dynamic IoT structures. The key idea of DynGATT is to use GATT descriptors, originally intended to specify data in static IoT scenarios, to also specify IoT systems whose structures may dynamically evolve. Peer devices reading these descriptors will know how to interpret the data of GATT characteristics provided by devices joining the IoT network. Because no additional data have to be transmitted, the connection time is then reduced with respect to classical BLE. DynGATT has been implemented and tested in an agricultural IoT application, with different types of sensor nodes. Our experimental evaluation shows that DynGATT is very power-efficient, despite its added flexibility. Its worst-case power consumption is only around 19.37 µA per data transmission and around 41.37 µA overall. This consumption can be further reduced by using the methods discussed in this paper. To the best of our knowledge, this work is the first to support dynamic IoT structures in a GATT-based setting.}
}


@article{DBLP:journals/cn/NandyalaKC23,
	author = {Chandra Sukanya Nandyala and
                  Hee{-}won Kim and
                  Ho{-}Shin Cho},
	title = {{QTAR:} {A} Q-learning-based topology-aware routing protocol for underwater
                  wireless sensor networks},
	journal = {Comput. Networks},
	volume = {222},
	pages = {109562},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109562},
	doi = {10.1016/J.COMNET.2023.109562},
	timestamp = {Sat, 13 May 2023 01:07:10 +0200},
	biburl = {https://dblp.org/rec/journals/cn/NandyalaKC23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, an energy-efficient Q-learning-based routing protocol, called the Q-learning-based topology-aware routing (QTAR) protocol, is proposed for underwater wireless sensor networks. Unlike existing protocols, QTAR considers the network topology to determine the next-forwarder (NF) candidates along the routing path and adopts Q-learning to aid in the optimal global decision-making of an NF from the NF candidates. In addition, QTAR utilizes implicit cut-vertex recognition to optimize NF selection, alleviating the energy wastage that arises from forwarding data packets away from the sink. In our study, we evaluated the performance of QTAR by comparing it with the Q-learning-based energy-efficient and lifetime-aware routing protocol (QELAR), energy-efficient depth-based routing protocol (EEDBR), Q-learning-based delay-aware routing (QDAR), and reinforcement learning-based opportunistic routing protocol (RLOR) in terms of the energy consumption, latency, and network lifetime. Our results revealed that QTAR demonstrated the advantages of a lower energy consumption, shorter latency, and longer network lifetime in the percentage ranges of 26.08 to 70.12, 22.2 to 50, and 37.8 to 75, respectively, than QELAR, EEDBR, QDAR, and RLOR.}
}
