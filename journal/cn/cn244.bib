@article{DBLP:journals/cn/MarinMMS24,
	author = {Andrea Marin and
                  Marco Ajmone Marsan and
                  Michela Meo and
                  Matteo Sereno},
	title = {Queuing models of links carrying streaming and elastic services},
	journal = {Comput. Networks},
	volume = {244},
	pages = {110306},
	year = {2024},
	url = {https://doi.org/10.1016/j.comnet.2024.110306},
	doi = {10.1016/J.COMNET.2024.110306},
	timestamp = {Sun, 06 Oct 2024 21:22:04 +0200},
	biburl = {https://dblp.org/rec/journals/cn/MarinMMS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We consider an access link carrying data generated by streaming and elastic services requested by fixed or mobile end users, and subjected to an admission control (AC) algorithm. For the performance analysis of such link we develop a new queuing model and we show that, with the considered AC, the queuing model admits a product form expression for the joint limiting probability distribution of the numbers of active services of the different types. In addition, we prove that, when mobility can be neglected, i.e., in the case of either fixed access or slow mobility, the queuing model is insensitive to the distribution of the amount of data to be transferred for the fulfillment of the different service requests. Numerical results show unexpected oscillating behaviors for several performance metrics, and provide interesting insight into the link performance.}
}


@article{DBLP:journals/cn/ZhuTCZQ24,
	author = {Sifeng Zhu and
                  Xiaohua Tian and
                  Hao Chen and
                  Hai Zhu and
                  Rui Qiao},
	title = {Edge collaborative caching solution based on improved {NSGA} {II}
                  algorithm in Internet of Vehicles},
	journal = {Comput. Networks},
	volume = {244},
	pages = {110307},
	year = {2024},
	url = {https://doi.org/10.1016/j.comnet.2024.110307},
	doi = {10.1016/J.COMNET.2024.110307},
	timestamp = {Fri, 06 Dec 2024 11:16:50 +0100},
	biburl = {https://dblp.org/rec/journals/cn/ZhuTCZQ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the rapid development of the Internet of Vehicles technology and the continuous advancement of intelligent transportation, vehicle network traffic is growing exponentially. Traditional caching solutions transmit content through the core network, causing significant latency. A vehicle-cloud collaborative edge caching network architecture was proposed to address this type of problem. Using this architecture, both the on-board terminals and cloud/edge servers could provide computing services. A communication model, caching model, latency model, energy consumption model, load model and multi-objective optimization problem model were designed. The edge collaborative caching solution based on the improved NSGA II algorithm was proposed. By caching some services to edge nodes and nearby vehicles, reducing content access latency and improving resource utilization. The results indicate that the caching solution outperforms the comparison scheme in terms of the comprehensive costs of latency, energy consumption, and load balancing in simulation experiments. It can meet the caching requirements of low latency and low energy consumption for in-vehicle applications, laying a solid foundation for achieving more efficient and reliable connected vehicles and autonomous driving.}
}


@article{DBLP:journals/cn/BellinGM24,
	author = {Arturo Bellin and
                  Fabrizio Granelli and
                  Daniele Munaretto},
	title = {A measurement-based approach to analyze the power consumption of the
                  softwarized 5G core},
	journal = {Comput. Networks},
	volume = {244},
	pages = {110312},
	year = {2024},
	url = {https://doi.org/10.1016/j.comnet.2024.110312},
	doi = {10.1016/J.COMNET.2024.110312},
	timestamp = {Fri, 31 May 2024 21:06:36 +0200},
	biburl = {https://dblp.org/rec/journals/cn/BellinGM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In light of the ever growing energy needs of the ICT sector, a value that is becoming increasingly important for a mobile network is its power consumption. However, the transition away from legacy network deployments tightly coupled with the underlying hardware and the adoption of the Network Function Virtualization (NFV) paradigm has made more difficult to accurately evaluate their energy and carbon footprint. In this paper, we propose and validate a measurement-based approach to analyze the power consumption of a virtualized 5G core network (5GC) deployment. We design an experimental testbed using commercial off-the-shelf (COTS) hardware and open-source software as a sample architecture simulating an edge computing node and supporting three different virtualization options. We make use of both hardware-based and software-based power meters to investigate the power consumption trends associated with increasing levels of traffic and multiple 5GC deployment types. The results show the feasibility of a real-time power monitoring system and highlight how deployment choices, such as virtualization framework and 5GC software, can significantly impact on the power consumption of the network.}
}


@article{DBLP:journals/cn/AlmeidaSTPPV24,
	author = {Leandro C. de Almeida and
                  Washington Rodrigo Dias da Silva and
                  Thiago Caproni Tavares and
                  Rafael Pasquini and
                  Chrysa Papagianni and
                  F{\'{a}}bio L. Verdi},
	title = {DESiRED - Dynamic, Enhanced, and Smart iRED: {A} {P4-AQM} with Deep
                  Reinforcement Learning and In-band Network Telemetry},
	journal = {Comput. Networks},
	volume = {244},
	pages = {110326},
	year = {2024},
	url = {https://doi.org/10.1016/j.comnet.2024.110326},
	doi = {10.1016/J.COMNET.2024.110326},
	timestamp = {Mon, 03 Mar 2025 21:30:41 +0100},
	biburl = {https://dblp.org/rec/journals/cn/AlmeidaSTPPV24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Active Queue Management (AQM) is a mechanism employed to alleviate transient congestion in network device buffers, such as routers and switches. Traditional AQM algorithms use fixed thresholds, like target delay or queue occupancy, to compute random packet drop probabilities. A very small target delay can increase packet losses and reduce link utilization, while a large target delay may increase queueing delays while lowering drop probability. Due to dynamic network traffic characteristics, where traffic fluctuations can lead to significant queue variations, maintaining a fixed threshold AQM may not suit all applications. Consequently, we explore the question: What is the ideal threshold (target delay) for AQMs? In this work, we introduce DESiRED (Dynamic, Enhanced, and Smart iRED), a P4-based AQM that leverages precise network feedback from In-band Network Telemetry (INT) to feed a Deep Reinforcement Learning (DRL) model. This model dynamically adjusts the target delay based on rewards that maximize application Quality of Service (QoS). We evaluate DESiRED in a realistic P4-based test environment running an MPEG-DASH service. Our findings demonstrate up to a 90x reduction in video stall and a 42x increase in high-resolution video playback quality when the target delay is adjusted dynamically by DESiRED.}
}


@article{DBLP:journals/cn/ShirsathCLC24,
	author = {Vaishali A. Shirsath and
                  Madhav Chandane and
                  Chhagan Lal and
                  Mauro Conti},
	title = {{SYNTROPY:} {TCP} {SYN} DDoS attack detection for Software Defined
                  Network based on R{\'{e}}nyi entropy},
	journal = {Comput. Networks},
	volume = {244},
	pages = {110327},
	year = {2024},
	url = {https://doi.org/10.1016/j.comnet.2024.110327},
	doi = {10.1016/J.COMNET.2024.110327},
	timestamp = {Sun, 04 Aug 2024 19:48:53 +0200},
	biburl = {https://dblp.org/rec/journals/cn/ShirsathCLC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The rapidly evolving landscape of network security, particularly in Software Defined Networks (SDNs), presents a critical need for efficient and adaptive DDoS attack detection methods, especially in the face of TCP SYN DDoS attacks. These attacks pose significant threats to network resources and service availability. Current state-of-the-art solutions, predominantly based on Shannon entropy, have inherent limitations, that give equal weightage to all frequency probability. This inherent assumption often leads to inadequate detection in complex and dynamic network environments, where attack patterns are increasingly sophisticated and variable. In this paper, we present a novel framework called SYNTROPY that is designed to detect TCP SYN DDoS attacks in SDN environments. The proposed SYNTROPY framework leverages Rényi entropy to effectively generalize the measurement of uncertainty in the network traffic. Unlike Shannon entropy, Rényi entropy offers the flexibility to adjust sensitivity to varying network conditions and attack patterns, thereby enhancing detection accuracy. It filters benign, flash, and suspicious traffic and employs a min–max threshold to identify attack patterns accurately. Our framework is implemented using the Ryu Controller, thus enabling seamless integration with SDN systems. The experiment is conducted to evaluate the SYNTROPY performance using the CAIDA UCSD DDoS 2007 Attack Dataset. The comparative analysis demonstrates that SYNTROPY performs better across various metrics than state-of-the-art solutions. It includes a 40% reduction in average CPU load, 59% enhancement in average detection time, 13% increase in true positives rate, 34% decrease in false negatives rate, 10% recall improvement, and 8% higher F1-Score. These promising results showcase the potential of SYNTROPY as a robust and effective solution for addressing TCP SYN DDoS attacks in SDNs.}
}


@article{DBLP:journals/cn/ToorchiLHZRH24,
	author = {Niloofar Toorchi and
                  Weiqiang Lyu and
                  Linsheng He and
                  Jiamiao Zhao and
                  Iftikhar Rasheed and
                  Fei Hu},
	title = {Deep reinforcement learning enhanced skeleton based pipe routing for
                  high-throughput transmission in flying ad-hoc networks},
	journal = {Comput. Networks},
	volume = {244},
	pages = {110330},
	year = {2024},
	url = {https://doi.org/10.1016/j.comnet.2024.110330},
	doi = {10.1016/J.COMNET.2024.110330},
	timestamp = {Fri, 31 May 2024 21:06:36 +0200},
	biburl = {https://dblp.org/rec/journals/cn/ToorchiLHZRH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Artificial Intelligence (AI) is a huge step towards the emergence of powerful and smart decision-makers which can optimally tune the network parameters. In this work, a novel idea of an intelligent pipe (iPipe) routing scheme for a network of unmanned aerial vehicles (UAVs) is presented by considering the availability of a centralized entity with enough computational resources. The proposed scheme deploys artificial intelligence to optimally decide on the direction of the routing pipe (i.e. the medial axis), based on the current network information and the prediction of the immediate future. To address the potential influx of input data, the application of Deep Reinforcement Learning (DRL) is proposed to enhance the throughput performance and adapt more effectively to network dynamics. The scheme benefits from the concept of flying ad hoc network (FANET) to provide nodes with geometric coordinates in order to facilitate the data forwarding mechanism. Compared to the conventional AI-based routing strategies, the proposed scheme does not require making decisions for the routing table of all the nodes. Instead, it only finds the trend as a set of geometric indices which will be included in the packet headers. However, the pipe nodes still act in a distributed manner. They build their routing tables according to the trend suggested by the controller and adjust the transmission probability of each link based on the local feedback. This reduces the complexity of the centralized solution. The simulation results show that the proposed iPipe method can outperform the other state-of-the-art SSR routing scheme, which is a distributed but low-cost pipe routing.}
}


@article{DBLP:journals/cn/FeraudoRMMB24,
	author = {Angelo Feraudo and
                  Nicol{\`{o}} Romandini and
                  Carlo Mazzocca and
                  Rebecca Montanari and
                  Paolo Bellavista},
	title = {{DIVA:} {A} DID-based reputation system for secure transmission in
                  VANETs using {IOTA}},
	journal = {Comput. Networks},
	volume = {244},
	pages = {110332},
	year = {2024},
	url = {https://doi.org/10.1016/j.comnet.2024.110332},
	doi = {10.1016/J.COMNET.2024.110332},
	timestamp = {Tue, 18 Jun 2024 09:26:12 +0200},
	biburl = {https://dblp.org/rec/journals/cn/FeraudoRMMB24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Today’s advancement in Vehicular Ad-hoc Networks (VANET) constitutes a cornerstone in ensuring traffic safety in Intelligent Transportation Systems (ITS). In this context, vehicle-to-vehicle (V2V) communications are a pivotal enabler for road safety, traffic optimization, and pedestrian protection. However, V2V communications lack effective and efficient security solutions that can adequately ensure the trustworthiness of the source of the transmitted content. In this work, we originally propose DIVA, i.e., a Decentralized Identifier-based reputation system for secure transmission in VAnets. In particular, we claim the suitability of utilizing IOTA, a Direct Acyclic Graph (DAG)-based ledger, to securely store reputation scores and of leveraging Decentralized Identifiers (DIDs) to identify participating vehicles. DIVA also incorporates and implements a reputation algorithm that computes reputation scores by analyzing both safety and non-safety messages, exchanged among vehicles and Road Side Units (RSUs) in compliance with the related European Telecommunications Standards Institute (ETSI) standards. Thus, DIVA can effectively identify malicious contributors and decrease their reputation scores. The reported experimental results clearly show the feasibility and effectiveness of DIVA, by working on an extended and comprehensive dataset of realistic V2V messages; the dataset has been made openly accessible to the research community, also to increase result reproducibility.}
}


@article{DBLP:journals/cn/ZhaoYDRSWZ24,
	author = {Baosen Zhao and
                  Wanghong Yang and
                  Wenji Du and
                  Yongmao Ren and
                  Jianan Sun and
                  Qinghua Wu and
                  Xu Zhou},
	title = {A multipath scheduler based on cross-layer information for low-delay
                  applications in 5G edge networks},
	journal = {Comput. Networks},
	volume = {244},
	pages = {110333},
	year = {2024},
	url = {https://doi.org/10.1016/j.comnet.2024.110333},
	doi = {10.1016/J.COMNET.2024.110333},
	timestamp = {Mon, 30 Dec 2024 20:28:00 +0100},
	biburl = {https://dblp.org/rec/journals/cn/ZhaoYDRSWZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Virtual Reality (VR) applications that require extremely low delay and high image quality are widely used in online games and other 5G scenarios, becoming a hot research field in recent years. However, the limited bandwidth in 5G edge networks fails to meet the peak rate requirements for multiple VR flows. MPTCP is suitable for 5G edge networks, supporting the simultaneous use of multiple networks on mobile devices. Nevertheless, accurately scheduling VR data blocks to different subflows to satisfy their low delay requirements is challenging due to their microburst characteristic. In this paper, we propose a novel MPTCP scheduler for cloud VR applications in 5G edge networks, called the Cross-layer information-based one-way delay Predictive Scheduler (CPS). CPS accurately predicts one-way delay by incorporating cross-layer information from both the application and edge wireless sides, and adaptively schedules VR data blocks to the optimal subflow. Experimental results show that CPS outperforms existing strategies, supporting 125% more users for VR applications in the typical scenario. CPS successfully meets the quality of experience needs of more users, providing a promising solution for large-scale deployment of cloud VR services in 5G edge networks.}
}


@article{DBLP:journals/cn/RioSJCA24,
	author = {Alberto del R{\'{\i}}o and
                  Javier Serrano and
                  David Jim{\'{e}}nez and
                  Luis M. Contreras and
                  Federico Alvarez},
	title = {Multisite gaming streaming optimization over virtualized 5G environment
                  using Deep Reinforcement Learning techniques},
	journal = {Comput. Networks},
	volume = {244},
	pages = {110334},
	year = {2024},
	url = {https://doi.org/10.1016/j.comnet.2024.110334},
	doi = {10.1016/J.COMNET.2024.110334},
	timestamp = {Sat, 08 Jun 2024 13:14:22 +0200},
	biburl = {https://dblp.org/rec/journals/cn/RioSJCA24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The massive growth of live streaming, especially gaming-focused content, has led to an overall increase in global bandwidth consumption. Certain services see their quality diminished at times of peak consumption, degrading the quality of the content. This trend generates new research related to optimizing image quality according to network and service conditions. In this work we present a gaming streaming use case optimization on a real multisite 5G environment. The paper outlines the virtualized workflow of the use case and provides a detailed description of the applications and resources deployed for the simulation. This simulation tests the optimization of the service based on the addition of Artificial Intelligence (AI) algorithms, assuring the delivery of content with good Quality of Experience (QoE) under different working conditions. The AI introduced is based on Deep Reinforcement Learning (DRL) algorithms that can adapt, in a flexible way, to the different conditions that the multimedia workflow could face. That is, adapt, through corrective actions, the streaming bitrate, in order to optimize the QoE of the content on a real-time multisite scenario. The results of this work demonstrate how we have been able to minimize content losses, as well as the fact of obtaining high audiovisual multimedia quality results with higher bitrates, compared to a service without an optimizer integrated in the system. In a multi-site environment, we have achieved an improvement of 20 percentage points in terms of blockiness efficiency and also 15 percentage points in block loss.}
}


@article{DBLP:journals/cn/MlikaKR24,
	author = {Fatma Mlika and
                  Wafa Karoui and
                  Lotfi Ben Romdhane},
	title = {Blockchain solutions for trustworthy decentralization in social networks},
	journal = {Comput. Networks},
	volume = {244},
	pages = {110336},
	year = {2024},
	url = {https://doi.org/10.1016/j.comnet.2024.110336},
	doi = {10.1016/J.COMNET.2024.110336},
	timestamp = {Fri, 31 May 2024 21:06:36 +0200},
	biburl = {https://dblp.org/rec/journals/cn/MlikaKR24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The influence of blockchain on technology, especially in the field of finance, has brought about the age of cryptocurrencies and decentralized control, spreading its impact across various industries to ensure precision. As the trend moves towards decentralized social networks, diverse approaches are explored, becoming crucial tools for defining trust and privacy in individuals’ personal lives during uncertain environments. Blockchain’s transformative role reaches beyond finance, revolutionizing how we establish trust and privacy in our interconnected digital societies. Concurrently, researchers recognize the efficacy of trust models in enhancing the security and reliability of social networks applications. However, a comprehensive review of recent advancements in trust models based on blockchain for social networks is lacking. To address this gap, our survey takes a comprehensive perspective on the theme of trust within decentralized networks. We examine various concepts such as the trust concept itself, trust models, trust prediction methodologies, decentralization in trust-based social networks, and the role of blockchain in fortifying trust and security in social networks. We investigate the intersection of trust and blockchain technology, encompassing concepts, types of blockchain, and their applications in social networks. These models are categorized based on different parameters, and we examine both their advantages and limitations. Finally, we propose prospective paths for researchers interested in exploring this area.}
}


@article{DBLP:journals/cn/MortaguaZS24,
	author = {Duarte Mort{\'{a}}gua and
                  Andr{\'{e}} Z{\'{u}}quete and
                  Paulo Salvador},
	title = {Enhancing 802.1X authentication with identity providers using {EAP-OAUTH}
                  and OAuth 2.0},
	journal = {Comput. Networks},
	volume = {244},
	pages = {110337},
	year = {2024},
	url = {https://doi.org/10.1016/j.comnet.2024.110337},
	doi = {10.1016/J.COMNET.2024.110337},
	timestamp = {Sun, 04 Aug 2024 19:48:54 +0200},
	biburl = {https://dblp.org/rec/journals/cn/MortaguaZS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {EAP-OAUTH is a novel Extensible Authentication Protocol (EAP) method that integrates the OAuth 2.0 framework to provide a secure and flexible authentication mechanism for LANs and WLANs that implement the IEEE 802.1X framework. EAP-OAUTH leverages existing, OAuth 2.0-enabled Identity Providers (IdPs) and their single sign-on (SSO) capabilities, thus offering a streamlined authentication experience for both users and organizations. The advantages of EAP-OAUTH for users include an SSO experience and enhanced privacy, while organizations benefit from simplified identity management, reduced operational costs, consistent security policies, and easier compliance. Furthermore, EAP-OAUTH represents a promising solution for addressing the challenges of authentication in modern wireless networks, such as the deployment of various multi-factor or risk-based, adaptive authentication strategies. This article presents an in-depth analysis of the EAP-OAUTH method, its design, implementation, and use cases in enterprise networks and public hotspots. It explores the OAuth 2.0 Device Authorization Grant flow and allows network clients to perform fast re-authentications without resorting to sessions on IdPs or even their SSO features. The implementation of EAP-OAUTH is demonstrated in real-world scenarios, using two IdPs (Google and Auth0), confirming its effectiveness, suitable performance and compatibility with various components of typical Wi-Fi infrastructures.}
}


@article{DBLP:journals/cn/LiangZBYWS24,
	author = {Junjie Liang and
                  Lei Zhang and
                  Can Bu and
                  Guangyu Yang and
                  Hao Wu and
                  Aiguo Song},
	title = {Plug-and-play multi-dimensional attention module for accurate Human
                  Activity Recognition},
	journal = {Comput. Networks},
	volume = {244},
	pages = {110338},
	year = {2024},
	url = {https://doi.org/10.1016/j.comnet.2024.110338},
	doi = {10.1016/J.COMNET.2024.110338},
	timestamp = {Mon, 03 Mar 2025 21:30:44 +0100},
	biburl = {https://dblp.org/rec/journals/cn/LiangZBYWS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Unlike image data, Human Activity Recognition (HAR) data is collected through sensors placed on different parts of the body. Each sensor may have varying importance for different human actions. Attention mechanisms can dynamically identify the significance of signals from different sensors. However, existing attention modules often operate along channel or spatial dimensions, producing one-dimensional or two-dimensional weights, and considering neurons within every channel or spatial location as equivalent. This might constrain their capacity to acquire more distinctive cues. In this paper, we present a novel Three-Dimensional Weight Attention Module (WAM) that considers both spatial and weight information of each channel. Specifically, we commence by introducing an energy function and subsequently assess the significance of each neuron through optimization. Unlike conventional channel or spatial attention modules, this module can compute 3D attention weights for feature maps without additional parameters. Experiments conducted on four diverse HAR datasets showcase that the Three-Dimensional Weight Attention Module can seamlessly integrate with convolutional models, significantly enhancing model performance without introducing extra computational burden. To further highlight the utility of WAM, we measure the actual inference time on an embedded platform.}
}


@article{DBLP:journals/cn/DuJCGW24,
	author = {An Du and
                  Jie Jia and
                  Jian Chen and
                  Liang Guo and
                  Xingwei Wang},
	title = {Online two-timescale service placement for time-sensitive applications
                  in MEC-assisted network: {A} {TMAGRL} approach},
	journal = {Comput. Networks},
	volume = {244},
	pages = {110339},
	year = {2024},
	url = {https://doi.org/10.1016/j.comnet.2024.110339},
	doi = {10.1016/J.COMNET.2024.110339},
	timestamp = {Tue, 03 Dec 2024 17:09:08 +0100},
	biburl = {https://dblp.org/rec/journals/cn/DuJCGW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Mobile edge computing (MEC) integrated with the Network Functions Virtualization (NFV) technique has been regarded as a promising solution for flexible services provision and user service experience improvement. However, existing service placement in such systems still faces the challenge of satisfying computing tasks with strict latency requirements, especially when massive mobile users roam around different coverage areas of edge servers. For this purpose, we first adopt a novel service placement framework that combines proactive replicas pre-deployment and reactive service migration. Based on this, we investigate the dynamic placement problem of multiple types of services achieved by the various virtualized network functions (VNFs) to minimize long-term redeployment costs in MEC-assisted systems, subject to the completion deadline of tasks and limited computing resources of edge servers. Considering that the update timescale of VNF replicas pre-deployment is different, we design a novel two-timescale multi-agent graph convolutional network-based reinforcement learning algorithm (TMAGRL) by invoking a long-timescale training layer for proactive VNF replicas placement and a short-timescale training layer for reactive VNF migration. Extensive numerical results reveal that TMAGRL, based on the designed hybrid framework, can learn a VNF placement strategy to adapt to the dynamics of the system without any prior information. Moreover, we verify its superior performance in terms of average service response latency and overall redeployment cost by comparing it with baselines.}
}


@article{DBLP:journals/cn/BaidasAA24,
	author = {Mohammed W. Baidas and
                  Ahmed M. AbdelGhaffar and
                  Emad Alsusa},
	title = {Network sum-rate maximization for network-coded clustered uplink {NOMA}
                  networks with SWIPT-enabled relays},
	journal = {Comput. Networks},
	volume = {244},
	pages = {110340},
	year = {2024},
	url = {https://doi.org/10.1016/j.comnet.2024.110340},
	doi = {10.1016/J.COMNET.2024.110340},
	timestamp = {Fri, 31 May 2024 21:06:36 +0200},
	biburl = {https://dblp.org/rec/journals/cn/BaidasAA24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper considers network sum-rate maximization for network-coded clustered uplink non-orthogonal multiple-access (NOMA) networks with simultaneous wireless information and power transfer (SWIPT)-enabled relays. Specifically, the aim is to perform joint power allocation, power-splitting, and relay selection (J-PA-PS-RS), subject to quality-of-service (QoS) requirements. The formulated problem is excessively computationally-intensive, as it is a non-convex optimization problem. To efficiently solve it, it is split into two sub-problems: (1) joint power allocation and power-splitting per relay, and (2) relay selection. Particularly, a solution procedure is proposed, where the joint user and relay power allocation, and power-splitting per relay sub-problem is solved via a low-complexity iterative three-layer algorithm, and then followed by optimal relay selection. Simulation results have revealed that the proposed solution procedure can efficiently be used to maximize the network sum-rate, achieve near-optimal solutions, and outperform other benchmark schemes, while satisfying QoS constraints.}
}


@article{DBLP:journals/cn/FaticantiN24,
	author = {Francescomaria Faticanti and
                  Giovanni Neglia},
	title = {Optimistic online caching for batched requests},
	journal = {Comput. Networks},
	volume = {244},
	pages = {110341},
	year = {2024},
	url = {https://doi.org/10.1016/j.comnet.2024.110341},
	doi = {10.1016/J.COMNET.2024.110341},
	timestamp = {Wed, 22 May 2024 12:46:42 +0200},
	biburl = {https://dblp.org/rec/journals/cn/FaticantiN24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we investigate ‘optimistic’ online caching policies, distinguished by their use of future request predictions derived, for example, from machine learning models. Traditional online optimistic policies, grounded in the Follow-The-Regularized-Leader (FTRL) algorithm, incur a higher computational cost compared to classic policies like Least Frequently Used (LFU) and Least Recently Used (LRU). This is due to each cache state update necessitating the resolution of a constrained optimization problem. To address this problem, we introduce and analyze the ‘batched’ version of two distinct FTRL-based optimistic policies. In this approach, the cache updates occur less frequently, thereby amortizing the update cost over time or over multiple requests. Rather than updating the cache with each new request, the system accumulates a batch of requests before modifying the cache content. First, we present a batched version of the Optimistic Bipartite Caching (OBC) algorithm, that works for single requests, then we introduce a new optimistic batched caching policy, the Per-Coordinate Optimistic Caching (PCOC) algorithm, derived from the per-coordinate-based FTRL. We demonstrate that these online algorithms maintain ‘vanishing regret’ in the batched case, meaning their average performance approaches over time that of an optimal static file allocation, regardless of the sequence of file requests. We then compare the performance of these two strategies with each other and against optimistic versions of LFU and LRU. Our experimental results indicate that this batched optimistic approach outperforms traditional caching policies on both stationary and real-world file request traces.}
}


@article{DBLP:journals/cn/LiLCTTC24,
	author = {Yue Li and
                  Yanjun Li and
                  Yuzhe Chen and
                  Jiahui Tong and
                  Xianzhong Tian and
                  Kaikai Chi},
	title = {Online resolution adaptation and resource allocation for edge-assisted
                  video analytics},
	journal = {Comput. Networks},
	volume = {244},
	pages = {110342},
	year = {2024},
	url = {https://doi.org/10.1016/j.comnet.2024.110342},
	doi = {10.1016/J.COMNET.2024.110342},
	timestamp = {Fri, 31 May 2024 21:06:36 +0200},
	biburl = {https://dblp.org/rec/journals/cn/LiLCTTC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Real-time analytics on video data from mobile devices demands intensive computation resources for the application like traffic monitoring and anomaly detection. Leveraging edge computing allows for the offloading of computation-intensive tasks to nearby edge servers, alleviating the constraints on resource-limited end-devices and reducing the long latency incurred by transmitting data to the cloud. When offloading the video data from multiple end-devices to multiple edge servers, factors such as video resolution, server selection, the allocation of bandwidth and computing resources have a substantial impact on key metrics like detection accuracy and real-time task success rate. The time-varying channel state and the dynamics of the event sequence also play a crucial role in decision-making. Building upon this foundation, our focus is on proposing an online solution for resolution adaptation and resource allocation that maximizes average utility over the long term, striking a balance between video analytics accuracy and real-time performance. The problem is formulated within a Markov decision process (MDP) framework. In view of the continuous state and action spaces, we propose an online solution based on the asynchronous advantage actor–critic (A3C) learning method. Extensive simulation results show that our proposed A3C-based solution exhibits faster convergence and superior performances compared with a series of benchmark algorithms under various settings, and thus achieves the best tradeoff between analytics accuracy and task success rate.}
}


@article{DBLP:journals/cn/ZhangYSWWZNLRG24,
	author = {Zixu Zhang and
                  Guangsheng Yu and
                  Caijun Sun and
                  Xu Wang and
                  Ying Wang and
                  Ming Zhang and
                  Wei Ni and
                  Ren Ping Liu and
                  Andrew Reeves and
                  Nektarios Georgalas},
	title = {TbDd: {A} new trust-based, DRL-driven framework for blockchain sharding
                  in IoT},
	journal = {Comput. Networks},
	volume = {244},
	pages = {110343},
	year = {2024},
	url = {https://doi.org/10.1016/j.comnet.2024.110343},
	doi = {10.1016/J.COMNET.2024.110343},
	timestamp = {Sun, 06 Oct 2024 21:22:05 +0200},
	biburl = {https://dblp.org/rec/journals/cn/ZhangYSWWZNLRG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Integrating sharded blockchain with IoT presents a solution for trust issues and optimized data flow. Sharding boosts blockchain scalability by dividing its nodes into parallel shards, yet it is vulnerable to the 1% attacks where dishonest nodes target a shard to corrupt the entire blockchain. Balancing security with scalability is pivotal for such systems. Deep Reinforcement Learning (DRL) adeptly handles dynamic, complex systems and multi-dimensional optimization. This paper introduces a Trust-based and DRL-driven (TbDd) framework, crafted to counter collusion attack risks and dynamically adjust node allocation, enhancing throughput while maintaining network security. With a comprehensive trust evaluation mechanism, TbDd discerns node types and performs targeted resharding against potential threats. The TbDd framework maximizes the tolerance for dishonest nodes, optimizes node movement frequency, ensures even node distribution in shards, and balances sharding risks. Extensive evaluations validate TbDd’s superiority over conventional random-, community-, and trust-based sharding methods in shard risk equilibrium and reducing cross-shard transactions.}
}


@article{DBLP:journals/cn/WengleELVD24,
	author = {Emil Wengle and
                  Elias Strandell Erstorp and
                  Viktor Lidstr{\"{o}}m and
                  Damiano Varagnolo and
                  Hefeng Dong},
	title = {Experimental assessment of a JANUS-based consensus protocol},
	journal = {Comput. Networks},
	volume = {244},
	pages = {110345},
	year = {2024},
	url = {https://doi.org/10.1016/j.comnet.2024.110345},
	doi = {10.1016/J.COMNET.2024.110345},
	timestamp = {Mon, 03 Mar 2025 21:30:47 +0100},
	biburl = {https://dblp.org/rec/journals/cn/WengleELVD24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper proposes a distributed, JANUS-based protocol that enables an underwater acoustic network to reach consensus on arbitrary local opinions as numeric state variables. An envisioned scenario where nodes shall agree on parameters describing the acoustic environment is used to evaluate the protocol. The scenario exemplifies the protocol’s potential in future applications where nodes use the environment description to decide on appropriate modulation and coding schemes.}
}


@article{DBLP:journals/cn/IqbalC24,
	author = {Muhammad Shahid Iqbal and
                  Chien Chen},
	title = {Instant queue occupancy used for automatic traffic scheduling in data
                  center networks},
	journal = {Comput. Networks},
	volume = {244},
	pages = {110346},
	year = {2024},
	url = {https://doi.org/10.1016/j.comnet.2024.110346},
	doi = {10.1016/J.COMNET.2024.110346},
	timestamp = {Fri, 31 May 2024 21:06:36 +0200},
	biburl = {https://dblp.org/rec/journals/cn/IqbalC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Datacenter applications desire low latency for short messages to provide a better user experience. Therefore, one of the goals of datacenter networks is to minimize flow completion time (FCT), especially for short flows. Multiple scheduling disciplines have been proposed to achieve this goal. In this paper, we develop a Dynamic Longer Stay Less Priority (D-LSLP) which looks at the current queue occupancy to adjust the demotion threshold for the packets of the flows arriving in the strict priority queues. Initially, D-LSLP considers every flow to be a short flow, and with the passage of time, the flow is demoted to the lower priority queue, similar to Multilevel Feedback Queue (MLFQ) Scheduling. It enables short flows to be completed in a couple of higher-priority queues. In contrast, large flows are demoted to the lower priority queues after remaining active in the queues for a certain amount of time (demotion threshold). However, for the different traffic patterns with different distribution of flow lengths, the demotion threshold for the flows should be adapted automatically. In this paper, we leverage the programmable nature of the P4 switches to measure the instant queue occupancy in the P4, which can be used to adjust the demotion threshold accordingly for the highest priority queue. This enables D-LSLP to increase or decrease its highest priority demotion threshold based on the instant queue status. D-LSLP allows multiple traffic patterns to coexist without manually tuning the demotion thresholds. Furthermore, it reduces the tail drop in the highest priority queue when many short flows overwhelm the highest priority queue. The performance evaluation shows that it works equally well for different traffic patterns without operator intervention.}
}


@article{DBLP:journals/cn/BilirCC24,
	author = {Emin Bilir and
                  Murtaza Cicioglu and
                  Ali {\c{C}}alhan},
	title = {Hybrid cell handover strategy for O-RAN-based campus networks},
	journal = {Comput. Networks},
	volume = {244},
	pages = {110347},
	year = {2024},
	url = {https://doi.org/10.1016/j.comnet.2024.110347},
	doi = {10.1016/J.COMNET.2024.110347},
	timestamp = {Tue, 18 Jun 2024 09:55:53 +0200},
	biburl = {https://dblp.org/rec/journals/cn/BilirCC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent years, the concept of Open Radio Access Network (O-RAN) has become a prominent and ongoing research area in mobile communications, as mobile operators strive to enhance the intelligence, efficiency, and vendor independence of their RAN (Radio Access Network) architectures and components. O-RAN aims to virtualize and improve RAN functions in software and therefore it supports virtualized RANs where disaggregated network components of multiple vendors are connected via open interfaces. O-RAN is a concept based on interoperability and standardization of RAN elements including a unified interconnection standard for white-box hardware and open-source software elements from different vendors. Architecture integrates a modular base station software stack on off-the-shelf hardware which allows baseband and radio unit components from different suppliers to operate seamlessly together. Analyzing and examining the O-RAN architecture in terms of various network scenarios and different network policies is crucial for next-generation networks. This study begins by discussing the O-RAN architecture and its advantages in detail. Subsequently, a campus network has been proposed for the analysis and simulation of the O-RAN architecture, and performance analyses have been performed within the scope of different scenarios and network policies. As a result of these analysis, a new hybrid algorithm for cell handovers in the O-RAN architecture has been developed and compared with traditional cell handover methods based on Reference Signal Received Power (RSRP) and Quality of Service (QoS). The results indicate that the proposed hybrid handover algorithm for O-RAN architecture yields better outcomes.}
}


@article{DBLP:journals/cn/HosseiniMMRLB24,
	author = {Soheil Hosseini and
                  Ignacio de Miguel and
                  Noem{\'{\i}} Merayo and
                  Ram{\'{o}}n de la Rosa and
                  Rub{\'{e}}n M. Lorenzo and
                  Ram{\'{o}}n J. Dur{\'{a}}n Barroso},
	title = {Energy efficient multipath routing in space division multiplexed elastic
                  optical networks},
	journal = {Comput. Networks},
	volume = {244},
	pages = {110349},
	year = {2024},
	url = {https://doi.org/10.1016/j.comnet.2024.110349},
	doi = {10.1016/J.COMNET.2024.110349},
	timestamp = {Tue, 18 Jun 2024 09:26:12 +0200},
	biburl = {https://dblp.org/rec/journals/cn/HosseiniMMRLB24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper introduces a novel dynamic multipath routing, modulation level, spatial and spectrum assignment algorithm for space division multiplexing (SDM) enabled elastic optical networks (EON) with the aim of minimizing the blocking probability and the energy consumed by bandwidth variable transponders (BVTs). The adopted multipath routing strategy allows the splitting of the demand into several sublightpaths using different fiber cores but ensuring that all of them utilize the same set of fibers in order to avoid differential delay. The method also imposes continuity constraints in both spectrum and core location in order to use cost-effective SDM Reconfigurable Optical Add and Drop Multiplexers (ROADMs) without lane change support. The complete usage of multi-core fibers (MCFs) in this kind of networks is restricted due to inter-core crosstalk (XT), which can reduce the quality of received signals. Therefore, the method besides using the most effective modulation format, also ensures that the XT of the lightpaths (or sublightpaths) does not exceed the threshold for each modulation format. A simulation study comparing our method with another similar proposal from the literature is presented for different types of topologies in terms of link distances. Simulation results demonstrate that the proposed multipath routing algorithm in networks including links close to or beyond 1000 km significantly boost the dynamic performance in terms of blocking probability, energy consumption, and latency.}
}


@article{DBLP:journals/cn/HakiriGYM24,
	author = {Akram Hakiri and
                  Aniruddha Gokhale and
                  Sadok Ben Yahia and
                  Nedra Mellouli},
	title = {A comprehensive survey on digital twin for future networks and emerging
                  Internet of Things industry},
	journal = {Comput. Networks},
	volume = {244},
	pages = {110350},
	year = {2024},
	url = {https://doi.org/10.1016/j.comnet.2024.110350},
	doi = {10.1016/J.COMNET.2024.110350},
	timestamp = {Fri, 31 May 2024 21:06:36 +0200},
	biburl = {https://dblp.org/rec/journals/cn/HakiriGYM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The rapid growth of industrial digitalization in the Industry 4.0 era is fundamentally transforming the industrial sector by connecting products, machines, and people, offering real-time digital models to allow self-diagnosis, self-optimization and self-configuration. However, this uptake in such a digital transformation faces numerous obstacles. For example, the lack of real-time data feeds to perform custom closed-loop control and realize common, powerful industrial systems, the complexity of traditional tools and their inability in finding effective solutions to industry problems, lack of capabilities to experiment rapidly on innovative ideas, and the absence of continuous real-time interactions between physical objects and their simulation representations along with reliable two-way communications, are key barriers towards the adoption of such a digital transformation. Digital twins hold the promise of improving maintainability and deployability, enabling flexibility, auditability, and responsiveness to changing conditions, allowing continuous learning, monitoring and actuation, and allowing easy integration of new technologies in order to deploy open, scalable and reliable Industrial Internet of Things (IIoT).}
}


@article{DBLP:journals/cn/NetoHDFM24,
	author = {H{\'{e}}lio N. Cunha Neto and
                  Jernej Hribar and
                  Ivana Dusparic and
                  Natalia Castro Fernandes and
                  Diogo M. F. Mattos},
	title = {FedSBS: Federated-Learning participant-selection method for Intrusion
                  Detection Systems},
	journal = {Comput. Networks},
	volume = {244},
	pages = {110351},
	year = {2024},
	url = {https://doi.org/10.1016/j.comnet.2024.110351},
	doi = {10.1016/J.COMNET.2024.110351},
	timestamp = {Fri, 31 May 2024 21:06:36 +0200},
	biburl = {https://dblp.org/rec/journals/cn/NetoHDFM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated Learning (FL) is a decentralized machine learning approach in which multiple participants collaboratively train a model. Participants keep data locally, train their local models, and aggregate them in a single global model in a federated server. Collaborative FL-based Intrusion Detection Systems face challenges on an uneven statistical distribution of data and malicious participants trying to subvert the learning process. The statistical hurdles associated with imbalanced data and malicious participants pose a risk of skewing the training with biased or random data. The inability to effectively manage these statistical inconsistencies may degrade system performance, leading to false intrusion detection or opening avenues for cybersecurity breaches. To overcome these challenges, we propose a training method that employs score-based participant selection and utilizes global momentum for model aggregation. Our method improves the global model performance while mitigating the risks posed by malicious participants. The proposal incorporates a scoring system based on an information gain variant to evaluate each participant’s contribution. The scoring system and an epsilon greedy selection method ensure robust participant selection in each aggregation round. Furthermore, incorporating a global momentum term helps preserve previous knowledge at each aggregation round, contributing to model stability and overall learning. The proposed solution has demonstrated superior performance, delivering 80% F1-Score and 90% accuracy on experiments even in the presence of malicious participants, revealing the robustness and effectiveness of the proposal in mitigating statistical challenges. Consequently, the proposed method significantly enhances the performance of federated learning models, leading to more secure and efficient collaborative intrusion detection systems.}
}


@article{DBLP:journals/cn/KumarA24a,
	author = {Neeraj Kumar and
                  Rifaqat Ali},
	title = {Blockchain-enabled authentication framework for Maritime Transportation
                  System empowered by 6G-IoT},
	journal = {Comput. Networks},
	volume = {244},
	pages = {110353},
	year = {2024},
	url = {https://doi.org/10.1016/j.comnet.2024.110353},
	doi = {10.1016/J.COMNET.2024.110353},
	timestamp = {Mon, 03 Mar 2025 21:30:44 +0100},
	biburl = {https://dblp.org/rec/journals/cn/KumarA24a.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent years, Maritime Transportation Systems (MTS) have experienced significant advancements through the adoption of Internet of Things (IoT) technology. The introduction of 6G mobile networks has further expanded possibilities by offering enhanced communication services and additional functionalities such as processing, caching, sensing, and control for a wide array of IoT devices. Despite these technological advancements, the integration of IoT and 6G has introduced new risks and challenges in terms of safety and reliability. The involvement of various maritime stakeholders in scheduling and managing marine transportation exacerbates these challenges. Moreover, the MTS has encountered escalating security and privacy concerns with unauthorized data access and message tampering pose significant vulnerabilities in the 6G-IoT-enabled MTS environment. Therefore, a shared and controlled access mechanism that cannot be manipulated or tampered with by unauthorized parties is also an essential requirement in MTS. To address these issues, this paper presents an authentication framework leveraging blockchain technology, specifically designed for 6G-IoT-enabled MTS. The objective is to handle real-time data using decentralized peer-to-peer cloud servers with minimal latency, all while addressing security and privacy concerns specific to MTS. This integration also serves to mitigate various security threats. The protocol’s security and privacy are verified through rigorous evaluations, including the ROR model, Scyther tool, and informal security analysis. A simulation of the proposed protocol using MIRACL is conducted, offering a comprehensive assessment of its computational costs and security features when compared to existing protocols, demonstrating its superior security and efficiency.}
}


@article{DBLP:journals/cn/BingolPFA24,
	author = {G{\"{u}}lnaziye Bing{\"{o}}l and
                  Simone Porcu and
                  Alessandro Floris and
                  Luigi Atzori},
	title = {WebRTC-QoE: {A} dataset of QoE assessment of subjective scores, network
                  impairments, and facial {\&} speech features},
	journal = {Comput. Networks},
	volume = {244},
	pages = {110356},
	year = {2024},
	url = {https://doi.org/10.1016/j.comnet.2024.110356},
	doi = {10.1016/J.COMNET.2024.110356},
	timestamp = {Sun, 04 Aug 2024 19:48:53 +0200},
	biburl = {https://dblp.org/rec/journals/cn/BingolPFA24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the realm of real-time communications, WebRTC-based multimedia applications are increasingly prevalent as these can be smoothly integrated within Web browsing sessions. The browsing experience is then significantly improved with respect to scenarios where browser add-ons and/or plug-ins are used; still, the end user's Quality of Experience (QoE) in WebRTC sessions may be affected by network impairments, such as delays and losses. Due to the variability in user perceptions under different communications scenarios, comprehending and enhancing the resulting service quality is a complex endeavor. To address this, we present a dataset that provides a comprehensive perspective on the conversational quality of a two-party WebRTC-based audiovisual telemeeting service. This dataset was gathered through subjective evaluations involving 20 subjects across 15 different test conditions (TCs). A specialized system was developed to induce controlled network disruptions such as delay, jitter, and packet loss rate, which adversely affected the communication between the parties. This methodology offered an insight into user perceptions under various network impairments. The dataset encompasses a blend of objective and subjective data including ACR (Absolute Category Rating) subjective scores, WebRTC-internals parameters, facial expressions features, and speech features. Consequently, it serves as a substantial contribution to the improvement of WebRTC-based video call systems, offering practical and real-world data that can drive the development of more robust and efficient multimedia communication systems, thereby enhancing the user's experience.}
}
