@article{DBLP:journals/cn/NasserFFAI22,
	author = {Nidal Nasser and
                  Zubair Md. Fadlullah and
                  Mostafa M. Fouda and
                  Asmaa Ali and
                  Muhammad Imran},
	title = {A lightweight federated learning based privacy preserving {B5G} pandemic
                  response network using unmanned aerial vehicles: {A} proof-of-concept},
	journal = {Comput. Networks},
	volume = {205},
	pages = {108672},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2021.108672},
	doi = {10.1016/J.COMNET.2021.108672},
	timestamp = {Tue, 15 Mar 2022 10:20:17 +0100},
	biburl = {https://dblp.org/rec/journals/cn/NasserFFAI22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The concept of an intelligent pandemic response network is gaining momentum during the current novel coronavirus disease (COVID-19) era. A heterogeneous communication architecture is essential to facilitate collaborative and intelligent medical analytics in the fifth generation and beyond (B5G) networks to intelligently learn and disseminate pandemic-related information and diagnostic results. However, such a technique raises privacy issues pertaining to the health data of the patients. In this paper, we envision a privacy-preserving pandemic response network using a proof-of-concept, aerial–terrestrial network system serving mobile user entities/equipment (UEs). By leveraging the unmanned aerial vehicles (UAVs), a lightweight federated learning model is proposed to collaboratively yet privately learn medical (e.g., COVID-19) symptoms with high accuracy using the data collected by individual UEs using ambient sensors and wearable devices. An asynchronous weight updating technique is introduced in federated learning to avoid redundant learning and save precious networking as well as computing resources of the UAVs/UEs. A use-case where an Artificial Intelligence (AI)-based model is employed for COVID-19 detection from radiograph images is presented to demonstrate the effectiveness of our proposed approach.}
}


@article{DBLP:journals/cn/LiFOCS22,
	author = {Wenhao Li and
                  Hamid Reza Faragardi and
                  Mustafa {\"{O}}zger and
                  Cicek Cavdar and
                  Bj{\"{o}}rn Skubic},
	title = {Cost aware service selection in a mobile edge marketplace},
	journal = {Comput. Networks},
	volume = {205},
	pages = {108680},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2021.108680},
	doi = {10.1016/J.COMNET.2021.108680},
	timestamp = {Tue, 26 Mar 2024 21:21:09 +0100},
	biburl = {https://dblp.org/rec/journals/cn/LiFOCS22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A marketplace plays an important role that bridges between Mobile Edge Infrastructure Services (EISs) providers and their customers, also manages relations between actors in a mobile edge ecosystem. One of the key services of the marketplace is service selection where not only a list of EISs matching the customers’ demands is provided but also enables service selection based on the customers’ requirements to fully automate the process. In this paper, we first investigate important attributes of EISs (such as coverage area, latency models, pricing models, etc.), and requirements of edge-based applications (such as latency and reliability) for EIS selection in a marketplace. We then formulate an optimization problem to choose the right set of EISs among available services in the marketplace. We propose two service selection algorithms, i.e., Best Fit (BF) and an Improved version of BF (IBF) to minimize the monetary cost of selected services subject to latency, reliability constraints and customer requirements. The evaluation shows that IBF has 4% improvement in monetary cost as compared to the BF. IBF has only 1% deviation from the optimal solution generated by a brute force algorithm, while it is 189 times faster than the brute force. Accordingly, IBF not only outperforms BF in terms of monetary costs but also achieves the optimal solution as compared to the brute force algorithm in significantly lower execution time. Furthermore, IBM CPLEX Optimizer is also implemented to solve the considered problem to have more concrete evaluation. The results indicate that although CPLEX can also solve the problem with the optimal result, its computing time is still dramatically worse than IBF.}
}


@article{DBLP:journals/cn/KukE22,
	author = {Ekber {\c{C}}etin K{\"{u}}k and
                  M{\"{u}}ge Erel{-}{\"{O}}z{\c{c}}evik},
	title = {Access protocol aware controller design for eMBB traffic in {SD-CDN}},
	journal = {Comput. Networks},
	volume = {205},
	pages = {108686},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2021.108686},
	doi = {10.1016/J.COMNET.2021.108686},
	timestamp = {Tue, 15 Mar 2022 10:20:17 +0100},
	biburl = {https://dblp.org/rec/journals/cn/KukE22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Under a tremendous increase in 5th Generation (5G) traffic, the conventional Domain Name Server(DNS)-based routing in Content Delivery Network (CDN) cannot meet enhanced Mobile BroadBand (eMBB) communication requirements. It routes the traffic flow to the local CDN server which is closest to the end-user geographically using Border Gateway Protocol (BGP). Therefore; the overloading in the local CDN server is inevitable. According to literature, the access types of eMBB content achieve a higher hit-ratio in CDN caching and the anycast-based routing can redirect some of the traffic flows to the original server despite having a geographical disadvantage. Therefore, we consider access protocol types of a user such as TCP-based Hyper-Text Transfer Protocol 2 (HTTP2) and Quick User Datagram Protocol Internet Connections (QUIC) which are commonly used today in iphone Operating System (ioS) and Android-based applications. However, they do not have a central view to select optimal server according to access type in CDN and they are unaware of network dynamics such as protocol-based load and heterogeneity; i.e. the number of total matches packets and the ratio of the packets according to access protocols (HTTP2/QUIC). Therefore, we propose access protocol aware Software Defined Content Delivery Networks (SD-CDN) for eMBB traffic which decouples Data and Control planes and enables easy implementation of anycast routing on this infrastructure. It dynamically takes statistics from OpenFlow switches in the Data plane to calculate a novel load and the heterogeneity metrics per device periodically. It embeds the OpenFlow rules by using a novel access protocol-aware routing algorithm in SD-CDN. According to performance evaluation in a real test-bed environment; the Quality of Server (QoS) of received eMBB content by end-user from either the local or the original CDN servers, the proposed SD-CDN outputs 60% better PSNR than the conventional DNS-based routing with an acceptable rate for 5G requirements.}
}


@article{DBLP:journals/cn/BagiesBMK22,
	author = {Enas Bagies and
                  Ahmed Barnawi and
                  Saoucene Mahfoudh and
                  Neeraj Kumar},
	title = {Content delivery network for IoT-based Fog Computing environment},
	journal = {Comput. Networks},
	volume = {205},
	pages = {108688},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2021.108688},
	doi = {10.1016/J.COMNET.2021.108688},
	timestamp = {Tue, 07 May 2024 20:23:15 +0200},
	biburl = {https://dblp.org/rec/journals/cn/BagiesBMK22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the continuous improvement and evolution of network technologies like IoT which demands the innovation and improvement of legacy networks, as well as, the requirements of end users’ Quality of Service (QoS) and Quality of Experience (QoE), new network paradigms have been invented, such as, Content Delivery Network (CDN), IoT and Fog Computing. In addition, the management and controlling of such a network may create an overhead to the network administrators. Therefore, Software-defined Network (SDN) has been introduced as a framework for managing and controlling the network devices where the network abstraction facilitates the introduction innovative solutions and improve the overall performance. In this paper, an SDN based architecture to implement fog-based CDN network was proposed aiming at further improvement on the routing functionalities essential in Fog-based CDN deployment. We have tested the proposed architecture and the results show significant gains. Moreover, we have identified some factors to be considered in such architectures for further performance improvement.}
}


@article{DBLP:journals/cn/CaoJHZQYL22,
	author = {Tuo Cao and
                  Yibo Jin and
                  Xiongfeng Hu and
                  Sheng Zhang and
                  Zhuzhong Qian and
                  Baoliu Ye and
                  Sanglu Lu},
	title = {Adaptive provisioning for mobile cloud gaming at edges},
	journal = {Comput. Networks},
	volume = {205},
	pages = {108704},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2021.108704},
	doi = {10.1016/J.COMNET.2021.108704},
	timestamp = {Wed, 23 Feb 2022 18:55:40 +0100},
	biburl = {https://dblp.org/rec/journals/cn/CaoJHZQYL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Mobile cloud gaming (MCG), which is proposed to deliver high-quality gaming experience to users anywhere and anytime, suffers from tremendous wide-area traffic and long network delays. In order to shorten the delays and provide the gaming services in close proximity to end users, the mobile edge computing (MEC) is envisioned as a promising approach to enable related computations at the edge of the network. Unfortunately, the performance of MEC-enabled MCG highly depends on the provisioning of both gaming services and bandwidth, since the quality of gaming experience (QoE) is easily impaired by both delays and video frame rates. Furthermore, due to the erratic mobility of users, migrating the services accordingly actually decreases the QoE impairment, but incurs extra system cost, leading to the performance-cost tradeoff. In order to address these challenges, we jointly investigate adaptive service placement and bandwidth allocation for MEC-enabled MCG. Considering the system dynamics, we propose to minimize the QoE impairment in a long-term scope, under the constrained cost for migrations. We design an online two-layer iterative algorithm (OnTrial) to solve the problem. Theoretical analysis demonstrates that OnTrial achieves a near-optimal performance and the potential violation of the migration constraint is bounded. Extensive experiments with real-world traces confirm that OnTrial outperforms other algorithms regarding the long-term QoE impairment for games.}
}


@article{DBLP:journals/cn/NasirKKF22,
	author = {Muhammad Hassan Nasir and
                  Salman A. Khan and
                  Muhammad Mubashir Khan and
                  Mahawish Fatima},
	title = {Swarm Intelligence inspired Intrusion Detection Systems - {A} systematic
                  literature review},
	journal = {Comput. Networks},
	volume = {205},
	pages = {108708},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2021.108708},
	doi = {10.1016/J.COMNET.2021.108708},
	timestamp = {Tue, 15 Mar 2022 10:20:17 +0100},
	biburl = {https://dblp.org/rec/journals/cn/NasirKKF22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {An Intrusion Detection System (IDS) is one of the fundamental building blocks in securing a network. A huge number of techniques have been proposed and implemented to improve the performance and accuracy of intrusion detection models. In recent years, efforts have been made to keep the attack surface as small as possible. However, the attack vectors have evolved in terms of complexity and diversity, and various intelligent techniques have been employed by the adversaries to exploit the ecosystems. This exploitation can either make the whole system dysfunctional or may lead to important information leakage. More specifically, with the evolution of Internet of Things (IoT), more heterogeneous and resource-constrained devices are interconnecting with each other. These devices have limited processing power and resources, particularly for detecting intrusions. Consequently, Swarm Intelligence (SI) based techniques have received considerable attention, especially in the past decade, as the SI approaches have achieved a decent success rate by optimizing various aspects of an IDS. This paper presents a systematic review with a thorough coverage of articles published between 2010 and 2020 of the state-of-the-art swarm intelligence approaches deployed in various attack surfaces for intrusion detection in various domains. The paper also presents a categorization in accordance with applicability of these SI approaches in improving various aspects of an intrusion detection process. Moreover, the paper also discusses the capabilities and features of various datasets used in experimentation. This aims to help researchers in assessing the capabilities and limitations of SI algorithms to identify security threats and challenges to design and implement an IDS for the detection of cyber attacks in various domains. Moreover, this will also help security individuals in differentiating SI based IDS with traditional ones. As such, the survey would be equally beneficial for the researchers working in the domain of swarm intelligence as well as cybersecurity. The survey highlights certain existing challenges and provides directions to address them effectively. In addition, new research directions are also identified.}
}


@article{DBLP:journals/cn/LinHZYZ22,
	author = {Jie Lin and
                  Lin Huang and
                  Hanlin Zhang and
                  Xinyu Yang and
                  Peng Zhao},
	title = {A Novel Lyapunov based Dynamic Resource Allocation for UAVs-assisted
                  Edge Computing},
	journal = {Comput. Networks},
	volume = {205},
	pages = {108710},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2021.108710},
	doi = {10.1016/J.COMNET.2021.108710},
	timestamp = {Tue, 14 Jan 2025 08:46:29 +0100},
	biburl = {https://dblp.org/rec/journals/cn/LinHZYZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Mobile edge computing (MEC), as a key component in the development of IoT and 5G technologies, can provide extra computation resources in edge servers for mobile devices to complete their computation tasks with low latency and high reliability. Considerable efforts on computation offloading and resource allocation have been developed to reduce the energy consumption and computation latency in edge computing. Nonetheless, the system utility of heterogeneous edge computing system (e.g., UAVs-assisted edge computing), in which multiple unmanned aerial vehicles (UAVs) are involved in an edge computing system to serve as edge servers still needs to be further investigated. To this end, in this paper, we propose a novel Lyapunov based Dynamic Resource Allocation (LDRA) for UAVs-assisted Mobile Edge Computing, which can effectively choose suitable edge servers for mobile devices to offload and complete their computation tasks with low system cost and great system utility of UAVs-assisted edge computing system, as well as acceptable computation latency and great reliability for computation tasks of mobile devices. Particularly, a random queue model for edge servers is conducted in our LDRA scheme to support the dynamic of offloaded computation tasks of mobile devices. Additionally, a system cost model of UAVs-assisted edge computing is developed considering the combination of multiple constraints, such as both the mobility of UAVs and mobile devices, energy consumption, communication cost, etc. With the objective of minimizing the system cost and maximizing the system utility in providing edge resources to complete the offloaded computation tasks of mobile devices, by introducing Lyapunov optimization, a dynamic resource allocation scheme is proposed to effectively determine edge servers to offload tasks of mobile devices with considering both the real-time execution state of offloaded tasks in edge servers and states of the communication link. Through analysis and performance evaluations, our results show that our proposed LDRA scheme can achieve a great balance between system cost and system stability. Additionally, our results also demonstrate that our LDRA scheme also can achieve better system utility in comparison with existing schemes.}
}


@article{DBLP:journals/cn/CasarPST22,
	author = {Matthias C{\"{a}}sar and
                  Tobias Pawelke and
                  Jan Steffan and
                  Gabriel Terhorst},
	title = {A survey on Bluetooth Low Energy security and privacy},
	journal = {Comput. Networks},
	volume = {205},
	pages = {108712},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2021.108712},
	doi = {10.1016/J.COMNET.2021.108712},
	timestamp = {Mon, 28 Aug 2023 21:39:18 +0200},
	biburl = {https://dblp.org/rec/journals/cn/CasarPST22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Since its introduction in 2009, Bluetooth Low Energy (BLE) has become a remarkable success. Due to its unique properties of low power requirements and its ubiquitous availability in practically every smartphone, it outnumbered classic Bluetooth BR/EDR in most areas. It enabled a multitude of new product categories like smart watches or connected health care devices that would not be feasible without such a technology. We are currently facing version 5.2 of the specification which is the result of a number of major and minor revisions, each fixing problems of earlier versions while adding new features and capabilities. This includes more secure pairing methods, like secure connection pairing. Cyber security was considered from the beginning of the Bluetooth specification and has been improved with each specification release. On the other hand, security weaknesses in the specification as well as in individual Bluetooth stack implementations have been identified. Designing a secure BLE device, or analyzing its security is a complicated task due to the overwhelming number of possible configurations. As the specification introduces constantly new features and subtle changes regarding privacy and security, this will become an even more complex task. To the best of our knowledge, no systematic overview over the current state of BLE does exist that covers the security and privacy properties of the different BLE versions and features including known weaknesses and attacks in a single place. With this survey we want to fill this gap.}
}


@article{DBLP:journals/cn/WangLC22,
	author = {Zhongyu Wang and
                  Tiejun Lv and
                  Zheng Chang},
	title = {Computation offloading and resource allocation based on distributed
                  deep learning and software defined mobile edge computing},
	journal = {Comput. Networks},
	volume = {205},
	pages = {108732},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2021.108732},
	doi = {10.1016/J.COMNET.2021.108732},
	timestamp = {Tue, 15 Mar 2022 10:20:17 +0100},
	biburl = {https://dblp.org/rec/journals/cn/WangLC22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, a software defined mobile edge computing (SD-MEC) in Internet of Things (IoT) is investigated, in which multiple IoT devices choose to offload their computation tasks to an appropriate edge server to support the emerging IoT applications with strict computation-intensive and latency-critical requirements. In considered SD-MEC networks, a joint computation offloading and power allocation problem is proposed to minimize the utility of weighted delay and power consumption in the distributed dense IoT. The optimization problem is a mixed-integer non-linear programming problem and difficult to solve by general optimization tools due to the nonconvexity and complexity. We propose a distributed deep learning based computation offloading and resource allocation (DDL-CORA) algorithm for SD-MEC IoT in which multiple parallel deep neural networks (DNNs) are invoked to generate the optimal offloading decision and resource scheduling. Additionally, we design a shared replay memory mechanism to effectively store newly generated offloading decisions which are further used to train and improve DNNs. The simulation results show that the proposed DDL-CORA algorithm can reduce the system utility on average 7.72% than reference Deep Q-network (DQN) algorithm and 31.9% than reference Branch-and-Bound (BNB) algorithm, and keep a good tradeoff between the complexity and utility performance.}
}


@article{DBLP:journals/cn/CarvalhoG22,
	author = {M{\'{a}}rcio Barbosa de Carvalho and
                  Lisandro Zambenedetti Granville},
	title = {JurisNN: Judging traffic differentiations as network neutrality violations
                  according to the regulation},
	journal = {Comput. Networks},
	volume = {205},
	pages = {108738},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2021.108738},
	doi = {10.1016/J.COMNET.2021.108738},
	timestamp = {Tue, 15 Mar 2022 10:20:17 +0100},
	biburl = {https://dblp.org/rec/journals/cn/CarvalhoG22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Network Neutrality (NN) is a principle that is not taken for granted on the Internet. Instead, it must be enforced by regulation that defines which Traffic Differentiation (TD) practices are allowed or prohibited from being adopted by ISPs. Thus, the regulation is the proper source of NN definitions to design solutions for detecting NN violations. However, the regulation set by legislators is valid within a geographical area named jurisdiction. Therefore, as an end-to-end network path may traverse multiple jurisdictions, distinct NN definitions along with this path must be considered. Thus, to be effective, solutions based on the regulation must consider where in the end-to-end network path the TD was deployed to evaluate the proper NN definitions stated there. We propose a solution named JurisNN that implements the functionalities required to judge TDs as NN violations considering the regulation. To evaluate the JurisNN judgments, we use TD information collected by a state-of-the-art solution to assess whether this information is enough to judge TDs as NN violations by analyzing the conclusiveness of the results (the TD is an NN violation or not). The results show that to help the signaling of NN violations according to the regulation solutions need both to collect the network paths traversed by tests and to pinpoint where the TD was deployed with better accuracy.}
}


@article{DBLP:journals/cn/AumayrCBDAGKBGK22,
	author = {Erik Aumayr and
                  Giuseppe Caso and
                  Anne{-}Marie Bosneag and
                  Almudena D{\'{\i}}az{-}Zayas and
                  {\"{O}}zg{\"{u}} Alay and
                  Bruno Garc{\'{\i}}a and
                  Konstantinos Kousias and
                  Anna Brunstr{\"{o}}m and
                  Pedro Merino G{\'{o}}mez and
                  Harilaos Koumaras},
	title = {Service-based Analytics for 5G open experimentation platforms},
	journal = {Comput. Networks},
	volume = {205},
	pages = {108740},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2021.108740},
	doi = {10.1016/J.COMNET.2021.108740},
	timestamp = {Tue, 21 Mar 2023 21:08:28 +0100},
	biburl = {https://dblp.org/rec/journals/cn/AumayrCBDAGKBGK22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A scalable, flexible and reliable Analytics service has become a requirement toward building efficient Fifth Generation (5G) experimental platforms that can support a suite of end-user experiments and verticals. Our paper presents the challenges that come with designing such a service-based Analytics component, and shows how we have used it in the context of open experimental platforms in the 5GENESIS project. Our Analytics service was designed both for enabling the efficient setup and configuration of the underlying platform, and also for ensuring that it provides useful insights into the experimentation Key Performance Indicators (KPIs) toward the end-user. Thus, Analytics proved to be a useful tool across several stages, starting from ensuring correct operation during the initial phases of the network setup and continuing into the normal day-to-day experimentation. Our experiments show how the tool was used in our setup and provide information on how to apply it to different environments. The Analytics component, designed as a set of microservices that serve several goals in the analytics workflow, is also provided as open source, being part of the Open5Genesis suite.}
}


@article{DBLP:journals/cn/SalehiBHC22,
	author = {Majid Salehi and
                  Gilles De Borger and
                  Danny Hughes and
                  Bruno Crispo},
	title = {NemesisGuard: Mitigating interrupt latency side channel attacks with
                  static binary rewriting},
	journal = {Comput. Networks},
	volume = {205},
	pages = {108744},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2021.108744},
	doi = {10.1016/J.COMNET.2021.108744},
	timestamp = {Fri, 13 May 2022 19:52:44 +0200},
	biburl = {https://dblp.org/rec/journals/cn/SalehiBHC22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Internet of Things (IoT) is becoming integrated into nearly every aspect of our modern life. Indeed, exploitation of such devices can directly lead to physical consequences in the real world. Previous work has shown that IoT devices can be compromised by exploits in lower software layers such as the Operating System (OS). Embedded Trusted Execution Environments (TEEs) provide a small Trusted Computing Base (TCB) to protect sensitive codes and data in such devices. TEEs assume a strong threat model where even a privileged attacker (e.g. OS) cannot compromise the confidentiality and integrity of the execution. Nevertheless, it has been shown that side channel attacks make it challenging to keep secrets during application execution.}
}


@article{DBLP:journals/cn/WangGWZ22,
	author = {Yang Wang and
                  Marco Giordani and
                  Xiangming Wen and
                  Michele Zorzi},
	title = {On the beamforming design of millimeter wave {UAV} networks: Power
                  vs. capacity trade-offs},
	journal = {Comput. Networks},
	volume = {205},
	pages = {108746},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2021.108746},
	doi = {10.1016/J.COMNET.2021.108746},
	timestamp = {Tue, 15 Mar 2022 10:20:17 +0100},
	biburl = {https://dblp.org/rec/journals/cn/WangGWZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The millimeter wave (mmWave) technology enables unmanned aerial vehicles (UAVs) to offer broadband high-speed wireless connectivity in 5G/6G networks. However, the limited footprint of a single UAV implementing analog beamforming (ABF) requires multiple aerial stations to operate in swarms to provide ubiquitous network coverage, thereby posing serious constraints in terms of battery power consumption. A possible remedy is to investigate the concept of hybrid beamforming (HBF) transceivers, which use a combination of analog beamformers to achieve higher flexibility in the beamforming design. This approach permits multiple ground users to be served simultaneously by the same UAV, despite involving higher energy consumption than its ABF counterpart. This paper presents a tractable stochastic analysis to characterize the ergodic capacity and power consumption of UAV mmWave networks, focusing on the trade-off between ABF and HBF architectures. A multi-beam coverage model is derived as a function of several UAV-specific parameters, including the number of UAVs, the deployment altitude, the antenna configuration, and the beamforming design. Our results show that, while ABF achieves better ergodic capacity at high altitudes, an HBF configuration with multiple beams, despite the use of more individually power-hungry RF blocks, always consumes less total power with limited capacity degradation.}
}


@article{DBLP:journals/cn/LiuZWX22,
	author = {Linfeng Liu and
                  Zhipeng Zhang and
                  Jiagao Wu and
                  Jia Xu},
	title = {Entropy optimization of degree distributions against security threats
                  in UASNs},
	journal = {Comput. Networks},
	volume = {205},
	pages = {108747},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2021.108747},
	doi = {10.1016/J.COMNET.2021.108747},
	timestamp = {Mon, 28 Aug 2023 21:39:20 +0200},
	biburl = {https://dblp.org/rec/journals/cn/LiuZWX22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Underwater Acoustic Sensor Networks (UASNs) are deployed for various underwater applications, such as underwater creature tracking and tactical surveillance. Particularly, an UASN deployed in military applications could be invaded by some underwater spy-robots which act as eavesdroppers or hackers. An UASN is confronted with two typical security threats: the eavesdroppers move around the anchored nodes and eavesdrop on the communication channels silently, and the data messages disseminated from the anchored nodes are probably stolen by these eavesdroppers; the hackers disguise themselves and propagate the viruses to infect the anchored nodes in a cascading manner. To reduce the theft probability of data messages and the number of cascading failures (the number of infected nodes) while maintaining the required topology connectivity, an analysis framework is first formulated to investigate the relations between the entropies of degree distributions and the resistances of security threats, and then the entropies of degree distributions are optimized to resist the security threats through appropriately coordinating the communication ranges of anchored nodes. We propose a Topology Control Strategy based on Entropy Optimization (TCSEO). In TCSEO, each anchored node independently sets the initial communication range according to a binomial distribution, and then the communications ranges of anchored nodes are checked and adjusted to maintain the required topology connectivity. Simulation results demonstrate the preferable performance of TCSEO, i.e. TCSEO can reduce the theft probability of data messages and the number of infected nodes effectively, while the required topology connectivity is maintained as much as possible.}
}


@article{DBLP:journals/cn/ZhongXCSGL22,
	author = {Hong Zhong and
                  Jinshan Xu and
                  Jie Cui and
                  Xiuwen Sun and
                  Chengjie Gu and
                  Lu Liu},
	title = {Prediction-based dual-weight switch migration scheme for {SDN} load
                  balancing},
	journal = {Comput. Networks},
	volume = {205},
	pages = {108749},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2021.108749},
	doi = {10.1016/J.COMNET.2021.108749},
	timestamp = {Tue, 15 Mar 2022 10:20:17 +0100},
	biburl = {https://dblp.org/rec/journals/cn/ZhongXCSGL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Software-defined networking (SDN) is considered one of the most promising development modes of the future Internet because of advantages such as programmability and centralized administration. A single centralized controller may cause reliability and scalability issues. Although multiple controllers can solve a single centralized controller\n′\ns scalability and reliability problems, a flexible mechanism to balance the load is needed. Traffic loads between controllers can easily lead to unbalanced load distribution between them. For multiple distributed controllers, a prediction-based SDN load balancing dual-weight switch migration scheme is proposed. The scheme considers the past traffic load as historical data to predict the future traffic load. Through predictive technology, we know the time when the controller is overloaded, so that the switch migration operation can be carried out in advance. We also propose a triggered load information algorithm to solve the additional processing and communication overhead of the control plane required for periodic active load information between distributed controllers. Considering the information from the past, the proposed scheme suggests that the management of specific switches be migrated between the controllers. We consider the historical load and future load of the switches and propose a switch migration algorithm with dual-weight, it reduces the frequency of switch migration. Experiments have proved that this scheme can quickly balance the load between controllers and reduce the number of switch migrations.}
}


@article{DBLP:journals/cn/SantosSGKT22,
	author = {Ricardo Santos and
                  Nina Skorin{-}Kapov and
                  Hakim Ghazzai and
                  Andreas Kassler and
                  Gia Khanh Tran},
	title = {Towards the optimal orchestration of steerable mmWave backhaul reconfiguration},
	journal = {Comput. Networks},
	volume = {205},
	pages = {108750},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2021.108750},
	doi = {10.1016/J.COMNET.2021.108750},
	timestamp = {Wed, 23 Feb 2022 18:55:40 +0100},
	biburl = {https://dblp.org/rec/journals/cn/SantosSGKT22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Future generations of mobile networks will require increased backhaul capacity to connect a massive amount of small cells (SCs) to the network. Since having an optical connection to each SC might be infeasible, mmWave links are an interesting alternative due to their large available bandwidth. An advantage of a wireless backhaul is that the topology can be reconfigured to adapt to changing traffic demands, new operator policies, or to rapidly overcome network failures. In this work, we investigate the problem of orchestrating the reconfiguration of mmWave wireless backhaul networks with mechanically steerable antennas assuming green backhaul operation where nodes are turned off when not in use. The orchestration involves scheduling and coordinating the powering on/off of nodes, the rotation of antennas to achieve alignment for link establishment, and setting up and tearing down links to minimize packet loss during the reconfiguration. We model the problem as a Mixed Integer Linear Program (MILP) for optimal orchestration and propose a sub-optimal reduced MILP for larger instances. Numerical results for different topologies using a realistic traffic trace indicate that optimizing reconfiguration orchestration can significantly reduce packet loss in comparison to a straightforward reconfiguration approach, enabling a smooth transition between target mmWave backhaul topologies.}
}


@article{DBLP:journals/cn/ZahediJB22,
	author = {Seyed Reza Zahedi and
                  Shahram Jamali and
                  Peyman Bayat},
	title = {A power-efficient and performance-aware online virtual network function
                  placement in SDN/NFV-enabled networks},
	journal = {Comput. Networks},
	volume = {205},
	pages = {108753},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2021.108753},
	doi = {10.1016/J.COMNET.2021.108753},
	timestamp = {Sun, 02 Oct 2022 15:31:03 +0200},
	biburl = {https://dblp.org/rec/journals/cn/ZahediJB22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recent development of software-defined networks (SDN) and network function virtualization (NFV), makes it feasible to replace dedicated hardware middleboxes with software virtualization to run network functions on general-purpose servers. The main challenge in the NFV is virtual network function placement (VNF-P) which is an NP-hard problem, and thus, heuristics and metaheuristics can be used to solve it. In this paper, a hybrid heuristic-metaheuristic learning model is introduced for online VNF-P. In this model, a multi-criteria heuristic (named MCH) is utilized for online VNF placement and routing, while a metaheuristic based on genetic algorithm (GA) is applied in an offline procedure to learn the hyperparameters of the online MCH model, aims to minimize the total power consumption in the NFV infrastructure. The optimization procedure using GA is performed only once before the main operation of the NFV. Simulation results demonstrate the effectiveness of the MCH-GA learning model against the existing methods.}
}


@article{DBLP:journals/cn/FlorisPAG22,
	author = {Alessandro Floris and
                  Simone Porcu and
                  Luigi Atzori and
                  Roberto Girau},
	title = {A Social IoT-based platform for the deployment of a smart parking
                  solution},
	journal = {Comput. Networks},
	volume = {205},
	pages = {108756},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2021.108756},
	doi = {10.1016/J.COMNET.2021.108756},
	timestamp = {Sat, 09 Apr 2022 12:25:52 +0200},
	biburl = {https://dblp.org/rec/journals/cn/FlorisPAG22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we propose a novel IoT-based smart parking (SP) solution which has been designed to provide information on the status of parking spots offered in on-street parking areas. We mostly focused on the following issues of the state of the art solutions: scalability, interoperability to address the heterogeneity of IoT devices, low energy consumption, and timely prediction of the availability of the parking spots. To this we leverage the Social IoT (SIoT) Lysis environment to create virtual entities of the real world objects involved in the SP system for on-street parking areas. The usage of the social virtual entities allows for addressing the interoperability issues among different types of IoT devices used by separate solutions deployed in adjacent areas. Magnetometer sensors are used to automatically detect the presence of a vehicle in each parking spot and the sensors data are collected through concentrators that cover the whole parking areas through low-energy Wi-Fi. Additionally, a control dashboard has been designed and developed to manage the monitored parking areas and provide responsive data analytics regarding the occupancy of parking areas in the city, which can be accessed through an Android App. Finally, a smart payment service allows the users to automatically pay for the used services making use of Bluetooth beacons. Experiments have been performed with the developed test-bed to show the performance of the system to timely detect the presence of a vehicle and identify the owner ID to trigger the payment procedure.}
}


@article{DBLP:journals/cn/CortesiBST22,
	author = {Eugenio Cortesi and
                  Francesco Bruschi and
                  Stefano Secci and
                  Sami Taktak},
	title = {A new approach for Bitcoin pool-hopping detection},
	journal = {Comput. Networks},
	volume = {205},
	pages = {108758},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2021.108758},
	doi = {10.1016/J.COMNET.2021.108758},
	timestamp = {Tue, 15 Mar 2022 10:20:17 +0100},
	biburl = {https://dblp.org/rec/journals/cn/CortesiBST22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Mining pool hopping is a phenomenon taking place in cryptocurrency networks such that a miner changes of pool overtime, in a regular or recurrent way, to increase its gains related to mining work rewards by the mining pools. This phenomenon is not well understood, also because of the lack of a precise pool-hoppers detection solution. In this paper, we propose a methodology for detecting the pool-hopping behavior in the Bitcoin network; we propose a deterministic framework exploiting the different time windowing phases (rounds, epochs) involved in the rewarding process. Our methodology includes a new algorithm to identify the miners, and a new algorithm to trace the revenue stream distribution. We assess the performance of our approach for the five mining pools with the highest hash rates during two three-month period in 2020 and 2021: we show that the phenomenon is still advantageous in terms of overall gains for the pool-hoppers. We also assess the fairness in stake: the phenomenon was known to be unfair in the beginning of the Bitcoin network due to the simple rewarding methods in place at that time, with single rewards higher for pool-hoppers than for miners; we show that this is no longer true and that the new rewarding policies now guarantee that pool-hopping is fair with respect to miners that do not perform pool-hopping. Nonetheless, we also show that the cumulative gain over time of pool-hoppers can be higher by 33% on median than static miners.}
}


@article{DBLP:journals/cn/LiuLLZLZ22,
	author = {Liang Liu and
                  Lin Liu and
                  Beibei Li and
                  Yi Zhong and
                  Shan Liao and
                  Lei Zhang},
	title = {{MSCCS:} {A} Monero-based security-enhanced covert communication system},
	journal = {Comput. Networks},
	volume = {205},
	pages = {108759},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2021.108759},
	doi = {10.1016/J.COMNET.2021.108759},
	timestamp = {Tue, 07 May 2024 20:23:16 +0200},
	biburl = {https://dblp.org/rec/journals/cn/LiuLLZLZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Existing public blockchain-based covert communication systems are suffering the issues of insufficient robustness, anti-temper modification, and anonymity at both the transaction and network layers. In this paper, to overcome this problem, we propose a novel Monero-based security-enhanced covert communication system, in which a new storage-type covert channel is developed. This channel makes Monero transaction amount as data carrier for covert communication. Then, we devise two new algorithms, respectively for resisting Eclipse attacks and the two existing node crawling attacks. Extensive simulation experiments show that the developed new covert communication channel can achieve higher robustness, anti-detection, and anonymity. The new security-enhanced algorithms can effectively mitigate Eclipse attacks by 37.6%, and the two existing node crawling attacks by 21.1% and 17.1% respectively.}
}


@article{DBLP:journals/cn/WangZHHLZJC22,
	author = {Chonghua Wang and
                  Hao Zhou and
                  Zhiqiang Hao and
                  Shu Hu and
                  Jun Li and
                  Xueying Zhang and
                  Bo Jiang and
                  Xuehong Chen},
	title = {Network traffic analysis over clustering-based collective anomaly
                  detection},
	journal = {Comput. Networks},
	volume = {205},
	pages = {108760},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.108760},
	doi = {10.1016/J.COMNET.2022.108760},
	timestamp = {Sat, 14 Dec 2024 21:39:21 +0100},
	biburl = {https://dblp.org/rec/journals/cn/WangZHHLZJC22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Due to the ever-growing presence of network traffic, there has been a considerable amount of research on anomaly detection in network traffic by clustering. Most of them have not considered the problem that collective anomaly detection in network traffic. Collective anomaly might scatter among multiple clusters when applying the clustering-based algorithms in the anomaly detection. In this paper, we propose a progressive exploration framework for collective anomaly detection on network traffic based on a clustering method, called CCAD. CCAD enables analysts to effectively explore collective anomaly in network traffic. This framework is different from the other anomaly detection methods. It is based on the analysis of the influence of collective anomaly on the clustering results in the network traffic stream data. CCAD framework efficiently supports the collective anomaly exploration. As demonstrated by our extensive experiments with real-world data, CCAD has high detection rate in comparison with other existing methods.}
}


@article{DBLP:journals/cn/LiuQP22,
	author = {Meili Liu and
                  Xiaogang Qi and
                  Hao Pan},
	title = {Construction of network topology and geographical vulnerability for
                  telecommunication network},
	journal = {Comput. Networks},
	volume = {205},
	pages = {108764},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.108764},
	doi = {10.1016/J.COMNET.2022.108764},
	timestamp = {Fri, 12 Jan 2024 21:08:47 +0100},
	biburl = {https://dblp.org/rec/journals/cn/LiuQP22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Telecommunications network is vulnerable to large-scale infrastructure failures caused by physical attacks or natural disasters. Academics view this failure as region failure, which is geographically related and highly localized. Several simplified models have been previously proposed, resulting in an inaccurate characterization of network activity. In this paper, we propose a probability model with full consideration of the actual situation, which gives a more realistic picture of network behavior. In particular, the disaster takes the form of a randomly placed disk in a plane. The research aims to find out disaster locations that can cause significant damage to network performance, i.e., vulnerable areas of the network. The topology of vulnerable areas can be redesigned to improve the network’s disaster survivability. Moreover, only a few special cases need to be judged for the sake of achieving the aim despite disasters occur randomly across the plane. Another primary contribution is our attempt to construct a proper network topology by using clusters as units. Finally, numerical experiments conducted on this network topology demonstrate the applicability of the methodology in realistic scenarios. The work in this paper provides guidance for real-world problems and offers a way to figure them.}
}


@article{DBLP:journals/cn/MuktaPLK22,
	author = {Rahma Mukta and
                  Hye{-}young Paik and
                  Qinghua Lu and
                  Salil S. Kanhere},
	title = {A survey of data minimisation techniques in blockchain-based healthcare},
	journal = {Comput. Networks},
	volume = {205},
	pages = {108766},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.108766},
	doi = {10.1016/J.COMNET.2022.108766},
	timestamp = {Tue, 15 Mar 2022 10:20:17 +0100},
	biburl = {https://dblp.org/rec/journals/cn/MuktaPLK22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The push for digitising personal health records needs to occur with serious consideration of privacy in order to instill public confidence. However, the healthcare sector still experiences leakage of Personally Identifiable Information (PII) due to improper data protection practices and security failures by data custodians. Data minimisation refers to the practice of limiting personal data collection and usage to only what is required to fulfil a specific purpose, and is one of the directives in many privacy regulations and data protection acts. Blockchain technology provides a neutral third-party platform for healthcare applications on which trust can be built to increase confidence in all participating parties to create, store and share sensitive data. However, the aspects of design and implementation of data minimisation techniques within the blockchain context have not been systematically explored and no effort has been made to review and analyse the existing solutions so far. In this paper, we undertake a survey of data minimisation techniques in blockchain-based healthcare systems. We provide a broad definition of data minimisation and classify data minimisation approaches according to the different lifecycle phases of data processing workflows. We also present a comparative analysis on privacy properties achieved by these methods. This study offers a unique view of data minimisation from both data custodians and data owners’ viewpoints, and suggests several areas of future research and development to improve privacy in healthcare through data minimisation.}
}


@article{DBLP:journals/cn/FrontedduPFA22,
	author = {Graziano Fronteddu and
                  Simone Porcu and
                  Alessandro Floris and
                  Luigi Atzori},
	title = {A dynamic hand gesture recognition dataset for human-computer interfaces},
	journal = {Comput. Networks},
	volume = {205},
	pages = {108781},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.108781},
	doi = {10.1016/J.COMNET.2022.108781},
	timestamp = {Sat, 09 Apr 2022 12:25:50 +0200},
	biburl = {https://dblp.org/rec/journals/cn/FrontedduPFA22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Computer vision systems are commonly used to design touch-less human-computer interfaces (HCI) based on dynamic hand gesture recognition (HGR) systems, which have a wide range of applications in several domains, such as, gaming, multimedia, automotive, home automation. However, automatic HGR is still a challenging task, mostly because of the diversity in how people perform the gestures. In addition, the number of publicly available hand gesture datasets is scarce, often the gestures are not acquired with sufficient image quality, and the gestures are not correctly performed. In this data article, we propose a dataset of 27 dynamic hand gesture types acquired at full HD resolution from 21 different subjects, which were carefully instructed before performing the gestures and monitored when performing the gesture; the subjects had to repeat the movement in case the performed hand gesture was not correct, i.e., the authors of this paper that were observing the gesture found that it did not correspond to the exact expected movement and/or the camera recorded a viewpoint did not allow for a plain visualizing of the gesture. Each subject performed 3 times the 27 hand gestures for a total of 1701 videos collected and corresponding 204,120 video frames.}
}


@article{DBLP:journals/cn/Barcelo-ArmadaC22,
	author = {Rub{\'{e}}n Barcel{\'{o}}{-}Armada and
                  Ismael Castell{-}Uroz and
                  Pere Barlet{-}Ros},
	title = {Amazon Alexa traffic traces},
	journal = {Comput. Networks},
	volume = {205},
	pages = {108782},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.108782},
	doi = {10.1016/J.COMNET.2022.108782},
	timestamp = {Fri, 13 May 2022 19:52:44 +0200},
	biburl = {https://dblp.org/rec/journals/cn/Barcelo-ArmadaC22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The number of devices that make up the Internet of Things (IoT) has been increasing every year, including smart speakers such as Amazon Echo devices. These devices have become very popular around the world where users with a smart speaker are estimated to be about 83 million in 2020. However, there has also been great concern about how they can affect the privacy and security of their users [1]. Responding to voice commands requires devices to continuously listen for the corresponding wake word, with the privacy implications that this entails. Additionally, the interactions that users may have with the virtual assistant can reveal private information about the user. In this document we publicly share two datasets that can help conduct privacy and security studies from the Amazon Echo Dot smart speaker. The included data contains 300.000 raw PCAP traces containing all the communications between the device and Amazon servers from 100 different voice commands on two different languages. The data can be used to train machine learning algorithms in order to find patterns that can characterize both, the voice commands and people using the device as well as Alexa as the device generating the traffic.}
}


@article{DBLP:journals/cn/PintorA22,
	author = {Lucia Pintor and
                  Luigi Atzori},
	title = {A dataset of labelled device Wi-Fi probe requests for {MAC} address
                  de-randomization},
	journal = {Comput. Networks},
	volume = {205},
	pages = {108783},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.108783},
	doi = {10.1016/J.COMNET.2022.108783},
	timestamp = {Sat, 09 Apr 2022 12:25:51 +0200},
	biburl = {https://dblp.org/rec/journals/cn/PintorA22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Probe requests are management frames emitted by devices that perform active scanning to connect to Access Points nearby. These messages can be captured and analysed to implement device counting algorithms. However, using random MAC addresses to protect users’ privacy challenges these algorithms, which must then perform address de-randomization (i.e., cluster the frames with the same source device by analysing valuable features). Datasets of labelled probe requests are needed to develop efficient de-randomization algorithms. Our dataset contains 20 min duration captures collected both in isolated and in "noisy" environments. Twenty-two different devices produced data in six different modes, including settings based on display status, Wi-Fi connection, and power saving. For each mode, we considered three channels contemporaneously for a total of 315 non-empty files. A Raspberry Pi captured the messages through a sniffing algorithm specifically designed to generate this dataset. We then filtered the data by deleting the messages from known sources and using power thresholds that exploit the burst structure of the probe requests. To the best of our knowledge, there are no other available datasets with labelled probe requests. This kind of dataset allows a more accurate analysis of the behaviour of individual devices in different modes and the training and test of algorithms for counting the number of devices through probe requests in the presence of random MAC addresses.}
}
