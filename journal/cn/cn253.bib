@article{DBLP:journals/cn/QinZHZDGG24,
	author = {Xin Qin and
                  Wenwu Zhu and
                  Qian Hu and
                  Zexi Zhou and
                  Yi Ding and
                  Xia Gao and
                  Rentao Gu},
	title = {DenseNet-Transformer: {A} deep learning method for spatial-temporal
                  traffic prediction in optical fronthaul network},
	journal = {Comput. Networks},
	volume = {253},
	pages = {110674},
	year = {2024},
	url = {https://doi.org/10.1016/j.comnet.2024.110674},
	doi = {10.1016/J.COMNET.2024.110674},
	timestamp = {Sun, 08 Sep 2024 16:07:18 +0200},
	biburl = {https://dblp.org/rec/journals/cn/QinZHZDGG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The rapid evolution of 6G Radio Access Networks (RAN) towards virtualization and intelligence is driven by the widespread adoption of high-bandwidth services and the proliferation of mobile communications. Active Antenna Units (AAU) interface with Distributed Units (DU) over Passive Optical Networks (PON), serving as crucial bearers that transmit extensive data through the optical fronthaul network to the core network. However, the escalating demand for high-bandwidth services, coupled with the uneven spatial–temporal traffic patterns influenced by factors such as geographical location and urban functionalities across various base stations, poses significant challenges to the optical fronthaul network in terms of operational costs and resource allocation efficiency. To tackle these challenges, we introduce the DenseNet-Transformer spatial–temporal traffic prediction algorithm tailored specifically for the traffic characteristics of optical fronthaul networks. In DenseNet-Transformer, DenseNet captures spatial feature correlations among nearby traffic in adjacent regions, facilitating enhanced learning of traffic characteristics across distant areas through dense connections. The Transformer component learns both long and short-term temporal dependencies, enhancing the algorithm’s temporal prediction capabilities using multi-head attention mechanisms and positional encoding. We validate the effectiveness of DenseNet-Transformer through a series of ablation experiments and comparative tests against other algorithms under identical conditions. Experimental results on real datasets demonstrate that, in most scenarios, DenseNet-Transformer outperforms existing algorithms for time traffic prediction in both wireless and optical communication domains, as well as spatial–temporal prediction algorithms.}
}


@article{DBLP:journals/cn/ParastarCILA24,
	author = {Paniz Parastar and
                  Giuseppe Caso and
                  Jesus Alberto Oma{\~{n}}a Iglesias and
                  Andra Lutu and
                  Ozgu Alay},
	title = {Rethinking the mobile edge for vehicular services},
	journal = {Comput. Networks},
	volume = {253},
	pages = {110687},
	year = {2024},
	url = {https://doi.org/10.1016/j.comnet.2024.110687},
	doi = {10.1016/J.COMNET.2024.110687},
	timestamp = {Mon, 09 Dec 2024 22:47:18 +0100},
	biburl = {https://dblp.org/rec/journals/cn/ParastarCILA24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The growing connected car market requires mobile network operators (MNOs) to rethink their network architecture to deliver ultra-reliable low-latency communications. In response, Multi-Access Edge Computing (MEC) has emerged as a solution, enabling the deployment of computing resources at the network edge. For MNOs to tap into the potential benefits of MEC, they need to transform their networks accordingly. Consequently, the primary objective of this study is to design a realistic MEC architecture and corresponding optimal deployment strategy – deciding on the placement and configuration of computing resources – as opposed to prior studies focusing on MEC run-time management and orchestration (e.g., service placement, computation offloading, and user allocation). To cater to the heterogeneous demands of vehicular services, we propose a multi-tier MEC architecture aligned with 5G and Beyond-5G radio access network deployments. Therefore, we frame MEC deployment as an optimization problem within this architecture, assuming 3 MEC tiers. Our data-driven evaluation, grounded in realistic assumptions about network architecture, usage, latency, and cost models, relies on datasets from a major MNO in the UK. We show the benefits of adopting a 3-tier MEC architecture over single-tier (centralized or distributed) architectures for heterogeneous vehicular services, in terms of deployment cost, energy consumption, and robustness.}
}


@article{DBLP:journals/cn/TuLKM24,
	author = {Yi{-}Hao Tu and
                  En{-}Cheng Lin and
                  Chih{-}Heng Ke and
                  Yi{-}Wei Ma},
	title = {Enhanced-SETL: {A} multi-variable deep reinforcement learning approach
                  for contention window optimization in dense Wi-Fi networks},
	journal = {Comput. Networks},
	volume = {253},
	pages = {110690},
	year = {2024},
	url = {https://doi.org/10.1016/j.comnet.2024.110690},
	doi = {10.1016/J.COMNET.2024.110690},
	timestamp = {Mon, 09 Dec 2024 22:47:19 +0100},
	biburl = {https://dblp.org/rec/journals/cn/TuLKM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we introduce the Enhanced Smart Exponential-Threshold-Linear (Enhanced-SETL) algorithm, a new approach that uses the multi-variable Deep Reinforcement Learning (DRL) framework to simultaneously optimize multiple settings of the Contention Window (CW) in IEEE 802.11 wireless networks. Unlike traditional DRL methods that adjust only a single CW parameter, our innovative approach simultaneously optimizes both the CW minimum (\nC\nW\nm\ni\nn\n) and CW Threshold (\nC\nW\nT\nh\nr\ne\ns\nh\no\nl\nd\n), significantly improving network traffic control. We utilize a Double Deep Q-learning Network (DDQN) for dynamic updates of these CW settings, broadcasted across the dense Wi-Fi networks. This dual adjustment method, coupled with dynamic, data-driven updates, not only enhances throughput, but also reduces collision rates, and ensures fairness access across both static and dynamic wireless environments. Enhanced-SETL achieves a throughput improvement ranging from 3.55% up to 43.73% and from 3.98% up to 30.15% in static and dynamic scenarios over standard protocols and state-of-the-art DRL models, while maintaining a fairness index near 99% across diverse stations, showcasing its effectiveness and adaptability in various network conditions.}
}


@article{DBLP:journals/cn/LaiTQXZTHL24,
	author = {Pan Lai and
                  Yiran Tao and
                  Jun Qin and
                  Yuanai Xie and
                  Shihua Zhang and
                  Shanjiang Tang and
                  Qirui Huang and
                  Shengquan Liao},
	title = {Joint optimization of application placement and resource allocation
                  for enhanced performance in heterogeneous multi-server systems},
	journal = {Comput. Networks},
	volume = {253},
	pages = {110692},
	year = {2024},
	url = {https://doi.org/10.1016/j.comnet.2024.110692},
	doi = {10.1016/J.COMNET.2024.110692},
	timestamp = {Mon, 26 Aug 2024 09:31:17 +0200},
	biburl = {https://dblp.org/rec/journals/cn/LaiTQXZTHL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Efficiently placing applications remains a critical challenge across diverse multi-server environments, including web hosting centers, cloud computing, and edge computing environments. Unfortunately, most existing studies tend to overlook the crucial aspect of resource allocation, leading to suboptimal system performance. To address this gap, there is a pressing need to holistically explore both application placement and resource allocation in a unified manner. In this paper, we introduce the place and allocate problem in heterogeneous multi-server systems, a novel approach aiming at simultaneously optimizing the placement and allocation of applications to maximize the overall utility of the heterogeneous multi-server system. Our proposed methodology harnesses the interplay between application placement and resource allocation, showcasing substantial improvements in system utility. To model individual application performance concerning their allocated resources, we employ utility functions. For concave utility functions, we present an approximation algorithm that operates efficiently with a time complexity of\nO\n(\nm\nn\n3\n(\nl\no\ng\nC\n)\n2\n)\n, where\nn\nrepresents the number of applications,\nm\nis the number of servers, and\nC\ndenotes the maximum available resource capacity of each server. Furthermore, we extend our approach to accommodate more general scenarios that involve applications with nonconcave utility functions and using multiple types of resources. Our study includes comprehensive experimental evaluations conducted on applications with both synthetic and real-world utility functions. Results consistently showcase that our algorithms achieve over 96.9% of optimal performance on average. Additionally, comparative analysis against several practical heuristics reveal that our algorithms outperform these methods by up to 4.3 times in total utility.}
}


@article{DBLP:journals/cn/LyuZYWFFZ24,
	author = {Zengwei Lyu and
                  Yu Zhang and
                  Xiaohui Yuan and
                  Zhenchun Wei and
                  Yu Fu and
                  Lin Feng and
                  Haodong Zhou},
	title = {Innovative edge caching: {A} multi-agent deep reinforcement learning
                  approach for cooperative replacement strategies},
	journal = {Comput. Networks},
	volume = {253},
	pages = {110694},
	year = {2024},
	url = {https://doi.org/10.1016/j.comnet.2024.110694},
	doi = {10.1016/J.COMNET.2024.110694},
	timestamp = {Mon, 03 Mar 2025 21:30:44 +0100},
	biburl = {https://dblp.org/rec/journals/cn/LyuZYWFFZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cooperative edge caching has emerged as a promising solution to alleviate the traffic burden of backhaul and improve the Quality of Service of 5G applications in the 5G era. Several cooperative edge caching methods alleviate the traffic burden of backhaul by transmitting contents between edge nodes cooperatively, thereby reducing the delay of content transmission. However, these methods have a limited ability to handle complex information in multi-edge scenarios, and they mainly focus on cooperation in content transmission while scarcely considering cooperation in cache replacement. As a result, they cannot effectively utilize the cache space of collaborative edges, leading to suboptimal system utility. In this paper, we propose a cache replacement strategy for cooperative edge caching based on a novel multi-agent deep reinforcement learning network. Firstly, we present a cooperative edge caching model aimed at maximizing the system throughput. Then, we formulate the cache replacement process in the cooperative edge caching system as a Markov Game (MG) model. Finally, we design a Discrete MADDPG algorithm based on a discrete multi-agent actor-critic network to derive the cache replacement strategy and effectively manage content redundancy within the system. Simulation results demonstrate that our proposed algorithm achieves higher system throughput while effectively controlling content redundancy.}
}


@article{DBLP:journals/cn/LeiTW24,
	author = {Lei Lei and
                  Aimin Tang and
                  Xudong Wang},
	title = {Achieving scalable capacity in wireless mesh networks},
	journal = {Comput. Networks},
	volume = {253},
	pages = {110696},
	year = {2024},
	url = {https://doi.org/10.1016/j.comnet.2024.110696},
	doi = {10.1016/J.COMNET.2024.110696},
	timestamp = {Sun, 08 Sep 2024 16:07:18 +0200},
	biburl = {https://dblp.org/rec/journals/cn/LeiTW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Wireless mesh networks are critical in enabling key networking scenarios in beyond-5G (B5G) and 6G networks, including integrated access and backhaul (IAB), multi-hop sidelinks, and V2X. However, it still poses a challenge to deliver scalable per-node throughput via mesh networking. As shown in Gupta and Kumar’s seminal research (Gupta and Kumar, 2000), multi-hop transmission results in a per-node throughput of\nΘ\n(\n1\n/\nn\nlog\nn\n)\nin a wireless network with\nn\nnodes, significantly limiting the potential of large-scale deployment of wireless mesh networks. Follow-up research has achieved\nO\n(\n1\n)\nper-node throughput in a dense network, but how to achieve scalability remains an unresolved issue for an extended wireless network where the network size increases with a constant node density. This issue prevents a wireless mesh network from large-scale deployment. To this end, this paper aims to develop a theoretical approach to achieving scalable per-node throughput in wireless mesh networks. First, the key factors that limit the per-node throughput of wireless mesh networks are analyzed, through which two major ones are identified, i.e., link sharing and interference. Next, a multi-tier hierarchical architecture is proposed to overcome the link-sharing issue. The inter-tier interference under this architecture is then mitigated by utilizing orthogonal frequency allocation between adjacent tiers, while the intra-tier interference is reduced by considering two specific transmission schemes, one is MIMO spatial multiplexing with time-division, the other is MIMO beamforming. Theoretical analysis shows that the multi-tier mesh networking architecture can achieve a per-node throughput of\nΘ\n(\n1\n)\nin both schemes, as long as certain conditions on network parameters including bandwidth, the number of antennas, and the number of nodes of each tier are satisfied. A case study on a realistic deployment of 10,000 nodes is then carried out, which demonstrates that a scalable throughput of\nΘ\n(\n1\n)\nis achievable with a reasonable assumption on bandwidth and the number of antennas.}
}


@article{DBLP:journals/cn/PatilILPPKK24,
	author = {Anita Patil and
                  Sridhar Iyer and
                  Onel Luis Alcaraz L{\'{o}}pez and
                  Rahul Jashvantbhai Pandya and
                  Krishna Pai and
                  Anshuman Kalla and
                  Rakhee Kallimani},
	title = {A comprehensive survey on spectrum sharing techniques for 5G/B5G intelligent
                  wireless networks: Opportunities, challenges and future research directions},
	journal = {Comput. Networks},
	volume = {253},
	pages = {110697},
	year = {2024},
	url = {https://doi.org/10.1016/j.comnet.2024.110697},
	doi = {10.1016/J.COMNET.2024.110697},
	timestamp = {Mon, 03 Mar 2025 21:30:45 +0100},
	biburl = {https://dblp.org/rec/journals/cn/PatilILPPKK24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The increasing popularity of the Internet of Everything and small-cell devices has enormously accelerated traffic loads. Consequently, increased bandwidth and high data rate requirements stimulate the operation at the millimeter wave and the Tera-Hertz spectrum bands in the fifth generation (5G) and beyond 5G (B5G) wireless networks. Furthermore, efficient spectrum allocation, maximizing the spectrum utilization, achieving efficient spectrum sharing (SS), and managing the spectrum to enhance the system performance remain challenging. To this end, recent studies have implemented artificial intelligence and machine learning techniques, enabling intelligent and efficient spectrum leveraging. However, despite many recent research advances focused on maximizing utilization of the spectrum bands, achieving efficient sharing, allocation, and management of the enormous available spectrum remains challenging. Therefore, the current article acquaints a comprehensive survey on intelligent SS methodologies for 5G and B5G wireless networks, considering the applications of artificial intelligence for efficient SS. Specifically, a thorough overview of SS methodologies is conferred, following which the various spectrum utilization opportunities arising from the existing SS methodologies in intelligent wireless networks are discussed. Subsequently, to highlight critical limitations of the existing methodologies, recent literature on existing SS methodologies is reviewed in detail, classifying them based on the implemented technology, i.e., cognitive radio, machine learning, blockchain, and multiple other techniques. Moreover, the related SS techniques are reviewed to highlight significant challenges in the B5G intelligent wireless network. Finally, to provide an insight into the prospective research avenues, the article is concluded by presenting several potential research directions and proposed solutions.}
}


@article{DBLP:journals/cn/LiuWGXQMZ24,
	author = {Ruitong Liu and
                  Yanbin Wang and
                  Zhenhao Guo and
                  Haitao Xu and
                  Zhan Qin and
                  Wenrui Ma and
                  Fan Zhang},
	title = {TransURL: Improving malicious {URL} detection with multi-layer Transformer
                  encoding and multi-scale pyramid features},
	journal = {Comput. Networks},
	volume = {253},
	pages = {110707},
	year = {2024},
	url = {https://doi.org/10.1016/j.comnet.2024.110707},
	doi = {10.1016/J.COMNET.2024.110707},
	timestamp = {Sun, 08 Sep 2024 16:07:18 +0200},
	biburl = {https://dblp.org/rec/journals/cn/LiuWGXQMZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {While machine learning progress is advancing the detection of malicious URLs, advanced Transformers applied to URLs face difficulties in extracting local information, character-level information, and structural relationships. To address these challenges, we propose a novel approach for malicious URL detection, named TransURL, that is implemented by co-training the character-aware Transformer with three feature modules—Multi-Layer Encoding, Multi-Scale Feature Learning, and Spatial Pyramid Attention. This special Transformer allows TransURL to extract embeddings that contain character-level information from URL token sequences, with three feature modules contributing to the fusion of multi-layer Transformer encodings and the capture of multi-scale local details and structural relationships. The proposed method is evaluated across several challenging scenarios, including class imbalance learning, multi-classification, cross-dataset testing, and adversarial sample attacks. The experimental results demonstrate a significant improvement compared to the best previous methods. For instance, it achieved a peak F1-score improvement of 40% in class-imbalanced scenarios, and exceeded the best baseline result by 14.13% in accuracy in adversarial attack scenarios. Additionally, we conduct a case study where our method accurately identifies all 30 active malicious web pages, whereas two pior SOTA methods miss 4 and 7 malicious web pages respectively. The codes and data are available at: https://github.com/Vul-det/TransURL/.}
}


@article{DBLP:journals/cn/XavierDMR24,
	author = {Bruno Missi Xavier and
                  Merim Dzaferagic and
                  Magnos Martinello and
                  Marco Ruffini},
	title = {Performance measurement dataset for open {RAN} with user mobility
                  and security threats},
	journal = {Comput. Networks},
	volume = {253},
	pages = {110710},
	year = {2024},
	url = {https://doi.org/10.1016/j.comnet.2024.110710},
	doi = {10.1016/J.COMNET.2024.110710},
	timestamp = {Sun, 08 Sep 2024 16:07:18 +0200},
	biburl = {https://dblp.org/rec/journals/cn/XavierDMR24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We present a comprehensive dataset collected from an Open-RAN (O-RAN) deployment in our OpenIreland testbed, aimed at facilitating advanced research in Radio Access Network (RAN). The dataset includes RAN measurements from users engaged in diverse traffic classes such as Web Browsing, Voice over IP (VoIP), Internet of Things (IoT), and Video Streaming, as well as malignant traffic classes including DDoS Ripper, DoS Hulk, and Slow Loris attacks. These measurements encompass various mobility patterns, including Static, Pedestrian, Train, Car, and Bus users. While Wi-Fi datasets, including probe requests, Wi-Fi fingerprints, and signal strengths, are common in the literature, and mobile networks present abundant research opportunities with billions of global subscribers, datasets with RAN Key Performance Indicator (KPI) measurements are relatively rare. This scarcity is particularly notable in the context of O-RAN networks, which have been scrutinized for higher potential vulnerability compared to single-vendor solutions. Our work addresses this gap by collecting and publicly sharing a dataset rich in RAN KPIs from our O-RAN deployment. We utilized this dataset to classify different traffic classes for the detection of service-level attacks. Beyond its immediate use for attack detection, the dataset is versatile, supporting research in intrusion detection, network protection strategies, and numerous other RAN-related challenges. By offering extensive performance metrics, this dataset enables researchers to explore issues like power consumption, Channel Quality Indicator (CQI)/Modulation and Coding Scheme (MCS) optimization, resource management, cell characterization, and more. We believe that this dataset will significantly advance the development of robust, efficient, and secure RAN solutions.}
}


@article{DBLP:journals/cn/JiXDZTLLZ24,
	author = {Ruoyu Ji and
                  Fangmin Xu and
                  Shihui Duan and
                  Jinyu Zhu and
                  Yiwen Tao and
                  Meihui Liu and
                  Peng Lv and
                  Chenglin Zhao},
	title = {A cooperative timestamp-free clock synchronization scheme based on
                  fast unscented Kalman filtering for time-sensitive networking},
	journal = {Comput. Networks},
	volume = {253},
	pages = {110711},
	year = {2024},
	url = {https://doi.org/10.1016/j.comnet.2024.110711},
	doi = {10.1016/J.COMNET.2024.110711},
	timestamp = {Sun, 08 Sep 2024 16:07:18 +0200},
	biburl = {https://dblp.org/rec/journals/cn/JiXDZTLLZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Clock synchronization, built on the classical two-way message exchange scheme, is the key prerequisite for the normal operation of time-sensitive networking (TSN). In practical TSN, the imperfect oscillator caused by environmental changes leads to clock parameters drift. Moreover, synchronization errors accumulate in multi-hop networks, making it difficult for nodes at the edge of the network to achieve precise synchronization performance. Additionally, in some industrial and vehicular scenarios, the energy consumption and complexity of clock synchronization are important factors that need to be considered. To address these problems, this paper proposes a cooperative synchronization clock offset and clock skew joint tracking algorithm based on fast Unscented Kalman filter (FUKF). To further reduce the computation and energy consumption caused by clock synchronization, we introduce randomized singular value decomposition and timestamp-free exchange. The former uses small sub-matrices approximations to replace extremely high-dimensional matrices, reducing computational time in the update stage of the UKF. The latter reduces energy consumption by setting response intervals at the receiving end, eliminating the need for timestamp exchange during the synchronization process. Therefore, this algorithm can achieve long-term synchronization without requiring excessive computational and communication overhead. The results show that the proposed method, while maintaining accuracy unchanged, reduced the running time by 20% to 90% as the number of observations increased, thus verifying the effectiveness of the algorithm.}
}


@article{DBLP:journals/cn/PeiYDLH24,
	author = {Hongmei Pei and
                  Peng Yang and
                  Miao Du and
                  Zengyu Liang and
                  Zhongjian Hu},
	title = {Blockchain-assisted Verifiable Secure Multi-Party Data Computing},
	journal = {Comput. Networks},
	volume = {253},
	pages = {110712},
	year = {2024},
	url = {https://doi.org/10.1016/j.comnet.2024.110712},
	doi = {10.1016/J.COMNET.2024.110712},
	timestamp = {Mon, 03 Mar 2025 21:30:45 +0100},
	biburl = {https://dblp.org/rec/journals/cn/PeiYDLH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Secure multi-party computation (SMPC) is a crucial technology that supports privacy preservation, enabling multiple users to perform computations on any function without disclosing their private inputs and outputs in a distrustful environment. Existing secure multi-party computation models typically rely on obfuscation circuits and cryptographic protocols to facilitate collaborative computation of tasks. However, the efficiency and privacy leakage of users have not been paid much attention during the computation process. To address these problems, this article proposes a privacy-preserving approach Blockchain-assisted Verifiable Secure Multi-Party Data Computing (BVS-MPDC). Specifically, to prevent privacy leakage when users and multiple participants share data, BVS-MPDC uses additive homomorphic encryption to encrypt data shares; and verifies the generated Pedersen commitment of all the data. BVS-MPDC utilizes an improved Schnorr aggregation signature to improve computation efficiency between computing nodes and smart contracts by submitting an aggregation signature to the blockchain. Moreover, we design and implement a smart contract for verifying aggregation signature results on Ethereum. The security proof is presented under the UC framework. Finally, simulation experiments of performance evaluations demonstrate that our scheme outperforms existing schemes in computation overhead and verification.}
}


@article{DBLP:journals/cn/EspinLM24,
	author = {Jos{\'{e}} Antonio Parra Esp{\'{\i}}n and
                  Rafael Mar{\'{\i}}n L{\'{o}}pez and
                  Gabriel L{\'{o}}pez Mill{\'{a}}n},
	title = {Establishment of IPsec Security Associations with Diffie-Hellman following
                  a SDN-based framework: Analysis and practical validation},
	journal = {Comput. Networks},
	volume = {253},
	pages = {110720},
	year = {2024},
	url = {https://doi.org/10.1016/j.comnet.2024.110720},
	doi = {10.1016/J.COMNET.2024.110720},
	timestamp = {Sun, 08 Sep 2024 16:07:18 +0200},
	biburl = {https://dblp.org/rec/journals/cn/EspinLM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The centralized management of IPsec Security Associations (SAs) by using Software Defined Network (SDN) paradigm has been already explored and standardized. Datacenters are some of the scenarios where the dynamic establishment of IPsec security associations among network nodes has been deemed relevant. In these scenarios, where nodes do not support protocols like IKEv2, applying solutions where the generation and distribution of keys for IPsec are delegated to the SDN controller. However, these scenarios have the issue that the controller itself generates the IPsec keys for the nodes, posing a higher risk to the system’s security in case the controller is compromised. For these scenarios, it would be necessary to define solutions that allow the distribution of this cryptographic material securely, while maintaining the capacity restrictions established by the nodes. To solve this risk, we propose the generation of the IPsec keys using key distribution through the Diffie–Hellman algorithm in such a manner, that the controller will never have access to the IPsec SAs session keys used by the network nodes, mitigating the aforementioned problem. In concrete, our approach makes the nodes responsible for generating their own Diffie–Hellman public and private keypair, while the controller is only in charge of distributing the public keys to the rest of nodes, as well as other parameters needed to install the IPsec SAs. As we will analyze, the distribution of the public keys will be enough to allow the network nodes to generate the session keys. This work presents the design, implementation and validation of this IPsec management solution based on Diffie–Hellman in SDN environments using asymmetric key distribution for negotiating encryption and integrity keys, focusing on the performance in key generation and installation of IPsec SAs.}
}


@article{DBLP:journals/cn/PalmieriBVPC24,
	author = {Luigi Palmieri and
                  Chiara Boldrini and
                  Lorenzo Valerio and
                  Andrea Passarella and
                  Marco Conti},
	title = {Impact of network topology on the performance of Decentralized Federated
                  Learning},
	journal = {Comput. Networks},
	volume = {253},
	pages = {110681},
	year = {2024},
	url = {https://doi.org/10.1016/j.comnet.2024.110681},
	doi = {10.1016/J.COMNET.2024.110681},
	timestamp = {Mon, 03 Mar 2025 21:30:45 +0100},
	biburl = {https://dblp.org/rec/journals/cn/PalmieriBVPC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Fully decentralized learning is gaining momentum for training AI models at the Internet’s edge, addressing infrastructure challenges and privacy concerns. In a decentralized machine learning system, data is distributed across multiple nodes, with each node training a local model based on its respective dataset. The local models are then shared and combined to form a global model capable of making accurate predictions on new data. Our exploration focuses on how different types of network structures influence the spreading of knowledge – the process by which nodes incorporate insights gained from learning patterns in data available on other nodes across the network. Specifically, this study investigates the intricate interplay between network structure and learning performance using three network topologies and six data distribution methods. These methods consider different vertex properties, including degree centrality, betweenness centrality, and clustering coefficient, along with whether nodes exhibit high or low values of these metrics. Our findings underscore the significance of global centrality metrics (degree, betweenness) in correlating with learning performance, while local clustering proves less predictive. We highlight the challenges in transferring knowledge from peripheral to central nodes, attributed to a dilution effect during model aggregation. Additionally, we observe that central nodes exert a pull effect, facilitating the spread of knowledge. In examining degree distribution, hubs in Barabási–Albert networks positively impact learning for central nodes but exacerbate dilution when knowledge originates from peripheral nodes. Finally, we demonstrate the formidable challenge of knowledge circulation outside of segregated communities, and discuss the impact of class cross-correlations.}
}


@article{DBLP:journals/cn/CiancaNARS24,
	author = {Ernestina Cianca and
                  Syed Junaid Nawaz and
                  Carla Amatetti and
                  Tommaso Rossi and
                  Mauro De Sanctis},
	title = {LEO-based network-centric localization in 6G: Challenges and future
                  perspectives},
	journal = {Comput. Networks},
	volume = {253},
	pages = {110689},
	year = {2024},
	url = {https://doi.org/10.1016/j.comnet.2024.110689},
	doi = {10.1016/J.COMNET.2024.110689},
	timestamp = {Fri, 20 Sep 2024 14:02:18 +0200},
	biburl = {https://dblp.org/rec/journals/cn/CiancaNARS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The future releases of 3rd Generation Partnership Project (3GPP) specifications, that is, beyond release 18, will consider the possibility to localize the User Equipment (UE) at network-side, eventually using satellite constellations of the integrated Terrestrial-Non-Terrestrial networks (T-NTN). Satellite network-centric localization schemes can be categorized into single- and multi-satellite localization using spatio-temporal measurements or instantaneous spatial diversity, respectively Direct channel measurements such as Doppler, Received Signal Strength (RSS), Round Trip Time (RTT) and Angle-of-Arrival (AoA) or differential measurements such as Time-Difference-of-Arrival (TDoA) and Frequency-Difference-of-Arrival (FDoA) have been considered in the literature to aid the localization operation. This paper focuses on the applicability of an RTT approach, which has some advantages with respect to the other approaches in case of satellite network-centric localization in the integrated T-NTN. The paper shows some preliminary results of the proposed RTT approach. Finally, challenges and research trends of this novel research field have been highlighted.}
}


@article{DBLP:journals/cn/PhamHTQTD24,
	author = {Van{-}Hau Pham and
                  Hien Do Hoang and
                  Phan Thanh Trung and
                  Van Dinh Quoc and
                  Trong{-}Nghia To and
                  Phan The Duy},
	title = {Raiju: Reinforcement learning-guided post-exploitation for automating
                  security assessment of network systems},
	journal = {Comput. Networks},
	volume = {253},
	pages = {110706},
	year = {2024},
	url = {https://doi.org/10.1016/j.comnet.2024.110706},
	doi = {10.1016/J.COMNET.2024.110706},
	timestamp = {Mon, 03 Feb 2025 10:44:20 +0100},
	biburl = {https://dblp.org/rec/journals/cn/PhamHTQTD24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {To discover threats to a network system, investigating the behaviors of attackers after successful exploitation is an important phase, called post-exploitation. Although various efficient tools support post-exploitation implementation, the crucial factor in completing this process remains experienced human experts, known as penetration testers or pen-testers. This study proposes the Raiju framework, a Reinforcement Learning (RL)-driven automation approach, which automatically implements steps of the post-exploitation phase for security-level evaluation. We implement two well-known RL algorithms, Advantage Actor–Critic (A2C) and Proximal Policy Optimization (PPO), to evaluate specialized agents capable of making intelligent actions. With the support of Metasploit, modules corresponding to selected actions of the agent automatically launch real attacks of privileges escalation (PE), gathering hashdump (GH), and lateral movement (LM) on multiple platforms. Through leveraging RL, our objective is to empower agents that can autonomously select suitable actions to exploit vulnerabilities within target systems. This approach enables the automation of specific components within the penetration testing (PT) workflow, thereby enhancing its efficiency and adaptability to evolving threats and vulnerabilities. The experiments are performed in four real environments with agents trained in thousands of episodes. The agents can automatically launch exploits on the four environments and achieve a success ratio of over 84% across the three attack types. Furthermore, our experiments demonstrate the remarkable effectiveness of the A2C algorithm in the realm of post-exploitation automation.}
}


@article{DBLP:journals/cn/DuZCZ24,
	author = {Bin Du and
                  He Zhang and
                  Xiangle Cheng and
                  Lei Zhang},
	title = {Neural quantile optimization for edge-cloud networking},
	journal = {Comput. Networks},
	volume = {253},
	pages = {110713},
	year = {2024},
	url = {https://doi.org/10.1016/j.comnet.2024.110713},
	doi = {10.1016/J.COMNET.2024.110713},
	timestamp = {Mon, 09 Dec 2024 22:47:19 +0100},
	biburl = {https://dblp.org/rec/journals/cn/DuZCZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We seek the best traffic allocation scheme for the edge–cloud networking subject to SD-WAN architecture and burstable billing. First, we formulate a family of quantile-based integer programming problems for a fixed network topology with random parameters describing the traffic demands. Then, to overcome the difficulty caused by the discrete feature, we generalize the Gumbel-softmax reparameterization method to induce an unconstrained continuous optimization problem as a regularized continuation of the discrete problem. Finally, we introduce the Gumbel-softmax sampling neural network to solve optimization problems via unsupervised learning. The neural network structure reflects the edge–cloud networking topology and is trained to minimize the expectation of the cost function for unconstrained continuous optimization problems. The trained network works as an efficient traffic allocation scheme sampler, outperforming the random strategy in feasibility and cost value. Besides testing the quality of the output allocation scheme, we examine the generalization property of the network by increasing the time steps and the number of users. We also feed the solution to existing integer optimization solvers as initial conditions and verify the warm-starts can accelerate the short-time iteration process. The framework is general, and the decoupled feature of the random neural networks is adequate for practical implementations.}
}


@article{DBLP:journals/cn/SojdehLSK24,
	author = {Mohammad Javad Sojdeh and
                  Mehdi Letafati and
                  Seyed Pooya Shariatpanahi and
                  Babak Hossein Khalaj},
	title = {Secure multi-server coded caching},
	journal = {Comput. Networks},
	volume = {253},
	pages = {110715},
	year = {2024},
	url = {https://doi.org/10.1016/j.comnet.2024.110715},
	doi = {10.1016/J.COMNET.2024.110715},
	timestamp = {Fri, 20 Sep 2024 14:02:18 +0200},
	biburl = {https://dblp.org/rec/journals/cn/SojdehLSK24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper considers multiple cache-enabled end-users connected to multiple servers through a linear network. We also prevent an external eavesdropper from obtaining any information about the original files in cache-aided networks. The eavesdropper does not exist in the placement phase. He can analyze and capture the multi-cast messages in the content delivery phase. He receives a single linear combination derived from each multi-cast message. Hence, we only consider the security of the delivery phase. Our work generalizes the secure caching problem with one server to a multi-server setup. A secure centralized multi-server coded caching scenario is considered, and closed-form coding delay and secret shared key storage expression are provided. Regarding our security guarantee, we show that the delivery phase does not reveal any information to the eavesdropper in terms of the mutual information metric. We analyze the system’s performance in terms of coding delay and guarantee the security of our scheme using the mutual information metric. Numerical evaluations verify that security incurs a negligible cost in terms of memory usage when the number of files and users increases, i.e., the secure and insecure bounds almost coincide. Also, we numerically show that our proposed scheme outperforms the secure coded caching problem with one server.}
}


@article{DBLP:journals/cn/ChandranV24,
	author = {Indu Chandran and
                  Kizheppatt Vipin},
	title = {A {PUF} secured lightweight mutual authentication protocol for multi-UAV
                  networks},
	journal = {Comput. Networks},
	volume = {253},
	pages = {110717},
	year = {2024},
	url = {https://doi.org/10.1016/j.comnet.2024.110717},
	doi = {10.1016/J.COMNET.2024.110717},
	timestamp = {Fri, 20 Sep 2024 14:02:18 +0200},
	biburl = {https://dblp.org/rec/journals/cn/ChandranV24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Unmanned aerial vehicles, initially developed for military use, have evolved to play vital roles in civilian applications including photography, agriculture, disaster management, and delivery services. Their agility, precision, and ad-hoc formation make them indispensable, particularly in time-sensitive tasks such as search-and-rescue missions. However, the widespread use of UAVs has raised security concerns, including unauthorized access, cyberattacks, and physical threats. In addition, the dynamic nature of these networks provides adversaries with opportunities to exploit node failures leading to potential data breaches. To address these risks, implementing robust security measures such as authentication, encryption, physical security, and proactive monitoring is essential even amidst the inherent resource limitations faced by UAVs. This paper proposes a lightweight authentication and key agreement protocol for multi-UAV networks, incorporating physically unclonable technology for securing the data sent over the network. The protocol also addresses security risks during UAV failures and the unauthorized access to data. The scheme has been validated using the Scyther simulation tool, with the PUF implemented on the Xilinx FPGA platform. An informal security analysis is also presented that demonstrates its adherence to security requirements. Additionally, the performance of the proposed scheme is compared with state-of-the-art approaches by evaluating network latency in terms of computational and communication costs, affirming its effectiveness in resource-constrained applications.}
}


@article{DBLP:journals/cn/DuCTS24,
	author = {Ruizhong Du and
                  Tianyang Chen and
                  Jin Tian and
                  Tao Shang},
	title = {StarCross: Redactable blockchain-based secure and lightweight data
                  sharing framework for satellite-based IoT},
	journal = {Comput. Networks},
	volume = {253},
	pages = {110718},
	year = {2024},
	url = {https://doi.org/10.1016/j.comnet.2024.110718},
	doi = {10.1016/J.COMNET.2024.110718},
	timestamp = {Fri, 20 Sep 2024 14:02:18 +0200},
	biburl = {https://dblp.org/rec/journals/cn/DuCTS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Due to limitations in network coverage and capacity, terrestrial networks cannot meet the growing demand for widespread intelligent applications in recent years. The increasingly popular Satellite-based Internet of Things (S-IoT), with its extensive and boundless coverage, has emerged as the optimal solution. However, the large-scale distributed communication and services have led to significant challenges in scalability and security. Blockchain can help mitigate security and privacy issues in data sharing of S-IoT. To address these challenges, we propose StarCross, a secure and lightweight data sharing framework for S-IoT based on redactable blockchain. Firstly, we develop a space-ground collaborative sharding blockchain network architecture. Low Earth Orbit (LEO) satellite network serves as the communication intermediary between shards. Secondly, StarCross employs an improved Proof of Work (PoW) consensus based on dynamic difficulty to mitigate the challenges of uneven computing power and centralization within each shard. To ensure the atomicity of cross-shard transactions, StarCross introduces a blockchain rewriting mechanism called RBCVC, which combines chameleon hash and voting-based consensus. Thirdly, we conducted theoretical analysis and experimental evaluations of StarCross. The results indicate that compared to existing solutions, StarCross achieves better scalability and security in S-IoT. StarCross’s TPS increased to 260.9% of the baseline, while the transaction confirmation latency decreased by 79.7%.}
}


@article{DBLP:journals/cn/LiuYZXL24,
	author = {Yanbo Liu and
                  Peng Yu and
                  Junye Zhang and
                  Zhe Xiao and
                  Wenjing Li},
	title = {Adaptive and low-cost resource synchronization based on data distribution
                  service in high dynamic networks},
	journal = {Comput. Networks},
	volume = {253},
	pages = {110719},
	year = {2024},
	url = {https://doi.org/10.1016/j.comnet.2024.110719},
	doi = {10.1016/J.COMNET.2024.110719},
	timestamp = {Fri, 27 Sep 2024 16:24:56 +0200},
	biburl = {https://dblp.org/rec/journals/cn/LiuYZXL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In disaster-stricken areas monitoring, management, search, and rescue operations, unmanned aerial vehicles (UAVs) play a crucial role in disaster management and emergency communication due to their high mobility. To efficiently coordinate and plan UAVs and their carried sensor and base station resources, synchronization is essential to establish consistency, laying the foundation for high-level demands. In such scenarios, synchronization relies on request–response (RR) or publish–subscribe (PS) forms of information exchange. Existing research in the field typically focuses on higher-level applications and selects either RR or PS synchronization, thereby overlooking the potential advantages that could be gained from combining both methods to meet synchronization requirements. We propose a resource synchronization method based on the Data Distribution Service (DDS) and a linear time complexity subscription mechanism tailored to specific query demands, which considers the pros and cons of the above two information exchange forms and the bottom-layer network topology. Experimental results using open-source simulation tools demonstrate that the proposed method adapts to scene requirements and decreases bandwidth by at least 21.2% and packet rate by at least 3.7% compared to different baseline methods across three topologies, while satisfying delay and query success rate requirements. Furthermore, the method maintains robust performance in the face of dynamic changes in network topology, showcasing its robustness.}
}


@article{DBLP:journals/cn/YoshinakaKKTH24,
	author = {Yutaro Yoshinaka and
                  Mio Kochiyama and
                  Yuki Koizumi and
                  Junji Takemasa and
                  Toru Hasegawa},
	title = {A lightweight anonymity protocol at terabit speeds on programmable
                  switches},
	journal = {Comput. Networks},
	volume = {253},
	pages = {110721},
	year = {2024},
	url = {https://doi.org/10.1016/j.comnet.2024.110721},
	doi = {10.1016/J.COMNET.2024.110721},
	timestamp = {Fri, 20 Sep 2024 14:02:18 +0200},
	biburl = {https://dblp.org/rec/journals/cn/YoshinakaKKTH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Anonymous communication protocols are integral tools for people to exercise the right to privacy in their online activities. Such tools are urged to offer maximum protection against various classes of adversaries, including rogue criminals, exploitative companies, and authoritarian or paternalistic regimes, while respecting the diversity of users’ activities, from e-mail and web browsing to file transfer and video streaming. In such a context, lightweight anonymity protocols are a promising solution to provide well-balanced anonymity and performance for daily use against a class of adversaries with a relaxed but realistic assumption of their capability. However, as the existing instantiations of these protocols solely target software implementation, they did not fully exhibit their advantages in performance by the relaxation of the adversarial model. This paper presents P5HI, a novel instantiation and implementation of a lightweight anonymity protocol on hardware programmable switches. Its realization requires a rethinking of all aspects of the system, beginning with the realization of bit-rotation on the switch, through the construction of a cryptographic scheme and attack prevention, to hardware-friendly procedures during path setup and data transmission. We deploy the full-fledged design of the lightweight anonymity protocol on an actual programmable switch, and our prototype demonstrates its operation at a speed of over 3.0 Tbps.}
}


@article{DBLP:journals/cn/KoutliaL24,
	author = {Katerina Koutlia and
                  Sandra Lag{\'{e}}n},
	title = {On the impact of Open {RAN} Fronthaul Control in scenarios with {XR}
                  Traffic},
	journal = {Comput. Networks},
	volume = {253},
	pages = {110722},
	year = {2024},
	url = {https://doi.org/10.1016/j.comnet.2024.110722},
	doi = {10.1016/J.COMNET.2024.110722},
	timestamp = {Fri, 20 Sep 2024 14:02:18 +0200},
	biburl = {https://dblp.org/rec/journals/cn/KoutliaL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Through extensive research and standardization efforts, mobile networks have rapidly evolved, offering improved services and allowing the establishment of new use cases, such as autonomous vehicles, smart cities, Industry 4.0, among others. While 5G networks have brought advancements that can support a broad spectrum of such new use cases, the requirements imposed by time-critical services as the eXtended Reality (XR) and Cloud Gaming (CG) applications still remain a challenge. Next generation networks are envisioned to adopt technologies that will allow them to surpass such barriers. Open Radio Access Network (RAN), utilizing the disaggregation paradigm, stands out as a pivotal technology thanks to its potential to endow the network with flexibility, automation, and intelligence. In fact, Open RAN is considered as one of the key enabling technologies for XR and CG applications. However, disaggregation of the RAN may result in bottlenecks in the links connecting the various parts of the network, like the Open Fronthaul link, especially when considering time-critical traffic. In this paper, we perform an analysis of the impact that the Open Fronthaul capacity limitations can have in the XR and CG traffic under 3GPP defined scenarios. Moreover, to address these limitations, we implement and extend a Fronthaul Control mechanism combined with modulation compression, using the open-source ns-3 based 5G-LENA network simulator. Results showcase that the Open Fronthaul capacity limitation can drastically reduce the performance of the XR and CG applications, and demonstrate the necessity for such mechanisms to be employed in order to meet their requirements in terms of latency and throughput.}
}


@article{DBLP:journals/cn/ElzoghbiH24,
	author = {Mahmoud Elzoghbi and
                  Hui He},
	title = {DIS-Guard: Enhancing {SDN} resilience to topology and {RCO} attacks},
	journal = {Comput. Networks},
	volume = {253},
	pages = {110723},
	year = {2024},
	url = {https://doi.org/10.1016/j.comnet.2024.110723},
	doi = {10.1016/J.COMNET.2024.110723},
	timestamp = {Fri, 20 Sep 2024 14:02:18 +0200},
	biburl = {https://dblp.org/rec/journals/cn/ElzoghbiH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {SDN controllers employ discovery protocols with LLDP packets to discover the network topology; however, this approach is susceptible to topology attacks due to the static reuse of LLDP packets without proper origin verification or integrity checks. This paper proposes a novel form of topology attack called the Round-trip time Confusion Onslaught (RCO) attack. Our findings showcase the capability of the RCO attack to mislead the discovery service of SDN controllers and bypass the Real-time Link Verification (RLV) defence mechanism, which depends on timing features in Machine Learning (ML) models. The RCO attack significantly reduces the effectiveness of the RLV mechanism in terms of True Positive Rate (TPR), Precision, F1-score, and Cohen’s Kappa and increases the False Positive Rate (FPR). These results underscore the difficulties in achieving dependable ML accuracy in topology attack detection. Accordingly, we propose the DIS-Guard framework, designed to protect and improve the efficiency of discovery protocols within SDN controllers. This framework utilizes the mutual Transport Layer Security (mTLS) protocol to discover hosts proactively. Moreover, it employs a novel combination of a chaos-tent map and the proposed statistical method for link discovery. Through extensive evaluation, we illustrate DIS-Guard’s superior performance and security over the established Ryu (switches.py) controller and the RLV defence mechanism. Notably, DIS-Guard reduces host-to-host access delays, decreases LLDP packet transmission and reception significantly, and improves control channel efficiency. Collectively, these quantifiable benefits manifest the efficacy of DIS-Guard as a significantly optimized solution for SDN security and performance.}
}


@article{DBLP:journals/cn/LiHQ24,
	author = {Zhengfa Li and
                  Chuanhe Huang and
                  Wanyu Qiu},
	title = {An intrusion detection method combining variational auto-encoder and
                  generative adversarial networks},
	journal = {Comput. Networks},
	volume = {253},
	pages = {110724},
	year = {2024},
	url = {https://doi.org/10.1016/j.comnet.2024.110724},
	doi = {10.1016/J.COMNET.2024.110724},
	timestamp = {Fri, 20 Sep 2024 14:02:18 +0200},
	biburl = {https://dblp.org/rec/journals/cn/LiHQ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Deep learning is a crucial research area in network security, particularly when it comes to detecting network attacks. While some deep learning algorithms have shown promising results in distinguishing between normal and abnormal traffic, identifying different types of imbalanced anomalous traffic data is still a challenging task at present. To enhance the detection performance of unbalanced anomalous flows, we propose a new intrusion detection architecture based on a variational auto-encoder (VAE) and generative adversarial networks (GAN) in this research. Firstly, we present the VAE-WGAN model, which combines the advantages of VAE and GAN and enables us to generate data with predefined labels to balance the original training dataset. In the intrusion detection phase, we use a hybrid neural network model based on stacked Long Short-Term Memory (LSTM) and Multi-Scale Convolutional Neural Network (MSCNN). Stacked LSTM and MSCNN networks can extract network characteristics at different depths and scales, and subsequent feature fusion is used to increase network attack detection rates. Finally, the results from the NSL-KDD and AWID datasets indicate that the proposed network intrusion detection model improves the accuracy of network attack detection. The model outperforms other existing intrusion detection approaches in terms of accuracy, precision, recall, and f1-score, obtaining 83.45% accuracy and 83.69% f1-score on the NSL-KDD dataset. Moreover, it attains an accuracy and f1-score exceeding 98.9% on the AWID dataset.}
}


@article{DBLP:journals/cn/PuglieseQSRZPGB24,
	author = {Daniele Pugliese and
                  Mattia Quadrini and
                  Domenico Striccoli and
                  Cesare Roseti and
                  Francesco Zampognaro and
                  Giuseppe Piro and
                  Luigi Alfredo Grieco and
                  Gennaro Boggia},
	title = {Integrating terrestrial and non-terrestrial networks via {IAB} technology:
                  System-level design and evaluation},
	journal = {Comput. Networks},
	volume = {253},
	pages = {110726},
	year = {2024},
	url = {https://doi.org/10.1016/j.comnet.2024.110726},
	doi = {10.1016/J.COMNET.2024.110726},
	timestamp = {Mon, 09 Dec 2024 22:47:19 +0100},
	biburl = {https://dblp.org/rec/journals/cn/PuglieseQSRZPGB24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As the telecommunications industry embarks on the transition to Sixth-Generation (6G) networks, this paper examines the integration of Non-Terrestrial Networks (NTN), and in particular satellite backhauling, in the context of Fifth-Generation (5G) systems. The Integrated Access and Backhaul (IAB) technology, conceived as a wireless terrestrial backhauling system in the Next Generation Radio Access Network (NG-RAN), has been identified as a possible enabler for the integration of satellite nodes. Despite the work already done in this direction, the combination of IAB architectures with satellite nodes operating in both the access and backhaul side requires further evaluations on feasibility and limitations for networks integrating Low Earth Orbit (LEO) and Geostationary Earth Orbit (GEO) satellites. To this end, this work contributes providing insights on background technologies, as well as a detailed analysis of the issues and challenges arising from such integration and a definition of use cases to support narrow-band and broadband services. Furthermore, the design and implementation of a simulation tool is proposed for a performance evaluation in terms of registration time, link capacity, single-hop and end-to-end delay. Results show that the integration turns out to be feasible, even if with strong constraints coming from the satellite system rather than the IAB usage itself. Indeed, the earth-satellite link in LEO systems has a significant impact on the packet delivery time due to the discontinuous coverage. In case of GEO satellite instead, a non-terrestrial backhaul link could limit the performance of the whole system, especially at lower elevation angles.}
}


@article{DBLP:journals/cn/LiuZWZ24,
	author = {Ximeng Liu and
                  Shizhen Zhao and
                  Xinbing Wang and
                  Chenghu Zhou},
	title = {LPulse: An efficient algorithm for service function chain placement
                  and routing with delay guarantee},
	journal = {Comput. Networks},
	volume = {253},
	pages = {110728},
	year = {2024},
	url = {https://doi.org/10.1016/j.comnet.2024.110728},
	doi = {10.1016/J.COMNET.2024.110728},
	timestamp = {Fri, 20 Sep 2024 14:02:18 +0200},
	biburl = {https://dblp.org/rec/journals/cn/LiuZWZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Modern network services increasingly depend on the effective orchestration of the Service Function Chain (SFC) with stringent end-to-end delay guarantees. To achieve this, the Delay-Constrained Service Function Chain Placement and Routing (DC-SFCPR) problem must be addressed. This problem involves the optimal selection of nodes for placing network functions and routes that adhere to a specific sequence of service functions, to minimize network bandwidth and CPU costs while strictly adhering to stringent end-to-end delay constraints. The DC-SFCPR problem is NP-hard and existing algorithms either fail to guarantee strict delay constraints or are computationally expensive, making them unsuitable for expanding network topologies. We propose the LPulse algorithm, designed to efficiently solve the DC-SFCPR problem. This algorithm utilizes a layered graph to embed the requirements of service functions, transforming the DC-SFCPR problem into a Delay-Constrained Shortest Path (DCSP) problem. The LPulse algorithm then applies Pulse, a depth-first search framework enhanced with efficient pruning strategies, and incorporates two novel acceleration strategies to solve the DCSP problem. We prove that LPulse ensures the optimality of solutions. Evaluations conducted across various topologies, with node scales ranging from 22 to 10,000, show that LPulse surpasses existing algorithms in both solution quality and speed. For instance, the number of cases meeting strict delay constraints with LPulse is\n1\n.\n9\n×\nthat of those solved by deep reinforcement learning algorithms; furthermore, its solving efficiency is\n4\n.\n9\n×\nthat of the highest-performing existing optimal algorithm, the LagrangianKsp algorithm.}
}


@article{DBLP:journals/cn/GongHT24,
	author = {Bobin Gong and
                  Gaofei Huang and
                  Wanqing Tu},
	title = {Minimize {BER} without {CSI} for dynamic RIS-assisted wireless broadcast
                  communication systems},
	journal = {Comput. Networks},
	volume = {253},
	pages = {110729},
	year = {2024},
	url = {https://doi.org/10.1016/j.comnet.2024.110729},
	doi = {10.1016/J.COMNET.2024.110729},
	timestamp = {Fri, 20 Sep 2024 14:02:18 +0200},
	biburl = {https://dblp.org/rec/journals/cn/GongHT24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper studies a dynamic reconfigurable intelligent surface (RIS)-assisted broadcast communication system where a transmitter broadcasts information to multiple receivers with time-varying locations via a RIS. The goal is to minimize the maximum bit error rate (BER) at the receivers by optimizing RIS phase shifts, subject to a given discrete phase shift constraint. Unlike most existing works where channel state information (CSI) is required, only location information of the receivers is needed in our work, due to the great challenge of instantaneous CSI estimation in RIS-assisted communications and the reason that statistical CSI does not apply to the dynamic scenario. The involved optimization problem is hard to tackle, because the BERs at the receivers cannot be calculated by classical CSI-dependent analytical expressions for lack of CSI and exhaustive searching is computationally prohibitive to achieve the optimal discrete phase shifts. To address this issue, a deep reinforcement learning (DRL) approach is proposed to solve the problem by reformulating the optimization problem as a Markov decision process (MDP), where the BERs are measured by the Monte Carlo method. Furthermore, to tackle the issue of the high-dimensional action space in the MDP, a novel action-composition based proximal policy optimization (PPO) algorithm is proposed to solve the MDP. Simulation results verify the effectiveness of the proposed PPO-based DRL approach.}
}


@article{DBLP:journals/cn/WangFG24,
	author = {Tianle Wang and
                  Xiuwen Fu and
                  Antonio Guerrieri},
	title = {Joint resource scheduling and flight path planning of UAV-assisted
                  IoTs in response to emergencies},
	journal = {Comput. Networks},
	volume = {253},
	pages = {110731},
	year = {2024},
	url = {https://doi.org/10.1016/j.comnet.2024.110731},
	doi = {10.1016/J.COMNET.2024.110731},
	timestamp = {Fri, 20 Sep 2024 14:02:18 +0200},
	biburl = {https://dblp.org/rec/journals/cn/WangFG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In unmanned aerial vehicles (UAV)-assisted Internet of Things (IoT), emergencies can lead to changes in the status of ground sensor networks. This necessitates UAV-assisted IoT systems to possess the capability to dynamically respond to changes in the status of the ground sensor network. Therefore, this paper proposes a UAV scheduling scheme based on regional coordination (USRC). In this scheme, we divide the ground sensor network into task sub-regions according to the deployment of base stations. Then, we introduce a scheduling relationship pairing algorithm to determine the scheduling relationships between task sub-regions and UAV resources that need to be scheduled for each sub-region. Based on this, a dynamic path planning algorithm is designed to synchronize the planning of cross-region flight paths and intra-region flight paths for UAVs. Experimental results have demonstrated that the proposed scheme can efficiently respond to changes in the status of the ground sensor network by scheduling UAVs from sub-regions with abundant resources to those with scarce resources. Compared to other schemes, our scheme exhibits superior performance in reducing the age of information (AoI) and packet loss rate.}
}


@article{DBLP:journals/cn/GuoZJ24,
	author = {Lili Guo and
                  Shibing Zhang and
                  Xiaodong Ji},
	title = {Joint optimization for energy efficient full-duplex {UAV} relaying
                  with multiple user pairs},
	journal = {Comput. Networks},
	volume = {253},
	pages = {110732},
	year = {2024},
	url = {https://doi.org/10.1016/j.comnet.2024.110732},
	doi = {10.1016/J.COMNET.2024.110732},
	timestamp = {Fri, 20 Sep 2024 14:02:18 +0200},
	biburl = {https://dblp.org/rec/journals/cn/GuoZJ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper investigates an unmanned aerial vehicle (UAV) assisted amplify-and-forward relaying, where a full-duplex (FD) fixed-wing UAV employs a time-division multiple access scheduling protocol to provide relay services for multiple source–destination user pairs. With the aim of maximizing energy efficiency (EE) of the system, a joint optimization problem is studied so as to jointly fulfill the communication scheduling of multiple user pairs, the transmit power control and the trajectory design of the UAV. Since the optimization variables of the problem are coupled, it is non-convex and hence hard to solve directly. To this end, the initial problem is decomposed into three subproblems corresponding to the optimization of communication scheduling, and transmit power and trajectory of the UAV, respectively. The three subproblems are solved by utilizing the linear programming, the successive convex approximation (SCA), and the Dinkelbach’s algorithm. Then an iterative algorithm based on the block coordinate descent technique is proposed to tackle the joint optimization problem by optimizing the three blocks of variables alternately. Simulation results demonstrate that the proposed algorithm converges efficiently, and the EE of the joint optimization scheme can be significantly improved compared to the benchmark schemes.}
}


@article{DBLP:journals/cn/CalsiKCN24,
	author = {Davide Li Calsi and
                  Paul Kohl and
                  Jinhyeock Choi and
                  Janis N{\"{o}}tzel},
	title = {The impact of message losses and retransmissions on quantum cryptographic
                  protocols},
	journal = {Comput. Networks},
	volume = {253},
	pages = {110735},
	year = {2024},
	url = {https://doi.org/10.1016/j.comnet.2024.110735},
	doi = {10.1016/J.COMNET.2024.110735},
	timestamp = {Mon, 09 Dec 2024 22:47:19 +0100},
	biburl = {https://dblp.org/rec/journals/cn/CalsiKCN24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Quantum cryptography promises information theoretic security of several cryptographic primitives. Most of the proposed security proofs work in an ideal communication scenario where all messages are correctly delivered after the first attempt. However, real networks are subject to message losses and require retransmissions to cope with them. While the latter is hardly ever a problem in classical cryptography, with quantum communication copy-and-retransmit could be impossible due to the famous no-cloning theorem. In this work, we analyze some quantum cryptoschemes such as public-key encryption, authentication and quantum money, assuming that quantum messages may be lost as they travel through the communication medium. Although all these schemes are theoretically secure, we show that this degree of realism renders some protocols insecure or impractical, while others are completely unaffected. When possible, we provide mitigations such as teleportation or protocol modifications to circumvent these challenges.}
}


@article{DBLP:journals/cn/ZhengDLPG24,
	author = {Yu Zheng and
                  Zhangxuan Dang and
                  Xinglin Lian and
                  Chunlei Peng and
                  Xinbo Gao},
	title = {Multi-view multi-label network traffic classification based on MLP-Mixer
                  neural network},
	journal = {Comput. Networks},
	volume = {253},
	pages = {110746},
	year = {2024},
	url = {https://doi.org/10.1016/j.comnet.2024.110746},
	doi = {10.1016/J.COMNET.2024.110746},
	timestamp = {Sun, 06 Oct 2024 21:22:05 +0200},
	biburl = {https://dblp.org/rec/journals/cn/ZhengDLPG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Network traffic classification is the basis of many network security applications and has received significant attention in the field of cyberspace security. Existing research on deep traffic analysis typically involves converting traffic data into images to extract spatial traffic features using Convolutional Neural Networks (CNNs). However, this approach ignores the semantic differences and details in the various packet structures. In this paper, we propose an MLP-Mixer based multi-view multi-label neural network for network traffic classification. Compared with the existing CNN-based methods, our method adopts the MLP-Mixer structure, which is more in line with the structure of the packet than the conventional convolution operation. In our method, one packet is divided into the packet header and the packet payload, together with the flow statistics of the packet as input from different views. We utilize a multi-label setting to learn different scenarios simultaneously to improve the classification performance by exploiting the correlations between different scenarios. We conduct experiments on three public datasets, and the experimental results show that our method can achieve superior performance. Code is available at https://github.com/ZxuanDang/MV-ML-traffic-classification.}
}


@article{DBLP:journals/cn/RamonetPPK24,
	author = {Alberto Gallegos Ramonet and
                  Tommaso Pecorella and
                  Benedetta Picano and
                  Kazuhiko Kinoshita},
	title = {Perspectives on IoT-oriented network simulation systems},
	journal = {Comput. Networks},
	volume = {253},
	pages = {110749},
	year = {2024},
	url = {https://doi.org/10.1016/j.comnet.2024.110749},
	doi = {10.1016/J.COMNET.2024.110749},
	timestamp = {Mon, 09 Dec 2024 22:47:19 +0100},
	biburl = {https://dblp.org/rec/journals/cn/RamonetPPK24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Internet of Things (IoT) paradigm is assumed to be a major component in the present and future Internet, with forecasts claiming a humongous number of devices connected in the near future, and applications fields spanning from agriculture, to healthcare. Despite this, the standardization efforts have not yet resulted in widely adopted standards, and the market is fragmented into multiple solutions both at physical and communication protocol levels. Moreover, IoT systems exacerbate the usual test bed limitations, e.g., scalability (very large number of devices), hardware compatibility, space, and price. Due to the above problems, simulation tools become an extremely interesting tool for studying IoT systems both for academia (new algorithms), standardization (new protocols), and industry (what-if analysis). In this paper we will discuss what are the most relevant features and models that a simulation tool like ns-3 should prioritize to enable the above-mentioned needs from academia, standardization, and industry, and if they are achievable in the short, medium, or long term.}
}
