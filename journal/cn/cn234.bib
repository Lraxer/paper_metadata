@article{DBLP:journals/cn/ChenTXCZLW23,
	author = {Luyao Chen and
                  Yong Tang and
                  Jingwen Xia and
                  Siyang Chen and
                  Chengyu Zheng and
                  Hai Lin and
                  Wenyong Wang},
	title = {Multi-MEC collaboration for {VR} video transmission: Architecture
                  and cache algorithm design},
	journal = {Comput. Networks},
	volume = {234},
	pages = {109864},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109864},
	doi = {10.1016/J.COMNET.2023.109864},
	timestamp = {Thu, 14 Sep 2023 20:26:40 +0200},
	biburl = {https://dblp.org/rec/journals/cn/ChenTXCZLW23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Virtual Reality (VR) is becoming an important use case for 5G wireless networks, and Mobile Edge Computing (MEC) servers are being explored as a way to reduce VR video latency. To address the limited cache space of a single MEC server, this paper proposes dividing geographically close MEC servers into collaborative domains. A new VR video transmission architecture is designed after analyzing video compression mechanisms.}
}


@article{DBLP:journals/cn/ShararaFHVB23,
	author = {Mahdi Sharara and
                  Francesca Fossati and
                  Sahar Hoteit and
                  V{\'{e}}ronique V{\`{e}}que and
                  Francesca Bassi},
	title = {Minimizing energy consumption by joint radio and computing resource
                  allocation in Cloud-RAN},
	journal = {Comput. Networks},
	volume = {234},
	pages = {109870},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109870},
	doi = {10.1016/J.COMNET.2023.109870},
	timestamp = {Sat, 30 Sep 2023 10:07:04 +0200},
	biburl = {https://dblp.org/rec/journals/cn/ShararaFHVB23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cloud-RAN is a key 5G enabler; it centralizes the baseband processing of several base stations by executing the baseband functions in a centralized, virtualized, and shared entity known as the Base Band Unit (BBU)-Pool. Cloud-RAN paves the way for joint management of the radio and computing resources of multiple base stations. In fact, centralization and virtualization allow for decreasing energy consumption which decreases Capital Expenditure (CAPEX) and Operational Expenditure (OPEX). Cloud-RAN architecture permits jointly allocating the radio and computing resources of multiple base stations. The radio resources include the Resource Blocks (RBs), the transmission power, and the Modulation Coding Scheme (MCS), whereas the computing resources include the CPUs resources. This paper investigates the potential benefits that could be scored thanks to the joint allocation of these two types of resources, with respect to energy consumption and overall throughput, when radio resources are finite and computing resources are not. The latter is an effect of the C-RAN architecture, which allows scalability and fast computing resource provisioning. Due to the unconstrained availability of computing resources, the joint allocation of radio and computing resources has a negligible impact when the objective is throughput maximization. However, it is highly beneficial when the target is energy consumption minimization in comparison to the sequential allocation that consists of allocating radio resources first, and then computing resources are allocated. For that, we formulate a Mixed Integer Linear Programming (MILP) problem having the objective of minimizing energy consumption. When the goal is to minimize energy consumption, the joint allocation of radio and computing resources reduces the total energy consumption by up to 21.3% when compared to the case where radio and computing resources in the BBU pool are allocated sequentially. Furthermore, given the NP-hardness of solving a MILP problem, we propose a two-step low-complexity matching game-based algorithm with a transmission power adjustment mechanism that aims at performing close to the MILP solver. The results show that our proposed matching game algorithm is a good alternative for solving the joint-allocation MILP problem, producing results that are very close to the MILP optimal solutions.}
}


@article{DBLP:journals/cn/TalauHFW23,
	author = {Marcos Talau and
                  Thiago A. Herek and
                  Mauro Fonseca and
                  Em{\'{\i}}lio C. G. Wille},
	title = {Improving {TCP} performance over a common IoT scenario using the Early
                  Window Tailoring method},
	journal = {Comput. Networks},
	volume = {234},
	pages = {109875},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109875},
	doi = {10.1016/J.COMNET.2023.109875},
	timestamp = {Sat, 30 Sep 2023 10:07:05 +0200},
	biburl = {https://dblp.org/rec/journals/cn/TalauHFW23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Internet of Things (IoT) is already a reality in homes, transforming the home network into a complex composition of different equipment where each one has its own attributes in terms of TCP protocol variants, transmission speed, reliability and delay. In home network scenarios where IoT devices are used, it is common to have a 802.11 environment with several devices sharing the same Access Point (AP). When TCP is used in this environment its performance is affected by many things, such as wireless link losses, queue saturation on access points, and fairness. To improve the TCP performance in these scenarios, this paper presents a new version of the Early Window Tailoring (EWT) approach. The EWT-IoT do not require any modification in the TCP, and it does not require that all routers in the path use the same Active Queue Management (AQM), the use in the AP is sufficient. To evaluate its performance, comparison tests against drop-tail, RED, ARED and EWA were performed. The EWT-IoT proved to be effective in congestion control, achieving greater performance than the other approaches, reducing the transfer time, having a superior goodput, maintaining a satisfactory fairness, and presenting no losses. Also, the EWT-IoT allowed the existence of a number of flows on average 65.2% better than its best competitor and 71.3% better when no AQM scheme was used.}
}


@article{DBLP:journals/cn/HuangLXC23,
	author = {Minmin Huang and
                  Yuan Lingyun and
                  Pan Xue and
                  Zhou Chuan},
	title = {Trusted edge and cross-domain privacy enhancement model under multi-blockchain},
	journal = {Comput. Networks},
	volume = {234},
	pages = {109881},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109881},
	doi = {10.1016/J.COMNET.2023.109881},
	timestamp = {Sun, 22 Oct 2023 11:14:48 +0200},
	biburl = {https://dblp.org/rec/journals/cn/HuangLXC23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With its promising security and distributed qualities, blockchain offers a significant opportunity to break through the privacy protection issues in the edge computing paradigm. However, when edge participants submit security tasks to a distributed blockchain network across domains, they may expose their data privacy and location privacy. These privacy will be maliciously attacked and exploited by attackers such as external attackers and untrusted third parties, increasing the difficulty of access control. In addition, the performance bottleneck of blockchain systems cannot meet the demand for efficient data processing. To address these problems, we propose a cross-domain privacy enhancement scheme based on multi-blockchain. The scheme first integrates edge computing based on master-slave multi-blockchain and designs an identity authentication mechanism and trust assessment mechanism to deploy a three-layer trusted network architecture, which ensures the security stability and operational efficiency at the edge side. Secondly, role mapping rules are developed and trust degree is evaluated for domain nodes, and a cross-domain access control model based on trust degree and role is proposed. Data in this model cannot be exchanged across domains until all nodes jointly verify whether the access control policy is effective, which ensures the secure sharing of data in heterogeneous domains. In addition, to ensure the privacy and authenticity of data in cross-domain sharing, a hybrid searchable encryption method based on symmetric encryption and public key encryption is proposed. Finally, the security theoretical analysis proves that the model successfully ensures the non-repudiation of access control policy and the controllability of cross-domain data. Experiments show that the proposed model improves access dynamics by 74.8% and reduces CPU usage by 24.6% on average compared to traditional RBAC. The scheme is scalable, and its sending rate to throughput ratio reaches 1:1, gaining a 2X throughput advantage over existing schemes.}
}


@article{DBLP:journals/cn/CaoLDWYZZ23,
	author = {Shaohua Cao and
                  Di Liu and
                  Congcong Dai and
                  Chengqi Wang and
                  Yansheng Yang and
                  Weishan Zhang and
                  Danyang Zheng},
	title = {Reinforcement learning based tasks offloading in vehicular edge computing
                  networks},
	journal = {Comput. Networks},
	volume = {234},
	pages = {109894},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109894},
	doi = {10.1016/J.COMNET.2023.109894},
	timestamp = {Thu, 14 Sep 2023 20:26:40 +0200},
	biburl = {https://dblp.org/rec/journals/cn/CaoLDWYZZ23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the rapid development of autonomous and intelligent techniques, vehicles are currently equipped with computation and communication modules for satisfying clients’ on-vehicle computing requests. To meet the client’s on-vehicle computation requests such as on-vehicle games and self-driving mechanisms, vehicles have to continuously generate computational tasks. However, due to the limited on-vehicle computation capacities, it is barely possible to handle the above requests by the vehicle itself. These requests are then offloaded to special devices such as roadside units or intelligent vehicles. With the fluid feature of the traffic, more requests are generated during the peak hours than at the low hours. Based on the above facts, two significant challenges arise in vehicular edge computing networks: (i) how to accurately determine whether the vehicular networks are in peak or low hours, and (ii) how to effectively offload the generated requests? In this paper, to tackle the above challenges, we investigate the problem of computational requests offloading under different vehicular networking scenarios. To handle the first challenge, we propose the fuzzy inference-based algorithm to identify the situation of the vehicular network (i.e., whether it is in peak hours or low hours). We employ the reinforcement learning-based algorithm for the second challenge to offload the computational requests effectively. Experiments show that our schemes outperform the benchmark by an average of 24.8% regarding resource utilization when satisfying the interests of both service providers and clients.}
}


@article{DBLP:journals/cn/XuXLLL23,
	author = {Chenglin Xu and
                  Cheng Xu and
                  Bo Li and
                  Siqi Li and
                  Tao Li},
	title = {Load-aware dynamic controller placement based on deep reinforcement
                  learning in SDN-enabled mobile cloud-edge computing networks},
	journal = {Comput. Networks},
	volume = {234},
	pages = {109900},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109900},
	doi = {10.1016/J.COMNET.2023.109900},
	timestamp = {Fri, 10 Nov 2023 21:09:27 +0100},
	biburl = {https://dblp.org/rec/journals/cn/XuXLLL23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Software-defined networks (SDNs) can improve network resource utilization and optimize the performance of mobile cloud-edge computing networks (MECCNs) through unified and flexible network management. However, network traffic in MECCNs can change over time and space, which affects the performance of the control plane in an SDN. Further, an MECCN may require the temporary addition of network access points, further reducing the network management capabilities of the control plane. To ensure that the control plane can handle the constant changes in network traffic, adapt to dynamic changes in network access points, and provide continuous and efficient network management functions, this study focuses on the dynamic controller placement problem in SDN-enabled MECCNs. We study the deployment of a two-layer control plane and accordingly construct the corresponding delay, load balancing, and control reliability models. Next, we construct a joint optimization problem considering the developed delay, load balancing, and control reliability, and solve this problem using an algorithm based on the deep deterministic policy gradient algorithm. The experimental results demonstrate that the proposed algorithm outperforms other algorithms on a variable-node network.}
}


@article{DBLP:journals/cn/YuYFG23,
	author = {Kan Yu and
                  Jiguo Yu and
                  Zhiyong Feng and
                  Min Guo},
	title = {Cooperative jamming aided securing wireless communications without
                  {CSI} of eavesdroppers},
	journal = {Comput. Networks},
	volume = {234},
	pages = {109906},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109906},
	doi = {10.1016/J.COMNET.2023.109906},
	timestamp = {Mon, 18 Nov 2024 20:29:49 +0100},
	biburl = {https://dblp.org/rec/journals/cn/YuYFG23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Physical layer security was designed as an effective solution to provide the security and confidentiality of information transmission in wireless networks, and secrecy transmission capacity (STC) played a key role in analyzing the impact of system parameters on physical layer security. Different from the previous works, which exploited cooperative jamming to improve the security with the assumption of perfect channel state information (CSI) of eavesdroppers (Eves), in this paper, without considering Eves’ CSI, we designed two secrecy improvement strategies aided by cooperative jamming with transmit power allocation scheme, i.e., connection guard zone (CGZ) and improved interferer protected zone (IIPZ). Specifically, we established an analytical framework of the STC by applying the tools of stochastic geometry and derived conditions that achieved a positive STC. In addition, we consider the impact of Random WayPoint (RWP) mobile receiver and active eavesdroppers on physical layer security. Simulations showed that IIPZ achieves the best reliability performance and CGZ makes the best secrecy performance than existing popular protections, and RWP mobile destination can achieve a higher level of reliability and STC than these achievable in static scenarios.}
}


@article{DBLP:journals/cn/WangHNJ23,
	author = {Yang Wang and
                  Qian Hu and
                  Long Nguyen and
                  Maryam Jalalitabar},
	title = {Minimum-cost embedding of virtual networks: An iterative decomposition
                  approach},
	journal = {Comput. Networks},
	volume = {234},
	pages = {109907},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109907},
	doi = {10.1016/J.COMNET.2023.109907},
	timestamp = {Thu, 14 Sep 2023 20:26:40 +0200},
	biburl = {https://dblp.org/rec/journals/cn/WangHNJ23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The ossification of the current Internet can be mitigated by network virtualization. The key idea of network virtualization is to abstract a logical service as a virtual network, which is mapped to the physical infrastructure as networked virtual machines. This process, known as virtual network embedding (VNE), entails two components: Node Assignment (NA), where virtual nodes are mapped to physical nodes as virtual machines (i.e., via node virtualization); and Link Mapping (LM), where physical paths are allocated to connect the embedded virtual nodes (i.e., via link virtualization). The existing VNE solutions based on Integer Linear Programming models and heuristic algorithms, unfortunately, fall in short in addressing either one of the two following perspectives: ILP-based models address NA and LM jointly, leading to optimal results but they suffer from extensive computation time; heuristic algorithms simplify the problem computationally but it lacks guaranteed solution quality. A large body of VNE solutions, particularly, adopt strategies like divide-and-conquer: NA and LM are resolved as two independent sub-problems in sequence. This paper is motivated by an important mathematical quest to better leverage this decomposition strategy: how can one identify the inherent link between the NA and LM sub-problems to obtain a decomposition approach without trading off solution quality? The major contributions of this work lie on three facets that fulfill this quest. First, based on a path-based VNE model, our primal–dual analysis reveals the process towards formulations of the NA, and LM sub-problems that preserve the link (as in ILP solutions). Second, we develop an iterative decomposition approach that employs merits from both worlds: the complexity of VNE (structurally and computationally) is simplified by decomposition while optimality or guaranteed closeness to the optimality is attained. Third, our evaluations confirm that the proposed schemes can achieve trade-offs in time and optimality, and outperform benchmark schemes by a large margin.}
}


@article{DBLP:journals/cn/ParkSKJ23,
	author = {Kibeom Park and
                  Sangmo Sung and
                  Hokeun Kim and
                  Jae{-}Il Jung},
	title = {Technology trends and challenges in {SDN} and service assurance for
                  end-to-end network slicing},
	journal = {Comput. Networks},
	volume = {234},
	pages = {109908},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109908},
	doi = {10.1016/J.COMNET.2023.109908},
	timestamp = {Thu, 14 Sep 2023 20:26:40 +0200},
	biburl = {https://dblp.org/rec/journals/cn/ParkSKJ23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Network slicing is a core technology to enable new services and solutions in 5G and upcoming 6G communications. However, many issues arise when applying network slicing at a commercial scale, as this requires end-to-end management and automation of the network. Network slicing also requires various state-of-the-art technologies based on collaboration across international standards organizations and open-source communities. This paper reviews and summarizes the recent technological trends and challenges related to Software-Defined Networking (SDN) and service assurance for end-to-end network slicing. First, we focus on the essential use cases and technology trends associated with network slicing, followed by a survey of standard organizations and open-source projects related to network slicing and how they have evolved. Then, we overview an end-to-end network slicing architecture considering Open Radio Access Network (O-RAN) standard. For Radio Access Network (RAN) slicing, we zero in on managing RAN and xHaul with an integrated policy. For transport slicing, we discuss SDN architecture and requirements for network slicing with traffic isolation, unified QoS policy, and traffic engineering. We also cover SLA management using protocol-independent active monitoring and passive monitoring. In the later part of the paper, we summarize technical considerations for end-to-end network slicing, including the RAN-integrated xHaul architecture, converged enterprise network for multi-connectivity, 5G edge data center architectures using programmable data plane, and network slicing security. Overall, this paper reviews the various design issues associated with network slicing and the proposals to resolve these issues to facilitate end-to-end network slicing at a commercial scale.}
}


@article{DBLP:journals/cn/NguyenN23,
	author = {Tien{-}Tung Nguyen and
                  Anh{-}Vinh Nguyen},
	title = {Outage analysis of cognitive inspired {NOMA} networks in the presence
                  of imperfect SIC, CCI, and non-ID fading channels},
	journal = {Comput. Networks},
	volume = {234},
	pages = {109909},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109909},
	doi = {10.1016/J.COMNET.2023.109909},
	timestamp = {Sat, 30 Sep 2023 10:07:04 +0200},
	biburl = {https://dblp.org/rec/journals/cn/NguyenN23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper analyzes the outage performance of cognitive-inspired non-orthogonal multiple access (NOMA) network under imperfect successive interference cancellation (SIC), co-channel interference (CCI), and non-identical distributed fading channels. Firstly, we aim to derive the cumulative distribution function (CDF) for the optimum channel with beamforming design, the selected channel maximization, and the selected channel minimization and the probability density function (PDF) for channel interference in order to facilitate the outage performance analysis. Secondly, we obtain the closed-form expressions of outage probability for the primary and secondary destinations according to two strategies: (1) the primary destination is near secondary transmitter and (2) the primary destination is far from secondary transmitter. Thirdly, to provide some useful insights into system designs, we carry out the asymptotic analysis for the three power setting scenarios. Finally, we validate the derived theoretical analyses using Monte-Carlo method.}
}


@article{DBLP:journals/cn/MoureGarridoCG23,
	author = {Marta Moure{-}Garrido and
                  Celeste Campo and
                  Carlos Garc{\'{\i}}a{-}Rubio},
	title = {Real time detection of malicious DoH traffic using statistical analysis},
	journal = {Comput. Networks},
	volume = {234},
	pages = {109910},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109910},
	doi = {10.1016/J.COMNET.2023.109910},
	timestamp = {Sun, 04 Aug 2024 19:48:54 +0200},
	biburl = {https://dblp.org/rec/journals/cn/MoureGarridoCG23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The DNS protocol plays a fundamental role in the operation of ubiquitous networks. All devices connected to these networks need DNS to work, both for traditional domain name to IP address translation, and for more advanced services such as resource discovery. DNS over HTTPS (DoH) solves certain security problems present in the DNS protocol. However, malicious DNS tunnels, a covert way of encapsulating malicious traffic in a DNS connection, are difficult to detect because the encrypted data prevents performing an analysis of the content of the DNS traffic.}
}


@article{DBLP:journals/cn/KwonSJCLKPC23,
	author = {Ted Taekyoung Kwon and
                  Junghwan Song and
                  Heeyoung Jung and
                  Selin Chun and
                  Hyunwoo Lee and
                  Minhyeok Kang and
                  Minkyung Park and
                  Eunsang Cho},
	title = {How to decentralize the internet: {A} focus on data consolidation
                  and user privacy},
	journal = {Comput. Networks},
	volume = {234},
	pages = {109911},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109911},
	doi = {10.1016/J.COMNET.2023.109911},
	timestamp = {Thu, 14 Sep 2023 20:26:40 +0200},
	biburl = {https://dblp.org/rec/journals/cn/KwonSJCLKPC23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Over the years, the Internet has become a field in which a small number of large Internet companies dominate most of the Internet services. As users get used to using their services, the users’ generated content and the data about their online behaviors are concentrated in such companies. This phenomenon, called “data consolidation”, has become a serious problem, which makes the Internet society seek to decentralize the current Internet. The decentralized Internet aims to (i) prevent the concentration of user data in a few giant companies like Google and Facebook, and (ii) give users full ownership and control of their data. Various technical solutions that address the data consolidation problem have been proposed; however, those solutions focus on somewhat different scopes of the problem often from their limited viewpoints. The main contributions in this paper are the following. First, we survey the solutions relevant to Internet decentralization based on the following criteria: data consolidation, data ownership, and the privacy of user data. Second, we suggest a holistic reference framework from a functional viewpoint, while the prior proposals in the literature handle a limited set of requirements. Last, we seek to identify remaining research issues, considering additional requirements that have not been addressed in the existing solutions.}
}


@article{DBLP:journals/cn/RezaeiG23,
	author = {Zahra Rezaei and
                  Behrouz Shahgholi Ghahfarokhi},
	title = {Energy and spectrum efficient cell switch-off with channel and power
                  allocation in ultra-dense networks: {A} deep reinforcement learning
                  approach},
	journal = {Comput. Networks},
	volume = {234},
	pages = {109912},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109912},
	doi = {10.1016/J.COMNET.2023.109912},
	timestamp = {Thu, 14 Sep 2023 20:26:40 +0200},
	biburl = {https://dblp.org/rec/journals/cn/RezaeiG23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The high density of small cells in the Ultra-Dense Network (UDN) has increased the capacity and the coverage of Fifth Generation (5G) cellular networks. However, with increasing the number of Small Base Stations (SBSs), energy consumption rises sharply. One suggested method to reduce energy consumption is to manage the SBS On/Off switching. Moreover, due to spectrum constraints, the Power Control and Resource Allocation (PCRA) are other significant issues in UDN, which affect the Energy Efficiency (EE) and the Spectrum Efficiency (SE). Recent works in UDN have not presented the optimal SBSs On/Off switching and PCRA technique simultaneously to maximize the EE and the SE while ensuring Quality of Service (QoS) requirements of User Equipments (UE). In this paper, a distributed method based on a multi-agent Deep Q-Network (DQN) is proposed to deal with the mentioned challenges simultaneously. Therefore, each SBS can learn a policy for managing On/Off switching and downlink PCRA using two DQNs. The proposed method seeks to optimize the EE and the SE as well as guarantee the minimum required data rate of UEs. Simulation results show that the proposed method improves the EE and the SE compared to previous solutions. Furthermore, unlike previous distributed approaches that use the UEs as learning agents, the proposed method uses the SBSs as agents. Thus, the signaling overhead and computational complexity of the UEs decrease.}
}


@article{DBLP:journals/cn/AntevskiB23,
	author = {Kiril Antevski and
                  Carlos J. Bernardos},
	title = {Applying Blockchain consensus mechanisms to Network Service Federation:
                  Analysis and performance evaluation},
	journal = {Comput. Networks},
	volume = {234},
	pages = {109913},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109913},
	doi = {10.1016/J.COMNET.2023.109913},
	timestamp = {Sun, 19 Jan 2025 14:22:24 +0100},
	biburl = {https://dblp.org/rec/journals/cn/AntevskiB23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cutting edge (vertical) applications may swiftly saturate service providers’ virtualized infrastructure. In 5G and beyond, service providers seek out for innovative solutions such as Network Service Federation (NSF) which allows orchestration of external domain services/resources to provide a zero-downtime end-to-end vertical service. Distributed ledger technologies, such as Blockchain, are used to enhance the federation process. In this article, we propose and evaluate the application of Blockchain technology for NSF. We evaluate four different consensus mechanisms: Proof-of-Work (PoW), Proof-of-Authority (PoA), Practical Byzantine-Fault Tolerant (PBFT), and Proof-of-Stake (PoS). The experimental evaluation is executed using Ethereum, Tendermint and Cosmos platforms. Results show that the evaluated consensus mechanisms enable the use of NSF for both latency-sensitive and security stringent vertical applications.}
}


@article{DBLP:journals/cn/LiuSHY23,
	author = {Jiayi Liu and
                  Xiangjie Shi and
                  Yizhi Huang and
                  Qinghai Yang},
	title = {Selective and on-demand network measurement with SRv6 and {INT}},
	journal = {Comput. Networks},
	volume = {234},
	pages = {109914},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109914},
	doi = {10.1016/J.COMNET.2023.109914},
	timestamp = {Thu, 14 Sep 2023 20:26:40 +0200},
	biburl = {https://dblp.org/rec/journals/cn/LiuSHY23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Network measurement plays a critical role in network management to provide rich real-time network state for further network analysis. The novel network measurement approach, In-band Network Telemetry (INT), provides real-time and fine-grained packet-level network measurement. However, INT incurs significant overhead and lacks of flexibility to perform configurable on-demand network measurement. In this work, by combining the programmability of SRv6 and the telemetry efficiency of INT, we propose a Selective On-demand Network Measurement mechanism (SONM-SR-INT) to enable customizable network measurement where the measurement targets and telemetry information can be both configured. SRv6 is applied to both drive the measurement probing packet to follow a certain probing path to cover a given list of network targets, and facilitate the upper layer INT to perform per-hop customized network telemetry. We determine the optimum probing path by solving a Traveling Salesman Problem (TSP) in an auxiliary graph. We also define the SONM-SR-INT probing packet frame and packet processing mechanism. Finally, we implement SONM-SR-INT in P4 and validate its performance through a set of experiments.}
}


@article{DBLP:journals/cn/QuW23,
	author = {Xiaofeng Qu and
                  Huiqiang Wang},
	title = {Emergency task offloading strategy based on cloud-edge-end collaboration
                  for smart factories},
	journal = {Comput. Networks},
	volume = {234},
	pages = {109915},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109915},
	doi = {10.1016/J.COMNET.2023.109915},
	timestamp = {Mon, 04 Sep 2023 15:49:17 +0200},
	biburl = {https://dblp.org/rec/journals/cn/QuW23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The realization of smart factories is becoming increasingly possible due to the rapid development of edge computing technology and 5G communication technology. Smart devices in smart factories can perform tasks such as environmental monitoring, production scheduling, and autonomous mobility. These tasks cannot be completed on time depending only on the computing power of smart devices. Therefore, some tasks need to be performed on edge servers and cloud servers. However, events such as natural disasters, network attacks, and hardware failures will cause server computing resource failures. These threats bring hidden dangers to the normal operation of smart factories. This paper proposes an emergency offloading strategy based on cloud–edge-end collaboration for smart factories. In this strategy, the total task execution delay and the key task execution delay constitute an objective function, which is solved by a Fast Chemical Reaction Optimization (Fast-CRO) algorithm. The algorithm follows the principle of prioritizing the offloading of key tasks in emergency situations, and it quickly makes emergency offloading decisions for the system. Simulation results show that this strategy outperforms the other five baseline algorithms and existing priority based CRO algorithms.}
}


@article{DBLP:journals/cn/RaoC23,
	author = {K. Venkatakrishna Rao and
                  C. Ravindranath Chowdary},
	title = {K{\unicode{65291}}{\unicode{65291}} Shell: Influence maximization
                  in multilayer networks using community detection},
	journal = {Comput. Networks},
	volume = {234},
	pages = {109916},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109916},
	doi = {10.1016/J.COMNET.2023.109916},
	timestamp = {Thu, 14 Sep 2023 20:26:40 +0200},
	biburl = {https://dblp.org/rec/journals/cn/RaoC23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Selecting influential users in a network is essential to spread information quickly. Identifying influential users is very useful for viral marketing and brand communication. Influence maximization (IM) is selecting a few influential users in the network who can maximize the influence spread. Many existing algorithms address IM in single-layer networks. However, the study of IM in multi-layer networks is gaining importance after the advancement and rapid growth in the usage of online social networks. Studying IM in multi-layer networks in the context of viral marketing will be interesting. Motivated by this, this paper investigates the K＋＋ Shell decomposition algorithm to find the\nk\nset of influential nodes (seed nodes) in a multi-layer network. The proposed model prunes the nodes based on degree and assign reward points to their neighbors. We conducted a comparative study of various IM algorithms and reported the results. We observed that the K＋＋ Shell decomposition algorithm outperforms other algorithms on various real-time datasets under various settings and environments.}
}


@article{DBLP:journals/cn/FuHLCL23,
	author = {Yanming Fu and
                  Bocheng Huang and
                  Xiao Liu and
                  Jiayuan Chen and
                  Shenglin Lu},
	title = {Privacy-preserving mobile crowd sensing task assignment with Stackelberg
                  game},
	journal = {Comput. Networks},
	volume = {234},
	pages = {109917},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109917},
	doi = {10.1016/J.COMNET.2023.109917},
	timestamp = {Sat, 30 Sep 2023 10:07:02 +0200},
	biburl = {https://dblp.org/rec/journals/cn/FuHLCL23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Mobile Crowd Sensing (MCS) has emerged as an effective method for sensing and collecting large-scale computational data in real time, which is favored by researchers from a wide range of industries. Task assignment is an important research direction in mobile crowd sensing. In the scenario of multiple workers and multiple tasks, it is a key challenge to develop an excellent task assignment scheme to ensure that both the platform and workers can also get high utility while workers’ location privacy is not leaked. In this regard, this paper proposes a task assignment scheme (PCTA-SG) with worker location privacy protection and worker merit-based selection mechanism, which improves platform utility and equilibrates worker utility through worker path planning and Stackelberg game under the constraint of a limited perceived budget. First, the platform publishes the task set and its related information. Next, each candidate worker perturbs its own location locally based on geographical indistinguishability, and uploads the required information to the platform after selecting the tasks. Then a worker priority factor model is established by comprehensively considering the factors such as worker credibility, perceived device power and so on. According to the priority factors of workers, the platform uses a greedy strategy to select high-quality and suitable workers and assign tasks to them, thereby forming an initial solution for task assignment. To enhance the utility of the platform, the initial solution for task assignment is continued as the initial population of the genetic algorithm to optimize the moving distance of workers and generate the final solution for task assignment. Finally, on the basis of the final solution for task assignment, a two-stage Stackelberg game is carried out between the platform and workers to further optimize the utility of the platform and take into account the utility of workers, thus perfecting the task assignment scheme. The experimental evaluation results with other baseline schemes under real-world dataset show that the scheme in this paper achieves the best overall effect. It not only protects the location privacy of workers, but also achieves good worker utility while obtaining the optimal platform utility and platform input–output ratio.}
}


@article{DBLP:journals/cn/LiuLXXX23,
	author = {Libin Liu and
                  Jingzong Li and
                  Hong Xu and
                  Kaiwen Xue and
                  Chun Jason Xue},
	title = {Efficient Real-time Video Conferencing with Adaptive Frame Delivery},
	journal = {Comput. Networks},
	volume = {234},
	pages = {109918},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109918},
	doi = {10.1016/J.COMNET.2023.109918},
	timestamp = {Thu, 14 Sep 2023 20:26:40 +0200},
	biburl = {https://dblp.org/rec/journals/cn/LiuLXXX23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Real-time video conferencing systems have recently become indispensable tools. However, existing commodity video conferencing systems often fail to deliver a satisfactory quality of experience (QoE) due to discrepancies between the actual network throughput and the average bitrate of encoded videos. In this paper, we present a system called Tyrus that aims to achieve efficient real-time video conferencing. Tyrus adapts its delivery of B-frames based on the real network bandwidth and the average bitrate of encoded videos, effectively addressing the QoE loss caused by mismatch issues. This system can be easily implemented on top of prevalent video conferencing systems that utilize standard video encoders. Unlike traditional approaches that treat all frame types equally, Tyrus enables adaptive delivery of B-frames, prioritizing the allocation of bandwidth to other crucial video frames. By doing so, it reduces end-to-end conferencing latency, especially when the network throughput experiences significant fluctuations. Additionally, Tyrus defines the playing deadline for B-frames by considering factors such as delivery time, buffering time, and the progress of preceding frames. It accurately classifies frame types according to video coding standards and estimates bandwidth allocation on a frame-by-frame basis. Moreover, Tyrus proactively handles potential errors in B-frame playing deadline estimation, minimizing their impact on video conferencing performance. Our evaluation results, obtained through real implementation on top of WebRTC, demonstrate the effectiveness of Tyrus. On average, it reduces per-frame latency by 19.03%, video stalls by 22.36%, and improves bandwidth utilization by at least 10.29%.}
}


@article{DBLP:journals/cn/ZengLD23,
	author = {Yaoping Zeng and
                  Dongyang Lu and
                  Jianbo Du},
	title = {Joint optimized multi-user access and {UAV} deployments based on heterogeneous
                  revenue in IoT network},
	journal = {Comput. Networks},
	volume = {234},
	pages = {109919},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109919},
	doi = {10.1016/J.COMNET.2023.109919},
	timestamp = {Thu, 14 Sep 2023 20:26:40 +0200},
	biburl = {https://dblp.org/rec/journals/cn/ZengLD23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the explosion demands of computation in the internet-of-things (IoT) sector, as an emerging technique with considerable computational capability, unmanned aerial vehicle (UAV) assisted mobile edge computing (MEC) has been proposed to reduce the latency and improve the quality-of-experience (QoE) of the user equipments (UEs). However, being existed massive heterogeneous UEs with different time sensitivity, how to offload the tasks of UEs, and where to deploy the positions of UAVs are two critical factors for the MEC system. In this work, we investigate a multi-UAV-assisted MEC system to maximize the sum of UEs’ revenue in the event that natural disasters block communication conditions. A two-hierarchy Stackelberg game framework model is constructed, with the upper-layer UAVs as leaders performing location deployments, while the lower-layer UEs as followers conducting offloading selections. Different from the existing revenue functions, for followers, we adopt three revenue functions in terms of different UEs having distinct responses to time consuming. Furthermore, both the leader-layer and follower-layer subgame are proved to be exact potential games (EPG) with at least one Nash equilibrium (NE), then demonstrating the existence of Stackelberg equilibrium (SE). Additionally, we evaluate the price of anarchy (PoA) of the NE and illustrate that the value of PoA is relatively small, which corroborates that our solution is close to the global optimum. Finally, the simulation results demonstrate that the proposed solution can improve the total revenue of UEs under guaranteeing the convergence.}
}


@article{DBLP:journals/cn/AllegrettaSGG23,
	author = {Mauro Allegretta and
                  Giuseppe Siracusano and
                  Roberto Gonzalez and
                  Marco Gramaglia},
	title = {Are crowd-sourced {CTI} datasets ready for supporting anti-cybercrime
                  intelligence?},
	journal = {Comput. Networks},
	volume = {234},
	pages = {109920},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109920},
	doi = {10.1016/J.COMNET.2023.109920},
	timestamp = {Thu, 14 Sep 2023 20:26:40 +0200},
	biburl = {https://dblp.org/rec/journals/cn/AllegrettaSGG23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cyber crimes rapidly increased over the past years, with attackers performing large-scale activities, using sophisticated and complex tactics and techniques, that have targeted governments, companies, and even strategic infrastructures. To tackle these attacks, the cyber-security community usually shares Cyber Threat Intelligence (CTI) that includes the collected Indicators of Compromise (IoC) using several open or private sharing platforms. In this paper, we study the informativeness and relevance of the IoCs related to cyber crimes following a major real-world event such as the war in Ukraine, which started in February 2022. To this end, we analyze different kinds of attacks available in a crowd-sourced dataset of Cyber Threat Intelligence (CTI) reports. Our analysis shows that while this data is able to capture major trends such as the ones following major events, the degree of miscellaneous information inside the reports makes it difficult to discern the association of a specific trace unequivocally.}
}


@article{DBLP:journals/cn/FernandezVeigaVVR23,
	author = {Manuel Fern{\'{a}}ndez{-}Veiga and
                  M. Estela Sousa Vieira and
                  Ana Fern{\'{a}}ndez Vilas and
                  Rebeca P. D{\'{\i}}az Redondo},
	title = {Irregular repetition slotted Aloha with multiuser detection: {A} density
                  evolution analysis},
	journal = {Comput. Networks},
	volume = {234},
	pages = {109921},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109921},
	doi = {10.1016/J.COMNET.2023.109921},
	timestamp = {Sun, 24 Sep 2023 15:46:09 +0200},
	biburl = {https://dblp.org/rec/journals/cn/FernandezVeigaVVR23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Irregular repetition slotted Aloha (IRSA) has shown significant advantages as a modern technique for uncoordinated random access with massive number of users due to its capability of achieving theoretically a throughput of 1 packet per slot. When the receiver has also the multi-packet reception of multi-user (MUD) detection property, by applying successive interference cancellation, IRSA also obtains very low packet loss probabilities at low traffic loads, but is unable in general to achieve a normalized throughput close to 1. In this paper, we reconsider the case of IRSA with\nk\n-MUD receivers and derive the general density evolution equations for the non-asymptotic analysis of the packet loss rate, for arbitrary frame lengths and two operational variants: frame-structured and frameless transmissions. The first one defers transmission attempts until the beginning of the next frame of slots, while the second allows transmission immediately after a packet arrival. Next, using the potential function, we give new capacity bounds on the capacity of the system, showing the threshold arrival rate for zero decoding error probability. Our numerical results illustrate performance in terms of throughput and average delay for\nk\n-MUD IRSA with finite memory at the receiver, and also with bounded maximum delay.}
}


@article{DBLP:journals/cn/ChenMSKAHGPVLRZS23,
	author = {Tingjun Chen and
                  Prasanthi Maddala and
                  Panagiotis Skrimponis and
                  Jakub Kolodziejski and
                  Abhishek Adhikari and
                  Hang Hu and
                  Zhihui Gao and
                  Arun Paidimarri and
                  Alberto Valdes{-}Garcia and
                  Myung J. Lee and
                  Sundeep Rangan and
                  Gil Zussman and
                  Ivan Seskar},
	title = {Open-access millimeter-wave software-defined radios in the {PAWR}
                  {COSMOS} testbed: Design, deployment, and experimentation},
	journal = {Comput. Networks},
	volume = {234},
	pages = {109922},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109922},
	doi = {10.1016/J.COMNET.2023.109922},
	timestamp = {Sun, 04 Aug 2024 19:48:54 +0200},
	biburl = {https://dblp.org/rec/journals/cn/ChenMSKAHGPVLRZS23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {While millimeter-wave (mmWave) wireless has recently gained tremendous attention with the transition to 5G, developing a broadly accessible experimental infrastructure will largely facilitate the research and allow the community to make significant progress in this area. In this paper, we present the design and implementation of various programmable and open-access mmWave software-defined radios (SDRs) that have been deployed in the PAWR COSMOS advanced wireless testbed, in both indoor and outdoor environments. These programmable mmWave radios are based on the IBM 28 GHz 64-element dual-polarized phased array antenna module (PAAM) subsystem board and the Sivers IMA 60 GHz WiGig transceiver. These front ends are integrated with USRP SDRs or Xilinx RFSoC boards, which provide baseband signal processing capabilities. Moreover, we present measurements of the TX/RX beamforming performance and example experiments (e.g., real-time channel sounding and RFNoC-based 802.11ad preamble detection), using the mmWave radios. Finally, we discuss ongoing enhancement and development efforts focusing on these radios.}
}


@article{DBLP:journals/cn/KarMW23,
	author = {Snigdhaswin Kar and
                  Prabodh Mishra and
                  Kuang{-}Ching Wang},
	title = {Dynamic packet duplication for reliable low latency communication
                  under mobility in 5G {NR-DC} networks},
	journal = {Comput. Networks},
	volume = {234},
	pages = {109923},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109923},
	doi = {10.1016/J.COMNET.2023.109923},
	timestamp = {Thu, 14 Sep 2023 20:26:40 +0200},
	biburl = {https://dblp.org/rec/journals/cn/KarMW23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The fifth generation (5G) networks and beyond are key to meeting the exponentially increasing demands of next generation services for high throughput and reliable low latency communication under various mobility scenarios. These promising features have critical gaps to be filled before they can be fully implemented for mobile applications in complex environments like smart cities. Millimeter wave (mmWave) communications is a key enabler for a significant increase in the performance of these networks. However, due to the extremely limited transmission range of mmWave frequencies, 5G network deployments are designed to have several small cells operating in the mmWave frequency range using Ultra-dense networking (UDN) techniques to provide continuous coverage. But, such deployments not only face challenges in terms of a higher number of handovers, higher latency, lower reliability, and higher interference levels but also in terms of site acquisition, logistics, unbalanced load distributions, and power requirements. Multi-connectivity can improve the performance of UDNs and provide better deployment strategies as it provides multiple simultaneous links between the User Equipment (UE) and base stations. In such systems, packet duplication can be used to meet the stringent reliability and latency requirements of modern cellular networks as data packets are duplicated and transmitted concurrently over two or more independent links. The downside to packet duplication, however, is the increased usage of resources like spectrum, power, etc. In this work, we explore and analyze different techniques that could aid in reducing radio resource utilization without sacrificing the improvements in reliability and latency observed through packet duplication. To perform this study, we develop a novel 5G deployment with new radio dual connectivity (NR-DC) and packet duplication to improve reliability. We then analyze possible enhancements in the system to improve radio resource utilization when packet duplication is implemented. In this article, we propose and evaluate this novel 5G network deployment with multi-connectivity using Simu5G network simulator for enabling future 5G systems. The proposed 5G architecture is shown to meet the requirements of next generation applications. Our simulations show that the proposed techniques improve the throughput by up to 165.72%, the latency by up to 91.22%, and the packet loss decreases to near zero compared to a single link system.}
}


@article{DBLP:journals/cn/ManzoniPDRM23,
	author = {Pietro Manzoni and
                  Claudio E. Palazzi and
                  Fl{\'{a}}via Coimbra Delicato and
                  Erika Rosas and
                  Spyridon Mastorakis},
	title = {Editorial: Pub/sub solutions for interoperable and dynamic IoT systems},
	journal = {Comput. Networks},
	volume = {234},
	pages = {109925},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109925},
	doi = {10.1016/J.COMNET.2023.109925},
	timestamp = {Mon, 04 Sep 2023 15:49:17 +0200},
	biburl = {https://dblp.org/rec/journals/cn/ManzoniPDRM23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{DBLP:journals/cn/ErgunSC23,
	author = {Serap Erg{\"{u}}n and
                  Ibrahim Sammour and
                  G{\'{e}}rard Chalhoub},
	title = {A survey on how network simulators serve reinforcement learning in
                  wireless networks},
	journal = {Comput. Networks},
	volume = {234},
	pages = {109934},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109934},
	doi = {10.1016/J.COMNET.2023.109934},
	timestamp = {Thu, 14 Sep 2023 20:26:40 +0200},
	biburl = {https://dblp.org/rec/journals/cn/ErgunSC23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Rapid adoption of mobile devices, coupled with the increase in prominence of mobile applications and services, resulted in unprecedented infrastructure requirements for mobile and wireless networks. To improve user experience, future 5G and wireless network systems evolve to support increased mobile traffic, real-time precision analysis, and adaptable network resource management. As mobile environments become more complex, heterogeneous, and evolving, these tasks become more difficult. In order to solve these problems, many researchers rely on reinforcement learning. The success of reinforcement learning stems from its support for new and powerful tools that solve problems. Nodes mobility, instability of wireless connections, the coexistence of multiple wireless technologies, and resource sharing among users are a few examples of what makes a wireless network a dynamic system. Learning, which is the main feature of reinforcement learning, enables wireless nodes to adapt to the dynamics of the system over time. For the learning to be efficient, it should be done over realistic and varied conditions. This is where network simulation tools can be useful. Network simulators are extensively used when it comes to studying wireless network protocols. They offer the advantage of scaling up scenarios at minimum cost and the ability to test many possible configurations quicker under a controlled environment. The main purpose of this survey is to show how network simulators help in developing reinforcement learning techniques in wireless networks. We emphasize how these tools can be used in the learning process and which problems they can solve. In the end, we discuss open issues related to this topic and highlight some best practice guidelines when it comes to mixing network simulators, reinforcement learning, and wireless protocols.}
}


@article{DBLP:journals/cn/PhuLUHNBN23,
	author = {Anh Tuan Phu and
                  Bo Li and
                  Faheem Ullah and
                  Tanvir Ul Huque and
                  Ranesh Naha and
                  Muhammad Ali Babar and
                  Hung Nguyen},
	title = {Defending {SDN} against packet injection attacks using deep learning},
	journal = {Comput. Networks},
	volume = {234},
	pages = {109935},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109935},
	doi = {10.1016/J.COMNET.2023.109935},
	timestamp = {Sun, 06 Oct 2024 21:22:04 +0200},
	biburl = {https://dblp.org/rec/journals/cn/PhuLUHNBN23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The (logically) centralized architecture of software-defined networks makes them an easy target for packet injection attacks. In these attacks, the attacker injects malicious packets into the SDN network to affect the services and performance of the SDN controller and overflows the capacity of the SDN switches. Such attacks have been shown to ultimately stop the network functioning in real-time, leading to network breakdowns. There have been significant works on detecting and defending against similar DoS attacks in non-SDN networks, but detection and protection techniques for SDN against packet injection attacks are still in their infancy. Furthermore, many of the proposed solutions have been shown to be easily bypassed by simple modifications to the attacking packets or by altering the attacking profile. In this paper, we develop novel Graph Convolutional Neural Network models and algorithms for grouping network nodes/users into security classes by learning from network data. We start with two simple classes — nodes that engage in suspicious packet injection attacks and nodes that are not. From these classes, we then partition the network into separate segments with different security policies using distributed Ryu controllers in an SDN network. We show in experiments on an emulated SDN that our detection solution outperforms alternative approaches with above 99% detection accuracy for various types (both old and new) of injection attacks. More importantly, our mitigation solution maintains continuous functions of non-compromised nodes while isolating compromised/suspicious nodes in real-time. All code and data are publicly available for the reproducibility of our results.}
}


@article{DBLP:journals/cn/LuoWZ23,
	author = {Feng Luo and
                  Zitong Wang and
                  Baoyin Zhang},
	title = {Impact analysis and detection of time-delay attacks in time-sensitive
                  networking},
	journal = {Comput. Networks},
	volume = {234},
	pages = {109936},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109936},
	doi = {10.1016/J.COMNET.2023.109936},
	timestamp = {Thu, 14 Sep 2023 20:26:40 +0200},
	biburl = {https://dblp.org/rec/journals/cn/LuoWZ23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Time-sensitive networking (TSN) will be widely used in automotive industry and industrial automation because it can provide deterministic transmission. Most of the TSN traffic shaping mechanisms rely on clock synchronization between different devices in the network. However, Time-Delay Attacks (TDAs) can interfere with synchronization, which further reduces traffic transmission quality. Although some studies have proposed detection strategies against TDAs, they are oriented to traditional ethernet and restricted by network architecture and devices. Therefore, this paper first analyzes the impact of TDAs on traffic transmission quality under different combinations of Time-Aware Shaper (TAS) or Cyclic Queue Forwarding (CQF) with link redundancy. Then, this paper provides a distributed monitoring parameter using Per-Stream Filtering and Policing (PSFP) for the detection and localization of TDAs, in which a modified token bucket mechanism is applied. Finally, the paper models the application of TSN in automotive industry for verification and further evaluates the effectiveness of this parameter through simulation. The results show that TDAs can cause undesirable variations in traffic latency under TAS and CQF. While proper parameter configuration and link redundancy can mitigate the impact of TDAs, they cannot prevent them. Besides, the proposed parameter helps detect and locate TDAs in TSN effectively.}
}


@article{DBLP:journals/cn/BoutibaBK23,
	author = {Karim Boutiba and
                  Miloud Bagaa and
                  Adlen Ksentini},
	title = {Optimal radio resource management in 5G {NR} featuring network slicing},
	journal = {Comput. Networks},
	volume = {234},
	pages = {109937},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109937},
	doi = {10.1016/J.COMNET.2023.109937},
	timestamp = {Thu, 14 Sep 2023 20:26:40 +0200},
	biburl = {https://dblp.org/rec/journals/cn/BoutibaBK23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {3GPP 5G New Radio (NR) has introduced several new features that the network slicing concept can leverage to guarantee the heterogeneous requirements in terms of throughput and delays of expected 5G network services. Mainly, these features are (i) Mixed-numerology to control the time slot duration, hence guaranteeing low latency requirements; (ii) Bandwidth Parts (BWP) to control the number of radio resources allocated to users, hence satisfying different throughput requirements. However, efficient radio resource management is already complex, and adding these new dimensions will further increase this complexity. In this paper, we first propose modeling radio resource management in 5G NR featuring network slicing through a Mixed Integer Linear Program (MILP). For our best knowledge, this is the first MILP modeling of the radio resource management featuring network slicing taking into account (i) Mixed-numerology, (ii) both latency and throughput requirements (iii) multiple slice attach per UE (iv) Inter-Numerology Interference (INI). After showing that solving the problem takes an exponential time, we considered a new approach to solve it in a polynomial time, which is highly required when scheduling radio resources. The new approach consists of formalizing this problem using a Deep Reinforcement Learning (DRL)-based solver. We evaluate the use of RL to solve the problem for different network configurations and compared its performance with the optimal solution obtained by solving the MILP problem.}
}


@article{DBLP:journals/cn/OnsuKB23,
	author = {Murat Arda Onsu and
                  Burak Kantarci and
                  Azzedine Boukerche},
	title = {How to cope with malicious federated learning clients: An unsupervised
                  learning-based approach},
	journal = {Comput. Networks},
	volume = {234},
	pages = {109938},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109938},
	doi = {10.1016/J.COMNET.2023.109938},
	timestamp = {Thu, 14 Sep 2023 20:26:40 +0200},
	biburl = {https://dblp.org/rec/journals/cn/OnsuKB23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the advent of data-driven and Artificial Intelligence solutions, data providers such as Internet of Things (IoT)-enabled devices and sensors have become essential for intelligent services. In conventional machine learning, data collected from sensors and edge devices are transmitted to a centralized server for model training. Although it achieves state-of-the-art results, this process has drawbacks, such as privacy concerns, data leakage, etc. Specifically, some companies or services like hospitals want to keep their data themselves. Since they do not share data on a server, training on the centralized server cannot take the overall benefit of all data. Therefore a new training method is proposed, namely federated learning. In this learning, users keep their data to themselves and train their local model with their data. After training, users send their model weights to the server instead of data. When the centralized server takes all weights of users, it starts federated aggregations and generates a new global model. This new model is distributed among clients. This method provides privacy and security over clients’ data. However, In the malicious environment, where malicious clients trained with corrupted data send their weights to a centralized server, global model aggregation degrades because of harmful weights. Also, in a collaboration environment, where clients can send and receive data from other clients, malicious clients can send their corrupted data to benign clients, negatively affecting their local training. In the end, those clients might turn into partially malicious clients. In this work, we improve our previous research, score-based aggregation (SBA), and develop a malicious-client elimination algorithm before aggregation. With this algorithm, global model training can be converged higher scores according to unseen validation data scores even if there are 50% malicious rate among clients.}
}


@article{DBLP:journals/cn/ZhuBHY23,
	author = {Rongxin Zhu and
                  Azzedine Boukerche and
                  Xiangdang Huang and
                  Qiuling Yang},
	title = {{DESLR:} Energy-efficient and secure layered routing based on channel-aware
                  trust model for UASNs},
	journal = {Comput. Networks},
	volume = {234},
	pages = {109939},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109939},
	doi = {10.1016/J.COMNET.2023.109939},
	timestamp = {Thu, 14 Sep 2023 20:26:40 +0200},
	biburl = {https://dblp.org/rec/journals/cn/ZhuBHY23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Underwater acoustic sensor networks (UASNs) have garnered significant interest and have found widespread applications in smart ocean applications and auxiliary navigation. Nevertheless, UASNs encounter a multitude of challenges due to the constraints of the underwater environment, such as high energy consumption, secure transmission, and dynamic network topology in uncertain conditions. In this paper, we propose an energy-efficient and secure layered routing method (DESLR) for UASNs to enhance energy efficiency and improve transmission reliability. The DESLR establishes a channel-based trust model which considers factors of direct trust and indirect trust to describe the behaviors of nodes. In order to effectively identify malicious nodes, great consideration is given to the state of the acoustic channel’s reliability, as varying channel conditions can significantly impact packet transmission. An improved Ant Colony Optimization Algorithm (ACOA) is introduced to discover energy-efficient and low-latency routing paths by balancing energy consumption and routing distance. Additionally, DESLR utilizes a Layered Clustering method to group nodes into clusters and a two-layer fuzzy logic approach to select cluster heads (CH) that avoid hotspots and ensure uniform energy distribution. Simulation results demonstrate that DESLR can effectively detect defective nodes by analyzing anomalous behaviors and outperforms other related work in terms of energy consumption, average end-to-end delay, and packet loss.}
}


@article{DBLP:journals/cn/LiLXL23,
	author = {Bin Li and
                  Wenshuai Liu and
                  Wancheng Xie and
                  Xiaohui Li},
	title = {Energy-efficient task offloading and trajectory planning in UAV-enabled
                  mobile edge computing networks},
	journal = {Comput. Networks},
	volume = {234},
	pages = {109940},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109940},
	doi = {10.1016/J.COMNET.2023.109940},
	timestamp = {Mon, 05 Feb 2024 20:24:11 +0100},
	biburl = {https://dblp.org/rec/journals/cn/LiLXL23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In order to meet the double-sided challenges brought by the shortage of computation resources and energy of users, we investigate in this paper the optimization of energy efficiency (EE) in an unmanned aerial vehicle (UAV)-assisted wireless network, where UAV is functioned as a flying energy station and edge server to provide charging and computing services for ground users. We aim to maximize the average EE of the mobile edge computing network by the joint design of user transmit power, user computing frequency, UAV transmit power, bandwidth allocation, and UAV trajectory planning under strict energy and power constraints. In order to solve such challenging problem, we first elaborately construct a Markov decision process to model task offloading and resource allocation by learning from past experiences. Then, an average EE maximization method relying on deep reinforcement learning (DRL) is designed to efficiently adjust task offloading policy, where the policy of agent can be gradually improved by interacting with the environment and collecting the experience for learning. Finally, the EE-maximization proximal policy optimization (EE-PPO) algorithm is proposed to train the DRL agent and thereby solve this optimization problem. Numerical results are given to indicate that the proposed EE-PPO method has the properties of both fast convergence and well performance.}
}


@article{DBLP:journals/cn/AliJ23a,
	author = {Mohammad Furqan Ali and
                  Dushantha Nalin K. Jayakody},
	title = {Corrigendum to "SIMO-Underwater Visible Light Communication {(UVLC)}
                  system" Computer Networks. 2023 May 9:109750},
	journal = {Comput. Networks},
	volume = {234},
	pages = {109942},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109942},
	doi = {10.1016/J.COMNET.2023.109942},
	timestamp = {Mon, 04 Sep 2023 15:49:17 +0200},
	biburl = {https://dblp.org/rec/journals/cn/AliJ23a.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{DBLP:journals/cn/ShenGY23,
	author = {Bo Shen and
                  Qi Gu and
                  Gang Yang},
	title = {Joint task offloading and UAVs deployment for UAV-assisted mobile
                  edge computing},
	journal = {Comput. Networks},
	volume = {234},
	pages = {109943},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109943},
	doi = {10.1016/J.COMNET.2023.109943},
	timestamp = {Thu, 08 Aug 2024 22:03:56 +0200},
	biburl = {https://dblp.org/rec/journals/cn/ShenGY23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recent advances in artificial intelligence (AI) have impacts on the development of communication networks. Diversified applications and scenarios put forward AI-native requirement for communication network. The network is envisioned to offer high data rate and low-latency communications, pervasive artificial intelligence, full coverage and programmable service. With the aid of AI, autonomous unmanned aerial vehicles (UAVs) play an indispensable role in the emerging scenarios. Owing to their flexibility and scalability, UAVs can be utilized as the mobile platform to deliver various kinds of services in dynamic and adversarial environments, especially the emergency scenarios. In this article, we deal with the post-disaster scenarios that UAVs, equipped with computing servers, work with the remaining infrastructures to provide communication and computing services for the ground mobile users (GMUs). With the aim of minimizing the energy cost and computing delay of task offloading, a two-layer optimization mechanism that can dynamically orchestrate the task offloading decision and the UAVs deployment is proposed. In lower layer, the problem of making offloading decisions is formulated into an evolutionary game. Replicator dynamics is exploited to help users to make decisions. In upper layer, a clustering approach for users is introduced to avoid unbalanced load distribution. By suggesting the locations and number of UAVs based the clusters, system cost is further reduced. The fairness of service load among UAVs is also achieved. Numerical results demonstrate the effectiveness of the proposed two-layer optimization mechanism.}
}


@article{DBLP:journals/cn/SuL23,
	author = {Lina Su and
                  Zongpeng Li},
	title = {Incentive-driven long-term optimization for hierarchical federated
                  learning},
	journal = {Comput. Networks},
	volume = {234},
	pages = {109944},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109944},
	doi = {10.1016/J.COMNET.2023.109944},
	timestamp = {Thu, 14 Sep 2023 20:26:40 +0200},
	biburl = {https://dblp.org/rec/journals/cn/SuL23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Hierarchical federated learning (HFL), an emerging paradigm of the client-edge-cloud architecture, can effectively leverage nearby edge servers to conduct model aggregation, significantly reducing transmission overhead. HFL faces both technical and economic challenges: first, in the online setting, computation resources and network bandwidth can only reveal themselves when clients participate in HFL model training. Second, the model training process consumes substantial resources at the clients, such as energy, computation, and bandwidth. It is unrealistic to assume that all clients contribute their resources voluntarily. Thorough investigation is lacking for these challenges in existing HFL research. This work develops a novel online algorithm AUCS, based on the auction and combinatorial multi-armed bandit, to minimize the overall latency of HFL training. AUCS utilizes the ratio of upper confidence bound-based reward to the bid as a criterion for winner determination. Then, AUCS computes the key payment for each winner to guarantee truthfulness of the incentive mechanism. Theoretically, AUCS can achieve sub-linear regret, truthfulness, individual rationality and computational efficiency, and guarantees model convergence. Simulations on real-world datasets and training tasks demonstrate the advantages of AUCS in terms of training latency, model accuracy, and system efficiency.}
}


@article{DBLP:journals/cn/PeiZJL23,
	title = {Retraction notice to 'Personalized Federated Learning Framework for
                  Network Traffic Anomaly Detection'},
	journal = {Comput. Networks},
	volume = {234},
	pages = {109945},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109945},
	doi = {10.1016/J.COMNET.2023.109945},
	timestamp = {Tue, 05 Sep 2023 09:14:37 +0200},
	biburl = {https://dblp.org/rec/journals/cn/PeiZJL23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{DBLP:journals/cn/QuWYZ23,
	author = {Lianwei Qu and
                  Yong Wang and
                  Jing Yang and
                  Meng Zhao},
	title = {A heterogeneous network structure publishing security framework based
                  on cloud-edge collaboration},
	journal = {Comput. Networks},
	volume = {234},
	pages = {109947},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109947},
	doi = {10.1016/J.COMNET.2023.109947},
	timestamp = {Mon, 04 Sep 2023 15:49:17 +0200},
	biburl = {https://dblp.org/rec/journals/cn/QuWYZ23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the integration of different fields, a large amount of heterogeneous data converges into a heterogeneous network with different types of nodes and edges. Then it is published by the cloud platform for applications such as recommendation services and public opinion analysis. However, in traditional cloud platform data publishing, one is privacy leakage due to the long transmission delay to the cloud platform, and the other is privacy leakage due to privacy attacks during cloud platform data publishing. In addition, there is an imbalance between privacy and availability in the privacy protection of the network structure between heterogeneous nodes. To address these issues, we propose a heterogeneous network structure publishing security framework based on cloud-edge collaboration. In this framework, we design a non-interactive edge privacy protection center and provide a heterogeneous network data publishing privacy protection model (HNPP). First, the network between heterogeneous nodes is transformed into an equivalent homogeneous network based on trivial closure. Then, we use differential privacy and random perturbations to achieve the homogeneous network structure reconstruction. Finally, we only rely on generation rules and reconstructed equivalent homogeneous networks to generate the heterogeneous network structure. We conducted extensive experimental analysis on real datasets, and the results show that the original edge retention rate of the network after privacy protection is above 0.88, and the clustering precision is above 0.92. It shows that the HNPP model is able to balance the privacy and availability of heterogeneous network structure publishing.}
}


@article{DBLP:journals/cn/ZhouLWCW23a,
	author = {Boqing Zhou and
                  Sujun Li and
                  Jian{-}Xin Wang and
                  Yun Cheng and
                  Jie Wu},
	title = {Corrigendum to "A secure model against mobile sink replication attacks
                  in unattended sensor networks" COMPNW, Volume 221, February 2023,
                  109529},
	journal = {Comput. Networks},
	volume = {234},
	pages = {109955},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109955},
	doi = {10.1016/J.COMNET.2023.109955},
	timestamp = {Mon, 04 Sep 2023 15:49:17 +0200},
	biburl = {https://dblp.org/rec/journals/cn/ZhouLWCW23a.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}
