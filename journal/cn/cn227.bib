@article{DBLP:journals/cn/ZhangYZLY23,
	author = {Hang Zhang and
                  Dongqi Yan and
                  Yanxi Zhang and
                  Jiamu Liu and
                  Mingwu Yao},
	title = {Distributed synchronization based on model-free reinforcement learning
                  in wireless ad hoc networks},
	journal = {Comput. Networks},
	volume = {227},
	pages = {109670},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109670},
	doi = {10.1016/J.COMNET.2023.109670},
	timestamp = {Sun, 12 Nov 2023 02:17:56 +0100},
	biburl = {https://dblp.org/rec/journals/cn/ZhangYZLY23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Time synchronization is a key issue in wireless ad hoc networks. Due to the dynamic characteristics of such networks, distributed synchronization (DS) is preferred for its reliability and validity. However, one major drawback of this synchronization mechanism is that nodes exchange time synchronization messages with their neighbors, which can be very time-consuming. In order to reduce network synchronization overhead while maintaining synchronization quality, this paper presents a model-free reinforcement learning distributed synchronization (RLDS) by evaluating the current network state and node synchronization level, adaptively deciding that the current node interacts with a certain portion of its neighbors instead of all of them for synchronization information. The simulation results indicated that during the initial network synchronization, RLDS achieves the same synchronization accuracy as the traditional DS, while reducing the total communication overhead by 15%. The superiority of RLDS is more evident in the long-term maintenance of network synchronization, reducing the communication overhead by 48% during 500 rounds of synchronization. This is because the number of node neighbors in communication can be appropriately reduced, thus achieving an adaptive trade-off between ensuring time synchronization and saving communication overhead. This study shows the latent capacity of reinforcement learning in improving the performance of traditional ad hoc networking technologies.}
}


@article{DBLP:journals/cn/MyneniJSADCH23,
	author = {Sowmya Myneni and
                  Kritshekhar Jha and
                  Abdulhakim Sabur and
                  Garima Agrawal and
                  Yuli Deng and
                  Ankur Chowdhary and
                  Dijiang Huang},
	title = {Unraveled - {A} semi-synthetic dataset for Advanced Persistent Threats},
	journal = {Comput. Networks},
	volume = {227},
	pages = {109688},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109688},
	doi = {10.1016/J.COMNET.2023.109688},
	timestamp = {Sat, 13 May 2023 01:07:10 +0200},
	biburl = {https://dblp.org/rec/journals/cn/MyneniJSADCH23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {U\nn\nr\na\nv\ne\nl\ne\nd\nis a novel cybersecurity dataset capturing Advanced Persistent Threat (APT) attacks not available in the public domain. Existing cybersecurity datasets lack coherent information about sophisticated and persistent cyber-attack features, including attack planning and deployment, stealthiness of the attacker(s), longer dorm period between attack activities, etc. Our APT attack scenario in\nU\nn\nr\na\nv\ne\nl\ne\nd\nis implemented on a real network system established on a cloud platform to emulate an organization’s network system. The new dataset provides a comprehensive network flow and host-level log information about the normal user(s) traffic and the cyber attacks traffic. To emulate realistic network traffic scenarios,\nU\nn\nr\na\nv\ne\nl\ne\nd\nalso includes attacks at different skills reflecting a typical organization’s threat posture, and by utilizing APT attack information from one of the well-known APT attack databases, i.e., MITRE’s APT-group database. Furthermore, we design and develop an Employee Behavior Generation (EBG) model to emulate multiple normal employees’ traffic and activities during a 6-week time period based on their pre-defined business functions. Using well-known machine learning models for anomaly detection, we show that the APT attack activities in\nU\nn\nr\na\nv\ne\nl\ne\nd\nare hardly detected, indicating the need for more effective solutions that are based on datasets representing real world APT attacks.}
}


@article{DBLP:journals/cn/ShaoSZWGQ23,
	author = {Sujie Shao and
                  Lili Su and
                  Qinghang Zhang and
                  Shuang Wu and
                  Shaoyong Guo and
                  Feng Qi},
	title = {Multi task dynamic edge-end computing collaboration for urban Internet
                  of Vehicles},
	journal = {Comput. Networks},
	volume = {227},
	pages = {109690},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109690},
	doi = {10.1016/J.COMNET.2023.109690},
	timestamp = {Sat, 13 May 2023 01:07:10 +0200},
	biburl = {https://dblp.org/rec/journals/cn/ShaoSZWGQ23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As the future trend, more and more vehicles access to the Internet of Vehicles, which means that a huge number of tasks of the vehicle terminals need to be transformed and completed on the network. Edge computing makes the tasks executed on the edge nodes near the terminal, but some vehicle terminals are at a relatively idle state and these additional computing resources are not utilized, causing great waste of resources. What is more, it is hard to highly and comprehensively satisfy the high real-time requirements of some tasks. In order to execute these tasks efficiently, we propose a dynamic edge–end computing collaboration architecture for urban IoV. In this architecture, edge nodes and vehicle terminals can cooperate with each other, which means tasks can be allocated more dynamically and flexibly. We evaluate the completion of the task by considering task latency and overhead, task transmission model, task priority, as well as edge node and vehicle terminal’s capacity when defining task comprehensive utility. Then weformulate the task allocation as an optimization problem and propose an improved quantum particle swarm optimization algorithm to solve the problem. Simulation results show that the proposed strategy have better task allocation utility than other strategies, which can effectively solve the multi task allocation problem.}
}


@article{DBLP:journals/cn/GuptaYNGTP23,
	author = {Naveen Kumar Gupta and
                  Rama Shankar Yadav and
                  Rajendra Kumar Nagaria and
                  Deepak Gupta and
                  Achyut Mani Tripathi and
                  Om Jee Pandey},
	title = {Anchor-based void detouring routing protocol in three dimensional
                  IoT networks},
	journal = {Comput. Networks},
	volume = {227},
	pages = {109691},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109691},
	doi = {10.1016/J.COMNET.2023.109691},
	timestamp = {Fri, 21 Apr 2023 12:02:20 +0200},
	biburl = {https://dblp.org/rec/journals/cn/GuptaYNGTP23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent years, several applications of Internet of Things (IoT) have been observed in various areas including environmental monitoring, healthcare systems, cognitive smart agriculture, industrial control, smart homes, intelligent transportation systems, and traffic management. For such applications, wireless sensor networks (WSNs) are generally deployed to gather the sensed data from the targeted application field. In order to transfer the sensor node data to the gateway (sink node), novel routing protocols need to be developed, leading to reduced data transmission delay, high data throughput, and improved energy efficiency across the network. In this context, geographical routing protocol has been considered as a promising approach for the path selection in WSNs. This approach is full of scalability and multi-hop routing is performed using local decisions. However, geographical routing protocols suffer from the void node problem (VNP) i.e., a region where active nodes are not available in the direction closer to the destination. Numerous protocols have been designed to get recovery from VNP in 2D networks which cannot be directly applied to 3D networks. The 3D routing includes the networks deployed in the hilly area, high buildings, airborne region, underground, underwater and so forth. On applying the 2D routing protocols on complex 3D topology, the network may face additional problems like packet looping, routing failure, ambiguity, or increased data latency due to longer path. Further, the majority of geographical routing protocols follow the boundary of void which leads to a longer path. In order to address the aforementioned challenges, this paper presents a novel anchor-based void detouring routing (AVDR) protocol where anchor node is treated as a sub-destination which provides the direct smaller path between source and gateway nodes. The proposed method bypasses the void boundaries and directly connects source to anchor, anchor to destination, or two successive anchors. Further, anchor information is distributed to the desired region to reduce the periodic anchor advertisement process. The effectiveness of the proposed method has been tested over both, real field data set and simulated testbed with OMNET++ simulator. The results obtained over real field data set claim that the proposed method takes only 29.09 ms (ms) for transferring the data on an average. However, this value is 32.37 ms, 34.32 ms, 33.61 ms, 37.20 ms, and 38.73 ms, respectively, using A3DR, EDGR, GPSR-3D, BSMH, and RPL methods. Moreover, it is also noted that the proposed method achieves an improvement of 8.2%, 7.54%, 7.66%, 8.49%, and 8.22%, in routing stretch when compared to aforementioned methods, respectively. This improvement with respect to network overhead is 30.25%, 57.45%, 51.05%, 75.56%, and 58.89% using the proposed method.}
}


@article{DBLP:journals/cn/ZhangWWZY23,
	author = {Chunrui Zhang and
                  Gang Wang and
                  Shen Wang and
                  Dechen Zhan and
                  Mingyong Yin},
	title = {Cross-domain network attack detection enabled by heterogeneous transfer
                  learning},
	journal = {Comput. Networks},
	volume = {227},
	pages = {109692},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109692},
	doi = {10.1016/J.COMNET.2023.109692},
	timestamp = {Mon, 05 Aug 2024 08:28:10 +0200},
	biburl = {https://dblp.org/rec/journals/cn/ZhangWWZY23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent years, cybersecurity has been endlessly challenged by more and more sophisticated network attacks, due to lacking the ability to detect unknown attacks in time. Recent researches show that machine learning helps to improve the efficacy of network attack detection, by training network attack classification models with huge amount labeled data. However in internal networks, due to the scarcity of attack instances and lacking expert labor force to label the data, it is always difficult to obtain sufficient labeled data to train such models. To uncover unknown attacks with machine learning techniques in internal networks, we propose to exploit transfer learning to utilize public datasets that contains attack instances to train a prediction model that will be used for un-labeled internal datasets. The main problem is to address the heterogeneity between datasets. Specifically, we project two heterogeneous datasets into a common latent space and formulate an optimization problem to minimize the distance of two distributions in the common space. Then we apply MLP classifier to the projected data to identify attack instances in internal networks. We conduct experiments that perform transfer learning between the NSLKDD to UNSW-NB15 datasets. The results validate that the proposed method notably improves the cross-domain attack detection accuracy in learning scenarios, such as “DoS to DoS” and “R2L to Exploits”.}
}


@article{DBLP:journals/cn/BarakabitzeW23,
	author = {Alcardo Alex Barakabitze and
                  Ray Walshe},
	title = {Corrigendum to "SDN and {NFV} for QoE-driven multimedia services delivery:
                  The road towards 6G and beyond networks" COMPNW, Volume 214, September
                  2022, pp. 1-25, 109133},
	journal = {Comput. Networks},
	volume = {227},
	pages = {109694},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109694},
	doi = {10.1016/J.COMNET.2023.109694},
	timestamp = {Fri, 21 Apr 2023 12:02:20 +0200},
	biburl = {https://dblp.org/rec/journals/cn/BarakabitzeW23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{DBLP:journals/cn/LiuCZLL23,
	author = {Waixi Liu and
                  Jun Cai and
                  Yinghao Zhu and
                  Junming Luo and
                  Jin Li},
	title = {Load balancing inside programmable data planes based on network modeling
                  prediction using a {GNN} with network behaviors},
	journal = {Comput. Networks},
	volume = {227},
	pages = {109695},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109695},
	doi = {10.1016/J.COMNET.2023.109695},
	timestamp = {Thu, 08 Aug 2024 08:11:03 +0200},
	biburl = {https://dblp.org/rec/journals/cn/LiuCZLL23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In data center networks, existing control plane- and end host-based load-balancing methods are encumbered by excessively large decision delays during rapid reactions to microbursts. However, existing programmable data plane-based load balancing methods require large overheads involved in active probing. Accurate network modeling can optimize load balancing. However, existing modeling methods suffer from low generalization and high overhead. In this study, we propose a network modeling method based on a graph neural network (GNN) with basic network behavior (hereinafter called GNN-Behavior). This is derived from two inherent correlations observed: the correlation between global network behavior and basic network behavior and the correlation among basic network behaviors. We employed the GNN with an improved message-passing neural network to learn such two inherent correlations. Particularly, we considered modeling end-to-end delay as a use case to validate GNN-Behavior. Furthermore, we propose a packet-level load-balancing scheme inside programmable data planes (PDPs) based on the accurate prediction of end-to-end delay from the GNN-Behavior model(LBPP). LBPP is a control plane-PDP collaborative method that integrates a global view from a controller and quick response from switches. Experimental results demonstrate the feasibility and effectiveness of the GNN-Behavior and LBPP. Compared with queuing theory (QT), RouteNet, and GNN-based scheme, GNN-Behavior increases goodness of fit (R2) by 73.1%, 11.1%, and 3.74%, respectively. Under an unknown traffic control strategy, the generalization ability of GNN-Behavior is considerably better than that of QT and RouteNet. Compared with flow-level ECMP, flowlet-level LetFlow, and packet-level DRILL, LBPP can reduce average flow completion time by up to 43.9%, 37.4%, and 17.2%, respectively.}
}


@article{DBLP:journals/cn/JiJCGDW23,
	author = {Pengshuo Ji and
                  Jie Jia and
                  Jian Chen and
                  Liang Guo and
                  An Du and
                  Xingwei Wang},
	title = {Reinforcement learning based joint trajectory design and resource
                  allocation for RIS-aided {UAV} multicast networks},
	journal = {Comput. Networks},
	volume = {227},
	pages = {109697},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109697},
	doi = {10.1016/J.COMNET.2023.109697},
	timestamp = {Tue, 03 Dec 2024 17:09:08 +0100},
	biburl = {https://dblp.org/rec/journals/cn/JiJCGDW23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper investigates an unmanned aerial vehicle (UAV)-enabled multicast network, where the UAV serves as a mobile transmitter to send typical contents to its corresponding ground receivers. A reconfigurable intelligent surface (RIS) is deployed to enhance the service quality with a limited power supply in the UAV-enabled multicast network. It can reconfigure the signal propagation environment and improve the received power of ground receivers by adjusting the reflection coefficients. The sum rate maximization problem is formulated by jointly designing the UAV movement, RIS reflection matrix, and beamforming design from the UAV to users. This paper proposes a Beamforming control and Trajectory design algorithm based on a Multi-Pass Deep Q-Network (BT-MP-DQN). In the proposed algorithm, the UAV acts as an agent for periodically observing the state of the UAV multicast network and takes actions to adapt to the dynamic environment. Specifically, the movement of the UAV is discrete action, and the beamforming design is continuous action. The simulation results show that this proposed algorithm can effectively improve the achievable rate and satisfy the minimum rate of multicast group users. The deployment of the RIS is beneficial to network performance enhancement. In addition, the multicast network with UAV also outperforms the conventional multicast channel with a fixed-location transmitter.}
}


@article{DBLP:journals/cn/HuCLJWW23,
	author = {Xinxin Hu and
                  Hongchang Chen and
                  Shuxin Liu and
                  Haocong Jiang and
                  Kai Wang and
                  Yahui Wang},
	title = {Who are the evil backstage manipulators: Boosting graph attention
                  networks against deep fraudsters},
	journal = {Comput. Networks},
	volume = {227},
	pages = {109698},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109698},
	doi = {10.1016/J.COMNET.2023.109698},
	timestamp = {Sat, 30 Sep 2023 10:07:03 +0200},
	biburl = {https://dblp.org/rec/journals/cn/HuCLJWW23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Telecommunications fraud causes vast economic losses all over the world every year. Although Graph Neural Networks (GNNs) brings new possibilities to the solution of fraud detection problem, their performance in telecom fraud detection is not satisfying. An important reason is that little prior work has noticed the deep fraudster phenomenon, which makes it difficult to be eradicated. Another reason may be the shortage of available datasets for researchers. After all, few operators are willing to publish telecom fraud detection benchmark datasets due to the sensitivity and privacy of subscriber data, resulting in less related research work. In this paper, we rearrange and publish two real-world telecom fraud detection datasets based on publicly available sources on the Internet. And we propose a GNN-based semi-supervised telecom fraud detection method by Boosting graph Attention Networks Against Deep frAudsters (BANADA). Specifically, we first learn different neighbor weights with the help of inner-layer attention, and then design simplified inter-layer attention to achieve inter-layer feature aggregation. Finally, we use GNNs with different depths as different base classifiers and perform ensemble learning through AdaBoost to discriminate deep fraudsters. Extensive experiments on two real-world telecom fraud datasets demonstrate the effectiveness of our proposed BANADA, which outperforms all state-of-the-art GNNs and GNN-based fraud detectors. The BANADA code and datasets are available at https://github.com/xxhu94/BANADA.}
}


@article{DBLP:journals/cn/ZidicMKCL23,
	author = {Dinko Zidic and
                  Toni Mastelic and
                  Ivana Nizetic Kosovic and
                  Mario Cagalj and
                  Josip Lorincz},
	title = {Analyses of ping-pong handovers in real 4G telecommunication networks},
	journal = {Comput. Networks},
	volume = {227},
	pages = {109699},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109699},
	doi = {10.1016/J.COMNET.2023.109699},
	timestamp = {Sat, 13 May 2023 01:07:10 +0200},
	biburl = {https://dblp.org/rec/journals/cn/ZidicMKCL23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The last decade has been characterized by a rapid increase in the usage of mobile communications. One of the main aspects of mobile communications is mobility. This means that mobile phones have to switch between base station cells in order to support the uninterrupted usage of all available services within the area of the mobile network coverage. The process of switching user devices between base station cells is called a handover. Accordingly, base stations are optimized to serve mobile phones with certain moving velocities based on an area and user characteristics to better handle handovers. However, issues appear when a mobile phone starts switching rapidly between two different cells in a short period of time, referred to as ping-pong handover. These occurrences cause negative effects in terms of increased telecom operators signaling overhead and user dissatisfaction. The 3rd Generation Partnership Project (3GPP) defines a metric called ping-pong rate in order to analyze what is the most adequate base station configuration concerning different user velocities and how well base stations handle handovers. The ping-pong rate is defined as a share of ping-pong handovers in total handovers, without taking into consideration the conditions under which they occur. In this paper, the conditions under which ping-pong handovers occur are analyzed by using live, non-simulated data. Findings show that the handovers under different conditions have different probabilities to become ping-pong handovers. Furthermore, these findings are utilized for defining a new empiric metric used for evaluating the handover handling of pre-configured base stations. Consequently, the novel empiric metric provides better insights into the base station handling of handovers than the ping-pong rate defined by 3GPP.}
}


@article{DBLP:journals/cn/YuanWCCL23,
	author = {Jingling Yuan and
                  Nana Wang and
                  Siqi Cai and
                  Mincheng Chen and
                  Xinping Li},
	title = {AMLFN-AD:Adaptive multi-level integrated fusion attack detection framework
                  for intelligent building systems},
	journal = {Comput. Networks},
	volume = {227},
	pages = {109700},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109700},
	doi = {10.1016/J.COMNET.2023.109700},
	timestamp = {Sat, 29 Apr 2023 19:27:28 +0200},
	biburl = {https://dblp.org/rec/journals/cn/YuanWCCL23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the development of emerging information technologies such as Internet of Things (IoT), cloud/edge computing and big data, the traditional building has been promoted in the direction of intelligence and become an indispensable part of the smart city nowadays. A higher level of intelligence and automation in the building can further meet people’s diverse needs. However, the lack of network security protection can pose a serious threat to intelligent building systems and their users. Due to the complex and changeable network environment, network attack detection may face the difficulty of data and model overload and unsatisfactory detection accuracy. Although many network security technologies have been proposed, few of them aim at intelligent building systems. In view of this, we propose an adaptive multi-level integrated fusion network attack detection framework (AMLFN-AD) to detect network attacks for intelligent building systems. In the first level, an efficient classification model is used to quickly distinguish attack from normal samples. Then, attack and misclassified normal samples are reclassified in fine granularity with an adaptive ensemble model in the second level. We adopt a hybrid model selection method to adaptively choose base classifiers from a pre-trained model pool for the ensemble model. Moreover, oversampling and undersampling techniques are combined to reduce the impact of data imbalance problem. A series of experiments against other comparative methods are conducted on three datasets, and the obtained results show that AMLFN-AD can achieve superior performance.}
}


@article{DBLP:journals/cn/StokkinkIEP23,
	author = {Quinten Stokkink and
                  Can Umut Ileri and
                  Dick H. J. Epema and
                  Johan Pouwelse},
	title = {Web3 Sybil avoidance using network latency},
	journal = {Comput. Networks},
	volume = {227},
	pages = {109701},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109701},
	doi = {10.1016/J.COMNET.2023.109701},
	timestamp = {Tue, 07 May 2024 20:23:16 +0200},
	biburl = {https://dblp.org/rec/journals/cn/StokkinkIEP23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Web3 is emerging as the new Internet-interaction model that facilitates direct collaboration between strangers without a need for prior trust between network participants and without central authorities. However, one of its shortcomings is the lack of a defense mechanism against the ability of a single user to generate a surplus of identities, known as the Sybil attack. Web3 has a Sybil attack problem because it uses peer sampling to establish connections between users. We evaluate the promising but under-explored direction of Sybil avoidance using network latency measurements, according to which two identities with equal latencies are suspected to be operated from the same node, and thus are likely Sybils. Network latency measurements have two desirable properties: they are only malleable by attackers by adding latency, and they do not require any trust between network participants. Our basic SybilSys mechanism avoids Sybil attackers using only network latency measurements if attackers do not actively exploit their malleability. We present an enhanced version of SybilSys that protects against targeted attacks using a variant of the flow correlation attack, which we name TrafficJamTrigger. We show how the message flows of Round-Trip Time measurements can be used to expose attack patterns and we propose and evaluate six classifiers to recognize these patterns. Our experiments show, through both emulation and real-world deployment, that enhanced SybilSys can serve a fundamental role for Web3, effectively establishing connections to real users even in the face of networks consisting of 99% Sybils.}
}


@article{DBLP:journals/cn/Ugurlu23,
	author = {Onur Ugurlu},
	title = {{ADA-PC:} An asynchronous distributed algorithm for minimizing pairwise
                  connectivity in wireless multi-hop networks},
	journal = {Comput. Networks},
	volume = {227},
	pages = {109703},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109703},
	doi = {10.1016/J.COMNET.2023.109703},
	timestamp = {Sat, 29 Apr 2023 19:27:28 +0200},
	biburl = {https://dblp.org/rec/journals/cn/Ugurlu23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Reliability analysis is of great significance to designing and maintaining wireless multi-hop networks (WMhNs). In WMhNs, several reasons can cause a node to be inoperable, such as hardware failure, software errors, and battery drain. Failure of some critical nodes may partition networks into disconnected segments. The presence of such critical nodes may also reduce the network lifetime since they consume more energy for packet forwarding. Therefore, it is crucial to identify the critical nodes of the networks and strengthen them by adding more nodes surrounding those or creating alternate pathways connecting other nodes to ensure connectivity maintenance in WMhNs. One of the most common approaches in direction is detecting the cut nodes of the networks. However, although finding cut nodes provide helpful information, it may be insufficient for precise reliability analysis since finding cut nodes only does not consider the remaining network. Critical Node Problem (CNP) aims to detect the most important nodes of the network whose removal minimizes the pairwise connectivity (the total number of node pairs connected by at least one path). In other words, the CNP tries to identify a set of nodes whose absence partitions the network into several disconnected segments of similar size. Detecting critical nodes for pairwise connectivity reveals the weak points and bottlenecks of the networks and may help to increase the fault tolerance and lifetime of WMhNs. This paper proposes an Asynchronous Distributed Algorithm for minimizing Pairwise Connectivity (ADA-PC) in WMhNs. To the best of our knowledge, this is the first distributed algorithm for the targeted problem in the network literature. The proposed algorithm uses a distributed Breadth-First Search (BFS) tree which limits bit complexity to\nO\n(\nn\n.\nm\n.\nl\no\ng\n2\nn\n)\nand space complexity to\nO\n(\nd\n)\n, where\nd\nis the network’s diameter. The experimental study on both testbed experiment and simulation reveals that the proposed algorithm is capable of finding the most critical nodes with up to 60% lower sent bytes than the existing central algorithms.}
}


@article{DBLP:journals/cn/GuoSGLW23,
	author = {Hui Guo and
                  Ruichang Shi and
                  Pingli Gu and
                  Jialu Li and
                  Shulong Wang},
	title = {Allocating edge service resources to the up-offloaded vehicle tasks
                  in {ICV} environment},
	journal = {Comput. Networks},
	volume = {227},
	pages = {109715},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109715},
	doi = {10.1016/J.COMNET.2023.109715},
	timestamp = {Tue, 08 Oct 2024 15:20:44 +0200},
	biburl = {https://dblp.org/rec/journals/cn/GuoSGLW23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Inspired by the rapid proliferation of intelligent transportation and smart city, ICV (Intelligent and Connected Vehicle) has drawn much attention, which not only brings great opportunities but also poses new challenges to the dynamic vehicle task serving mode. In this paper, we focus on the edge resource allocation process of the overloaded vehicle tasks that offloaded to edge servers in ICV environment. First of all, we introduce MEC and SDN technology into the traditional IoV (Internet of Vehicle) architecture to construct an SDN-assisted ICV network model. Next, a BiGRU+Attention edge service resource demands predicting model is designed, and based on the above model, we are able to further assess the future edge service resources availability and perceive the future vehicle mobility. Then, we build a task serving delay minimization problem for the edge service resource allocation process, where the impact of resource allocation decision-makings on the global network performance is also considered in the form of soft constraints. Furthermore, we put forward a timeslot-based edge service resource allocation algorithm with three phases. Finally, we simulate our scheme and another three schemes on NS3 platform, the results show that our algorithm outperforms in terms of average task serving delay, success ratio and load distribution.}
}


@article{DBLP:journals/cn/VizzielloMSG23,
	author = {Anna Vizziello and
                  Maurizio Magarini and
                  Pietro Savazzi and
                  Laura Galluccio},
	title = {Intra-body communications for nervous system applications: Current
                  technologies and future directions},
	journal = {Comput. Networks},
	volume = {227},
	pages = {109718},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109718},
	doi = {10.1016/J.COMNET.2023.109718},
	timestamp = {Sat, 08 Jun 2024 13:14:22 +0200},
	biburl = {https://dblp.org/rec/journals/cn/VizzielloMSG23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Internet of Medical Things (IoMT) paradigm will enable next generation healthcare by enhancing human abilities, supporting continuous body monitoring and restoring lost physiological functions due to serious impairments. This paper presents intra-body communication solutions that interconnect implantable devices for application to the nervous system, challenging the specific features of the complex intra-body scenario. The presented approaches include both speculative and implementative methods, ranging from neural signal transmission to testbeds, to be applied to specific neural diseases therapies. Also future directions in this research area are considered to overcome the existing technical challenges mainly associated with miniaturization, power supply, and multi-scale communications.}
}


@article{DBLP:journals/cn/LuNHC23,
	author = {Yufei Lu and
                  Qian Ning and
                  Linyu Huang and
                  Bingcai Chen},
	title = {A network traffic prediction model based on reinforced staged feature
                  interaction and fusion},
	journal = {Comput. Networks},
	volume = {227},
	pages = {109719},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109719},
	doi = {10.1016/J.COMNET.2023.109719},
	timestamp = {Sat, 29 Apr 2023 19:27:28 +0200},
	biburl = {https://dblp.org/rec/journals/cn/LuNHC23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the increasingly intelligent services provided by the Internet, users’ requirements are further improved in communication quality. Real-time and accurate prediction of network traffic plays an important role in network resource allocation, abnormal traffic detection and other works. However, existing single or combined prediction methods cannot model its complex non-linear and spatial–temporal dependence. To address this problem, we propose a novel prediction model titled “reinforced staged spatial–temporal feature interaction and fusion (RSTIF)”. Specifically, we model the dynamic spatial dependence of the traffic through diffusion convolution. And then we deploy a staged feature interaction and fusion module. Spatial and temporal feature extractors are designed to cooperate with the interaction module. In the interaction process of feature integration-feedback, the complementary of temporal and spatial features are fully utilized, and the spatial–temporal dependence is modeled. We conduct extensive experiments on three real-world traffic datasets. The experiment results demonstrate that our model achieves state-of-the-art performance and is superior to the existing prediction models.}
}


@article{DBLP:journals/cn/SarahNK23,
	author = {Annisa Sarah and
                  Gianfranco Nencioni and
                  Muhidul Islam Khan},
	title = {Resource Allocation in Multi-access Edge Computing for 5G-and-beyond
                  networks},
	journal = {Comput. Networks},
	volume = {227},
	pages = {109720},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109720},
	doi = {10.1016/J.COMNET.2023.109720},
	timestamp = {Sat, 13 May 2023 01:07:09 +0200},
	biburl = {https://dblp.org/rec/journals/cn/SarahNK23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Innovative services with strict requirements are expected in the fifth generation (5G) of mobile networks and beyond. For example, the Ultra-Reliable Low-Latency Communication (URLLC) requires up to 1 ms latency, end-to-end security, and reliability of up to 99.999%. The Multi-access Edge Computing (MEC) promises to support the delivery of URLLC services by providing computing and storage resources in the proximity of user equipment. The data which previously needed to be processed and stored in the cloud systems can be kept at the edge network, decreasing the total latency and increasing the context-awareness, security, and dependability. Vastly available resources, which are available from cloud to edge, must be appropriately allocated to deliver a service efficiently. The resource allocation problem in MEC for 5G-and-beyond networks can be formulated differently, depending on the nature of the problem. This survey outlines the resource allocation problem as a proper problem formulation, which can be addressed by target, resource type, resource issue, and the considered assumptions. Moreover, this paper also describes the open issues and future directions for MEC resource allocation based on the state of the art on this research topic.}
}


@article{DBLP:journals/cn/LiuXXWYJ23,
	author = {Jian Liu and
                  Qingsai Xiao and
                  Liling Xin and
                  Qiuyun Wang and
                  Yepeng Yao and
                  Zhengwei Jiang},
	title = {{M3F:} {A} novel multi-session and multi-protocol based malware traffic
                  fingerprinting},
	journal = {Comput. Networks},
	volume = {227},
	pages = {109723},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109723},
	doi = {10.1016/J.COMNET.2023.109723},
	timestamp = {Sat, 30 Sep 2023 10:07:03 +0200},
	biburl = {https://dblp.org/rec/journals/cn/LiuXXWYJ23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent years, cyber attacks have become increasingly frequent, which has had a tremendous negative impact on public life and social order. Accurately and quickly finding malware traffic from massive network traffic is one of the keys to defending against network attacks. Traditional detection methods, whether signature-based or machine learning-based, use a packet or a session as the smallest detection unit. Usually, malware creates more than one session while executing malicious functions. Detecting these sessions alone without contextual information is prone to false negatives and false positives.}
}


@article{DBLP:journals/cn/MathurKGBL23,
	author = {Shikha Mathur and
                  Anshuman Kalla and
                  G{\"{u}}rkan G{\"{u}}r and
                  Manoj Kumar Bohra and
                  Madhusanka Liyanage},
	title = {A Survey on Role of Blockchain for IoT: Applications and Technical
                  Aspects},
	journal = {Comput. Networks},
	volume = {227},
	pages = {109726},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109726},
	doi = {10.1016/J.COMNET.2023.109726},
	timestamp = {Sun, 12 Nov 2023 02:17:57 +0100},
	biburl = {https://dblp.org/rec/journals/cn/MathurKGBL23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent times, IoT has emerged as a new paradigm for the interconnection of heterogeneous, resource-constrained, and communication-capable smart devices. It has been anticipated as a key enabler for various domains of applications such as health care, automotive, agriculture, industrial operations, automation, energy, and the next generation of living. However, the current IoT applications face significant challenges in terms of the huge amount of collected data, intensive data exchange, security, privacy, centralized processing, and interoperability. To mitigate many of these issues, blockchain has been identified as a promising innovative technology. Blockchain, in conjunction with smart contracts, has received significant attention both from the industry and academia and offers features such as irreversibility, non-repudiation, proof of provenance, fault tolerance, pseudonymity, decentralized operations and decision-making, and distributed ledger. The integration of blockchain with IoT requires essential insights concerning the application areas, scalability, security, privacy, data college and storage, performance, and governance. Thus, this paper intends to expound on the opportunities and key aspects of using blockchain in the IoT landscape. Specifically, this paper surveys the utilization of blockchain for various IoT applications. Besides, the paper distinguishes different technical aspects and presents the associated research challenges. At last, future research directions are discussed depending on the lessons learned.}
}


@article{DBLP:journals/cn/AlhamedSCOVPC23,
	author = {Faris Alhamed and
                  Davide Scano and
                  Piero Castoldi and
                  Juan Jose Vegas Olmos and
                  Ilya Vershkov and
                  Francesco Paolucci and
                  Filippo Cugini},
	title = {{P4} Telemetry collector},
	journal = {Comput. Networks},
	volume = {227},
	pages = {109727},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109727},
	doi = {10.1016/J.COMNET.2023.109727},
	timestamp = {Sun, 12 Nov 2023 02:17:57 +0100},
	biburl = {https://dblp.org/rec/journals/cn/AlhamedSCOVPC23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As the complexity of computer networks increases to accommodate the demand for massive connectivity and cloud services, so does the probability of fault occurrence and the surface of attacks. Hence the need for constant monitoring of network devices and accurate analysis of traffic patterns to ensure the highest performance and maximum security. This requires collecting and processing telemetry data from many sources in the network which leads to extra bandwidth usage and strains the CPU at the monitoring system resulting in scalability issues as the network grows. In this paper, we propose a two-stage postcard telemetry collector based on data plane programmability using the P4 language to address the scalability issues. We show a decrease in the CPU load of the telemetry server by over 70% while lowering the bandwidth to less than 7% in the most extreme scenario, at the cost of variable delay introduced in the collection of the postcards.}
}
