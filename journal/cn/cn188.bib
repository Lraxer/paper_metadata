@article{DBLP:journals/cn/TouijerMM21,
	author = {Bethaina Touijer and
                  Yann Ben Maissa and
                  Salma Mouline},
	title = {{IEEE} 802.15.6 {CSMA/CA} access method for WBANs: Performance evaluation
                  and new backoff counter selection procedure},
	journal = {Comput. Networks},
	volume = {188},
	pages = {107759},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2020.107759},
	doi = {10.1016/J.COMNET.2020.107759},
	timestamp = {Tue, 23 Mar 2021 12:07:17 +0100},
	biburl = {https://dblp.org/rec/journals/cn/TouijerMM21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Wireless body area networks (WBANs) are supposed to be an effective proposition to revolutionize the present and the future of health care services. They provide a proactive diagnosis for many deadly diseases, as well as remote and real-time monitoring. On the other hand, they impose several challenges to the medium access control (MAC) protocols design, regarding the energy-efficiency, quality-of-service, priority, scalability, reliability, and security. The standardization of the IEEE 802.15.6 provides new MAC specifications for WBANs, that take these issues into account. In the case of the narrowband frequency (402 to 405 MHz) dedicated to medical applications, the WBAN employs the carrier sense multiple access with collision avoidance (CSMA/CA) access method: the main contention-based access method of the IEEE 802.15.6 MAC protocol that supports the unpredictable data traffic. This access method suffers from the loss of its performance with the increase of the network density. Consequently, evaluating and improving it is important, especially with the sensitivity of the medical data it deals with. In this paper, we evaluate the performance of the IEEE 802.15.6 CSMA/CA access method, through an illustrative case-study, using the statistical model-checking (SMC) toolset UPPAAL-SMC. Then, based on the results of this evaluation regarding the negative impact of the converged contention window (\nC\nW\n) intervals, we propose new ones and a new backoff counter (\nB\nC\n) selection procedure. Relevant metrics we use are energy-efficiency, throughput, and delay. Finally, we validate the performance of our proposition, in comparison to the old one, on the same case-study and toolset. Our access method manages to decrease the number of collisions and to increase the number of packets successfully transmitted.}
}


@article{DBLP:journals/cn/KazemifardS21,
	author = {Nasim Kazemifard and
                  Vahid Shah{-}Mansouri},
	title = {Minimum delay function placement and resource allocation for Open
                  {RAN} {(O-RAN)} 5G networks},
	journal = {Comput. Networks},
	volume = {188},
	pages = {107809},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.107809},
	doi = {10.1016/J.COMNET.2021.107809},
	timestamp = {Tue, 23 Mar 2021 12:07:17 +0100},
	biburl = {https://dblp.org/rec/journals/cn/KazemifardS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Digitalization is a journey that has been started and put ICT industry in a crucial situation to provide required infrastructure for diverse range of data hungry, short tempered applications and services. One of the main technologies that will pave the way towards new digital ecosystem is fifth Generation of mobile technology. To meet 5G network service requirements, innovative architectures, technologies and standards focusing on cloudification are employed. Cloudification of network functions along with the use of virtualized network functions (VNFs) and containerized network functions (CNFs) allows agile and scalable service provisioning. The use of VNFs and CNFs has been started from core and networking middleboxes but then extended to RAN functions. Open radio access network (O-RAN) proposes an interoperable and standard architecture for cloudified RAN. The main idea behind this architecture is to make RAN more flexible. O-RAN allows different layers of RAN to be split and deployed as virtual function and openly communicate with each other for service provisioning. In this paper, we model an End-to-End mobile network operator (MNO) employing O-RAN. We consider a mobile network architecture, with three layer hierarchical data centers (Local, Regional, and Core) to add flexibility in resource allocation, and increase reliability, taking the advantages of O-RAN. MNO receives various service function requests (SFRs) requiring accommodation on the network. We assume RAN and core functions are deployed as CNFs on the data centers. Users of SFRs connects to remote radio heads (RRH) to receive the service. In this paper, we mathematically model the CNF placement and resource allocation of an O-RAN enabled LTE/5G network while trying to minimize the End-to-End delay of the data plane. We study the problem in two different cases First, we assume that the SFR traffic traverse through a single path across the RAN functions and model this problem. This is a mixed integer non-linear programming problem. With some change of variables, we make it a linear mixed integer programming problem but it is still non-trivial to solve. Then, we model the problem for the case where traffic of an SFR can be split and be served via multiple CNFs. We proposed a gradient based scheme to solve the minimum delay problem in this case.}
}


@article{DBLP:journals/cn/HendaouiEY21,
	author = {Fatma Hendaoui and
                  Hamdi Eltaief and
                  Habib Youssef},
	title = {{UAP:} {A} unified authentication platform for IoT environment},
	journal = {Comput. Networks},
	volume = {188},
	pages = {107811},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.107811},
	doi = {10.1016/J.COMNET.2021.107811},
	timestamp = {Wed, 07 Apr 2021 15:59:43 +0200},
	biburl = {https://dblp.org/rec/journals/cn/HendaouiEY21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Internet of Things (IoT) is a network that encompasses every physical object being connected to the Internet. The IoT objects face several issues and challenges due to the large number and the heterogeneity of the interconnected devices. Many researchers have shown that security is among the most important challenges that the IoT faces. Security requirements such as confidentiality, integrity and authentication are fundamental, but the last one is considered as the cornerstone security service.}
}


@article{DBLP:journals/cn/KhormaliPAASM21a,
	author = {Aminollah Khormali and
                  Jeman Park and
                  Hisham Alasmary and
                  Afsah Anwar and
                  Muhammad Saad and
                  David Mohaisen},
	title = {Corrigendum to "Domain name system security and privacy: {A} contemporary
                  survey" Computer Networks Volume 185 {(2020)} 107699},
	journal = {Comput. Networks},
	volume = {188},
	pages = {107814},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.107814},
	doi = {10.1016/J.COMNET.2021.107814},
	timestamp = {Mon, 28 Aug 2023 21:39:20 +0200},
	biburl = {https://dblp.org/rec/journals/cn/KhormaliPAASM21a.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{DBLP:journals/cn/ZhangWGYDYLGH21,
	author = {Yu Zhang and
                  Bo Wang and
                  Bingli Guo and
                  Yabo Yuan and
                  Tao Dong and
                  Jie Yin and
                  Kexin Li and
                  Xiang Guo and
                  Shanguo Huang},
	title = {A Research on Integrated Space-Ground Information Network Simulation
                  Platform Based on {SDN}},
	journal = {Comput. Networks},
	volume = {188},
	pages = {107821},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.107821},
	doi = {10.1016/J.COMNET.2021.107821},
	timestamp = {Tue, 23 Mar 2021 12:07:17 +0100},
	biburl = {https://dblp.org/rec/journals/cn/ZhangWGYDYLGH21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the development of society, ground communication technologies are hard to meet the demands of communicating at anytime and from anywhere. As a result, the integrated space-ground information network, which connects the satellites with ground stations to provide seamless and efficient global communications, is becoming one of the most important and potential networks for future communications. In the integrated space-ground information network, satellite network is a crucial part, in which problems caused by the dynamics are eager to be solved. To investigate those problems, this paper proposed an integrated space-ground information network simulation platform with STK(Satellite Tool Kit), Mininet and ONOS(Open Network Operating System) to simulate SDN(Software Defined Network) enabled networking devices. We designed a 3-layer(GEO/MEO/LEO) Walker constellation, a topology construction algorithm depending on available times of ISLs(inter-satellite links) and a routing algorithm considering both the processing delay and transmission delay. The simulation results show that the proposed topology construction algorithm could provide a relatively stable topology and reduce the computational resource consumption and the routing algorithm could control the delay of path to improve the quality of service. Indeed, the platform can support the simulation of integrated space-ground network with a good performance in solving problems caused by the dynamics of the satellite network.}
}


@article{DBLP:journals/cn/SalhabLR21,
	author = {Nazih Salhab and
                  Rami Langar and
                  Rana Rahim},
	title = {5G network slices resource orchestration using Machine Learning techniques},
	journal = {Comput. Networks},
	volume = {188},
	pages = {107829},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.107829},
	doi = {10.1016/J.COMNET.2021.107829},
	timestamp = {Wed, 07 Apr 2021 15:59:43 +0200},
	biburl = {https://dblp.org/rec/journals/cn/SalhabLR21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {To efficiently serve heterogeneous demands in terms of data rate, reliability, latency and mobility, network operators must optimize the utilization of their infrastructure resources. In this context, we propose a framework to orchestrate resources for 5G networks by leveraging Machine Learning (ML) techniques. We start by classifying the demands for resources into groups in order to adequately serve them by dedicated logical virtual networks or Network Slices (NSs). To optimally implement these heterogeneous NSs that share the same infrastructure, we develop a new dynamic slicing approach of Physical Resource Blocks (PRBs). On first hand, we propose a predictive approach to achieve optimal slicing decisions of the PRBs from a limited resource pool. On second hand, we design an admission controller and a slice scheduler and formalize them as Knapsack problems. Finally, we design an adaptive resource manager by leveraging Deep Reinforcement Learning (DRL). Using our 5G experimental prototype based on OpenAirInterface (OAI), we generate a realistic dataset for evaluating ML based approaches as well as two baselines solutions (i.e. static slicing and uninformed random slicing-decisions). Simulation results show that using regression trees for both classification and prediction, coupled with the DRL-based adaptive resource manager, outperform alternative approaches in terms of prediction accuracy, resource smoothing, system utilization and network throughput.}
}


@article{DBLP:journals/cn/GolkarifardCMM21,
	author = {Morteza Golkarifard and
                  Carla{-}Fabiana Chiasserini and
                  Francesco Malandrino and
                  Ali Movaghar},
	title = {Dynamic {VNF} placement, resource allocation and traffic routing in
                  5G},
	journal = {Comput. Networks},
	volume = {188},
	pages = {107830},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.107830},
	doi = {10.1016/J.COMNET.2021.107830},
	timestamp = {Wed, 12 May 2021 10:56:01 +0200},
	biburl = {https://dblp.org/rec/journals/cn/GolkarifardCMM21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {5G networks are going to support a variety of vertical services, with a diverse set of key performance indicators (KPIs), by using enabling technologies such as software-defined networking and network function virtualization. It is the responsibility of the network operator to efficiently allocate the available resources to the service requests in such a way to honor KPI requirements, while accounting for the limited quantity of available resources and their cost. A critical challenge is that requests may be highly varying over time, requiring a solution that accounts for their dynamic generation and termination. With this motivation, we seek to make joint decisions for request admission, resource activation, VNF placement, resource allocation, and traffic routing. We do so by considering real-world aspects such as the setup times of virtual machines, with the goal of maximizing the mobile network operator profit. To this end, first, we formulate a one-shot optimization problem which can attain the optimum solution for small size problems given the complete knowledge of arrival and departure times of requests over the entire system lifespan. We then propose an efficient and practical heuristic solution that only requires this knowledge for the next time period and works for realistically-sized scenarios. Finally, we evaluate the performance of these solutions using real-world services and large-scale network topologies. Results demonstrate that our heuristic solution performs better than a state-of-the-art online approach and close to the optimum.}
}


@article{DBLP:journals/cn/MorianoHC21,
	author = {Pablo Moriano and
                  Raquel Hill and
                  L. Jean Camp},
	title = {Using bursty announcements for detecting {BGP} routing anomalies},
	journal = {Comput. Networks},
	volume = {188},
	pages = {107835},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.107835},
	doi = {10.1016/J.COMNET.2021.107835},
	timestamp = {Fri, 14 May 2021 08:31:59 +0200},
	biburl = {https://dblp.org/rec/journals/cn/MorianoHC21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Despite the robust structure of the Internet, it is still susceptible to disruptive routing updates that prevent network traffic from reaching its destination. Our research shows that BGP announcements that are associated with disruptive updates tend to occur in groups of relatively high frequency, followed by periods of infrequent activity. We hypothesize that we may use these bursty characteristics to detect anomalous routing incidents. In this work, we use manually verified ground truth metadata and volume of announcements as a baseline measure, and propose a burstiness measure that detects prior anomalous incidents with high recall and better precision than the volume baseline. We quantify the burstiness of inter-arrival times around the date and times of four large-scale incidents: the Indosat hijacking event in April 2014, the Telecom Malaysia leak in June 2015, the Bharti Airtel Ltd. hijack in November 2015, and the MainOne leak in November 2018; and three smaller scale incidents that led to traffic interception: the Belarusian traffic direction in February 2013, the Icelandic traffic direction in July 2013, and the Russian telecom that hijacked financial services in April 2017. Our method leverages the burstiness of disruptive update messages to detect these incidents. We describe limitations, open challenges, and how this method can be used for routing anomaly detection.}
}


@article{DBLP:journals/cn/KilincerES21,
	author = {Ilhan Firat Kilincer and
                  Fatih Ertam and
                  Abdulkadir Seng{\"{u}}r},
	title = {Machine learning methods for cyber security intrusion detection: Datasets
                  and comparative study},
	journal = {Comput. Networks},
	volume = {188},
	pages = {107840},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.107840},
	doi = {10.1016/J.COMNET.2021.107840},
	timestamp = {Sat, 30 Sep 2023 10:07:03 +0200},
	biburl = {https://dblp.org/rec/journals/cn/KilincerES21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The increase in internet usage brings security problems with it. Malicious software can affect the operation of the systems and disrupt data confidentiality due to the security gaps in the systems. Intrusion Detection Systems (IDS) have been developed to detect and report attacks. In order to develop IDS systems, artificial intelligence-based approaches have been used more frequently. In this study, literature studies using CSE-CIC IDS-2018, UNSW-NB15, ISCX-2012, NSL-KDD and CIDDS-001 data sets, which are widely used to develop IDS systems, are reviewed in detail. In addition, max-min normalization was performed on these data sets and classification was made with support vector machine (SVM), K-Nearest neighbor (KNN), Decision Tree (DT) algorithms, which are among the classical machine learning approaches. As a result, more successful results have been obtained in some of the studies given in the literature. The study is thought to be useful for developing IDS systems on the basis of artificial intelligence with approaches such as machine learning.}
}


@article{DBLP:journals/cn/YangLMD21,
	author = {Lei Yang and
                  Liang Liu and
                  Zuchao Ma and
                  Youwei Ding},
	title = {Detection of selective-edge packet attack based on edge reputation
                  in IoT networks},
	journal = {Comput. Networks},
	volume = {188},
	pages = {107842},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.107842},
	doi = {10.1016/J.COMNET.2021.107842},
	timestamp = {Wed, 07 Apr 2021 15:59:43 +0200},
	biburl = {https://dblp.org/rec/journals/cn/YangLMD21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Internet of Things (IoT) is widely used in environmental monitoring, smart home and other fields, and has become a research hotspot in recent years. Due to its distributed nature, IoT is vulnerable to various attacks. In traditional packet attack, malicious nodes will indiscriminately attack packets. The existing detection algorithms can detect the attack by observing the overall behaviour of nodes. In this paper, we introduce an advanced attack named selective-edge packet attack, in which malicious nodes only attack packets sent to specific neighbours. Due to selectively attack packets, the attack is more covert than the traditional packet attack, which makes it difficult for the existing detection algorithms to detect. To detect selective-edge packet attack, we propose machine learning-based detection framework (MDMK) and machine learning-based detection algorithm (MDA) based on the framework, which uses regression algorithm and clustering algorithm to evaluate the reputation of communication links and nodes, and detects malicious nodes accordingly. To further improve the detection performance, machine learning-based detection algorithm with enhancement (MDAE) is designed by optimizing the routing path. The experimental results demonstrate that compared with the existing detection algorithms, the accuracy of MDA and MDAE in different situations is improved by around 7%–30% on average.}
}


@article{DBLP:journals/cn/GaoXC21,
	author = {Peixuan Gao and
                  Yang Xu and
                  H. Jonathan Chao},
	title = {{OVS-CAB:} Efficient rule-caching for Open vSwitch hardware offloading},
	journal = {Comput. Networks},
	volume = {188},
	pages = {107844},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.107844},
	doi = {10.1016/J.COMNET.2021.107844},
	timestamp = {Mon, 28 Aug 2023 21:39:20 +0200},
	biburl = {https://dblp.org/rec/journals/cn/GaoXC21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Open vSwitch (OVS) is a crucial component in today’s Software Defined Networking (SDN) and Network Function Virtualization (NFV) ecosystem. It has been widely deployed in datacenters to provide connectivity and virtual network services. Fast growing demands for cloud services require OVS to support complicated rules and provide high-throughput and low-latency data exchange with low host CPU overhead. However, the sophisticated packet classification operation required for every packet makes this goal a significant challenge. Hardware offloading is a popular solution boosting OVS’s performance, but the significant memory usage when directly applying the OVS’s rule-caching scheme makes it infeasible. In this paper, we propose OVS-CAB, an efficient rule-caching for OVS hardware offloading.}
}


@article{DBLP:journals/cn/XuNS21,
	author = {Chuan Xu and
                  Giovanni Neglia and
                  Nicola Sebastianelli},
	title = {Dynamic backup workers for parallel machine learning},
	journal = {Comput. Networks},
	volume = {188},
	pages = {107846},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.107846},
	doi = {10.1016/J.COMNET.2021.107846},
	timestamp = {Fri, 12 May 2023 14:41:09 +0200},
	biburl = {https://dblp.org/rec/journals/cn/XuNS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The most popular framework for distributed training of machine learning models is the (synchronous) parameter server (PS). This paradigm consists of\nn\nworkers, which iteratively compute updates of the model parameters, and a stateful PS, which waits and aggregates all updates to generate a new estimate of model parameters and sends it back to the workers for a new iteration. Transient computation slowdowns or transmission delays can intolerably lengthen the time of each iteration. An efficient way to mitigate this problem is to let the PS wait only for the fastest\nn\n−\nb\nupdates, before generating the new parameters. The slowest\nb\nworkers are called backup workers. The correct choice of the number\nb\nof backup workers depends on the cluster configuration and workload, but also (as we show in this paper) on the hyper-parameters of the learning algorithm and the current stage of the training. We propose DBW, an algorithm that dynamically decides the number of backup workers during the training process to maximize the convergence speed at each iteration. Our experiments show that DBW (1) removes the necessity to tune\nb\nby preliminary time-consuming experiments, and (2) makes the training up to a factor 3 faster than the optimal static configuration.}
}


@article{DBLP:journals/cn/VolnesKP21,
	author = {Espen Volnes and
                  Stein Kristiansen and
                  Thomas Plagemann},
	title = {Improving the accuracy of timing in scalable {WSN} simulations with
                  communication software execution models},
	journal = {Comput. Networks},
	volume = {188},
	pages = {107855},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.107855},
	doi = {10.1016/J.COMNET.2021.107855},
	timestamp = {Fri, 14 May 2021 08:32:00 +0200},
	biburl = {https://dblp.org/rec/journals/cn/VolnesKP21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Emerging infrastructure-less network architectures such as WSNs consist of devices that perform packet processing in software. General-purpose network simulators do currently not possess models to simulate the intra-node delay of such devices. For example, a TelosB mote with TinyOS spends seven ms on processing packets with a size of 36 bytes and fifteen ms on packets of 124 bytes. The core problem addressed in this work is that simulation does not include such delays, and therefore, the results are inaccurate. To overcome this problem, we create a communication software execution model of TelosB that accounts for its temporal behavior to enable more accurate WSN simulations in the ns-3 simulator. A challenge is to create a tracing framework for TinyOS that can be used to accurately and reliably trace the behavior of a very resource-constrained system. By analyzing the software execution of TelosB running TinyOS in the emulator Cooja/MSPSim and on a real device, we discover discrepancies in the temporal behavior. The evaluation of our model shows that it is scalable and accurate; the simulated intra-OS delay deviates at most 5% from the intra-OS delay in the real mote. When we include the model in simulations, the forwarding capacity of a mote is decreased by 36%. The WSN community can use this model for more realistic simulations, and future WSN mote models will be easier to make with it as a foundation.}
}


@article{DBLP:journals/cn/ZhangLGIR21,
	author = {Tianzhu Zhang and
                  Leonardo Linguaglossa and
                  Paolo Giaccone and
                  Luigi Iannone and
                  James Roberts},
	title = {Performance benchmarking of state-of-the-art software switches for
                  {NFV}},
	journal = {Comput. Networks},
	volume = {188},
	pages = {107861},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.107861},
	doi = {10.1016/J.COMNET.2021.107861},
	timestamp = {Wed, 07 Apr 2021 15:59:43 +0200},
	biburl = {https://dblp.org/rec/journals/cn/ZhangLGIR21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the ultimate goal of replacing proprietary hardware appliances with Virtual Network Functions (VNFs) implemented in software, Network Function Virtualization (NFV) has gained popularity in the past few years. Software switches are widely employed to route traffic between VNFs and physical Network Interface Cards (NICs). It is thus of paramount importance to compare the performance of different switch designs and architectures. In this paper, we propose a methodology to compare fairly and comprehensively the performance of software switches. We first explore the design spaces of 7 state-of-the-art software switches and then compare their performance under four representative test scenarios. Each scenario corresponds to a specific case of routing NFV traffic between NICs and/or VNFs. In our experiments, we evaluate the throughput and latency between VNFs in two of the most popular virtualization environments, namely virtual machines (VMs) and containers. Our experimental results show that no single software switch prevails in all scenarios. It is, therefore, crucial to choose the most suitable solution for the given use case. At the same time, the presented results and analysis provide a more in-depth insight into the design tradeoffs and identify potential performance bottlenecks that could inspire new designs.}
}


@article{DBLP:journals/cn/FaroughiMVFMJ21,
	author = {Azadeh Faroughi and
                  Andrea Morichetta and
                  Luca Vassio and
                  Flavio V. D. de Figueiredo and
                  Marco Mellia and
                  Reza Javidan},
	title = {Towards website domain name classification using graph based semi-supervised
                  learning},
	journal = {Comput. Networks},
	volume = {188},
	pages = {107865},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.107865},
	doi = {10.1016/J.COMNET.2021.107865},
	timestamp = {Wed, 16 Feb 2022 14:32:19 +0100},
	biburl = {https://dblp.org/rec/journals/cn/FaroughiMVFMJ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this work, we tackle the problem of classifying websites domain names to a category, e.g., mapping bbc.com to the ”News and Media” class. Domain name classification is challenging due to the high number of class labels and the highly skewed class distributions. Differently from prior efforts that need to crawl and use the web pages’ actual content, we rely only on traffic logs passively collected, observing traffic regularly flowing in the network, without the burden to crawl and parse web pages. We exploit the information carried by network logs, using just the name of the websites and the sequence of visited websites by users. For this, we propose and evaluate different classification methods based on machine learning. Using a large dataset with hundreds of thousands of domain names and 25 different categories, we show that semi-supervised learning methods are more suitable for this task than traditional supervised approaches. Using graphs, we incorporate in the classifier aspects not strictly related to the labeled data, and we can classify most of the unlabeled domains. However, in this framework, classification scores are lower than those usually found when exploiting the page-specific content. Our work is the first to perform an extensive evaluation of domain name classification using only passive flow-level logs to the best of our knowledge.}
}


@article{DBLP:journals/cn/BenedettiPG21,
	author = {Paolo Benedetti and
                  Giuseppe Piro and
                  Luigi Alfredo Grieco},
	title = {A softwarized and MEC-enabled protocol architecture supporting consumer
                  mobility in Information-Centric Networks},
	journal = {Comput. Networks},
	volume = {188},
	pages = {107867},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.107867},
	doi = {10.1016/J.COMNET.2021.107867},
	timestamp = {Tue, 23 Mar 2021 12:07:17 +0100},
	biburl = {https://dblp.org/rec/journals/cn/BenedettiPG21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Information-Centric Networking emerged as a powerful enabling technology for the provisioning of scalable and efficient real-time services in Future Internet, mobile architectures, and multi-hop wireless mesh networks. To serve mobile consumers, most of scientific contributions suggest to extend the information-centric communication primitives by means of a pull-based methodology, according to which the mobile consumer issues pending requests every time it reaches a new network attachment point. This approach, however, generates two important shortcomings. First, the requests delivered before the handover will generate stale paths with wrong forwarding information in their network routers. As a consequence, some new contents will be delivered also to previous locations, thus wasting bandwidth. Second, during handovers, mobile consumers may miss some contents released in real-time and lose the synchronization with the remote producer. In order to solve these issues, this work conceives a novel protocol architecture that successfully integrates and properly customizes the key functionalities of Information-Centric Networking, Multi-access Edge Computing, and Software Defined Networking paradigms. Specifically, the designed approach envisages that (1) Multi-access Edge Computing assists mobile consumers in retrieving data, while transparently managing the information-centric communication primitives and recovering the synchronization with the remote producer after the handover, (2) Software-Defined Controllers dynamically configure forwarding functionalities, and (3) Information-Centric Networking enables efficient data dissemination and delivers network control instructions. The impact of the devised protocol architecture on the communication overhead is analytically formulated and evaluated in scenarios with different topology, mobility, application settings, and number of mobile consumers. The comparison with respect to the pure Information-Centric Networking deployment demonstrates that the proposed solution ensures a reduction of the communication overhead up to 99.99% on the data plane, an overall bandwidth saving up to 99.93%, and a not negligible memory saving in intermediary routers. At the same time, the adoption of information-centric communication primitives for the control plane achieves an overhead reduction ranging from 29.36% to 51.13% with respect to an implementation based on the conventional OpenFlow protocol.}
}


@article{DBLP:journals/cn/Doost-Mohammady21,
	author = {Rahman Doost{-}Mohammady and
                  Oscar Bejarano and
                  Ashutosh Sabharwal},
	title = {Good times for wireless research},
	journal = {Comput. Networks},
	volume = {188},
	pages = {107870},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.107870},
	doi = {10.1016/J.COMNET.2021.107870},
	timestamp = {Wed, 07 Apr 2021 15:59:43 +0200},
	biburl = {https://dblp.org/rec/journals/cn/Doost-Mohammady21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Wireless communications has been one of the major success stories of engineering, and as a field of research, it’s future maybe even brighter than its past. The field will need many breakthroughs to achieve the grand vision of next-generation networks, and hence, it is important to empower thousands of researchers. One of the challenges is how do we empower experiment-based wireless research at a scale and speed not possible today. In this paper, we discuss the challenges faced by the experiment-based wireless research and ongoing efforts to address those challenges. We discuss the RENEW platform as part of the POWDER-RENEW city-scale testbed in Salt Lake City, which is dedicated to the deployment of massive MIMO technology and the tools that are developed for experimentation.}
}


@article{DBLP:journals/cn/AmaizuNBLK21,
	author = {Gabriel Chukwunonso Amaizu and
                  Cosmas Ifeanyi Nwakanma and
                  Sanjay Bhardwaj and
                  Jae{-}Min Lee and
                  Dong{-}Seong Kim},
	title = {Composite and efficient DDoS attack detection framework for {B5G}
                  networks},
	journal = {Comput. Networks},
	volume = {188},
	pages = {107871},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.107871},
	doi = {10.1016/J.COMNET.2021.107871},
	timestamp = {Fri, 02 Dec 2022 12:44:20 +0100},
	biburl = {https://dblp.org/rec/journals/cn/AmaizuNBLK21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Distributed denial-of-service (DDoS) remains an ever-growing problem that has affected and continues to affect a host of web applications, corporate bodies, and governments. With the advent of fifth-generation (5G) network and beyond 5G (B5G) networks, the number and frequency of occurrence of DDoS attacks are predicted to soar as time goes by, hence there is a need for a sophisticated DDoS detection framework to enable the swift transition to 5G and B5G networks without worrying about the security issues and threats. A range of schemes has been deployed to tackle this issue, but along the line, few limitations have been noticed by the research community about these schemes. Owing to these limitations/drawbacks, this paper proposes a composite and efficient DDoS attack detection framework for 5G and B5G. The proposed detection framework consists of a composite multilayer perceptron which was coupled with an efficient feature extraction algorithm and was built not just to detect a DDoS attack, but also, return the type of DDoS attack it encountered. At the end of the simulations and after testing the proposed framework with an industry-recognized dataset, results showed that the framework is capable of detecting DDoS attacks with a high accuracy score of 99.66% and a loss of 0.011. Furthermore, the results of the proposed detection framework were compared with their contemporaries.}
}


@article{DBLP:journals/cn/WangKD21,
	author = {Tao Wang and
                  Li Kang and
                  Jiang Duan},
	title = {Dynamic fine-grained access control scheme for vehicular ad hoc networks},
	journal = {Comput. Networks},
	volume = {188},
	pages = {107872},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.107872},
	doi = {10.1016/J.COMNET.2021.107872},
	timestamp = {Wed, 07 Apr 2021 15:59:43 +0200},
	biburl = {https://dblp.org/rec/journals/cn/WangKD21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Secure communication in vehicular ad hoc networks (VANETs) has been extensively researched; however, access control in VANETs has not been studied adequately. Access control ensures that only authorized vehicles receive quality services over the VANETs to enhance the driving experience. Attribute-based encryption (ABE) with revocation is a promising access control technique that keeps data confidential and is suitable for application in VANETs. However, most existing revocable ABE schemes require the private keys of all non-revoked users to be updated if the private key of any user is revoked, which makes the implementation of such schemes extremely inefficient. In this paper, a dynamic fine-grained access control scheme based on ABE is proposed to ensure vehicle network security. It enables the message sender to determine which vehicles receive the message according to their attributes and can also freely revoke the decryption authorization of certain vehicles without needing to update all non-revoked keys. To the best of our knowledge, this is the first time that secure and efficient dynamic access control in VANETs has been achieved. Performance analysis and simulation evaluations have shown that the algorithm is more efficient in terms of computational delay and communication overhead, as compared with existing schemes.}
}


@article{DBLP:journals/cn/KumarUT21,
	author = {Rohit Kumar and
                  Venkanna U. and
                  Vivek Tiwari},
	title = {Opt-ACM: An Optimized load balancing based Admission Control Mechanism
                  for Software Defined Hybrid Wireless based IoT (SDHW-IoT) network},
	journal = {Comput. Networks},
	volume = {188},
	pages = {107888},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.107888},
	doi = {10.1016/J.COMNET.2021.107888},
	timestamp = {Thu, 04 Jul 2024 21:53:03 +0200},
	biburl = {https://dblp.org/rec/journals/cn/KumarUT21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The wide network applications of Internet of Things (IoT) urge to integrate the different wireless networking technologies. However, the future generation technologies like Software Defined Networking (SDN) can be useful to alleviate the associated challenges such as security, installation issues, coverage, etc. The growing number of IoT users produce massive volume of traffic causing heavy network load conditions, resulting in the state of network congestion. The network congestion may cause severe performance degradation issues such as frequent packet drops, longer delays, low throughput, etc. Thus, a promising solution is needed to reduce and/or prevent the network congestion. This paper presents an Optimized load balancing based Admission Control Mechanism (Opt-ACM) for effective network flow management resulting in the reduced network congestion. In addition to this, the paper highlights the challenges of the existing solutions, and discusses a Software Defined Hybrid Wireless based IoT (SDHW-IoT) network architecture consisting of Software Defined Wireless Sensor Network (SDWSN) and Software Defined Wireless Mesh Network (SDWMN). To validate the efficiency of Opt-ACM, a Mixed-Integer Linear Programming (MILP) based optimization problem is formulated and tested using a well-known mathematical optimization solver called Gurobi. Additionally, Opt-ACM is also emulated in Mininet-Wifi with varying network scenarios against some traditional (OLSR and OSPF) and state-of-the-art (FACOR and EASDN) approaches. Opt-ACM achieves an overall efficiency of 9.47% and 12.32% over other approaches for Packet Delivery Ratio (PDR) and Packet Loss Ratio (PLR) respectively. Similarly, an average improved efficiency of 26.77% and 33.10% is achieved with respect to the Average Delay (AD) and Average Jitter (AJ) metrics respectively.}
}


@article{DBLP:journals/cn/DerakhshanfardS21,
	author = {Nahideh Derakhshanfard and
                  Reza Soltani},
	title = {Opportunistic routing in wireless networks using bitmap-based weighted
                  tree},
	journal = {Comput. Networks},
	volume = {188},
	pages = {107892},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.107892},
	doi = {10.1016/J.COMNET.2021.107892},
	timestamp = {Tue, 21 Mar 2023 21:08:28 +0100},
	biburl = {https://dblp.org/rec/journals/cn/DerakhshanfardS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Multi-hop wireless networks consist of a group of nodes that do not rely on pre-built infrastructures such as routers in wired networks or access points on managed wireless networks. Instead, each node contributes to the routing by forwarding data to other nodes. Each node can act as a router to transmit traffic to its intended destination. Opportunistic routing is used as an approach to increase the efficiency of multi-hop wireless networks. By using opportunistic routing, each packet is allowed to dynamically create a path from source to destination. This is done according to the conditions of the wireless links as the packet is being transmitted. In wireless networks, due to the mobility of nodes and no specific time for the connection between the nodes, it is necessary to select a method for routing and sending packets in the shortest possible time possible. The existence of interim and definitive communications, limited energy of the nodes, and additional network traffic are the challenges of multi-hop wireless networks. In the opportunistic routing, the next step of the packet transfer is determined in the same step. Choosing the next step is another key challenge in opportunistic routing. Most routing methods have problems such as low delivery rates, high delivery numbers, and high delivery times. This paper presents a bitmap-based approach. Using a bitmap, a tree is designed to send packets directly, without any additional and pointless routes, upon receiving a request to send a message to a specified node. Because in this way, each packet will have its unique path that finding it won't be time-consuming. The simulation results show that the proposed method has improved in terms of packet delivery ratio, delivery average, and the number of shipments compared to similar methods.}
}


@article{DBLP:journals/cn/TakedaSSO21,
	author = {Kenta Takeda and
                  Takehiro Sato and
                  Ryoichi Shinkuma and
                  Eiji Oki},
	title = {Multipath provisioning scheme for fault tolerance to minimize required
                  spectrum resources in elastic optical networks},
	journal = {Comput. Networks},
	volume = {188},
	pages = {107895},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.107895},
	doi = {10.1016/J.COMNET.2021.107895},
	timestamp = {Tue, 23 Mar 2021 12:07:17 +0100},
	biburl = {https://dblp.org/rec/journals/cn/TakedaSSO21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Multipath provisioning (MPP) uses multiple disjoint paths for data transmission to tolerate network failures. This paper proposes an MPP scheme, which allows allocating the different number of spectrum slots and different amount of transmission capacity to each path to minimize required spectrum resources in elastic optical networks. We present two optimization problems based on the proposed scheme and formulate them. Numerical results observe that the proposed scheme reduces the required spectrum resources compared to the conventional scheme, which allocates the same number of spectrum slots or the same amount of transmission capacity to each path.}
}
