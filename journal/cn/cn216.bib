@article{DBLP:journals/cn/PirayeshGCK22,
	author = {Jamshid Pirayesh and
                  Alberto Giaretta and
                  Mauro Conti and
                  Parviz Keshavarzi},
	title = {A PLS-HECC-based device authentication and key agreement scheme for
                  smart home networks},
	journal = {Comput. Networks},
	volume = {216},
	pages = {109077},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109077},
	doi = {10.1016/J.COMNET.2022.109077},
	timestamp = {Tue, 29 Nov 2022 16:01:50 +0100},
	biburl = {https://dblp.org/rec/journals/cn/PirayeshGCK22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {IoT devices permeate our society, collect personal data, and support critical infrastructures such as the healthcare. Therefore, there is a critical need for authentication and authorization schemes for IoT devices to meet privacy requirements, such as mutual authentication and user anonymity, as well as robustness against security attacks. In this paper, we propose a device authentication and key agreement scheme for IoT networks. Our proposal takes as a model the scheme proposed by Rezai et al., and combines it with a physical layer security technique and a hyper-elliptic curve cryptosystem. Our results show that not only our authentication scheme provides anonymity, mutual authentication, and efficiency, but it also provides resilience to various attacks, including man-in-the-middle, replay, and de-synchronization attacks. Our comparison shows that our scheme performs better than the state-of-the-art in terms of security properties, while adding a small overhead of\n≈\n10\n(\nms\n)\n.}
}


@article{DBLP:journals/cn/BeduneauJD22,
	author = {Guillaume B{\'{e}}duneau and
                  Ghada Jaber and
                  Bertrand Ducourthial},
	title = {A method for predicting {ITS} cooperative applications performances},
	journal = {Comput. Networks},
	volume = {216},
	pages = {109148},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109148},
	doi = {10.1016/J.COMNET.2022.109148},
	timestamp = {Mon, 28 Aug 2023 21:39:18 +0200},
	biburl = {https://dblp.org/rec/journals/cn/BeduneauJD22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Vehicular cooperation taking place in Intelligent Transportation Systems (ITS) aims to solve traffic issues or to improve road safety for vehicles and vulnerable road users. Such cooperation is achieved through distributed applications running in the vehicular network (VANET), composed of communicating units in vehicles and infrastructure. For safety and legal reasons, it is expected that ITS services reach a satisfactory level of efficiency in the context they are deployed. However, predicting the behavior of distributed applications running in dynamic topologies remains a complex problem, which limits their deployment. In this paper, we propose a method able to predict the performances of cooperative ITS (C-ITS) applications in dynamic vehicular networks. It concerns applications relying on messages exchanges between close vehicles or between vehicles and infrastructure. The proposed method is based on an analysis of the application with respect to the vehicular traffic for determining the conditions ensuring the success of its underlying distributed algorithms and protocols. This is formalized as performances properties depending on the network dynamic. It becomes then easy to check whether these conditions are fulfilled or not in a given road traffic, either captured (and anonymized) for an existing road or expected for a new one. Thanks to an appropriate modeling, the conditions are sought and the performances of the C-ITS applications are predicted. We believe that our approach fills a gap between formal studies, VANET simulations and road tests. It will be of particular interest for the deployment of C-ITS applications. This is illustrated by several use-cases studied in realistic conditions.}
}


@article{DBLP:journals/cn/YanMLHMX22,
	author = {Lei Yan and
                  Maode Ma and
                  Dandan Li and
                  Xiaohong Huang and
                  Yan Ma and
                  Kun Xie},
	title = {A flexible and lightweight privacy-preserving handshake protocol based
                  on DTLShps for IoT},
	journal = {Comput. Networks},
	volume = {216},
	pages = {109169},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109169},
	doi = {10.1016/J.COMNET.2022.109169},
	timestamp = {Tue, 18 Oct 2022 22:17:05 +0200},
	biburl = {https://dblp.org/rec/journals/cn/YanMLHMX22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Anonymous authentication is widely studied for preserving the privacy of IoT devices. Although attribute-based signature (ABS) schemes can show identity attributes flexibly, letting the private key be generated by someone else is not safe. The computational overhead of traditional anonymous credential schemes based on zero-knowledge proofs (ZKP) is heavy for resource-constrained IoT devices. DTLShps, a lightweight handshake protocol based on software-defined networking (SDN), brings a new thought to verify certificates for resource-constrained IoT devices without anonymous functions. In this article, a lightweight privacy-preserving handshake protocol is designed based on DTLShps to flexibly present attributes of anonymous certificates for resource-constrained IoT devices. An authorization code is designed to represent the authorization status of each identity attribute defined in the X.509 standard. The IoT device cooperating with the CA can flexibly show arbitrary identity attributes to its peer by the authorization code. Only one signing operation of the elliptic curve digital signature algorithm (ECDSA) is needed to grant the authorization on the IoT device with the cooperation of the controller. The security of the proposed scheme is validated by the BAN logic and the tool Scyther. The performance evaluation shows that the computational delay on the IoT device and overall handshake delay is effectively reduced compared with the existing anonymous certificate schemes.}
}


@article{DBLP:journals/cn/KhawamFLMM22,
	author = {Kinda Khawam and
                  Hassan Fawaz and
                  Samer Lahoud and
                  Odalric{-}Ambrym Maillard and
                  Steven Martin},
	title = {A channel selection game for multi-operator LoRaWAN deployments},
	journal = {Comput. Networks},
	volume = {216},
	pages = {109185},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109185},
	doi = {10.1016/J.COMNET.2022.109185},
	timestamp = {Mon, 28 Aug 2023 21:39:19 +0200},
	biburl = {https://dblp.org/rec/journals/cn/KhawamFLMM22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With over 75 billion Internet of Things (IoT) devices expected worldwide by the year 2025, inaugural MAC layer solutions for long-range IoT deployments no longer suffice. LoRaWAN, the principal technology for comprehensive IoT deployments, enables low power and long range communications. However, synchronous transmissions on the same spreading factors and within the same frequency channel, augmented by the necessary clustering of IoT devices, will cause collisions and drops in efficiency. The performance is further impacted by the shortage of radio resources and by multiple operators utilizing the same unlicensed frequency bands. In this paper, we propose a game theoretic based channel selection algorithm for LoRaWAN in a multi-operator deployment scenario. We begin by proposing an optimal formulation for the selection process with the objective of maximizing the total normalized throughput per spreading factor, per channel. Then, we propose centralized optimal approaches, as well as distributed algorithms, based on reinforcement learning and regret matching dynamics, to finding both the Nash and Correlated equilibria of the proposed game. We simulate our proposals and compare them to the legacy approach of randomized channel access, stressing their efficiency in improving the total normalized throughput as well as the packet delivery ratios.}
}


@article{DBLP:journals/cn/ElkaelAACJ22,
	author = {Maxime Elkael and
                  Massinissa Ait Aba and
                  Andrea Araldo and
                  Hind Castel{-}Taleb and
                  Badii Jouaber},
	title = {Monkey Business: Reinforcement learning meets neighborhood search
                  for Virtual Network Embedding},
	journal = {Comput. Networks},
	volume = {216},
	pages = {109204},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109204},
	doi = {10.1016/J.COMNET.2022.109204},
	timestamp = {Tue, 27 Sep 2022 16:31:00 +0200},
	biburl = {https://dblp.org/rec/journals/cn/ElkaelAACJ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this article, we consider the Virtual Network Embedding (VNE) problem for 5G networks slicing. This problem requires to allocate multiple Virtual Networks (VN) on a substrate virtualized physical network while maximizing among others, resource utilization, maximum number of placed VNs and network operator’s benefit. We solve the online version of the problem where slices arrive over time. Inspired by the Nested Rollout Policy Adaptation (NRPA) algorithm, a variant of the well known Monte Carlo Tree Search (MCTS) that learns how to perform good simulations over time, we propose a new algorithm that we call Neighborhood Enhanced Policy Adaptation (NEPA). The key feature of our algorithm is to observe NRPA cannot exploit knowledge acquired in one branch of the state tree for another one which starts differently. NEPA learns by combining NRPA with Neighborhood Search in a frugal manner which improves only promising solutions while keeping the running time low. We call this technique a monkey business because it comes down to jumping from one interesting branch to the other, similar to how monkeys jump from tree to tree instead of going down everytime. NEPA achieves better results in terms of acceptance ratio and revenue-to-cost ratio compared to other state-of-the-art algorithms, both on real and synthetic topologies.}
}


@article{DBLP:journals/cn/LimaM22,
	author = {Diogo Lima and
                  Hugo Miranda},
	title = {A geographical-aware state deployment service for Fog Computing},
	journal = {Comput. Networks},
	volume = {216},
	pages = {109208},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109208},
	doi = {10.1016/J.COMNET.2022.109208},
	timestamp = {Mon, 24 Oct 2022 20:51:28 +0200},
	biburl = {https://dblp.org/rec/journals/cn/LimaM22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Today’s distributed mobile applications assume a permanent network connectivity to mediate the interactions between a large number of users, coordinated by resourceful servers on cloud datacenters. Cloud-based distributed applications penalize performance with the unavoidable latency and jitter resulting from the geographical distance between clients and application servers. Fog Computing architectures mitigate this impact by deploying state fragments and providing computing power on surrogate servers, located at the network edge. Performance improves with the ability to deploy each fragment at the most convenient surrogate, and with efficient consistency procedures even when fragments at different locations are used. This paper presents a self-configuring geographical-aware state deployment service that combines a state deployment algorithm with a scalable distribution support framework.}
}


@article{DBLP:journals/cn/BhamareKVKTMOC22,
	author = {Deval Bhamare and
                  Andreas Kassler and
                  Jonathan Vestin and
                  Mohammad Ali Khoshkholghi and
                  Javid Taheri and
                  Toktam Mahmoodi and
                  Peter {\"{O}}hl{\'{e}}n and
                  Calin Curescu},
	title = {IntOpt: In-band Network Telemetry optimization framework to monitor
                  network slices using {P4}},
	journal = {Comput. Networks},
	volume = {216},
	pages = {109214},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109214},
	doi = {10.1016/J.COMNET.2022.109214},
	timestamp = {Mon, 24 Oct 2022 20:51:28 +0200},
	biburl = {https://dblp.org/rec/journals/cn/BhamareKVKTMOC22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The emergence of Network Functions Virtualization (NFV) is being heralded as an enabler of the recent technologies such as 5G/6G, IoT and heterogeneous networks. Existing NFV monitoring frameworks either do not have the capabilities to express the range of telemetry items needed to perform management or do not scale to large traffic volumes and rates. We present IntOpt, a scalable and expressive telemetry system designed for flexible NFV monitoring using active probing and P4. IntOpt allows us to specify monitoring requirements for individual service chain, which are mapped to telemetry item collection jobs that fetch the required telemetry items from P4 programmable data-plane elements. We propose mixed integer linear program (MILP) as well as a simulated annealing based random greedy (SARG) meta-heuristic approach to minimize the overhead due to active probing and collection of telemetry items. Using P4-FPGA, we benchmark the overhead for telemetry collection. Our numerical evaluation shows that the proposed approach can reduce monitoring overheads by 39% and monitoring delays by 57%. Such optimization may as well enable existing expressive monitoring frameworks to scale for larger real-time networks.}
}


@article{DBLP:journals/cn/GharagezlouNI22,
	author = {Abdolrasoul Sakhaei Gharagezlou and
                  Mahdi Nangir and
                  Nima Imani},
	title = {Energy efficient power allocation with joint antenna and user selection
                  in massive {MIMO} systems},
	journal = {Comput. Networks},
	volume = {216},
	pages = {109225},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109225},
	doi = {10.1016/J.COMNET.2022.109225},
	timestamp = {Tue, 18 Oct 2022 22:17:05 +0200},
	biburl = {https://dblp.org/rec/journals/cn/GharagezlouNI22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The problem of maximizing energy efficiency (EE) is considered in this paper. The system in question is a massive multiple-input multiple-output (MIMO) system that transmits information simultaneously in the uplink and downlink. To maximize EE, an optimal antenna selection strategy is used to send information. Furthermore, we propose an optimal user selection method and then obtain their optimal allocated power. The optimization problem of the system has two constraints, including power limitations in the uplink and downlink. Due to the non-convexity and being constrained of the optimization problem, in order to obtain the optimal power of users, it must first be converted to a convex problem form and then turned into an unconstrained problem using the Lagrange dual function method. The bisection algorithm is utilized to select the optimal set of active antennas for sending information. The cross-entropy algorithm with the proposed algorithm is used simultaneously to select the set of users and determine their optimal power values. The results of computer simulations show that the proposed selection schemes of antennas and users significantly improve the system performance.}
}


@article{DBLP:journals/cn/PaolucciSCP22,
	author = {Francesco Paolucci and
                  Davide Scano and
                  Piero Castoldi and
                  Emiliano De Paoli},
	title = {Latency control in service chaining using P4-based data plane programmability},
	journal = {Comput. Networks},
	volume = {216},
	pages = {109227},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109227},
	doi = {10.1016/J.COMNET.2022.109227},
	timestamp = {Tue, 18 Oct 2022 22:17:05 +0200},
	biburl = {https://dblp.org/rec/journals/cn/PaolucciSCP22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Service chaining is becoming one of the most considered service deployment frameworks in the context of Network Function Virtualization (NFV) in edge and data center environments, conveniently supported by automatic connectivity configurations offered by Software Defined Networking (SDN). Current research on the topic is focusing on how to guarantee Quality of Service (QoS) in terms of guaranteed end-to-end latency for time critical services. Indeed, latency issues may depend on intra-server virtualization inefficiencies, leading to Virtual Network Function (VNF) delivery delays, or by congestion events occurring at intermediate network elements connecting VNFs. Latency control requires stateful information such as flow delay measurements at a per-packet level, typically not available at traditional SDN switches or inside the VNF.}
}


@article{DBLP:journals/cn/VanithaSDN22,
	author = {C. N. Vanitha and
                  Malathy Sathyamoorthy and
                  Rajesh Kumar Dhanaraj and
                  Anand Nayyar},
	title = {Optimized pollard route deviation and route selection using Bayesian
                  machine learning techniques in wireless sensor networks},
	journal = {Comput. Networks},
	volume = {216},
	pages = {109228},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109228},
	doi = {10.1016/J.COMNET.2022.109228},
	timestamp = {Sat, 30 Sep 2023 10:07:05 +0200},
	biburl = {https://dblp.org/rec/journals/cn/VanithaSDN22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Optimal route selection and circumventing the route deviation is essential in sensor transmission to reach the destination properly and to save energy in sensors. Wireless sensor networks (WSNs) play an indispensable role to achieve faster communication. Sensors are tiny devices which can store less power and need the power to be retained until final communication. The main need is to achieve routing of the sensors while performing the data transmission should be taken care. Optimal routing technique is necessitated to transfer data from sensors in the clusters and to the central station. The main focus is to dwindle the battery power consumption and increase the network life time. In this proposed work, the route deviation is pollard by Bayesian machine learning technique which uses the posterior distribution incrementally when new evidence is occurred. The approach calculates the conditional probability using the prior knowledge to determine the route deviation and optimal route. The methodology mainly focuses on parameters like, end-to-end delay, detection of route deviation, optimal route selection and network life time. The experimental results of proposed Optimal Pollard Route Deviation using Bayesian (OPDB) protocol focuses on the evaluation metrics of machine learning algorithm in terms of accuracy and error rate. The proposed algorithm is 28.5% better in minimizing the route deviation, 86.67% improved route selection, delay is very much minimized up to 07.12% and the 93.87% improved network life time compared with other routing algorithms. The route deviation detection is 14.5% improved, optimal route selection is improved by 31.84%, delay is minimized by 20.32% and network lifetime is increased by15.24% while using the OPDB algorithm.}
}


@article{DBLP:journals/cn/OligeriSIP22,
	author = {Gabriele Oligeri and
                  Savio Sciancalepore and
                  Omar Adel Ibrahim and
                  Roberto Di Pietro},
	title = {{GPS} spoofing detection via crowd-sourced information for connected
                  vehicles},
	journal = {Comput. Networks},
	volume = {216},
	pages = {109230},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109230},
	doi = {10.1016/J.COMNET.2022.109230},
	timestamp = {Mon, 28 Aug 2023 21:39:18 +0200},
	biburl = {https://dblp.org/rec/journals/cn/OligeriSIP22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Modern vehicular systems rely on the Global Positioning System (GPS) technology to provide accurate and timely services. However, the GPS has been proved to be characterized by an intrinsic insecure design, thus being subject to several security attacks. Current solutions can reliably detect GPS spoofing attacks leveraging the physical features of the received GPS signals or resorting to multiple antennas. However, these techniques cannot be deployed when the physical properties of the received signals cannot be accessed, which is the most general case for commercial GPS receivers. Alternative solutions in the literature rely on the cross-check of the received signal with information coming from additional sources. However, such proposals are typically limited to a single source, are rarely supported by experimental results, and do not provide insights on the impact of several parameters, such as detection accuracy, time, false-positives, and robustness to malicious information.}
}


@article{DBLP:journals/cn/XieHXZL22,
	author = {Shengxu Xie and
                  Guyu Hu and
                  Chang{-}you Xing and
                  Jiachen Zu and
                  Yaqun Liu},
	title = {{FINT:} Flexible In-band Network Telemetry method for data center
                  network},
	journal = {Comput. Networks},
	volume = {216},
	pages = {109232},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109232},
	doi = {10.1016/J.COMNET.2022.109232},
	timestamp = {Tue, 18 Oct 2022 22:17:05 +0200},
	biburl = {https://dblp.org/rec/journals/cn/XieHXZL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {By embedding the state data maintained by the programmable data plane into user packets, the In-band Network Telemetry (INT) can greatly improve the freshness of measured data, such as capturing the micro-bursts in data center networks. However, because the existing INT schemes use fixed telemetry tasks and metadata adding strategies, INT cannot be adjusted in time according to the network state, thus lacking flexibility. To solve the above problems, we propose a Flexible In-band Network Telemetry method FINT. With the designed triple bitmap mechanism, telemetry tasks and parameters can be set dynamically at runtime, which providing flexibility without redeployment to improve telemetry efficiency and reduce the impact of telemetry on network performance. With the designed flexible INT field structure, the types of telemetry metadata carried by user packets can be flexibly selected without significantly adding the indication field. Based on this, to meet the limitation of packet length and reduces the impact on the flow completion time, a greedy telemetry metadata selection algorithm MSG is designed to preferentially select the telemetry metadata with maximum bit-width among the remaining telemetry metadata. The experimental results show that FINT is flexible in adjusting telemetry tasks and add telemetry metadata, and effectively reduce the average flow completion time of the mice flow carrying INT data in the network without significantly increasing the bandwidth consumption.}
}


@article{DBLP:journals/cn/Vargas-ArcilaCS22,
	author = {Angela M. Vargas{-}Arcila and
                  Juan Carlos Corrales and
                  Araceli Sanchis and
                  Alvaro Rend{\'{o}}n},
	title = {{SOFI} dataset: Symptom-fault relationship for IP-network},
	journal = {Comput. Networks},
	volume = {216},
	pages = {109233},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109233},
	doi = {10.1016/J.COMNET.2022.109233},
	timestamp = {Mon, 26 Jun 2023 20:51:10 +0200},
	biburl = {https://dblp.org/rec/journals/cn/Vargas-ArcilaCS22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This article describes a dataset of network performance and well-known faults. It is a dataset of symptom-fault causal relationships for an IP-based network. This information is periodically gathered from edge nodes of an emulated enterprise network. The dataset contains about 649 h of network monitoring data, 10 of which refer to artificially induced faults. Those faults are impact failures as faulty cables, fiber cuts, high link utilization, line card failure, link down, misconfigurations, protocol issues, and distribution layer going down. Data were methodically structured by an authoring tool. It is an original dataset created on purpose because of no availability of this dataset type. It is of interest to researchers in data mining, fault diagnosis, and overall network management.}
}


@article{DBLP:journals/cn/WuWHYG22,
	author = {Weiqi Wu and
                  Xingfu Wang and
                  Ammar Hawbani and
                  Longzhi Yuan and
                  Wei Gong},
	title = {A survey on ambient backscatter communications: Principles, systems,
                  applications, and challenges},
	journal = {Comput. Networks},
	volume = {216},
	pages = {109235},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109235},
	doi = {10.1016/J.COMNET.2022.109235},
	timestamp = {Mon, 28 Aug 2023 21:39:19 +0200},
	biburl = {https://dblp.org/rec/journals/cn/WuWHYG22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Owing to the nature of ultra-low-power and extremely low deployment as well as maintenance costs, ambient backscatter technology is promising to become a prominent choice of future low-power communications systems, especially Internet of Things (IoT). Considerable studies have been reported in the emerging area of ambient backscatter communications. However, there is a lack of this kind of survey that is specific to a certain area of ambient backscatter communications and discusses some of the latest systems and the developments in the emerging area. Therefore, in this paper, we provide a comprehensive survey of the existing literature related to ambient backscatter communications. We first present the basic principles of ambient backscatter communications covering architecture, basic techniques, and primer knowledge of ambient signals. After that, we provide a new taxonomy for ambient backscatter communications systems, based on the type of ambient signals. We also review different ambient backscatter communications systems proposed in the literature for each category. Then, we describe potential applications driven by ambient backscatter communications. Finally, some open issues and challenges for future research are identified and discussed.}
}


@article{DBLP:journals/cn/SunZCC22,
	author = {Guoying Sun and
                  Zhaoxin Zhang and
                  Yanan Cheng and
                  Tingting Chai},
	title = {Adaptive segmented webpage text based malicious website detection},
	journal = {Comput. Networks},
	volume = {216},
	pages = {109236},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109236},
	doi = {10.1016/J.COMNET.2022.109236},
	timestamp = {Sat, 30 Sep 2023 10:07:04 +0200},
	biburl = {https://dblp.org/rec/journals/cn/SunZCC22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Malicious websites pose a great threat to the physical and mental health and property security of netizens, and malicious website detection is a key research topic in network security. Many researchers first extract features from webpage texts, and then detect malicious websites through deep learning methods. However, due to the limited sequence length that the deep learning model can process, researchers generally directly discard the webpage text that exceeds the maximum sequence length (MSL), which will affect the website detection accuracy to a great extent. Therefore, a malicious website detection model based on adaptive segmented webpage text is proposed. By ensuring the integrity of webpage text, the malicious website detection results are significantly improved, which greatly contribute to the accurate handling of malicious websites in cyberspace. Firstly, according to the MSL set by deep learning model and the length of webpage text, the number of text segments of each webpage text is determined, and rich features are extracted from multiple spaces of each segmented text through Multi-Head Self-Attention (MHSA) mechanism. Secondly, in order to solve the problem of missing context continuity caused by segmentation, the hidden vector obtained by Bi-directional Long Short-Term Memory (BILSTM) in the previous segment is combined with the embedding vector of the latter segment, and then input into the MHSA network. Thirdly, combining the results of multiple segments into multi-channel vector, classification is carried out by multi-channel text convolution (MCTC) network. In order to avoid misclassification of website type caused by webpage text alone, the digital certificate and Uniform Resource Locator (URL) of website are used to assist in detecting malicious websites. Multiple comparison experiment results on the malicious and benign website datasets demonstrate that the proposed model outperforms the state-of-the-art comparison models, and experiment results on public text classification datasets demonstrate that the proposed model has strong generalization ability.}
}


@article{DBLP:journals/cn/NiuZCSG22,
	author = {Juncui Niu and
                  Shubin Zhang and
                  Kaikai Chi and
                  Guanqun Shen and
                  Wei Gao},
	title = {Deep learning for online computation offloading and resource allocation
                  in {NOMA}},
	journal = {Comput. Networks},
	volume = {216},
	pages = {109238},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109238},
	doi = {10.1016/J.COMNET.2022.109238},
	timestamp = {Tue, 21 Mar 2023 21:08:29 +0100},
	biburl = {https://dblp.org/rec/journals/cn/NiuZCSG22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The limited battery capacity and low computing capability of wireless Internet of Things (IoT) devices can hardly support computation-intensive and delay-sensitive applications. While recent development of wireless power transfer (WPT) and mobile edge computing (MEC) technologies help IoT devices harvest energy and offload computation tasks to edge servers. While it is still challenging to design an efficient offloading policy to improve the performance of the IoT network. In this article, we consider a MEC network that has WPT capability and adopts the non-orthogonal multiple access (NOMA) technology to offload tasks partially. Our goal is to propose an online algorithm to optimize resource allocation under a wireless dynamic channel scenario. In order to obtain the optimal offloading decision and resource allocation efficiently, we propose a Deep Reinforcement learning-based Online Sample-improving (DROS) framework which implements a deep neural network to input the discretized channel gains to obtain the optimal WPT duration. Based on the WPT duration derived by DNN, we design an optimization algorithm to derive the optimal energy proportion for offloading data. Numerical results verify that compared with traditional optimization algorithms, our proposed DROS has significantly sped up convergence for better solutions.}
}


@article{DBLP:journals/cn/NahaGBAG22,
	author = {Ranesh Naha and
                  Saurabh Kumar Garg and
                  Sudheer Kumar Battula and
                  Muhammad Bilal Amin and
                  Dimitrios Georgakopoulos},
	title = {Multiple linear regression-based energy-aware resource allocation
                  in the Fog computing environment},
	journal = {Comput. Networks},
	volume = {216},
	pages = {109240},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109240},
	doi = {10.1016/J.COMNET.2022.109240},
	timestamp = {Thu, 07 Mar 2024 22:42:57 +0100},
	biburl = {https://dblp.org/rec/journals/cn/NahaGBAG22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Fog computing is a promising computing paradigm for processing time-sensitive Internet of Things (IoT) applications. It helps process application requests close to the users to deliver faster processing outcomes than the Cloud by minimising overall response time. The Fog computing computation environment is highly dynamic regarding resource availability and communication. Furthermore, most Fog devices are battery-powered; hence, the chances of the failure of the application processing is high, leading to delaying the application outcome. If we process the application requests on other available devices after the failure occurs, it might cause delay and may not comply with time-sensitive requirements. To avoid application processing failure due to power unavailability, we can run applications in an energy-aware manner. This is a challenging task due to the dynamic nature of the Fog computing environment. It is required to allocate resources for application requests so that the application processing should not fail due to the unavailability of power. In this paper, we propose a multiple linear regression-based resource allocation mechanism to run applications with energy-awareness in the Fog computing environment. This approach minimises failures due to power constraints of the devices. Prior works lack energy-aware application execution considering the dynamism of the Fog computing environment. Hence, we propose multiple linear regression-based approaches to achieve energy-awareness objectives. We present a sustainable energy-aware framework and algorithm that executes applications in a Fog environment in an energy-aware manner that minimises application execution failures. The trade-off between energy-efficient allocation and application execution time has been investigated and shown to have a minimum negative impact on the system while employing energy-aware allocation. The evaluation of the proposed method is carried out in a controlled simulation environment by extending CloudSim toolkit. We compared our proposed method with existing approaches. Our proposed approach minimises the delay and processing time by 20%, and 17% compared with the existing one. Furthermore, SLA violations decreased by 57% for the proposed energy-aware allocation.}
}


@article{DBLP:journals/cn/LiZTRW22,
	author = {Yanbin Li and
                  Jiajie Zhu and
                  Ming Tang and
                  Shougang Ren and
                  Fusheng Wu},
	title = {{TSCL:} {A} time-space crossing location for side-channel leakage
                  detection},
	journal = {Comput. Networks},
	volume = {216},
	pages = {109242},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109242},
	doi = {10.1016/J.COMNET.2022.109242},
	timestamp = {Sat, 11 Jan 2025 00:33:55 +0100},
	biburl = {https://dblp.org/rec/journals/cn/LiZTRW22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cryptographic algorithms on devices are vulnerable to the so-called side-channel attacks(SCAs). The security evaluation of the cryptographic circuits is necessary to provide earlier leakage detection before manufacture. However, the complexity of locating leakage points is high because of the long execution time and the large scale of the circuit. To overcome this limitation, we propose an efficient leakage location method named time–space crossing location(TSCL) to locate the leakage in the hardware design, which combines the dynamic and static analysis. Unlike the traditional detection methods, we analyze the design features and power consumption characteristics of implementation to construct the candidate set on dynamic detection while further verifying candidate leakage points in the static detection stage. The t-test is known as a dynamic detection method to decrease the time of formal verification based on label propagation. The design features decrease the complexity of dynamic detection while the results of power consumption analysis promote static detection. We confirm the efficiency of the proposed method on unprotected and masking implementation of AES. Moreover, TSCL can be regarded as a third-party tool in the existing EDA tools of hardware design.}
}


@article{DBLP:journals/cn/SharmaP22,
	author = {Payal Sharma and
                  B. R. Purushothama},
	title = {{BP-MGKM:} An efficient multi-group key management scheme based on
                  bivariate polynomial},
	journal = {Comput. Networks},
	volume = {216},
	pages = {109244},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109244},
	doi = {10.1016/J.COMNET.2022.109244},
	timestamp = {Tue, 07 May 2024 20:23:16 +0200},
	biburl = {https://dblp.org/rec/journals/cn/SharmaP22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As wireless sensor networks are becoming increasingly reliant on communication among heterogeneous wireless sensor nodes, the need for secure communication in multi-groups has grown tremendously. Secure group key management in the multi-group scenario is a major challenge. The existing group key management schemes focus on managing a single group. However, there is not much work done regarding secure communication in multiple groups simultaneously. Existing multi-group key management schemes usually fail to meet the performance demands and suffer from improper management of keys, violation of security requirements, or huge complexity. We have analyzed the existing schemes for secure multi-group key management and found that the major issue lies in the complexity overhead during the membership update process in the multi-group scenario. On that account, we have proposed a new and efficient scheme (BP-MGKM) for secure multi-group key management based on bivariate polynomial. BP-MGKM is more efficient than other existing schemes in the context of complexity incurred during re-keying procedures. BP-MGKM features forward and backward secrecy, resilience against node compromise attack, collusion attack, and replay attack. The proposed scheme is secure and efficient than the existing schemes.}
}


@article{DBLP:journals/cn/TedeschiSP22,
	author = {Pietro Tedeschi and
                  Savio Sciancalepore and
                  Roberto Di Pietro},
	title = {Satellite-based communications security: {A} survey of threats, solutions,
                  and research challenges},
	journal = {Comput. Networks},
	volume = {216},
	pages = {109246},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109246},
	doi = {10.1016/J.COMNET.2022.109246},
	timestamp = {Mon, 28 Aug 2023 21:39:19 +0200},
	biburl = {https://dblp.org/rec/journals/cn/TedeschiSP22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Satellite-based Communication (SATCOM) systems are gaining renewed momentum in Industry and Academia, thanks to innovative services introduced by leading tech companies and the promising impact they can deliver towards the global connectivity objective tackled by early 6G initiatives. On the one hand, the emergence of new manufacturing processes and radio technologies promises to reduce service costs while guaranteeing outstanding communication latency, available bandwidth, flexibility, and coverage range. On the other hand, cybersecurity techniques and solutions applied in SATCOM links should be updated to reflect the substantial advancements in attacker capabilities characterizing the last two decades. However, business urgency and opportunities are leading operators towards challenging system trade-offs, resulting in an increased attack surface and a general relaxation of the available security services.}
}


@article{DBLP:journals/cn/SatpathySSSB22,
	author = {Anurag Satpathy and
                  Manmath Narayan Sahoo and
                  Arun Kumar Sangaiah and
                  Chittaranjan Swain and
                  Sambit Bakshi},
	title = {CoMap: An efficient virtual network re-mapping strategy based on coalitional
                  matching theory},
	journal = {Comput. Networks},
	volume = {216},
	pages = {109248},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109248},
	doi = {10.1016/J.COMNET.2022.109248},
	timestamp = {Mon, 28 Aug 2023 21:39:17 +0200},
	biburl = {https://dblp.org/rec/journals/cn/SatpathySSSB22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Virtualization of resources has been adopted in different environments such as wireless sensor networks (WSN), 5G networks, Fog computing, Internet of Things (IoT), and traditional data center (DC) networks. In DC networks, virtualized resources are provisioned as virtual networks (VNs), which comprise multiple communicating virtual machines (VMs) and virtual links (VLs) capturing their communication dependencies. However these virtual components, i.e., VMs and VLs, often experience fluctuating resource demands and require dynamic re-embedding as part of the management activities undertaken by the service providers (SPs). This paper focuses on addressing the issue of resource re-embedding via solution components (SCs), where a SC comprises a VM and its attached VLs, with either the VM and/or at least one of the VLs facing resource expansion. In fact, the resource provisioning problem for VNs is proven to be\nNP\n-Hard. Further, the requirement of distributed allocation of VMs of the VNs across the servers to avoid single point failure and enhance the survivability adds to the existing complexity. We propose a framework called CoMap that aims to generate an efficient relocation plan in polynomial time for VNs to reduce the re-embedding costs and improve the utilization of DC servers. The overall problem is modeled as a one-to-many matching game with coalition formation at the servers. Simulation results confirm a 32% average reduction in re-embedding cost and a 69% improvement in the average server utilization compared to the baseline algorithms.}
}


@article{DBLP:journals/cn/RajakSCHST22,
	author = {Shaik Rajak and
                  Poongundran Selvaprabhu and
                  Sunil Chinnadurai and
                  A. S. M. Sanwar Hosen and
                  Aldosary Saad and
                  Amr Tolba},
	title = {Energy efficient {MIMO-NOMA} aided IoT network in {B5G} communications},
	journal = {Comput. Networks},
	volume = {216},
	pages = {109250},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109250},
	doi = {10.1016/J.COMNET.2022.109250},
	timestamp = {Tue, 07 May 2024 20:23:16 +0200},
	biburl = {https://dblp.org/rec/journals/cn/RajakSCHST22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {To accelerate future intelligent wireless systems, we designed an energy-efficient Massive multiple-input-multiple-output (MIMO)- non-orthogonal multiple access (NOMA) aided internet of things (IoT) network in this paper to support the massive number of distributed users and IoT devices with seamless data transfer and maintain connectivity between them. Massive MIMO has been identified as a suitable technology to implement the energy efficient IoT network in beyond 5G (B5G) communications due to its distinct characteristics with large number of antennas. However, to provide fast data transfer and maintain hyper connectivity between the IoT devices in B5G communications will bring the challenge of energy deficiency. Hence, we considered a massive MIMO–NOMA aided IoT network considering imperfect channel state information and practical power consumption at the transmitter. The far users of the base stations are selected to investigate the power consumption and quality of service. Then, calculate the power consumption which is non-convex function and non-deterministic polynomial problem. To solve the above problem, fractional programming properties are applied which converted polynomial problem into the difference of convex function. And then we employed the successive convex approximation technique to represent the non-convex to convex function. Effective iterative based branch and the reduced bound process are utilized to solve the problem. Numerical results observe that our implemented approach surpasses previous standard algorithms on the basis of convergence, energy-efficiency and user fairness.}
}


@article{DBLP:journals/cn/Herreria-Alonso22,
	author = {Sergio Herrer{\'{\i}}a{-}Alonso and
                  Andr{\'{e}}s Su{\'{a}}rez{-}Gonz{\'{a}}lez and
                  Miguel Rodr{\'{\i}}guez{-}P{\'{e}}rez and
                  C{\'{a}}ndido L{\'{o}}pez{-}Garc{\'{\i}}a},
	title = {Enhancing LoRaWAN scalability with Longest First Slotted {CSMA}},
	journal = {Comput. Networks},
	volume = {216},
	pages = {109252},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109252},
	doi = {10.1016/J.COMNET.2022.109252},
	timestamp = {Mon, 24 Oct 2022 20:51:28 +0200},
	biburl = {https://dblp.org/rec/journals/cn/Herreria-Alonso22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Compelling features such as low power consumption and low complexity make LoRaWAN one of the most promising technologies to provide long-range connectivity to resource-constrained devices. However, LoRaWAN suffers from limited scalability since it uses an Aloha-based protocol for accessing the channel that causes a huge amount of frame collisions when the number of devices (or the network load) is high. This paper presents LFS-CSMA, a new medium access control mechanism that enhances the scalability of LoRaWAN networks by just combining the well-known slotted Aloha and CSMA schemes in a novel manner. With LFS-CSMA, longer frames are transmitted earlier within a given timeslot. Thus, devices with short frames to be transmitted can check the channel availability before sending them and avoid collisions if they detect an ongoing transmission. Performance results show that LFS-CSMA causes far less collisions than traditional MAC mechanisms, thus improving the scalability of LoRaWAN networks significantly.}
}


@article{DBLP:journals/cn/CastellanosGMKJ22,
	author = {Germ{\'{a}}n Castellanos and
                  Simon De Gheselle and
                  Luc Martens and
                  Niels Kuster and
                  Wout Joseph and
                  Margot Deruyck and
                  Sven K{\"{u}}hn},
	title = {Multi-objective optimisation of human exposure for various 5G network
                  topologies in Switzerland},
	journal = {Comput. Networks},
	volume = {216},
	pages = {109255},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109255},
	doi = {10.1016/J.COMNET.2022.109255},
	timestamp = {Mon, 28 Aug 2023 21:39:20 +0200},
	biburl = {https://dblp.org/rec/journals/cn/CastellanosGMKJ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The constant increase in the required user capacity and the evolution of wireless network technologies impact the exposure that users experience from wireless networks. This paper evaluates various 5G network topologies regarding human exposure, mobile communication quality, and sustainability. We assess human exposure, based on a novel Exposure Ratio (ER) metric, in 5G networks that include Massive Multiple-Input Multiple-Output (MaMIMO) and compare them with existing 4G deployments in three environments in Switzerland. The quality and sustainability of mobile communication are evaluated by extrapolating data rates from mobile operators to the year 2030. A multi-objective optimisation algorithm is implemented to design the 5G network topologies, maximising the user coverage while minimising the downlink (DL) and uplink (UL) exposure. An extensive set of simulations investigated three municipalities, three operators plus one unified network, three use cases (UL/DL data rates), three scenarios (indoor and outdoor coverage), and two optimisation methods. The study results confirm that the human exposure in a 5G network is dominated by the UL being ten times larger than the DL exposure. Furthermore, comparing a 5G deployment with 10 times the traffic capacity of a real 4G network, DL exposure increases by 36% on average, and UL exposure decreases by up to 75% depending on the scenario. Regarding indoor coverage versus outdoor only, our results show that DL exposure can be reduced by a factor of 10 if only outdoor coverage is targeted. Finally, the study concludes that from the human exposure perspective, the ideal network should use 5G MaMIMO and be optimised for both UL and DL exposure.}
}


@article{DBLP:journals/cn/SharmaA22,
	author = {Abhilasha Sharma and
                  Lalit Kumar Awasthi},
	title = {Ob-EID: Obstacle aware event information dissemination for {SDN} enabled
                  vehicular network},
	journal = {Comput. Networks},
	volume = {216},
	pages = {109257},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109257},
	doi = {10.1016/J.COMNET.2022.109257},
	timestamp = {Sun, 12 Nov 2023 02:17:57 +0100},
	biburl = {https://dblp.org/rec/journals/cn/SharmaA22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With rapid increase in traffic density in urban areas, the accident rate is also becoming a serious problem which results in traffic congestion, inconvenience and sometimes life loss. The rate of accidents can be minimized by sharing real-time event information among vehicles on the road through safety application. To realize the safety applications, it is paramount to disseminate event information in real-time through a reliable path which is extremely challenging due to unique vehicular characteristics. To ensure reliable path, there are majorly two critical issues: (i). It is very difficult to form the stable connections due to varying vehicular density and dynamic topology. (ii) the dynamic obstacles affect the signal intensity and hinder the communication between vehicles. Indeed, majority of dissemination schemes are based on distance and dissemination time only, while neglecting the effect of dynamic obstacles. Also, the localized traffic view is considered in such schemes lack in providing the real time vehicular dynamics and network status information. To overcome these issues, a Software Defined Network (SDN) based vehicular network model has been presented to ensure real time vehicular dynamics awareness in urban environment to share event information. For reliable event information dissemination, a heuristic based reliable path selection (HRPS) algorithm is proposed to disseminate event messages between a source and destination vehicle in real-time that will minimize the hindrance due to dynamic obstacles. The proposed algorithm selects a multi-modal path reliability function that depends on multiple routing metrics (connectivity, link reliability and obstacle impact probability) and selects the reliable path by optimizing the path reliability function. The proposed algorithm is simulated for varying urban traffic conditions to analyze its performance. The proposed algorithm shows packet delivery ratio between 90%–95% for varying vehicular density. The simulation results show the supremacy of proposed algorithm as compared to existing compared routing scheme. The proposed algorithm ensures real time event information dissemination for delay sensitive event information that minimizes the impact of dynamic obstacles.}
}


@article{DBLP:journals/cn/ChenCL22,
	author = {Junmei Chen and
                  Hao Chen and
                  Zongpeng Li},
	title = {A double serial concatenated code using CRC-aided error correction
                  for highly reliable communication},
	journal = {Comput. Networks},
	volume = {216},
	pages = {109260},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109260},
	doi = {10.1016/J.COMNET.2022.109260},
	timestamp = {Tue, 18 Oct 2022 22:17:05 +0200},
	biburl = {https://dblp.org/rec/journals/cn/ChenCL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Highly Reliable Communication (HRC) is an emerging paradigm for meeting the quality of service requirements of new applications such as intelligent vehicle networking and industrial Internet. HRC brings challenges to channel coding and multiple access. Various channel coding techniques have been proposed to improve reliability, but often suffer from limited reliability and high decoding complexity. This work presents a double serial concatenated code using CRC-aided error correction, abbreviated as DSC\n3\nEC, to improve reliability and reduce complexity. The encoding scheme is a double serial concatenated code, with the cascade of a set of CRC encoders, a linear block encoder, a series of interleavers, and a set of convolutional encoders. The decoding scheme consists of two modules: (i) decoding of serial concatenated codes, which includes the decoding of single parity check convolutional code (SPC-CC) and the decoding of Reed–Solomon convolutional code (RS-CC) for intra-block error correction at the physical layer to control BER; (ii) decoding of CRC-aided linear error correction, which can effectively identify, locate and correct error bits at the inter-block level to solve the problem of block loss caused by residual errors at the physical layer. Simulation results show that the joint scheme can effectively improve communication reliability while reducing complexity.}
}


@article{DBLP:journals/cn/ZhangZX22,
	author = {Jianfeng Zhang and
                  Wensheng Zhang and
                  Jingdong Xu},
	title = {Bandwidth-efficient multi-task {AI} inference with dynamic task importance
                  for the Internet of Things in edge computing},
	journal = {Comput. Networks},
	volume = {216},
	pages = {109262},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109262},
	doi = {10.1016/J.COMNET.2022.109262},
	timestamp = {Sun, 02 Oct 2022 15:31:03 +0200},
	biburl = {https://dblp.org/rec/journals/cn/ZhangZX22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Over the past years, artificial intelligence (AI) models have been utilized for the Internet of Things (IoT) in applications such as remote assistance based on augmented reality (AR) in smart factories, as well as powerline inspection and precision agriculture missions performed by unmanned aerial vehicles (UAVs). Due to the limited battery capacity and computing power of these devices (e.g., AR glasses and UAVs), edge computing is recognized as a means to empower the Internet of Things (IoT) with AI. Considering that multiple AI model inference tasks (e.g., point cloud classification and fault detection) are typically performed on the same stream of sensory data (e.g., UAV camera feed), we propose TORC (Tasks-Oriented Edge Computing) to reduce the bandwidth requirement. By incorporating AI into data transmission, the lightweight framework of TORC preserves edge computing servers’ ability to reconstruct/restore data into the original form, ensuring the proper coexistence of AI inference tasks and traditional non-AI tasks like human inspection, as well as simultaneous localization and mapping. It encodes and decodes sensory data with neural networks, whose training is driven by the AI inference tasks, in order to reduce bandwidth consumption and latency without impairing the accuracy of the AI inference tasks. Additionally, taking into account the mobility of the IoT and changes in the environment, TORC can adapt to variation in the bandwidth budget, as well as the temporally dynamic importance of AI inference tasks, without the need to train multiple neural networks for each setting. As a demonstration, empirical results conducted on the Cityscapes dataset and tasks related to autonomous driving show that, at the same level of accuracy, TORC reduces the bandwidth consumption by up to 48% and latency by up to 26%.}
}


@article{DBLP:journals/cn/RestucciaDARCIM22,
	author = {Francesco Restuccia and
                  Salvatore D'Oro and
                  Amani Al{-}Shawabka and
                  Bruno Costa Rendon and
                  Kaushik R. Chowdhury and
                  Stratis Ioannidis and
                  Tommaso Melodia},
	title = {Generalized Wireless Adversarial Deep Learning},
	journal = {Comput. Networks},
	volume = {216},
	pages = {109264},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109264},
	doi = {10.1016/J.COMNET.2022.109264},
	timestamp = {Thu, 22 Feb 2024 08:14:17 +0100},
	biburl = {https://dblp.org/rec/journals/cn/RestucciaDARCIM22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Deep learning techniques can classify spectrum phenomena (e.g., waveform modulation) with accuracy levels that were once thought impossible. Although we have recently seen many advances in this field, extensive work in computer vision has demonstrated that adversarial machine learning (AML) can seriously decrease the accuracy of a classifier. This is done by designing inputs that are close to a legitimate one but interpreted by the classifier as being of a completely different class. On the other hand, it is unclear if, when, and how AML is concretely possible in practical wireless scenarios, where (i) the highly time-varying nature of the channel could compromise adversarial attempts; and (ii) the received waveforms still need to be decodable and thus cannot be extensively modified. This paper advances the state of the art by proposing the first comprehensive analysis and experimental evaluation of adversarial learning attacks to wireless deep learning systems. We postulate a series of adversarial attacks, and formulate a Generalized Wireless Adversarial Machine Learning Problem (GWAP) where we analyze the combined effect of the wireless channel and the adversarial waveform on the efficacy of the attacks. We propose a new neural network architecture called FIRNet, which can be trained to “hack” a classifier based only on its output. We extensively evaluate the performance on (i) a 1000-device radio fingerprinting dataset, and (ii) a 24-class modulation dataset. Results obtained with several channel conditions show that our algorithms can decrease the classifier accuracy up to 3x. We also experimentally evaluate FIRNet on a radio testbed, and show that our data-driven blackbox approach can confuse the classifier up to 97% while keeping the waveform distortion to a minimum.}
}


@article{DBLP:journals/cn/FebroXSC22a,
	author = {Aldo Febro and
                  Hannan Xiao and
                  Joseph Spring and
                  Bruce Christianson},
	title = {Synchronizing DDoS defense at network edge with P4, SDN, and Blockchain},
	journal = {Comput. Networks},
	volume = {216},
	pages = {109267},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109267},
	doi = {10.1016/J.COMNET.2022.109267},
	timestamp = {Tue, 18 Oct 2022 22:17:05 +0200},
	biburl = {https://dblp.org/rec/journals/cn/FebroXSC22a.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Botnet-originated DDoS attacks continue to plague the internet and disrupt services for legitimate users. While various proposals have been presented in the last two decades, the botnet still has advantages over the defenders, because botnets have orchestrated processes to launch disruptive attacks. On the other hand, the defenders use manual methods, siloed tools, and lack orchestration among different organizations. These unorchestrated efforts slow down the attack response and extend the lifespan of botnet attacks. This article presents shieldSDN and shieldCHAIN, an inter-organization collaborative defense framework using P4, SDN, and Blockchain, which extends our earlier research on microVNF, a solution of Edge security for SIP-enabled IoT devices with P4. Besides mitigating DDoS attacks, microVNF also produces attack fingerprints called Indicator of Compromise (IOC) records. ShieldSDN and shieldCHAIN distribute these IOCs to other organizations so that they can create their own packet filters. Effectively, shieldSDN and shieldCHAIN synchronize packet filters for different organizations to mitigate against the same botnet strain. Four experiments were performed successfully to validate the functionalities of shieldSDN and shieldCHAIN. The scope for the first experiment was intra-company, while the second, third, and fourth experiments were inter-company. In the first experiment, shieldSDN extracted IOCs from the source switch and installed these as packet filters on other switches within the same organization (in the U.S.). In the second experiment, the shieldCHAIN in the publishing organization (in the U.S.) shared IOCs by posting them to the Blockchain. In the third experiment, the shieldCHAIN in the subscriber organizations (in Singapore & the U.K.) retrieved these IOCs from Blockchain. Finally, in the last experiment, the shieldCHAIN in the subscriber organizations installed the retrieved IOCs as packet filters; that are identical to those in the originating organization. To the best of our knowledge, this is the first framework that uses the P4 switch, SDN controller, and Blockchain together for this use case. As SDN and Blockchain gain acceptance, this framework empowers community members to collaborate and defend against botnet DDoS attacks.}
}


@article{DBLP:journals/cn/BatchuS22,
	author = {Raj Kumar Batchu and
                  Hari Seetha},
	title = {An integrated approach explaining the detection of distributed denial
                  of service attacks},
	journal = {Comput. Networks},
	volume = {216},
	pages = {109269},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109269},
	doi = {10.1016/J.COMNET.2022.109269},
	timestamp = {Mon, 05 Feb 2024 20:24:12 +0100},
	biburl = {https://dblp.org/rec/journals/cn/BatchuS22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent years, several machine learning and deep learning models have been designed to detect various DDoS attacks, but the presence of irrelevant features, lack of transparency and class imbalance make these models less efficient. In this paper, we developed a novel efficient model to address these issues in detecting DDOS attacks. To begin with, data preprocessing is performed to improve the quality of the training data. The minority class samples are then generated using the Adaptive Synthetic oversampling technique to overcome the class imbalance. Following that, feature selection is performed by embedding SHAP feature importance within recursive feature elimination with five base classifiers. In addition, the hyperparameter of these classifiers is tuned to determine the most contributed features. Furthermore, global and local explanations for extracted features are provided to ensure transparency. Finally, these features are fed to the dynamic ensemble selection techniques such as KNORA-E and KNORA-U for classification by varying k values. These evaluations are analyzed using the CICDDoS2019 dataset. The evaluations are carried out in balanced and imbalanced data scenarios. The results indicate that the balanced data scenario outperformed the imbalanced data scenario as well as existing approaches. An accuracy of 99.9878% using KNORA-E and 99.9886% using KNORA-U is obtained utilizing the five most contributed features.}
}


@article{DBLP:journals/cn/ZhaoC22,
	author = {Yubo Zhao and
                  Jinyong Chang},
	title = {Certificateless public auditing scheme with designated verifier and
                  privacy-preserving property in cloud storage},
	journal = {Comput. Networks},
	volume = {216},
	pages = {109270},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109270},
	doi = {10.1016/J.COMNET.2022.109270},
	timestamp = {Tue, 18 Oct 2022 22:17:05 +0200},
	biburl = {https://dblp.org/rec/journals/cn/ZhaoC22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent years, cloud storage has become an attractive service for data owners to store their personal data. Since they lose physical control of their data, it is necessary to regularly audit its integrity. The public auditing technique is very popular because it is suitable to outsource the auditing task to any third-party auditor, who has professional knowledge on auditing. However in many practical scenarios, the data owner may expect some designated verifier (instead of any) to audit its data. Thus, the public auditing scheme with designated verifier was proposed. In order to further reduce the cost of managing certificates, and to avoid the dependence on public key infrastructure, identity-based auditing scheme with designated verifier was recently proposed. Nevertheless, the proposed identity-based auditing scheme still suffers from the key escrow attack the risk of privacy leakage. In this paper, for the first time, we propose a certificateless public auditing protocol with designated verifier privacy-preserving property. More concretely, it can not only protect the privacy of the stored data against the designated verifier, but also resolve key escrow problem existed in identity-based technique. Its security is based on the Computational Diffie–Hellman and Weil Diffie–Hellman assumptions. Finally, the performance analysis experimental results of the proposed protocol show that our auditing scheme is efficient feasible to applications in real life.}
}


@article{DBLP:journals/cn/WangF22,
	author = {Yantong Wang and
                  Vasilis Friderikos},
	title = {Energy-efficient proactive caching with multipath routing},
	journal = {Comput. Networks},
	volume = {216},
	pages = {109272},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109272},
	doi = {10.1016/J.COMNET.2022.109272},
	timestamp = {Tue, 18 Oct 2022 22:17:05 +0200},
	biburl = {https://dblp.org/rec/journals/cn/WangF22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The ever-continuing explosive growth of on-demand content distribution has imposed great pressure on mobile/wireless network infrastructures. To ease congestion in the network and to increase perceived user experience, caching of popular content closer to the end-users can play a significant role and as such this issue has received significant attention over the last few years. Additionally, energy saving is treated as a fundamental requirement in the design of next-generation mobile networks. However, there has been little attention to the overlapping area between energy saving and network caching especially when considering multipath routing. To this end, this paper proposes an energy-efficient caching with multipath routing support. The proposed scheme provides a joint anchoring of popular content into a set of potential caching nodes with optimized multipath support whilst ensuring a balance between transmission and caching energy cost. The proposed model also considers different content delivery modes, such as multicast and unicast. Two separated Integer-Linear Programming (ILP) models are formulated for each delivery mode. To tackle the curse of dimensionality we then provide a greedy simulated annealing algorithm, which not only reduces the time complexity but also provides a competitive performance. A wide set of numerical investigations reveal that the proposed scheme reduces the energy consumption up to 75% compared with other widely used caching approaches under the premise of network resource limitation. Sensitivity analysis to different parameters is also meticulously discussed in this paper.}
}


@article{DBLP:journals/cn/MiuraHT22,
	author = {Hideyoshi Miura and
                  Kouji Hirata and
                  Takuji Tachibana},
	title = {P4-based design of fast failure recovery for software-defined networks},
	journal = {Comput. Networks},
	volume = {216},
	pages = {109274},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109274},
	doi = {10.1016/J.COMNET.2022.109274},
	timestamp = {Mon, 28 Aug 2023 21:39:20 +0200},
	biburl = {https://dblp.org/rec/journals/cn/MiuraHT22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Communication networks require high availability to provide reliable services to users. One of techniques maintaining high availability of communication networks is fast failure recovery such as the multiple routing configurations (MRC) algorithm. In MRC, multiple virtual networks named backup routing configurations for transmitting data after a single link/node failure occurrence are constructed on the basis of a normal routing configuration on a physical network. When a failure occurs during data transmission on the physical network, MRC immediately switches the normal routing configuration to appropriate backup routing configurations to ensure data transmission without significant delay and packet loss. In this paper, we introduce a design of a fast failure recovery mechanism using MRC for software-defined networks with Programming Protocol-independent Packet Processors (P4). P4 is a programming language that enables us to define the behavior of the data plane of network devices in software-defined networks. We provide the implementation of some functions for fast failure recovery, including failure detection and packet forwarding. We verify the behavior of our implementation through practical demonstrations using Mininet.}
}


@article{DBLP:journals/cn/KhorasaniRJ22,
	author = {Yaghoub Khorasani and
                  Akbar Ghaffarpour Rahbar and
                  Mohammad Jafari{-}Beyrami},
	title = {A novel two-dimensional metric for fragmentation evaluation in elastic
                  optical networks},
	journal = {Comput. Networks},
	volume = {216},
	pages = {109275},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109275},
	doi = {10.1016/J.COMNET.2022.109275},
	timestamp = {Sun, 06 Oct 2024 21:22:03 +0200},
	biburl = {https://dblp.org/rec/journals/cn/KhorasaniRJ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Elastic optical networking with multicore fiber is a promising option to meet the growing demands of the Internet traffic. The use of space division multiplexed elastic optical network (SDM-EON) technology with multi-core fibers improves these needs. However, despite the wide bandwidth in these networks, a destructive phenomenon, called fragmentation, wastes a lot of bandwidth. Fragmentation on a core/fiber leaves empty slots unused, which reduces the efficiency of elastic optical networks. Measuring the amount of fragmentation is one of the most important issues in elastic optical networks, so it is very important to have a proper metric that has an accurate estimation of the amount of fragmentation on a core/fiber. Since existing metrics could not meet the expectations due to various weaknesses, a two-dimensional metric to measure the amount of fragmentation in elastic optical networks is presented in this paper, called Golden metric. Then Golden-Routing Spectrum and Core Assignment (Golden-RSCA) algorithm is proposed based on this metric. Performance evaluation and comparison of the efficiency and complexity of this two-dimensional metric with other metrics show its efficiency compared to other metrics.}
}


@article{DBLP:journals/cn/BlaiseBCS22,
	author = {Agathe Blaise and
                  Mathieu Bouet and
                  Vania Conan and
                  Stefano Secci},
	title = {Group anomaly detection in mobile app usages: {A} spatiotemporal convex
                  hull methodology},
	journal = {Comput. Networks},
	volume = {216},
	pages = {109277},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109277},
	doi = {10.1016/J.COMNET.2022.109277},
	timestamp = {Tue, 27 Sep 2022 16:31:01 +0200},
	biburl = {https://dblp.org/rec/journals/cn/BlaiseBCS22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Analysing mobile apps communications can unleash significant information on both the communication infrastructure state and the operations of mobile computing services. A wide variety of events can engender unusual mobile communication patterns possibly interesting for pervasive computing applications, e.g., in smart cities. For instance, local events, national events, and network outages can produce spatiotemporal load anomalies that could be taken into consideration by both mobile applications and infrastructure providers, especially with the emergence of edge computing frameworks where the two environments merge. Being able to detect and timely treat these anomalies is therefore a desirable feature for next-generation cellular and edge computing networks, with regards to security, network and application performance, and public safety. We focus on the detection of mobile access spatiotemporal anomalies by decomposing, aggregating and grouping cellular data usage features time series. We propose a methodology to detect first raw anomalies, and group them in a spatiotemporal convex hull, further refining the anomaly detection logic, with a novel algorithmic framework. We show how with the proposed framework we can unveil details about broad-category mobile events timeline, their spatiotemporal spreading, and their impacted apps. We apply our technique to extensive real-world data and open source our code. By linkage with ground-truth special events that happened in the observed period, we show how our methodology is able to detect them. We also evidence the existence of five main categories of anomalies, finely characterising them. Finally, we identify global patterns in the anomalies and assess their level of unpredictability, based on the nature of the impacted mobile applications.}
}


@article{DBLP:journals/cn/LiMDXZL22,
	author = {Kehong Li and
                  Wengang Ma and
                  Huawei Duan and
                  Han Xie and
                  Juanxiu Zhu and
                  Ruiqi Liu},
	title = {Unbalanced network attack traffic detection based on feature extraction
                  and {GFDA-WGAN}},
	journal = {Comput. Networks},
	volume = {216},
	pages = {109283},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109283},
	doi = {10.1016/J.COMNET.2022.109283},
	timestamp = {Tue, 18 Oct 2022 22:17:05 +0200},
	biburl = {https://dblp.org/rec/journals/cn/LiMDXZL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Detecting various types of attack traffic is critical to computer network security. The current detection methods require massive amounts of data to detect attack traffic. However, in most cases, the attack traffic samples are unbalanced. A typical neural network model cannot detect such unbalanced attack traffic. Additionally, malicious network noise traffic has a detrimental effect on the detection stability. Very few effective methods exist to detect unbalanced attack traffic. In this paper, we develop a method to detect unbalanced attack traffic. A dynamic chaotic cross-optimized bidirectional residual-gated recurrent unit (DCCSO-Res-BIGRU) and an adaptive Wasserstein generative adversarial network with generated feature domains (GFDA-WGAN) are proposed. First, feature extraction is achieved using the DCCSO-Res-BIGRU. The GFDA-WGAN can then be used to detect the unbalanced attack traffic. We use a conditional WGAN network to generate the pseudo-sample features of the invisible classes. A GFDA strategy for conditional WGAN optimization is also proposed. Furthermore, we use an invisible sample and supervised learning to detect unbalanced attack traffic. Finally, the performance of the proposed method is validated using four network datasets. According to the experimental results, the proposed method significantly improves sample convergence and generation. It has a higher detection accuracy with respect to detecting unbalanced attack traffic. Furthermore, it provides the most powerful and effective visual classification. When noise is added, it outperforms all other conventionally used methods. Real-time traffic detection is also possible using this method.}
}


@article{DBLP:journals/cn/GaoFYZWQLZ22,
	author = {Jing Gao and
                  Lei Feng and
                  Peng Yu and
                  Fanqin Zhou and
                  Zihao Wu and
                  Xuesong Qiu and
                  Jingchun Li and
                  Yifei Zhu},
	title = {Resource consumption and security-aware multi-tenant service function
                  chain deployment based on hypergraph matching},
	journal = {Comput. Networks},
	volume = {216},
	pages = {109298},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109298},
	doi = {10.1016/J.COMNET.2022.109298},
	timestamp = {Thu, 30 Nov 2023 12:18:25 +0100},
	biburl = {https://dblp.org/rec/journals/cn/GaoFYZWQLZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Network function virtualization (NFV) technology enables cloud service providers (CSPs) to deploy their service function chains (SFCs) into the common shared physical infrastructures to operate the network or cloud service. However, designing a suitable placement scheme for multi-tenant SFCs to balance resource consumption with performance and security is a tricky issue. In this paper, we first proposed security constraints based on physical isolation and formulated the problem of reasonably placing multi-tenant SFCs subject to multiple constraints to minimize resource consumption. The proposed problem is more intractable than previous works because of the extra introduced security constraints. To solve it, a new non-uniform weighted hypergraph construction approach is proposed by defining hyperedge weights to represent the resource consumption on one SFC. A hypergraph matching algorithm is proposed to find the maximum weight subset of hypergraphs whose vertices do not intersect to give a high degree of physical isolation by dealing with the conflict graphs. Simulation results show that the proposed hypergraph matching algorithm outperforms the comparison schemes in terms of the resource consumption while satisfying the security requirements.}
}


@article{DBLP:journals/cn/SilveiraRBMSC22,
	author = {Lucas Baleeiro Dominato Silveira and
                  Henrique Cesar Carvalho de Resende and
                  Cristiano Bonato Both and
                  Johann M. M{\'{a}}rquez{-}Barja and
                  Bruno O. Silvestre and
                  Kleber Vieira Cardoso},
	title = {Tutorial on communication between access networks and the 5G core},
	journal = {Comput. Networks},
	volume = {216},
	pages = {109301},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109301},
	doi = {10.1016/J.COMNET.2022.109301},
	timestamp = {Thu, 08 Feb 2024 10:56:52 +0100},
	biburl = {https://dblp.org/rec/journals/cn/SilveiraRBMSC22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Fifth-generation (5G) networks enable a variety of use cases that require differentiated connectivity, e.g., Ultra-Reliable and Low-Latency Communications (URLLC), enhanced Mobile Broadband (eMBB), and massive Machine Type Communication (mMTC). To explore the full potential of these use cases, it is mandatory to understand the communication along with the 5G network segments and architecture components. User Equipment (UE), Radio Access Network (RAN), and 5G Core (5GC) are the main components that support these new network concepts and paradigms. 3rd Generation Partnership Project has recently published Release 16, including the protocols used to communicate between RANs and 5GC, i.e., Non-Access Stratum (NAS) and NG Application Protocol (NGAP). The main goal of this work is to present a comprehensive tutorial about NAS and NGAP specifications using a didactic and practical approach. The tutorial describes the protocol stacks and aspects of the functionality of these protocols in 5G networks, such as authentication and identification procedures, data session establishment, and resource allocation. Moreover, we review the message flows related to these protocols in UE and Next Generation Node B (gNodeB) registration. To illustrate the concepts presented in the tutorial, we developed the my5G Tester: a 5GC tester that implements NAS and NGAP for evaluating three open-source 5GC projects using a black-box testing methodology.}
}


@article{DBLP:journals/cn/LvLBCZLQ22,
	author = {Yunxin Lv and
                  Zixin Liu and
                  Meihua Bi and
                  Hao Chi and
                  Yanrong Zhai and
                  Yang Lu and
                  Zhengfeng Qian},
	title = {Artificial neural network assisted polling scheme for central coordinated
                  low-latency WLANs},
	journal = {Comput. Networks},
	volume = {216},
	pages = {109303},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109303},
	doi = {10.1016/J.COMNET.2022.109303},
	timestamp = {Tue, 27 Sep 2022 16:31:01 +0200},
	biburl = {https://dblp.org/rec/journals/cn/LvLBCZLQ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Focusing on uplink transmission, a low-latency medium access control scheme is proposed and investigated for central coordinated wireless local area networks (WLANs). By categorizing user-stations using a trained artificial neural network and avoiding polling empty user-stations during the polling period, effective polling of user-stations can be realized and network latency can be reduced. The artificial neural network is trained by samples collected from a request-based polling scheme, and the boundary for categorization decisioning is selected according to the calculated outputs of training samples. Compared to the conventional controlled channel access scheme, the proposed scheme achieves up to 32.9% reduction in network latency, and significantly improves the network capacity in delivering services requiring 200 μs average latency. Moreover, to improve service quality for user-stations delivering mission-critical services, a latency guarantee mechanism is incorporated. The incorporated scheme records the last access time for each of these user-stations and requires these user-stations to report their buffer statuses when they are in danger of exceeding their latency targets. Simulation results show that the incorporated scheme can ensure a delay below 500 μs for 99.9% of packets of these user-stations, enabling a WLAN to realize ultrahigh quality low-latency performance.}
}
