@article{DBLP:journals/cn/LiuWLC23,
	author = {Xiaoxue Liu and
                  Yichuan Wang and
                  Yanping Li and
                  Hao Cao},
	title = {{PTAP:} {A} novel secure privacy-preserving {\&} traceable authentication
                  protocol in VANETs},
	journal = {Comput. Networks},
	volume = {226},
	pages = {109643},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109643},
	doi = {10.1016/J.COMNET.2023.109643},
	timestamp = {Mon, 27 Jan 2025 14:01:13 +0100},
	biburl = {https://dblp.org/rec/journals/cn/LiuWLC23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In vehicular ad-hoc networks (VANETs), road traffic efficiency and road safety can be improved through message interaction and sharing between vehicle users, which inevitably depends on secure identity authentication and message credibility verification. However, security and privacy of message are the critical factors restricting VANETs’ development. Most existing protocols rely on the trusted third-party to achieve identity authentication and message, which are prone to system single points of failure and low efficiency. To address these challenges, in 2021, Vasudev and Das proposed a privacy preserving secure hash based authentication and revelation protocol. They claimed that their protocol can resist various known attacks, e.g. modification, man-in-the-middle, TPD stolen attack, et al. Unfortunately, in this paper, we found that their protocol does not address above-mentioned problems and has other devastating security bugs. Attacker can easily obtain vehicle’s original/real identity, pseudo-identity and password, which are the cornerstone of their protocol security. In other words, the attacker successfully can launch any attacks including those mentioned above to destroy the whole system. Then, a novel secure privacy-preserving traceable authentication protocol (abbreviated to PTAP) is proposed. The PTAP not only mitigates the weaknesses, but has other advantages. First, the PTAP uses semi-honest\nR\nS\nU\ns to realize interaction between stakeholders without the help of trusted third-party in extremely low computational cost (reducing 32.75% in vehicle side). Second, the PTAP can enable vehicles to enjoy the remote services with identity anonymity protection and location privacy (traceability when needed). Finally, the PTAP is proven to be safe against passive and active attacks under CDHP assumption and CL-eCK model. Hence, these features make the PTAP very suitable for high safety coefficient and computation-limited mobile devices (such as TPD) compared with other related existing protocols.}
}


@article{DBLP:journals/cn/AlqarniCA23,
	author = {Manal M. Alqarni and
                  Asma Cherif and
                  Entisar Alkayyal},
	title = {{ODM-BCSA:} An Offloading Decision-Making Framework based on Binary
                  Cuckoo Search Algorithm for Mobile Edge Computing},
	journal = {Comput. Networks},
	volume = {226},
	pages = {109647},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109647},
	doi = {10.1016/J.COMNET.2023.109647},
	timestamp = {Sat, 13 May 2023 01:07:10 +0200},
	biburl = {https://dblp.org/rec/journals/cn/AlqarniCA23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Computational task offloading facilitates real-time applications on constrained mobile devices that require a large amount of processing resources, high storage capacity and battery power. Mobile Edge Computing (MEC) is a computing paradigm that shifts computing resources closer to the user at the network’s edges. Heavy tasks are then offloaded to edge nodes, thereby reducing the computations required on the mobile side. However, offloading computational tasks may result in additional energy consumption and delays, due to network congestion and time spent in server queues. Thus, to minimize completion time and energy consumption, it is essential to optimize offloading decisions, while also considering the financial costs. In this paper, we propose an Offloading Decision-Making Framework based on the Binary Cuckoo Search Algorithm for Mobile Edge Computing (ODM-BCSA). We formulated an offloading problem as a mixed-integer optimization problem to minimize time, energy, and payment costs. We resolved the problem of resource allocation using the Binary Cuckoo Search Algorithm (BCSA). The simulation results revealed that offloading decisions depend on multiple parameters, including the number of mobile devices being handled by the edge server, the bandwidth, and the number of tasks. Decisions made also depended on the priority assigned to each objective. Finally, we compared the ODM-BCSA against a brute force search, proving that the ODM-BCSA is more efficient and greatly minimizes execution time when a huge number of mobile devices are involved (by 99.9 %).}
}


@article{DBLP:journals/cn/HassanpourKMS23,
	author = {Seyedeh Bahereh Hassanpour and
                  Ahmad Khonsari and
                  Masoumeh Moradian and
                  Seyed Pooya Shariatpanahi},
	title = {Privacy-preserving edge caching: {A} probabilistic approach},
	journal = {Comput. Networks},
	volume = {226},
	pages = {109654},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109654},
	doi = {10.1016/J.COMNET.2023.109654},
	timestamp = {Sun, 16 Apr 2023 20:31:00 +0200},
	biburl = {https://dblp.org/rec/journals/cn/HassanpourKMS23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Edge caching (EC) decreases the average access delay of end-users through caching popular content at the edge of the network, however, it increases the leakage probability of valuable information such as users’ preferences. Most of the existing privacy-preserving approaches focus on adding extra layers of encryption, which confronts the network with more challenges such as energy and computation limitations. We employ a chunk-based joint probabilistic caching (JPC) approach to mislead an adversary eavesdropping on the communication inside an EC network and maximizing the adversary’s error in estimating the requested file and the requesting cache. Then, we optimize the probability of different cache placements in JPC in order to minimize the communication cost while guaranteeing the desired privacy. We show that the optimization problem can be formulated as a linear programming (LP) problem. Since JPC inherits the curse of dimensionality, we also propose scalable JPC (SPC), which reduces the number of feasible cache placements by dividing the files into non-overlapping subsets. We also compare the JPC and SPC approaches against an existing probabilistic method, referred to as disjoint probabilistic caching (DPC), as well as a random dummy-based approach (RDA). Results obtained through extensive numerical evaluations confirm the validity of the analytical approach and the superiority of JPC and SPC over DPC and RDA.}
}


@article{DBLP:journals/cn/AkarK23,
	author = {Nail Akar and
                  Ezhan Karasan},
	title = {Is proportional fair scheduling suitable for age-sensitive traffic?},
	journal = {Comput. Networks},
	volume = {226},
	pages = {109668},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109668},
	doi = {10.1016/J.COMNET.2023.109668},
	timestamp = {Sun, 04 Aug 2024 19:48:53 +0200},
	biburl = {https://dblp.org/rec/journals/cn/AkarK23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Proportional Fair (PF) scheduling with successful deployments in various cellular wireless networks and wireless LANs, aims at maximizing the sum of the logarithms of user throughputs. PF scheduling is known to strike an appropriate balance between fairness and throughput, for conventional data traffic. On the other hand, there has recently been a surge of interest in status update networks carrying age-sensitive traffic for which information freshness is crucial and therefore network performance metrics driven by Age of Information (AoI) are instrumental, as opposed to conventional performance metrics such as delay, loss, or throughput, used for conventional data traffic. This paper studies the scheduling problem for the downlink of a cellular wireless network with a transmitter sending age-sensitive status update packets from multiple information sources to users with the goal of keeping the information as fresh as possible for the users. For this purpose, under the generate-at-will scenario, an age-agnostic model-free scheduler is proposed with the goal of minimizing the weighted sum peak AoI of the network, which is the performance metric used in this paper for quantifying information freshness. With numerical examples, the proposed scheduler is compared and contrasted with weighted PF scheduling in terms of implementation and performance, in both non-opportunistic and opportunistic scenarios.}
}


@article{DBLP:journals/cn/HuangHLXZ23,
	author = {Xiaohong Huang and
                  Lu Han and
                  Dandan Li and
                  Kun Xie and
                  Yong Zhang},
	title = {A reliable and fair federated learning mechanism for mobile edge computing},
	journal = {Comput. Networks},
	volume = {226},
	pages = {109678},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109678},
	doi = {10.1016/J.COMNET.2023.109678},
	timestamp = {Thu, 30 Mar 2023 22:57:32 +0200},
	biburl = {https://dblp.org/rec/journals/cn/HuangHLXZ23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated learning-enabled mobile edge computing implements privacy-preserving collaborative machine learning of complex models. However, mobile end devices have high mobility and are vulnerable to be corrupted due to exposuring to an open network environment, which not only affect the performance of federated learning models but also bring serious security issues. To solve the above problem, we propose a reliable and fair federated learning mechanism for mobile edge computing. To begin with, in order to select end nodes as reliable as possible, a reputation-based end nodes selection scheme is proposed, which includes the construction of the reputation model and the concealment of selected end nodes. Then, corresponding counter strategies are proposed for the possible attack behaviors launched by corrupted end nodes during the training process. To avoid the impact of poisoning attacks on the model performance, a new global model aggregation strategy is proposed to maintain the model performance by meritocratic campaigning. To solve the fairness problem caused by end nodes’ escape, a reward-penalty scheme using blockchain is proposed. Finally, the numerical results clearly show that the proposed mechanism is effective for reliable and fair federated learning for mobile edge computing, maintaining high accuracy under attacks from malicious end nodes while penalizing them to ensure fairness.}
}


@article{DBLP:journals/cn/RengarajLK23,
	author = {Ramaprabha Rengaraj and
                  Lavanya Dhamodharan Loganathan and
                  Gunaseelan Konganathan},
	title = {Secure upgraded spatial modulation for wireless transmission systems},
	journal = {Comput. Networks},
	volume = {226},
	pages = {109680},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109680},
	doi = {10.1016/J.COMNET.2023.109680},
	timestamp = {Sun, 16 Apr 2023 20:31:00 +0200},
	biburl = {https://dblp.org/rec/journals/cn/RengarajLK23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Physical layer security (PLS) is gaining traction as a potent supplement, if not a complete replacement for encryption-based secure communication systems. The PLS strategy with secret key generation using physical signatures and a novel spatial modulation technique is presented. In this paper, a chaotic theory-based secret key generation method and an upgraded spatial modulation (USM) method with multiple amplitude and phase keying signal constellations are proposed, which ensures secure communication and improves spectral efficiency. The four security levels built into USM are (i) secret key generation, (ii) adaptive selection, (iii) mapping table shuffling, and (iv) transmit vector rotation. The proposed work is compared with other conventional techniques in terms of key strength, spectral efficiency, energy efficiency, and secrecy, and the BER performance of USM has a significant improvement over existing techniques.}
}


@article{DBLP:journals/cn/MushtaqZN23,
	author = {Earum Mushtaq and
                  Aneela Zameer and
                  Rubina Nasir},
	title = {Knacks of a hybrid anomaly detection model using deep auto-encoder
                  driven gated recurrent unit},
	journal = {Comput. Networks},
	volume = {226},
	pages = {109681},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109681},
	doi = {10.1016/J.COMNET.2023.109681},
	timestamp = {Sun, 16 Apr 2023 20:31:00 +0200},
	biburl = {https://dblp.org/rec/journals/cn/MushtaqZN23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The cyber-attacks have recently posed a threat to national security; meanwhile, the pervasiveness of malware and cyber terrorism encumbers the beneficial utilization of the internet. Intrusion detection systems (IDS) can prevent such malevolent attacks. Inappropriate and redundant features affect the performance of IDS by slowing down the classification process and leading to incorrect decisions, specifically when dealing with big data. Therefore, in this study, we propose an auto-encoder and gated recurrent unit (GRU) based intrusion detection system (AE-GRU) to accurately, efficiently, and precisely classify network traffic. In the first step, the most relevant features are extracted from the auto-encoder to pass on to the GRU for traffic type classification. Classification of binary and multiclass have been carried out on the well-known NSL-KDD dataset. The AE-GRU is evaluated in terms of performance indices such as accuracy, precision, recall, F-score, MCC, DR, and FAR. The generalization of the proposed technique is also assessed on another dataset UNSW-NB15. Experimental results demonstrate that the AE-GRU outperforms existing methods in terms of all performance indices. Furthermore, the proposed model has also been statistically evaluated using a one-way ANOVA test. Results signify the potential utilization of the proposed technique in network traffic classification.}
}


@article{DBLP:journals/cn/SinghSMSS23,
	author = {Prabhjot Singh and
                  Parulpreet Singh and
                  Nitin Mittal and
                  Urvinder Singh and
                  Supreet Singh},
	title = {An optimum localization approach using hybrid {TSNMRA} in 2D WSNs},
	journal = {Comput. Networks},
	volume = {226},
	pages = {109682},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109682},
	doi = {10.1016/J.COMNET.2023.109682},
	timestamp = {Sun, 16 Apr 2023 20:31:00 +0200},
	biburl = {https://dblp.org/rec/journals/cn/SinghSMSS23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Wireless Sensor Network (WSN) localization has grown in importance in the research community over the last several decades. Finding the exact position of an event is necessary for many applications, including tracking objects, animals, and a wide range of resources in both indoor and outdoor environment. With the help of a huge number of sensors scattered around the world, WSNs may gather data and communicate with each other. The idea is to investigate various location optimization strategies in order to solve a WSN localization challenge and assign suitable coordinates to unknown sensor nodes. For target node localization using dynamic approach, the authors use a hybrid tunicate swarm naked mole-rat algorithm (TSNMRA) and a single static anchor node to identify targets, and then using the concept of virtual anchors to determine the target nodes location using a hexagonal projection approach. In this study, several location optimization strategies are compared to the TSNMRA-based on the number of localized nodes and localization error.}
}


@article{DBLP:journals/cn/JeonLL23,
	author = {So{-}Eun Jeon and
                  Sun{-}Jin Lee and
                  Il{-}Gu Lee},
	title = {Hybrid in-network computing and distributed learning for large-scale
                  data processing},
	journal = {Comput. Networks},
	volume = {226},
	pages = {109686},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109686},
	doi = {10.1016/J.COMNET.2023.109686},
	timestamp = {Sun, 16 Apr 2023 20:31:00 +0200},
	biburl = {https://dblp.org/rec/journals/cn/JeonLL23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recently, the value of big data generated, processed, and shared by mobile devices and intelligent Internet of Things devices has significantly increased. The speed of data generation is accelerating, and the amount of data that needs to be collected and learned in a distributed database is increasing. However, the conventional data processing methods, centralized and distributed computing, are reaching their limits owing to the trade-off between data processing speed and learning accuracy. To solve this problem, in this study, a hybrid in-network computing (HINC) method that can process data quickly and accurately is proposed. The efficiency of the proposed HINC method was verified by comparing and analyzing its data loss, throughput, and accuracy to those of the conventional method. The experimental results show that in an environment with many nodes in the network, HINC reduces the data loss, which means data that could not be processed because it exceeded the available throughput of the node by 20.94% compared to the conventional method. Furthermore, in an environment with full workload, HINC reduced data loss by an average of 55.6% compared with the conventional centralized computation method. It also improved throughput by an average of 18.91% and model evaluation accuracy by 15.7% compared with the conventional fully distributed computing model.}
}


@article{DBLP:journals/cn/CastellUrozB23,
	author = {Ismael Castell{-}Uroz and
                  Pere Barlet{-}Ros},
	title = {TrackSign-labeled web tracking dataset},
	journal = {Comput. Networks},
	volume = {226},
	pages = {109687},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109687},
	doi = {10.1016/J.COMNET.2023.109687},
	timestamp = {Sat, 13 May 2023 01:07:10 +0200},
	biburl = {https://dblp.org/rec/journals/cn/CastellUrozB23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recent studies [8] show that more than 95% of the websites available on the Internet contain at least one of the so-called web tracking systems. These systems are specialized in identifying their users by means of a plethora of different methods. Some of them (e.g., cookies) are very well known by most Internet users. However, the percentage of websites including more "obscure" and privacy-threatening systems, such as fingerprinting methods identifying a user\'s computer, is constantly increasing. Detecting those methods on today\'s Internet is very difficult, as almost any website modifies its content dynamically and minimizes its code in order to speed up loading times. This minimization and dynamicity render the website code unreadable by humans. Thus, the research community is constantly looking for new ways to discover unknown web tracking systems running under the hood.}
}


@article{DBLP:journals/cn/FazioMVRT23,
	author = {Peppino Fazio and
                  Miralem Mehic and
                  Miroslav Vozn{\'{a}}k and
                  Floriano De Rango and
                  Mauro Tropea},
	title = {A novel predictive approach for mobility activeness in mobile wireless
                  networks},
	journal = {Comput. Networks},
	volume = {226},
	pages = {109689},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109689},
	doi = {10.1016/J.COMNET.2023.109689},
	timestamp = {Sat, 13 May 2023 01:07:10 +0200},
	biburl = {https://dblp.org/rec/journals/cn/FazioMVRT23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Nowadays, mobile computing has become a key component of telecommunication systems, and the Open Systems Interconnection (OSI) layer operations are affected by the effects of node movements along the roads, from the physical to the routing/transport layers. In particular, routing approaches have been investigated from many years, trying to optimize the performance of the whole considered system, under different points of view. In this paper we are focusing the attention on the analysis of the mobility grade trend for a mobile ad-hoc network environment, as well as on the way it can be a-priori known, in order to have the possibility to study how the dynamics of mobile nodes can be described and in-advance known, with a predicted knowledge of nodes stability (in terms of mobility). Our simulations considered mobility in real geographical maps, and the obtained results confirmed the goodness of our proposed study.}
}


@article{DBLP:journals/cn/ZhengP23,
	author = {Jiaxing Zheng and
                  Li Pan},
	title = {Dominant coverage for target users at the lowest cost under competitive
                  propagation in social networks},
	journal = {Comput. Networks},
	volume = {226},
	pages = {109693},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109693},
	doi = {10.1016/J.COMNET.2023.109693},
	timestamp = {Sun, 16 Apr 2023 20:31:00 +0200},
	biburl = {https://dblp.org/rec/journals/cn/ZhengP23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Multiple pieces of information disseminated in social networks can create a competitive environment where the influence of each message will be reduced. Thus, how to increase the influence under competitive propagation is significant for many applications such as product marketing and rumor suppression. In this paper, to make the dissemination targeted and maximize revenue, we propose the lowest cost problem to achieve dominant coverage for target users under competitive propagation(LC-CTU problem), using target user profiles and setting the objective to dominate coverage. To better model this scene, this paper proposes a competitive restricted propagation independent cascade model based on weights of attribute-generating edges(IC-CRA model), which adds competition, delay, and attributes to the basic independent cascade model. After proving that the LC-CTU problem under the IC-CRA model is NP-hard and the objective function is monotonic and submodular, the problem can be solved by a greedy algorithm. However, the greedy algorithm is time-consuming for large social networks. Thus, to improve the efficiency of the algorithm, we propose the lowest cost heuristic algorithm based on target users and restricted competition (LCH-TU algorithm), which uses the local influence update of each node for selecting the seed node. Finally, this paper demonstrates the effectiveness, efficiency, and scalability of the LCH-TU algorithm through extensive experiments on seven datasets, including real and artificial networks.}
}


@article{DBLP:journals/cn/ZengCQZW23,
	author = {Zijie Zeng and
                  Lin Cui and
                  Mimi Qian and
                  Zhen Zhang and
                  Kaimin Wei},
	title = {A survey on sliding window sketch for network measurement},
	journal = {Comput. Networks},
	volume = {226},
	pages = {109696},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109696},
	doi = {10.1016/J.COMNET.2023.109696},
	timestamp = {Sun, 16 Apr 2023 20:31:00 +0200},
	biburl = {https://dblp.org/rec/journals/cn/ZengCQZW23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As an important basis for network management, effective network measurement is critical for improving network performance and security. As an efficient tool for network measurement, sketch is a probabilistic data structure which can measure traffic statistics with low overhead. Considering that the most recent data of flows are more significant, sliding window sketch is proposed by combining sliding window model with the sketch. Sliding window sketch focuses on measuring information of the most recent period, e.g., data of the last\nN\nitems or in the last\nN\ntime units of measured traffic. By prioritizing the latest data, sliding window sketch can better reflect the current network situation and the future trend while avoiding information loss. However, implementation of sliding window sketch is very challenging considering the memory limitations of network devices and the need to maintain the window content in real-time. This paper conducts a comprehensive survey on the latest research works and provides insights into sliding window sketch. First, we briefly review the fundamentals of network measurement and sketch, and then we thoroughly go through and analyze the existing works on sliding window sketch for three different types. Afterwards, we provide a comparative analysis on the design of sliding window sketch in terms of data structures, supported operations, measurement tasks, implementation platforms and performance. Finally, we summarize this survey paper and highlight some future research directions.}
}
