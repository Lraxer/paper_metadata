@article{DBLP:journals/cn/AhatBAAOE21,
	author = {Bet{\"{u}}l Ahat and
                  Ahmet Cihat Baktir and
                  Necati Aras and
                  I. Kuban Altinel and
                  Atay {\"{O}}zg{\"{o}}vde and
                  Cem Ersoy},
	title = {Optimal server and service deployment for multi-tier edge cloud computing},
	journal = {Comput. Networks},
	volume = {199},
	pages = {108393},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108393},
	doi = {10.1016/J.COMNET.2021.108393},
	timestamp = {Wed, 15 Dec 2021 10:28:58 +0100},
	biburl = {https://dblp.org/rec/journals/cn/AhatBAAOE21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A wide variety of novel services have been envisioned lately due to wearable gadgets, autonomous vehicles, and IoT applications. These services cannot directly be implemented using centralized cloud computing infrastructure due to large Wide Area Network (WAN) delays. Recently, edge computing is proposed to comply with the requirements of these services, where resilient local servers are accessed through fast wireless links. With this approach, real-time service access can be achieved by handling the user requests at the edge computing infrastructure. Since edge and cloud servers may potentially cooperate, operators can maximize their revenues by optimally deploying the computational resources, distributing the services within the network, and assigning the tasks generated by the end-users. These decisions, each of which is a difficult task on its own, are integrated in this study and formulated as a mixed-integer linear programming (MILP) model to optimally design a multi-tier computation structure. Because of the scalability issue, a heuristic algorithm based on the Lagrangian relaxation of the MILP formulation is proposed to solve larger instances. Additionally, in order to provide an opportunity for the operators to find a feasible solution in a very short time, a greedy heuristic approach is presented. To evaluate the performance of the proposed methods, computational experiments are conducted on a broad suite of randomly generated topologies. The results indicate that the proposed approaches can obtain high-quality solutions within the given time limit.}
}


@article{DBLP:journals/cn/LiuHFLAW21,
	author = {Peng Liu and
                  Han He and
                  Tingting Fu and
                  Huijuan Lu and
                  Abdulhameed Alelaiwi and
                  Md. Wasif Islam Wasi},
	title = {Task offloading optimization of cruising {UAV} with fixed trajectory},
	journal = {Comput. Networks},
	volume = {199},
	pages = {108397},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108397},
	doi = {10.1016/J.COMNET.2021.108397},
	timestamp = {Wed, 03 Nov 2021 08:26:11 +0100},
	biburl = {https://dblp.org/rec/journals/cn/LiuHFLAW21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Unmanned aerial vehicle (UAV) have been deployed in many applications, such as Power Grid inspection, forest fire prevention, and pollution surveillance. They often cruise along a fixed route above the target area. Due to the cost of remote communication and local computationally intensive tasks, resource-constrained drones tend to offload tasks to edge servers. In most cases, drones do not know the prior knowledge of user nodes and edge servers, and must reduce the altitude to provide services. Therefore, it is necessary to carefully decide when and where to collect and offload tasks to avoid unnecessary energy consumption and time delays. In this paper, we propose the benefit maximization problem under constraints such as time sensitivity, and propose an optimized task offloading strategy based on the reinforcement learning algorithm. We strive to directly solve the deficiencies in the profit maximization problem with modified Q-Learning algorithm. We test the performance under practical application scenarios with different environmental parameters. The experimental results prove that the solution proposed in this paper has better convergence and performance, as well as better reusability in similar application scenarios.}
}


@article{DBLP:journals/cn/BarliYHH21,
	author = {Eirik Molde B{\aa}rli and
                  Anis Yazidi and
                  Enrique Herrera{-}Viedma and
                  H{\aa}rek Haugerud},
	title = {DoS and DDoS mitigation using Variational Autoencoders},
	journal = {Comput. Networks},
	volume = {199},
	pages = {108399},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108399},
	doi = {10.1016/J.COMNET.2021.108399},
	timestamp = {Wed, 15 Dec 2021 10:28:57 +0100},
	biburl = {https://dblp.org/rec/journals/cn/BarliYHH21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {DoS and DDoS attacks have been growing in size and number over the last decade and existing solutions to mitigate these attacks are largely inefficient. Compared to other types of malicious cyber attacks, DoS and DDoS attacks are particularly challenging to combat. Because of their ability to mask themselves as legitimate traffic, it has proven difficult to develop methods to detect these types of attacks on a packet or flow level. In this paper, we explore the potential of Variational Autoencoders to serve as a component within an intelligent security solution that differentiates between normal and malicious traffic. The motivation behind resorting to Variational Autoencoders is that unlike normal encoders that would code an input flow as a single point, they encode a flow as a distribution over the latent space which avoids overfitting. Intuitively, this allows a Variational Autoencoder to not only learn latent representations of seen input features, but to generalize in a way that allows for an interpretation of unseen flows and flow features with slight variations.}
}


@article{DBLP:journals/cn/PopliJJ21,
	author = {Sakshi Popli and
                  Rakesh Kumar Jha and
                  Sanjeev Jain},
	title = {Green {NOMA} assisted NB-IoT based urban farming in multistory buildings},
	journal = {Comput. Networks},
	volume = {199},
	pages = {108410},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108410},
	doi = {10.1016/J.COMNET.2021.108410},
	timestamp = {Wed, 07 Dec 2022 23:01:40 +0100},
	biburl = {https://dblp.org/rec/journals/cn/PopliJJ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this study, 5G- NB-IoT, enabled smart urban farming framework is presented. In order to maximize the Energy-Efficiency (EE) of NB-IoT enabled sensor network's downlink performance (deployed in urban structure), 5 G promising technology device to device (D2D) communication along with power-domain Non-Orthogonal-Multiple-Access (NOMA) principle were used and studied at two levels, i.e. NOMA-at- Base Station (BS) and NOMA-at-Edge. In the case of NOMA-at-BS, the BS transmits the superimposed signals to the NB-IoT-enabled sensor D2D pairs (termed as NOMA-D2D approach). Whereas in the case of NOMA at the Edge, in the group of NB-IoT enabled sensor nodes, the group head will transmit the superimposed signals to other group receiver sensor nodes (termed as Group-NOMA-D2D approach). These suggested solutions, ensure interference-free communication among deployed NB-IoT enabled sensor networks. The proposed approaches were implemented on the NB-IoT sensor network (deployed in balconies of two multistory building structures) and their results were evaluated through simulation. The promising enhancement in terms of sum-rate (32% to 35 %), total-energy efficiency, and fairness factor (1- 0.98) has been achieved using the Group NOMA-D2D approach in comparison to NOMA-D2D and conventional D2D approach. In addition to this, a fuzzy logic-aided solution has also been proposed for NB-IoT enabled sensor network, uplink resource grant, and post allocation resource re-utilization, this, in turn, improved the Quality of Experience (QoE) by 2–14%.}
}


@article{DBLP:journals/cn/SalehiE21,
	author = {Shavbo Salehi and
                  Behdis Eslamnour},
	title = {Improving {UAV} base station energy efficiency for industrial IoT
                  {URLLC} services by irregular repetition slotted-ALOHA},
	journal = {Comput. Networks},
	volume = {199},
	pages = {108415},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108415},
	doi = {10.1016/J.COMNET.2021.108415},
	timestamp = {Wed, 03 Nov 2021 08:26:11 +0100},
	biburl = {https://dblp.org/rec/journals/cn/SalehiE21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the past few years, the continual improvement of 5G technology has supported powerful IoT (Internet of Things) and IIoT (Industrial IoT) devices which have been used to provide a wide range of services. One of the service types that has been noticed recently is URLLC (Ultra-Reliable Low-Latency Communication) service that requires highly reliable communication and low latency bounds. In this paper, intending to meet the latency and reliability requirements of IIoT users located outdoor in a hard-to-reach area, we propose to use a UAV-BS (Unmanned Aerial Vehicle Base Station) for air-to-ground (A2G) communications. Despite the very fact that UAV-BSs have been used widely, yet they have some shortcomings in flight time. So we proposed an energy-efficient trajectory design method to reduce the UAV-BS’s energy consumption for both the communication and mobility functions while fulfilling the application’s reliability and latency requirements. We proposed a UMC-IRSA (UAV-BS Multi-Channel Irregular Repetition Slotted-ALOHA) method to adapt the New Radio (NR) distinct frame structure for IIoT users. The IIoT nodes are clustered by the UMC-IRSA method (based on Mahalanobis distance) to decrease the UAV-BS energy consumption. The simulation results show that the UMC-IRSA clustering method combined with the Q-Learning algorithm for clusters serving decreases the UAV-BS energy consumption for flying in fixed altitude. The reduction in energy consumption provided by using the combination of UMC-IRSA and Q-Learning, in comparison to the combination of UMC-IRSA and Random Serving, combination of CRP (Chinese Restaurant Process) and Q-Learning, and CRP and Random Serving is 19%, 24%, and 31% respectively.}
}


@article{DBLP:journals/cn/Halgamuge21,
	author = {Malka N. Halgamuge},
	title = {Optimization framework for Best Approver Selection Method {(BASM)}
                  and Best Tip Selection Method {(BTSM)} for {IOTA} tangle network:
                  Blockchain-enabled next generation Industrial IoT},
	journal = {Comput. Networks},
	volume = {199},
	pages = {108418},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108418},
	doi = {10.1016/J.COMNET.2021.108418},
	timestamp = {Wed, 03 Nov 2021 08:26:12 +0100},
	biburl = {https://dblp.org/rec/journals/cn/Halgamuge21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We develop an optimization framework to increase network scalability and to incorporate a priority level for essential transactions based on the Internet of Things and Application (IOTA) Tangle network for a blockchain-enabled next-generation industrial network. Firstly, we propose a model to count newly arrived tips (transactions) into a selected timeframe and calculate the transaction time before joining the Tangle network as a new tip. Selecting secure transactions for approval requires an accurate tip selection method. Secondly, we develop the Best Tip Selection Method (BTSM) to increase network security and to incorporate the priority level for essential or prioritized IoT transactions. Thirdly, we develop a multiple-objective unconstrained optimization strategy, the Best Approver Selection Method (BASM). The objective of BASM is to optimize the trade-off between the multiplication of network latency and the cumulative weight of transactions and approvers’ Tangle time after joining the network. Finally, we estimate the probability of malicious attacks on a Tangle network by assuming the transactions’ cumulative weight increases linearly with transaction arrival speed to a Tangle. We adapt the fault-tolerance relationship to secure the system. We then analyze our model to decide that requires us to consider the trade-off between these two factors to obtain the optimal value. Our results show that BTSM and BASM are viable solutions for next-generation Industrial IoT networks with fast machine-to-machine communications. Compared with IOTA and other existing strategies, our proposed model offers the advantage of identifying the probability of malicious attacks with high accuracy; thus minimizing malicious attacks and optimizing the network latency for next-generation Industrial IoT networks. In summary, the proposed mechanism would allow adding more transactions from IoT devices to the IOTA Tangle and discourage existing malicious transactions from verifying new transactions. The proposed mechanism could be utilized in real-world applications, including enabling preference levels for essential or prioritized activities and fault-tolerance adaptation. IOTA aims to play a vital role in the next-generation industrial revolution; our study advances the IOTA Tangle to move a step forward towards this direction.}
}


@article{DBLP:journals/cn/KohliCDWSKZ21,
	author = {Manav Kohli and
                  Tingjun Chen and
                  Mahmood Baraani Dastjerdi and
                  Jackson Welles and
                  Ivan Seskar and
                  Harish Krishnaswamy and
                  Gil Zussman},
	title = {Open-access full-duplex wireless in the {ORBIT} and {COSMOS} testbeds},
	journal = {Comput. Networks},
	volume = {199},
	pages = {108420},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108420},
	doi = {10.1016/J.COMNET.2021.108420},
	timestamp = {Wed, 03 Nov 2021 08:26:11 +0100},
	biburl = {https://dblp.org/rec/journals/cn/KohliCDWSKZ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In order to support experimentation with full-duplex (FD) wireless, we integrated two generations of FD radios in the open-access ORBIT and COSMOS testbeds. In the indoor ORBIT testbed, we integrated a customized 1st generation (Gen-1) narrowband FD radio. In the city-scale PAWR COSMOS testbed, we integrated four 2nd generation (Gen-2) wideband FD radios, as well as static and mobile Gen-1 FD radios.}
}


@article{DBLP:journals/cn/QinCCLZP21,
	author = {Hua Qin and
                  Weihong Chen and
                  Weimin Chen and
                  Ni Li and
                  Min Zeng and
                  Yang Peng},
	title = {A collision-aware mobile tag reading algorithm for RFID-based vehicle
                  localization},
	journal = {Comput. Networks},
	volume = {199},
	pages = {108422},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108422},
	doi = {10.1016/J.COMNET.2021.108422},
	timestamp = {Wed, 03 Nov 2021 08:26:11 +0100},
	biburl = {https://dblp.org/rec/journals/cn/QinCCLZP21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the development of radio frequency identification (RFID) technology, RFID systems on roads (RSR) have recently been put forward to localize not only manned vehicles but also autonomous vehicles. In such an RFID-based localization infrastructure, passive RFID tags with road-related information are deployed on road surfaces, and any vehicle equipped with an RFID reader can interrogate the tags to obtain its locations. However, like traditional RFID systems, reader collisions could occur when many vehicles (readers) continuously move in and out of a tag’s reading range, significantly degrading tag reading performance. Although many anti-collision algorithms have been devised to improve tag reading efficiency, none can be applied in highly mobile and dynamic road environments. In this paper, we propose an adaptive mobile tag reading algorithm, which can effectively reduce reader collisions and improve tag reading efficiency for reliable vehicle localization under various traffic scenarios. Extensive simulation and experiment have verified the feasibility and the effectiveness of our proposed scheme. Particularly, the field tests demonstrate that, with moderate vehicle density and sparsely deployed tags, our proposed algorithm can satisfy the tag reading requirements specified by the upper-layer localization system with a probability as high as 0.976.}
}


@article{DBLP:journals/cn/PlattM21,
	author = {Moritz Platt and
                  Peter McBurney},
	title = {Sybil attacks on identity-augmented Proof-of-Stake},
	journal = {Comput. Networks},
	volume = {199},
	pages = {108424},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108424},
	doi = {10.1016/J.COMNET.2021.108424},
	timestamp = {Sat, 09 Apr 2022 12:25:50 +0200},
	biburl = {https://dblp.org/rec/journals/cn/PlattM21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {IdAPoS is an identity-based consensus protocol for decentralised Blockchain networks that implements a trustless reputation system by extending Proof-of-Stake to facilitate leader selection in non-economic contexts. Like any protocol operating in a public/permissionless setting, it is vulnerable to Sybil attacks in which byzantine actors interfere with peer sampling by presenting artificially large numbers of identities. This paper demonstrates what influence these attacks have on the stability of member selection of a Blockchain system using the IdAPoS protocol and investigates how attacks can be mitigated. As a novel protocol, its vulnerability to this type of attack has not previously been researched. The research question is approached via an agent-based model of an IdAPoS system in which both honest and malicious actors are represented as agents. Simulations are run on some reasonable configurations of an IdAPoS system that employ different attack mitigation strategies. The results show that a super strategy that combines multiple individual mitigation strategies is more effective for containing Sybil attacks than the unmitigated protocol and any other individual strategies proposed. In the simulation this strategy extended the time until a system was taken over by a malicious entity approximately by a factor of 5. These positive initial results indicate that further research into the practical viability of the protocol is warranted.}
}


@article{DBLP:journals/cn/XiangEMN21,
	author = {Bin Xiang and
                  Jocelyne Elias and
                  Fabio Martignon and
                  Elisabetta Di Nitto},
	title = {Resource calendaring for Mobile Edge Computing: Centralized and decentralized
                  optimization approaches},
	journal = {Comput. Networks},
	volume = {199},
	pages = {108426},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108426},
	doi = {10.1016/J.COMNET.2021.108426},
	timestamp = {Wed, 03 Nov 2021 08:26:11 +0100},
	biburl = {https://dblp.org/rec/journals/cn/XiangEMN21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Mobile Edge Computing (MEC) is a key technology for the deployment of next generation (5G and beyond) mobile networks. The computational power it provides at the edge could allow providers to fulfill the requirements of use cases in need of ultra-low latency, high bandwidth, as well as real-time access to the radio network. However, this potential needs to be carefully administered as the edge is certainly limited in terms of computation capability, as opposed to the cloud which holds the promise of a virtually infinite power. MEC nodes, though, could still try to exploit not only their local capacity, but also the one that the neighbor MEC nodes could offer. Considering that the 5G scenario assumes an ultra-dense distribution of MEC nodes, this possibility could be feasible, provided that we find an effective way to carefully allocate the resources available at each edge node.}
}


@article{DBLP:journals/cn/LiuXXMWQH21,
	author = {Jianchun Liu and
                  Hongli Xu and
                  Yang Xu and
                  Zhenguo Ma and
                  Zhiyuan Wang and
                  Chen Qian and
                  He Huang},
	title = {Communication-efficient asynchronous federated learning in resource-constrained
                  edge computing},
	journal = {Comput. Networks},
	volume = {199},
	pages = {108429},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108429},
	doi = {10.1016/J.COMNET.2021.108429},
	timestamp = {Mon, 26 Jun 2023 20:51:11 +0200},
	biburl = {https://dblp.org/rec/journals/cn/LiuXXMWQH21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated learning (FL) has been widely used to train machine learning models over massive data in edge computing. However, the existing FL solutions may cause long training time and/or high resource (e.g., bandwidth) cost, and thus cannot be directly applied for resource-constrained edge nodes, such as base stations and access points. In this paper, we propose a novel communication-efficient asynchronous federated learning (CE-AFL) mechanism, in which the parameter server will aggregate the local model updates only from a certain fraction\nα\n, with\n0\n<\nα\n<\n1\n, of all edge nodes by their arrival order in each epoch. As a case study, we design efficient algorithms to determine the optimal value of\nα\nfor two cases of CE-AFL, single learning task and multiple learning tasks, under bandwidth constraints. We formally prove the convergence of the proposed algorithm. We evaluate the performance of our algorithm with experiments on Jetson TX2, deep learning workstation and extensive simulations. Both experimental results and simulation results on the classical models and datasets show the effectiveness of our proposed mechanism and algorithms. For example, CE-AFL can reduce the training time by about 69% while achieving similar accuracy, and improve the accuracy of the trained models by about 18% under resource constraints, compared with the state-of-the-art solutions.}
}


@article{DBLP:journals/cn/ArnoldL21,
	author = {Rachel Arnold and
                  Dave Longley},
	title = {Continuity: {A} deterministic Byzantine fault tolerant asynchronous
                  consensus algorithm},
	journal = {Comput. Networks},
	volume = {199},
	pages = {108431},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108431},
	doi = {10.1016/J.COMNET.2021.108431},
	timestamp = {Wed, 03 Nov 2021 08:26:12 +0100},
	biburl = {https://dblp.org/rec/journals/cn/ArnoldL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In 1985, Fischer, Lynch, and Patterson presented the FLP Impossibility Theorem which states that it is impossible for an asynchronous system to reach consensus if at least one node fails; asynchrony prevents distinguishing between process crashes and delays. Traditionally, asynchronous consensus algorithms implement protocol adaptations to handle delays and prevent indefinite runs (e.g. coordination protocols in the form of ordered rounds). In this paper, we present a deterministic Byzantine fault tolerant asynchronous consensus algorithm called Continuity. Within this system, processes do not begin by supporting a possible decision value. Instead, Continuity utilizes logical monotonicity to build an initial configuration that is necessarily univalent, thus eliminating the assumed initial conditions of the FLP Impossibility Theorem. As such, Continuity achieves consensus in a wait-free manner.}
}


@article{DBLP:journals/cn/LiuX21,
	author = {Yong Liu and
                  Guangxia Xu},
	title = {Fixed degree of decentralization DPoS consensus mechanism in blockchain
                  based on adjacency vote and the average fuzziness of vague value},
	journal = {Comput. Networks},
	volume = {199},
	pages = {108432},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108432},
	doi = {10.1016/J.COMNET.2021.108432},
	timestamp = {Wed, 03 Nov 2021 08:26:11 +0100},
	biburl = {https://dblp.org/rec/journals/cn/LiuX21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Delegated Proof of Stake (DPoS) consensus mechanism is the fastest, most effective, most decentralized, and most flexible consensus model. The DPoS consensus uses the power of stakeholders to agree to vote in resolving consensus issues in a fair and democratic manner. However, in a traditional DPoS consensus mechanism, the degree of decentralization is undefined, and the number of agent nodes is fixed in advance. In this paper, a new fixed degree of decentralization for the DPoS consensus mechanism is proposed based on the adjacency vote and the average fuzziness of vague value. Moreover, the degree of decentralization is defined and discussed. As nodes are dynamically added and withdrawn, the total number of nodes in the blockchain changes. The proposed new consensus mechanism can automatically determine the number of agent nodes to be selected, based on the degree of decentralization and the total number of nodes in the blockchain. The adjacency vote and the average fuzziness of vague value are used to select agent nodes, and this method improves the fairness and security of the blockchain. We analyze five agent nodes, selected from 15 nodes, using the balloting distribution results. The feasibility and effectiveness of our new consensus mechanism are confirmed based on two test examples.}
}


@article{DBLP:journals/cn/PopliJJ21a,
	author = {Sakshi Popli and
                  Rakesh Kumar Jha and
                  Sanjeev Jain},
	title = {A comprehensive survey on Green {ICT} with 5G-NB-IoT: Towards sustainable
                  planet},
	journal = {Comput. Networks},
	volume = {199},
	pages = {108433},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108433},
	doi = {10.1016/J.COMNET.2021.108433},
	timestamp = {Wed, 07 Dec 2022 23:01:41 +0100},
	biburl = {https://dblp.org/rec/journals/cn/PopliJJ21a.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Rapid advancement in ICT is promoting us into an era of unprecedented prosperity & countless possibilities. However, there is one gloomy side of the ICT technology that contributes toward the inflation of carbon footprint. Research from 2020, estimates the ICT sector, carbon emission, to be 1,100 million tons. The future generation networks and IoT will further escalate this figure, as these would overburden the core ICT pillars i.e. Data Centers (DC's), and Mobile networks (NT). This in turn will inflate the ICT power consumption and leads to more carbon emission. Thus researchers and industries are continuously putting efforts to transform ICT into Green ICT. Apart from this, there is one bright side of ICT i.e. “Green BY ICT” that helps other industries to abate their carbon emission using smart IoT applications. However, the smart IoT devices/sensors/actuators used for this are mostly battery-operated. To reduce the battery waste, efforts are also being made to either prolong their battery life or to make them self-powered or battery-free. This survey discusses both aspects of ICT i.e. Green of ICT and Green by ICT. Firstly, the recent approaches for the Greening of ICT include techniques for Green-DC, Green-NT are discussed. Post discussing this, the paper also confers the energy harvesting solutions & energy-efficient techniques for the greening of user device/senor. In continuation of this, 5G green physical layer solution, Narrowband Internet of Things (NB-IoT) that prolongs battery life is also discussed, including its enhancement from release 13 to release 16, recent techniques to further optimize the NB-IoT performance, and future research challenges. Apart from this the recent advancement related to renewable energy solutions for Green ICT is also discussed. Overall this survey concludes that ICT's own environmental impact must be evaded, to utilize the ICT's tremendous potential.}
}


@article{DBLP:journals/cn/FouratiMCJ21,
	author = {Hasna Fourati and
                  Rihab Maaloul and
                  Lamia Chaari and
                  Mohamed Jmaiel},
	title = {Comprehensive survey on self-organizing cellular network approaches
                  applied to 5G networks},
	journal = {Comput. Networks},
	volume = {199},
	pages = {108435},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108435},
	doi = {10.1016/J.COMNET.2021.108435},
	timestamp = {Sat, 09 Apr 2022 12:25:52 +0200},
	biburl = {https://dblp.org/rec/journals/cn/FouratiMCJ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Self-Organizing Network (SON) stands for a key concept characterizing the behavior of the future mobile networks. The evolution of telecom infrastructures towards 5G transforms the network management from the traditional and static processes to automatic and dynamic ones. SON was proposed to offer agile on-demand services to the users through providing self-adaptation capabilities to mobile networks on different categories. This paper presents a detailed and exhaustive survey on SON evolution from 4G towards 5G networks. The central focus of this survey is upon providing a deep understanding of SON mechanisms along with the architectural changes associated with 5G networks. Within this framework, the approaches and trends in self-organizing cellular networks are discussed. Additionally, the main functionalities of SON, namely self-configuration, self-optimization and self-healing are displayed. Our work serves as an enlightening guideline for future research works on SON as far as cellular networks domain is concerned.}
}


@article{DBLP:journals/cn/AlhowaidiNHRB21,
	author = {Mohammad Alhowaidi and
                  Deepak Nadig and
                  Boyang Hu and
                  Byrav Ramamurthy and
                  Brian Bockelman},
	title = {Cache management for large data transfers and multipath forwarding
                  strategies in Named Data Networking},
	journal = {Comput. Networks},
	volume = {199},
	pages = {108437},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108437},
	doi = {10.1016/J.COMNET.2021.108437},
	timestamp = {Wed, 03 Nov 2021 08:26:12 +0100},
	biburl = {https://dblp.org/rec/journals/cn/AlhowaidiNHRB21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Named Data Networking (NDN) is a promising approach to provide fast in-network access to compact muon solenoid (CMS) datasets. It proposes a content-centric rather than a host-centric approach to data retrieval. Data packets with unique and immutable names are retrieved from a content store (CS) using Interest packets. The current NDN architecture relies on forwarding strategies that are only dependent upon on-path caching. Such a design does not take advantage of the cached content available on the adjacent off-path routers in the network, thus reducing data transfer efficiency. In this work, we propose a software-defined, storage-aware routing mechanism that leverages NDN router cache-states, software defined networking (SDN) and multipath forwarding strategies to improve the efficiency of very large data transfers. First, we propose a novel distributed multipath (D-MP) forwarding strategy and enhancements to the NDN Interest forwarding pipeline. In addition, we develop a centralized SDN-enabled control for the multipath forwarding strategy (S-MP), which leverages the global knowledge of NDN network states that distributes Interests efficiently. We perform extensive evaluations of our proposed methods on an at-scale wide area network (WAN) testbed spanning six geographically separated sites. Our proposed solutions easily outperform the existing NDN forwarding strategies. The D-MP strategy results in performance gains ranging between 10.4x to 12.5x over the default NDN implementation without in-network caching, and 12.2x to 18.4x with in-network caching enabled. For S-MP strategy, we demonstrate a performance improvement of 10.6x to 12.6x, and 12.9x to 18.5x, with in-network caching disabled and enabled, respectively. Further, we also present a comprehensive analysis of NDN cache management for large data transfers and propose a novel prefetching mechanism to improve data transfer performance. Due to the inherent capacity limitations of the NDN router caches, we use SDN to provide an intelligent and efficient solution for data distribution and routing across multiple NDN router caches. We demonstrate how software-defined control can be used to partition and distribute large CMS files based on NDN router cache-state knowledge. Further, SDN control will also configure the router forwarding strategy to retrieve CMS data from the network. Our proposed solution demonstrates that the CMS datasets can be retrieved 28%–38% faster from the NDN routers’ caches than existing NDN approaches. Lastly, we develop a prefetching mechanism to improve the transfer performance of files that are not available in the router’s cache.}
}


@article{DBLP:journals/cn/WeiMLWHL21,
	author = {Dawei Wei and
                  Jianfeng Ma and
                  Linbo Luo and
                  Yunbo Wang and
                  Lei He and
                  Xinghua Li},
	title = {Computation offloading over multi-UAV {MEC} network: {A} distributed
                  deep reinforcement learning approach},
	journal = {Comput. Networks},
	volume = {199},
	pages = {108439},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108439},
	doi = {10.1016/J.COMNET.2021.108439},
	timestamp = {Wed, 24 May 2023 14:07:31 +0200},
	biburl = {https://dblp.org/rec/journals/cn/WeiMLWHL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Unmanned aerial vehicle (UAV)-assisted computation offloading allows mobile devices (MDs) to process computation-intensive and latency-sensitive tasks with limited or no-available infrastructures. To achieve long-term performance under changing environment, deep reinforcement-based methods have been applied to solve the UAV-assisted computation offloading problem. However, the deployment of multiple UAVs for computation offloading in mobile edge computing (MEC) network still faces the challenge of lacking flexible learning scheme to efficiently adjust computation offloading policy according to dynamic UAV mobility pattern and UAV failure. To this end, a distributed deep reinforcement learning (DRL)-based method with the cooperative exploring and prioritized experience replay (PER) is proposed in this paper. Our distributed exploring process achieves flexible learning scheme under UAV failure by allowing MDs to learning cost-efficient offloading policy cooperatively. Furthermore, PER allows MDs can explore the transitions with high TD-error, which can improve the performance under dynamic UAV mobility patterns. The efficiency of the proposed method is demonstrated by comparing with the existing computation offloading methods, and results show that the proposed method outperforms the compared methods in terms of convergence rate, energy-task efficiency and average processing time.}
}


@article{DBLP:journals/cn/DengHLGXR21,
	author = {Qingyong Deng and
                  Shaobo Huang and
                  Zhetao Li and
                  Bin Guo and
                  Liyao Xiang and
                  Rong Ran},
	title = {A secure data collection strategy using mobile vehicles joint UAVs
                  in smart city},
	journal = {Comput. Networks},
	volume = {199},
	pages = {108440},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108440},
	doi = {10.1016/J.COMNET.2021.108440},
	timestamp = {Fri, 22 Oct 2021 09:37:49 +0200},
	biburl = {https://dblp.org/rec/journals/cn/DengHLGXR21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recruiting mobile vehicles (MVs) has been proved as an effective and low-cost strategy to collect data from sensing devices (SDs) in the smart city. However, few works consider data security when using MVs as data mules. In our previous work, we have proposed a Consistent Trust Verification for MVs (CTV-MV), which builts trust through recommendation relationships, but this method was vulnerable to collusion attack, that is, multiple MVs provided consistent fake data to deceive the system. Therefore, a Cross Trust Verification for MVs joint UAVs (CTV-MVU) data collection strategy is proposed in this paper, where the Unmanned Aerial Vehicles (UAVs) are deployed to collect data from specific SDs which are used as baseline data to realize trust reasoning mechanism. Besides, the UAVs can also sense the SDs that are difficult to be collected by MVs due to their limitations of coverage, and thus improve the data collection ratio. Furthermore, a Trust Priority Recruitment (TPR) strategy for CTV-MVU is also proposed to prioritize the recruitment of high-trust MVs. Experiment results show that the proposed CTV-MVU strategy outperforms the CTV-MV one in terms of the excellent ratio, trust, data collection ratio, and robustness.}
}


@article{DBLP:journals/cn/JagannathJ21,
	author = {Anu Jagannath and
                  Jithin Jagannath},
	title = {Dataset for modulation classification and signal type classification
                  for multi-task and single task learning},
	journal = {Comput. Networks},
	volume = {199},
	pages = {108441},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108441},
	doi = {10.1016/J.COMNET.2021.108441},
	timestamp = {Fri, 22 Oct 2021 09:37:49 +0200},
	biburl = {https://dblp.org/rec/journals/cn/JagannathJ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Wireless signal characterization is a growing area of research and an essential tool to enable spectrum monitoring, tactical signal recognition, spectrum management, signal authentication for secure communication, and so on. Recent years have witnessed several deep neural network models to perform single task signal characterization such as radio fingerprinting for emitter identification, automatic modulation classification, spectrum sharing, etc. However, with the emergence of 5G and the prospects of beyond 5G communication, there has been an increased deployment of edge devices that requires lightweight neural network models to perform signal characterization. To this end, a multi-task learning model that can perform multiple signal characterization tasks with a single neural network model has been proposed. However, due to the novel nature of multi-task learning as applied to signal characterization, there is a lack of a corresponding dataset with multiple labels for each waveform. In this paper, we openly share a synthetic wireless waveforms dataset suited for modulation recognition and wireless signal (protocol) classification tasks separately as well as jointly. The waveforms comprise radar and communication waveforms generated with GNU Radio to represent a heterogeneous wireless environment.}
}


@article{DBLP:journals/cn/HamoudKC21,
	author = {Othmane Nait Hamoud and
                  Tayeb Kenaza and
                  Yacine Challal},
	title = {Certificateless Public Key Systems Aggregation: An enabling technique
                  for 5G multi-domain security management and delegation},
	journal = {Comput. Networks},
	volume = {199},
	pages = {108443},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108443},
	doi = {10.1016/J.COMNET.2021.108443},
	timestamp = {Mon, 28 Aug 2023 21:39:20 +0200},
	biburl = {https://dblp.org/rec/journals/cn/HamoudKC21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Network slicing is promising to provide the most cost-effective way of supporting 5G and beyond End-to-End (E2E) services in a multi-domain/multi-tenant environment. However, security issues are expected to worsen. Indeed, a 5G E2E service could be provided among participation of multiple stakeholders deploying each its security mechanism, which would reduce the flexibility and efficiency that are supposed to characterize 5G services. Also, fierce competition for market share may lead some stakeholders to cheat in the processing of individuals’ data and thus infringe on privacy, and undermine the trust between stakeholders. Public Key Cryptography is widely used where the main challenge is how to ensure the authenticity of cryptographic keys. Thus, a trusted third party is the most common way to assure binding a public–private key pair to the identity of the owner, where the word trusted differs from a public key scheme to another. In Public Key Infrastructure, the Certification Authority is trusted for not forging users’ certificates. In Identity-Based Public Key Cryptography, the Private Key Generator is trusted for not decrypting entities’ ciphertext, let alone forging their signatures. Similarly, in Certificateless Public Key Cryptography, the Key Generator Center (KGC) is trusted for not replacing entities’ public keys. In this paper, we propose an aggregation of several Certificateless Public Key systems in a 5G multi-domain/multi-tenant environment to merge them into a virtual cryptosystem without requiring any sort of trustiness in KGCs. The only assumption is that KGCs do not collude through sharing their secret keys. We have put this new cryptosystem into concrete encryption, signature, and authenticated key agreement schemes, and proved their security against a new adversarial model based on new underlying computational and bilinear hardness assumptions about Diffie–Hellman problem in the random oracle model. We believe that this new cryptosystem enables and ensures a secure management of multi-domain/multi-tenant 5G E2E services, even if at most (n-1) KGCs do collude.}
}


@article{DBLP:journals/cn/AranaBGL21,
	author = {Oscar Arana and
                  H{\'{e}}ctor Ben{\'{\i}}tez{-}P{\'{e}}rez and
                  Javier Gomez and
                  Miguel L{\'{o}}pez{-}Guerrero},
	title = {Never Query Alone: {A} distributed strategy to protect Internet users
                  from {DNS} fingerprinting attacks},
	journal = {Comput. Networks},
	volume = {199},
	pages = {108445},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108445},
	doi = {10.1016/J.COMNET.2021.108445},
	timestamp = {Sun, 06 Oct 2024 21:22:02 +0200},
	biburl = {https://dblp.org/rec/journals/cn/AranaBGL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Domain Name System (DNS) plays an essential role in everyday Internet activities. However, unauthorized access to DNS-generated traffic also poses some serious privacy concerns. For instance, DNS traffic traces can be processed by third parties to identify an Internet user by means of behavioral analysis (i.e., a technique that employs machine learning classifiers to link multiple pieces of traffic belonging to the same person). In general, the more sessions an attacker can link, the more he or she will learn about the interests of an individual, and the more likely that the identity of this user will be revealed. The development of such methods of user identification has been the focus of several pieces of research, and currently, there are several strategies to obtain behavioral fingerprints from DNS traces. However, only a few works have proposed countermeasures to protect users against this privacy threat on the Internet. Furthermore, new technologies such as DNS-over-TLS, DNS-over-HTTPS, or DNS over QUIC can potentially render available countermeasures ineffective. This paper proposes Never Query Alone (NQA), a strategy that allows a set of nodes to modify their DNS query patterns to mitigate the risk of being tracked by DNS resolvers. In NQA, users forward their DNS queries through their neighbors in such a way that the identification accuracy achieved by the attackers is proportionally reduced as the number of participant nodes is increased. A second strategy, called NQA-SA, is also proposed. NQA-SA decreases the accuracy of the attackers to nearly 1 %, independently of the number of participant nodes. Both proposed countermeasures reduce the accuracy of the classifiers at the cost of increasing the delay of the DNS query resolution process. Thus, a trade-off between privacy and delay arises, which is theoretically studied in this work by means of queueing analysis. Experimental results with real networks demonstrate that the proposed countermeasures can significantly degrade the accuracy of commonly used machine learning classifiers, thus increasing the privacy protection of individuals on the Internet.}
}


@article{DBLP:journals/cn/SharaffKPBKH21,
	author = {Aakanksha Sharaff and
                  Chandramani Kamal and
                  Siddhartha Porwal and
                  Surbhi Bhatia and
                  Kuljeet Kaur and
                  Mohammad Mehedi Hassan},
	title = {Spam message detection using Danger theory and Krill herd optimization},
	journal = {Comput. Networks},
	volume = {199},
	pages = {108453},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108453},
	doi = {10.1016/J.COMNET.2021.108453},
	timestamp = {Sun, 04 Aug 2024 19:48:54 +0200},
	biburl = {https://dblp.org/rec/journals/cn/SharaffKPBKH21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Due to proliferation of online posts and rise in the active social media users, fraudulent activities related with spam messages have taken a spike drift. Spam is an activity by which hackers use electronic messaging system to unsolicited messages in mass content to unknown users. It can be also taken as one of the major attraction of attackers in the form of short message service (SMS) messages. Spam messages can be categorized in different categories such as business opportunity spam, trending topic spam, banking services spam etc. These problems can be tackled by confirming to the actions taken by users towards these messages. There is an urgent explicit need of practical medium in order to assist the users against these spam messages. This paper proposes a novel SMS spam filtering model based on Danger theory of Artificial Immune System (AIS). Several feature extraction and selection techniques have been applied for optimizing the algorithm and claiming an admissible accuracy. This paper uses a biologically inspired algorithm named Krill herd Optimization (KHO) for the task of feature selection and various optimization functions like Quing function, Sumsquare function, Levy function etc. are applied for enhancing its performance. The Dendritic Cell Algorithm (DCA) is also incorporated with KHA as an added advantage towards achieving efficiency. Comparative results between Dendritic Cell Algorithm (DCA) with KHA and other spam filtering models have been shown in comparison with several state-of-the-art machine learning classifiers. The algorithms have been experimented by using varied optimization functions illustrated using visualization tools and results have been validated in the paper. The obtained results demonstrate an admissible accuracy of 96% that is calculated using different information retrieval metrics using recall, F-measure and precision.}
}


@article{DBLP:journals/cn/SheshjavaniKSM21,
	author = {Abdollah Ghaffari Sheshjavani and
                  Ahmad Khonsari and
                  Seyed Pooya Shariatpanahi and
                  Masoumeh Moradian},
	title = {Content caching for shared medium networks under heterogeneous users'
                  behaviors},
	journal = {Comput. Networks},
	volume = {199},
	pages = {108454},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108454},
	doi = {10.1016/J.COMNET.2021.108454},
	timestamp = {Wed, 07 Dec 2022 23:01:41 +0100},
	biburl = {https://dblp.org/rec/journals/cn/SheshjavaniKSM21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Content caching is a widely studied technique aimed to reduce the network load imposed by data transmission during peak time while ensuring users’ quality of experience. It has been shown that when there is a common link between caches and the server, delivering contents via the coded caching scheme can significantly improve performance over conventional caching. However, finding the optimal content placement is a challenge in the case of heterogeneous users’ behaviors. In this paper we consider heterogeneous number of demands and non-uniform content popularity distribution in the case of homogeneous and heterogeneous user-preferences. We propose a hybrid coded–uncoded caching scheme to trade-off between popularity and diversity. We derive explicit closed-form expressions of the server load for the proposed hybrid scheme and formulate the corresponding optimization problem. Results show that the proposed hybrid caching scheme can reduce the server load significantly and outperforms the baseline pure coded and pure uncoded schemes and previous works in the literature for both homogeneous and heterogeneous user preferences.}
}


@article{DBLP:journals/cn/LiaoWZJ21,
	author = {Xuening Liao and
                  Zhenqiang Wu and
                  Yuanyu Zhang and
                  Xiaohong Jiang},
	title = {Trust-aware buffer-aided relay selection for secure communications
                  in cooperative wireless systems},
	journal = {Comput. Networks},
	volume = {199},
	pages = {108456},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108456},
	doi = {10.1016/J.COMNET.2021.108456},
	timestamp = {Wed, 03 Nov 2021 08:26:11 +0100},
	biburl = {https://dblp.org/rec/journals/cn/LiaoWZJ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cooperative wireless networks have been facing security challenges due to the inherent openness of wireless channels. Previous studies on the physical layer security (PLS) of cooperative networks mainly focus on scenarios with only trusted relays. In practice, however, untrusted relays may exist in the network and such relays may refuse to cooperate or even work as a helper of an eavesdropper for packets eavesdropping/interception. To address this issue, we consider in this paper a cooperative wireless network with untrusted relays and a passive eavesdropper attempting to wiretap packets transmitted in the network. To select a secure and trusted relay, we first propose two buffer-aided relay selection schemes, one for perfect eavesdropper channel state information (CSI) case and another for no eavesdropper CSI case. We then conduct theoretical analysis to derive the models for the performance metrics of secrecy outage probability (SOP) and expected queuing delay. Finally, simulation and numerical results are provided for the validation of our theoretical models. The results indicate that our proposed schemes can outperform the typical max-ratio scheme under perfect eavesdropper CSI case and can outperform the max-link and the max-max relay selection schemes under no eavesdropper CSI case in terms of the SOP and expected queuing delay.}
}


@article{DBLP:journals/cn/SadriA21,
	author = {Mohammad Javad Sadri and
                  Maryam Rajabzadeh Asaar},
	title = {An anonymous two-factor authentication protocol for IoT-based applications},
	journal = {Comput. Networks},
	volume = {199},
	pages = {108460},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108460},
	doi = {10.1016/J.COMNET.2021.108460},
	timestamp = {Fri, 22 Oct 2021 09:37:49 +0200},
	biburl = {https://dblp.org/rec/journals/cn/SadriA21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Internet of things (IoT) allows people to establish a real-time connection with physical objects. To fulfill this lifelong ambition, the infrastructure of Wireless Sensor Networks (WSNs) plays a pivotal role. However, the public channel that is used by the sensors and users can imperil the security of their connection. Accordingly, many authentication protocol have been proposed to preserve the integrity and confidentiality of the transmitted messages. In this paper, we examine Wu et al.’s protocol as one of the most state-of-the-art protocols and prove that it is susceptible to sensor capture attack, user trace attack, and DoS attack, also it cannot provide forward secrecy. To mitigate these weaknesses, we propose our protocol and analyze that with both formal and informal methods to show that it is secure against various known attacks such as sensor and user trace, sensor capture, offline password guessing, and replay attacks. Finally, we evaluate our protocol in terms of security features and communication and computation costs. The results show that our protocol not only is more secure than other existing protocols but also reduces 62.1% of the computation cost and 30.76% of the communication cost in comparison with the costs of Wu et al.’s protocol.}
}


@article{DBLP:journals/cn/VemireddyR21,
	author = {Satish Vemireddy and
                  Rashmi Ranjan Rout},
	title = {Fuzzy Reinforcement Learning for energy efficient task offloading
                  in Vehicular Fog Computing},
	journal = {Comput. Networks},
	volume = {199},
	pages = {108463},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108463},
	doi = {10.1016/J.COMNET.2021.108463},
	timestamp = {Wed, 03 Nov 2021 08:26:11 +0100},
	biburl = {https://dblp.org/rec/journals/cn/VemireddyR21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Vehicular Fog Computing (VFC) has been envisioned as a potential fog computing paradigm which aims to offload delay sensitive tasks to mobile fog vehicles instead of remote cloud in order to facilitate computational demands of smart villages close to rural highways. There exists challenges related to task offloading in VFC that need to be addressed. Most often, Road Side Units (RSUs) deployed along rural highways are energy constrained and they need to provide energy efficient scheduling services for the allocation of tasks to fog vehicles. On the other hand, energy consumption optimization is challenging, since scheduling decision of local processing of tasks incur computation cost while the allocation of tasks to fog vehicles incurs communication cost. Although the task offloading to VFC reduces response latency, it leads to higher RSU energy consumption contributed by the communication of task data to fog vehicles. Therefore, this paper presents an energy efficient vehicle scheduling problem for offloading of tasks to mobile fog nodes subject to satisfy constraints of task deadline and resource availability. To resolve high dimensionality issue caused by increased number of vehicles in RSU coverage, we propose an on-policy reinforcement leaning based scheduling algorithm combined with fuzzy logic based greedy heuristic, named as Fuzzy Reinforcement Learning (FRL). This greedy heuristic not only accelerates learning process, but also improves long term reward when compared to Q-learning algorithm. Extensive experiments have been performed to evaluate the proposed algorithm and the simulation results show that the proposed FRL algorithm outperforms other scheduling algorithms such as First Come First Serve (FCFS), Rate Monotonic Scheduling (RMS), Fuzzy and Distributed Task Allocation with Distributed Process (DTA_DP).}
}


@article{DBLP:journals/cn/AmanlouHB21,
	author = {Sanaz Amanlou and
                  Mohammad Kamrul Hasan and
                  Khairul Azmi Abu Bakar},
	title = {Lightweight and secure authentication scheme for IoT network based
                  on publish-subscribe fog computing model},
	journal = {Comput. Networks},
	volume = {199},
	pages = {108465},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108465},
	doi = {10.1016/J.COMNET.2021.108465},
	timestamp = {Wed, 03 Nov 2021 08:26:12 +0100},
	biburl = {https://dblp.org/rec/journals/cn/AmanlouHB21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Internet of Things (IoT) has converged with Cloud computing to provide comprehensive services to users in different places. However, with the exponential growth of smart devices connected to the Internet, Cloud computing has severe challenges, especially for applications that require low-latency and real-time processing. Therefore, the Fog computing paradigm emerged that is more compatible with the IoT, in which events are processed near where they occurred for practical and quick response time. Authentication is an essential issue for fog computing security since fog gateways and IoT devices are subject to many attacks. The main problem to provide authentication between IoT devices is that they have limited resources and computational processing. On the one hand, certificate-based authentication algorithms are secure, but they are heavy for IoT devices. On the other hand, Pre-shared authentication algorithms such as PSK are suitable for low-resource devices, but are not widely used due to their low security. Therefore, this paper proposes to use the Elliptic Curve Diffie–Hellman Ephemeral (ECDHE) key exchange algorithm along with the Pre-Shared Key (PSK) as a lightweight and secure authentication scheme between the fog gateway and IoT device based on the Message Queuing Telemetry Transport (MQTT) publish–subscribe protocol in a distributed fog computing architecture. The proposed ECDHE-PSK authentication scheme uses Ephemeral Pre-shared key instead of heavy certificates that is very lightweight and also provides Perfect Forward Secrecy (PFS) feature to enhance security in comparison with the static PSK algorithm. To evaluate the resource consumption and security resistance of the proposed scheme it was implemented on the real test environment and then was compared with two state-of-the-art certificate-based authentication schemes and a static PSK-based scheme. The comprehensive performance and security evaluations showed that in the distributed publish–subscribe fog computing architecture the proposed ECDHE-PSK is almost as light as the PSK algorithm while has all security features of certificate-based algorithms.}
}


@article{DBLP:journals/cn/LiuWRXYW21,
	author = {Juncai Liu and
                  Jessie Hui Wang and
                  Chenghao Rong and
                  Yuedong Xu and
                  Tao Yu and
                  Jilong Wang},
	title = {FedPA: An adaptively partial model aggregation strategy in Federated
                  Learning},
	journal = {Comput. Networks},
	volume = {199},
	pages = {108468},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108468},
	doi = {10.1016/J.COMNET.2021.108468},
	timestamp = {Wed, 03 Nov 2021 08:26:11 +0100},
	biburl = {https://dblp.org/rec/journals/cn/LiuWRXYW21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated Learning has sparked increasing interest as a promising approach to utilize large amounts of data stored on network edge devices. Federated Averaging is the most widely accepted Federated Learning framework. In Federated Averaging, the server keeps waiting for client models to compute the global model in each round unless all client models are received or a pre-configured timer expires, therefore it suffers seriously from participant devices with weak computation and/or communication capability, which is a kind of straggler problem. In this paper we design FedPA, a framework based on partial model aggregation strategy, in which the server waits for only an appropriate number of device models (referred to as aggregation number) in each round. Our experiment shows that the accuracy loss of the aggregated global model in a single round is not significant if the aggregation number is decided carefully. We propose a waiting strategy to determine the aggregation number for each round dynamically and the aggregation number is adaptive to achieve a tradeoff between single-round training time and the expected number of rounds to reach the target accuracy. Stale models are also included during aggregation when they arrive, and their positive value and negative effect are carefully evaluated and reflected in the aggregation strategy. Experiments show that FedPA outperforms the baseline strategy FedAvg and other three algorithms named FedAsync, FLANP and AD-SG. It can work well in all scenarios with different distributions of data samples (characterized by non-IID ratio) and computation/communication capability (characterized by level of heterogeneity) among devices. Experiments also show that FedPA is robust when a certain amount of noise is added into the input from clients for privacy concerns.}
}


@article{DBLP:journals/cn/VelascoMO21,
	author = {Francisco Alcaraz Velasco and
                  Jos{\'{e}} Manuel Palomares Mu{\~{n}}oz and
                  Joaqu{\'{\i}}n Olivares},
	title = {Lightweight method of shuffling overlapped data-blocks for data integrity
                  and security in WSNs},
	journal = {Comput. Networks},
	volume = {199},
	pages = {108470},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108470},
	doi = {10.1016/J.COMNET.2021.108470},
	timestamp = {Tue, 16 Aug 2022 23:06:46 +0200},
	biburl = {https://dblp.org/rec/journals/cn/VelascoMO21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Wireless Sensor Networks (WSN) consist of devices with limited resources to explore and sense the environment in a cooperative way. Security, mainly in terms of guaranteeing the data integrity, is a primary issue for many applications, but with an extra energy cost. Thus, trade-off is required between security level and energy consumption in real applications. First of all, a brief survey about security methods, focusing in data integrity, in WSN is implemented. The objective of this paper is to propose a new data integrity method with medium security levels and low energy cost. Therefore, we propose a new and lightweight mechanism for data integrity with overlapping blocks in WSNs. Hence, an attacker will spend much time and effort to interpret and alter the packets. The experiments were performed using TinyOS 2.1 operating system and TelosB nodes for measuring the overhead in terms of energy consumption, memory, and packet size. Moreover, the receiver is able to detect tampering packets and request those retransmission data. An attacker would require huge amounts of memory and processing time to extract the original information, even for small-sized data blocks. Thus, this fact makes this approach a simple, yet effective, mechanism to protect data whilst enhancing the data integrity.}
}


@article{DBLP:journals/cn/ChengWEYLLG21,
	author = {Jin Cheng and
                  Yulei Wu and
                  Yuepeng E and
                  Junling You and
                  Tong Li and
                  Hui Li and
                  Jingguo Ge},
	title = {{MATEC:} {A} lightweight neural network for online encrypted traffic
                  classification},
	journal = {Comput. Networks},
	volume = {199},
	pages = {108472},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108472},
	doi = {10.1016/J.COMNET.2021.108472},
	timestamp = {Tue, 31 Oct 2023 15:43:37 +0100},
	biburl = {https://dblp.org/rec/journals/cn/ChengWEYLLG21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Increased awareness of privacy protection has led to a surge in the volume of encrypted traffic, which creates a heavy burden for efficient network management (e.g. quality-of-service guarantees). The opacity of encrypted traffic essentially requires high computational overheads to make traffic classification, which is even worse when encrypted traffic surges. However, existing deep learning approaches sacrifice the efficiency to obtain high-precision classification results, which are no longer suitable for scenarios with large volumes of encrypted traffic. In this paper, a lightweight and online approach implemented as MATEC is proposed. The way we optimize the classification process follows the “Maximizing the reuse of thin modules” design principle. The multi-head attention and the convolutional network are adopted in the thin module. Attributed to the one-step interaction of all packets and the parallel computing of the multi-head attention mechanism, a key advantage of our model is that the number of parameters and running time are significantly reduced. In addition, the effectiveness and efficiency of convolutional networks have been proved in traffic classification. Comparisons to the existing state-of-the-art models on three typical datasets demonstrate that the proposed MATEC model has higher accuracy and running efficiency. In addition, the number of parameters is reduced to 1.8% of the state-of-the-art models and the training time halves.}
}


@article{DBLP:journals/cn/AraujoSM21,
	author = {Samuel Moreira Abreu Ara{\'{u}}jo and
                  Fernanda Sumika Hojo de Souza and
                  Geraldo R. Mateus},
	title = {A hybrid optimization-Machine Learning approach for the {VNF} placement
                  and chaining problem},
	journal = {Comput. Networks},
	volume = {199},
	pages = {108474},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108474},
	doi = {10.1016/J.COMNET.2021.108474},
	timestamp = {Fri, 21 Jan 2022 22:00:27 +0100},
	biburl = {https://dblp.org/rec/journals/cn/AraujoSM21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Virtual Network Function Placement and Chaining Problem focuses on allocation of customers demand’s on the Substrate Network. Among other factors, an optimal allocation of resources is hampered by nature of the online problem and by its complexity. Since we are dealing with an NP-hard combinatorial problem, while the number of network components grows linearly, the computational processing and runtime increase exponentially. Therefore, an application of Machine Learning techniques to reduce the number of components present in the SN is proposed in this work. In particular, we have developed clustering techniques that aim to find groups of promising components to map customer demands and disregard those that are less promising. Two different clustering models are proposed: (i) based on the Spatial Location of the SN components; and (ii) based on SN’s historical resource consumption data. An Integer Linear Programming model is proposed to evaluate the different simulation scenarios. Both approaches reduced the execution time (\n≈\n75\n%\n) and the end-to-end delay of virtual requests, in addition to keeping the acceptance rate and profit stable compared to the exact approach.}
}


@article{DBLP:journals/cn/MallAOH21,
	author = {Priyanka Mall and
                  Ruhul Amin and
                  Mohammad S. Obaidat and
                  Kuei{-}Fang Hsiao},
	title = {CoMSeC++: PUF-based secured light-weight mutual authentication protocol
                  for Drone-enabled {WSN}},
	journal = {Comput. Networks},
	volume = {199},
	pages = {108476},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108476},
	doi = {10.1016/J.COMNET.2021.108476},
	timestamp = {Thu, 25 Apr 2024 15:20:54 +0200},
	biburl = {https://dblp.org/rec/journals/cn/MallAOH21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {An unattended environment like a disputed area, a battlefield, or a dense forest area is an environment that is completely inaccessible. Hence, certain kinds of activities that may occur in such an environment would be difficult to notice, which actually is required to be known. Therefore, sensors could be mounted in those places so that the essential data could be gathered. In this paper, we are considering an unattended environment with sensors mounted at certain spots from which the data could be collected through mobile device which actually is an Unmanned Aerial Vehicle (UAV) or say, Drone. We have first designed a suitable architecture for the same and designed a light-weight protocol to establish a secure communication among devices and the cloud via the relocatable drone. Our protocol also utilizes the benefits of Physically Unclonable Function (PUF) to generate, which is used to encrypt the message in communication. The well-popular Scyther simulator has been used to simulate the protocol and the results shows that the protocol is completely protected against leakage of private information. Considering the hardness problem of hash function and PUF, the informal analysis also confirms the high-level security protection against known attacks. The protocol is not only better in terms of security strength, but it also achieves better performance when compared to existing competitive works.}
}


@article{DBLP:journals/cn/SamailaLASSFI21,
	author = {Musa G. Samaila and
                  Carolina Galv{\~{a}}o Lopes and
                  {\'{E}}di Aires and
                  Jo{\~{a}}o B. F. Sequeiros and
                  Tiago M. C. Sim{\~{o}}es and
                  M{\'{a}}rio M. Freire and
                  Pedro R. M. In{\'{a}}cio},
	title = {Performance evaluation of the {SRE} and {SBPG} components of the IoT
                  hardware platform security advisor framework},
	journal = {Comput. Networks},
	volume = {199},
	pages = {108496},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108496},
	doi = {10.1016/J.COMNET.2021.108496},
	timestamp = {Mon, 28 Aug 2023 21:39:19 +0200},
	biburl = {https://dblp.org/rec/journals/cn/SamailaLASSFI21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The applications of Internet of Things (IoT) and associated technologies have been spreading rapidly across a wide range of domains, including environmental monitoring, home automation, and supply chain, having a significant bearing on the social and economic well-being of humans as well as enhancing environmental sustainability. In recent years, however, there have been several data breaches and other security and privacy incidents involving IoT devices, which have attracted significant attention from the research community in both academia and industry. This has resulted in a surge of proposals put forward by many researchers, including IoT blockchain-based security solutions, IoT intrusion detection systems, IoT authentication systems, and IoT security analytics. While these proposals are aimed at addressing various IoT security and privacy-related issues, many of these solutions arguably seem not to focus on helping designers and developers with little or no security expertise in start-up companies to produce secure IoT systems. To this end, the IoT Hardware Platform Security Advisor (IoT-HarPSecA) framework was proposed to foster the design and implementation of secure IoT systems. In this paper, we present the performance and usability evaluation of the Security Requirements Elicitation (SRE) and Security Best Practice Guidelines (SBPG) component tools of IoT-HarPSecA, which are two of the three component tools of the security framework. Results show that the two components of the IoT-HarPSecA framework can facilitate the development of secure IoT systems and that the SRE and SBPG tools are easy to use.}
}
