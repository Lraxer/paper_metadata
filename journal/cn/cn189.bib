@article{DBLP:journals/cn/FarrokhiFRM21,
	author = {Alireza Farrokhi and
                  Reza Farahbakhsh and
                  Javad Rezazadeh and
                  Roberto Minerva},
	title = {Application of Internet of Things and artificial intelligence for
                  smart fitness: {A} survey},
	journal = {Comput. Networks},
	volume = {189},
	pages = {107859},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.107859},
	doi = {10.1016/J.COMNET.2021.107859},
	timestamp = {Thu, 29 Apr 2021 15:13:00 +0200},
	biburl = {https://dblp.org/rec/journals/cn/FarrokhiFRM21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The revolution of Internet of Things (IoT) is pervading many facets of our everyday life. Among the multiple IoT application domains, well-being is becoming one of the popular scenarios in IoT which aims to offer new services including smart fitness. This paper focuses on smart fitness covering IoT-based solutions for this domain as well as the impacts of artificial intelligence and social-IoT. IoT-based smart fitness is divided into three categories: Fitness trackers (including wearable and non-wearable sensors), movement analysis and fitness applications. Data collected from IoT-based smart fitness and users could be used for enhancing training performance by Artificial Intelligence (AI)-based algorithms. Sensor to sensor relationship is another notable topic which can be implemented by social-IoT that can share data, information and experiences of users’ training from different places and times. In this his study a comprehensive review on different types of fitness trackers and fitness applications in provided and followed by a review of AI algorithms used in smart fitness scenarios. Lastly detail discussions on the benefits and the potential problems of smart fitness are presented and a shortlist of existing gaps and potential future work have been identified and proposed.}
}


@article{DBLP:journals/cn/0002HZY021,
	author = {Jie Lin and
                  Lin Huang and
                  Hanlin Zhang and
                  Xinyu Yang and
                  Peng Zhao},
	title = {A novel Latency-Guaranteed based Resource Double Auction for market-oriented
                  edge computing},
	journal = {Comput. Networks},
	volume = {189},
	pages = {107873},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.107873},
	doi = {10.1016/J.COMNET.2021.107873},
	timestamp = {Tue, 14 Jan 2025 08:46:29 +0100},
	biburl = {https://dblp.org/rec/journals/cn/0002HZY021.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Edge computing, taking of distributed architecture and edge-servers being close to end-devices, has been widely attended to provide extra computation resources to assist smart end-devices in completing computation tasks with low latency. Although considerable efforts on resource allocation have been developed to reduce energy consumption and computation latency in edge computing, the profits of edge-servers in market-oriented edge computing have not been investigated. In addition, few efforts considered the combination of multiple constraints (such as bandwidth, latency, etc.) in resource auctions for the edge-servers with limited communication and computation resources. To this end, in this paper we propose a novel Latency-Guaranteed based Resource Double Auction (LGRDA) scheme for the market-oriented edge computing system with resource-constrained edge-servers existed. The proposed scheme can maximize the profits of edge-servers and achieve the great efficiency of resources utilization, as well as guarantee acceptable latency for computation tasks of end-devices. Particularly, LGRDA conducts a resource-task matching model to match the limited communication and computation resources of edge-servers to computation tasks of end-devices with considering the combination of multiple constraints, such as bandwidth, latency, etc. To determine the effective resource-task pairs from all available matches with objective of achieving maximum profits for edge-servers, a multi-users double auction mechanism is proposed to determine the effective matches (also namely winning resource-task pairs) through bidding. Via analysis and simulation experiments, our data show that LGRDA can achieve individual rationality, budget balance and truthfulness in auctions. Additionally, our data also demonstrate that our LGRDA can significantly increase the system efficiency of market-oriented edge computing in terms of resource utilization rate and average profits for edge-servers, as well as the number of winning matches, in comparison with existing schemes.}
}


@article{DBLP:journals/cn/HuangZ021,
	author = {Xiaohong Huang and
                  Man Zeng and
                  Kun Xie},
	title = {Intelligent traffic control for QoS optimization in hybrid SDNs},
	journal = {Comput. Networks},
	volume = {189},
	pages = {107877},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.107877},
	doi = {10.1016/J.COMNET.2021.107877},
	timestamp = {Thu, 29 Apr 2021 15:12:59 +0200},
	biburl = {https://dblp.org/rec/journals/cn/HuangZ021.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Software Defined Networking (SDN) provides a flexible way to control traffic in networks and it is seen a rapid increase among network operators in adoption of SDN. However, due to some policy and economic issues, the coexistence of SDN-enabled devices and legacy devices will continue for a long time. This hybrid scenery comes with many challenges that do not exist in pure SDN. How to find an efficient and suitable routing policy in a hybrid SDN is essential for promoting the development of SDN. In this paper, we propose a near-optimal traffic control method for QoS optimization in a hybrid SDN. First, an SDN migration sequence is explored to maximize controllable traffic to improve the effects of optimization. Then, a Deep Reinforcement Learning (DRL) algorithm is used to address the multi-splittable routing problem in the hybrid SDN. The flow split ratio strategy is implemented by setting the OpenFlow group bucket constraints. Finally, we evaluate the proposed method with open-source traffic datasets. The simulation results show that the method of this paper can achieve a significant improvement in optimizing network QoS performance such as delay, jitter, and link utilization.}
}


@article{DBLP:journals/cn/FawazHLK21,
	author = {Hassan Fawaz and
                  Melhem El Helou and
                  Samer Lahoud and
                  Kinda Khawam},
	title = {A reinforcement learning approach to queue-aware scheduling in full-duplex
                  wireless networks},
	journal = {Comput. Networks},
	volume = {189},
	pages = {107893},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.107893},
	doi = {10.1016/J.COMNET.2021.107893},
	timestamp = {Sat, 30 Sep 2023 10:07:02 +0200},
	biburl = {https://dblp.org/rec/journals/cn/FawazHLK21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Full-duplex communications promise to double the throughput of a wireless network, so long as the resulting interferences can be combated. Nonetheless, already dealing with the intricacy of determining base station-to-user radio channels, full duplex wireless networks need additional information on the channels in between all the user equipment. This information is necessary to determine user radio conditions, and thereafter efficiently allocate resources. A signaling overhead is likely to burden the user equipment, which already lack any methods to estimate and convey such user-to-user channel states. In this paper, we aim to circumvent the complexities and requirements of traditional scheduling techniques by introducing a reinforcement learning based scheduling algorithm for full-duplex wireless networks. This scheduling approach does not need to estimate user-to-user channels, and rather learns how to best allocate the network’s radio resources. We show that our proposal can match scheduling with complete channel state information in terms of user equipment throughput, and that it performs well under multiple testing scheduling scenarios: increased user equipment numbers, randomized user equipment demand, and user equipment clustering among others.}
}


@article{DBLP:journals/cn/WuCCCC21,
	author = {Libing Wu and
                  Shuqin Cao and
                  Yanjiao Chen and
                  Jianqun Cui and
                  Yanan Chang},
	title = {An adaptive multiple spray-and-wait routing algorithm based on social
                  circles in delay tolerant networks},
	journal = {Comput. Networks},
	volume = {189},
	pages = {107901},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.107901},
	doi = {10.1016/J.COMNET.2021.107901},
	timestamp = {Thu, 29 Apr 2021 15:13:00 +0200},
	biburl = {https://dblp.org/rec/journals/cn/WuCCCC21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In delay tolerant networks (DTN), the social attributes of nodes show long-term stability, which can be leveraged for more effective routing. In this paper, we first present a novel way of constructing social circles based on the node clustering phenomena in DTN. Then, considering that the forwarding capability of nodes is significantly different, we propose a spray strategy based on social circles (named SC-SS) to improve the spray-and-wait routing algorithm. SC-SS selects the next hop based on the social circle of nodes in the spray phase. Instead of fixing the initial number of copies, we design an adaptive multiple spray-and-wait routing algorithm based on social circles (named SC-AMSW) to further improve the performance of SC-SS. SC-AMSW selectively sprays messages multiple times in the wait phase and determines an appropriate number of redundant message copies based on delivery predictability. We conduct extensive simulations to confirm the effectiveness of our proposed routing algorithms in DTN.}
}


@article{DBLP:journals/cn/RahdariMKV21,
	author = {Farhad Rahdari and
                  Naser Movahhedinia and
                  Mohammad Reza Khayyambashi and
                  Shahrokh Valaee},
	title = {QoE-aware power control and user grouping in Cognitive Radio {OFDM-NOMA}
                  systems},
	journal = {Comput. Networks},
	volume = {189},
	pages = {107906},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.107906},
	doi = {10.1016/J.COMNET.2021.107906},
	timestamp = {Sat, 30 Sep 2023 10:07:04 +0200},
	biburl = {https://dblp.org/rec/journals/cn/RahdariMKV21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As a dramatic advancement in mobile communications, 5G has put together several state of the art technologies including Cognitive Radio (CR) and Quality-of-Experience (QoE). While CR is to overcome frequency scarcity, how to maintain QoE for all the connected users is one of the paramount issues in such integration, especially for multimedia communications. As a key technology for 5G, Non-Orthogonal-Multiple Access (NOMA) is combined with Orthogonal Frequency Division Multiplexing (OFDM) to improve the spectral efficiency. In this paper, the QoE requirements for typical applications in a CR platform are characterized, based on which a method for user grouping and power management in an OFDM–NOMA system is proposed. The performance of the proposed method is analyzed and evaluated by simulating a typical network. The evaluations show noticeable improvement in transmit power reduction while the requested users’ perception levels are maintained.}
}


@article{DBLP:journals/cn/ZakariyaRZ21,
	author = {Ahmed Y. Zakariya and
                  Sherif I. Rabia and
                  Waheed K. Zahra},
	title = {Optimal decision making in multi-channel RF-powered cognitive radio
                  networks with ambient backscatter capability},
	journal = {Comput. Networks},
	volume = {189},
	pages = {107907},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.107907},
	doi = {10.1016/J.COMNET.2021.107907},
	timestamp = {Wed, 19 May 2021 08:29:48 +0200},
	biburl = {https://dblp.org/rec/journals/cn/ZakariyaRZ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In RF-powered backscatter cognitive radio networks, the secondary user transmits his data either by harvesting energy then actively transmitting the data or by backscattering. However, it is challenging for the secondary user to determine the optimal licensed channel to select and the optimal action to do under the uncertainty of the state of the licensed channels and the dynamic behavior of the primary users. In this paper, we formulate the decision problem as a Markov decision process to obtain the optimal channel-action pair for the secondary user that maximizes his average throughput over the long run. In the proposed model, an incomplete information case is assumed where the secondary user does not know the actual state of the licensed channels. Moreover, sensing errors of missed detection and false alarm are considered and a general batch arrival stream is assumed. Numerical results show the superiority of the proposed optimal hybrid mode compared to the harvest-then-transmit mode in terms of both the average throughput and blocking probability, especially in the case of heavy primary user loads.}
}


@article{DBLP:journals/cn/0002TVK21,
	author = {Andrea Morichetta and
                  Martino Trevisan and
                  Luca Vassio and
                  Julia Krickl},
	title = {Understanding web pornography usage from traffic analysis},
	journal = {Comput. Networks},
	volume = {189},
	pages = {107909},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.107909},
	doi = {10.1016/J.COMNET.2021.107909},
	timestamp = {Mon, 03 Jan 2022 22:01:35 +0100},
	biburl = {https://dblp.org/rec/journals/cn/0002TVK21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Pornography is massively available on the Internet, often free of charge. It represents a significant fraction of the overall Internet traffic, with thousands of websites and millions of users. Studying web pornography consumption is useful to understand human behavior, and it is crucial for different disciplines, helping in sociological, statistical and behavioral research. However, given the lack of public datasets, most of the works build on surveys, limited by multiple factors, e.g., unreliable answers that volunteers may (even unconsciously) give. In this work, we analyze anonymized accesses to pornography websites using HTTP-level traces collected from an operational network. Our dataset includes anonymized traffic from about\n15\n000\nbroadband subscribers over three years. We use it to provide quantitative figures on pornographic website consumption, focusing on time and frequency of use, habits, and trends. We also compare web pornography users’ interests with those who do not consume web pornography, showing notable differences.}
}


@article{DBLP:journals/cn/AhmedSL21,
	author = {Usman Ahmed and
                  Gautam Srivastava and
                  Jerry Chun{-}Wei Lin},
	title = {A Machine Learning Model for Data Sanitization},
	journal = {Comput. Networks},
	volume = {189},
	pages = {107914},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.107914},
	doi = {10.1016/J.COMNET.2021.107914},
	timestamp = {Thu, 05 Jan 2023 14:06:40 +0100},
	biburl = {https://dblp.org/rec/journals/cn/AhmedSL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Discovering important knowledge that may be available from databases while preserving the privacy of sensitive information can be considered a hot research subject of data mining in recent times. With the establishment of strong Internet of Things (IoT) networks globally, several data-intensive applications will be developed. Privacy of information over the network is increasingly relevant, and as edge computing has grown more important, applications running over networks require protection. The privacy of information while utilizing data is a trade-off that needs to be addressed. In the past, many heuristics and meta heuristics-based approaches were revealed to sensitize sensitive information in privacy-preserving data mining (PPDM). They perturb the original database to hide sensitive information using addition or deletion operations. This is a known NP-hard problem. In this paper, we propose data privacy of IoT connected devices over heterogeneous networks. A deep re-enforcement learning-based technique is applied to sensitize sensitive information from a given database while keeping the balance between privacy protection and knowledge discovery during the sanitization process. Furthermore, minimizing known side effects that can be caused in the sanitization process is also be considered. Substantial experiments are conducted on both synthetic and real-world datasets. Results are evaluated based on sanitization side effects which include failing to hide sensitive items as well as choosing not to hide sensitive items. The proposed approach shows significant performance improvement compared to meta-heuristics (Genetic Algorithm, Particle Swarm Optimization) and heuristics (Greedy) approaches by our evaluation.}
}


@article{DBLP:journals/cn/ChuprikovDKN021,
	author = {Pavel Chuprikov and
                  Alex Davydow and
                  Kirill Kogan and
                  Sergey I. Nikolenko and
                  Alexander Sirotkin},
	title = {Formalization and taxonomy of compute-aggregate problems for cloud
                  computing applications},
	journal = {Comput. Networks},
	volume = {189},
	pages = {107915},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.107915},
	doi = {10.1016/J.COMNET.2021.107915},
	timestamp = {Thu, 29 Apr 2021 15:13:00 +0200},
	biburl = {https://dblp.org/rec/journals/cn/ChuprikovDKN021.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Efficient representation of data aggregations is a fundamental problem in modern big data applications, where network topologies and deployed routing and transport mechanisms play a fundamental role in optimizing desired objectives such as cost, latency, and others. In traditional networking, applications use TCP and UDP transports as a primary interface for implemented applications that hide the underlying network topology from end systems. On the flip side, to exploit network infrastructure in a better way, applications restore characteristics of the underlying network. In this work, we demonstrate that both specified extreme cases can be inefficient to optimize given objectives. We study the design principles of routing and transport infrastructure and identify extra information that can be used to improve implementations of compute-aggregate tasks. We build a taxonomy of compute-aggregate services unifying aggregation design principles, propose algorithms for each class, analyze them theoretically, and support our results with an extensive experimental study.}
}


@article{DBLP:journals/cn/ZhongGYW21,
	author = {Shijie Zhong and
                  Songtao Guo and
                  Hongyan Yu and
                  Quyuan Wang},
	title = {Cooperative service caching and computation offloading in multi-access
                  edge computing},
	journal = {Comput. Networks},
	volume = {189},
	pages = {107916},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.107916},
	doi = {10.1016/J.COMNET.2021.107916},
	timestamp = {Thu, 23 Jun 2022 20:03:26 +0200},
	biburl = {https://dblp.org/rec/journals/cn/ZhongGYW21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Multi-access edge computing (MEC) as an emerging and promising paradigm can alleviate the physical resource bottlenecks for smart mobile devices, involving storage and processing capacities. In the MEC system, the traffic load and the quality of service (QoS) can be improved through service caching. However, due to the highly coupled relationship between service caching and offloading decisions, it is extremely challenging to flexibly configure edge service cache within limited edge storage capacity to improve system performance. In this paper, we aim to minimize the average task execution time in the edge system by considering the heterogeneity of task requests, the pre-storage of the application data, and the cooperation of the base stations. Firstly, we formulate the problem of joint computation offloading, service caching, and resource allocation as a Mixed Integer Non-Linear Programming (MINLP) problem, which is difficult to solve because of the coupling relationship between optimization variables. Then we solve the MINLP problem by the decomposition theory based on Generalized Benders Decomposition. Moreover, we develop an efficient algorithm of cooperative service caching and computation offloading, called GenCOSCO, to improve QoS while reducing computation complexity. In particular, for special cases when the service cache configuration is fixed, the FixSC algorithm is proposed to derive the offloading strategy by cache replacement. Finally, numerous simulation experiments indicate that our proposed scheme can significantly reduce the average time consumption of task execution.}
}


@article{DBLP:journals/cn/Baidas21,
	author = {Mohammed W. Baidas},
	title = {Resource allocation for offloading-efficiency maximization in clustered
                  NOMA-enabled mobile edge computing networks},
	journal = {Comput. Networks},
	volume = {189},
	pages = {107919},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.107919},
	doi = {10.1016/J.COMNET.2021.107919},
	timestamp = {Fri, 03 Dec 2021 17:20:27 +0100},
	biburl = {https://dblp.org/rec/journals/cn/Baidas21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, the problem of resource allocation for multi-carrier clustered non-orthogonal multiple-access (NOMA)-enabled mobile edge computing (MEC) networks is considered. In particular, the goal is to maximize the network sum-offloading-efficiency (SOE) via joint subcarrier assignment, power allocation, and computing resource allocation (J-SA-PA-CRA) for all user clusters, under the partial offloading mode, and subject to transmit power, delay and computing resource constraints. However, the formulated J-SA-PA-CRA problem is non-convex, and happens to be NP-hard, and thus is computationally-prohibitive. In turn, a low-complexity solution procedure is proposed, which decouples problem J-SA-PA-CRA into two subproblems: (1) J-PA-CRA per (user cluster, subcarrier) pair, and (2) one-to-one subcarrier assignment. The first subproblem is optimally solved via a successive convex approximation algorithm. As for the second subproblem, the polynomial-time complexity Kuhn–Munkres (KM) algorithm is proposed for optimal subcarrier assignment. Also, the stable marriage matching (SMM) algorithm is devised for a sub-optimal subcarrier assignment solution, but with less complexity than the KM algorithm. Extensive simulation results are provided to validate the proposed solution procedure, illustrating that the KM-based (SMM-based) solution procedure efficiently yields the optimal (a sub-optimal) network SOE, in comparison to the J-SA-PA-CRA scheme (solved via a global optimization package), while being superior to their OMA counterpart schemes (e.g. FDMA and TDMA).}
}


@article{DBLP:journals/cn/MartinezAM21,
	author = {Cristiane A. Pendeza Martinez and
                  Taufik Abr{\~{a}}o and
                  Andr{\'{e}} Lu{\'{\i}}s Machado Martinez},
	title = {Energy and spectral efficiency trade-off in {OCDMA-PON} assisted by
                  non-linear programming methods},
	journal = {Comput. Networks},
	volume = {189},
	pages = {107920},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.107920},
	doi = {10.1016/J.COMNET.2021.107920},
	timestamp = {Thu, 29 Apr 2021 15:13:00 +0200},
	biburl = {https://dblp.org/rec/journals/cn/MartinezAM21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Two important metrics for performance evaluation in optical code division multiple access networks (OCDMA) are energy efficiency (EE) and spectral efficiency (SE). Both metrics are investigated in this work through the bi-objective optimization approach by analyzing the trade-off between SE and EE. We first formulate the SE–EE optimization as a bi-objective optimization (BOO) problem with minimum rate requirement constraints. Then, considering the non-convexity of the BOO problem, it is converted into a single-objective optimization (SOO) problem by utilizing weighted sum method. Nonlinear programming methods as sequential quadratic programming method (SQP) and majoration–minimization (MaMi) are applied to solve the BOO problem, with QoS guarantees for the OCDMA networks. Resource efficiency (RE) is able to explore the trade-off between EE and SE in OCDMA networks. The optimization methods were applied and their performance-complexity trade-offs are compared with the exhaustive search (ES) method. Numerical results were performed considering practical and realistic scenarios, including a wide range of nodes, while the solutions obtained by the methods are represented in the Pareto front.}
}


@article{DBLP:journals/cn/FengHWZJ21,
	author = {Yue Feng and
                  Weiqing Huang and
                  Siye Wang and
                  Yanfang Zhang and
                  Shang Jiang},
	title = {Detection of {RFID} cloning attacks: {A} spatiotemporal trajectory
                  data stream-based practical approach},
	journal = {Comput. Networks},
	volume = {189},
	pages = {107922},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.107922},
	doi = {10.1016/J.COMNET.2021.107922},
	timestamp = {Wed, 22 Jan 2025 14:53:43 +0100},
	biburl = {https://dblp.org/rec/journals/cn/FengHWZJ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the rapid development of the internet of things (IoT), radio frequency identification (RFID) technology plays an important role in various fields. However, tags are vulnerable to cloning attacks because they are limited by size and production costs. A cloning attack fabricates one or more replicas of a genuine tag, which behave exactly the same as the genuine tag and can deceive the reader to obtain legitimate authorization, leading to potential economic loss or reputation damage. Many advanced solutions have been proposed to combat cloning attacks. Existing trajectory-based RFID clone detection methods use historical trajectories for model training. However, the environment of the RFID monitoring area is complex and diverse and changes in real time. The features trained based on historical trajectories cannot effectively adapt to the complex environment. In this article, we make a novel attempt to counterattack tag cloning based on real-time trajectories. We propose the clone attack detection approach (deClone), which can intuitively and accurately display the positions of abnormal tags in real time. It requires only commercial off-the-shelf (COTS) RFID devices, unlike methods based on radio frequency (RF) fingerprints and synchronization keys, which require additional hardware devices or software redesign. According to the experimental results, our scheme improves the detection precision by 16.71% compared with that of the existing trajectory-based detection methods.}
}


@article{DBLP:journals/cn/Venkateswararao21,
	author = {Kuna Venkateswararao and
                  Pravati Swain and
                  Christophoros Christophorou and
                  Andreas Pitsillides},
	title = {Using {UE-VBS} for dynamic virtual small cells deployment and backhauling
                  in 5G Ultra-Dense networks},
	journal = {Comput. Networks},
	volume = {189},
	pages = {107926},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.107926},
	doi = {10.1016/J.COMNET.2021.107926},
	timestamp = {Thu, 29 Apr 2021 15:13:00 +0200},
	biburl = {https://dblp.org/rec/journals/cn/Venkateswararao21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper builds on the UE-based Virtual Base Station (UE-VBS) concept, which enables the Smartphones (i.e., UEs) of the general population to be enhanced with Base Station and Relay Node functionalities and be embedded as an integral part of the Mobile Network Infrastructure, offering relief in stressful or overloaded situations. This paper focuses on the selection process of eligible-UEs that will be activated on-the-fly into UE-VBSs to complement and support the Mobile Network infrastructure, either as virtual small cells (VSCs) or virtual relay nodes (VRNs). We adopt a Modified Affinity Propagation Clustering (MAPC) algorithm to select UE-VBSs to act as VSCs for capacity/data rate expansion in areas where the infrastructure is weak and a more effective and agile network operation is needed. Additionally, to provide for a more spectrum efficient backhauling of mobile data traffic from the VSCs towards the BS, the Multi-hop Load balanced Geographical Path selection (MLGP) algorithm is proposed. The MAPC and MLGP algorithms are implemented and evaluated in MATLAB and also validated using the NS3 network simulator, with mobile data traffic modeled as a non-uniform distribution with respect to the time and space domain. The results demonstrated that the proposed approaches improve the network performance in terms of throughput, delay and jitter.}
}


@article{DBLP:journals/cn/BiswasGC21,
	author = {Soumadip Biswas and
                  Arobinda Gupta and
                  Sandip Chakraborty},
	title = {Load-balanced user associations in dense {LTE} networks},
	journal = {Comput. Networks},
	volume = {189},
	pages = {107928},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.107928},
	doi = {10.1016/J.COMNET.2021.107928},
	timestamp = {Fri, 18 Oct 2024 15:41:27 +0200},
	biburl = {https://dblp.org/rec/journals/cn/BiswasGC21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Minimizing the number of handovers incurred by a mobile User Equipment (UE) in a LTE network is an important and well-studied problem. In a dense LTE network, a mobile UE may have many target base stations (eNBs) for handover at any point in time, and choosing the correct target eNB that reduces the number of spurious handovers while maintaining good signal quality is a challenging problem. An additional problem is to avoid unbalanced distribution of UEs among candidate eNBs with similar capabilities to ensure better network resource utilization and user experience. In this paper, we address the problem of minimizing the number of handovers incurred by mobile UEs in a dense LTE network while balancing the load among the eNBs. In particular, we formulate two problems - Handover Minimized User Association for Single UE (HMUA-S) that addresses the problem of minimizing the number of handovers for a single UE, and Load Balanced Handover Minimized User Association (HMUA-LB) that addresses the problem of jointly maximizing the number of eNBs that are not highly loaded and minimizing the number of handovers per UE in a scenario with multiple UEs. We first propose an algorithm, UE Association based on Look-ahead Signal Strength Approximation (USSL-A), for the HMUS-S problem. A greedy heuristic algorithm called LB-USSL is then proposed for the HMUA-LB problem. Detailed simulation results are given on real world scenarios to show that the algorithms significantly outperform other existing algorithms that address similar problems.}
}


@article{DBLP:journals/cn/Lu0SVP021,
	author = {Ning Lu and
                  Dan Li and
                  Wenbo Shi and
                  Pandi Vijayakumar and
                  Francesco Piccialli and
                  Victor Chang},
	title = {An efficient combined deep neural network based malware detection
                  framework in 5G environment},
	journal = {Comput. Networks},
	volume = {189},
	pages = {107932},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.107932},
	doi = {10.1016/J.COMNET.2021.107932},
	timestamp = {Tue, 13 Dec 2022 14:51:12 +0100},
	biburl = {https://dblp.org/rec/journals/cn/Lu0SVP021.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {While Android smartphones are widely used in 5G networks, third-party application platforms are facing a rapid increase in the screening of applications for market launch. However, on the one hand, due to the receipt of excessive applications for listing, the review requires a lot of time and computing resources. On the other hand, due to the multi-selectivity of Android application features, it is difficult to determine the best feature combination as a criterion for distinguishing benign and malicious software. To address these challenges, this paper proposes an efficient malware detection framework based on deep neural network called DLAMD that can face large-scale samples. An efficient detection framework is designed, which combines the pre-detection phase of rapid detection and the deep detection phase of deep detection. The Android application package (APK) is analyzed in detail, and the permissions and opcodes feature that can distinguish benign from malicious are quickly extracted from the APK. Besides, to obtain the feature subset that can distinguish the attributes most, the random forest with good effect is selected for importance selection and the convolutional neural network (CNN) which automatically extracted the hidden pattern inside features is selected for feature selection. In the experiment, real data from shared malware collection and third-party application download platforms are used to verify the high efficiency of the proposed method. The results show that the comprehensive classification index F1-score of DLAMD can reach 95.69%.}
}


@article{DBLP:journals/cn/EnochLK21,
	author = {Simon Yusuf Enoch and
                  Jang Se Lee and
                  Dong Seong Kim},
	title = {Novel security models, metrics and security assessment for maritime
                  vessel networks},
	journal = {Comput. Networks},
	volume = {189},
	pages = {107934},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.107934},
	doi = {10.1016/J.COMNET.2021.107934},
	timestamp = {Sun, 04 Aug 2024 19:48:54 +0200},
	biburl = {https://dblp.org/rec/journals/cn/EnochLK21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the past few years, maritime vessels have become computerized and connected to the internet. However, with this technology, critical systems based on-board ships that manage the vessel’s navigation system, radar, cargo management system, etc have become more prone to cyber-attacks. Moreover, attackers are now becoming aware of the vulnerabilities associated with such maritime vessel systems. As a result, it is of vital importance to manage and secure the maritime vessel networks against cyber-attacks, but there is a lack of capabilities to efficiently manage the identifications of vulnerabilities, security risk assessment, and evaluate the effectiveness of countermeasures. Hence, we propose a novel framework and security risk modeling and assessment method to evaluate the security of maritime vessel networks. We develop (1) a security model for maritime vessels to capture probabilistic events, vulnerabilities, and network configurations of vessel components; (2) propose an approach to assess the network with a single function, multiple functions, and the inter-dependencies between the functions as attack goal(s); (3) adopt three well-defined security metrics with the proposed model to evaluate possible attacks and/or threats; and (4) compare the effectiveness of cyber-defense strategies based on different attack scenarios on the maritime vessel network. Besides, we perform sensitivity analysis based on temporal and permanent connections that are associated with the vessels’ systems to understand the effect of the connections on security. Our results demonstrate the applicability and usability of the proposed model for finding potential attack paths, assessing security, and mitigating the impact of cyber-attacks and threats on a vessel network.}
}


@article{DBLP:journals/cn/Shang0J021,
	author = {Longkang Shang and
                  Dong Guo and
                  Yuede Ji and
                  Qiang Li},
	title = {Discovering unknown advanced persistent threat using shared features
                  mined by neural networks},
	journal = {Comput. Networks},
	volume = {189},
	pages = {107937},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.107937},
	doi = {10.1016/J.COMNET.2021.107937},
	timestamp = {Thu, 29 Apr 2021 15:13:00 +0200},
	biburl = {https://dblp.org/rec/journals/cn/Shang0J021.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Command and control channel(C&C) is used in some cyber attacks to remotely control infected hosts to steal data or conduct espionage. An effective type of C&C detection methods is network flow based. The insight is that network flow is evitable because the hidden malware in the target system has to communicate with the external C&C server to either receive commands or send data. However, existing network flow-based methods face two challenges to efficiently detect C&C of APT(Advanced persistent threat) attacks, i.e., stealth and flexible attack techniques. To combat these two challenges, we design a new network flow-based C&C detection method. Our work is inspired from two observations that different APT attacks share the same intrusion tools and services, and the unknown malware evolves from existing one. Therefore, the malwares of different groups have some shared attributes that are not easy to find, which leads to some hidden shared features in the network flows between the malware and the C&C server in different attacks. Based on this, we propose a method to detect the hidden C&C channel of unknown APT attacks. First, we use deep learning techniques to mine the shared network flow features from the known multi-class attack flows. Later, we use an appropriate classifier to detect the C&C network flow . Finally, we test our method on public available dataset. The experimental results show that our method can achieve up to F1 score of 0.968 when dealing with unknown malicious network flows. This will help discover unknown APT attacks.}
}


@article{DBLP:journals/cn/DavydowCNK21,
	author = {Alex Davydow and
                  Pavel Chuprikov and
                  Sergey I. Nikolenko and
                  Kirill Kogan},
	title = {Competitive buffer management for packets with latency constraints},
	journal = {Comput. Networks},
	volume = {189},
	pages = {107942},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.107942},
	doi = {10.1016/J.COMNET.2021.107942},
	timestamp = {Thu, 29 Apr 2021 15:13:00 +0200},
	biburl = {https://dblp.org/rec/journals/cn/DavydowCNK21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Modern datacenters are increasingly required to deal with latency-sensitive applications. Incorporation of multiple traffic characteristics (e.g., packet values and required processing requirements) significantly increases the complexity of buffer management policies. In this context two major questions arise: how to represent the latency in desired objectives and how to provide guarantees for buffer management policies that would hold across a wide variety of traffic patterns. In this work, we consider a single queue buffering architecture, where every incoming packet is prepended with intrinsic value, required processing, and slack (offset from the arrival time during which this packet should be transmitted); the buffer size is implicitly bounded by slack values. Our goal is to maximize a total transmitted value (weighted throughput). In these settings, we study worst-case performance guarantees of the proposed online algorithms by means of competitive analysis whose effectiveness is compared versus an optimal clairvoyant offline algorithm. We show non-constant general lower bounds that hold for arbitrary slack values and for slacks that are additively separated from processing requirements; for the case of a multiplicative separation, we present a novel buffer management policy\nSPQ\n(stack with priority queue) and show that it is at most 3-competitive. Our theoretical results are supported by a comprehensive evaluation study on CAIDA traces.}
}


@article{DBLP:journals/cn/ModeasKMT21,
	author = {Ioannis Modeas and
                  Alexandros Kaloxylos and
                  Lazaros F. Merakos and
                  Dimitris Tsolkas},
	title = {An adaptive and distributed network selection mechanism for 5G networks},
	journal = {Comput. Networks},
	volume = {189},
	pages = {107943},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.107943},
	doi = {10.1016/J.COMNET.2021.107943},
	timestamp = {Tue, 21 Mar 2023 21:08:30 +0100},
	biburl = {https://dblp.org/rec/journals/cn/ModeasKMT21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {5G networks aim to support a vast amount of data exchange, through network densification, including the integration of multiple radio access technologies (RATs) under a unified radio access and core network. This integration creates a heterogeneous environment where end devices dynamically select the most suitable RAT for consuming a service via a new or even an ongoing communication session. This paper proposes a distributed and adaptive network selection mechanism to address this challenge. The proposed mechanism comprises two co-operating algorithms, one located at the user equipment (UE), and the other at the core network. Its main objective is to satisfy user preferences regarding monetary cost, quality of service, security, energy consumption etc., while safeguarding an operator's traffic engineering policy to avoid congestion. A key feature of the mechanism is the use of a dynamic threshold used to find the sweet spot between a well-balanced access network and maximizing the number of user sessions placed into their most preferred RAT. This threshold is adjusted in real time according to the experienced network conditions. Extensive network performance and quality of experience simulations show that the proposed mechanism accomplishes its objectives and can be used to provide efficient traffic steering decisions.}
}
