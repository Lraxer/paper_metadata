@article{DBLP:journals/cn/DiarraDITT22,
	author = {Mamoutou Diarra and
                  Walid Dabbous and
                  Amine Ismail and
                  Brice Tetu and
                  Thierry Turletti},
	title = {{RAPID:} {A} RAN-aware performance enhancing proxy for high throughput
                  low delay flows in MEC-enabled cellular networks},
	journal = {Comput. Networks},
	volume = {218},
	pages = {109357},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109357},
	doi = {10.1016/J.COMNET.2022.109357},
	timestamp = {Mon, 05 Dec 2022 13:34:48 +0100},
	biburl = {https://dblp.org/rec/journals/cn/DiarraDITT22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {5G enhanced Mobile broadband (eMBB) aims to provide users with a peak data rate of 20 Gbps in the Radio Access Network (RAN). However, since most Congestion Control Algorithms (CCAs) rely on startup and probe phases to discover the bottleneck bandwidth, they cannot quickly utilize the available RAN bandwidth and adapt to fast capacity changes without introducing large delay increase, especially when multiple flows are sharing the same Radio Link Control (RLC) buffer. To tackle this issue, we propose RAPID, a RAN-aware proxy-based flow control mechanism that prevents CCAs from overshooting more than the available RAN capacity while allowing near optimal link utilization. Based on analysis of up-to-date radio information using Multi-access Edge Computing (MEC) services and packet arrival rates, RAPID is able to differentiate slow interactive flows from fast download flows and allocate the available bandwidth accordingly. Our simulation and experimentation results with concurrent Cubic and BBR flows show that RAPID can reduce delay increase by a factor of 10 to 50 in both Line-of-Sight (LOS) and Non-LOS (NLOS) conditions while preserving high throughput in both 4G and 5G environments.}
}


@article{DBLP:journals/cn/XieYFY22,
	author = {Pengshou Xie and
                  Haoxuan Yang and
                  Tao Feng and
                  Yan Yan},
	title = {Implementing efficient attribute encryption in IoV under cloud environments},
	journal = {Comput. Networks},
	volume = {218},
	pages = {109363},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109363},
	doi = {10.1016/J.COMNET.2022.109363},
	timestamp = {Mon, 06 Jan 2025 07:45:05 +0100},
	biburl = {https://dblp.org/rec/journals/cn/XieYFY22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {CP-ABE is a flexible cryptographic algorithm that enables efficient implementation of access control techniques in cloud architectures. However, when CP-ABE is applied to the IoV environment, the weak performance of IoV individuals will inevitably reduce the efficiency of the overall cryptosystem. In addition, various contingencies in IoV require CP-ABE to be able to dynamically respond to various access requests, and generating only a single ciphertext cannot satisfy various additional access requests. In this paper, we propose an encryption algorithm VM-CP-ABE for IoV in cloud environment, which has the features of offline encryption and outsourced decryption. The offline encryption process utilizes the large amount of offline time of individuals in the vehicular network to generate the initial ciphertext segments, while executing its secret sharing process for each offline phase of the ciphertext segments, thus completing the initial combination of ciphertext parameters. The outsourced decryption can generate transformation keys, thus stripping the most complex pairing operations in the decryption process from the weak performing IoV individuals and transferring this part of operations to the more powerful outsourced individuals. In addition, VM-CP-ABE can generate special hierarchical ciphertexts that will have a smaller ciphertext space. And it can avoid the problem of space efficiency due to the high volume of access control policy transfer. We show the static security of all mechanisms of VM-CP-ABE and conclude with a detailed efficiency analysis. VM-CP-ABE is more time- and space-efficient than traditional attribute encryption for extensive sets of IoV attributes in cloud environments.}
}


@article{DBLP:journals/cn/GaoZGLMS22,
	author = {Caina Gao and
                  Jia Zhang and
                  Linlin Guo and
                  Ke Liu and
                  Lili Meng and
                  Jiande Sun},
	title = {Coordinated rate splitting and power allocation in energy-spectral
                  efficiency tradeoff-based multicell networks},
	journal = {Comput. Networks},
	volume = {218},
	pages = {109364},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109364},
	doi = {10.1016/J.COMNET.2022.109364},
	timestamp = {Sat, 27 Jul 2024 13:40:54 +0200},
	biburl = {https://dblp.org/rec/journals/cn/GaoZGLMS22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In order to support the energy efficiency (EE) and spectral efficiency (SE) in beyond 5G (B5G) wireless communication networks, we propose a flexible tradeoff design of these key performance metrics to obtain simultaneous EE and SE performance enhancement compared to conventional investigations where EE and SE are optimized independently. In this paper, a multi-objective optimization problem (MOOP) in the coordinated rate splitting (Co-RS) based multicell network is formulated to jointly optimize the private power, the coordinated common power and the common rate, by which both network EE and SE can be simultaneously achieved under the consideration of estimated channel error. To make the formulated MOOP tractable, we first transform the independent EE and SE maximization MOOP into a EE and SE tradeoff based single-objective optimization problem (SOOP) equivalently by introducing a flexible weight parameter. Then, fractional optimization is used to handle the multi-ratio objective function, by which an alternative optimization (AO) based sub-optimal solution is proposed to optimize the private power allocation, the joint common power and the spitted rate allocation iteratively with guaranteed convergence. Numerical results have demonstrated that the proposed Co-RS framework is able to achieve flexible EE-SE tradeoff in the multicell network, where better tradeoff has been achieved compared to the related benchmarks.}
}


@article{DBLP:journals/cn/DandachiCAOR22,
	author = {Ghina Dandachi and
                  Sophie Cerf and
                  Yassine Hadjadj Aoul and
                  Abdelkader Outtagarts and
                  {\'{E}}ric Rutten},
	title = {A robust control-theory-based exploration strategy in deep reinforcement
                  learning for virtual network embedding},
	journal = {Comput. Networks},
	volume = {218},
	pages = {109366},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109366},
	doi = {10.1016/J.COMNET.2022.109366},
	timestamp = {Mon, 05 Dec 2022 13:34:48 +0100},
	biburl = {https://dblp.org/rec/journals/cn/DandachiCAOR22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Network slice management and, more generally, resource orchestration should be fully automated in 6G networks, as envisioned by the ETSI ENI. In this context, artificial intelligence (AI) and context-aware policies are certainly major options to move in this direction and to adapt service delivery to changing user needs, environmental conditions and business objectives. In this paper, we step towards this objective by addressing the problem of optimal placement of dynamic virtual networks through a self-adaptive learning-based strategy. These constantly evolving networks present, however, several challenges, mainly due to their stochastic nature, and the high dimensionality of the state and the action spaces. This curse of dimensionality requires, indeed, a broader exploration, which is not always compatible with a real-time execution in an operational network. Thus, we propose DQMC, a new strategy for virtual network embedding in mobile networks combining a Deep Reinforcement Learning (DRL) strategy, namely a Deep Q-Network (DQN), and Monte Carlo (MC). As learning is costly in time and computing resources, and sensitive to changes in the network, we suggest a control-theory-based techniques to dynamically leverage exploration in DQMC. This leads to fast, efficient, and sober learning compared to a Monte Carlo-based strategy. This also ensures a reliable solution even in the case of a change in the requests’ sizes or a node’s failure, showing promising perspectives for solutions combining control-theory and machine learning.}
}


@article{DBLP:journals/cn/AzariCSLLBIDMWC22,
	author = {Bahar Azari and
                  Hai Cheng and
                  Nasim Soltani and
                  Haoqing Li and
                  Yanyu Li and
                  Mauro Belgiovine and
                  Tales Imbiriba and
                  Salvatore D'Oro and
                  Tommaso Melodia and
                  Yanzhi Wang and
                  Pau Closas and
                  Kaushik R. Chowdhury and
                  Deniz Erdogmus},
	title = {Automated deep learning-based wide-band receiver},
	journal = {Comput. Networks},
	volume = {218},
	pages = {109367},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109367},
	doi = {10.1016/J.COMNET.2022.109367},
	timestamp = {Tue, 07 Jan 2025 08:32:34 +0100},
	biburl = {https://dblp.org/rec/journals/cn/AzariCSLLBIDMWC22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We propose a modular and full-fledged physical layer receiver design for Orthogonal Frequency Division Multiplexing (OFDM) wireless systems leveraging the advances of deep neural networks (DNN). We adopt a detailed modular design that includes proper and utmost domain knowledge in each element and train it using data collected both via simulations as well as over-the-air and emulated wireless transmissions. We then unify all the modules into an end-to-end automated deep learning-based wide-band receiver and fine-tune it to further improve its accuracy. Our combined pipeline analysis exhibits superior performance by showing bit error rate values up to 8 times lower if compared to the traditional approaches for wireless communications.}
}


@article{DBLP:journals/cn/LiZBWL22,
	author = {Wenhao Li and
                  Xiaoyu Zhang and
                  Huaifeng Bao and
                  Qiang Wang and
                  Zhaoxuan Li},
	title = {Robust network traffic identification with graph matching},
	journal = {Comput. Networks},
	volume = {218},
	pages = {109368},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109368},
	doi = {10.1016/J.COMNET.2022.109368},
	timestamp = {Sun, 04 Aug 2024 19:48:53 +0200},
	biburl = {https://dblp.org/rec/journals/cn/LiZBWL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Network traffic identification is of great value as an effective way for network management. Typically, intelligent classifiers are deployed for advanced network protection, including intrusion traffic detection and network behavior monitoring etc. Robust network traffic classifiers with generalization ability should also ensure stable performance in various network environments. Unfortunately, although the existing network traffic classifiers can achieve the claimed performance when initialized and tested in invariant network environments with stable attribute distributions, they are inclined to fail when adapting to varying practical networks and suffer from significant performance degradation. Based on analysis of representative state-of-the-art classifiers with respect to their transferability, we arrive at that feature distribution of the same class is vulnerable to the changes of networking which account for the degradation of most existing methods. To tackle the issues, we propose a weakly-supervised network traffic classification method based on graph matching. Specifically, network sessions are aggregated to several clusters with the extracted principal features through weakly-supervised clustering. Moreover, we measure the correlations between clusters from the same networks to construct the similarity graphs. Clusters from the testing network are associated with those from the initial network by the carefully designed graph matching algorithm, so that the testing clusters can be labeled according to the associated ones in the initialized network. Our method shows eye-catching robustness, achieving an accuracy of 88.19% when practically deployed in different networks, which significantly outperforms the existing approaches.}
}


@article{DBLP:journals/cn/ZhangXX22,
	author = {Ziming Zhang and
                  Xiaolong Xu and
                  Fu Xiao},
	title = {5GMEC-DP: Differentially private protection of trajectory data based
                  on 5G-based mobile edge computing},
	journal = {Comput. Networks},
	volume = {218},
	pages = {109376},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109376},
	doi = {10.1016/J.COMNET.2022.109376},
	timestamp = {Mon, 05 Dec 2022 13:34:48 +0100},
	biburl = {https://dblp.org/rec/journals/cn/ZhangXX22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Machine learning has become a core technology in areas such as big data, Internet of Things, and cloud computing. Training machine learning models requires a large amount of data, How to protect these data with low cost and high efficiency is an important issue. This paper proposes a trajectory data collection model based on the 5G-based mobile edge computing, and uses the service characteristics of the MEC server to propose a differentially private protection scheme of trajectory data based on 5G-based mobile edge computing (5GMEC-DP). If the encrypted location information does not belong to the service range of the current MEC server, it will be projected to the service edge of the MEC server, thereby limiting the amount of noise of the Geo-Indistinguishability algorithm, making it suitable for the protection of trajectory data, and it also proves that the 5GMEC-DP algorithm still satisfies the definition of ε-Geo-Indistinguishability. Finally, experiments on the real data set prove that 5GMEC-DP can maintain the high practicability of the data when the degree of privacy protection is high. At ε=0.001 and ε=0.0005, Average Qloss of each coordinate in the trajectory decreases by 64% and 81%, respectively, compared with Geo-Indistinguishability algorithm. The overall database availability loss decreases by 64% and 82%, respectively.}
}


@article{DBLP:journals/cn/BellaBCM22,
	author = {Giampaolo Bella and
                  Pietro Biondi and
                  Gianpiero Costantino and
                  Ilaria Matteucci},
	title = {Designing and implementing an AUTOSAR-based Basic Software Module
                  for enhanced security},
	journal = {Comput. Networks},
	volume = {218},
	pages = {109377},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109377},
	doi = {10.1016/J.COMNET.2022.109377},
	timestamp = {Sat, 08 Jun 2024 13:14:22 +0200},
	biburl = {https://dblp.org/rec/journals/cn/BellaBCM22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Electronic Control Units (ECUs) communicate with each other to accomplish the functionalities of modern vehicles. ECUs form an in-vehicle network that is precisely regulated and must be adequately protected from malicious activity, which has had several outbreaks in recent years. Therefore, we present CINNAMON, an AUTOSAR-based Basic Software Module that aims at confidentiality, integrity and authentication, all at the same time, for the traffic exchanged over the bus protocols that AUTOSAR supports. CINNAMON in fact stands for Confidential, INtegral aNd Authentic onboard coMmunicatiON.}
}


@article{DBLP:journals/cn/OuHZZZH22,
	author = {Wei Ou and
                  Shiying Huang and
                  Jingjing Zheng and
                  Qionglu Zhang and
                  Guang Zeng and
                  Wenbao Han},
	title = {An overview on cross-chain: Mechanism, platforms, challenges and advances},
	journal = {Comput. Networks},
	volume = {218},
	pages = {109378},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109378},
	doi = {10.1016/J.COMNET.2022.109378},
	timestamp = {Sat, 08 Jun 2024 13:14:22 +0200},
	biburl = {https://dblp.org/rec/journals/cn/OuHZZZH22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {After years of in-depth development of blockchain, various blockchains with different characteristics and suitable for different application scenarios coexist in large numbers. Due to the isolation of blockchains and the high degree of heterogeneity between chains, value transfer and data communication between existing blockchains are facing unprecedented challenges, and the phenomenon of value isolated island is gradually emerging. The cross-chain technology of blockchain is an important technical means to realize the interconnection of blockchains and improve the interoperability and scalability of blockchains. In this paper, the development and application of blockchain cross-chain technology are studied, the background and significance of cross-chain technology are described, the research status of cross-chain technology is expounded, the current mainstream cross-chain technologies and cross-chain projects are introduced, the mentioned cross-chain technologies and cross-chain projects are analyzed and compared. In addition, this paper also summarizes the difficulties existing in the current cross-chain technology and provides solutions for reference, so as to lead to the discussion of the development trend of cross-chain technology, and finally complete the summary of the research content of the full text and the prospect of cross-chain technology. It is hoped that the relevant summary results can help relevant researchers and practitioners quickly grasp the research progress in the field of blockchain interoperability, and obtain relevant knowledge and application methods in this field.}
}


@article{DBLP:journals/cn/SamikwaMB22,
	author = {Eric Samikwa and
                  Antonio Di Maio and
                  Torsten Braun},
	title = {{ARES:} Adaptive Resource-Aware Split Learning for Internet of Things},
	journal = {Comput. Networks},
	volume = {218},
	pages = {109380},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109380},
	doi = {10.1016/J.COMNET.2022.109380},
	timestamp = {Sat, 30 Sep 2023 10:07:04 +0200},
	biburl = {https://dblp.org/rec/journals/cn/SamikwaMB22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Distributed training of Machine Learning models in edge Internet of Things (IoT) environments is challenging because of three main points. First, resource-constrained devices have large training times and limited energy budget. Second, resource heterogeneity of IoT devices slows down the training of the global model due to the presence of slower devices (stragglers). Finally, varying operational conditions, such as network bandwidth, and computing resources, significantly affect training time and energy consumption. Recent studies have proposed Split Learning (SL) for distributed model training with limited resources but its efficient implementation on the resource-constrained and decentralized heterogeneous IoT devices remains minimally explored. We propose Adaptive REsource-aware Split-learning (ARES), a scheme for efficient model training in IoT systems. ARES accelerates training in resource-constrained devices and minimizes the effect of stragglers on the training through device-targeted split points while accounting for time-varying network throughput and computing resources. ARES takes into account application constraints to mitigate training optimization tradeoffs in terms of energy consumption and training time. We evaluate ARES prototype on a real testbed comprising heterogeneous IoT devices running a widely-adopted deep neural network and dataset. Results show that ARES accelerates model training on IoT devices by up to 48% and minimizes the energy consumption by up to 61.4% compared to Federated Learning (FL) and classic SL, without sacrificing model convergence and accuracy.}
}


@article{DBLP:journals/cn/KoitaDMT22,
	author = {Moussa Ko{\"{\i}}ta and
                  Youssouf M. Diagana and
                  Oumar Y. Ma{\"{\i}}ga and
                  Mamadou Kaba Traor{\'{e}}},
	title = {A generic learning simulation framework to assess security strategies
                  in cyber-physical production systems},
	journal = {Comput. Networks},
	volume = {218},
	pages = {109381},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109381},
	doi = {10.1016/J.COMNET.2022.109381},
	timestamp = {Sun, 06 Oct 2024 21:22:03 +0200},
	biburl = {https://dblp.org/rec/journals/cn/KoitaDMT22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Connected systems through computerized networks are at the heart of the Industry of the future. As they merge physical entities with cyber spaces, they fall under the paradigm of cyber-physical production systems. Cybersecurity is a key challenge for such systems, as they are subject to daily attempts of intruders to gain unauthorized access to their internal resources or to compromise their integrity. The fast increase of new attack strategies requires the rapid design and assessment of new defense strategies. It entails a complex, error-prone and time-consuming process, including the clear specification of the attack and defense strategies involved, and the design and implementation of the simulation model allowing to evaluate the performances of the defense strategy. This work intends to make such a process transparent to cybersecurity managers by limiting their workload to the sole specification of the characteristics of the system and the logic of the attack and the defense. It provides a generic hybrid simulation framework for flexible evaluation of cybersecurity policies, which is demonstrated on a SYN flooding application. Therefore, the contribution is twofold: (1) The proposed framework offers a high-level environment allowing various experts to collaborate by graphically modeling a given attack strategy and the envisioned defense strategy, without engaging in heavy implementation efforts. Then the framework's executable infrastructure, which combines simulation with machine learning to understanding the interactions between the attackers & the defender, will allow them assessing the performances of these strategies. The proposed framework differs from state-of-the-art cybersecurity simulation environments in its uniqueness to combining the expressive power of a universal simulation modeling formalism with the user-friendliness of a visual simulation tool. Therefore, it offers at one side, a very high modeling flexibility for easy exploration of various cybersecurity strategies, and at the other side, integrated learning capabilities for allowing self-adaptive user-based cybersecurity strategy design. (2) The application demonstrating the framework focuses on the most encountered and still uncontrolled threats in cybersecurity, i.e. the SYN-Flooding based Denial of Service (DoS) attack. The application targeted is not meant to propose yet another SYN flood detection algorithm or to improve the state-of-the-art in that domain, but to prove the framework operationality. The experimental results obtained showcase the ability of the framework to support learning simulation-based SYN flood defense algorithm design and validation.}
}


@article{DBLP:journals/cn/LiuWX22,
	author = {Jianmin Liu and
                  Qi Wang and
                  Yongjun Xu},
	title = {{AR-GAIL:} Adaptive routing protocol for FANETs using generative adversarial
                  imitation learning},
	journal = {Comput. Networks},
	volume = {218},
	pages = {109382},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109382},
	doi = {10.1016/J.COMNET.2022.109382},
	timestamp = {Wed, 05 Feb 2025 15:17:52 +0100},
	biburl = {https://dblp.org/rec/journals/cn/LiuWX22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Flying ad hoc networks (FANETs), as the emerging communication paradigm, have been widely used in civil and military fields. Packet routing in FANETs is challenging due to dynamic network conditions. Traditional topology-based routing protocols are unsuitable for FANETs with dynamic network topologies. Routing protocols based on reinforcement learning (RL) may be the first choice for FANETs because of their good learning ability. However, existing RL-based routing protocols for FANETs have limited adaptability to network dynamics due to ignoring neighborhood environment states, and are prone to get stuck in suboptimal routing policies owing to inappropriate reward design and delayed reward issues. We propose AR-GAIL, an adaptive routing protocol based on Generative Adversarial Imitation Learning (GAIL), which aims to select the minimal end-to-end delay route according to ongoing network conditions for FANETs. We formulate the routing decision process as a Markov decision process (MDP) and design a novel MDP state which consists of the current node state and the neighborhood environment state. Moreover, we develop an efficient value function-based GAIL learning framework to learn the routing policy from expert routes instead of a predefined reward function. The simulation shows that AR-GAIL can adapt well to network dynamics. Compared with state-of-the-art routing protocols, AR-GAIL shows outstanding performance in terms of the end-to-end delay and packet delivery ratio.}
}


@article{DBLP:journals/cn/ZhangYZFLQ22,
	author = {Junye Zhang and
                  Peng Yu and
                  Fanqin Zhou and
                  Lei Feng and
                  Wenjing Li and
                  Xuesong Qiu},
	title = {Resource and delay aware fine-grained service offloading in collaborative
                  edge computing},
	journal = {Comput. Networks},
	volume = {218},
	pages = {109383},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109383},
	doi = {10.1016/J.COMNET.2022.109383},
	timestamp = {Mon, 05 Dec 2022 13:34:48 +0100},
	biburl = {https://dblp.org/rec/journals/cn/ZhangYZFLQ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Fine-grained service offloading in collaborative edge computing can realize full use of the limited resources of edge nodes to achieve efficient parallel computing. The existing research mainly focuses on service delay but pays insufficient attention to the network status, which will easily cause unbalanced resource utilization. Therefore, we propose a resource and delay aware fine-grained service offloading mechanism. First, we propose a novel network-adaptive service graph reconstruction algorithm to reduce the complexity of service offloading and the transmission delay, which includes service graph partition, dependency conflict detection and elimination, and service graph re-creation. Next, to better balance link and node resource utilization respectively, we propose original graph-based and association graph-based service graph mapping algorithms based on graph neural networks. A goal-directed affinity-based loss function is explored for them, which aims to address the difficulty of label generation in supervised learning. We conduct extensive simulation experiments with different numbers of subtasks, edge nodes and service requests under different network resource statuses. The experimental results show that the proposed service graph reconstruction method can balance network resource utilization, while reducing the service transmission delay and algorithm execution time for complex services. Moreover, the service graph mapping algorithms can improve the resource utilization balance degree while satisfying service constraints with start-end node location, resources and delay in various scenarios, especially in the case of unbalanced user distribution. Generally, our fine-grained service offloading mechanism enables short execution time and strong scalability, and is applicable to dynamic edge networks.}
}


@article{DBLP:journals/cn/AlwanBCGBF22,
	author = {Ahmed Abdulhasan Alwan and
                  Allan J. Brimicombe and
                  Mihaela Anca Ciupala and
                  Seyed Ali Ghorashi and
                  Andres Baravalle and
                  Paolo Falcarin},
	title = {Time-series clustering for sensor fault detection in large-scale Cyber-Physical
                  Systems},
	journal = {Comput. Networks},
	volume = {218},
	pages = {109384},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109384},
	doi = {10.1016/J.COMNET.2022.109384},
	timestamp = {Sun, 12 Nov 2023 02:17:57 +0100},
	biburl = {https://dblp.org/rec/journals/cn/AlwanBCGBF22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Large-scale Cyber–Physical Systems (CPSs) are information systems that involve a vast network of sensor nodes and other devices that stream observations in real-time and typically are deployed in uncontrolled, broad geographical terrains. Sensor node failures are inevitable and unpredictable events in large-scale CPSs, which compromise the integrity of the sensors measurements and potentially reduce the quality of CPSs services and raise serious concerns related to CPSs safety, reliability, performance, and security. While many studies were conducted to tackle the challenge of sensor nodes failure detection using domain-specific solutions, this paper proposes a novel sensor nodes failure detection approach and empirically evaluates its validity using a real-world case study. This paper investigates time-series clustering techniques as a feasible solution to identify sensor nodes malfunctions by detecting long-segmental outliers in their observations’ time series. Three different time-series clustering techniques have been investigated using real-world observations collected from two various sensor node networks, one of which consists of 275 temperature sensors distributed around London. This study demonstrates that time-series clustering effectively detects sensor node’s continuous (halting/repeating) and incipient faults. It also showed that the feature-based time series clustering technique is a more efficient long-segmental outliers detection mechanism compared to shape-based time-series clustering techniques such as DTW and K-Shape, mainly when applied to shorter time-series windows.}
}


@article{DBLP:journals/cn/PengLLLW22,
	author = {Yabin Peng and
                  Caixia Liu and
                  Shuxin Liu and
                  Yuchen Liu and
                  Yiteng Wu},
	title = {SmartTRO: Optimizing topology robustness for Internet of Things via
                  deep reinforcement learning with graph convolutional networks},
	journal = {Comput. Networks},
	volume = {218},
	pages = {109385},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109385},
	doi = {10.1016/J.COMNET.2022.109385},
	timestamp = {Fri, 11 Nov 2022 16:52:56 +0100},
	biburl = {https://dblp.org/rec/journals/cn/PengLLLW22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The reliability problems caused by random failure or malicious attacks in the Internet of Things (IoT) are becoming increasingly severe, while a highly robust network topology is the basis for highly reliable Quality of Service (QoS). Therefore, improving the robustness of the IoT against cyber-attacks by optimizing the network topology becomes a vital issue. Heuristic algorithms as the mainstream idea to solve the network robustness optimization, but their high computational cost cannot meet the timeliness requirements of real IoT scenarios. This paper proposes a Smart Topology Robustness Optimization (SmartTRO) algorithm based on Deep Reinforcement Learning (DRL). First, we design a rewiring operation as an evolutionary behavior in IoT network topology robustness optimization, which achieves topology optimization at a low cost without changing the degree of all nodes. Then, SmartTRO learns the evolutionary behavior characteristics of IoT network topology by combining Graph Convolutional Network (GCN) and policy network, where the training of neural network parameters is completed by DRL. Experimental results demonstrate that SmartTRO improves the ability of IoT topology to resist cyber-attacks effectively and outperforms the state-of-the-art heuristic algorithm in terms of both topology robustness optimization performance and computational cost.}
}


@article{DBLP:journals/cn/ParsaMS22,
	author = {Ali Parsa and
                  Neda Moghim and
                  Pouyan Salavati},
	title = {Joint power allocation and {MCS} selection for energy-efficient link
                  adaptation: {A} deep reinforcement learning approach},
	journal = {Comput. Networks},
	volume = {218},
	pages = {109386},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109386},
	doi = {10.1016/J.COMNET.2022.109386},
	timestamp = {Mon, 05 Dec 2022 13:34:48 +0100},
	biburl = {https://dblp.org/rec/journals/cn/ParsaMS22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Link adaptation is a promising tool of modern networks to combat the time-variant quality of channels. Modulation and Coding Scheme (MCS) selection is essentially used for link adaptation with channel dynamism. However, future generation networks need flexible link adaptation schemes that consider more parameters to improve the network performance. This paper proposes an energy-efficient link adaptation algorithm, in which a Deep Reinforcement Learning (DRL) agent is used to find the best match between the channel condition and the link parameters. Also, the downlink transmission power has been considered as a link parameter in addition to the modulation order and coding rate to make the link adaptation more flexible and efficient. Simulation results show that the proposed algorithm outperforms the benchmark algorithms regarding energy efficiency and link throughput.}
}


@article{DBLP:journals/cn/LyuGS22,
	author = {Minzhao Lyu and
                  Hassan Habibi Gharakheili and
                  Vijay Sivaraman},
	title = {Classifying and tracking enterprise assets via dual-grained network
                  behavioral analysis},
	journal = {Comput. Networks},
	volume = {218},
	pages = {109387},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109387},
	doi = {10.1016/J.COMNET.2022.109387},
	timestamp = {Mon, 05 Dec 2022 13:34:48 +0100},
	biburl = {https://dblp.org/rec/journals/cn/LyuGS22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Enterprise networks continue to grow in scale and complexity, encompassing a wide range of Internet-connected end-points including web servers/proxies, DNS/VPN/mail servers, and other special-purpose devices. Monitoring this dynamically evolving set of assets, for the purposes of ensuring operational efficiency and cyber security, poses a significant challenge for IT personnel. In this paper, we develop a system that automatically classifies enterprise Internet-connected assets in a continuous manner by analyzing their network activity, thereby reducing blind spots for organizational IT departments. Our contributions are three-fold: (1) We analyze over 3 billion packets from a large enterprise network to deduce network behavioral profiles of the popular asset types like website servers, DNS servers, and file storage systems and transport-layer patterns of less popular ones such as non-typical TCP/UDP servers, proxies, and NAT gateways; (2) We systematically develop host-level graph structure, identify a rich set of behavioral attributes, balance the computational cost against predictive power, train classifiers in a dual-grained classification scheme to categorize assets, and evaluate them via cross-fold validation as well as open set; and (3) We prototype our system on multiple 10Gbps Internet links of a campus network, and present insights over a month, such as the ability to identify hundreds of typical servers as well as thousands of non-typical assets, track their utilization, and highlight anomalous behaviors pertinent to possible cyber-threats. Our solution provides a dynamic and scalable way for IT personnel to effectively track enterprise assets.}
}


@article{DBLP:journals/cn/Sarraf-Maralaniyan22,
	author = {Sarah Sarraf{-}Maralaniyan and
                  Akbar Ghaffarpour Rahbar},
	title = {MT\({}^{\mbox{3}}\)A : {A} Novel Multicast Routing, Spectrum and Modulation-Level
                  Assignment in Elastic Optical Networks},
	journal = {Comput. Networks},
	volume = {218},
	pages = {109388},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109388},
	doi = {10.1016/J.COMNET.2022.109388},
	timestamp = {Sat, 30 Sep 2023 10:07:04 +0200},
	biburl = {https://dblp.org/rec/journals/cn/Sarraf-Maralaniyan22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Elastic Optical Networks (EONs) were introduced to eliminate the challenges of Wavelength Division Multiplexing (WDM) networks. EONs can improve resource efficiency compared to WDM networks. The issue of resource allocation in EONs is a major challenge for the optimal use of maximum network capacity for each communication demand. On the other hand, multicasting is defined as the transfer of data from one source to multiple destinations and it is one of the most effective methods based on cost and efficiency in order to provide flow in computer networks. In this article, we present a novel Multicast Two-part Two-path Two-direction Allocation (\nM\nT\n3\nA\n) scheme in order to routing, spectrum and modulation-level assignment for dynamic multicast traffic in EONs. With this scheme, each sub-request related to a multicast request is divided into two parts considering the property of Sliceable Bandwidth Variable Transponders (SBVTs) and is set up in two different directions in two different light-paths. By using the\nM\nT\n3\nA\nscheme compared to comparative schemes, with increasing the data rate, Bandwidth Blocking Probability (BBP) is reduced, which is very important due to increasing demand for contents with high data rate.}
}


@article{DBLP:journals/cn/LopesRCOZ22,
	author = {Rafael S. Lopes and
                  Denis Ros{\'{a}}rio and
                  Eduardo Cerqueira and
                  Helder M. N. S. Oliveira and
                  Sherali Zeadally},
	title = {Priority-aware traffic routing and resource allocation mechanism for
                  space-division multiplexing elastic optical networks},
	journal = {Comput. Networks},
	volume = {218},
	pages = {109389},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109389},
	doi = {10.1016/J.COMNET.2022.109389},
	timestamp = {Mon, 05 Dec 2022 13:34:48 +0100},
	biburl = {https://dblp.org/rec/journals/cn/LopesRCOZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent years, the introduction of new technologies and applications connected to the Internet has demonstrated the physical incapacity of current optical backbone networks in providing resources soon. One of the main proposals to deal with this problem today is space-division multiplexing elastic optical networks. However, to transport the massive amount of data that is being generated today, these backbone networks should provide efficient resilience mechanisms. We propose a routing algorithm with a protection mechanism that considers traffic priority for elastic optical networks space-division multiplexing. The results obtained demonstrate the proposed algorithm’s high efficiency in establishing resilient high priority connections compared with recently proposed algorithms in the literature.}
}


@article{DBLP:journals/cn/WilhelmiGD22,
	author = {Francesc Wilhelmi and
                  Lorenza Giupponi and
                  Paolo Dini},
	title = {Analysis and evaluation of synchronous and asynchronous FLchain},
	journal = {Comput. Networks},
	volume = {218},
	pages = {109390},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109390},
	doi = {10.1016/J.COMNET.2022.109390},
	timestamp = {Wed, 07 Dec 2022 23:01:40 +0100},
	biburl = {https://dblp.org/rec/journals/cn/WilhelmiGD22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Motivated by the heterogeneous nature of devices participating in large-scale federated learning (FL) optimization, we focus on an asynchronous server-less FL solution empowered by blockchain technology. In contrast to mostly adopted FL approaches, which assume synchronous operation, we advocate an asynchronous method whereby model aggregation is done as clients submit their local updates. The asynchronous setting fits well with the federated optimization idea in practical large-scale settings with heterogeneous clients. Thus, it potentially leads to higher efficiency in terms of communication overhead and idle periods. To evaluate the learning completion delay of BC-enabled FL, namely FLchain, we provide an analytical model based on batch service queue theory. Furthermore, we provide simulation results to assess the performance of both synchronous and asynchronous mechanisms. Important aspects involved in the BC-enabled FL optimization, such as the network size, link capacity, or user requirements, are put together and analyzed. As our results show, the synchronous setting leads to higher prediction accuracy than the asynchronous case. Nevertheless, asynchronous federated optimization provides much lower latency in many cases, thus becoming an appealing solution for FL when dealing with large datasets, tough timing constraints (e.g., near-real-time applications), or highly varying training data.}
}


@article{DBLP:journals/cn/NandhiniKMP22,
	author = {P. S. Nandhini and
                  S. Kuppuswami and
                  Subramaniam Malliga and
                  R. Devi Priya},
	title = {A Lightweight Energy-Efficient Algorithm for mitigation and isolation
                  of Internal Rank Attackers in {RPL} based Internet of Things},
	journal = {Comput. Networks},
	volume = {218},
	pages = {109391},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109391},
	doi = {10.1016/J.COMNET.2022.109391},
	timestamp = {Wed, 08 Mar 2023 08:48:35 +0100},
	biburl = {https://dblp.org/rec/journals/cn/NandhiniKMP22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Internet of Things (IoT) has become a pivotal technology for connecting various physical things or devices to the internet. Despite the potential advantages, security in IoT network continues to be a major concern due to enormous volume of the data generated and transmitted. Since the devices in IoT are resource-constrained and heterogeneous, it is becoming harder to maintain security in routing protocols such as Routing Protocol for Low-power and Lossy networks (RPL). RPL uses control packets for the construction of tree topology and it is prone to various attacks such as flood, version, rank and so on. Rank attack leads to the formation of loop, increased latency in packet delivery, energy depletion in nodes, decreased delivery ratio of packets and so on. Since the impact of the rank attack is high on the network, a lightweight energy-efficient algorithm is needed for the detection and isolation of rank attackers. The proposed Rank Attack Detection (RAD) algorithm uses a non-cryptographic hash algorithm to preserve the integrity of control packets. It uses random sampling to reduce energy consumption. Once the rank attacker is detected, an alarm is generated against the attackers. The alarm is not a separate control packet; it is appended to the control message itself. The proposed algorithm is analysed using different topologies by comparing it with the already existing algorithms in terms of control packet overhead, delivery ratio, latency for delivery of data packets, accuracy and energy consumption. It achieves better accuracy in grid-centered topology and the average energy consumption is reduced in random topology.}
}


@article{DBLP:journals/cn/ShanZXZ22,
	author = {Minghui Shan and
                  Sheng Zhang and
                  Mingjun Xiao and
                  Yanchao Zhao},
	title = {{LENS:} Bandwidth-efficient video analytics with adaptive super resolution},
	journal = {Comput. Networks},
	volume = {218},
	pages = {109392},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109392},
	doi = {10.1016/J.COMNET.2022.109392},
	timestamp = {Mon, 05 Dec 2022 13:34:48 +0100},
	biburl = {https://dblp.org/rec/journals/cn/ShanZXZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Video streaming analytic pipelines are deployed widely nowadays, where in many cases videos are transmitted continuously from cameras to servers. However, video analytic accuracy highly depends on video resolution, and when bandwidth suffers only low-resolution videos can be transmitted which leads to low accuracy. The rapid development of super resolution DNNs sparks the possibility of reconstructing high-resolution videos reliably from low resolution videos, and thus boosts video analytic accuracy. However, pretrained SR models may fail to cope with dynamic video content, while introducing online learning can be efficient under this condition. In this paper, we propose a practical system, LENS, which integrates an online learning period into analytic pipelines. The experimental results show that LENS is capable of responding to video dynamics and retraining SR models for changes quickly. In summary, LENS can save bandwidth consumption by up to 87%, or achieve a higher accuracy by up to 9.6% compared with state-of-the-art methods with slight additional bandwidth.}
}


@article{DBLP:journals/cn/UrasFCLA22,
	author = {Marco Uras and
                  Enrico Ferrara and
                  Raimondo Cossu and
                  Antonio Liotta and
                  Luigi Atzori},
	title = {{MAC} address de-randomization for WiFi device counting: Combining
                  temporal- and content-based fingerprints},
	journal = {Comput. Networks},
	volume = {218},
	pages = {109393},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109393},
	doi = {10.1016/J.COMNET.2022.109393},
	timestamp = {Mon, 05 Dec 2022 13:34:48 +0100},
	biburl = {https://dblp.org/rec/journals/cn/UrasFCLA22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {To preserve people privacy and prevent device (and people) tracking, WiFi MAC address randomization is been introduced by an ever increasing number of operating systems. Accordingly, mobile devices make use of different virtual addresses over time so that not a single fixed factory address is used that may identify a specific user. This has the consequence that it is not even possible to extract anonymous information on people mobility by analyzing WiFi traffic traces, which would be useful for many purposes (e.g., counting the number of people in a mass transport vehicle).}
}


@article{DBLP:journals/cn/GhosalHC22,
	author = {Amrita Ghosal and
                  Subir Halder and
                  Mauro Conti},
	title = {Secure over-the-air software update for connected vehicles},
	journal = {Comput. Networks},
	volume = {218},
	pages = {109394},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109394},
	doi = {10.1016/J.COMNET.2022.109394},
	timestamp = {Sun, 22 Oct 2023 11:14:48 +0200},
	biburl = {https://dblp.org/rec/journals/cn/GhosalHC22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Current trends forecast that Over-the-Air (OTA) software updates will be highly significant for future connected vehicles. The OTA software updates will enable upgrading vehicle functionalities or bug fixations in embedded software installed on electronic control units remotely. However, in terms of security, OTA updates are highly critical as they need complete access to the in-vehicle communication network. Furthermore, scheduling OTA software updates at a massive scale over a cellular network is highly challenging. This paper proposes STRIDE, a novel technique for secure and scalable software updates using cloud through cellular network. STRIDE ensures end-to-end security using ciphertext-policy attribute-based encryption. To enable fast and reliable distribution of update package, we then propose a software update scheduling algorithm to serve dynamic traffic flow. Particularly, we integrate dynamic traffic flow with the Lyapunov-drift analysis framework, and establish throughput optimality of our proposed scheduling algorithm. We evaluate the performance of STRIDE through extensive experiments. Experimental results show that STRIDE reduces more than 52% computation and storage overheads, 60% propagation delay and increases throughput by 35% than the state-of-the-art solutions, in addition to enjoying the stronger security properties.}
}


@article{DBLP:journals/cn/RanjanJKC22,
	author = {Shashi Ranjan and
                  Pranav Jha and
                  Abhay Karandikar and
                  Prasanna Chaporkar},
	title = {Two stage downlink scheduling for balancing QoS in multihop {IAB}
                  networks},
	journal = {Comput. Networks},
	volume = {218},
	pages = {109395},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109395},
	doi = {10.1016/J.COMNET.2022.109395},
	timestamp = {Mon, 05 Dec 2022 13:34:48 +0100},
	biburl = {https://dblp.org/rec/journals/cn/RanjanJKC22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The 3GPP has envisioned Integrated Access and Backhaul (IAB) as a key enabler to support the flexible and ultra-dense deployment of 5G cells with significantly reduced deployment costs. However, IAB introduces new research challenges, especially when studying multihop topology. This paper presents a QoS-based downlink scheduler designed explicitly for IAB networks. The scheduler is devised after considering multihop relaying topology, QoS requirements, and backhaul constraints. We investigate its performance using system-level simulations under diverse IAB topologies. The performance results show that the scheduler is capable of fulfilling QoS requirements for different types of services, even at heavy network load. The scheduler also maintains excellent fairness among QoS flows belonging to the same service type.}
}


@article{DBLP:journals/cn/FedrizziBCG22,
	author = {Riccardo Fedrizzi and
                  Rasoul Behravesh and
                  Cristina Costa and
                  Fabrizio Granelli},
	title = {An adaptive GA-based slice provisioning method for vertical industries
                  in 5G and beyond networks},
	journal = {Comput. Networks},
	volume = {218},
	pages = {109397},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109397},
	doi = {10.1016/J.COMNET.2022.109397},
	timestamp = {Mon, 05 Dec 2022 13:34:48 +0100},
	biburl = {https://dblp.org/rec/journals/cn/FedrizziBCG22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The fifth-generation of mobile communication networks are expected to support a large number of vertical industries requiring services with diverging requirements. In this vein, mobile networks have been witnessing a radical transformation to satisfy three key services types, ultra-reliable low-latency communication, enhanced mobile broadband, and massive machine-type communication, that will coexist on the same network infrastructure thanks to the network slicing paradigm. Moreover, a distributed user-plane deployment is introduced, allowing edge deployment of delay-sensitive applications thanks to the multi-access edge computing technology. However, designing resilient, elastic, end-to-end slice provisioning mechanisms is still an open issue. In this paper, we study the problem of end-to-end network slice provisioning for different vertical industries whose requested services are modeled as service function chains spanning from the radio access to the application and including user plane and control plane functionalities. Two slice provisioning strategies are considered by formulating a mixed integer linear programming problem and considering different objective functions allowing network operators to deploy the services while pursuing specific business logic. Further, an adaptive genetic algorithm based approach is proposed to solve the same problem in a short time scale by improving the search-space exploration while the population evolves. The simulation results demonstrate the effectiveness of the approach providing near-optimal solutions while drastically reducing the computational complexity.}
}


@article{DBLP:journals/cn/HuangLZL22,
	author = {Guanglun Huang and
                  Jianming Liu and
                  Baoxian Zhang and
                  Cheng Li},
	title = {Quality-driven video streaming for ultra-dense {OFDMA} heterogeneous
                  networks},
	journal = {Comput. Networks},
	volume = {218},
	pages = {109398},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109398},
	doi = {10.1016/J.COMNET.2022.109398},
	timestamp = {Mon, 05 Dec 2022 13:34:48 +0100},
	biburl = {https://dblp.org/rec/journals/cn/HuangLZL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The explosive growth of mobile video traffic has brought enormous traffic pressure to the existing bandwidth-limited cellular network. Ultra-dense heterogeneous networks (HetNets) are deemed as one of the most promising 5G technologies for increasing the cellular network capacity. In this paper, we study quality-driven multiuser video streaming algorithm for two-tier orthogonal frequency division multiple access (OFDMA) HetNets. Specifically, we formulate a stochastic optimization problem for the quality-driven multiuser video streaming in two-tier OFDMA HetNets to maximize the average perceived video quality of small cell users while meeting the average data rate demand of macrocell users. We then decompose the original stochastic problem into a sequence of per-slot deterministic subproblems of adaptive bitrate selection and radio resource management which have no requirement of prior channel knowledge by employing Lyapunov optimization technique. We accordingly propose an online quality-driven video streaming algorithm. In this algorithm, we derive the optimal bitrate decision for the adaptive bitrate selection subproblem, and design an iterative scheduling algorithm of joint subchannel assignment and power control by utilizing alternating optimization and successive convex approximation techniques to solve the radio management subproblem. Extensive simulation results validate the high efficiency of the proposed quality-driven video streaming algorithm in OFDMA HetNets.}
}


@article{DBLP:journals/cn/RamineniVB22,
	author = {Chaturasan Ramineni and
                  T. G. Venkatesh and
                  Lokesh Bommisetty},
	title = {Performance evaluation of random access in narrow band Internet of
                  Things},
	journal = {Comput. Networks},
	volume = {218},
	pages = {109399},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109399},
	doi = {10.1016/J.COMNET.2022.109399},
	timestamp = {Mon, 05 Dec 2022 13:34:48 +0100},
	biburl = {https://dblp.org/rec/journals/cn/RamineniVB22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Low power wide area network (LPWAN) is one of the enabling technologies for Internet of Things (IoT). 3GPP has introduced a new standard called Narrow Band Internet of Things (NB-IoT) for LPWAN. This paper develops an analytical model to estimate the throughput of User Equipments (UEs) in NB-IoT system. We carry out Markov chain analysis of our model under steady state conditions by considering different Coverage Enhancement (CE) levels, number of preamble transmission attempts, and size of the back-off window as state variables. The Markov chain model is used to derive the transmission and the success probabilities of random access procedure for UEs in different CE levels. Further, we derive the throughput of the packets transmitted by the UEs in different CE levels. The analytical model is validated against simulation for a different set of combinations of parameters. We show that the throughput of NB-IoT critically depends on the allocation of the number of sub-carriers to different CE levels.}
}


@article{DBLP:journals/cn/YadavMPBL22,
	author = {Awaneesh Kumar Yadav and
                  Manoj Misra and
                  Pradumn Kumar Pandey and
                  An Braeken and
                  Madhusanka Liyanage},
	title = {An improved and provably secure symmetric-key based 5G-AKA Protocol},
	journal = {Comput. Networks},
	volume = {218},
	pages = {109400},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109400},
	doi = {10.1016/J.COMNET.2022.109400},
	timestamp = {Sat, 30 Sep 2023 10:07:05 +0200},
	biburl = {https://dblp.org/rec/journals/cn/YadavMPBL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {One of the primary authentication mechanisms defined for the 5G system is the 5G-Authentication and Key Agreement (5G-AKA) protocol. It is set to be used in the next generation of mobile communications but has several serious flaws such as privacy issues, vulnerability to traceability attacks, and has de-synchronization problem. To deal with these issues, An Braeken presented a lightweight authentication mechanism that provides security features not present in 5G-AKA, but the scheme fails to provide perfect forward secrecy. Later Munilla et al. introduced an improved version of the Braeken authentication scheme that claims to provide perfect forward secrecy but is computationally expensive and prone to DoS attacks if the size of the server database is large. Taking this in view, we propose a cost-effective scheme that provides all the security features, including perfect forward secrecy. We do the informal (non-mathematical) and formal analysis (using the ROR, GNY, and Scyther tool) of the security properties of the proposed protocol and show that the proposed protocol provides all the security features. Furthermore, we measure the performance of the proposed protocol in terms of energy consumption and computational, communication and storage costs. The evaluation results show that the proposed protocol takes significantly less cost than most of its competitors. In addition to this, we also compute the performance of the proposed protocol under unknown attacks in terms of computational, communication, and energy consumption costs. The outcome of analysis shows that the proposed protocol takes very less overhead under unknown attacks compared to its competitors.}
}


@article{DBLP:journals/cn/RatheeKC22,
	author = {Geetanjali Rathee and
                  Chaker Abdelaziz Kerrache and
                  Carlos T. Calafate},
	title = {An Ambient Intelligence approach to provide secure and trusted Pub/Sub
                  messaging systems in IoT environments},
	journal = {Comput. Networks},
	volume = {218},
	pages = {109401},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109401},
	doi = {10.1016/J.COMNET.2022.109401},
	timestamp = {Mon, 05 Dec 2022 13:34:48 +0100},
	biburl = {https://dblp.org/rec/journals/cn/RatheeKC22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Ambient Intelligence (AmI) is defined as a high-quality vision technology where content and information can be sensed and adopted from anytime, anywhere, and by any user in the environment. Much of the research in this area has focused on several aspects of AmI, such as computational and storage complexity, accuracy, and transmission criteria. However, few works have focused on the various trust and security concerns associated to the message publish/subscribe (Pub/Sub) procedure when the on-the-fly technique is adopted. In fact, malicious devices may easily breach the legitimate devices with the aim of degrading the security and privacy in the network. The aim of this paper is to propose a secure and trusted on-the-fly Pub/Sub communication mechanism where the trust and transmission among various devices occurs by computing their trust using indirect factors. In addition, the accuracy and legitimacy of each communicating device is validated using a reinforcement learning scheme. Moreover, the proposed solution is validated and verified against various security measures over a traditional approach.}
}


@article{DBLP:journals/cn/TuZLSY22,
	author = {Zhe Tu and
                  Huachun Zhou and
                  Kun Li and
                  Haoxiang Song and
                  Yuzheng Yang},
	title = {A Blockchain-based Trust and Reputation Model with Dynamic Evaluation
                  Mechanism for IoT},
	journal = {Comput. Networks},
	volume = {218},
	pages = {109404},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109404},
	doi = {10.1016/J.COMNET.2022.109404},
	timestamp = {Sat, 08 Jun 2024 13:14:22 +0200},
	biburl = {https://dblp.org/rec/journals/cn/TuZLSY22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The rapid development of the Internet of Things (IoT) has dramatically increased the number of distributed IoT devices and users. Trust and Reputation Model (TRM) is a well-known technique for improving the security of IoT, which detects malicious attacks by evaluating user behavior. Since traditional distributed TRMs lack secure and reliable data sharing mechanisms, some works have integrated the TRMs into the trusted blockchains. Nevertheless, they have not realized the security requirements of the comprehensive assessment of user behavior and dynamic evaluation of reputation. Therefore, this paper introduces a Blockchain-based Trust and Reputation Model (BTRM), which evaluates user reputation from many aspects and can resist multiple malicious attacks in the distributed network. Second, we propose a novel Dynamic Evaluation Mechanism (DEM), which reduces the number of reputation evaluations without degrading network security and builds a trusting foundation between long-term inactive users and the network. Eventually, we deploy the proposed model DEM-BTRM in a prototype system of Hyperledger Fabric and compare it with existing reputation evaluation methods. The results show that the DEM-BTRM can comprehensively evaluate user behavior and dynamically detect malicious attacks.}
}


@article{DBLP:journals/cn/YeLWSY22,
	author = {Weidu Ye and
                  Junzhou Luo and
                  Wenjia Wu and
                  Feng Shan and
                  Ming Yang},
	title = {{MUTAA:} An online trajectory optimization and task scheduling for
                  UAV-aided edge computing},
	journal = {Comput. Networks},
	volume = {218},
	pages = {109405},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109405},
	doi = {10.1016/J.COMNET.2022.109405},
	timestamp = {Mon, 05 Dec 2022 13:34:48 +0100},
	biburl = {https://dblp.org/rec/journals/cn/YeLWSY22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A novel UAV-aided edge computing system is proposed in this work, where UAV-aided edge nodes are dispatched to provide communication and computation assistance for completing tasks generated by ground clients (GCs). We formulate a trajectory design and task allocation problem (TDTAP), aiming at maximizing the sum of completed tasks of GCs by optimizing the proper trajectory for each UAV and scheduling tasks from each GC. It is impossible to solve the TDTAP problem directly in polynomial time since UAVs lack all GCs’ information, e.g., position and amount of tasks. To this end, we put forward an online iterative algorithm named Maximum UAV trajectory and Task Allocation Algorithm (MUTAA) to solve the TDTAP problem by jointly optimizing UAVs’ trajectory and GCs’ task scheduling. Unlike existing algorithms, MUTAA can make real-time decisions for each UAV without acquiring information from all GCs in advance. During each iteration, MUTAA consists of two sub-algorithms: (1) trajectory design algorithm TDA and (2) task allocation strategy TAS. Specifically, the preschedule step is used in TDA to find the proper trajectory for UAVs, and a competitive online algorithm, TAS, is proposed to schedule GCs’ tasks. Theoretical analysis proves that TAS is\ne\n/\n(\ne\n−\n1\n)\n-competitive, that is, it processes\n(\ne\n−\n1\n)\n/\ne\n(approximately 63%) tasks when compared with the optimal offline solution. Experimental results demonstrate that MUTAA completes 83% data on an average of the optimal offline solution, illustrating that the proposed algorithm MUTAA can be widely used in time-sensitive scenarios.}
}


@article{DBLP:journals/cn/ShahidK22,
	author = {Syed Maaz Shahid and
                  Sungoh Kwon},
	title = {Distributed robust channel allocation for clustered cognitive radio-based
                  IoT networks using graph theory},
	journal = {Comput. Networks},
	volume = {218},
	pages = {109406},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109406},
	doi = {10.1016/J.COMNET.2022.109406},
	timestamp = {Mon, 26 Jun 2023 20:51:10 +0200},
	biburl = {https://dblp.org/rec/journals/cn/ShahidK22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The exponential growth in the Internet of Things (IoT) devices for the Internet of Everything (IoE) services demands more operating spectrum. Utilizing the unlicensed spectrum by a large number of IoT networks leads to congestion in the unlicensed spectrum. To mitigate the scarcity of radio spectrum for IoT networks, integration of the cognitive radio technology with IoT networks allows IoT devices to operate and share the licensed spectrum with primary users (PUs). For efficient licensed-spectrum sharing, a cognitive radio-based spectrum assignment algorithm is proposed for IoT networks, which minimizes network interference and ensures connectivity against the PUs activity. For interference reduction, a conflict graph is used to determine the potential interfering links in the network, and channels are accordingly assigned to the radio interfaces of each IoT device. To ensure connectivity in the network, an ordered pair of channels is assigned to the radios of the IoT devices such that the network topology is robust to the presence of the PUs on multiple channels. The robustness of the network topology avoids frequent channel switching and improves the energy efficiency of the network. Simulation results show that the proposed algorithm minimizes overall network interference, and achieves 100% successful packet transmission, compared to other channel assignment algorithms. The algorithm shows that the network is not partitioned due to the PUs’ presence on up to half of the available licensed channels, which significantly reduces the amount of channel switching required, and conserves energy in the IoT devices.}
}


@article{DBLP:journals/cn/AlaniT22,
	author = {Mohammed M. Alani and
                  Hissam Tawfik},
	title = {PhishNot: {A} Cloud-Based Machine-Learning Approach to Phishing {URL}
                  Detection},
	journal = {Comput. Networks},
	volume = {218},
	pages = {109407},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109407},
	doi = {10.1016/J.COMNET.2022.109407},
	timestamp = {Mon, 05 Dec 2022 13:34:48 +0100},
	biburl = {https://dblp.org/rec/journals/cn/AlaniT22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Phishing is constantly growing to be one of the most adopted tools for conducting cyber-attacks. Recent statistics indicated that 97% of users could not recognize a sophisticated phishing email. With over 1.5 million new phishing websites being created every month, legacy black lists and rule-based filters can no longer mitigate the increasing risks and sophistication level of phishing. Phishing can deploy various malicious payloads that compromise the network’s security. In this context, machine learning can play a crucial role in adapting the capabilities of computer networks to recognize current and evolving phishing patterns. In this paper, we present PhishNot, a phishing URL detection system based on machine learning. Hence, our work uses a primarily ”learning from data” driven approach, validated with a representative scenario and dataset. The input features were reduced to 14 to assure the system’s practical applicability. Experiments showed that Random Forest presented the best performance with a very high accuracy of 97.5%. Furthermore, the design of our system also lends itself to being more adoptable in practice through a combination of high phishing detection rate and high speed (an average of\n11\n.\n5\nμ\ns\nper URL) when deployed on the cloud.}
}


@article{DBLP:journals/cn/HadiG22,
	author = {Majid Hadi and
                  Reza Ghazizadeh},
	title = {Joint resource allocation, user clustering and 3-D location optimization
                  in multi-UAV-enabled mobile edge computing},
	journal = {Comput. Networks},
	volume = {218},
	pages = {109420},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109420},
	doi = {10.1016/J.COMNET.2022.109420},
	timestamp = {Fri, 11 Nov 2022 16:52:56 +0100},
	biburl = {https://dblp.org/rec/journals/cn/HadiG22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper studies a multi-unmanned aerial vehicle (UAV)-enabled mobile edge computing (MEC) system, where UAVs are equipped with a powerful MEC server to provide computation services for ground users. Under NOMA protocol and partial offloading mode, we aim to jointly optimize the NOMA user clustering, sub-carrier assignment, transmit power of users, CPU frequency, and 3-D location of UAVs to maximize the sum computation bits of all users. Since the formulated problem is a mixed-integer non-linear optimization, we propose a three-stage algorithm to address the four sub-problems iteratively. First, two efficient NOMA user clustering algorithms are proposed to divide the users into several NOMA clusters. Second, a heuristic sub-carrier assignment algorithm is presented based on the channel gain and interfering users. Third, by adopting the successive convex approximation (SCA) technique and Lagrange dual method, the closed-form expressions of the transmit power and CPU frequency of users are derived. Forth, a convex optimization problem is obtained to optimize the 3-D location of UAVs. The numerical evaluations illustrate that the proposed system outperforms the benchmark schemes in terms of sum computation bits performance.}
}


@article{DBLP:journals/cn/TianJLZXM22,
	author = {Chuang Tian and
                  Qi Jiang and
                  Teng Li and
                  Junwei Zhang and
                  Ning Xi and
                  Jianfeng Ma},
	title = {Reliable PUF-based mutual authentication protocol for UAVs towards
                  multi-domain environment},
	journal = {Comput. Networks},
	volume = {218},
	pages = {109421},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109421},
	doi = {10.1016/J.COMNET.2022.109421},
	timestamp = {Sat, 30 Sep 2023 10:07:05 +0200},
	biburl = {https://dblp.org/rec/journals/cn/TianJLZXM22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the widespread application of unmanned aerial vehicles (UAVs), the discussion about the various security and privacy issues of UAVs have never stopped. Physical Unclonable Function (PUF) is inherently unclonable and tamper-proof, many authentication and key agreement protocols based on PUF for UAVs have been proposed in the past. But they can only be suitable for mutual authentication between a single ground station and multiple UAVs. Not only does this centralized authentication method have a single point of failure, but also cannot adapt to the increasing demand for UAV authentication in multi-domain settings. In this paper, we propose a novel lightweight mutual authentication scheme based on PUF which is resistant to well-known attacks such as node tampering attacks, and cloning attacks, etc. Furthermore, we realized cross-domain authentication for UAVs, ensuring secure and efficient communication for UAVs in different domains. We have demonstrated the correctness of our scheme in detail, and carried out experimental analysis. The results show that our scheme is sufficiently secure and effective, and is suitable for UAVs in a multi-domain environment.}
}
