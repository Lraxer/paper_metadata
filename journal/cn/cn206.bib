@article{DBLP:journals/cn/SousaBL22,
	author = {Roniel S. de Sousa and
                  Azzedine Boukerche and
                  Antonio A. F. Loureiro},
	title = {On the prediction of large-scale road-network constrained trajectories},
	journal = {Comput. Networks},
	volume = {206},
	pages = {108337},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2021.108337},
	doi = {10.1016/J.COMNET.2021.108337},
	timestamp = {Fri, 01 Apr 2022 11:23:42 +0200},
	biburl = {https://dblp.org/rec/journals/cn/SousaBL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Trajectory data mining-based applications benefit from the increasing availability of vehicle trajectory and road network datasets. For instance, the application of trajectory prediction makes it possible to design more efficient routing protocols for vehicular networks. This paper proposes a novel cluster-based framework for the long-term prediction of road-network constrained trajectories. The framework employs a new hierarchical agglomerative clustering algorithm and trains prediction models from historical trajectory datasets. Experimental results show the framework’s effectiveness and efficiency to predict trajectories with different characteristics in a new real-world, large-scale scenario. Furthermore, the framework outperformed the related work in terms of prediction accuracy and time complexity.}
}


@article{DBLP:journals/cn/WangTPKSP22,
	author = {Xiaoyang Wang and
                  Jonathan D. Thomas and
                  Robert J. Piechocki and
                  Shipra Kapoor and
                  Ra{\'{u}}l Santos{-}Rodr{\'{\i}}guez and
                  Arjun Parekh},
	title = {Self-play learning strategies for resource assignment in Open-RAN
                  networks},
	journal = {Comput. Networks},
	volume = {206},
	pages = {108682},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2021.108682},
	doi = {10.1016/J.COMNET.2021.108682},
	timestamp = {Tue, 21 Mar 2023 21:08:29 +0100},
	biburl = {https://dblp.org/rec/journals/cn/WangTPKSP22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Open Radio Access Network (ORAN) is being developed with an aim to democratise access and lower the cost of future mobile data networks, supporting network services with various QoS requirements, such as massive IoT and URLLC. In ORAN, network functionality is dis-aggregated into remote units (RUs), distributed units (DUs) and central units (CUs), which allows flexible software on Commercial-Off-The-Shelf (COTS) deployments. Furthermore, the mapping of variable RU requirements to local mobile edge computing centres for future centralised processing would significantly reduce the power consumption in cellular networks. In this paper, we study the RU–DU resource assignment problem in an ORAN system, modelled as a 2D bin packing problem. A deep reinforcement learning-based self-play approach is proposed to achieve efficient RU–DU resource management, with AlphaGo Zero inspired neural Monte-Carlo Tree Search (MCTS). Experiments on representative 2D bin packing environment and real sites data show that the self-play learning strategy achieves intelligent RU–DU resource assignment for different network conditions. Comparing with baseline methods, including a heuristic virtual resource allocation algorithm, the Lego heuristic algorithm and the MCTS methods, the proposed approach achieves a performance gain between 5.70% to 12.95% in terms of resource utilisation efficiency.}
}


@article{DBLP:journals/cn/HosseiniNG22,
	author = {Entesar Hosseini and
                  Mohsen Nickray and
                  Shamsollah Ghanbari},
	title = {Optimized task scheduling for cost-latency trade-off in mobile fog
                  computing using fuzzy analytical hierarchy process},
	journal = {Comput. Networks},
	volume = {206},
	pages = {108752},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2021.108752},
	doi = {10.1016/J.COMNET.2021.108752},
	timestamp = {Fri, 01 Apr 2022 11:23:42 +0200},
	biburl = {https://dblp.org/rec/journals/cn/HosseiniNG22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Mobile Fog Computing (MFC) paradigm can be integrated as a unit called as Multi-Access Edge Computing (MFC) in a fifth-generation (5G) network. There are extensive researches coercing to the MFC. Task scheduling is an important issue in the area of MFC to solve computing capacities such as limited CPU power, storage capacity, memory constraints, and limited battery life in Mobile Devices (MDs). The multi-criteria decision-making problem in fog nodes has not been widely studied. According to the variety and difficulty of criteria, the scheduling in the fog node has become a challenge. The previous works in the tasks scheduling context considered a few criteria of dynamic scheduling without covering other enough criteria. Besides, in MFC, the tasks come with different priorities. We present a scheduling algorithm based on the Priority Queue, Fuzzy and Analytical Hierarchy Process namely PQFAHP in our paper. We use PQFAHP to combine several priorities and prioritize multi-criteria. In our paper, dynamic scheduling includes the completion time, energy consumption, RAM, and deadline criteria. Our experimental results show that the proposed algorithm can consider multi-criteria for scheduling Our proposed work is one of the multi-criteria algorithms that performs optimal results than several benchmark algorithms in terms of waiting time, delay, service level, mean response time, and the number of scheduled tasks on the MFC side. This paper has considerable contributions related to the scheduling of fog computing. For instance, it could decrease 14.2%, 49%, and 26% in average waiting time, delay, and energy consumption respectively, and increase 10.8% in service level.}
}


@article{DBLP:journals/cn/YangSMLYW22,
	author = {Yan Yang and
                  Xingang Shi and
                  Qiang Ma and
                  Yahui Li and
                  Xia Yin and
                  Zhiliang Wang},
	title = {Path stability in partially deployed secure {BGP} routing},
	journal = {Comput. Networks},
	volume = {206},
	pages = {108762},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.108762},
	doi = {10.1016/J.COMNET.2022.108762},
	timestamp = {Fri, 25 Mar 2022 09:59:20 +0100},
	biburl = {https://dblp.org/rec/journals/cn/YangSMLYW22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Border Gateway Protocol (BGP), as the current de-facto routing protocol connecting various cooperating domains on the Internet, did not consider security when it was originally designed. With the expansion of the Internet, security is increasingly valued and many BGP enhancement mechanisms are proposed and experimented. Some of them like BGPsec have been standardized and promoted by the IETF. However, the deployment of these inter-domain secure routing mechanisms is subject to many economic and political restrictions. Consequently, there will be a long period of partial deployment, during which instability of BGP can be observed. Specifically, when some networks start deploying secure BGP mechanisms, they may be involved in some temporary or persistent route oscillations. In this paper, we systematically study the stability problem induced by partially deployed secure BGP mechanisms. We analyze the characteristics of topology and routing strategies when BGP oscillations will be introduced. In particular, we propose dispute chain, a derived structure of dispute wheel proposed in Griffin et al. (2002), to formally analyze this problem. Based on dispute chain, we analyze how different security adoption strategies can cause BGP oscillations under the general Gao–Rexford model. Our analysis shows that, even in a situation when there is no dispute wheel, dispute chains may widely appear, indicating that BGP oscillation problems will be introduced when security mechanisms are casually deployed, affecting the security and quality of inter-domain communications. To avoid possible oscillations, we also propose some deployment guidelines from different perspectives of the operator and the Internet, so that a wider deployment of security mechanisms will not blindly disrupt the Internet.}
}


@article{DBLP:journals/cn/ChoiAAASWCNAM22,
	author = {Jinchun Choi and
                  Afsah Anwar and
                  Abdulrahman Alabduljabbar and
                  Hisham Alasmary and
                  Jeffrey Spaulding and
                  An Wang and
                  Songqing Chen and
                  DaeHun Nyang and
                  Amro Awad and
                  David Mohaisen},
	title = {Understanding Internet of Things malware by analyzing endpoints in
                  their static artifacts},
	journal = {Comput. Networks},
	volume = {206},
	pages = {108768},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.108768},
	doi = {10.1016/J.COMNET.2022.108768},
	timestamp = {Sun, 12 Nov 2023 02:17:56 +0100},
	biburl = {https://dblp.org/rec/journals/cn/ChoiAAASWCNAM22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The lack of security measures among the Internet of Things (IoT) devices and their persistent online connection gives adversaries a prime opportunity to target them or even abuse them as intermediary targets in larger attacks such as distributed denial-of-service (DDoS) campaigns. In this paper, we analyze IoT malware and focus on the endpoints reachable on the public Internet, that play an essential part in the IoT malware ecosystem. Namely, we analyze endpoints acting as dropzones and their targets to gain insights into the underlying dynamics in this ecosystem, such as the affinity between the dropzones and their target IP addresses, and the different patterns among endpoints. Towards this goal, we reverse-engineer 2423 IoT malware samples and extract strings from them to obtain IP addresses. We further gather information about these endpoints from public Internet-wide scanners, such as Shodan and Censys. Our results, through analysis and visualization expose clear patterns of affinity between sources and targets of attacks, attack exposure by Internet infrastructure, and clear depiction of the ecosystem of IoT malware as a whole, only utilizing static artifacts. Our investigation from four different perspectives provides profound insights into the role of endpoints in IoT malware attacks, which deepens our understanding of IoT malware ecosystems and can assist future defenses.}
}


@article{DBLP:journals/cn/DahanayakaJS22,
	author = {Thilini Dahanayaka and
                  Guillaume Jourjon and
                  Suranga Seneviratne},
	title = {Dissecting traffic fingerprinting CNNs with filter activations},
	journal = {Comput. Networks},
	volume = {206},
	pages = {108770},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.108770},
	doi = {10.1016/J.COMNET.2022.108770},
	timestamp = {Fri, 01 Apr 2022 11:23:42 +0200},
	biburl = {https://dblp.org/rec/journals/cn/DahanayakaJS22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {HTTPS encrypted traffic flows leak information on underlying contents through various statistical properties such as packet lengths and timing, enabling traffic fingerprinting attacks. Recent traffic fingerprinting attacks leveraged Convolutional Neural Networks (CNNs) to record very high accuracies undermining state-of-the-art defenses. In this paper, we analyze such CNNs to understand their inner workings which helps in building efficient traffic classifiers and effective defenses. First, we experiment on three datasets and show that website fingerprinting CNNs focus majorly on transitions between uploads and downloads in trace fronts while video fingerprinting CNNs focus more on finer shapes of periodic bursts. Next, we show that traffic fingerprinting CNNs exhibit transfer-learning capabilities allowing identification of new websites with fewer data. We also demonstrate how traffic fingerprinting CNNs outperform Recurrent Neural Networks (RNNs) due to their resilience to random shifts in data, which is common in network traces. We further generalize these observations on other publicly available network traffic datasets. Leveraging our observations, we propose two new defenses against traffic fingerprinting. Our first defense FRONT-U, defends website visits by obfuscating transitions between uploads and downloads in trace fronts and provides similar privacy as the state-of-the-art defense FRONT, with half the data overhead. Our second defense STOMA, defends streaming traffic by obfuscating the finer sub-bursts within major bursts of a trace using only the next few seconds as opposed to using the entire trace as in the state-of-the-art.}
}


@article{DBLP:journals/cn/AhangerAA22,
	author = {Tariq Ahamed Ahanger and
                  Abdullah Aljumah and
                  Mohammed Atiquzzaman},
	title = {State-of-the-art survey of artificial intelligent techniques for IoT
                  security},
	journal = {Comput. Networks},
	volume = {206},
	pages = {108771},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.108771},
	doi = {10.1016/J.COMNET.2022.108771},
	timestamp = {Sun, 06 Oct 2024 21:22:02 +0200},
	biburl = {https://dblp.org/rec/journals/cn/AhangerAA22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The data protection problem concerning the Internet of Things (IoT) paradigm has drawn the innovation community’s considerable attention. Several surveys have covered different IoT-centered issues, namely vulnerability simulation, intrusion detection systems, and state-of-the-art techniques were put forward for this purpose. In comparison, we concentrate exclusively on the emerging IoT vulnerabilities and related Artificial Techniques in the current research. This paper initializes the detailed categorization of recent research works, which explore different Machine Learning and Deep Learning techniques for the IoT paradigm. Additionally, a novel taxonomy is included based on IoT vulnerabilities, corresponding attackers, and effects, threats that explore weak links, effective remedies, and organizational authentication technologies that are currently available to recognize and track such deficiencies. This seeks to offer a multidimensional analysis viewpoint on IoT vulnerabilities to the reader, including the technological specifics and effects, which are intended to be leveraged for remediation goals. Inspired by the lack of IoT paradigm-related scientific (and malicious) evidence, the current study provides an emphasis on IoT manipulation from passive measurements. The current research illustrates the seriousness of the IoT problem while offering organizational knowledge resources that will inevitably assist in the mitigating mission in general. In addition to open issues and research concerns, informative conclusions, inferences, and results are revealed in the current research, which will lead to future research initiatives to resolve scientific concerns relevant to IoT security.}
}


@article{DBLP:journals/cn/RaskarN22,
	author = {Charushila Raskar and
                  Shikha Nema},
	title = {Metaheuristic enabled modified hidden Markov model for traffic flow
                  prediction},
	journal = {Comput. Networks},
	volume = {206},
	pages = {108780},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.108780},
	doi = {10.1016/J.COMNET.2022.108780},
	timestamp = {Fri, 25 Mar 2022 09:59:20 +0100},
	biburl = {https://dblp.org/rec/journals/cn/RaskarN22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Traffic flow prediction is essential for traffic management, pollution reduction, and public safety, and is an important component of Intelligent Transportation Systems (ITS). Since most of the links are not outfitted with traffic sensors, extracting traffic flow data in real-time scenarios has proven to be challenging. Moreover, the parameters that affect traffic flows (such as accidents, road closures, and public events) are mostly unexpected, which makes traffic flow prediction a complex task. Hence, this paper plans to design an enhanced prediction model for traffic flow using a Modified Hidden Markov Model (MHMM). The input features subjected to prediction via MHMM are “Average True Range (ATR), Exponential Moving Average (EMA), Relative Strength Indicator (RSI), and Rate of Change (ROC)” respectively. In fact, the modification in HMM relies on the optimal tuning of state numbers using the Mean Fitness-oriented Dragonfly Algorithm (MF-DA). Finally, the betterment of implemented work is compared and proved over the conventional models.}
}


@article{DBLP:journals/cn/MadarasinghaMJJ22,
	author = {Chamara Madarasingha and
                  Shashika Ranga Muramudalige and
                  Guillaume Jourjon and
                  Anura P. Jayasumana and
                  Kanchana Thilakarathna},
	title = {VideoTrain++: GAN-based adaptive framework for synthetic video traffic
                  generation},
	journal = {Comput. Networks},
	volume = {206},
	pages = {108785},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.108785},
	doi = {10.1016/J.COMNET.2022.108785},
	timestamp = {Sun, 02 Oct 2022 15:31:02 +0200},
	biburl = {https://dblp.org/rec/journals/cn/MadarasinghaMJJ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Video streaming traffic has been dominating the global network and the challenges have exacerbated with the gaining popularity of interactive videos, a.k.a.360° videos, as they require more network resources. However, effective provision of network resources for video streaming traffic is problematic due to the inability to identify video traffic flows through the network because of end-to-end encryption. Despite the promise given for network security and privacy, end-to-end encryption also provides a shield for adversaries. To this end, encrypted traffic classification and content fingerprinting with advanced Machine Learning (ML) methods have been proposed. Nevertheless, achieving high performance requires a significant amount of training data, which is a challenging task in operational networks due to the sheer volume of traffic and privacy concerns. As a solution, in this paper, we propose a novel Generative Adversarial Network (GAN) based data generation solution to synthesize video streaming data for two different tasks, 360°/normal video classification and video fingerprinting. The solution consists of a percentile-based data mapping mechanism to enhance the data generation process, which is further supported by novel algorithms for data pre-processing and GAN model training. Taking over 6600 actual video traces and generating over 150,000 new traces, our ML-based traffic classification results show a 5%–16% of accuracy improvement in both tasks.}
}


@article{DBLP:journals/cn/SilvaA22,
	author = {Giovanni Maciel Ferreira Silva and
                  Taufik Abr{\~{a}}o},
	title = {Throughput and latency in the distributed Q-learning random access
                  mMTC networks},
	journal = {Comput. Networks},
	volume = {206},
	pages = {108787},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.108787},
	doi = {10.1016/J.COMNET.2022.108787},
	timestamp = {Fri, 01 Apr 2022 11:23:42 +0200},
	biburl = {https://dblp.org/rec/journals/cn/SilvaA22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In mMTC mode, where thousands of devices try to access network resources sporadically, the problem of random access (RA) and collisions between devices that select the same resources arise. A promising approach to solve the RA problem is the use of learning mechanisms, specially Q-learning (QL) algorithm, where the devices learn about the best time-slot periods to transmit through rewards sent by the central node. In this work, we propose a distributed packet-based learning method of varying the reward given by the central node that favors devices having a larger number of remaining packets to transmit. The numerical results indicated that the proposed distributed packet-based QL method attains a better throughput–latency trade-off than the independent and collaborative techniques in practical scenarios, while the number of payload bits of the packet-based technique is reduced regarding the collaborative QL RA technique for achieving the same normalized throughput.}
}


@article{DBLP:journals/cn/YangWLLPX22,
	author = {Furong Yang and
                  Qinghua Wu and
                  Zhenyu Li and
                  Yanmei Liu and
                  Giovanni Pau and
                  Gaogang Xie},
	title = {BBRv2+: Towards balancing aggressiveness and fairness with delay-based
                  bandwidth probing},
	journal = {Comput. Networks},
	volume = {206},
	pages = {108789},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.108789},
	doi = {10.1016/J.COMNET.2022.108789},
	timestamp = {Mon, 29 Jul 2024 21:17:50 +0200},
	biburl = {https://dblp.org/rec/journals/cn/YangWLLPX22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {BBRv2, proposed by Google, aims at addressing BBR’s shortcomings of unfairness against loss-based congestion control algorithms (CCAs) and excessive retransmissions in shallow-buffered networks. In this paper, we first comprehensively study BBRv2’s performance under various network conditions and show that BBRv2 mitigates the shortcomings of BBR. Nevertheless, BBRv2’s benefits come with several costs, including slow responsiveness to bandwidth dynamics and low resilience to random losses. We then propose BBRv2+ to address BBRv2’s performance issues without sacrificing its advantages over BBR. To this end, BBRv2+ uses delay information to cautiously guide the aggressiveness of its bandwidth probing. In doing so, it achieves fast responsiveness to bandwidth dynamics and fairness against loss-based CCAs at the same time. BBRv2+ also integrates mechanisms for improved resilience to random losses and network jitter. Extensive experiments demonstrate the effectiveness of BBRv2+. Specifically, it achieves 25% higher throughput and comparable queuing delay in comparison with BBRv2 in high-mobility network scenarios.}
}


@article{DBLP:journals/cn/ZhangWL22,
	author = {Lihao Zhang and
                  Taotao Wang and
                  Soung Chang Liew},
	title = {Speeding up block propagation in Bitcoin network: Uncoded and coded
                  designs},
	journal = {Comput. Networks},
	volume = {206},
	pages = {108791},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.108791},
	doi = {10.1016/J.COMNET.2022.108791},
	timestamp = {Fri, 01 Apr 2022 11:23:42 +0200},
	biburl = {https://dblp.org/rec/journals/cn/ZhangWL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper designs and validates new block propagation protocols for the peer-to-peer (P2P) network of the Bitcoin blockchain. Despite its strong protection for security and privacy, the current Bitcoin blockchain can only support a low number of transactions per second (TPS). Besides the PoW consensus protocol, the other key aspect of Bitcoin that limits TPS is its networking protocol. In this work, we aim at redesigning the current Bitcoin’s networking protocol to increase TPS without changing the vital components in its consensus-building protocol. In particular, this work improves the compact-block relaying protocol to enable the propagation of blocks containing a massive number of transactions without inducing extra propagation latencies. The improvements of this work consist of (i) replacing the existing store-and-forward compact-block relaying scheme with a cut-through compact-block relaying scheme; (ii) exploiting rateless erasure codes for P2P networks to increase the block-propagation efficiency. Since the protocols designed in this work only need to rework the current Bitcoin’s networking protocol and do not modify the data structures and crypto-functional components, they can be seamlessly incorporated into the existing Bitcoin blockchain. To validate the designs, we perform analysis on the protocols and implement a Bitcoin network simulator on NS3 to run different block propagation protocols. Our analysis and experimental results confirm that the new block propagation protocols could increase the TPS of the Bitcoin blockchain by 100x without compromising security and consensus-building.}
}


@article{DBLP:journals/cn/XiongZLHLY22,
	author = {Ting Xiong and
                  Ran Zhang and
                  Jiang Liu and
                  Tao Huang and
                  Yunjie Liu and
                  F. Richard Yu},
	title = {A blockchain-based and privacy-preserved authentication scheme for
                  inter-constellation collaboration in Space-Ground Integrated Networks},
	journal = {Comput. Networks},
	volume = {206},
	pages = {108793},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.108793},
	doi = {10.1016/J.COMNET.2022.108793},
	timestamp = {Fri, 01 Apr 2022 11:23:42 +0200},
	biburl = {https://dblp.org/rec/journals/cn/XiongZLHLY22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Space-Ground Integrated Networks (SGINs) make it convenient for users to access services anywhere. In the space segment, satellite constellations can cooperate to provide better space services. However, due to the lack of trust among different constellations, communication security and privacy protection are important issues that need to be solved during inter-constellation cooperation. In this work, with recent advances of blockchain, we present a trusted and privacy-preserved authentication scheme for inter-constellation collaboration. To preserve privacy, we design permanent and temporary identities for each satellite. The permanent one is used for inner-constellation communication, and the temporary identity is for inter-constellation cooperation, respectively. Meanwhile, satellites generate temporary identities for themselves to avoid privacy leakage. A consortium blockchain is introduced for sharing information among cooperative satellite constellations. Furthermore, to achieve efficient authentication under limited resources, a replica storage node method is proposed, where well-resourced satellites cache the replicated information shared through the blockchain. The replica storage node selection is formulated as an integer programming problem and solved with a branch and bound algorithm. Security analysis, including formal analysis using BAN Logic and informal verification, shows that the proposed authentication scheme is secure against various potential attacks. A comparative analysis among the proposed scheme and other blockchain-based schemes shows that the proposed scheme achieves efficiency in signaling, computation, and communication overheads with more functionality attributes. In addition, evaluations also demonstrate that the proposed on-board caching scheme achieves low communication latency and storage cost.}
}


@article{DBLP:journals/cn/SaburCHA22,
	author = {Abdulhakim Sabur and
                  Ankur Chowdhary and
                  Dijiang Huang and
                  Adel Alshamrani},
	title = {Toward scalable graph-based security analysis for cloud networks},
	journal = {Comput. Networks},
	volume = {206},
	pages = {108795},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.108795},
	doi = {10.1016/J.COMNET.2022.108795},
	timestamp = {Mon, 28 Aug 2023 21:39:19 +0200},
	biburl = {https://dblp.org/rec/journals/cn/SaburCHA22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cloud-based systems and services are seeing exponential growth in the last few years. Many companies and digital services are actively migrating their storage and computational needs to the cloud. With such an expansion of virtual services, security threats are also significantly increasing. Utilizing the Attack Representation Methods (ARMs) and Attack Graph (AG) enables the security administrator to understand the cloud network’s current security situation. However, the AG suffers from scalability challenges. It relies on the connectivity between the services and the vulnerabilities associated with the services to allow the system administrator to realize its security state. This approach caused the AG to be vast and challenging to generate and analyze. To address the scalability challenges, we propose a segmentation-based scalable security state (S3) framework for the network. Our framework utilizes the well-known divide-and-conquer approach to divide the large network region into smaller, manageable segments. We follow a well-known segmentation approach derived from the K-means clustering algorithm to partition the system into segments based on the similarity between the services. A distributed firewall (DFW) separates the segments to ensure the attacker cannot move laterally and compromise them. Our evaluation shows that the separation of segments not only preserves the original reachability and connectivity but also enhances the scalability of the AG. The presented framework (a) provides a scalable attack graph generation algorithm by reducing attack graph generation time and density, which in turn reduces the complexity of security analysis on an extensive cloud network, (b) ensures a loop-free attack graph through the utilization of cycle detection and removal algorithm, and (c) presents an approach to provide the optimal number of segments based on the cost of implementing the segmentation using the distributed firewall rules.}
}


@article{DBLP:journals/cn/Brehon-Grataloup22,
	author = {Lucas Br{\'{e}}hon{-}Grataloup and
                  Rahim Kacimi and
                  Andr{\'{e}}{-}Luc Beylot},
	title = {Mobile edge computing for {V2X} architectures and applications: {A}
                  survey},
	journal = {Comput. Networks},
	volume = {206},
	pages = {108797},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.108797},
	doi = {10.1016/J.COMNET.2022.108797},
	timestamp = {Mon, 28 Aug 2023 21:39:19 +0200},
	biburl = {https://dblp.org/rec/journals/cn/Brehon-Grataloup22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In mobile environments, with the help of larger bandwidths and cloud computing solutions, any task can be offloaded from a mobile user equipment to be handled remotely. However, even though this process is accelerated with every cellular generation, with 5G being no exception, offloading to a faraway centralized cloud implies non-negligible delay. To tackle this issue concerning delay-sensitive applications, mobile edge computing, now denominated as multi-access edge computing (MEC), was brought to light. With cloud resources brought closer to the edge of the network, MEC greatly reduces task offloading delay, thereby striving to satisfy the constraints of real-time applications. As highly demanding mobile applications, vehicular networks are a target to be addressed in terms of performance, especially communication and computation delay. In this article, we establish the specificities of MEC when applied to the Internet of Vehicles (IoV), and survey recent papers studying implementations of MEC relevant to real-time vehicular considerations. We categorize these latest V2X architectures so as to unveil the mechanisms behind their improved performance: network availability and coverage, reliability and loss of network connectivity, large data handling and task offloading. This survey not only provides an initial understanding of the state-of-the-art advancements in the field of MEC-enabled vehicular networks, but also raises open issues and challenges that need to be addressed before enjoying the full benefits of this paradigm.}
}


@article{DBLP:journals/cn/Sciancalepore22,
	author = {Savio Sciancalepore},
	title = {{PARFAIT:} Privacy-preserving, secure, and low-delay service access
                  in fog-enabled IoT ecosystems},
	journal = {Comput. Networks},
	volume = {206},
	pages = {108799},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.108799},
	doi = {10.1016/J.COMNET.2022.108799},
	timestamp = {Fri, 13 May 2022 19:52:44 +0200},
	biburl = {https://dblp.org/rec/journals/cn/Sciancalepore22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Traditional fog-enabled IoT ecosystems always assume fully-trusted and secure fog nodes, offering computational capabilities and storage space closer to constrained IoT devices. However, such security-related assumptions can easily fall when considering the exposure of fog nodes’ location, the heterogeneity of device providers, and the ease of misuse and misconfigurations by end-users, to name a few. As a result, compromised fog nodes can stealthily steal sensitive information, such as the devices’ location, path, and private personal attributes.}
}


@article{DBLP:journals/cn/DebR22,
	author = {Raktim Deb and
                  Sudipta Roy},
	title = {A comprehensive survey of vulnerability and information security in
                  {SDN}},
	journal = {Comput. Networks},
	volume = {206},
	pages = {108802},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.108802},
	doi = {10.1016/J.COMNET.2022.108802},
	timestamp = {Mon, 28 Aug 2023 21:39:20 +0200},
	biburl = {https://dblp.org/rec/journals/cn/DebR22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {SDN changes the networking vision with an impressive thought of segregating the networking control from the data management hardware and brings new functionalities such as programmability, elasticity, flexibility, and adoption capability in the network, which are difficult to think of in traditional rigid network architecture. However, a wide range of vulnerable surfaces directly or indirectly affect the SDN-based system’s information security and launch various attacks. The paper begins with a glimpse of the advantages of SDN over the traditional network but, the findings of the research work take off the wraps regarding vulnerabilities and their consequences on information security. Consequently, the threat surfaces are exposed that exist in SDN architecture due to weak information security. In addition, the research findings also disclose other prominent issues irrespective of information security issues. The inclusion intends to ring the bell in the maximum SDN aspects and make researchers or professionals aware of current trends of SDN in the best possible way. The comprehensiveness of this work is retained by detailing every part of SDN, which helps the researchers or professionals to improve SDN structurally or functionally.}
}


@article{DBLP:journals/cn/El-ZawawyBC22,
	author = {Mohamed A. El{-}Zawawy and
                  Alessandro Brighente and
                  Mauro Conti},
	title = {{SETCAP:} Service-Based Energy-Efficient Temporal Credential Authentication
                  Protocol for Internet of Drones},
	journal = {Comput. Networks},
	volume = {206},
	pages = {108804},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.108804},
	doi = {10.1016/J.COMNET.2022.108804},
	timestamp = {Fri, 01 Apr 2022 11:23:42 +0200},
	biburl = {https://dblp.org/rec/journals/cn/El-ZawawyBC22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Internet of Drones (IoD) is a framework to set up drones networks that may serve multiple purposes, e.g., data collection. New IoD applications (such as drone assisted internet of vehicles) envision the simultaneous collection of multiple data types. Although authentication may prevent unauthorized users to access the collected data, existing authentication solutions do not distinguish between the different types of data collected by drones. Therefore, authenticated users may receive sensitive data regarding another user incurring hence in a privacy leakage.}
}


@article{DBLP:journals/cn/VasudevanTKGP22,
	author = {Vipindev Adat Vasudevan and
                  Muhammad Tayyab and
                  George P. Koudouridis and
                  Xavier Gelabert and
                  Ilias Politis},
	title = {An integrated approach for energy efficient handover and key distribution
                  protocol for secure NC-enabled small cells},
	journal = {Comput. Networks},
	volume = {206},
	pages = {108806},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.108806},
	doi = {10.1016/J.COMNET.2022.108806},
	timestamp = {Fri, 01 Apr 2022 11:23:42 +0200},
	biburl = {https://dblp.org/rec/journals/cn/VasudevanTKGP22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Future wireless networks must serve dense mobile networks with high data rates, keeping energy requirements to a possible minimum. The small cell-based network architecture and device-to-device (D2D) communication are already being considered part of 5G networks and beyond. In such environments, network coding (NC) can be employed to achieve both higher throughput and energy efficiency. However, NC-enabled systems need to address security challenges specific to NC, such as pollution attacks. All integrity schemes against pollution attacks generally require proper key distribution and management to ensure security in a mobile environment. Additionally, the mobility requirements in small cell environments are more challenging and demanding in terms of signaling overhead. This paper proposes a blockchain-assisted key distribution protocol tailored for MAC-based integrity schemes, which combined with an uplink reference signal (UL RS) handover mechanism, enables energy efficient secure NC. The performance analysis of the protocol during handover scenarios indicates its suitability for ensuring high level of security against pollution attacks in dense small cell environments with multiple adversaries being present. Furthermore, the proposed scheme achieves lower bandwidth and signaling overhead during handover compared to legacy schemes and the signaling cost reduces significantly as the communication progresses, thus enhancing the network’s cumulative energy efficiency.}
}


@article{DBLP:journals/cn/KimKH22,
	author = {Hak{-}Jin Kim and
                  Marie S. Kim and
                  Seung{-}Jae Han},
	title = {Collision-free optimal packet scheduling algorithm for multi-hop wireless
                  IoT networks},
	journal = {Comput. Networks},
	volume = {206},
	pages = {108816},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.108816},
	doi = {10.1016/J.COMNET.2022.108816},
	timestamp = {Fri, 01 Apr 2022 11:23:42 +0200},
	biburl = {https://dblp.org/rec/journals/cn/KimKH22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {One of the key challenges for the IoT (Internet of Things) evolution is the network connectivity provision to a large number of resource-limited low-cost IoT devices. To meet this challenge, various efforts have been made in today’s wireless network technologies, such as LTE eMTC, 5G NB-IoT, IEEE 802.11ah, BLE, etc. Meanwhile, most of these technologies consider multi-hop wireless relaying to extend the wireless coverage and to enhance the network transmission capacity. Despite the benefits, however, the usage of multi-hop relaying has been limited in the real world, because of the performance degradation caused by the self-interference between adjacent wireless links. In this paper, we tackle the problem of alleviating the performance degradation in the multi-hop wireless network for IoT devices. In particular, we target low cost IoT devices that are equipped with inexpensive wireless links such as WiFi, IEEE 802.15.4, and Bluetooth. Our approach is to avoid self-interference by controlling the transmission timing at each hop. More specifically, our design goal is to minimize the data delivery delay for fast IoT sensing by preventing packet collisions (i.e., collision-free transmission). Since the retransmission at the IoT devices is eliminated, buffering at the intermediate nodes is not necessary so that no extra storage is consumed at the IoT devices to store the data being relayed. We present an algorithm to produce the packet transmission schedule at each hop. We prove that our algorithm is optimal in terms of data delivery delay (i.e., minimal delay is guaranteed) while collision between transmissions is completely avoided.}
}


@article{DBLP:journals/cn/MagdyAM22,
	author = {Safaa Magdy and
                  Yasmine Abouelseoud and
                  Mervat Mikhail},
	title = {Efficient spam and phishing emails filtering based on deep learning},
	journal = {Comput. Networks},
	volume = {206},
	pages = {108826},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.108826},
	doi = {10.1016/J.COMNET.2022.108826},
	timestamp = {Tue, 21 Mar 2023 21:08:27 +0100},
	biburl = {https://dblp.org/rec/journals/cn/MagdyAM22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Nowadays, spam emails represent a severe threat to security and cause a big waste in transmission time and users’ time spent in browsing unsolicited bulk emails (UBE). This is in addition to a lot of bandwidth and large severs storage consumed by these spam emails, resulting in financial losses for organizations and annoying individual users. Another type of malicious emails is phishing emails, which aim to get sensitive information from users leading to credential theft. This forms a challenging threat in the cyberspace. Many machine learning (ML) approaches are used to classify emails as ham or spam emails. In this paper, a deep learning model is introduced that showed improvement in performance compared to state-of-the-art related studies. Three benchmark datasets are employed in our experiments, which include content-based features rather than text analysis techniques that may consume more time. Our classifier is used to discriminate between three classes for more general spam filtering. Different performance measures are used for model validation and testing. Moreover, the time consumed in both offline training and online detection stages is reported. The proposed classifier is designed with an eye on the validation accuracy achieving fast and competitive performance promoting its use in practical applications. A comparative study is presented to show that our work outperforms recent related studies.}
}


@article{DBLP:journals/cn/SicariRC22,
	author = {Sabrina Sicari and
                  Alessandra Rizzardi and
                  Alberto Coen{-}Porisini},
	title = {Security{\&}privacy issues and challenges in NoSQL databases},
	journal = {Comput. Networks},
	volume = {206},
	pages = {108828},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.108828},
	doi = {10.1016/J.COMNET.2022.108828},
	timestamp = {Mon, 28 Aug 2023 21:39:20 +0200},
	biburl = {https://dblp.org/rec/journals/cn/SicariRC22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Organizing the storing of information and data retrieval from databases is a crucial issue, which has become more critical with the spreading of cloud and Internet of Things (IoT) based applications. In fact, not only the network’s traffic has increased, but also the amount of memory and the mechanisms needed to manage the so-called Big Data efficiently. Relational databases, based on SQL, are giving way to the NoSQL ones due to their efficiency in managing the heterogeneous information gathered from IoT environments. Such data can be stored, in a distributed manner, within the IoT network’s devices or in the cloud. Hence, security and privacy concerns naturally emerge regarding access control, authentication, and authorization requirements. This paper analyzes the current state of the art of security and privacy solutions tailored to NoSQL databases, particularly Redis, Cassandra, MongoDB, and Neo4j stores. The paper also aims to shed light on current challenges and future research directions in the field databases’ security in the IoT scenario.}
}
