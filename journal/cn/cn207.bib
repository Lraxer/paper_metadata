@article{DBLP:journals/cn/AouediPB22,
	author = {Ons Aouedi and
                  Kandaraj Piamrat and
                  Dhruvjyoti Bagadthey},
	title = {Handling partially labeled network data: {A} semi-supervised approach
                  using stacked sparse autoencoder},
	journal = {Comput. Networks},
	volume = {207},
	pages = {108742},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2021.108742},
	doi = {10.1016/J.COMNET.2021.108742},
	timestamp = {Fri, 01 Apr 2022 11:23:42 +0200},
	biburl = {https://dblp.org/rec/journals/cn/AouediPB22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Network traffic analytics has become a crucial task in order to better understand and manage network resources, especially in the network softwarization era where the implementation of this concept can be done easily with network function virtualization. Currently, many approaches have been proposed to improve the performance of traffic classification. However, as new types of traffic emerge every day (and they are generally not labeled), this opens a new challenge to be handled. Moreover, the question of how to accurately classify the traffic using a limited amount of labeled data or partially labeled data is also another important concern. In fact, labeling data is often difficult and time-consuming. In order to solve the previously described issues, we reformulate traffic classification into a semi-supervised learning where both supervised learning (using labeled data) and unsupervised learning (no label data) are combined. To do so, this paper presents a stacked sparse autoencoder (SSAE) based semi-supervised deep-learning model for traffic classification. The main motivations of this approach are: (i) unlabeled data is often abundant and easily available; (ii) classification performance of the whole model can be greatly improved when a large amount of unlabeled traffic is included in the training process; (iii) there is a limit to how much human effort can be thrown at the labeling problem. To investigate the performance of our approach, an empirical study has been conducted on a real dataset and results indicate that using a large amount of unlabeled data in the SSAE pre-trained phase can improve significantly the classification performance of the whole model. Furthermore, the proposed approach is compared against other representative machine-learning and deep-learning models, which are Support Vector Machine (SVM), Decision Tree (DT), Random Forest (RF), Multi-Layer Perceptron (MLP), eXtreme Gradient Boosting (XGBoost), and Autoencoder.}
}


@article{DBLP:journals/cn/AlSabehKKCB22,
	author = {Ali AlSabeh and
                  Joseph Khoury and
                  Elie F. Kfoury and
                  Jorge Crichigno and
                  Elias Bou{-}Harb},
	title = {A survey on security applications of {P4} programmable switches and
                  a STRIDE-based vulnerability assessment},
	journal = {Comput. Networks},
	volume = {207},
	pages = {108800},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.108800},
	doi = {10.1016/J.COMNET.2022.108800},
	timestamp = {Mon, 28 Aug 2023 21:39:18 +0200},
	biburl = {https://dblp.org/rec/journals/cn/AlSabehKKCB22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The emergence of the IoT, cloud systems, data centers, and 5G networks is increasing the demand for a rapid development of new applications and protocols at all levels of the protocol stack. However, traditional fixed-function data planes have been characterized by a lengthy and costly development process at the hand of few chip manufacturers. Recently, data plane programmability has attracted significant attention, permitting network owners to run customized packet processing functions using P4, the de facto data plane programming language. Network security is one of the key research areas exploiting the capabilities of programmable switches. Examples include new encapsulations and secure tunnels implemented in short times, mitigation techniques for DDoS attacks that occur at terabit rates, customized firewalls that track hundreds of thousands of connections per second, and traffic anonymization systems that operate at line rate. Moreover, applications can be reconfigured in the field without additional hardware upgrades, facilitating the deployment of new defenses against unforeseen attacks and vulnerabilities. Furthermore, these security applications are designed by network owners who can meet their specific requirements, rather than by chip manufacturers.}
}


@article{DBLP:journals/cn/GuoZG22,
	author = {Yimin Guo and
                  Zhenfeng Zhang and
                  Yajun Guo},
	title = {SecFHome: Secure remote authentication in fog-enabled smart home environment},
	journal = {Comput. Networks},
	volume = {207},
	pages = {108818},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.108818},
	doi = {10.1016/J.COMNET.2022.108818},
	timestamp = {Fri, 01 Apr 2022 11:23:42 +0200},
	biburl = {https://dblp.org/rec/journals/cn/GuoZG22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Fog computing is the best solution for IoT applications with low latency and real-time interaction. Fog can endow smart home with many smart functions and services. One of the most important services is that users can remotely access and control smart devices. Since remote users and smart homes communicate through insecure channels, it is necessary to design a secure and effective remote authentication scheme to guarantee secure communications. The existing authentication schemes designed for smart homes have some security issues and are not suitable for fog-enabled smart home environments. Therefore, this paper designs a secure remote user authentication scheme, SecFHome. It supports secure communication at the edge of the network and remote authentication in fog-enabled smart home systems. Specifically, We present an efficient authentication mode in the fog-enabled environment, which includes the edge negotiation phase and the authentication phase. SecFHome adds updated information to the authenticator, which can verify the message synchronization simultaneously with the authentication, thus improving the authentication efficiency. In addition, SecFHome does not store sensitive information of users and smart devices in the memory of the smart gateway, which can avoid various attacks caused by the compromised gateway. The formal security proof and informal security analysis show that the SecFHome is secure and can resist known attacks. Compared with the related authentication schemes, SecFHome only needs fewer communication costs and computation costs, and achieves more security features.}
}


@article{DBLP:journals/cn/NassefSPTM22,
	author = {Omar Nassef and
                  Wenting Sun and
                  Hakimeh Purmehdi and
                  Mallik Tatipamula and
                  Toktam Mahmoodi},
	title = {A survey: Distributed Machine Learning for 5G and beyond},
	journal = {Comput. Networks},
	volume = {207},
	pages = {108820},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.108820},
	doi = {10.1016/J.COMNET.2022.108820},
	timestamp = {Fri, 13 May 2022 19:52:44 +0200},
	biburl = {https://dblp.org/rec/journals/cn/NassefSPTM22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {5\nG\nis the fifth generation of cellular networks. It enables billions of connected devices to gather and share information in real time; a key facilitator in Industrial Internet of Things (IoT) applications. It has more capabilities in terms of bandwidth, latency/delay, processing powers and flexibility to utilize either edge or cloud resources. Furthermore, 6G is expected to be equipped with the new capability to converge ubiquitous communication, computation, sensing and controlling for a variety of sectors, which heightens the complexity in a more heterogeneous environment This increased complexity, combined with energy efficiency and Service Level Agreement (SLA) requirements makes application of Machine Learning (ML) and distributed ML necessary. A decentralized approach stemming from distributed learning is a very attractive option compared with a centralized architecture for model learning and inference. Distributed ML exploits recent Artificial Intelligence (AI) technology advancements to allow collaborated ML, whilst safeguarding private data, minimizing both communication and computation overhead along with addressing ultra-low latency requirements. In this paper, we review a number of distributed ML architectures and designs, that focus on optimizing communication, computation and resource distribution. Privacy, information security and compute frameworks, are also analyzed and compared with respect to different distributed ML approaches. We summarize the major contributions and trends in this area and highlight the potential of distributed ML to help researchers and practitioners make informed decisions on selecting the right ML approach for\n5\nG\nand Beyond related AI applications. To enable distributed ML for\n5\nG\nand Beyond, communication, security, and computing platform often counter balance each other, thus, consideration and optimization of these aspects at an overall system level is crucial to realize the full potential of AI for 5G and Beyond. These different aspects do not only pertain to\n5\nG\n, but will also enable careful design of distributed machine learning architectures to circumvent the same hurdles that will inevitably burden\n5\nG\nand Beyond network generations. This is the first survey paper that brings together all these aspects for distributed ML.}
}


@article{DBLP:journals/cn/MakaremDMM22,
	author = {Nabil Makarem and
                  Wafaa Bou Diab and
                  Imad Mougharbel and
                  Naceur Malouch},
	title = {On the design of efficient congestion control for the Constrained
                  Application Protocol in IoT},
	journal = {Comput. Networks},
	volume = {207},
	pages = {108824},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.108824},
	doi = {10.1016/J.COMNET.2022.108824},
	timestamp = {Fri, 01 Apr 2022 11:23:42 +0200},
	biburl = {https://dblp.org/rec/journals/cn/MakaremDMM22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Constrained Application Protocol (CoAP) is one of the main candidates for a lightweight communication protocol for the Internet-of-Things. CoAP provides a simple congestion control mechanism based on successive retransmissions and binary exponential timeouts. This simple mechanism significantly reduces CoAP performance especially in networks with high packet loss, and thus preventing an efficient deployment of the protocol. Enhanced mechanisms for CoAP were proposed in the literature. Some considered improving retransmission timeout estimation whereas others focused on augmenting the retransmission procedure. In this work, we analyze deeply main and recent proposals to highlight their shortcomings. Then, we propose and implement two congestion control algorithms IDC-CoAP and MBC-CoAP which improve retransmission timeout estimation for congestion detection, and adopt adequately a rate-based approach for congestion counteraction, while maintaining simplicity required by constrained devices. The two proposed algorithms are evaluated by means of pure simulations considering several network scenarios, and also using the realistic environment Cooja/Contiki. All results show that our algorithms achieve a much better tradeoff between goodput, reliability and overhead.}
}


@article{DBLP:journals/cn/HuangTZW22,
	author = {Cheng Huang and
                  Aimin Tang and
                  Bangzhao Zhai and
                  Xudong Wang},
	title = {Physical layer forwarding for 5G multi-hop Backhaul networks},
	journal = {Comput. Networks},
	volume = {207},
	pages = {108830},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.108830},
	doi = {10.1016/J.COMNET.2022.108830},
	timestamp = {Mon, 26 Feb 2024 15:49:00 +0100},
	biburl = {https://dblp.org/rec/journals/cn/HuangTZW22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In 5G networks, an integrated access and backhaul network is formed to connect IAB-nodes to the core network via an IAB-donor. To support multi-hop communications in this network, an adaptation-layer forwarding mechanism has been specified in the standard. However, the end-to-end delay achieved by such a mechanism cannot satisfy the requirement of delay-sensitive traffic. To this end, a PHY-layer forwarding mechanism is designed to complement the adaptation-layer forwarding mechanism. In the PHY-layer forwarding mechanism, when a transport block (TB) is received, it is first determined whether or not the TB is forwarded at the PHY layer, based on an ingress indicator that is sent prior to the transmission of the TB. If the ingress indicator shows that the TB is to be forwarded at the PHY layer, the indicator is mapped to an egress indicator that will be sent as an ingress indicator for a certain next-hop node. The process of ingress–egress indicator mapping can be conducted in parallel with TB decoding, so it does not cause additional forwarding delay. To improve the reliability of PHY-layer forwarding, the TB is buffered until it is successfully received, which is achieved by exploiting the hybrid automatic repeat request (HARQ) mechanism of 5G new radio (NR). The end-to-end delay of the PHY-layer forwarding mechanism and the adaptation-layer forwarding mechanism are analyzed and also evaluated via simulations. Performance results show that the PHY-layer forwarding mechanism reduces the end-to-end delay by more than 40% compared with the adaptation-layer forwarding mechanism under various system parameters.}
}


@article{DBLP:journals/cn/JuniorVVG22,
	author = {Nildo dos Santos Ribeiro J{\'{u}}nior and
                  Marcos A. M. Vieira and
                  Luiz Filipe Menezes Vieira and
                  Omprakash Gnawali},
	title = {SplitPath: High throughput using multipath routing in dual-radio Wireless
                  Sensor Networks},
	journal = {Comput. Networks},
	volume = {207},
	pages = {108832},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.108832},
	doi = {10.1016/J.COMNET.2022.108832},
	timestamp = {Fri, 01 Apr 2022 11:23:42 +0200},
	biburl = {https://dblp.org/rec/journals/cn/JuniorVVG22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Dual-Radio platforms were proposed to improve the throughput of Wireless Sensor Network applications while conserving energy efficiency. However, current dual-radio protocols do not use all the hardware available. We model this problem as the minimum disjoint parity paths problem. We present the design, implementation and evaluation of SplitPath, a distributed routing protocol that computes two vertex-disjoint paths with the same parity. Unlike previous work on multipath routing, SplitPath is the first protocol to use multiple paths in dual-radio WSNs to achieve maximum throughput. The protocol was evaluated with experiments in the physical world. We compare our proposal with FastForward, the state-of-the-art protocol for dual-radio. Our approach improved the throughput by 60%, and achieved 96% of the maximum theoretical limit.}
}


@article{DBLP:journals/cn/NduwayezuY22,
	author = {Maurice Nduwayezu and
                  Ji{-}Hoon Yun},
	title = {Latency and energy aware rate maximization in MC-NOMA-based multi-access
                  edge computing: {A} two-stage deep reinforcement learning approach},
	journal = {Comput. Networks},
	volume = {207},
	pages = {108834},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.108834},
	doi = {10.1016/J.COMNET.2022.108834},
	timestamp = {Fri, 01 Apr 2022 11:23:42 +0200},
	biburl = {https://dblp.org/rec/journals/cn/NduwayezuY22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Future network services are emerging with an inevitable need for high wireless capacity along with strong computational capabilities, stringent latency and reduced energy consumption Two technologies are promising, showing potential to support these requirements: multi-access (or mobile) edge computing (MEC) and non-orthogonal multiple access (NOMA). While MEC allows users to access the abundant computing resources at the edge of the network, NOMA technology enables an increase in the density of a cellular network. However, integrating NOMA technology into MEC systems faces challenges in terms of joint offloading decisions (remote or local computation) and inter-user interference management. In this paper, with the objective of maximizing the system-wide sum computation rate under latency and energy consumption constraints, we propose a two-stage deep reinforcement learning algorithm to solve the joint problem in a multicarrier NOMA-based MEC system, in which the first-stage agent handles offloading decisions while the second-stage agent considers the offloading decisions to determine the resource block assignments for users. Simulation results show that compared with other benchmark algorithms, the proposed algorithm improves the sum computation rate while meeting the latency and energy consumption requirements, and it outperforms the approach in which a single agent handles both offloading decisions and resource block assignments due to faster convergence performance.}
}


@article{DBLP:journals/cn/ShahrakiATJ22,
	author = {Amin Shahraki and
                  Mahmoud Abbasi and
                  Amir Taherkordi and
                  Anca Delia Jurcut},
	title = {A comparative study on online machine learning techniques for network
                  traffic streams analysis},
	journal = {Comput. Networks},
	volume = {207},
	pages = {108836},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.108836},
	doi = {10.1016/J.COMNET.2022.108836},
	timestamp = {Fri, 13 May 2022 19:52:44 +0200},
	biburl = {https://dblp.org/rec/journals/cn/ShahrakiATJ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Modern networks generate a massive amount of traffic data streams. Analyzing this data is essential for various purposes, such as network resources management and cyber-security analysis. There is an urgent need for data analytic methods that can perform network data processing in an online manner based on the arrival of new data. Online machine learning (OL) techniques promise to support such type of data analytics. In this paper, we investigate and compare the OL techniques that facilitate data stream analytics in the networking domain. We also investigate the importance of traffic data analytics and highlight the advantages of online learning in this regard, as well as the challenges associated with OL-based network traffic stream analysis, e.g., concept drift and the imbalanced classes. We review the data stream processing tools and frameworks that can be used to process such data online or on-the-fly along with their pros and cons, and their integrability with de facto data processing frameworks. To explore the performance of OL techniques, we conduct an empirical evaluation on the performance of different ensemble- and tree-based algorithms for network traffic classification. Finally, the open issues and the future directions in analyzing traffic data streams are presented. This technical study presents valuable insights and outlook for the network research community when dealing with the requirements and purposes of online data streams analytics and learning in the networking domain.}
}


@article{DBLP:journals/cn/AlghafariH22,
	author = {Hadeel Alghafari and
                  Mohammad Sayad Haghighi},
	title = {Decentralized joint resource allocation and path selection in multi-hop
                  integrated access backhaul 5G networks},
	journal = {Comput. Networks},
	volume = {207},
	pages = {108837},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.108837},
	doi = {10.1016/J.COMNET.2022.108837},
	timestamp = {Sun, 06 Oct 2024 21:22:02 +0200},
	biburl = {https://dblp.org/rec/journals/cn/AlghafariH22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cell densification has recently been considered as a solution to the high bandwidth demand from the ever-increasing number of connected devices as well as the emerging bandwidth-thirsty applications in 5\u202fG networks. Ultra-dense networks suffer from backhaul bottlenecks. Wireless backhaul connections, especially in the mm-wave bands, have become attractive solutions for the backhaul bottleneck problem. The third-generation partnership project (3GPP) introduced a new Integrated Access Backhaul (IAB) study item in which the same spectral resources are dynamically used for both access and backhaul connections. In densified multi-hop topologies, especially when more than one fiber-linked node exists, it is difficult to solve the problem of resource allocation in a centralized manner. Trying to address this, we propose a distributed stochastic scheme to jointly solve the problem of resource/bandwidth allocation and path selection in a multi-hop multi-path IAB mm-wave 5\u202fG network. First, a Directed Acyclic Graph (DAG) topology formation algorithm is proposed. This algorithm does cell search and performs initial access procedures. It spreads information across child/parent links about the topology. Then, stochastic optimization tools are employed for path selection from the resource perspective. We study the efficiency of the proposed scheme in exploiting resources. Additionally, we explore the effects of stochastic information spread in the topology and also the probability levels on the performance of our scheme. Our analyses show that the proposed distributed scheme yields nearly the same performance as an optimal centralized algorithm in joint resource allocation and path selection tasks. This alternative can take the place of centralized resource management, especially in scenarios where central resource allocation is not possible. In comparison, our scheme outperforms traditional load-based resource partitioning algorithms in the allocation of resources by up to 20%. Results also show that our scheme exploits the resources similar to what an instantaneous load-based strategy does, but without the need for excessive signalings.}
}


@article{DBLP:journals/cn/MondalDW22,
	author = {Sourav Mondal and
                  Goutam Das and
                  Elaine Wong},
	title = {An Economic and Non-cooperative Load-balancing Framework among Federated
                  Cloudlets},
	journal = {Comput. Networks},
	volume = {207},
	pages = {108847},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.108847},
	doi = {10.1016/J.COMNET.2022.108847},
	timestamp = {Fri, 01 Apr 2022 11:23:42 +0200},
	biburl = {https://dblp.org/rec/journals/cn/MondalDW22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Edge computing servers like cloudlets from different service providers compensate scarce computational and storage resources of mobile devices, are distributed across access networks. However, the dynamically varying computational requirements of associated mobile devices make cloudlets either overloaded or under-loaded. Hence, load-balancing among neighboring cloudlets appears to be an essential research problem. Especially, the load-balancing problem among federated cloudlets from the same as well as different service providers for low-latency applications needs significant attention. Thus, in this paper, we propose a load-balancing framework among federated cloudlets for low-latency applications that focuses on latency bound rather than latency minimization. In this framework, we employ dynamic processor slicing for internal handling of job requests from heterogeneous classes by the cloudlets. We propose a continuous-action reinforcement learning automata-based algorithm that enables cloudlets to independently compute the load-balancing strategies against their neighboring cloudlets in a software-defined networking enabled distributed network setting without any exhaustive control message exchange. To capture the economic interaction among federated cloudlets, we model this load-balancing problem as an economic and non-cooperative game and by scaffolding the properties of the game formulation, we achieve faster convergence of the reinforcement learning automata. Furthermore, through extensive simulations, we study the impacts of exploration and exploitation on learning accuracy.}
}


@article{DBLP:journals/cn/WangTGXSGL22,
	author = {Zuyan Wang and
                  Jun Tao and
                  Yang Gao and
                  Yifan Xu and
                  Weice Sun and
                  Yu Gao and
                  Wenqiang Li},
	title = {Joint flight scheduling and task allocation for secure data collection
                  in UAV-aided IoTs},
	journal = {Comput. Networks},
	volume = {207},
	pages = {108849},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.108849},
	doi = {10.1016/J.COMNET.2022.108849},
	timestamp = {Thu, 02 Jan 2025 19:03:14 +0100},
	biburl = {https://dblp.org/rec/journals/cn/WangTGXSGL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the flexible mobility and deployment, Unmanned Aerial Vehicles (UAVs) have created a new dimension to provide data collection services for a large number of distributed wireless sensory devices. Unfortunately, the broadcast nature of wireless channels make it hard to guarantee the security of data transmission in Internet of Things (IoTs). In this paper, focusing on the scenario where potential eavesdroppers intend to intercept the data uploading of legitimate nodes, we take the advantages of the UAV technology and the physical-layer security approach to study the Secure Data Collection Problem (SDCP). We first explore the flight scheduling and task allocation, that is, determining which areas to be visited and who to be served by UAVs, to establish favorable communication channels. Then we set up the utility function with secrecy rates and non-negative budget constraints. Due to the coupling between the UAV scheduling and task allocation optimization variables in the SDCP, we construct a surrogate function to achieve decoupling and reformulate SDCP into the SDCP-m problem, which is analyzed and proved to be a nonnegative monotone submodular function subject to a general constraint. Finally, an efficient Cost–Benefit Greedy (CBG) algorithm, which is theoretically analyzed to seek the quantitative value of approximation ratio, is proposed. The simulation results show that the CBG algorithm not only outperforms benchmark algorithms in terms of the average secrecy rate and the iteration number, but also generates a nearly optimal trajectory.}
}


@article{DBLP:journals/cn/BouzidiOLB22,
	author = {E. L. Hocine Bouzidi and
                  Abdelkader Outtagarts and
                  Rami Langar and
                  Raouf Boutaba},
	title = {Dynamic clustering of software defined network switches and controller
                  placement using deep reinforcement learning},
	journal = {Comput. Networks},
	volume = {207},
	pages = {108852},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.108852},
	doi = {10.1016/J.COMNET.2022.108852},
	timestamp = {Fri, 01 Apr 2022 11:23:42 +0200},
	biburl = {https://dblp.org/rec/journals/cn/BouzidiOLB22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Software defined networking (SDN) has emerged as a promising alternative to the traditional networks, offering many advantages, including flexibility in network management, network programmability and guaranteeing application Quality-of-Service (QoS) requirements. In SDN, the control plane is separated from the data plane, and deployed as a logically centralized controller. However, due to the large scale of networks as well as latency and reliability requirements, it is necessary to deploy multiple controllers to satisfy these requirements. The distributed deployment of SDN controllers unveiled new challenges in terms of determining the number of controllers needed, their locations and the assignment of switches to controllers that minimizes flow set delay. In this context, we propose, in this paper, a new method that dynamically computes the optimal number of controllers, determines their optimal locations, and at the same time partitions the set of data plane switches into clusters and assigns them to these controllers. First, we mathematically formulate the controller placement as an optimization problem, whose objectives are to minimize the controller response time, that is the delay between the SDN controller and assigned switches, the Control Load (CL), the Intra-Cluster Delay (ICD) and the Intra-Cluster Throughput (ICT). Second, we propose a simple yet computationally efficient heuristic, called Deep Q-Network based Dynamic Clustering and Placement (DDCP), that leverages the potential of reinforcement and deep learning techniques to solve the aforementioned optimization problem. Experimental results using ONOS controller show that the proposed approach can significantly improve the network performances in terms of response time and resource utilization.}
}


@article{DBLP:journals/cn/ZhangZYHL22,
	author = {Ke Zhang and
                  Guang Zhang and
                  Xiuwu Yu and
                  Shaohua Hu and
                  Moxiao Li},
	title = {Clustering the sensor networks based on energy-aware affinity propagation},
	journal = {Comput. Networks},
	volume = {207},
	pages = {108853},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.108853},
	doi = {10.1016/J.COMNET.2022.108853},
	timestamp = {Fri, 25 Mar 2022 09:59:20 +0100},
	biburl = {https://dblp.org/rec/journals/cn/ZhangZYHL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Due to the limited energy of wireless sensor networks (WSNs), improving energy efficiency and prolonging network lifetime are the key issues of WSNs application. In this paper, we proposed a cluster routing protocol based on energy-aware affinity propagation(CAP). The CAP protocol enhances network performance from three aspects. First, an energy-aware affinity propagation clustering algorithm is proposed, which finds the optimal network clustering topology taking into account the total network energy consumption and load balancing. Second, an inter-cluster relay selection method is proposed for CH relay selection in multi-hop routing. At last, the energy threshold re-cluster scheme is applied to avoid frequent re-clustering that consumes a large amount of energy. The simulation experiments are conducted in two sink node deployment scenarios: sink external(case 1) and central(case 2) deployment. The results indicate that our proposed CAP outperforms LEACH, LEACHC, and KCE in terms of energy efficiency and network lifetime. In case 1, the first node death of the proposed CAP algorithm occurs in 1114 rounds, which is 61.4%, 64.5%, and 33.3% longer compared to LEACH, LEACHC, and KCE, respectively. In case 2, the first node death of the CAP algorithm occurs in 1372 rounds, which is 68.8%, 31.9%, and 49.8% longer compared to LEACH, LEACHC, and KCE, respectively.}
}


@article{DBLP:journals/cn/PeiCS22,
	author = {Jiahui Pei and
                  Hongbin Chen and
                  Lei Shu},
	title = {UAV-assisted connectivity enhancement algorithms for multiple isolated
                  sensor networks in agricultural Internet of Things},
	journal = {Comput. Networks},
	volume = {207},
	pages = {108854},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.108854},
	doi = {10.1016/J.COMNET.2022.108854},
	timestamp = {Fri, 01 Apr 2022 11:23:42 +0200},
	biburl = {https://dblp.org/rec/journals/cn/PeiCS22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent years, Wireless Sensor Networks (WSNs) are used in agricultural Internet of Things (IoT) to observe crop data, that has improved the output and quality of agricultural product. However, the connectivity of WSNs in agricultural IoT will encounter new challenges when a farmland is segmented into multiple isolated sub-sensor networks (MISN) due to natural environmental factors. In order to tackle this issue, a new definition of connectivity in MISN is proposed, and the Unmanned Aerial Vehicle (UAV) assisted connectivity enhancement algorithms (UCE) are designed. Our target is to minimize energy consumption of the UAV while satisfying MISN connectivity requirements. Firstly, the destination selection ant colony optimization algorithm (DSACO) and the normalized ant colony optimization algorithm (NACO) are proposed to connect all the sub-sensor networks. Through comparative analysis of them, the optimal path for the UAV to solve the above optimization problem is found. Secondly, autonomously generated optimal point ant colony optimization algorithm (AGOP) is proposed to connect non-communicable nodes within each sub-sensor network. Simulation results show that the complexity of the three algorithms is low, and they can complete the connectivity enhancement task of a large outdoor MISN with reduced energy consumption of the UAV, and the connectivity of the MISN has been significantly improved.}
}


@article{DBLP:journals/cn/TangLJWLL22,
	author = {Qiang Tang and
                  Lixin Liu and
                  Caiyan Jin and
                  Jin Wang and
                  Zhuofan Liao and
                  Yuansheng Luo},
	title = {An UAV-assisted mobile edge computing offloading strategy for minimizing
                  energy consumption},
	journal = {Comput. Networks},
	volume = {207},
	pages = {108857},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.108857},
	doi = {10.1016/J.COMNET.2022.108857},
	timestamp = {Fri, 01 Apr 2022 11:23:42 +0200},
	biburl = {https://dblp.org/rec/journals/cn/TangLJWLL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Owing to the high economic benefits, flexible deployment, and controllable maneuverability, unmanned aerial vehicles (UAVs) have been envisioned as promising and potential technologies for dispensing wireless communication services. This paper investigates a mobile edge computing (MEC) system assisted by multiple access points (APs) and an UAV, in which APs may not be able to straightly establish wireless communications with terrestrial Internet of Thing devices (IoT) due to ground signal blockage. Consequently, an UAV is dispatched as a mobile AP to serve a group of users and render the air-to-ground channel. In this scenario, we contemplate dividing the computing tasks of IoTDs into three parts: either be calculated locally, or offloaded to the UAV for processing, or accomplished on AP through relaying. This work attempts to minimize the weighted sum of communication consumption, calculation consumption, and the UAV’s flight consumption over a finite UAV mission duration by jointly optimizing calculation task allocation ratio, power distribution as well as the UAV’s trajectory. However, the resulting problem we put forward is demonstrated to be highly non-convex and challenging to solve. To tackle this issue, we decompose the original problem into two sub-problems hinging on the block coordinate descent (BCD) method. We settle the two sub-problems iteratively through the Lagrangian duality method and succession convex approximation (SCA) technique. The simulation results further reveal that the proposed approach is superior to other comparison baselines.}
}


@article{DBLP:journals/cn/ContiLPS22,
	author = {Mauro Conti and
                  Eleonora Losiouk and
                  Radha Poovendran and
                  Riccardo Spolaor},
	title = {Side-channel attacks on mobile and IoT devices for Cyber-Physical
                  systems},
	journal = {Comput. Networks},
	volume = {207},
	pages = {108858},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.108858},
	doi = {10.1016/J.COMNET.2022.108858},
	timestamp = {Tue, 07 May 2024 20:23:15 +0200},
	biburl = {https://dblp.org/rec/journals/cn/ContiLPS22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The attacks that leverage the side-channels produced by processes running on mobile and IoT devices are a concrete threat for cyber–physical systems. This special issue is focused on the most recent research work that investigates novel aspects of this topic. This editorial summarizes the contributions of the seven accepted papers for this special issue.}
}


@article{DBLP:journals/cn/Hyland-WoodJ22,
	author = {David Hyland{-}Wood and
                  Sandra Johnson},
	title = {Guest editorial: Blockchain consensus protocols},
	journal = {Comput. Networks},
	volume = {207},
	pages = {108861},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.108861},
	doi = {10.1016/J.COMNET.2022.108861},
	timestamp = {Fri, 25 Mar 2022 09:59:20 +0100},
	biburl = {https://dblp.org/rec/journals/cn/Hyland-WoodJ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}
