@article{DBLP:journals/cn/AlamKRT22,
	author = {M. M. Gowthul Alam and
                  S. Jerald Nirmal Kumar and
                  Uma Mageswari R and
                  Michael Raj TF},
	title = {An efficient {SVM} based {DEHO} classifier to detect DDoS attack in
                  cloud computing environment},
	journal = {Comput. Networks},
	volume = {215},
	pages = {109138},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109138},
	doi = {10.1016/J.COMNET.2022.109138},
	timestamp = {Sun, 02 Oct 2022 15:31:00 +0200},
	biburl = {https://dblp.org/rec/journals/cn/AlamKRT22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Distributed denial of service (DDoS) attacks is rising exponentially and creates a severe threat to security. Generally, the DDoS attack may appear uncomplicated but they are hard to prevent and considered as one of the most significant cybersecurity issues. Hence, addressing against DDoS attacks turns out to be imperative. The major goal of this paper involves the optimal detection of data samples as normal data samples and malicious/attacked data samples. This paper proposes a security algorithm against DDoS attacks by employing four significant phases namely the Database training phase, Data pre-processing phase, Feature selection phase and Classification phase. Initially, the data samples are to be trained before using it for attack detection. Later, the sample group is created for every file and the data samples are pre-processed in the data pre-processing phase. Secondly, in feature selection phase, the selected features are optimized by employing kernel principal component analysis (KPCA) to obtain optimal features. Later, in the classification phase, a support vector machine-based discrete elephant herding optimization (SVM-DEHO) classifier is utilized to detect the data sample as normal data and attacked or malicious data. Finally, the proposed approach is examined for four different databases namely NSL-KDD, UNSW-NB15, ISCX ID and CIC-IDS2017 databases respectively. The experimental analyses are performed for various simulation metrics and the outcome reveals that the detection system performances are high using SVM-DEHO approach than other approaches.}
}


@article{DBLP:journals/cn/QuBCWYL22,
	author = {Bin Qu and
                  Yan Bai and
                  Yul Chu and
                  Li{-}e Wang and
                  Feng Yu and
                  Xianxian Li},
	title = {Resource allocation for {MEC} system with multi-users resource competition
                  based on deep reinforcement learning approach},
	journal = {Comput. Networks},
	volume = {215},
	pages = {109181},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109181},
	doi = {10.1016/J.COMNET.2022.109181},
	timestamp = {Wed, 17 Apr 2024 21:37:56 +0200},
	biburl = {https://dblp.org/rec/journals/cn/QuBCWYL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Mobile edge computing (MEC) is an effective computing paradigm for mobile devices in the 5G era to reduce computing delay and energy consumption. However, in a multi-user resource competition environment, the revenue-driven behavior of edge servers will cause some users to increase delays or fail tasks. Considering this situation, we take the success rate of computation offloading as the trust value of the edge server, and build a system model from the user’s perspective, taking delay and energy consumption as the multi-objective task of joint optimization. In the optimization goal, we consider three factors: offloading delay, energy consumption, and queuing delay. Simultaneously minimizing energy consumption and delay is a contradiction problem. Therefore, we solve the problem based on the principle of reducing energy consumption as much as possible when the offload success rate (decreasing delay) is prioritized. Further, we build the problem as a Markov decision problem (MDP) with multi-factor reward value, and treat the trust value as a state of the system. Finally, we use an extended deep deterministic policy gradient (DDPG) algorithm (a DDPG algorithm with multi-objective reward) to work around this problem. Experimental results show that our proposed scheme can better reduce the delay and energy consumption in computation offloading of mobile users (MUs) significantly better than the baseline schemes. The advantages of our proposed scheme are more obvious in an environment where computing resources are tight.}
}


@article{DBLP:journals/cn/BringhentiV22,
	author = {Daniele Bringhenti and
                  Fulvio Valenza},
	title = {Optimizing distributed firewall reconfiguration transients},
	journal = {Comput. Networks},
	volume = {215},
	pages = {109183},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109183},
	doi = {10.1016/J.COMNET.2022.109183},
	timestamp = {Mon, 26 Jun 2023 20:51:10 +0200},
	biburl = {https://dblp.org/rec/journals/cn/BringhentiV22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The flexibility and dynamism brought over by softwarization for network management have increased the frequency of configuration changes. In this context, when a distributed security function is subject to a series of configuration changes, a problem that arises is the preservation of the security. The transient from the application of the first change to the last one may present unsecure temporary states, where the required security protection is missing. Establishing a safe scheduling of the configuration changes can significantly limit the number of unsecure states and decrease the time period where the network may be at risk. However, the literature challenged this problem only for centralized firewalls or SDN switches, and without applying formal methods to ensure the correctness of the computed scheduling. In order to overcome these limitations, this paper addresses the problem for distributed firewalls, aiming to satisfy the largest number of user-specified network security policies in each transient state. To this end, it proposes a formal methodology relying on the combination of three main features: automation, formal verification and optimization. This combination is achieved by pursuing a correctness-by-construction approach, based on the formulation of a Maximum Satisfiability Modulo Theories problem. A framework has been developed on the basis of this methodology, so that validation tests have been experimentally executed to assess the feasibility, efficacy and scalability of the approach.}
}


@article{DBLP:journals/cn/ZhangCCPK22,
	author = {Jiang Zhang and
                  Lillian Clark and
                  Matthew A. Clark and
                  Konstantinos Psounis and
                  Peter Kairouz},
	title = {Privacy-utility trades in crowdsourced signal map obfuscation},
	journal = {Comput. Networks},
	volume = {215},
	pages = {109187},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109187},
	doi = {10.1016/J.COMNET.2022.109187},
	timestamp = {Thu, 22 Sep 2022 19:58:37 +0200},
	biburl = {https://dblp.org/rec/journals/cn/ZhangCCPK22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cellular providers and data aggregating companies crowdsource cellular signal strength measurements from user devices to generate signal maps, which can be used to improve network performance. Recognizing that this data collection may be at odds with growing awareness of privacy concerns, we consider obfuscating such data before the data leaves the mobile device. The goal is to increase privacy such that it is difficult to recover sensitive features from the obfuscated data (e.g. user ids and user whereabouts), while still allowing network providers to use the data for improving network services (i.e. create accurate signal maps). To examine this privacy-utility tradeoff, we identify privacy and utility metrics and threat models suited to signal strength measurements. We then obfuscate the measurements using several preeminent techniques, spanning differential privacy, generative adversarial privacy, and information-theoretic privacy techniques, in order to benchmark a variety of promising obfuscation approaches and provide guidance to real-world engineers who are tasked to build signal maps that protect privacy without hurting utility. Our evaluation results, based on multiple, diverse, real-world signal map datasets, demonstrate the feasibility of concurrently achieving adequate privacy and utility, with obfuscation strategies which use the structure and intended use of datasets in their design, and target average-case, rather than worst-case, guarantees.}
}


@article{DBLP:journals/cn/CostaBCRA22,
	author = {Breno G. S. Costa and
                  Jo{\~{a}}o Bachiega Jr. and
                  Leonardo Rebou{\c{c}}as de Carvalho and
                  Michel J. F. Rosa and
                  Alet{\'{e}}ia P. F. Ara{\'{u}}jo},
	title = {Monitoring fog computing: {A} review, taxonomy and open challenges},
	journal = {Comput. Networks},
	volume = {215},
	pages = {109189},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109189},
	doi = {10.1016/J.COMNET.2022.109189},
	timestamp = {Mon, 28 Aug 2023 21:39:17 +0200},
	biburl = {https://dblp.org/rec/journals/cn/CostaBCRA22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Fog computing is a distributed paradigm that provides computational resources in the users’ vicinity. Fog orchestration is a set of functionalities that coordinate the dynamic infrastructure and manage the services to guarantee the Service Level Agreements. Monitoring is an orchestration functionality of prime importance. It is the basis for resource management actions, collecting status of resource and service and delivering updated data to the orchestrator. There are several cloud monitoring solutions and tools, but none of them comply with fog characteristics and challenges. Fog monitoring solutions are scarce, and they may not be prepared to compose an orchestration service. This paper updates the knowledge base about fog monitoring, assessing recent subjects in this context like observability, data standardization and instrumentation domains. We propose a novel taxonomy of fog monitoring solutions, supported by a systematic review of the literature. Fog monitoring proposals are analyzed and categorized by this new taxonomy, offering researchers a comprehensive overview. This work also highlights the main challenges and open research questions.}
}


@article{DBLP:journals/cn/MouawadMD22,
	author = {Mostafa Mouawad and
                  Firmin Mah and
                  Zbigniew Dziong},
	title = {RRH-Sector selection and load balancing based on {MDP} and dynamic
                  RRH-Sector-BBU mapping in {C-RAN}},
	journal = {Comput. Networks},
	volume = {215},
	pages = {109192},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109192},
	doi = {10.1016/J.COMNET.2022.109192},
	timestamp = {Sat, 17 Sep 2022 23:41:17 +0200},
	biburl = {https://dblp.org/rec/journals/cn/MouawadMD22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cloud radio access network (C-RAN) is a paradigmatic architecture that supports the tremendous increase in mobile network traffic. Despite the novel advancements that C-RAN offers, a time-varying traffic environment can cause load imbalances, resulting in inefficient resource utilization. Consequently, the network performance can degrade in terms of the blocked users, the number of unnecessary handovers, and the power consumption. This paper presents an RRH-Sector pair selection for new connections and network load-balancing framework that optimizes the network performance and operator reward without affecting the users’ Quality of Service (QoS) in C-RAN. Firstly, the proposed approach selects the best RRH-Sector pair for each new connection demand by considering the user and operator objectives jointly. This decision is based on an algorithm derived from the Markov decision process (MDP). Secondly, the load-balancing problem is addressed via optimization of the RRH-Sector-BBU dynamic mapping formulated as a linear integer-based constrained optimization problem. We compare solutions for this problem obtained by several evolutionary algorithms. Simulation results show that the proposed RRH-Sector selection scheme provides significant gains when compared with the traditional method based on the received signal strength (RSS). Furthermore, the RRH-Sector-BBU mappings obtained by the evolutionary algorithms are compared with the optimal exhaustive search method. The results show that in most cases the proposed models reach the optimum solution for the number of blocked users, the number of handovers, and the BBU power consumption.}
}


@article{DBLP:journals/cn/WuXZL22,
	author = {Fan Wu and
                  Chaonong Xu and
                  Yutong Zhu and
                  Chao Li},
	title = {Complexity of minimum uplink power scheduling with delay bound for
                  Backbone-assisted {PD-NOMA} wireless networks},
	journal = {Comput. Networks},
	volume = {215},
	pages = {109194},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109194},
	doi = {10.1016/J.COMNET.2022.109194},
	timestamp = {Mon, 28 Aug 2023 21:39:18 +0200},
	biburl = {https://dblp.org/rec/journals/cn/WuXZL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Although it has high spectrum utilization ratio, the technique of Power-Domain Non-orthogonal Multiplexing Access (PD-NOMA) has a fatal disadvantage of high power consumptions. Backbone-Assisted PD-NOMA provides a feasible way to lowering power consumptions, since scheduling flexibilities are further enhanced by sharing both decoding capabilities of wireline-connected multiple sinks and the geographical diversity of the sinks. In this paper, we study the problem of minimizing uplink power consumption sum for backbone-assisted PD-NOMA wireless networks, under the constraint of given uplink delay bound. We formulate the problem, and prove that it is NP-Complete by presenting an original reduction from the classic problem of partition into triangles, which is known to be NP-Complete. We further propose a low-complexity heuristic algorithm based on the greedy strategy that as many user equipments as possible are simultaneously scheduled in one slot, which is also the optimal for one sink scenario. The analysis based on experimental results shows that the power consumption sum achieved by the heuristic algorithm will exponentially decrease with linearly-relaxed delay bound, and besides, it is virtually very close to the optimum.}
}


@article{DBLP:journals/cn/LiSWLLKL22,
	author = {Jiahui Li and
                  Geng Sun and
                  Aimin Wang and
                  Ming Lei and
                  Shuang Liang and
                  Hui Kang and
                  Yanheng Liu},
	title = {A many-objective optimization charging scheme for wireless rechargeable
                  sensor networks via mobile charging vehicles},
	journal = {Comput. Networks},
	volume = {215},
	pages = {109196},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109196},
	doi = {10.1016/J.COMNET.2022.109196},
	timestamp = {Wed, 26 Jun 2024 19:56:33 +0200},
	biburl = {https://dblp.org/rec/journals/cn/LiSWLLKL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In wireless rechargeable sensor networks (WRSNs), the energy can be transferred from the mobile charging vehicles (MCVs) to sensor nodes via the wireless medium, so that providing a new paradigm to prolong the network lifetime. However, the network lifetime of MCV-enabled WRSNs is affected by several factors such as the charging priority of sensor nodes. Moreover, the communication protocols can dynamically affect the energy consumptions of sensor nodes, which should be taken into account. In this paper, we consider a low energy adaptive clustering hierarchy (LEACH)-based WRSNs, and formulate an MCV deployment many-objective optimization problem (MDMaOP) for replenishing energy to sensor nodes, in which the number of sensor nodes within the charging ranges of the MCVs, motion energy consumptions of the MCVs, remaining energy of the node with the least residual energy and distance between the MCVs and sensor nodes are simultaneously optimized, to prolong the network lifetime. Moreover, the formulated MDMaOP is analyzed and proven as NP-hard. Then, we propose a fast optimization approach and an accurate optimization approach to solve the formulated problem for satisfying the demands of calculation time and accuracy in different scenarios. Simulation results demonstrate that the proposed methods are effective for prolonging the network lifetime and outperform some other comparison algorithms.}
}


@article{DBLP:journals/cn/ZengCTZ22,
	author = {Hongxin Zeng and
                  Lin Cui and
                  Fung Po Tso and
                  Zhen Zhang},
	title = {Optimizing multipath {QUIC} transmission over heterogeneous paths},
	journal = {Comput. Networks},
	volume = {215},
	pages = {109198},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109198},
	doi = {10.1016/J.COMNET.2022.109198},
	timestamp = {Thu, 30 Mar 2023 22:57:26 +0200},
	biburl = {https://dblp.org/rec/journals/cn/ZengCTZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As a novel UDP-based transport protocol which supports stream multiplexing, QUIC is faster, more lightweight and flexible than TCP. With the prevalence of multi-homed devices such as smartphones with both WiFi and 4G/5G cellular connectivity, Multipath QUIC (MPQUIC) can effectively utilize multiple network interfaces (i.e., multiple paths) to improve transmission efficiency. Current MPQUIC implementation adopts the Lowest-RTT-First (LRF) scheduler which always selects the path with the lowest smoothed RTT among all available paths. However, we show that in networks with heterogeneous paths where network characteristics (e.g., RTT, loss rate) differ considerably, such scheduling scheme leads to unnecessary waiting on fast paths and bufferbloat, degrading overall transmission performance significantly. To use heterogeneous paths efficiently (i.e., to reduce the overall file transfer completion time), this paper proposes a novel scheduling mechanism that assigns data to paths with transfer simulation without causing much additional overhead. Extensive experiment results in Mininet demonstrate that the proposed scheduling mechanism can reduce the transfer completion time by up to 29.6% as compared to existing MPQUIC implementation.}
}


@article{DBLP:journals/cn/Leyva-PupoCAP22,
	author = {Irian Leyva{-}Pupo and
                  Cristina Cervell{\'{o}}{-}Pastor and
                  Christos Anagnostopoulos and
                  Dimitrios P. Pezaros},
	title = {Dynamic {UPF} placement and chaining reconfiguration in 5G networks},
	journal = {Comput. Networks},
	volume = {215},
	pages = {109200},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109200},
	doi = {10.1016/J.COMNET.2022.109200},
	timestamp = {Mon, 24 Oct 2022 20:51:28 +0200},
	biburl = {https://dblp.org/rec/journals/cn/Leyva-PupoCAP22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Network function virtualization (NFV) and multi-access edge computing (MEC) have become two crucial pillars in developing 5G and beyond networks. NFV promises cost-saving and fast revenue generation through dynamic instantiation and the scaling of virtual network functions (VNFs) according to time-varying service demands. Additionally, MEC provides considerable reductions in network response time and backhaul traffic since network functions and server applications can be deployed close to users. Nevertheless, the placement and chaining of VNFs at the network edge is challenging due to numerous aspects and attendant trade-offs. This paper addresses the problem of dynamic user plane function placement and chaining reconfiguration (UPCR) in a MEC environment to cope with user mobility while guaranteeing cost reductions and acceptable quality of service (QoS). The problem is formalized as a multi-objective integer linear programming model to minimize multiple cost components involved in the UPCR procedure. We propose a heuristic algorithm called dynamic priority and cautious UPCR (DPC-UPCR) to reduce the solution time complexity. Additionally, we devise a scheduler mechanism based on optimal stopping theory to determine the best reconfiguration time according to instantaneous values of latency violations and a pre-established QoS threshold. Our detailed simulation results evidence the efficiency of the proposed approaches. Specifically, the DPC-UPCR provides near-optimal solutions, within 15% of the optimum in the worst case, in significantly shorter times than the mathematical model. Moreover, the proposed scheduling method outperforms two scheduler baseline solutions regarding the number of reconfiguration events and QoS levels.}
}


@article{DBLP:journals/cn/GedikliKS22,
	author = {Ahmet Melih Gedikli and
                  Mehmet K{\"{o}}seoglu and
                  Sevil Sen},
	title = {Deep reinforcement learning based flexible preamble allocation for
                  {RAN} slicing in 5G networks},
	journal = {Comput. Networks},
	volume = {215},
	pages = {109202},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109202},
	doi = {10.1016/J.COMNET.2022.109202},
	timestamp = {Thu, 22 Sep 2022 19:58:37 +0200},
	biburl = {https://dblp.org/rec/journals/cn/GedikliKS22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {One of the most difficult challenges in radio access network slicing occurs in the connection establishment phase where multiple devices use a common random access channel in order to gain access to the network. It is now very well known that random access channel congestion is a serious issue in case of sporadic arrival of machine-to-machine nodes and may result in a significant delay for all nodes. Hence, random access channel resources are also needed to be allocated to different services to enable random access network slicing. In the random access channel procedure, the nodes transmit a selected preamble from a predefined set of preambles. If multiple nodes transmit the same preamble at the same random access channel opportunity, a collision occurs at the eNodeB. To isolate the one service class from others during this phase, one approach is to allocate different preamble subsets to different service classes. This research proposes an adaptive preamble subset allocation method using deep reinforcement learning. The proposed method can distribute preambles to different service classes according to their priority providing virtual isolation for service classes. The results indicate that the proposed mechanism can quickly adapt the preamble allocation according to the changing traffic demands of service classes.}
}


@article{DBLP:journals/cn/WangWHMSTC22,
	author = {Weilong Wang and
                  Yingjie Wang and
                  Yan Huang and
                  Chunxiao Mu and
                  Zice Sun and
                  Xiangrong Tong and
                  Zhipeng Cai},
	title = {Privacy protection federated learning system based on blockchain and
                  edge computing in mobile crowdsourcing},
	journal = {Comput. Networks},
	volume = {215},
	pages = {109206},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109206},
	doi = {10.1016/J.COMNET.2022.109206},
	timestamp = {Mon, 30 Jan 2023 11:14:31 +0100},
	biburl = {https://dblp.org/rec/journals/cn/WangWHMSTC22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the rapid popularization and development of the Internet of Things (IoT) and 5G networks, mobile crowdsourcing (MCS) has become an indispensable part in today’s society. However, when task participants submit tasks, they are likely to expose their data privacy and location privacy. These privacy will be maliciously attacked and exploited by attackers (external attackers and untrusted third party). With the rapid increase of MCS data throughput, traditional cloud platforms can no longer meet the huge data processing needs. To solve these problems, this paper proposes an MCS federated learning system based on Blockchain and edge computing. This paper uses federated learning as the framework of the MCS system. The system protects data privacy and location privacy by using the Double local disturbance Localized Differential Privacy (DLD-LDP) proposed in this paper. Because the sensed data exists in multiple modalities (text, video, audio, etc.), this paper uses the Multi-modal Transformer (MulT) method to merge the multi-modal data before subsequent operations. To solve the problem that the third party is untrusted, we utilize Blockchain to distribute tasks and collect models in a distributed way. A reputation calculation method (Sig-RCU) is proposed to calculate the real-time reputation of task participants. Through conducting experiments on real data sets, the effectiveness and adaptation of the proposed DLD-LDP algorithm and Sig-RCU algorithm are verified.}
}


@article{DBLP:journals/cn/RobinK22,
	author = {Debobroto Das Robin and
                  Javed I. Khan},
	title = {{P4TE:} {PISA} switch based traffic engineering in fat-tree data center
                  networks},
	journal = {Comput. Networks},
	volume = {215},
	pages = {109210},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109210},
	doi = {10.1016/J.COMNET.2022.109210},
	timestamp = {Thu, 22 Sep 2022 19:58:37 +0200},
	biburl = {https://dblp.org/rec/journals/cn/RobinK22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This work presents P4TE, an in-band traffic monitoring, load-aware packet forwarding, and flow rate controlling mechanism for traffic engineering in fat-tree topology-based data center networks using PISA switches. It achieves sub-RTT reaction time to change in network conditions, improved flow completion time, and balanced link utilization. Unlike the classical probe-based monitoring approach, P4TE uses an in-band monitoring approach to identify traffic events in the data plane. Based on these events, it re-adjusts the priorities of the paths. It uses a heuristic-based load-aware forwarding path selection mechanism to respond to changing network conditions and control the flow rate by sending feedback to the end hosts. It is implementable on emerging v1model.p4 architecture-based programmable switches and capable of maintaining the line-rate performance. Our evaluation shows that P4TE uses a small amount of resources in the PISA pipeline and achieves an improved flow completion time than ECMP and HULA.}
}


@article{DBLP:journals/cn/TuZXZQH22,
	author = {Huaqing Tu and
                  Gongming Zhao and
                  Hongli Xu and
                  Yangming Zhao and
                  Yuhang Qiu and
                  Liusheng Huang},
	title = {RoNS: Robust network function services in clouds},
	journal = {Comput. Networks},
	volume = {215},
	pages = {109212},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109212},
	doi = {10.1016/J.COMNET.2022.109212},
	timestamp = {Mon, 28 Aug 2023 21:39:19 +0200},
	biburl = {https://dblp.org/rec/journals/cn/TuZXZQH22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In multi-tenant clouds, the traffic of tenants (e.g., enterprises) needs to be processed by network functions (NFs), for security and business logic issues. Due to potential hardware failures and software errors, NFs may break down. When encountering NF failures, we should consider two critical requirements for maintaining cloud robustness: limited influence scope and fast failure recovery. Without considering these two requirements, prior works based on deploying backup NF instances may result in large influence scope and long recovery time when a failure occurs. To bridge the gap, this paper investigates how to build robust network function services (RoNS) in multi-tenant clouds. Specifically, RoNS limits the number of tenants that each NF instance will serve so as to control the influence scope of an NF failure, and schedule requests with the help of agents designed in the data plane to achieve fast failure recovery. This is however a difficult undertaking. To solve this problem, RoNS takes a two-phase approach: NF instance allocation and tenant request scheduling. For NF instance allocation, we propose an efficient algorithm with bounded approximation factors based on the randomized rounding method. For tenant request scheduling, we present a primal–dual-based algorithm with a superior competitiveness ratio to solve it. We implement RoNS on a real testbed for experimental studies and use simulations for large-scale investigation. Both experiment results and simulation results show the superior performance of the proposed algorithms compared with other alternatives. For example, RoNS can cut down the number of affected tenants by 60%, and reduce recovery delay from\n1170\nms to\n316\nms on average, compared with existing failure recovery mechanisms based on deploying backup instances.}
}


@article{DBLP:journals/cn/CiccoTCR22,
	author = {Nicola Di Cicco and
                  Federico Tonini and
                  Valentina Cacchiani and
                  Carla Raffaelli},
	title = {Optimization over time of reliable 5G-RAN with network function migrations},
	journal = {Comput. Networks},
	volume = {215},
	pages = {109216},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109216},
	doi = {10.1016/J.COMNET.2022.109216},
	timestamp = {Sun, 12 Nov 2023 02:17:57 +0100},
	biburl = {https://dblp.org/rec/journals/cn/CiccoTCR22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Resource optimization in 5G Radio Access Networks (5G-RAN) has to face the dynamics over time in networks with increasing numbers of nodes and virtual network functions. In this context, multiple objectives need to be jointly optimized, and key application requirements such as latency must be enforced. In addition, virtual network functions realizing baseband processing are subject to failures of the cloud infrastructure, requiring an additional level of reliability. Overall, this is a complex problem to solve, requiring fast algorithms to cope with dynamic networks while avoiding resource overprovisioning. This paper considers the problem of optimal virtual function placement in 5G-RAN with reliability against a single DU Hotel failure and proposes a solution that takes service dynamics into account. Firstly, the joint optimization of the total number of DU Hotels, of the RU–DU latency and of the backup DU sharing in a static traffic scenario is considered, and the DUOpt algorithm, based on Lexicographic Optimization, is proposed for solving efficiently this multi-objective problem. DUOpt splits the multi-objective problem into smaller Integer Linear Programming (ILP) subproblems that are sequentially solved, adopting for each one the most effective methodology to reduce the total execution time. The proposed DUOpt algorithm is extensively benchmarked to show its effectiveness in optimization of medium to large size networks: in particular, it is shown to greatly outperform an aggregate multi-objective approach, being able to compute optimal or close to optimal solutions for networks of several tens of nodes in computing times of a few seconds. Then, the problem is extended to a dynamic traffic scenario in which optimization is performed over time. In this context, in addition to the aforementioned objectives, the total number of network function migrations induced by multiple reoptimizations must be kept to the minimum. For solving efficiently this problem the DUMig algorithm is proposed, which extends and improves DUOpt. Reoptimization over a time horizon of one day in an illustrative dynamic traffic scenario is performed to evaluate the proposed DUMig algorithm against DUOpt, the latter being oblivious of the traffic dynamics. DUMig shows remarkable savings in the total number of migrations (above 86.1% for primary virtual functions and 83% for backup virtual functions) compared to DUOpt, while preserving near-optimal resource assignment.}
}
