@article{DBLP:journals/cn/BagnuloGMBHM23,
	author = {Marcelo Bagnulo and
                  Alberto Garc{\'{\i}}a{-}Mart{\'{\i}}nez and
                  Anna Maria Mandalari and
                  Praveen Balasubramanian and
                  Daniel Havey and
                  Gabriel Montenegro},
	title = {Design, implementation and validation of a receiver-driven less-than-best-effort
                  transport},
	journal = {Comput. Networks},
	volume = {233},
	pages = {109841},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109841},
	doi = {10.1016/J.COMNET.2023.109841},
	timestamp = {Sat, 30 Sep 2023 10:07:02 +0200},
	biburl = {https://dblp.org/rec/journals/cn/BagnuloGMBHM23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {LEDBAT++ is a congestion-control algorithm that implements a less-than-best-effort transport service. In this paper we present rLEDBAT, a purely receiver-based mechanism to implement LEDBAT++ for TCP. rLEDBAT enables a receiver to select some incoming traffic as less-than-best-effort, managing the capacity of the downlink. We describe the different mechanisms composing rLEDBAT that enable the execution of the LEDBAT++ congestion control algorithm at the receiver. We have implemented and experimentally tested rLEDBAT. We validate that the mechanisms incorporated by rLEDBAT at the receiver are indeed effective to implement a less-than-best-effort transport service at the receiver, as it performs similarly to the original sender-based LEDBAT++.}
}


@article{DBLP:journals/cn/YaoLDYZLS23,
	author = {Mingwu Yao and
                  Jiamu Liu and
                  Jing Du and
                  Dongqi Yan and
                  Yanxi Zhang and
                  Wei Liu and
                  Anthony Man{-}Cho So},
	title = {A unified flow scheduling method for time sensitive networks},
	journal = {Comput. Networks},
	volume = {233},
	pages = {109847},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109847},
	doi = {10.1016/J.COMNET.2023.109847},
	timestamp = {Wed, 07 Aug 2024 07:59:36 +0200},
	biburl = {https://dblp.org/rec/journals/cn/YaoLDYZLS23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Given the network and the time-triggered flow requests of a Time Sensitive Network (TSN), configuring the gate control lists (GCL) of IEEE 802.1Qbv for the ports of each node can be formed as a Job Shop Scheduling Problem, which is NP-hard. At present, most of the existing heuristic solutions for such problems consider scenarios where all given traffic flows can be scheduled. In order to solve the undetermined flow scheduling problem in scenarios no matter whether the flows can be scheduled or not, we propose to maximize the remaining time in conjunction with optimizing the network utilization instead of only minimizing the flowspan. Though the new problem is still NP-hard, it is a unified framework capable of covering general scenarios. On the basis of the new framework, we propose a novel Mixed initial population Genetic Algorithm (MGA) to solve the problem. Extensive simulation evaluation shows that MGA performs better and faster in different network scenarios while other methods prevails only in specific scenarios. This feature makes the method attractive in realistic TSN scheduling applications for in most cases it is hard for users to properly classifying the problem.}
}


@article{DBLP:journals/cn/LekssaysCF23,
	author = {Ahmed Lekssays and
                  Barbara Carminati and
                  Elena Ferrari},
	title = {MalCon: {A} blockchain-based malware containment framework for Internet
                  of Things},
	journal = {Comput. Networks},
	volume = {233},
	pages = {109853},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109853},
	doi = {10.1016/J.COMNET.2023.109853},
	timestamp = {Tue, 12 Nov 2024 10:12:41 +0100},
	biburl = {https://dblp.org/rec/journals/cn/LekssaysCF23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {IoT devices have become a primary medium for malware (e.g., botnets) to launch Distributed Denial of Service (DDoS) attacks. Such malware exploit low-security measures in IoT devices to spread in networks and recruit new victims. Thus, there is a need for malware countermeasures that consider both the security and operability of the network. Indeed, some IoT devices might run critical processes that do not tolerate interruptions.}
}


@article{DBLP:journals/cn/RenCYJ23,
	author = {Xiangyu Ren and
                  Lin Cai and
                  Pu Yang and
                  Jiequ Ji},
	title = {Congestion-aware delay-guaranteed scheduling and routing with renewal
                  optimization},
	journal = {Comput. Networks},
	volume = {233},
	pages = {109863},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109863},
	doi = {10.1016/J.COMNET.2023.109863},
	timestamp = {Fri, 21 Jul 2023 22:26:38 +0200},
	biburl = {https://dblp.org/rec/journals/cn/RenCYJ23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The emergence of time-critical applications imposes great challenges on traditional best-effort data networks. Such applications demand delay-guaranteed services with different granularity. In this paper, we propose a novel fully distributed approach that provides delay-guaranteed services at the packet level within an autonomous system. Specifically, we adopt priority queues with fixed buffer sizes to provide differentiated services and per-hop delay upper bound and explore path diversity in the network to achieve multiplex gain. Network congestion is a major cause of long delay. To address this issue, a virtual queue manager is deployed at each node in the network to exchange their local queue information with neighbors periodically. The exchanged queue information reflects the congestion status of the neighborhood so the nodes can avoid congested routes in making routing decisions. Given the rich control space including routing and queuing decisions, we aim at maximizing the overall network utility. Due to the randomness caused by network dynamics, we transform the utility maximization problem into renewal optimization which is solved at each node. A delay laxity-based reward function and a weighted queue time cost are designed to characterize each decision. To solve the renewal optimization problem, an algorithm named DSROpt is proposed using an iterative approach. Extensive experiments are conducted to verify the performance of the proposed solution using NS-3. Simulation results show that the proposed solution can guarantee packet-level delay while achieving significant performance improvements in goodput and network utility over the state-of-the-art.}
}


@article{DBLP:journals/cn/ZhangJJLC23,
	author = {Menghan Zhang and
                  Xianliang Jiang and
                  Guang Jin and
                  Penghui Li and
                  Haiming Chen},
	title = {CapRadar: Real-time adaptive bandwidth prediction for dynamic wireless
                  networks},
	journal = {Comput. Networks},
	volume = {233},
	pages = {109865},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109865},
	doi = {10.1016/J.COMNET.2023.109865},
	timestamp = {Fri, 21 Jul 2023 22:26:38 +0200},
	biburl = {https://dblp.org/rec/journals/cn/ZhangJJLC23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the emergence of 4G/5G cellular networks, mobile Internet is becoming increasingly popular and numerous mobile applications have emerged, which puts higher demands on the accuracy of predicting available bandwidth. However, compared to WiFi and wired networks, the links of 4G/5G cellular networks are highly dynamic, and the unstable nature of their network environments makes the bandwidth trajectories vary. Traditional bandwidth prediction models rarely consider the bandwidth characteristics of various network scenarios, and a single prediction model is difficult to be applied to all scenarios, which makes it challenging to achieve high accuracy of available bandwidth prediction. To solve the above problems, we propose a real-time bandwidth prediction method called CapRadar. The method classifies bandwidth into scenarios and matches the optimal prediction model for each type of scenario, i.e., switches the prediction model in real time according to the changes of the scenario. Specifically, we first extract the statistical characteristics of the bandwidth using statistical method, and based on the extracted characteristics, a SVM classifier is used to detect different network scenarios. After that, the best prediction model is matched for them in the algorithm library based on the scenario classification results. The experimental results show that CapRadar can reduce the root mean square error (RMSE) by about 18.9% and the mean error (MAE) by about 21.5%. For practical applications, we use a pre-trained SVM model for real-time scenario detection, and then we can dynamically switch the prediction model.}
}


@article{DBLP:journals/cn/LiWZCL23,
	author = {Chen Li and
                  Xiaoyu Wang and
                  Tongyu Zong and
                  Houwei Cao and
                  Yong Liu},
	title = {Predictive edge caching through deep mining of sequential patterns
                  in user content retrievals},
	journal = {Comput. Networks},
	volume = {233},
	pages = {109866},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109866},
	doi = {10.1016/J.COMNET.2023.109866},
	timestamp = {Tue, 23 Jul 2024 08:24:23 +0200},
	biburl = {https://dblp.org/rec/journals/cn/LiWZCL23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Edge caching plays an increasingly important role in boosting user content retrieval performance while reducing redundant network traffic. The effectiveness of caching ultimately hinges on the accuracy of predicting content popularity in the near future. However, at the network edge, content popularity can be extremely dynamic due to diverse user content retrieval behaviors and the low-degree of user multiplexing. It is challenging for the traditional reactive caching systems to keep up with the dynamic content popularity patterns. In this paper, we propose a novel Predictive Edge Caching (PEC) system that predicts the future content popularity using fine-grained learning models that mine sequential patterns in user content retrieval behaviors, and opportunistically prefetches contents predicted to be popular in the near future using idle network bandwidth. Through extensive experiments driven by real content retrieval traces, we demonstrate that PEC can adapt to highly dynamic content popularity at network edge, and significantly improve cache hit ratio and reduce user content retrieval latency over the state-of-art caching policies. More broadly, our study demonstrates that edge caching performance can be boosted by deep mining of user content retrieval behaviors.}
}


@article{DBLP:journals/cn/ZhouRXLGZ23,
	author = {Yuwen Zhou and
                  Bangbang Ren and
                  Junjie Xie and
                  Lailong Luo and
                  Deke Guo and
                  Xiaobo Zhou},
	title = {Enable the proactively load-balanced control plane for {SDN} via intelligent
                  switch-to-controller selection strategy},
	journal = {Comput. Networks},
	volume = {233},
	pages = {109867},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109867},
	doi = {10.1016/J.COMNET.2023.109867},
	timestamp = {Fri, 02 Aug 2024 08:20:03 +0200},
	biburl = {https://dblp.org/rec/journals/cn/ZhouRXLGZ23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The novelty of the software-defined network(SDN) is to separate the control plane and the data plane for easier manipulation of the network. The distributed control plane is designed to achieve more powerful computation capacity and address the single-point failure problem. However, it also poses a new challenge that how to arrange switch-controller associations effectively. The direct static configuration cannot adapt the time-varying requests from switches well, and it would result in imbalance problems on the control plane and cause long-tail latency. Thus, it is necessary to take proper actions to adjust the switch-to-controller association dynamically. Existing controller-based load balancing methods need to communicate with the switches frequently and incur not only high assumptions of the rare control channel of SDN but also high computation costs. In this paper, we provide a switch-based solution that puts Reinforcement Learning agents on all Switches (RLoS). Instead of setting static rules predefined by operators, RLoS makes each switch actively select the best controller. RLoS treats every switch as an independent agent with its own neural network and parameters. With the carefully designed training algorithm, the agents could choose their preferable controllers via their local information. The results show that even with partial observation, the RLoS still can achieve considerable improvement in the load balance among all controllers compared with those controller-based association benchmarks. Our RLoS could decrease the maximum response latency among controllers by about\n5\n%\n∼\n15\n%\nunder different scenarios on average.}
}


@article{DBLP:journals/cn/RuizVillafrancaGMGV23,
	author = {Sergio Ruiz{-}Villafranca and
                  Jos{\'{e}} Rold{\'{a}}n G{\'{o}}mez and
                  Javier Carrillo Mond{\'{e}}jar and
                  Juan Manuel Castelo G{\'{o}}mez and
                  Jos{\'{e}} Miguel Villal{\'{o}}n Mill{\'{a}}n},
	title = {A MEC-IIoT intelligent threat detector based on machine learning boosted
                  tree algorithms},
	journal = {Comput. Networks},
	volume = {233},
	pages = {109868},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109868},
	doi = {10.1016/J.COMNET.2023.109868},
	timestamp = {Mon, 15 Apr 2024 16:58:04 +0200},
	biburl = {https://dblp.org/rec/journals/cn/RuizVillafrancaGMGV23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent years, new management methods have appeared that mark the beginning of a new industrial revolution called Industry 4.0 or the Industrial Internet of Things (IIoT). IIoT brings together new emerging technologies, such as the Internet of Things (IoT), Deep Learning (DL) and Machine Learning (ML), that contribute to new applications, industrial processes and efficiency management in factories. This combination of new technologies and contexts is paired with Multi-access Edge Computing (MEC) to reduce costs through the virtualisation of networks and services. As these new paradigms increase in growth, so does the number of threats and vulnerabilities, making IIoT a very desirable target for cybercriminals. In addition, IIoT devices have certain intrinsic limitations, especially due to their limited resources, and this makes it impossible, in many cases, to detect attacks by using solutions designed for other paradigms. So it is necessary to design, implement and evaluate new solutions or adapt existing ones. Therefore, this paper proposes an intelligent threat detector based on boosted tree algorithms. Such detectors have been implemented and evaluated in an environment specifically designed to test IIoT deployments. In this way, we can learn how these algorithms, which have been successful in multiple contexts, behave in a paradigm with known constraints. The results obtained in the study show that our intelligent threat detector achieves a mean efficiency of between 95%–99% in the F1 Score metric, indicating that it is a good option for implementation in these scenarios.}
}


@article{DBLP:journals/cn/ZhangY23b,
	author = {Shengyu Zhang and
                  Kwan L. Yeung},
	title = {Efficient embedding of service function chains in space-division multiplexing
                  elastic optical networks},
	journal = {Comput. Networks},
	volume = {233},
	pages = {109869},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109869},
	doi = {10.1016/J.COMNET.2023.109869},
	timestamp = {Fri, 21 Jul 2023 22:26:38 +0200},
	biburl = {https://dblp.org/rec/journals/cn/ZhangY23b.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Virtual Network Functions (VNFs) are implemented as software instances on generic servers in Data Centers (DCs). A network service is implemented by an ordered list of VNFs, called Service Function Chain (SFC). SFC embedding decides which DC to place/instantiate a VNF, and how to route traffic through the instantiated VNFs/DCs. Benefits from its high capacity and flexibility, the Space-Division Multiplexing Elastic Optical Networks (SDM-EONs) have been proposed as a promising solution to provide connection service between DCs. In this paper, the problem of SFC embedding in SDM-EONs is studied. We first formulate an Integer Linear Programming (ILP) to minimize the Maximum Index of the Utilized Frequency Slot (MIUFS) for a given set of SFC requests. To achieve scalability, a greedy algorithm is proposed to embed SFCs separately. For each SFC, the lowest cost embedding solution can be found by enumeration would be selected for service embedding. A novel stretch algorithm is then designed to reduce the computing complexity further. The key idea is to place VNFs close to the least-cost path between the source and destination of a request. Three strategies to measure the path cost are evaluated. Simulation results show that our stretch algorithm gives the best overall performance in terms of running time, bandwidth consumption, MIUFS and request blocking probability.}
}


@article{DBLP:journals/cn/AlonsoPMJPN23,
	author = {Rodney Martinez Alonso and
                  David Plets and
                  Luc Martens and
                  Wout Joseph and
                  Ernesto Fontes Pupo and
                  Glauco Guillen Nieto},
	title = {White spaces pattern finding and inference based on machine learning
                  for multi-frequency spectrum footprints},
	journal = {Comput. Networks},
	volume = {233},
	pages = {109871},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109871},
	doi = {10.1016/J.COMNET.2023.109871},
	timestamp = {Fri, 21 Jul 2023 22:26:38 +0200},
	biburl = {https://dblp.org/rec/journals/cn/AlonsoPMJPN23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Spectrum surveys performed worldwide demonstrate that the spectrum utilization efficiency is less than 0.25. Therefore, the traditional long-term licensed spectrum allocation by regulators is not sustainable. Although dynamic spectrum access networks allow increasing the efficiency of spectrum utilization, coexistence is still a major problem. In this paper, we investigate the capability of machine learning for estimating the white space availability based on a dataset from a spectrum survey from 170 MHz to 1 GHz. In addition, we present an algorithm for minimizing the effect of hidden nodes on wrongful spectrum allocation and interference. Our optimization algorithm based on supervised machine learning allows increasing the spectrum utilization efficiency with a factor 5 (from 0.09 to 0.47) in the surveyed region. In addition, our algorithm allows decreasing the interference probability caused by the effect of hidden nodes by a factor 6, compared to the traditional distributed allocation of spectrum in Dynamic Spectrum Access networks.}
}


@article{DBLP:journals/cn/DamsgaardOMFN23,
	author = {Hans Jakob Damsgaard and
                  Aleksandr Ometov and
                  Md. Munjure Mowla and
                  Adam Flizikowski and
                  Jari Nurmi},
	title = {Approximate computing in {B5G} and 6G wireless systems: {A} survey
                  and future outlook},
	journal = {Comput. Networks},
	volume = {233},
	pages = {109872},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109872},
	doi = {10.1016/J.COMNET.2023.109872},
	timestamp = {Tue, 12 Sep 2023 07:58:35 +0200},
	biburl = {https://dblp.org/rec/journals/cn/DamsgaardOMFN23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As modern 5G systems are being deployed, researchers question whether they are sufficient for the oncoming decades of technological evolution. Growing numbers of interconnected intelligent devices put these networks under tremendous pressure, demanding their development. Paving the way for beyond 5G and 6G systems, commonly denoted by B5G herein, therefore means seeking enablers to increase efficiency from different perspectives. One novel look on this is the application of inexact computations where nine 9s reliability is not needed, for example, in non-critical mobile broadband traffic. The paradigm of Approximate Computing (AxC) focuses on such areas where constrained quality degradation results in savings that benefit the users and operators. This paper surveys the state-of-the-art publications on the intersection of AxC and B5G systems, identifying and emphasizing trends and tendencies in existing work and directions for future research. The work highlights resource allocation algorithms as particularly mesmerizing in the former, while research related to Intelligent Reflective Surfaces appears the most prominent in the latter. In both, problems are often NP-hard and, thus, only solvable using heuristics or approximations, Successive Convex Approximation and Reinforcement Learning are most frequently applied.}
}


@article{DBLP:journals/cn/LyuGS23,
	author = {Minzhao Lyu and
                  Hassan Habibi Gharakheili and
                  Vijay Sivaraman},
	title = {{PEDDA:} Practical and Effective Detection of Distributed Attacks
                  on enterprise networks via progressive multi-stage inference},
	journal = {Comput. Networks},
	volume = {233},
	pages = {109873},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109873},
	doi = {10.1016/J.COMNET.2023.109873},
	timestamp = {Fri, 21 Jul 2023 22:26:38 +0200},
	biburl = {https://dblp.org/rec/journals/cn/LyuGS23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Network attacks on enterprises are distributed in sources and versatile in patterns. However, practical solutions (firewalls) often focus on potential enterprise victims by way of coarse-grained monitoring due to their limited compute resources; thus, ineffective in detecting distributed sources and flows of network attacks. In contrast, fine-grained flow-level detection methods are impractical in handling millions of flows for large enterprises. We present PEDDA, a progressive multi-stage inference method to detect distributed attacks by leveraging dynamic controls of programmable networks. It flexibly applies inference stages, each with an orchestratable granularity, whereby packet streams are either proactively or reactively partitioned and analysed by specialised functions depending on the evolution of attacks. The granularity of each stage/function is dynamically determined by an optimisation framework subject to computing resource constraints. We prototype a proof-of-concept system consisting of three inference stages that monitors active enterprise hosts, detects and isolates those victims under attacks, and differentiates distributed sources and flows from benign ones, respectively. We evaluate the efficacy of our prototype by applying it to real traffic traces from a large enterprise network injected by DDoS attacks from a public dataset.}
}


@article{DBLP:journals/cn/NaqviHA23,
	author = {Haidlir Naqvi and
                  Muhammad Hafizhuddin Hilman and
                  Bayu Anggorojati},
	title = {Implementability improvement of deep reinforcement learning based
                  congestion control in cellular network},
	journal = {Comput. Networks},
	volume = {233},
	pages = {109874},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109874},
	doi = {10.1016/J.COMNET.2023.109874},
	timestamp = {Sat, 30 Sep 2023 10:07:04 +0200},
	biburl = {https://dblp.org/rec/journals/cn/NaqviHA23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The application of deep reinforcement learning to improve the adaptability of congestion control is promising. However, the state-of-the-art method indicates a high packet loss and requires a high CPU to handle a flow. Those hinder the implementation of deep reinforcement learning-based congestion control in the production network. Therefore, we propose modifications in the agent’s deployment design, specifically in the monitoring component, interval, and transport protocol to reduce packet loss and CPU usage. Unfortunately, those agent modifications yield a tradeoff in throughput performance. In order to compensate for the tradeoff, we re-train the policy model using ns-3 (network-simulator-3) as a gym environment and custom reward function to improve the throughput. Our work shows that the proposed method evaluated in cellular networks is able to reduce packet loss by up to 50.7\n×\n, suppress CPU (central processing unit) usage by up to 4.13\n×\n, and increase the throughput by up to 6.94%. We hope our contribution can drive the adoption of deep reinforcement learning-based congestion control to the production network.}
}


@article{DBLP:journals/cn/Satoh23,
	author = {Daisuke Satoh},
	title = {Analysis for flow termination in the decentralized and centralized
                  pre-congestion notification architecture},
	journal = {Comput. Networks},
	volume = {233},
	pages = {109876},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109876},
	doi = {10.1016/J.COMNET.2023.109876},
	timestamp = {Tue, 12 Sep 2023 07:58:35 +0200},
	biburl = {https://dblp.org/rec/journals/cn/Satoh23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper discusses decentralized and centralized pre-congestion notification (PCN)-based measured-rate flow termination (FT) in the case of a single bottleneck. The paper finds out that asynchronous measurement periods between ingress–egress aggregates (IEAs) cause overtermination in the decentralized PCN although RFC6661 states that the operation of PCN is not affected if the starting and ending times of the measurement periods for IEAs are different. Also, the paper finds that the asynchronous measurement periods can prevent a FT for one IEA from terminating enough flows in one shot. Furthermore, the paper proves that overtermination occurs in the decentralized PCN due to asynchronous measurement periods regardless of the same or different round trip time (RTT) and synchronous measurement period with different RTTs. In contrast, the centralized PCN can avoid overtermination due to effects of the asynchronous measurement periods and different RTTs.}
}


@article{DBLP:journals/cn/OliveiraV23,
	author = {Afonso Oliveira and
                  Teresa Vaz{\~{a}}o},
	title = {Towards green machine learning for resource allocation in beyond 5G
                  {RAN} slicing},
	journal = {Comput. Networks},
	volume = {233},
	pages = {109877},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109877},
	doi = {10.1016/J.COMNET.2023.109877},
	timestamp = {Mon, 05 Feb 2024 20:24:11 +0100},
	biburl = {https://dblp.org/rec/journals/cn/OliveiraV23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The new generation of mobile communications, 5G, has been rolled out. While basic features were successively implemented, more complex ones have been left aside for a new release. Such is the case of RAN slicing, which enables the division of a radio infrastructure into software-controlled logical networks. Among the technical difficulties is the radio resource allocation since slices can be attached to contract agreements with network performance targets, and the number of resources required to support the performance varies with the signal quality of the connected devices. Machine learning solutions can predict the number of radio resources needed based on the current state of the network. Our previous work, KPI-Converter, addressed this issue with densely connected neural networks. However, amid the current global energy crisis, we should focus on more green machine learning solutions that can achieve similar performance with much lower usage of computational resources. In this work, we present KPIC-Lite, a solution for resource allocation for RAN slicing that consumes 700 to 1000 times fewer resources than our previous work while performing similarly in most tested scenarios. We introduce a new asymmetric loss function that significantly boosts convergence compared to a-OMC, the state-of-the-art loss function for operator monetary costs. Another bonus compared to a-OMC is its ability to use second-order optimisers efficiently. The second-order optimiser used in our work reduced the computational resources of the solution.}
}


@article{DBLP:journals/cn/LiCZL23,
	author = {Yinlong Li and
                  Siyao Cheng and
                  Hao Zhang and
                  Jie Liu},
	title = {Dynamic adaptive workload offloading strategy in mobile edge computing
                  networks},
	journal = {Comput. Networks},
	volume = {233},
	pages = {109878},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109878},
	doi = {10.1016/J.COMNET.2023.109878},
	timestamp = {Fri, 21 Jul 2023 22:26:38 +0200},
	biburl = {https://dblp.org/rec/journals/cn/LiCZL23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the increasing popularity of mobile devices and explosive growth of task processing requirements, edge computing attracts more attention from researchers nowadays since it can improve the QoS and utilize resources of the cloudlets, including mobile devices and base stations, as much as possible. In a Mobile Edge Computing (MEC) network, the workload offloading problem is quite important since it directly influences the latency of the task processing, and many efficient algorithms have been proposed to deal with it. However, most of the existing algorithms only consider the static or quasi-static scenario, and are not suitable for a system with several fast-moving devices. Since that more and more mobile devices with high speed are involved in a MEC system, a new workload offloading strategy is required to adapt to such a dynamic scenario. In this paper, we sufficient consider the dynamic properties of a MEC system, and proposed a dynamic adaptive workload offloading algorithm based on Lyapunov theories and an FC-LSTM based schedule determining algorithm to balance the workload of different cloudlets and minimize the weighted average energy and time consumption of mobile devices. Theoretical analysis and extensive experimental results show that all the proposed algorithms achieve high performance in terms of energy consumption, convergence and latency.}
}


@article{DBLP:journals/cn/LiWXMLTZC23,
	author = {Xinhao Li and
                  Yingjie Wang and
                  Bingyi Xie and
                  Lingkang Meng and
                  Zhaowei Liu and
                  Xiangrong Tong and
                  Ao Zhou and
                  Zhipeng Cai},
	title = {Planning-based mobile crowdsourcing bidirectional multi-stage online
                  task assignment},
	journal = {Comput. Networks},
	volume = {233},
	pages = {109879},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109879},
	doi = {10.1016/J.COMNET.2023.109879},
	timestamp = {Wed, 17 Jul 2024 16:21:23 +0200},
	biburl = {https://dblp.org/rec/journals/cn/LiWXMLTZC23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the development of mobile Internet networks, Mobile CrowdSourcing (MCS) is becoming increasingly popular in online scenarios. This poses a new challenge to the task assignment mechanism in the mobile crowdsourcing system. Existing task assignment schemes are mainly platform-centric and worker-centric. The previous focuses are on the total utility, while the latter focuses on the interests of workers. In actual online scenarios, current researches are difficult to take both platform and worker wishes into consideration. In this paper, a Bidirectional Multi-Stage Online task assignment algorithm (BMSO) is proposed. It divides the task assignment process into three stages. The first stage selects tasks not only satisfy the basic Spatio-temporal constraints but also have a high acceptance value for workers by using two rounds of screening. The second stage combines price forecasting with reverse auctions, considering both of the platform’s benefits and workers’ wish. In the third stage, the workers and tasks which have not completed their assignments are assigned twice to improve the total utility. Furthermore, we solve the problem that traditional task-planning methods are unsuitable for mobile crowdsourcing scenarios. This paper proposes a Dynamic Voronoi diagram-based Task Planning algorithm (DVTP) that generates a Voronoi diagram using the real-time positions of the workers to find the most efficient task execution sequence for the workers. Finally, we conduct comprehensive experiments on real datasets. The results demonstrate our proposed BMSO algorithm achieves superior performances on total utility, running time, number of assigned tasks, and task assignment rate compared to other baseline algorithms.}
}


@article{DBLP:journals/cn/WongC23,
	author = {Kakei Wong and
                  Lin Cui},
	title = {Fine-grained {HTTP/3} prioritization via reinforcement learning},
	journal = {Comput. Networks},
	volume = {233},
	pages = {109880},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109880},
	doi = {10.1016/J.COMNET.2023.109880},
	timestamp = {Sun, 04 Aug 2024 19:48:54 +0200},
	biburl = {https://dblp.org/rec/journals/cn/WongC23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As the latest version of HTTP, HTTP/3 reduces the loading time of web pages and improves the user experience by replacing TCP and TLS with QUIC. Previous studies have already demonstrated the importance of prioritization for optimizing the performance of HTTP. By default, HTTP/3 schedules all the requests in a round-robin (RR) way on the server. However, in practice, in addition to the different characteristics of web resources, the differences and dynamic changes of network conditions and user equipment (e.g., mobile and PC) will also have a great impact on prioritization. Without considering these factors, existing prioritization schemes deployed on both clients and servers cannot always ensure optimal performance for HTTP/3. In light of the above issues, in this paper, we proposed Dynamic Resources Prioritization via Reinforcement Learning (DRP-RL) to provide fine-grained resource prioritization for HTTP/3 by considering the effects of both network and user equipment. Reinforcement learning (RL) is adopted, in which the RL agent can leverage network, user and web page information to learn the best prioritization of resources across different user groups. The HTTP/3 server is instructed to send the resources in a particular order for different clients dynamically to improve performance. DRP-RL has been implemented based on quic-go, and extensive evaluations indicate that DRP-RL minimizes 3.1%\n∼\n21.0% of First Content Paint (FCP) and saves 5.3%\n∼\n23.7% of Page Load Time (PLT) across various web pages when compared with RR.}
}


@article{DBLP:journals/cn/FangZXTW23,
	author = {Jin Fang and
                  Gongming Zhao and
                  Hongli Xu and
                  Huaqing Tu and
                  Haibo Wang},
	title = {Reveal: Robustness-aware {VNF} placement and request scheduling in
                  edge clouds},
	journal = {Comput. Networks},
	volume = {233},
	pages = {109882},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109882},
	doi = {10.1016/J.COMNET.2023.109882},
	timestamp = {Fri, 21 Jul 2023 22:26:38 +0200},
	biburl = {https://dblp.org/rec/journals/cn/FangZXTW23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the edge cloud network, service providers place virtual network functions (VNFs) in edge clouds to serve users’ requests. Thus, it is essential to consider VNF placement and request scheduling in edge clouds. Existing works often focus on minimizing request completion time or maximizing network throughput to utilize network resources and ensure users’ QoS efficiently. However, they ignore two practical factors: malicious users and failed VNFs, leading to poor network robustness. To this end, this paper studies robustness-aware VNF placement and request scheduling, named Reveal. Specifically, we limit the number of VNFs each user can access and the number of users each VNF can serve to control the influence scope of malicious users and VNF failures. Since placing VNFs is time-consuming and requests arrive dynamically, we solve this problem through two phases: robust VNF placement and assignment, and online request scheduling. For the first phase, we design an efficient knapsack-based rounding algorithm with bounded approximation factors. For online request scheduling, we propose a primal–dual based algorithm with a competitive ratio of\n1\n−\nϵ\n,\nO\n(\nlog\n1\n/\nϵ\n)\nwhere\nϵ\n∈\n(\n0\n,\n1\n)\n. Experiment and simulation results show that Reveal can achieve better performance and robustness than other alternatives.}
}


@article{DBLP:journals/cn/DoganK23,
	author = {Orkun Dogan and
                  K{\"{u}}bra Kalkan},
	title = {{SOREC:} Self-organizing and resource efficient clustered blockchain
                  network},
	journal = {Comput. Networks},
	volume = {233},
	pages = {109893},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109893},
	doi = {10.1016/J.COMNET.2023.109893},
	timestamp = {Sun, 22 Oct 2023 11:14:48 +0200},
	biburl = {https://dblp.org/rec/journals/cn/DoganK23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the emergence of Industry 4.0, the features of the technologies that are utilized in broad range of areas are obliged to change according to the new necessities. Especially, the network requirements have to be adopted accordingly in terms of efficiency, transparency, faster pay-outs and asset security. The blockchain technology promises to fulfill the requirements these key aspects of networking impose with the advantages it provides. However, the technology has certain limitations regarding its scalability and its transaction throughput rate. The advantages in security provided by blockchain comes at a cost in terms of scalability and transaction throughput rate. In this paper, a novel decentralized and distributed network architecture is presented. With its novel approach the proposed architecture aims to address these issues with network scalability and to provide an increased transaction throughput rate. Without introducing any centralization with its clusters, the proposed architecture allows the network to utilize its resources much more efficiently and effectively, which allows the participants to focus their efforts on mining, increasing the performance of the network. The architecture also proposes a novel communication handling promoting bulk communications and random workload distribution over the entire network to reduce the bottlenecking that occurs on the peers. A comparison to other state-of-the-art works, namely Bitcoin [1] and Community Clustering [2], is also presented in this paper. The comparison of the collected data shows that the proposed architecture in this paper is able to reduce the overall network latency and provide an increase in the transaction throughout of the network.}
}


@article{DBLP:journals/cn/LiHLLYMHJ23,
	author = {Qing Li and
                  He Huang and
                  Ruoyu Li and
                  Jianhui Lv and
                  Zhenhui Yuan and
                  Lianbo Ma and
                  Yi Han and
                  Yong Jiang},
	title = {A comprehensive survey on DDoS defense systems: New trends and challenges},
	journal = {Comput. Networks},
	volume = {233},
	pages = {109895},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109895},
	doi = {10.1016/J.COMNET.2023.109895},
	timestamp = {Tue, 14 Jan 2025 14:24:31 +0100},
	biburl = {https://dblp.org/rec/journals/cn/LiHLLYMHJ23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the past ten years, the source of DDoS has migrated to botnets composed of IoT devices. The scale of DDoS attacks increases dramatically with the number of IoT devices.New variants of DDoS attacks using different system vulnerabilities emerge in an endless stream. In response to this situation, researchers have made significant contributions to the field of DDoS defense by applying modern programmable network technology and network-level resource scheduling management technology. However, the existing review articles need more research on these technologies. After investigating the development trend of DDoS attacks in recent years and the new challenges caused by them, this paper classifies the new technologies that have emerged in the field of DDoS defense in the past ten years. Among them, the collaboration between domains and inter-domain resource scheduling is one of the critical challenges in designing a large-scale distributed DDoS cooperative defense system. In addition, modern programmable network technology has dramatically expanded network systems’ functional diversity and deployment flexibility. We will discuss building a defense system based on programmable networks and focus on SOTA defense solutions based on programmable switches. Finally, developing DDoS defense mechanisms with broad-spectrum detection capabilities, robustness against adversarial attacks, and cost-effective and collaborative DDoS defense mechanisms for establishing the Internet are future research directions in network security.}
}


@article{DBLP:journals/cn/NSJ23,
	author = {Pruthvi C. N. and
                  Vimala H. S. and
                  Shreyas J.},
	title = {A systematic survey on content caching in {ICN} and ICN-IoT: Challenges,
                  approaches and strategies},
	journal = {Comput. Networks},
	volume = {233},
	pages = {109896},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109896},
	doi = {10.1016/J.COMNET.2023.109896},
	timestamp = {Sat, 30 Sep 2023 10:07:04 +0200},
	biburl = {https://dblp.org/rec/journals/cn/NSJ23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Data traffic increased in recent years due to the expansion of IoT (Internet of Things) applications, and most IoT applications follow a content-oriented paradigm. The host-to-host nature of the existing internet architecture makes it inefficient for handling content distribution and information sharing. ICN (Information Centric Network) is a content-centric network that offers guaranteed solutions for data transfer between consumers and producers. ICN caching enables the caching technique in available resources, which can enhance the overall network performance by enabling users to access data within the network.}
}


@article{DBLP:journals/cn/MegiasVRCD23,
	author = {Carlos Meg{\'{\i}}as and
                  V{\'{\i}}ctor V{\'{a}}zquez and
                  Eduardo Ros and
                  Mauro Cappelli and
                  Javier D{\'{\i}}az},
	title = {Ethernet-based timing system for accelerator facilities: The {IFMIF-DONES}
                  case},
	journal = {Comput. Networks},
	volume = {233},
	pages = {109897},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109897},
	doi = {10.1016/J.COMNET.2023.109897},
	timestamp = {Sun, 06 Oct 2024 21:22:04 +0200},
	biburl = {https://dblp.org/rec/journals/cn/MegiasVRCD23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This article presents the design of a timing system for accelerator facilities, which relies on a general networking approach based on standard Ethernet protocols that keeps all the devices synchronized to a common time reference. The case of the IFMIF-DONES infrastructure is studied in detail, providing a framework for the implementation of the timing system. The network time protocol (NTP) with software timestamping and the precision time protocol (PTP) with hardware timestamping are used to synchronize devices with sub-millisecond and sub-microsecond accuracy requirements, respectively. The design also considers the utilization of IEEE 1588 high accuracy default PTP profile (PTP-HA) to provide sub-nanosecond accuracy for the most demanding components. Three different solutions for the design of the timing system are discussed in detail. The first solution considers the deployment of one time-dedicated network for each synchronization protocol, while the second one proposes the integration of the synchronization data of NTP and PTP into the networks of the facility. The third solution relies on the single distribution of PTP-HA to all the systems. The final design aims to be fully based on standard technologies and to be cost-efficient, seeking for interoperability and scalability, and minimizing the impact on other systems in the facility. An experimental setup has been implemented to evaluate and discuss the suitability of the solutions for the timing system by studying the synchronization accuracy obtained with NTP, PTP and PTP-HA under different network conditions. It includes a timing evaluation platform that tries to resemble the network architecture foreseen in the facility. The measured results revealed that PTP is the most limiting protocol for the second solution. Using the default PTP configuration, it tolerates less than 20% of maximum bandwidth utilization for symmetric bidirectional flows, and around 30% in the case of unidirectional flows (server to client or client to server), with the current setup and using switches without enabled timing support. This case study provides a better understanding of the trade-off between bandwidth utilization, synchronization accuracy and cost in these kinds of facilities.}
}


@article{DBLP:journals/cn/LiuXLXCF23,
	author = {Jing Liu and
                  Jianguo Xie and
                  Biao Liu and
                  Liwei Xu and
                  Xiaoming Chen and
                  Huamin Feng},
	title = {{SED-SGC:} {A} scalable, efficient, and distributed secure group communication
                  scheme based on superlattice {PUF}},
	journal = {Comput. Networks},
	volume = {233},
	pages = {109898},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109898},
	doi = {10.1016/J.COMNET.2023.109898},
	timestamp = {Fri, 21 Jul 2023 22:26:38 +0200},
	biburl = {https://dblp.org/rec/journals/cn/LiuXLXCF23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A critical challenge in group communication is to guarantee the authenticity, integrity, and confidentiality of sensitive data, especially in scenarios with potential and prospective massive device access, such as the Internet of Everything (IoE). This paper explores a scalable, efficient, distributed secure group communication (SED-SGC) scheme that employs superlattice Physical Unclonable Function (PUF), tree structure, and the Decision Diffie–Hellman Problem. In SED-SGC, superlattice PUF facilitates lightweight, high-security mutual authentication and key generation. The Decision Diffie–Hellman Problem and tree structure construct group key agreement and dynamic member management protocol with logarithmic complexity, achieving forward and backward secrecy. Also, we demonstrate that SED-SGC can effectively guarantee security against multiple attack methods such as collusion attacks, man-in-the-middle attacks (MITM), and impersonation attacks.}
}


@article{DBLP:journals/cn/AmadorSCU23,
	author = {Oscar Amador and
                  Ignacio Soto and
                  Mar{\'{\i}}a Calder{\'{o}}n and
                  Manuel Urue{\~{n}}a},
	title = {Studying and improving the performance of {ETSI} {ITS} contention-based
                  forwarding {(CBF)} in urban and highway scenarios: S-FoT+},
	journal = {Comput. Networks},
	volume = {233},
	pages = {109899},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109899},
	doi = {10.1016/J.COMNET.2023.109899},
	timestamp = {Tue, 07 May 2024 20:23:16 +0200},
	biburl = {https://dblp.org/rec/journals/cn/AmadorSCU23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper evaluates the performance of ETSI ITS Contention-Based Forwarding (CBF) and ETSI Simple GeoBroadcast forwarding while disseminating warning messages over a Geographical Area in highway and urban scenarios. Our experimental evaluation considers the complete ETSI ITS architecture including the Decentralized Congestion Control (DCC) mechanism. We propose an enhanced CBF mechanism, named S-FOT+, which combines several improvements to the ETSI CBF algorithm. S-FoT+ has a similar or better performance than the ETSI forwarding algorithms regarding both reliability and end-to-end delay while requiring much fewer transmissions. The improvements are equally effective and efficient in both urban and highway scenarios with large Destination Areas. Finally, we evaluate the trade-offs that stem from using multi-hop broadcast mechanisms in urban settings with smaller Destination Areas when compared to single-hop broadcast. Results show that multi-hop mechanisms significantly improve coverage at the cost of an increased number of transmissions.}
}


@article{DBLP:journals/cn/JiangYLYHWW23,
	author = {Wanchun Jiang and
                  Renfu Yao and
                  Kaiqin Liao and
                  Yulong Yan and
                  Jiawei Huang and
                  Weiping Wang and
                  Jian{-}xin Wang},
	title = {Practical periodic strategy for 40/100 Gbps Energy Efficient Ethernet},
	journal = {Comput. Networks},
	volume = {233},
	pages = {109901},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109901},
	doi = {10.1016/J.COMNET.2023.109901},
	timestamp = {Sat, 05 Aug 2023 00:02:49 +0200},
	biburl = {https://dblp.org/rec/journals/cn/JiangYLYHWW23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The 40/100 Gbps Energy Efficient Ethernet (EEE) standardized by IEEE 802.3bj contains two power saving states. Correspondingly, the strategy determining the state transitions is crucial to both the power consumption and the incurred latency of frames. However, existing strategies hardly configure proper parameters for consistent good performance of power saving under variable traffic loads in reality. To address this issue, we design Practical Periodic Strategy (PPS) for the 40/100 Gbps EEE. Specifically, PPS periodically optimizes the power saving independently in each cycle. In this way, PPS decouples the incurred latency and the energy saving. (1) It limits the incurred delay by the length of the cycle. (2) It achieves good power saving by selecting a proper low power state based on the estimated traffic load in each cycle. Moreover, PPS is practical for two reasons. First, PPS involves just one cycle length parameter, which can be set according to either the given tail latency constraint or optimized automatically according to the cost function reflecting user preference. Second, the good performance of PPS is insensitive to traffic variation, because the traffic variation is smoothed by the cycles of PPS. Extensive simulations based on NS3 confirm that PPS outperforms existing strategies under different traffic patterns.}
}


@article{DBLP:journals/cn/SedratiMO23,
	author = {Anass Sedrati and
                  Abdellatif Mezrioui and
                  Aafaf Ouaddah},
	title = {IoT-Gov: {A} structured framework for internet of things governance},
	journal = {Comput. Networks},
	volume = {233},
	pages = {109902},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109902},
	doi = {10.1016/J.COMNET.2023.109902},
	timestamp = {Thu, 20 Jul 2023 12:34:39 +0200},
	biburl = {https://dblp.org/rec/journals/cn/SedratiMO23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The rise of artificial intelligence and smart devices with decision-making capabilities has highlighted the critical need for governance in the field of IoT. Effective governance can ensure accountability, reliability, security, and privacy in the development and use of these technologies, as well as safeguard against unethical or malicious activities. Moreover, it can drive innovation and growth in the IoT and AI industries, while fostering public trust in these technologies. The objective of this paper is to propose a new governance framework for IoT, called IoT-Gov. To achieve this objective, the paper first defines the requirements for IoT governance and assesses the compatibility of existing IT and IoT governance frameworks with these requirements. The limitations of current frameworks prove the need for a new framework, and IoT-Gov is presented as a solution. The paper explains the layers and processes of the proposed framework and provides a high-level simulation of its deployment. Specifically, the paper illustrates how the proposed framework can be applied in an example scenario of access control in a smart hospital parking, enabled with Blockchain technology. Finally, the paper concludes with an exploration of potential challenges and future research directions for the framework.}
}


@article{DBLP:journals/cn/WangLZ23,
	author = {Jian Wang and
                  Jia Liu and
                  Guosheng Zhao},
	title = {Trusted user selection for fusion of multimodal cognition in self-organizing
                  pattern of mobile crowdsensing},
	journal = {Comput. Networks},
	volume = {233},
	pages = {109903},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109903},
	doi = {10.1016/J.COMNET.2023.109903},
	timestamp = {Mon, 03 Jun 2024 08:09:47 +0200},
	biburl = {https://dblp.org/rec/journals/cn/WangLZ23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Mobile Crowd Sensing is mainly aimed at registered users of the sensing platform, which inevitably has the problem of insufficient users. In addition, the existing methods mostly use single-mode data for user quality assessment. Aiming at the existing limitations, this paper proposes a trusted user selection method that integrates multimodal cognition under the self-organization pattern. Firstly, recruit users based on the group effect and center effect in social networks. Then, Convolutional Neural Network and Doc2Vec are used to extract multimodal information features and calculate the user's task achievement degree. Finally, establish the reputation similarity network by considering the interaction between users under the self-organization pattern, and select trusted users. By selecting high-quality trusted users, we can save platform expenditure and improve sensing quality. Experiments were conducted on the simulation dataset. Under the best conditions, the reputation value of the selected sensing users increased by 12%, the user utility increased by 14%, and the data quality increased by 28%.}
}


@article{DBLP:journals/cn/LiuSBDY23,
	author = {Zunyi Liu and
                  Dian Shen and
                  Jiaang Bao and
                  Fang Dong and
                  Jiong You},
	title = {DeepMetricCorr: Fast flow correlation for data center networks with
                  deep metric learning},
	journal = {Comput. Networks},
	volume = {233},
	pages = {109904},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109904},
	doi = {10.1016/J.COMNET.2023.109904},
	timestamp = {Tue, 16 Jul 2024 15:14:16 +0200},
	biburl = {https://dblp.org/rec/journals/cn/LiuSBDY23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Flow correlation is a crucial task for operators to efficiently manage data center networks, as it provides a holistic perspective of the data center network by correlating ingress flow at each network node with the corresponding egress flow on a hop-by-hop basis. Existing attempts to solve the flow correlation problem involve traditional and feature-based methods, which have major limitations in application scenarios, processing speed and accuracy in the dynamic data center network environment, especially at the presence of chains of Virtual Network Functions (VNFs). Addressing this issue, this paper proposes a novel deep neural network based flow correlation method, called DeepMetricCorr. DeepMetricCorr composes multidimensional flow statistical features, metric learning, and a channel attention mechanism to solve flow correlation problems accurately. It is featured with a lightweight design which reduces computational overhead. The experiments on real-world datasets demonstrate that DeepMetricCorr outperforms other state-of-the-art methods in correlation accuracy, especially on load balancers with an over\n2\n×\nimprovement. Furthermore, the model maintains a low latency (¡0.5 s) as the number of candidate flows increases over 8000.}
}


@article{DBLP:journals/cn/EspinLMPC23,
	author = {Jos{\'{e}} Antonio Parra Esp{\'{\i}}n and
                  Rafael Mar{\'{\i}}n L{\'{o}}pez and
                  Gabriel L{\'{o}}pez Mill{\'{a}}n and
                  Fernando Pere{\~{n}}{\'{\i}}guez{-}Garcia and
                  {\'{O}}scar C{\'{a}}novas},
	title = {SDN-based automated rekey of IPsec security associations: Design and
                  practical validations},
	journal = {Comput. Networks},
	volume = {233},
	pages = {109905},
	year = {2023},
	url = {https://doi.org/10.1016/j.comnet.2023.109905},
	doi = {10.1016/J.COMNET.2023.109905},
	timestamp = {Sun, 06 Oct 2024 21:22:03 +0200},
	biburl = {https://dblp.org/rec/journals/cn/EspinLMPC23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The standard Request for Comments (RFC) 9061 defines a framework to autonomously manage IPsec security associations (SAs) in SDN environments. The standard describes two cases: the IKE case, in which the nodes use the Internet Key Exchange (IKEv2) protocol to negotiate IPsec SAs, and the IKE-less case, in which IKEv2 is not shipped in the network devices, and the SDN controller is in charge of distributing the IPsec SAs with all the information needed to secure the communications (cryptographic material, traffic selectors, algorithms, etc.). In both cases, for security reasons, the IPsec protocol requires the periodic renovation of the keys used by the IPsec SAs in a process named rekey. The IKE case already has an automatic rekey mechanism, the IKEv2 protocol, however the IKE-less case requires the definition of a rekey method, which is implemented by the controller. The use of the IKE-less case has been recognized useful in scenarios such as datacenters, with thousands of nodes requiring the management of SAs, or Internet of Things, with constrained devices that may not have enough resources to use IKEv2. Therefore, the definition of a suitable rekey process is a keystone for the IKE-less case. This work presents the design, implementation and validation of four different algorithms to perform a rekey process in the IKE-less case from the IPsec standard, taking to account performance, security and packet loss. We have also analyzed each algorithm’s behavior in representative network scenarios based on mesh or star topologies.}
}
