@article{DBLP:journals/cn/SekaranGKRPG21,
	author = {Ramesh Sekaran and
                  Surya Narayana Goddumarri and
                  Suresh Kallam and
                  Manikandan Ramachandran and
                  Rizwan Patan and
                  Deepak Gupta},
	title = {5G Integrated Spectrum Selection and Spectrum Access using AI-based
                  Frame work for IoT based Sensor Networks},
	journal = {Comput. Networks},
	volume = {186},
	pages = {107649},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2020.107649},
	doi = {10.1016/J.COMNET.2020.107649},
	timestamp = {Tue, 07 May 2024 20:23:17 +0200},
	biburl = {https://dblp.org/rec/journals/cn/SekaranGKRPG21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The convulsive advancement of multiple-input multiple-output devices and ultra-dense networks has been extensively considered as the key facilitators that ease the evolution and formation of 5G systems. The explosive growth of wireless devices necessitates the deployment of the Internet of Things (IoT), which is the potential of interconnecting diversified things using wireless communications. To enable wireless accesses of IoT devices, Artificial Intelligence (AI) plays a significant role in 5G network. While existing end-to-end learning and adaptive model require continuous monitoring and dynamic changes cannot achieve global optimization due to wireless signal classifiers and a higher amount of interference. In this work, an integrated spectrum selection and spectrum access using a greedy and AI-based framework to allow the forthcoming and subsequent demands on 5G and beyond is presented. Fractional Knapsack Greedy-based strategy is introduced, and Langrange Hyperplane-based approach is utilized to realize the AI-based strategies for spectrum selection and spectrum allocation for IoT-enabled sensor networks. This framework is called as Fractional Knapsack and Langrange Hyperplane Spectrum Access (FK-LHSA). First Fractional Knapsack Multi-band spectrum selection (FKMSS) model is designed along with an energy consumption model to optimize channel or spectrum throughput. Next, a Lagrange Hyperplane (LH) spectrum access model is designed to minimize spectrum access delay and improve spectrum access accuracy. The simulation results show that the proposed FKM model and LH model can effectively reduce the spectrum access delay along with the improvement of throughput and spectrum access accuracy.}
}


@article{DBLP:journals/cn/HaileGFHB21,
	author = {Habtegebreil Haile and
                  Karl{-}Johan Grinnemo and
                  Simone Ferlin and
                  Per Hurtig and
                  Anna Brunstr{\"{o}}m},
	title = {End-to-end congestion control approaches for high throughput and low
                  delay in 4G/5G cellular networks},
	journal = {Comput. Networks},
	volume = {186},
	pages = {107692},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2020.107692},
	doi = {10.1016/J.COMNET.2020.107692},
	timestamp = {Fri, 14 May 2021 08:32:00 +0200},
	biburl = {https://dblp.org/rec/journals/cn/HaileGFHB21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cellular networks have evolved to support high peak bitrates with low loss rates as observed by the higher layers. However, applications and services running over cellular networks are now facing other difficult congestion-related challenges, most notably a highly variable link capacity and bufferbloat. To overcome these issues and improve performance of network traffic in 4G/5G cellular networks, a number of in-network and end-to-end solutions have been proposed. Fairness between interacting congestion control algorithms (CCAs) has played an important role in the type of CCAs considered for research and deployment. The placement of content closer to the user and the allocation of per-user queues in cellular networks has increased the likelihood of a cellular access bottleneck and reduced the extent of flow interaction between multiple users. This has resulted in renewed interest in end-to-end CCAs for cellular networks by opening up room for research and exploration. In this work, we present end-to-end CCAs that target a high throughput and a low latency over highly variable network links, and classify them according to the way they address the congestion control. The work also discusses the deployability of the algorithms. In addition, we provide insights into possible future research directions, such as coping with a higher degree of variability, interaction of CCAs in a shared bottleneck, and avenues for synergized research, such as CCAs assisted by software defined networking and network function virtualization. We hope that this work will serve as a starting point for systematically navigating through the expanding number of cellular CCAs.}
}


@article{DBLP:journals/cn/AlGhadhban21,
	author = {Amer AlGhadhban},
	title = {F4Tele: {FSO} for data center network management and packet telemetry},
	journal = {Comput. Networks},
	volume = {186},
	pages = {107711},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2020.107711},
	doi = {10.1016/J.COMNET.2020.107711},
	timestamp = {Tue, 09 Feb 2021 15:29:32 +0100},
	biburl = {https://dblp.org/rec/journals/cn/AlGhadhban21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The proliferation of bandwidth-hungry applications and services forces datacenter (DC) administrators to optimize the utilization of available resources. Precisely, the network share of management traffic (NMT) has grown significantly because DC networks are becoming more sophisticated and require a massive amount of data for efficient debugging and troubleshooting. Accordingly, we use free space optics communication (FSO) with wavelength division multiplexing (WDM) technology to build a flexible yet high-performance logical network responsible for NMT. The FSO-WDM can provide reconfigurable multi-terabit topology over indirect line-of-sight (LoS) links. Due to space and processing capacity reasons, we cannot offer direct connections from every NMT source to the network management cluster. Alternatively, the NMT sources are grouped together as each group is serviced for a duration of time matches its average arrival-rate. Since the NMT sources showed different arrival-rates, the hotspot racks are allocated with longer service time. The evaluation results show that F4Tele carried out a throughput 72% of the expensive solution (benchmark).}
}


@article{DBLP:journals/cn/FujitaHO21,
	author = {Risa Fujita and
                  Fujun He and
                  Eiji Oki},
	title = {Shared backup resource assignment for middleboxes considering server
                  protection capabilities},
	journal = {Comput. Networks},
	volume = {186},
	pages = {107734},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2020.107734},
	doi = {10.1016/J.COMNET.2020.107734},
	timestamp = {Tue, 09 Feb 2021 15:29:32 +0100},
	biburl = {https://dblp.org/rec/journals/cn/FujitaHO21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Middleboxes provide a wide range of functions and realize the network. If network functions fail and cannot be recovered, network services which utilize them cannot continue. In order to improve survival probabilities of functions, this paper presents six strategies which obtain an assignment of backup servers to network functions. Backup servers have capabilities of protecting functions and recovering some of them. In the previous work, the range of server capabilities, where an assignment can be obtained, is limited. By adopting the idea of temporarily dividing each server into a set of small servers, we expand the range of server capabilities in the first two strategies. We also consider the applicability of one of the first two strategies through deriving three theorems. Furthermore, in the last four strategies, we enable to obtain an assignment without any limitation of server capabilities by utilizing the knowledge of the first two strategies. To compare our strategies, we also provide a baseline strategy, which is a greedy algorithm and try to balance burden of each server. The numerical results show that in all the settings, more than one of our strategies provides the higher survival probability than the baseline strategy within an allowable computation time.}
}


@article{DBLP:journals/cn/TriantafyllouSL21,
	author = {Anna Triantafyllou and
                  Panagiotis G. Sarigiannidis and
                  Thomas Lagkas and
                  Ioannis D. Moscholios and
                  Antonios Sarigiannidis},
	title = {Leveraging fairness in LoRaWAN: {A} novel scheduling scheme for collision
                  avoidance},
	journal = {Comput. Networks},
	volume = {186},
	pages = {107735},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2020.107735},
	doi = {10.1016/J.COMNET.2020.107735},
	timestamp = {Thu, 11 Feb 2021 11:53:38 +0100},
	biburl = {https://dblp.org/rec/journals/cn/TriantafyllouSL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The employment of Low-Power Wide Area Networks (LPWANs) has proven quite beneficial to the advancement of the Internet of Things (IoT) paradigm. The utilization of low power but long range communication links of the LoRaWAN technology promises low energy consumption, while ensuring sufficient throughput. However, due to LoRa’s original scheduling process there is a high chance of packet collisions, compromising the technology’s reliability. In this paper, we propose a new Medium Access Control (MAC) protocol, entitled the FCA-LoRa leveraging fairness and improving collision avoidance in LoRa wide-area networks. The novel scheduling process that is introduced is based on the broadcasting of beacon frames by the network’s gateway in order to synchronize communication with end devices. Our results demonstrate the benefits of FCA-LoRa over an enhanced version of the legacy LoRaWAN employing the ALOHA protocol and an advanced adaptive rate mechanism, in terms of throughput and collision avoidance. Indicatively, in a single gateway scenario with 600 nodes, FCA-LoRa can increase throughput by nearly 50% while in a multiple gateway scenario, throughput reaches an increase of 49% for 500 nodes.}
}


@article{DBLP:journals/cn/Balasubramanian21,
	author = {Venkatraman Balasubramanian and
                  Moayad Aloqaily and
                  Martin Reisslein},
	title = {An {SDN} architecture for time sensitive industrial IoT},
	journal = {Comput. Networks},
	volume = {186},
	pages = {107739},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2020.107739},
	doi = {10.1016/J.COMNET.2020.107739},
	timestamp = {Thu, 11 Feb 2021 11:53:38 +0100},
	biburl = {https://dblp.org/rec/journals/cn/Balasubramanian21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Industrial Internet of Things (IoT) applications have diverse network session requirements. Certain critical applications, such as emergency alert relay, industrial floor evacuation, and surveillance systems, require fresh updates that can maintain the most recently delivered packets. This requires high reconfigurability to an extent where the system can measure the impact of an event and adapt the network accordingly. Several approaches have been proposed that provide high precision transmission and bounded latencies. One prominent solution strategy in the literature is based on Software Defined Networking (SDN) control to resolve latency-related issues, such as congestion, for factory floor transmissions. The OpenFlow protocol is a key interface used in SDN to create a low-latency environment. However, the existing approaches provide only offline solutions that are typically compute intensive. Therefore, this article proposes an algorithm based on simple online strategies that utilize an SDN controller with a global view of the network. More specifically, within the context of the IEEE Time Sensitive Networking (TSN) standards this article: (1) designs a control policy framework called TSNu that guarantees transmission time-slot allocations for Scheduled Traffic while mitigating network congestion, (2) develops a utility maximization approach to jointly optimize scheduling, routing, and admission control while ensuring network stability and maximizing the flow admission to the network, and (3) presents extensive theoretical analysis and simulation to evaluate the proposed TSNu design. The conducted evaluations indicate substantially improved performance compared with state-of-the-art policies.}
}


@article{DBLP:journals/cn/ChenHXWZP21,
	author = {Chen Chen and
                  Qiang Hui and
                  Wenxuan Xie and
                  Shaohua Wan and
                  Yang Zhou and
                  Qingqi Pei},
	title = {Convolutional Neural Networks for forecasting flood process in Internet-of-Things
                  enabled smart city},
	journal = {Comput. Networks},
	volume = {186},
	pages = {107744},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2020.107744},
	doi = {10.1016/J.COMNET.2020.107744},
	timestamp = {Sat, 30 Sep 2023 10:07:02 +0200},
	biburl = {https://dblp.org/rec/journals/cn/ChenHXWZP21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the advancement of water conservancy informatization based on Internet of Things (IoT), the hydrological data are increasingly enriched. As a result, more and more algorithms and methods relying on deep learning are introduced in the flood forecasting. Considering the ability of deep learning on complex features extraction, we proposed a flood process forecasting model based on Convolution Neural Network (CNN) with two-dimension (2D) convolutional operation. At first, we imported the rainfall spatial–temporal features by gridding the Xixian basin. After that, we processed the data from Digital Elevation Model (DEM) as the geographical feature and employed the historical streamflow process of Xixian basin as the trend feature. Next, extensive experiments were implemented to determine the optimal hyper-parameters of the proposed CNN flood process forecasting model. Numerical results show that our proposed model demonstrated a better accuracy for predicting the flood peak and arrival occasion, with a 24-hour and 36-hour lead time respectively.}
}


@article{DBLP:journals/cn/RamirezLTH21,
	author = {Pedro Luis Gonzalez Ramirez and
                  Jaime Lloret and
                  Jes{\'{u}}s Tom{\'{a}}s and
                  Mikel Hurtado},
	title = {IoT-networks group-based model that uses {AI} for workgroup allocation},
	journal = {Comput. Networks},
	volume = {186},
	pages = {107745},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2020.107745},
	doi = {10.1016/J.COMNET.2020.107745},
	timestamp = {Sat, 30 Sep 2023 10:07:04 +0200},
	biburl = {https://dblp.org/rec/journals/cn/RamirezLTH21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper presents a centralized management architecture model for designing workgroup-based Internet of Things (IoT) and Internet of Everything (IoE) networks. The architecture establishes the organization of an object according to its functions and capacities in layers. From its model, it is derived the design of the algorithms that give the network operation. These algorithms include the multi-protocol communication and interconnectivity algorithm, the routing algorithm, the resource sharing algorithm, and the grouping algorithm, all controlled by Artificial Intelligence (AI). The grouping algorithm consists of creating collaborative workgroups based on Machine Learning (ML) techniques that use the objects’ features to allocating these within a workgroup that attends a type of service and within an architecture layer according to its capabilities. The model was tested with a simulation that shows the Machine-to-Machine (M2M) interaction between the devices involved in providing a service to a user within a Smart Home. This simulation uses an AI hosted within an IoT-Gateway to collect data on the features that define a connected object's functions and services. The extraction of the features is done using the Discovery of Functions and Services Protocol (DFSP) transported through an IoT-Protocol. With this information, the AI assigns a layer and a workgroup to a new object when it enters the network. The result of these tests can be used to know which ML technique has better accuracy.}
}


@article{DBLP:journals/cn/NetoSSNI21,
	author = {Emidio P. Neto and
                  Felipe Sampaio Dantas da Silva and
                  Lucas M. Schneider and
                  Augusto Jos{\'{e}} Ven{\^{a}}ncio Neto and
                  Roger Immich},
	title = {Seamless {MANO} of multi-vendor {SDN} controllers across federated
                  multi-domains},
	journal = {Comput. Networks},
	volume = {186},
	pages = {107752},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2020.107752},
	doi = {10.1016/J.COMNET.2020.107752},
	timestamp = {Fri, 19 Feb 2021 11:41:40 +0100},
	biburl = {https://dblp.org/rec/journals/cn/NetoSSNI21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The upcoming 5G networks promise to provide end-to-end network service delivery that spans across Cloud-Network federated multi-domains while providing monolithic service guarantees. By adopting a Cloud-Network federated multi-domain approach, heterogeneity raises a number of challenging Management and Orchestration (MANO) perspectives, especially concerning the need to deal with SDN controllers of multi-vendor approaches that lack a standard Northbound API. In this work, we tackle the issue of providing a seamless MANO of SDN Controllers running in Cloud-Network federated multi-domains. Owing to the weaknesses and limitations of the related works, we propose the WAN Infrastructure Manager Agnostic (WIMA) that enables a seamless and vendor-agnostic MANO abstraction to run on top of federated SDN multi-domains. The WIMA provides a common Northbound API for external triggering, maintains a global topology view of the federation as a whole, and deals with each SDN Controller directly by deploying an ontology-based scheme for efficient Northbound API mapping. The effectiveness and performance impact of WIMA was assessed in an emulated testbed with homogeneous (“Hom”) and heterogeneous (“Het”) multi-domain SDN control-planes, along with a varying density of active Tenants which simultaneously makes flow stress data connections during an experimental time of 900 s. The obtained results reveal that WIMA’s MANO abstraction system is able to connect around 52.66% (“Het”) and 86.87% (“Hom”) more end-to-end data flows across the federated SDN multi-domains while adding greater agility 52.72% (“Het”) and 85.27% (“Hom”) than the rival Baseline solution. Thus, the WIMA’s central logic has proven to be a suitable and feasible means of ensuring the MANO framework’s efficiency atop the multi-domain SDN Controllers within a Cloud-Network federation while optimizing the operation time.}
}


@article{DBLP:journals/cn/Choudhury21,
	author = {Hiten Choudhury},
	title = {HashXor: {A} lightweight scheme for identity privacy of IoT devices
                  in 5G mobile network},
	journal = {Comput. Networks},
	volume = {186},
	pages = {107753},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2020.107753},
	doi = {10.1016/J.COMNET.2020.107753},
	timestamp = {Thu, 11 Feb 2021 11:53:38 +0100},
	biburl = {https://dblp.org/rec/journals/cn/Choudhury21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Mobile networks are set to play a crucial role as backbone network in IoT deployments due to their low cost, broad coverage, high bandwidth, and low latency. However, a challenging security issue prevalent in mobile networks across the various generations including 4G, is identity privacy. In a recent standard for 5G mobile network: 3GPP TS 33.501, an Elliptic Curve Integrated Encryption Scheme (ECIES) is adopted to tackle this issue. While this mechanism seems to provide a reasonable solution for modern smart phones, it may not be best suitable for resource constrained IoT devices because of the computationally intensive calculations involved in elliptic curve cryptography. In this paper, an alternative lightweight scheme for identity privacy of IoT devices in 5G mobile network is proposed. This new scheme called ‘HashXor’ requires only two Hash operations and three Xor operations for the IoT device to achieve its objective. The scheme is found safe and logically correct through security analysis and formal analysis (using AVISPA tool). Through an execution time analysis in the ATmega328P microchip, the scheme is found to be computationally efficient compared to ECIES and few other recent proposals in this area.}
}


@article{DBLP:journals/cn/MajumdarD21,
	author = {Prasanta Majumdar and
                  Tanmay De},
	title = {A non-backtracking spectrum allocation algorithm in a large {EON}
                  under dynamic traffic grooming},
	journal = {Comput. Networks},
	volume = {186},
	pages = {107757},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2020.107757},
	doi = {10.1016/J.COMNET.2020.107757},
	timestamp = {Tue, 09 Feb 2021 15:29:32 +0100},
	biburl = {https://dblp.org/rec/journals/cn/MajumdarD21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the recent years, the elasticity implemented in an optical spectrum domain is found to be one of the key aspects under optical fiber communication technology. Here, the Orthogonal Frequency Division Multiplexing\n(\nO\nF\nD\nM\n)\nimplemented by re-configurable optical add–drop multiplexors\n(\nR\nO\nA\nD\nM\ns\n)\nand bandwidth variable Wavelength Selective Switches\n(\nW\nS\nS\ns\n)\ntogether is the emergent technology that facilitate the elasticity. However, the spectrum allocation process retaining Spectrum Continuity Constraints (\nS\nC\nC\n) is one of the major aspects in data communication methodology under\nE\nO\nN\n(Elastic Optical Network). In this regard, it is worth mentioning that the backtracking spectrum allocation algorithms are inevitably applied in an\nE\nO\nN\nwhich is inherently exempted from spectrum conversion facility. In this study, various aspects of spectrum allocation strategies are considered and an innovative idea (best of our knowledge and belief) — A non-backtracking spectrum allocation (\nN\nB\nS\nA\n) algorithm is developed and applied in an\nE\nO\nN\nwell equipped by spectrum converters as well. The prime objective of this algorithm is to increase the network throughput with less spectrum allocation time in comparison to the traditional backtracking spectrum allocation algorithms. Moreover, to investigate the efficiency of the proposed algorithm,\nE\nO\nN\nof various sizes are considered and comparison measurements are done to the traditional backtracking algorithm. Here, an important and subtle observation in algorithmic efficiency is noted along with the increasing size of the networks.}
}


@article{DBLP:journals/cn/JradiSNMP21,
	author = {Hassan Jradi and
                  Abed Ellatif Samhat and
                  Fabienne Nouvel and
                  Mohamad Mrou{\'{e}} and
                  Jean{-}Christophe Pr{\'{e}}votet},
	title = {Overview of the mobility related security challenges in LPWANs},
	journal = {Comput. Networks},
	volume = {186},
	pages = {107761},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2020.107761},
	doi = {10.1016/J.COMNET.2020.107761},
	timestamp = {Mon, 05 Feb 2024 20:24:12 +0100},
	biburl = {https://dblp.org/rec/journals/cn/JradiSNMP21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Internet of Things (IoT) is a new emerging system of interconnected devices that experiences significant growth in a wide variety of applications. The rising communication technologies for IoT are the Low Power Wide Area Networks (LPWANs) having long range, low cost and low power characteristics. In this context, an important part of the applications requires the mobility of the end devices with secure communications. In this paper, we consider the mobility management solutions in LPWAN networks and we investigate how they ensure security. We first review the basic IoT security requirements and the typical IoT protocol stack. We then focus on the existing mobility management solutions in LPWAN and we highlight the mobility related security issues by checking the attacks that can be performed in case of mobility. Furthermore, we evaluate the security in each mobility solution by checking the aforementioned attacks and we draw a comparison study.}
}


@article{DBLP:journals/cn/TanSZLZMLL21,
	author = {Li{-}Zhuang Tan and
                  Wei Su and
                  Wei Zhang and
                  Jianhui Lv and
                  Zhenyi Zhang and
                  Jingying Miao and
                  Xiaoxi Liu and
                  Na Li},
	title = {In-band Network Telemetry: {A} Survey},
	journal = {Comput. Networks},
	volume = {186},
	pages = {107763},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2020.107763},
	doi = {10.1016/J.COMNET.2020.107763},
	timestamp = {Tue, 12 Jul 2022 19:29:11 +0200},
	biburl = {https://dblp.org/rec/journals/cn/TanSZLZMLL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the development of software-defined network and programmable data-plane technology, in-band network telemetry has emerged. In-band network telemetry technology collects hop-by-hop network status information through business packets to achieve end-to-end visualization of network services. In-band network telemetry uses the data plane to directly drive the network measurement process, subverting the research idea of traditional network measurement that treats network switching device as an intermediate black box. In-band network telemetry technology has the advantages of flexible programming, strong real-time, less noise and path-level network status perception, etc. It has become an emerging representative of network telemetry technology and has received extensive attention from academia and industry.}
}


@article{DBLP:journals/cn/TalatiVKT21,
	author = {Shreya Talati and
                  Darshan Vekaria and
                  Aparna Kumari and
                  Sudeep Tanwar},
	title = {An AI-driven object segmentation and speed control scheme for autonomous
                  moving platforms},
	journal = {Comput. Networks},
	volume = {186},
	pages = {107783},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2020.107783},
	doi = {10.1016/J.COMNET.2020.107783},
	timestamp = {Thu, 11 Feb 2021 11:53:38 +0100},
	biburl = {https://dblp.org/rec/journals/cn/TalatiVKT21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent times, Autonomous Moving Platforms (AMP) have been a vital component for various industrial sectors across the globe as they include a diverse set of aerial, marine, and land-based vehicles. The emergence and the rise of AMP necessitate a precise object-level understanding of the environment, which directly impacts the functioning like decision making, speed control, and direction of the autonomous driving vehicles. Obstacle detection and object classification are the key issues in the AMP. The autonomous vehicle is designed to move in the city roads and it should be bolstered with high-quality object detection/segmentation mechanisms since inaccurate movements and speed limits can prove to be fatal. Motivated from the aforementioned discussion, in this paper, we present\nϑ\ninspect (velocity-inspect), an AI-based 5G enabled object segmentation and speed limit identification scheme for self-driving cars on the city roads. In\nϑ\ninspect, the Convolutional Neural Network (CNN) based semantic image segmentation is carried out to segment the objects as interpreted from the Cityscapes dataset. Then, object clustering is done using the K-Means approach based on the number of unique objects. The semantic segmentation is done over 12 classes and the model outshines concerning state-of-the-art approaches for various parameters like latency, high accuracy of 82.2%, and others. Further, K-Means clustering based Speed Range Analyser (SRA) is proposed to determine the acceptable and safe speed range for the vehicle, which is computed based on the object density of every object in the environment. The results show that the proposed scheme outperforms compared to traditional schemes in terms of latency and accuracy.}
}


@article{DBLP:journals/cn/GeSFBR21,
	author = {Mengmeng Ge and
                  Naeem Firdous Syed and
                  Xiping Fu and
                  Zubair A. Baig and
                  Antonio Robles{-}Kelly},
	title = {Towards a deep learning-driven intrusion detection approach for Internet
                  of Things},
	journal = {Comput. Networks},
	volume = {186},
	pages = {107784},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2020.107784},
	doi = {10.1016/J.COMNET.2020.107784},
	timestamp = {Thu, 11 Feb 2021 11:53:38 +0100},
	biburl = {https://dblp.org/rec/journals/cn/GeSFBR21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Internet of Things (IoT) as a paradigm comes with a range of benefits to humanity. Domains of research for the IoT range from healthcare automation to energy and transport. However, due to their limited resources, IoT devices are vulnerable to various types of cyber attacks as carried out by the adversary. In this paper, we propose a novel intrusion detection approach for the IoT, through the adoption of a customised deep learning technique. We utilise a cutting-edge IoT dataset comprising IoT traces and realistic attack traffic, including denial of service, distributed denial of service, data gathering and data theft attacks. A feed-forward neural networks model with embedding layers (to encode high-dimensional categorical features) for multi-class classification, is developed. The concept of transfer learning is subsequently applied to encode high-dimensional categorical features to build a binary classifier based on a second feed-forward neural networks model. We obtain results through the evaluation of the proposed approach which demonstrate a high classification accuracy for both classifiers, namely, binary and multi-class.}
}


@article{DBLP:journals/cn/MalboubiBJ21,
	author = {Mehdi Malboubi and
                  Abhijeet Bhorkar and
                  Frank Jiang},
	title = {PAveMENT: a framework for the intelligent and safe navigation of unmanned
                  aerial vehicles over optimal PAths in MobilE NeTworks},
	journal = {Comput. Networks},
	volume = {186},
	pages = {107785},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2020.107785},
	doi = {10.1016/J.COMNET.2020.107785},
	timestamp = {Tue, 16 Feb 2021 16:58:52 +0100},
	biburl = {https://dblp.org/rec/journals/cn/MalboubiBJ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The demand for using Unmanned Aerial Vehicles (UAV) is increasing in different applications, such as delivery, environmental monitoring, media, and wireless internet access. In these applications, UAVs are enabled by a cellular device and act as aerial users that need to be served by the underlying mobile-wireless network. The large-scale and low-cost usage of UAVs in such applications/services requires a framework that enables the safe and optimal navigation of UAVs over wide areas. Current cellular mobile networks have the infrastructure and the capability for implementing such frameworks. In contrast to other related work [6,15], in this paper, we propose a framework, called PAveMENT, that provides safe and optimal paths for navigating UAVs where: a) they experience reliable and high-quality communications with the underlying cellular network; b) UAVs cannot fly over no-flying zones and interrupt public/private services, and c) UAVs have minimal impact on the ground users of the mobile network. These are important factors from the perspective of a cellular service provider, as the main enabler for navigating UAVs over wide areas. In this framework, providing safe-optimal paths are performed by constructing a graph around the local area of interest to fly over and computing a least-cost path from the source to the destination. In addition, unlike other related work, we use real network performance indicators, and practical path-loss models with proprietary operational parameters to evaluate the performance of this framework.}
}


@article{DBLP:journals/cn/RiosIMF21,
	author = {Vin{\'{\i}}cius de Miranda Rios and
                  Pedro R. M. In{\'{a}}cio and
                  Damien Magoni and
                  M{\'{a}}rio M. Freire},
	title = {Detection of reduction-of-quality DDoS attacks using Fuzzy Logic and
                  machine learning algorithms},
	journal = {Comput. Networks},
	volume = {186},
	pages = {107792},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2020.107792},
	doi = {10.1016/J.COMNET.2020.107792},
	timestamp = {Wed, 07 Apr 2021 15:59:43 +0200},
	biburl = {https://dblp.org/rec/journals/cn/RiosIMF21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Distributed Denial of Service (DDoS) attacks are still among the most dangerous attacks on the Internet. With the advance of methods for detecting and mitigating these attacks, crackers have improved their skills in creating new DDoS attack types with the aim of mimicking normal traffic behavior therefore becoming silently powerful. Among these advanced DDoS attack types, the so-called low-rate DoS attacks aim at keeping a low level of network traffic. In this paper, we study one of these techniques, called Reduction of Quality (RoQ) attack. To investigate the detection of this type of attack, we evaluate and compare the use of four machine learning algorithms: Multi-Layer Perceptron (MLP) neural network with backpropagation, K-Nearest Neighbors (K-NN), Support Vector Machine (SVM) and Multinomial Naive Bayes (MNB). We also propose an approach for detecting this kind of attack based on three methods: Fuzzy Logic (FL), MLP and Euclidean Distance (ED). We evaluate and compare the approach based on FL, MLP and ED to the above machine learning algorithms using both emulated and real traffic traces. We show that among the four Machine Learning algorithms, the best classification results are obtained with MLP, which, for emulated traffic, leads to a F1-score of 98.04% for attack traffic and 99.30% for legitimate traffic, while, for real traffic, it leads to a F1-score of 99.87% for attack traffic and 99.95% for legitimate traffic. Regarding the approach using FL, MLP and EC, for classification of emulated traffic, we obtained a F1-score of 98.80% for attack traffic and 99.60% for legitimate traffic, while, for real traffic, we obtained a F1-score of 100% for attack traffic and 100% for legitimate traffic. However, the better performance of the approach based on FL, MLP and ED is obtained at the cost of larger execution time, since MLP required 0.74 ms and 0.87 ms for classification of the emulated and real traffic datasets, respectively, where as the approach using FL, MLP and ED required 11’46” and 46’48” to classify the emulated and real traffic datasets, respectively.}
}


@article{DBLP:journals/cn/LiSZL21,
	author = {Chunlin Li and
                  Mingyang Song and
                  Qingchuan Zhang and
                  Youlong Luo},
	title = {Cluster load based content distribution and speculative execution
                  for geographically distributed cloud environment},
	journal = {Comput. Networks},
	volume = {186},
	pages = {107807},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.107807},
	doi = {10.1016/J.COMNET.2021.107807},
	timestamp = {Fri, 17 Mar 2023 15:18:19 +0100},
	biburl = {https://dblp.org/rec/journals/cn/LiSZL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The scale of big data has shown an explosive growth, which makes the processing of big data put forward higher requirements on data centers, and a single data center can no longer meet the needs of big data processing. To deal with this situation, a geographically distributed cloud system needs to be built. However, in the geographically distributed cloud system, each data center is distributed in different geographic locations, which makes the data placement operations in the geographically distributed cloud system lead to greater overhead. To solve this problem, this paper proposes a data placement strategy. This strategy comprehensively considers the data transmission latency, bandwidth cost, cloud server storage capacity, and load capacity during the data placement process, and formulates a data placement problem that minimizes the energy consumption of data transmission. Then the minimum set cover method based on Lagrangian relaxation is used to solve this problem and obtain the optimal data placement scheme. On the other hand, in a geographically distributed cloud data center, the execution progress of the job submitted by the user will be affected by the straggler task. To solve this problem, this paper proposes a speculative execution strategy for the geographically distributed cloud system. This strategy performs different speculative execution operations according to the state of the cluster load, and then calculates the load capacity of the nodes in the cluster. The node with the strongest load capacity in the cluster is used to perform speculative execution operations. Experimental results show that the proposed data placement strategy can effectively improve the performance of the energy consumption, the data storage cost, the network transmission cost and the data transmission time. The proposed speculative execution strategy can effectively improve the performance of the job completion time, cluster throughput and QoS satisfaction rate.}
}


@article{DBLP:journals/cn/DayalS21,
	author = {Neelam Dayal and
                  Shashank Srivastava},
	title = {{SD-WAN} Flood Tracer: Tracking the entry points of DDoS attack flows
                  in {WAN}},
	journal = {Comput. Networks},
	volume = {186},
	pages = {107813},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.107813},
	doi = {10.1016/J.COMNET.2021.107813},
	timestamp = {Tue, 09 Feb 2021 15:29:32 +0100},
	biburl = {https://dblp.org/rec/journals/cn/DayalS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Countering DDoS attacks in the network requires identification of attack flows and their removal, resulting in the removal of legitimate flows as well. Mitigation of attacks near the attacker reduces the chances of affecting legitimate communication as the attack path is curtailed. Hence, an efficient DDoS countermeasure requires an efficient traceback scheme to identify the attack source in order to mitigate the attack at entry point itself. This paper proposes SD-WAN Flood Tracer to facilitate tracing the attack source in software-defined wide area network (SD-WAN). The traceback scheme is divided into two parts; the first part is internal traceback to trace the sources in the vicinity of a single controller. The second part is external traceback to trace the source belonging to another controller’s vicinity. Such a global traceback scheme prevents the impact of DDoS attacks on legitimate traffic. Not just DDoS attack sources, but this scheme may also support tracking other anomaly sources as well. The traceback scheme is lightweight with low overhead on the communication channel and converges the trace quickly. The proposed scheme is capable of efficiently tracing internal anomaly sources, as well as external anomaly sources to the farthest location, preventing damage to legitimate communications in the network.}
}
