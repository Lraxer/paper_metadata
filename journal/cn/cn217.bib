@article{DBLP:journals/cn/WangHS22,
	author = {Kewei Wang and
                  Changzhen Hu and
                  Chun Shan},
	title = {Calculation of utility of network services based on state manifolds},
	journal = {Comput. Networks},
	volume = {217},
	pages = {109258},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109258},
	doi = {10.1016/J.COMNET.2022.109258},
	timestamp = {Mon, 28 Aug 2023 21:39:20 +0200},
	biburl = {https://dblp.org/rec/journals/cn/WangHS22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Network service, as a behavioral process oriented toward network operation, plays a vital role in the function of network application system. State-of-the-art researches are prone to ignore the intrinsic behavioral characteristics of network services, and yield subjective and biased analysis results on service selection, coordination, composition, and management. To fill in this gap, an approach of calculating the network service behavioral utility is presented in this paper. We first propose a method of extracting the behavioral attributes and constructing the state space model of network service with machine learning and differential geometry techniques. Moreover, based on the state space model, which is described as Riemannian manifold, we propose a method of calculating the utility of network services and applications, which serves as a measure of impact of the particular network behavior. The proposed method is examined in different application scenarios under the service mesh architecture, and experimental results show that the method can effectively reflect the intrinsic behavioral characteristic of network service.}
}


@article{DBLP:journals/cn/MountaserPM22,
	author = {Ghizlane Mountaser and
                  Enric Pardo and
                  Toktam Mahmoodi},
	title = {Graphical Modelling and Optimization of {RAN} function split deployed
                  through UAVs},
	journal = {Comput. Networks},
	volume = {217},
	pages = {109266},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109266},
	doi = {10.1016/J.COMNET.2022.109266},
	timestamp = {Mon, 28 Aug 2023 21:39:20 +0200},
	biburl = {https://dblp.org/rec/journals/cn/MountaserPM22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we demonstrate the potentials of deploying radio access network function split architecture through aerial network and present a graph-based model to analyse and improve the performance. We consider radio units (RUs) are deployed on Unmanned aerial vehicles, while central unit (CU) is on the ground, then model the air-to-ground communication as a maximum flow problem on the connectivity graph. The air-to-ground connections include both network (RUs) to users and the RUs to the CU connections. Using this model, we build a framework that ensures maximizing throughput in the access network, while maintaining the essential latency on the fronthaul, i.e. connection between RUs and CU. We further develop a heuristic solution with low complexity and hence the ability to scale up to a large network. The results examine close-to-optimal solutions of the heuristic method, and the impact of flying networks’ deployment parameters, such as flying height, on the performance.}
}


@article{DBLP:journals/cn/XiaoCNZZL22,
	author = {Da Xiao and
                  Shuo Chen and
                  Wei Ni and
                  Jie Zhang and
                  Jian (Andrew) Zhang and
                  Ren Ping Liu},
	title = {A sub-action aided deep reinforcement learning framework for latency-sensitive
                  network slicing},
	journal = {Comput. Networks},
	volume = {217},
	pages = {109279},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109279},
	doi = {10.1016/J.COMNET.2022.109279},
	timestamp = {Sun, 19 Feb 2023 11:59:39 +0100},
	biburl = {https://dblp.org/rec/journals/cn/XiaoCNZZL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Network slicing is a core technique of fifth-generation (5G) systems and beyond. To maximize the number of accepted network slices with limited hardware resources, service providers must avoid over-provisioning of quality-of-service (QoS), which could prevent them from lowering capital expenditures (CAPEX)/operating expenses (OPEX) for 5G infrastructure. In this paper, we propose a sub-action aided double deep Q-network (SADDQN)-based network slicing algorithm for latency-aware services. Specifically, we model network slicing as a Markov decision process (MDP), where we consider virtual network function (VNF) placements to be the actions of the MDP, and define a reward function based on cost and service priority. Furthermore, we adopt the Dijkstra algorithm to determine the forwarding graph (FG) embedding for a given VNF placement and design a resource allocation algorithm – binary search assisted gradient descent (BSAGD) – to allocate resources to VNFs given the VNF-FG placement. For every service request, we first use the DDQN to choose an MDP action to determine the VNF placement (main action). Next, we employ the Dijkstra algorithm (first-phase sub-action) to find the shortest path for each pair of adjacent VNFs in the given VNF chain. Finally, we implement the BSAGD (second-phase sub-action) to realize this service with the minimum cost. The joint action results in an MDP reward that can be utilized to train the DDQN. Numerical evaluations show that, compared to state-of-the-art algorithms, the proposed algorithm can improve the cost-efficiency while giving priority to higher-priority services and maximizing the acceptance ratio.}
}


@article{DBLP:journals/cn/KaurMK22,
	author = {Karamjeet Kaur and
                  Veenu Mangat and
                  Krishan Kumar},
	title = {A review on Virtualized Infrastructure Managers with management and
                  orchestration features in {NFV} architecture},
	journal = {Comput. Networks},
	volume = {217},
	pages = {109281},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109281},
	doi = {10.1016/J.COMNET.2022.109281},
	timestamp = {Tue, 21 Mar 2023 21:08:30 +0100},
	biburl = {https://dblp.org/rec/journals/cn/KaurMK22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Nowadays, Network Function Virtualization (NFV) is a growing and powerful technology in the research community and IT world. Traditional computer networks consist of hardware appliances such as firewalls and load balancers, called middleboxes. The implementation of these hardware devices is a difficult task due to their proprietary nature. NFV proposes an alternative way to design and deploy network functions called Virtual Network Functions (VNFs) on top of the commercial hardware by leveraging virtualization technology. NFV offers many advantages such as flexibility, agility, reduced capital and operational expenditure over the traditional network architecture. With the emergence of VNF, NFV needs to add new features regarding life-cycle management and end-to-end orchestration of VNFs. To fulfill this demand, NFV introduced the NFV-MANO framework for the management and orchestration of VNFs and provide network services to users. The NFV-MANO consists of NFV Orchestrator (NFVO), VNF Manager (VNFM), and Virtualized Infrastructure Manager (VIM). This paper provides a comprehensive overview of Virtualized Infrastructure Managers with NFV orchestration and VNF Management for implementing Service Function Chain (SFC) in NFV architecture. Further, this study critically analyzes relevant research articles and proposes a taxonomy to select an appropriate VIM based on Emulation, Virtualization, Containerization, and Hybrid environment for reliable SFC provisioning. Finally, various use cases have been identified for selecting particular VIM according to the requirements of the application.}
}


@article{DBLP:journals/cn/RagoMPAB22,
	author = {Arcangela Rago and
                  Sergio Martiradonna and
                  Giuseppe Piro and
                  Andrea Abrardo and
                  Gennaro Boggia},
	title = {A tenant-driven slicing enforcement scheme based on Pervasive Intelligence
                  in the Radio Access Network},
	journal = {Comput. Networks},
	volume = {217},
	pages = {109285},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109285},
	doi = {10.1016/J.COMNET.2022.109285},
	timestamp = {Mon, 05 Feb 2024 20:24:11 +0100},
	biburl = {https://dblp.org/rec/journals/cn/RagoMPAB22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In Beyond 5G mobile networks, the network slicing paradigm offers the possibility of sharing the network infrastructure among different tenants: the tenant declares communication service requirements and the Infrastructure Provider configures (potentially on-demand) the corresponding network slice instances. The management of network slicing in the core network has been deeply investigated in the current scientific literature. On the contrary, handling network slicing in the Radio Access Network still represents an open and very challenging research topic, mostly due to the unpredictable variability of the wireless channel, network dynamics and heterogeneity, slice isolation, as well as different Quality of Service requirements of various services. In order to achieve an important step forward in this direction, this paper proposes a tenant-driven Radio Access Network slicing enforcement scheme based on Pervasive Intelligence. The proposed approach grounds its roots in the Pay for What You Get paradigm: it promises to avoid the radio resources over-provisioning while saving bandwidth. To achieve these goals, Artificial Intelligence mechanisms are innovatively and pervasively integrated into some key functionalities of both Infrastructure Provider and tenants. On the one hand, the Infrastructure Provider exploits a Deep Learning scheme (i.e., convolutional autoencoder) to compress the information on network resources and connectivity and share the actual (but hidden through compression) network status with the tenants. On the other hand, each tenant implements a Deep Reinforcement Learning algorithm (i.e., Deep Deterministic Policy Gradient) to dynamically adapt bandwidth requests according to its own users’ requirements. The outcomes of this algorithm are then used by the Infrastructure Provider to effectively enforce network slicing at the Radio Access Network level. Computer simulations investigate the proposed approach in a realistic scenario, which jointly embraces enhanced Mobile BroadBand, Advanced Driver Assistant Systems, and best-effort applications. Obtained results demonstrate the effectiveness of the proposal against conventional resource allocation methods.}
}


@article{DBLP:journals/cn/KangHO22,
	author = {Rui Kang and
                  Fujun He and
                  Eiji Oki},
	title = {Fault-tolerant resource allocation model for service function chains
                  with joint diversity and redundancy},
	journal = {Comput. Networks},
	volume = {217},
	pages = {109287},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109287},
	doi = {10.1016/J.COMNET.2022.109287},
	timestamp = {Mon, 28 Aug 2023 21:39:20 +0200},
	biburl = {https://dblp.org/rec/journals/cn/KangHO22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper proposes an optimization model to derive a resilient virtual network function allocation in service function chains aiming to reduce the end-to-end (E2E) latency during the migrations from the primary functions to backup functions. The model considers\nk\n-fault tolerance assurance and the satisfactions of service requirements under different error patterns in this model. The allocation provided by the proposed model ensures that the processing ability satisfies the requirements even though there are\nk\nfailed nodes in the network. Diversity splits a single virtual network function (VNF) into a pool of replicas with different specifications. The diversity of both primary and backup functions is considered. Redundancy is used for recovering the failed functions. We formulate the proposed model as a mixed integer linear programming problem to select suitable replicas from the pools of replicas and decide the locations of these replicas for both primary and backup functions. The objective of the proposed model is to minimize the sum of the maximum E2E latencies among functions under all possible failure patterns which have\nk\nnode failures. The numerical results show that the proposed model reduces the E2E latency between the pair of primary and backup VNFs with ensuring the resiliency of the functions compared with baseline models in the examined cases. Two approximate approaches are developed to reduce the computation time of solving the proposed model with a limited performance penalty. We derive theorems to give the bounds of maximum resiliency in the proposed model.}
}


@article{DBLP:journals/cn/ZhangWWJSC22,
	author = {Lejun Zhang and
                  Jinlong Wang and
                  Weizheng Wang and
                  Zilong Jin and
                  Yansen Su and
                  Huiling Chen},
	title = {Smart contract vulnerability detection combined with multi-objective
                  detection},
	journal = {Comput. Networks},
	volume = {217},
	pages = {109289},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109289},
	doi = {10.1016/J.COMNET.2022.109289},
	timestamp = {Thu, 27 Feb 2025 22:37:47 +0100},
	biburl = {https://dblp.org/rec/journals/cn/ZhangWWJSC22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Blockchains have been booming in recent years. As a decentralized system architecture, smart contracts give blockchains a user-defined logic. A smart contract is an executable program that can automatically carry out transactions on the Ethereum blockchain. However, some security issues in smart contracts are difficult to fix, and smart contracts also lack quality assessment standards. Therefore, this study proposes a Multiple-Objective Detection Neural Network (MODNN), a more scalable smart contract vulnerability detection tool. MODNN can validate 12 types of vulnerabilities, including 10 recognized threats, and identify more unknown types without the need for specialist or predefined knowledge through implicit features and Multi-Objective detection (MOD) algorithms. It supports the parallel detection of multiple vulnerabilities and has high scalability, eliminating the need to train separate models for each type of vulnerability and reducing significant time and labor costs. This paper also developed a data processing tool called Smart Contract-Crawler (SCC) to address the lack of smart contract vulnerability datasets. MODNN was evaluated using more than 18,000 smart contracts from Ethereum. Experiments showed that MODNN could achieve an average F1 Score of 94.8%, the current highest compared to several standard machine learning (ML) classification models.}
}


@article{DBLP:journals/cn/CavdarKU22,
	author = {Mustafa Can {\c{C}}avdar and
                  Ibrahim Korpeoglu and
                  {\"{O}}zg{\"{u}}r Ulusoy},
	title = {Application placement with shared monitoring points in multi-purpose
                  IoT wireless sensor networks},
	journal = {Comput. Networks},
	volume = {217},
	pages = {109302},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109302},
	doi = {10.1016/J.COMNET.2022.109302},
	timestamp = {Sun, 06 Oct 2024 21:22:02 +0200},
	biburl = {https://dblp.org/rec/journals/cn/CavdarKU22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The main function of a wireless sensor network (WSN) is to gather data from a certain region and transfer the data to a center or remote locations for further processing. The collected data can be of interest for many applications. Therefore, a physical WSN owned by a single provider can be utilized by many customer applications. Additionally, the data of a particular point or sub-region can satisfy the need of multiple applications. Hence, sensing the data only once in such cases is beneficial to reduce the energy consumption, network traffic and acceptance ratio of the applications. We call this as monitoring point based shared data approach. In this paper, we focus on the placement of applications each of which requires several points to be monitored in an area a WSN covers. We first propose such a monitoring point based shared data approach for WSNs that will serve multiple dynamic applications. We also propose two methods for application placement over a shared physical WSN: one greedy method and one genetic algorithm based method called GABAP. We did extensive simulation experiments to evaluate our algorithms. The results show the effectiveness of our methods in fast and close-to-optimum placement of applications over a single network.}
}


@article{DBLP:journals/cn/MesodiakakiZK22,
	author = {Agapi Mesodiakaki and
                  Enrica Zola and
                  Andreas Kassler},
	title = {Robust and energy-efficient user association and traffic routing in
                  {B5G} HetNets},
	journal = {Comput. Networks},
	volume = {217},
	pages = {109305},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109305},
	doi = {10.1016/J.COMNET.2022.109305},
	timestamp = {Thu, 05 Jan 2023 17:09:20 +0100},
	biburl = {https://dblp.org/rec/journals/cn/MesodiakakiZK22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Next-generation cellular networks, i.e., beyond fifth generation (B5G) and sixth generation (6G) networks, aim at significantly increasing capacity by deploying a massive number of small cells (SCs) and leveraging millimeter wave (mmWave) links that have large bandwidth availability. However, as optical connections to a large number of base stations (BSs) are not cost effective, wireless backhaul (BH) links may be used to connect SCs to the core network using mmWave frequencies and forming multihop mesh BH paths. While very flexible in deployment, the uncertainty in user demand, which varies over time and place, makes network planning and management challenging. In this work, we propose novel algorithms to solve the joint problem of energy-efficient user association, BH traffic routing and BS/BH link on/off switching. We first formulate an exact model assuming user traffic demand uncertainty leveraging\nΓ\n-robustness theory. As the model is intractable for large-scale instances, we develop a novel greedy robust heuristic (P-HEUR), which includes a robustifying step to effectively cope with demand uncertainty. Our evaluation demonstrates that P-HEUR provides robust and energy-efficient solutions quickly for different scenarios and traffic demand uncertainty levels, and it significantly outperforms state-of-the-art approaches while achieving up to 83% of the optimal capacity, even in the most demanding scenarios in terms of traffic load and demand uncertainty, with up to 200k times lower complexity.}
}


@article{DBLP:journals/cn/SuLFLHZ22,
	author = {Yishan Su and
                  Yao Liu and
                  Rong Fan and
                  Luyu Li and
                  Meng Han and
                  Hongliang Zhang},
	title = {A secure relay selection scheme based on cooperative jamming for Underwater
                  Acoustic Sensor Networks},
	journal = {Comput. Networks},
	volume = {217},
	pages = {109307},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109307},
	doi = {10.1016/J.COMNET.2022.109307},
	timestamp = {Thu, 05 Jan 2023 17:09:20 +0100},
	biburl = {https://dblp.org/rec/journals/cn/SuLFLHZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Physical layer security (PLS) is one of the important methods to solve the security problems of Underwater Acoustic Sensor Networks (UASNs). In this paper, combining the characteristics of cooperative communication and cooperative jamming in PLS, we propose a Secure Relay Selection Scheme based on Cooperative Jamming for UASNs. On the one hand, according to the link quality and residual energy, one or several nodes are selected to forward information as relays. On the other hand, the scheme takes advantage of long propagation delay of the underwater acoustic channel and employs two different jamming ways: Self-Protection Jamming and Assistance Jamming, both of which can interfere with eavesdroppers without affecting the reception of legal users. The proposed scheme can increase the channel capacity of the legal channel by deploying relay nodes to forward the information and reduce the channel capacity of the eavesdropping channel by Self-Protection Jamming and Assistance Jamming. Simulation and field experiment results show that the proposed scheme can improve the PLS of the network.}
}


@article{DBLP:journals/cn/JiangLFCCXG22,
	author = {Minghao Jiang and
                  Zhen Li and
                  Peipei Fu and
                  Wei Cai and
                  Mingxin Cui and
                  Gang Xiong and
                  Gaopeng Gou},
	title = {Accurate mobile-app fingerprinting using flow-level relationship with
                  graph neural networks},
	journal = {Comput. Networks},
	volume = {217},
	pages = {109309},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109309},
	doi = {10.1016/J.COMNET.2022.109309},
	timestamp = {Tue, 07 May 2024 20:23:16 +0200},
	biburl = {https://dblp.org/rec/journals/cn/JiangLFCCXG22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Identifying mobile applications (apps) from encrypted network traffic (also known as app fingerprinting) plays an important role in areas like network management, advertising analysis, and quality of service. Existing methods mainly extract traffic features from packet-level information (e.g. packet size sequence) and build up classifiers to obtain good performance. However, the packet-level information suffers from small discrimination for the common traffic across apps (e.g. advertising traffic) and rapidly changing for the traffic before and after apps’ updating. As a result, their performance declines in these two real scenes. In this paper, we propose FG-Net, a novel app fingerprinting based on graph neural network (GNN). FG-Net leverages a novel kind of information: flow-level relationship, which is distinctive between different apps and stable across apps’ versions. We design an information-rich graph structure, named FRG, to embed both raw packet-level information and flow-level relationship of traffic concisely. With FRG, we transfer the problem of mobile encrypted traffic fingerprinting into a task of graph representation learning, and we designed a powerful GNN-based traffic fingerprint learner. We conduct comprehensive experiments on both public and private datasets. The results show the FG-Net outperforms the SOTAs in classifying traffic with about 18% common traffic. Without retraining, FG-Net obtains the most robustness against the updated traffic and increases the accuracy by 5.5% compared with the SOTAs.}
}


@article{DBLP:journals/cn/LiXDC22,
	author = {Yupeng Li and
                  Mengjia Xia and
                  Jingpu Duan and
                  Yang Chen},
	title = {Pricing-based resource allocation in three-tier edge computing for
                  social welfare maximization},
	journal = {Comput. Networks},
	volume = {217},
	pages = {109311},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109311},
	doi = {10.1016/J.COMNET.2022.109311},
	timestamp = {Sun, 13 Nov 2022 17:53:48 +0100},
	biburl = {https://dblp.org/rec/journals/cn/LiXDC22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Edge computing is a promising computing paradigm for Internet of Everything and AI-driven applications where substantial computing resources are pushed to the edge of the network in close proximity to the end users. Unlike most of the existing works concentrating on system-side metrics such as job response time, we study how the entities in edge computing interact with each other. Specifically, we study a three-tier edge computing market that consists of edge servers, brokers, and edge users, where brokers are introduced to connect edge servers and edge users, and to facilitate resource deployment and maintenance for edge users. Our goal is to maximize social welfare. The uniqueness of this market, such as the agents’ private information and selfishness, prevents one from using standard optimization techniques. Therefore, we propose a pricing-based resource allocation mechanism via iterative bidding, called MECM, for the three-tier edge computing market. Our theoretical results show that MECM converges to the social optimum with a provable convergence rate of\nO\n(\n1\nk\n)\n, where\nk\nis the number of iterations, and has desirable properties, i.e., budget balance and individual rationality. Our extensive simulations validate MECM’s performance and its properties in various scenarios.}
}


@article{DBLP:journals/cn/KuangLHZW22,
	author = {Ye Kuang and
                  Dandan Li and
                  Xiaohong Huang and
                  Mo Zhou and
                  Weidu Wang},
	title = {PoiEvent: An approach to extract the persistent and destructive routing
                  events},
	journal = {Comput. Networks},
	volume = {217},
	pages = {109313},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109313},
	doi = {10.1016/J.COMNET.2022.109313},
	timestamp = {Thu, 27 Oct 2022 21:55:25 +0200},
	biburl = {https://dblp.org/rec/journals/cn/KuangLHZW22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {To extract the persistent and destructive routing events is critical for Internet service providers (ISPs) to improve the network performance. Currently, the latest approach that leverages the notion of empathy to aggregate the paths that changed similarly over time can extract routing events from an arbitrary set of traceroutes. However, the cascading effects of path change prevent ISPs from accurately identifying the root cause of routing events. Meanwhile, the lack of evaluation for the impact of events limit ISPs from extracting the persistent and destructive routing events. In order to extract the persistent and destructive routing events and identify their root causes accurately, we propose PoiEvent. First, to infer the routing events and identify their root causes accurately, we improve the existing algorithm to remove the cascading effects. Then, to characterize the impact of routing events, we propose an event-based characterization method, which considers the location, severity, scope, congestion effect, and duration of each routing event. Finally, to extract the persistent and destructive routing events, we propose an event filtering method using the number of changed paths as hints to extract the routing events in terms of their impact. We perform experiments with data from RIPE Atlas to evaluate the performance of PoiEvent. The results show that PoiEvent can extract the persistent and destructive routing events. We believe that PoiEvent can be an effective aid for improving the network performance at the ISPs level.}
}


@article{DBLP:journals/cn/MazzianeAN22,
	author = {Younes Ben Mazziane and
                  Sara Alouf and
                  Giovanni Neglia},
	title = {Analyzing Count Min Sketch with Conservative Updates},
	journal = {Comput. Networks},
	volume = {217},
	pages = {109315},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109315},
	doi = {10.1016/J.COMNET.2022.109315},
	timestamp = {Sun, 06 Oct 2024 21:22:04 +0200},
	biburl = {https://dblp.org/rec/journals/cn/MazzianeAN22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Count-Min Sketch with Conservative Updates (CMS-CU) is a popular algorithm to approximately count items’ appearances in a data stream. Despite CMS-CU’s widespread adoption, the theoretical analysis of its performance is still wanting because of its inherent difficulty. In this paper, we propose a novel approach to study CMS-CU and derive new upper bounds on both the expected value and the CCDF of the estimation error under an i.i.d. request process. Our formulas can be successfully employed to derive improved estimates for the precision of heavy-hitter detection methods and improved configuration rules for CMS-CU. The bounds are evaluated both on synthetic and real traces.}
}


@article{DBLP:journals/cn/BuccafurriAL22,
	author = {Francesco Buccafurri and
                  Vincenzo De Angelis and
                  Gianluca Lax},
	title = {An integrity-preserving technique for range queries over data streams
                  in two-tier sensor networks},
	journal = {Comput. Networks},
	volume = {217},
	pages = {109316},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109316},
	doi = {10.1016/J.COMNET.2022.109316},
	timestamp = {Sun, 13 Nov 2022 17:53:49 +0100},
	biburl = {https://dblp.org/rec/journals/cn/BuccafurriAL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Two-tier sensor networks enable energy and computation saving due to the introduction of non-constrained storage nodes acting as intermediates between the sensors, which provide data, and the sink, which needs to access these data by submitting queries to the storage nodes. However, the storage nodes maintain a lot of data coming from different sensors and represent a single point of failure targeted by the attackers. In this scenario, robust guarantees about the integrity of the query result (i.e., completeness, freshness, and correctness) should be provided. This is a very well-known problem, traditionally faced through Merkle-Hash-Tree-based data structures. This paper presents a technique more efficient than the state-of-the-art methods for data insertions and deletions, supporting range queries over even non-temporal dimensions. Thus, the proposed solution appears suitable to the considered scenario, in which data can be updated with high frequency and insertions and deletions are executed by constrained devices.}
}


@article{DBLP:journals/cn/HouXLSW22,
	author = {Tianhao Hou and
                  Hongyan Xing and
                  Xinyi Liang and
                  Xin Su and
                  Zenghui Wang},
	title = {Network intrusion detection based on {DNA} spatial information},
	journal = {Comput. Networks},
	volume = {217},
	pages = {109318},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109318},
	doi = {10.1016/J.COMNET.2022.109318},
	timestamp = {Sun, 06 Oct 2024 21:22:03 +0200},
	biburl = {https://dblp.org/rec/journals/cn/HouXLSW22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {There is an ever-increasing risk of illegal access-induced Network Intrusion (NI), which calls for prompt detection of illegal network behavior through profound Network Traffic (NT) analyses. However, current intrusion detection methods are limited in accuracy due to insufficient data standardization. This paper puts forward a deoxyribonucleic acid (DNA)-Spatial Information (SI) method to overcome these limitations. A DNA encoding model is formed, which defines a mapping relationship between NT attributes and nucleobases to reconstruct NT samples expressed as DNA sequences. Then, a feature extraction algorithm is constructed that deduces a Spatial Information Feature Matrix (SIFM) to represent sequence statistical features. A Random Forest (RF) algorithm is adopted as a matching process to determine NI behaviors considering the detection efficiency. Following experiments evaluate its method performance on two datasets, NSL-KDD and UNSW-NB15. Results demonstrate that DNA-SI obtains better results than state-of-the-art works, where the accuracy, F1-score, recall, far are 95.75%, 94.41%, 94.12%, 3.26% and 92.30%, 92.78%, 89.82%, 4.66% respectively. The fact that it is insusceptible to minority intrusion samples is another point worth attention. In sum, this quick and accurate network intrusion detection points to a new orientation for safeguarding network security.}
}


@article{DBLP:journals/cn/LuW22,
	author = {Tingting Lu and
                  Junfeng Wang},
	title = {{F2DC:} Android malware classification based on raw traffic and neural
                  networks},
	journal = {Comput. Networks},
	volume = {217},
	pages = {109320},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109320},
	doi = {10.1016/J.COMNET.2022.109320},
	timestamp = {Mon, 26 Jun 2023 20:51:09 +0200},
	biburl = {https://dblp.org/rec/journals/cn/LuW22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Given the growing threat of Android malware, its family classification is important for identifying new variants, building robust signatures, assessing threat levels, and planning defenses. Since static and host-based dynamic classification techniques suffer from several limitations such as low adversarial capabilities, network-based dynamic techniques have been proposed as a complementary way. However, existing network-based approaches are heavily engineered on a specific application protocol (i.e., HTTP) and implement classification based on domain-expert driven features, rendering them hardly generalizable to many real-world classification scenarios (e.g., TLS encryption and unknown application protocols) and unable to keep pace with the rapid evolution of Android malware. To address these issues, we propose F2DC, a new Android malware classification method based on raw traffic and neural networks. F2DC characterizes Android malware from raw payload rather than application protocols and is therefore application-protocol independent and encryption-agnostic in principle. A novel traffic encoding scheme called F2D is designed to map the raw payload space into a flow-based latent feature space that facilitates convolutional neural networks (CNNs) to distill more discriminative features for effective classification. Experiments show that F2DC outperforms state-of-the-art methods and exhibits highly competitive performance against popular mobile antivirus (AV) tools. These results indicate that F2DC is a promising network-based Android malware classification solution complementary to existing alternatives.}
}


@article{DBLP:journals/cn/AbdollahiNN22,
	author = {Mehran Pourmohammad Abdollahi and
                  Javad Musevi Niya and
                  Mahdi Nangir},
	title = {Optimizing the operator's economy in multi-tier cellular networks
                  with underlaid {D2D} communications},
	journal = {Comput. Networks},
	volume = {217},
	pages = {109322},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109322},
	doi = {10.1016/J.COMNET.2022.109322},
	timestamp = {Sun, 13 Nov 2022 17:53:49 +0100},
	biburl = {https://dblp.org/rec/journals/cn/AbdollahiNN22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we consider a three-tier cellular network, consisting of a Macrocell base station, several Femtocell base stations, cellular users, and Device-to-Device (D2D) users. Each user is attached to the Macrocell or one of the Femtocells while D2D users communicate directly. The Macrocell divides the spectrum into several subchannels. The Femtocell users are allowed to communicate over the common spectrum which is allocated to one of the Macrocell users. We consider the scenario in which the Femtocells do not interfere each other while the Macrocell users experience interference from Femtocells and vice versa. Likewise, the Macrocell users would suffer from the interferences caused by underlaid Femtocells and D2D communications in the same spectrum. The average outage probability over the shared sub-channel is investigated assuming the effect of D2D users, and the closed form expressions are obtained in an interference limited scheme. Then, the object function is defined to minimize the operator’s cost function for establishing Femtocell network. The problem is generally non-convex and hence, it is solved through separation to subproblems to derive the near-optimal solutions for the intensity of Femtocells and power allocation. The analytical results are verified by the simulation results, which show that although the D2D and Femtocells improve the network performance by handling the data traffic, increasing the D2D users’ transmission power and the intensity of physical distribution of Femtocells increase the network cost function.}
}


@article{DBLP:journals/cn/ChheaL22,
	author = {Kimchheang Chhea and
                  Jung{-}Ryun Lee},
	title = {Energy-efficient full-duplex {D2D} for SWIPT-empowered underlay cellular
                  networks using a deep neural network},
	journal = {Comput. Networks},
	volume = {217},
	pages = {109324},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109324},
	doi = {10.1016/J.COMNET.2022.109324},
	timestamp = {Sun, 13 Nov 2022 17:53:49 +0100},
	biburl = {https://dblp.org/rec/journals/cn/ChheaL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Close-packed small-cell networks enables a device-to-device (D2D) user equipment (DUE) to harvest energy from an ambient source, which increases the energy efficiency of the devices. Conceptually, full-duplex (FD) communications can double spectral efficiency compared to traditional half-duplex (HD) communications. However, the use of FD mode increases self-interference, which impacts spectral capacity and energy efficiency. In this paper, we study the performance of full-duplex D2D underlay cellular networks, where D2D devices decipher information and harvest energy simultaneously using SWIPT technology. Specifically, we build an optimization model to maximize the energy efficiency of the system, and obtain global- and sub-optimal solutions from the exhaustive search (ES) algorithm and the gradient search (GS) with barrier algorithm, respectively. In addition, we design deep neural networks (DNN) algorithm for the optimization model and evaluate the performance of the proposed DNN algorithm compared to the ES and GS algorithms. From the results, we confirm that the FD mode outperforms the HD mode in terms of energy efficiency and sum-rate and the proposed DNN algorithm can achieve near-global-optimal solution.}
}


@article{DBLP:journals/cn/KolukisaYEAG22,
	author = {Burak Kolukisa and
                  Veli Can Yildirim and
                  Bahadir Elmas and
                  Cem Ayyildiz and
                  Vehbi Cagri Gungor},
	title = {Deep learning approaches for vehicle type classification with 3-D
                  magnetic sensor},
	journal = {Comput. Networks},
	volume = {217},
	pages = {109326},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109326},
	doi = {10.1016/J.COMNET.2022.109326},
	timestamp = {Sat, 30 Sep 2023 10:07:03 +0200},
	biburl = {https://dblp.org/rec/journals/cn/KolukisaYEAG22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the Intelligent Transportation Systems, it is crucial to determine the type of vehicles to improve traffic management, increase human comfort, and enable future development of transport infrastructures. This paper presents a deep learning-based vehicle type classification approach for intermediate road traffic. Specifically, a low-cost, easy-to-install, battery-operated 3-D traffic sensor is designed and developed. In addition, a total of 376 vehicle samples are collected, and the vehicles are identified into three different classes according to their structures: light, medium, and heavy. Firstly, an oversampling method is applied to increase the number of samples in the training set. Then, the signals are converted into time series for LSTM and GRU and 2-D images for transfer learning models. Finally, soft voting is proposed using the LSTM, GRU, and VGG16, which is the best transfer learning method for vehicle type classification. The developed system is portable, power-limited, battery-operated, and reliable. Comparative performance results show that the soft voting ensemble method using a deep learning classifier improves the accuracy and f-measure performances by 92.92% and 93.42%, respectively. Additionally, the battery lifetime of the developed magnetic sensor node can work for up to 2 years.}
}


@article{DBLP:journals/cn/KumariSST22,
	author = {Swati Kumari and
                  Maninder Singh and
                  Raman Singh and
                  Hitesh Tewari},
	title = {A post-quantum lattice based lightweight authentication and code-based
                  hybrid encryption scheme for IoT devices},
	journal = {Comput. Networks},
	volume = {217},
	pages = {109327},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109327},
	doi = {10.1016/J.COMNET.2022.109327},
	timestamp = {Mon, 28 Aug 2023 21:39:20 +0200},
	biburl = {https://dblp.org/rec/journals/cn/KumariSST22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Internet of Things (IoT) introduces an active connection between smart devices for revolutionizing our modern lives in this world. But, IoT devices often exhibit several security issues, so transmission between the nodes should be protected using cryptographic approaches. However, the complexity of conventional cryptographic approaches is very high and is vulnerable to quantum attacks. This paper presents a robust and lightweight post-quantum lattice-based authentication and code-based hybrid encryption scheme for resource-constrained IoT devices. The proposed Ring-Learning with Errors (Ring-LWE) based authentication scheme introduces Bernstein reconstruction in polynomial multiplication to achieve minimal computation cost; hence, resource-limited IoT devices are viable to use the reliable authentication mutually. This approach offers indefinite identity privacy and location privacy. Hence, the proposed signature generation and verification process are highly efficient compared to the existing ring signature systems. Also, the proposed post-quantum hybrid code-based encryption scheme follows Diagonal Structure Based QC‑LDPC Codes with column loop optimization and Simplified Log Domain Sum-Product Algorithm (SLDSPA) to provide the function of light weight encryption with minimum hardware requirements. The total authentication delay of the proposed authentication scheme is 23% less than the authentication scheme that is considered conventional polynomial multiplication. Also, the optimized design of the proposed code based HE uses only 64 slices and 640 slices on Xilinx Virtex-6 FPGA for encoding and decoding processes, respectively. These simulation results prove the effectiveness of the proposed cryptographic scheme against other competitive systems in terms of its functionality and hardware complexities.}
}


@article{DBLP:journals/cn/GalmesSPSXCBC22,
	author = {Miquel Ferriol Galm{\'{e}}s and
                  Jos{\'{e}} Su{\'{a}}rez{-}Varela and
                  Jordi Paillisse and
                  Xiang Shi and
                  Shihan Xiao and
                  Xiangle Cheng and
                  Pere Barlet{-}Ros and
                  Albert Cabellos{-}Aparicio},
	title = {Building a Digital Twin for network optimization using Graph Neural
                  Networks},
	journal = {Comput. Networks},
	volume = {217},
	pages = {109329},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109329},
	doi = {10.1016/J.COMNET.2022.109329},
	timestamp = {Mon, 26 Jun 2023 20:51:11 +0200},
	biburl = {https://dblp.org/rec/journals/cn/GalmesSPSXCBC22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Network modeling is a critical component of Quality of Service (QoS) optimization. Current networks implement Service Level Agreements (SLA) by careful configuration of both routing and queue scheduling policies. However, existing modeling techniques are not able to produce accurate estimates of relevant SLA metrics, such as delay or jitter, in networks with complex QoS-aware queueing policies (e.g., strict priority, Weighted Fair Queueing, Deficit Round Robin). Recently, Graph Neural Networks (GNNs) have become a powerful tool to model networks since they are specifically designed to work with graph-structured data. In this paper, we propose a GNN-based network model able to understand the complex relationship between\n(\ni\n)\nthe queueing policy (scheduling algorithm and queue sizes),\n(\ni\ni\n)\nthe network topology,\n(\ni\ni\ni\n)\nthe routing configuration, and\n(\ni\nv\n)\nthe input traffic matrix. We call our model TwinNet, a Digital Twin that can accurately estimate relevant SLA metrics for network optimization. TwinNet can generalize to its input parameters, operating successfully in topologies, routing, and queueing configurations never seen during training. We evaluate TwinNet over a wide variety of scenarios with synthetic traffic and validate it with real traffic traces. Our results show that TwinNet can provide accurate estimates of end-to-end path delays in 106 unseen real-world topologies, under different queuing configurations with a Mean Absolute Percentage Error (MAPE) of 3.8%, as well as a MAPE of 6.3% error when evaluated with a real testbed. We also showcase the potential of the proposed model for SLA-driven network optimization and what-if analysis.}
}


@article{DBLP:journals/cn/WangWWMH22,
	author = {Xueyi Wang and
                  Xingwei Wang and
                  Dongkuo Wu and
                  Lianbo Ma and
                  Min Huang},
	title = {Truthful auction mechanisms for {VNF} chain provisioning and allocation
                  across geo-distributed datacenters},
	journal = {Comput. Networks},
	volume = {217},
	pages = {109331},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109331},
	doi = {10.1016/J.COMNET.2022.109331},
	timestamp = {Wed, 02 Nov 2022 17:07:57 +0100},
	biburl = {https://dblp.org/rec/journals/cn/WangWWMH22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the fast development of network function virtualization (NFV), NFV markets are emerging that allows network service providers (NSPs) to trade different virtual network function (VNF) chains among users. Therefore, efficient mechanisms for VNF chain provisioning and allocation are key to guarantee efficient operations of the NFV markets. One fundamental issue is how to maximize the social welfare of the market such that selfish users have incentives to acquire VNF chains from the markets. To overcome this issue, in this paper, we propose a truthful randomized combinatorial auction mechanism (TRCAM), which integrates the primal–dual approximation algorithm design technique and efficient pricing strategy. This mechanism considers dynamic VNF chain provisioning of the NSP and flexible VNF chain deployment of users. To be specific, we first formulate the social welfare maximization problem as an integer linear program, which is proven to be NP-hard. Then, we propose a primal–dual approximate algorithm which is near-optimal with polynomial-time complexity and employ it as a building block to design the TRCAM. Furthermore, we develop a novel binary-search-based algorithm to boost the average-case performance of the TRCAM. Both strict theoretical analysis and extensive experimental studies demonstrate the effectiveness of our proposed TRCAM, which achieves approximate truthfulness, near-optimal social welfare, individual rationality, and computational efficiency.}
}


@article{DBLP:journals/cn/TanejaRGHA22,
	author = {Ashu Taneja and
                  Shalli Rani and
                  Sahil Garg and
                  Mohammad Mehedi Hassan and
                  Salman A. AlQahtani},
	title = {Energy aware resource control mechanism for improved performance in
                  future green 6G networks},
	journal = {Comput. Networks},
	volume = {217},
	pages = {109333},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109333},
	doi = {10.1016/J.COMNET.2022.109333},
	timestamp = {Tue, 07 May 2024 20:23:16 +0200},
	biburl = {https://dblp.org/rec/journals/cn/TanejaRGHA22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The increasing power consumption and the energy crisis owing to several billion of connected devices raises concern. The battery powered devices or mobile terminals consume a lot of power and led to huge energy overhead. Thus, the need is to design energy sustainable networks which aims for optimum utilization of power resources. 6G enabled networks offer enhanced network coverage along with green communication capabilities and energy-aware resource management. Cell-free Massive MIMO is a promising 6G technology which offers power optimization by allowing only a subset of access points (APs) to serve a particular user. In this paper, the performance of the proposed network is evaluated for different power control methods. The average mean square error (MSE), average signal-to-noise ratio (SNR) and spectral efficiency (SE) are obtained for different users,transmit powers and pilot lengths. An efficient resource management algorithm namely, MIPA-MCAS is proposed which offers Minimum Interference Power Allocation and Maximum Channel gain AP Selection. It is observed that the spectral efficiency obtained at 95% of all user locations improves by 3.39% with the proposed algorithm. In the end, a comparative analysis is carried out with two other algorithms namely, Round-Robin Power Allocation and Maximum Channel gain AP Selection (RRPA-MCAS) and Random Power Allocation and Maximum Channel gain AP Selection (RPA-MCAS) for the proposed and conventional system models.}
}


@article{DBLP:journals/cn/AkramMLSLC22,
	author = {Waseem Akram and
                  Khalid Mahmood and
                  Xiong Li and
                  Mazhar Sadiq and
                  Zhihan Lv and
                  Shehzad Ashraf Chaudhry},
	title = {An energy-efficient and secure identity based {RFID} authentication
                  scheme for vehicular cloud computing},
	journal = {Comput. Networks},
	volume = {217},
	pages = {109335},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109335},
	doi = {10.1016/J.COMNET.2022.109335},
	timestamp = {Mon, 05 Feb 2024 20:24:11 +0100},
	biburl = {https://dblp.org/rec/journals/cn/AkramMLSLC22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Vehicular Cloud Computing (VCC) is a contemporary paradigm that includes the Internet of Things (IoT), cloud computing, and vehicular networking technologies. VCC offers vehicle-to-device, vehicle-to-infrastructure, and vehicle-to-vehicle communication in which the vehicles can communicate using sensing abilities. VCC is exploiting the IoT environment, cloud architecture, and vehicle resources. However, the energy-efficient privacy of communicators and security of communication are assertive problems in VCC. To accomplish this goal, we present an identity-based authentication scheme for VCC which also uses radio frequency identification (RFID). The security and robustness of the devised scheme are evaluated using informal and formal analysis. The informal analysis shows that our scheme is vigorous to resist various attacks. The formal analysis is done through Random Oracle Model (ROM) which shows that the scheme is secure and efficient. The performance of our scheme is also determined and compared with various related schemes which clearly illustrate the efficiency of the proposed scheme. Thus, our scheme is very efficient for employment in the VCC environment.}
}


@article{DBLP:journals/cn/AlrubeiBR22,
	author = {Subhi Alrubei and
                  Edward A. Ball and
                  Jonathan Michael Rigelsford},
	title = {HDPoA: Honesty-based distributed proof of authority via scalable work
                  consensus protocol for IoT-blockchain applications},
	journal = {Comput. Networks},
	volume = {217},
	pages = {109337},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109337},
	doi = {10.1016/J.COMNET.2022.109337},
	timestamp = {Sun, 04 Aug 2024 19:48:53 +0200},
	biburl = {https://dblp.org/rec/journals/cn/AlrubeiBR22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Applying blockchain technology to the Internet of Things (IoT) provides several advantages when compared to conventional systems, including improving the security by ensuring data integrity and accountability while enabling reliable control over many devices. However, integrating blockchain into IoT systems presents some challenges. A main challenges is designing a consensus protocol that is suitable for the IoT systems, where some devices may lack adequate resources, such as computation power. This paper introduces a novel consensus protocol called honesty-based distributed proof of authority (HDPoA) via scalable work. HDPoA is based on proof of authority (PoA) and proof of work (PoW), with the integration of PoW, HDPoA is able to realize the security advantages provided by PoW. This is achieved by utilizing the IoT devices’ collective computation power to mine and generate a new block.}
}


@article{DBLP:journals/cn/ViolosTTLTV22,
	author = {John Violos and
                  Stylianos Tsanakas and
                  Theodoros Theodoropoulos and
                  Aris Leivadeas and
                  Konstantinos Tserpes and
                  Theodora A. Varvarigou},
	title = {Intelligent Horizontal Autoscaling in Edge Computing using a Double
                  Tower Neural Network},
	journal = {Comput. Networks},
	volume = {217},
	pages = {109339},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109339},
	doi = {10.1016/J.COMNET.2022.109339},
	timestamp = {Sun, 13 Nov 2022 17:53:49 +0100},
	biburl = {https://dblp.org/rec/journals/cn/ViolosTTLTV22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Edge computing is characterized by varying workload intensities that have a strong effect on applications’ performance and requirements in terms of resources. Thus, in order to maintain a sustainable performance a resource autoscaling mechanism that will automatically add or remove computational nodes is needed. This autoscaling mechanism must ensure that the user’s requirements in terms of Quality of Service (QoS) are satisfied, while respecting the Service Level Agreements (SLAs) and delivering always-on services using affordable on-demand computing solutions. The autoscaling could take place proactively or reactively and the adjustability of the resources could be static or dynamic. To this end, the research goal of this paper is to design a novel autoscaling mechanism that minimizes the task execution times and maximizes the corresponding throughput while using the minimum number of resources. In this direction, we propose an Intelligent Horizontal Proactive Autoscaling (IHPA) mechanism that leverages resource usage metrics of processing edge nodes such as CPU, RAM and Bandwidth in order to provide timely scale up and scale down decisions. The IHPA is based on a double tower Deep Learning (DL) architecture. In order to find a close to optimal DL architecture and guarantee the generality of our approach we also propose the innovative hybrid Bayesian Evolution Strategy method. We conduct an extensive simulation of the IHPA with three baseline task offloading mechanisms keeping the same statistical task generation distribution. We also compare the performance of our proposed IHPA against a reactive autoscaling approach and the Kubernetes Horizontal autoscaling mechanism. The results show that our framework shows significant improvements in terms of latency and throughput, while making an optimal use of the available resources.}
}


@article{DBLP:journals/cn/ZhangCSW22,
	author = {Pengfei Zhang and
                  Xiang Cheng and
                  Sen Su and
                  Ning Wang},
	title = {Area coverage-based worker recruitment under geo-indistinguishability},
	journal = {Comput. Networks},
	volume = {217},
	pages = {109340},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109340},
	doi = {10.1016/J.COMNET.2022.109340},
	timestamp = {Sun, 19 Mar 2023 00:07:07 +0100},
	biburl = {https://dblp.org/rec/journals/cn/ZhangCSW22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Location information is usually required for area coverage-based worker recruitment in mobile crowdsensing, which may pose considerable threats to individual privacy without proper privacy protection. In this paper, we investigate the problem of area coverage-based worker recruitment under geo-indistinguishability while considering each participant’s sensing radius, which aims to select a suitable set of participants under a worker number constraint to achieve the maximum coverage ratio for a target region. To this end, we present a geo-indiStinguishable arEa Coverage-based workeR rEcruitmenT approach, referred to as SECRET. In SECRET, to protect each participant’s location, we develop an optimized geographical exponential mechanism OptGEM with solid privacy and utility guarantees. To select the recruited workers based on the obfuscated locations while ensuring large coverage for the target region, we design a coverage-aware worker selection method CWS. We show SECRET satisfies a discrete version of\nɛ\n-geo-indistinguishability. Extensive experiments on two real-world datasets and a synthetic dataset confirm the effectiveness of SECRET.}
}


@article{DBLP:journals/cn/BarmpounakisMKK22,
	author = {Sokratis Barmpounakis and
                  Nikolaos Maroulis and
                  Nikolaos Koursioumpas and
                  Apostolos Kousaridas and
                  Angeliki Kalamari and
                  Panagiotis Kontopoulos and
                  Nancy Alonistioti},
	title = {AI-driven, QoS prediction for {V2X} communications in beyond 5G systems},
	journal = {Comput. Networks},
	volume = {217},
	pages = {109341},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109341},
	doi = {10.1016/J.COMNET.2022.109341},
	timestamp = {Tue, 07 May 2024 20:23:15 +0200},
	biburl = {https://dblp.org/rec/journals/cn/BarmpounakisMKK22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {On the eve of 5G-enabled Connected and Automated Mobility, challenging Vehicle-to-Everything services have emerged towards safer and automated driving. The requirements that stem from those services pose very strict challenges to the network primarily with regard to the end-to-end delay and service reliability. At the same time, the in-network Artificial Intelligence that is emerging, reveals a plethora of novel capabilities of the network to act in a proactive manner towards satisfying the aforementioned challenging requirements. This work presents PreQoS, a computationally-efficient, predictive Quality of Service mechanism that focuses on Vehicle-to-Everything services. PreQoS is able to timely predict specific Quality of Service metrics, such as uplink and downlink data rate and end-to-end delay, in order to offer the required time window to the network to allocate more efficiently its resources. Geographical space discretization and clustering techniques are applied in advance to the prediction process for computational and communication requirements minimization. On top of that, the proactive management of those resources enables the respective Vehicle-to-Everything services and applications to perform any potential Quality of Service-related required adaptations in advance. The evaluation of the proposed mechanism based on a realistic, simulated, Connected and Automated Mobility environment proves the viability and validity of such an approach.}
}


@article{DBLP:journals/cn/YangLZLC22,
	author = {Yi Yang and
                  Fenglei Li and
                  Xinzhe Zhang and
                  Zhixin Liu and
                  Kit Yan Chan},
	title = {Dynamic power allocation in cellular network based on multi-agent
                  double deep reinforcement learning},
	journal = {Comput. Networks},
	volume = {217},
	pages = {109342},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109342},
	doi = {10.1016/J.COMNET.2022.109342},
	timestamp = {Mon, 06 Feb 2023 08:52:34 +0100},
	biburl = {https://dblp.org/rec/journals/cn/YangLZLC22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the massively growing wireless data traffic, the dense cellular network has become a significant mode for the fifth generation (5G) network. To fully utilize the benefit of the cellular network, it is primary to design optimal allocation strategy with limited network resource. In this paper, we investigate the dynamic power allocation problem in downlink cellular network based on multi-agent reinforcement learning (RL), where each base station (BS)-user (UE) is modeled as a RL agent to learn optimal power allocation policy in order to maximize the total system capacity. Due to the non-convex and large-scale characteristic of the optimization problem, the computational complexity of centralized traditional methods is unacceptable in practice. Therefore, the power allocation problem is transformed into a multi-agent RL (MARL) issue which can be solved by Deep Reinforcement Learning (DRL) method in a distributed way. We address the expandability of reward function and state space, in order to adapt the variation of network size, such as the number of BSs or UEs and the coverage area of cells. Moreover, the impacts of learning hyperparameters are evaluated for the algorithmic performance. Finally, the effectiveness and superiority of the proposed method are validated by numerical results in different scenarios.}
}


@article{DBLP:journals/cn/DuongK22,
	author = {Tho Minh Duong and
                  Sungoh Kwon},
	title = {A frame work of handover analysis for randomly deployed heterogeneous
                  networks},
	journal = {Comput. Networks},
	volume = {217},
	pages = {109351},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109351},
	doi = {10.1016/J.COMNET.2022.109351},
	timestamp = {Mon, 26 Jun 2023 20:51:10 +0200},
	biburl = {https://dblp.org/rec/journals/cn/DuongK22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In 5G HetNets, the massive deployments of small cells result in an excessive number of handovers, including both vertical and horizontal handovers, which induces heavy signalling overhead and significantly impact the network performance. However, handover statistics are difficult to analyse due to the random formations and the coverage limitation of small cells. To tackle such analytical challenges, we propose a stochastic geometric analysis scheme in order to capture the statistics and the impact of mobility on handovers. In a single frame-work, we estimate the average numbers of vertical and horizontal handovers that users undergo inside the network, and derive its closed-form expression by approximation. We observe that the total number of handovers is an increasing function of small cell density, whereas the number of vertical handovers is concave. Our results also show that under a sufficient condition, the expected number of handover is independent of mobility pattern but relies only on the travelling distance for a given wireless network. The authenticity of our analysis are verified via simulations.}
}


@article{DBLP:journals/cn/LuglioRRZ22,
	author = {Michele Luglio and
                  Simon Pietro Romano and
                  Cesare Roseti and
                  Francesco Zampognaro},
	title = {Satellite multi-beam multicast support for an efficient community-based
                  {CDN}},
	journal = {Comput. Networks},
	volume = {217},
	pages = {109352},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109352},
	doi = {10.1016/J.COMNET.2022.109352},
	timestamp = {Tue, 07 May 2024 20:23:15 +0200},
	biburl = {https://dblp.org/rec/journals/cn/LuglioRRZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The design and implementation of an efficient end-to-end IP-based infrastructure for the delivery of multimedia content is of paramount importance in current public networks, dominated by the constant growth of video streaming traffic. Content Delivery Networks (CDNs) represent the main technological solution to manage the huge volumes of traffic involved, by guaranteeing high quality levels to applications and low impact to the core networks, thanks to the efficient distribution of content among edge caches that are located as close as possible to end-users. Nonetheless, the hierarchical data distribution associated with CDNs can be in principle subject to inefficiencies, as well as performance limitations in case of congested segments along the end-to-end delivery path. In this context, we propose the exploitation of satellite multicast capabilities offered by modern high throughput satellite (HTS) platforms, in a virtualized-compatible model, to compensate for flaws of terrestrial networks. The role of satellite communication is to offer multicast support (as a complement to landline connectivity) with wide geographical service areas based on the available satellite beams, enabling a popularity-based content distribution support. In addition, multi-beam satellite technology allows for a more fine-grained approach to popularity evaluation based on user location. The proposed service and the related network configuration are described in the paper, in relation with current and future SatCom platforms. We then present the results of the proposed CDN caching algorithms in a simulated environment, showing promising results associated with a preliminary performance evaluation.}
}


@article{DBLP:journals/cn/TranNHDV22,
	author = {Phuong T. Tran and
                  Ba Cao Nguyen and
                  Tran Manh Hoang and
                  Le The Dung and
                  Nguyen Van Vinh},
	title = {Combining multi-RIS and relay for performance improvement of multi-user
                  {NOMA} systems},
	journal = {Comput. Networks},
	volume = {217},
	pages = {109353},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109353},
	doi = {10.1016/J.COMNET.2022.109353},
	timestamp = {Mon, 05 Feb 2024 20:24:11 +0100},
	biburl = {https://dblp.org/rec/journals/cn/TranNHDV22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we propose a theoretical framework to examine the performance of a non-orthogonal multiple access (NOMA) system with multiple users under the support of multiple advanced reconfigurable intelligent surfaces (RISs) and a traditional relay. We derive the analytical expressions of main performance metrics of the proposed multi-RIS-and-relay aided multiple-user NOMA system (so called the RIS-R-NOMA system), including the outage probability (OP) and the achievable data rate (ADR) over Nakagami-\nm\nfading channels. We conduct the Monte-Carlo simulations to confirm the exactness of our mathematical expressions. Numerical results reveal that the OP of the proposed RIS-R-NOMA system is significantly lower than the OPs of the traditional NOMA systems without either RIS or relay (the R-NOMA and RIS-NOMA systems), and the ADR of the proposed RIS-R-NOMA system is much higher than the ADR of the R-NOMA system. Importantly, at high transmit power, the ADRs of both RIS-R-NOMA and R-NOMA systems are similar due to the property of NOMA. Additionally, the effects of various parameters such as the number of reflecting elements (REs), the locations of the RISs, the power allocation coefficients, and the data transmission rates on the performance of the RIS-R-NOMA system are demonstrated.}
}


@article{DBLP:journals/cn/RenQ22,
	author = {Junyu Ren and
                  Tuanfa Qin},
	title = {A novel multidimensional trust evaluation and fusion mechanism in
                  fog-based Internet of Things},
	journal = {Comput. Networks},
	volume = {217},
	pages = {109354},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109354},
	doi = {10.1016/J.COMNET.2022.109354},
	timestamp = {Tue, 06 Dec 2022 13:15:06 +0100},
	biburl = {https://dblp.org/rec/journals/cn/RenQ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the fast advancement of IoT, it has gained more attention from industry and academia. However, because diverse security attacks result in the lack of trust between IoT edge devices and the network, a proper trust mechanism is necessary. To address the issue, a novel trust management approach is proposed in this work. In particular, we have proposed a multidimensional trust evaluation mechanism to comprehensively evaluate the trustworthiness of IoT edge devices, with diverse opinions formed by different network entities after observing. Next, a novel trust fusion scheme named JSDM-AHP that integrates the objective Jensen–Shannon divergence measure (JSDM) and analytic hierarchy process (AHP) is developed to fuse diverse decision factors. Theoretical analysis and simulation results show that the proposed trust strategy has high computation-efficiency, scalability, resilience, robustness, and outperforms all the other compered methods in reliability. Furthermore, with the proposed security approach, diverse cyber attacks such as flooding attacks, random attacks, conflicting behavior attacks, on–off attacks, and recommendation attacks can well be defended against, reflecting the high security of the method.}
}


@article{DBLP:journals/cn/SelimK22,
	author = {Mohamed Y. Selim and
                  Ahmed E. Kamal},
	title = {Self-backhauling failure mitigation using 5G new radio},
	journal = {Comput. Networks},
	volume = {217},
	pages = {109355},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109355},
	doi = {10.1016/J.COMNET.2022.109355},
	timestamp = {Sun, 13 Nov 2022 17:53:49 +0100},
	biburl = {https://dblp.org/rec/journals/cn/SelimK22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {5G network operators will consider the dense deployment of small cells to increase network coverage and capacity. However, in order to install a large number of gNBs, operators will face the challenge of backhauling their traffic to the core network in a cost-effective manner. Although Integrated Access and Backhaul (IAB) using 5G new radio is a promising solution to solve the dilemma of small cells’ backhauling, densifying the network will increase the probability of failure of these links. To cope with this problem, a self-healing scheme is used to mitigate or at least alleviate the effect of backhaul failure. We propose to use IAB with the collaboration of neighboring gNBs to mitigate the failed backhaul link(s). Hence, our goal is to design a pre-planned network capable of providing the minimum rate requirements to its users in the presence of backhaul failure. We formulate a joint resource allocation/backhaul outage compensation optimization problem as a non-convex mixed integer non-linear program. Due to the difficulty of this problem, we divide this problem into two sub-problems, in addition to the use of different approximation and relaxation techniques to find an approximated sub-optimal solution. Simulation results show that the proposed scheme is capable of providing the network users an acceptable continuous, albeit slightly degraded, service during backhaul failure. The degradation percentage is inversely proportional to the network densification for single and multiple failures. Meanwhile, the Degree of Recovery (DoR), i.e., subtracting the degradation percentage from 100, of single failure scenarios range from 95% (for the best case) to 54% (for the worst case). For the multiple failures scenario, the DoR is much lower and can reach zero in case of three concurrent failures}
}


@article{DBLP:journals/cn/RamezanpourJ22,
	author = {Keyvan Ramezanpour and
                  Jithin Jagannath},
	title = {Intelligent zero trust architecture for 5G/6G networks: Principles,
                  challenges, and the role of machine learning in the context of {O-RAN}},
	journal = {Comput. Networks},
	volume = {217},
	pages = {109358},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109358},
	doi = {10.1016/J.COMNET.2022.109358},
	timestamp = {Mon, 28 Aug 2023 21:39:19 +0200},
	biburl = {https://dblp.org/rec/journals/cn/RamezanpourJ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this position paper, we discuss the critical need for integrating zero trust (ZT) principles into next-generation communication networks (5G/6G). We highlight the challenges and introduce the concept of an intelligent zero trust architecture (i-ZTA) as a security framework in 5G/6G networks with untrusted components. While network virtualization, software-defined networking (SDN), and service-based architectures (SBA) are key enablers of 5G networks, operating in an untrusted environment has also become a key feature of the networks. Further, seamless connectivity to a high volume of devices has broadened the attack surface on information infrastructure. Network assurance in a dynamic untrusted environment calls for revolutionary architectures beyond existing static security frameworks. To the best of our knowledge, this is the first position paper that presents the architectural concept design of an i-ZTA upon which modern artificial intelligence (AI) algorithms can be developed to provide information security in untrusted networks. We introduce key ZT principles as real-time Monitoring of the security state of network assets, Evaluating the risk of individual access requests, and Deciding on access authorization using a dynamic trust algorithm, called MED components. To ensure ease of integration, the envisioned architecture adopts an SBA-based design, similar to the 3GPP specification of 5G networks, by leveraging the open radio access network (O-RAN) architecture with appropriate real-time engines and network interfaces for collecting necessary machine learning data. Therefore, this work provides novel research directions to design machine learning based components that contribute towards i-ZTA for the future 5G/6G networks.}
}


@article{DBLP:journals/cn/MPA22,
	author = {Shyama M and
                  Anju S. Pillai and
                  Alagan Anpalagan},
	title = {Self-healing and optimal fault tolerant routing in wireless sensor
                  networks using genetical swarm optimization},
	journal = {Comput. Networks},
	volume = {217},
	pages = {109359},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109359},
	doi = {10.1016/J.COMNET.2022.109359},
	timestamp = {Thu, 27 Oct 2022 21:55:25 +0200},
	biburl = {https://dblp.org/rec/journals/cn/MPA22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A wireless sensor network (WSN) is used in area monitoring, surveillance, virtual reality, artificial intelligence, etc. The interaction between sensor nodes (SNs) and base station (BS) play a major role in WSN. SNs use more energy to transmit data, and the occurrence of faults in these nodes may lead to complete network failure. To ensure enhanced network performance, the incorporation of an efficient fault detection mechanism becomes essential in WSN. The major aim of the work is to improve the self-healing capacity of the network. To meet the above requirement, a fault-tolerant routing path identification with genetical swarm optimization (FTGSO) is introduced in this work. Genetical swarm optimization (GSO) is the integration of the two optimizations like Genetic Algorithm (GA) and Particle swarm optimization (PSO). The cluster head (CH) selection carried out on the basis of residual energy, coverage, communication cost and proximity. Further, a fault-free routing path is introduced by GSO, and a self-healing method is employed to resolve any network connectivity issues and resume the normal system operation. The analysis and simulation outcomes are compared with other optimization algorithms to verify the effectiveness. The evaluation results verify the enhanced performance of the introduced scheme with a higher PDR (packet delivery ratio) of 96.8%, lower energy consumption of 0.19 J with a minimum packet loss ratio of 3.2% and 30 ms of E2E (end-to-end delay) compared to other existing routing protocols. Also, the performance of the proposed method is compared on the basis of E2E, energy efficiency, (PLR) packet loss ratio and PDR.}
}


@article{DBLP:journals/cn/ShariqSLCK22,
	author = {Mohd Shariq and
                  Karan Singh and
                  Chhagan Lal and
                  Mauro Conti and
                  Tayyab Ali Khan},
	title = {{ESRAS:} An efficient and secure ultra-lightweight {RFID} authentication
                  scheme for low-cost tags},
	journal = {Comput. Networks},
	volume = {217},
	pages = {109360},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109360},
	doi = {10.1016/J.COMNET.2022.109360},
	timestamp = {Tue, 07 May 2024 20:23:17 +0200},
	biburl = {https://dblp.org/rec/journals/cn/ShariqSLCK22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Internet of Things (IoT) technologies rapidly evolve and are used in many real-life applications. One of the core technologies used in various IoT applications is Radio Frequency IDentification (RFID) technology. RFID wirelessly and uniquely identifies the tagged objects without a direct line of sight. However, the research community had reported privacy and security-related concerns in RFID systems, where an adversary may tamper, eavesdrop, add, delete, or even modify the transmitted messages over an insecure communication channel.}
}


@article{DBLP:journals/cn/ShaliniRS22,
	author = {P. V. Shalini and
                  V. Radha and
                  Sriram G. Sanjeevi},
	title = {DOCUS-DDoS detection in {SDN} using modified {CUSUM} with flash traffic
                  discrimination and mitigation},
	journal = {Comput. Networks},
	volume = {217},
	pages = {109361},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109361},
	doi = {10.1016/J.COMNET.2022.109361},
	timestamp = {Sun, 13 Nov 2022 17:53:49 +0100},
	biburl = {https://dblp.org/rec/journals/cn/ShaliniRS22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Software Defined Networking (SDN) is a network paradigm with a significant philosophy of separating the data plane from the control plane. This separation helps in achieving centralized control over the entire network and faster data transmission. However, SDN suffers from network security challenges; Distributed Denial of Service (DDoS) is one such significant challenge. Most of the existing SDN DDoS attack detection models have an issue with identifying the genuine benign flash traffic as a DDoS attack. In this paper, we develop DOCUS (DDoS detection in SDN by modified CUSUM) to overcome this major issue, i.e., to identify and separate flash traffic while detecting DDoS attacks, thus reducing false detection of benign traffic as an attack.}
}


@article{DBLP:journals/cn/SaadAAAYM22,
	author = {Muhammad Saad and
                  Afsah Anwar and
                  Ashar Ahmad and
                  Hisham Alasmary and
                  Murat Yuksel and
                  David Mohaisen},
	title = {\emph{RouteChain}: Towards Blockchain-based secure and efficient {BGP}
                  routing},
	journal = {Comput. Networks},
	volume = {217},
	pages = {109362},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109362},
	doi = {10.1016/J.COMNET.2022.109362},
	timestamp = {Sun, 12 Nov 2023 02:17:56 +0100},
	biburl = {https://dblp.org/rec/journals/cn/SaadAAAYM22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Routing on the Internet is defined among autonomous systems (ASes) based on a weak trust model where it is assumed that ASes are honest. While this trust model strengthens the connectivity among ASes, it also results in an attack surface that can be exploited to hijack the routing paths. One such attack is known as the BGP prefix hijacking, in which a malicious AS broadcasts IP prefixes that belong to a target AS, thereby hijacking its traffic. In this paper, we propose RouteChain: a blockchain-based secure BGP routing system that counters BGP hijacking and maintains a consistent view of the Internet routing paths. Towards that, we leverage provenance assurance and tamper-proof properties of blockchains to augment trust among ASes. We group ASes based on their geographical (network) proximity and construct a bi-hierarchical blockchain model that detects false prefixes prior to their spread over the Internet. We evaluate RouteChain using three different consensus protocols and show its effectiveness by drawing a case study with the Youtube hijacking of 2008. Our results show that RouteChain can efficiently detect false prefix announcements and prevent BGP attacks over the Internet.}
}


@article{DBLP:journals/cn/Masoudi-Sobhanzadeh22,
	author = {Yosef Masoudi{-}Sobhanzadeh and
                  Shabnam Emami{-}Moghaddam},
	title = {A real-time IoT-based botnet detection method using a novel two-step
                  feature selection technique and the support vector machine classifier},
	journal = {Comput. Networks},
	volume = {217},
	pages = {109365},
	year = {2022},
	url = {https://doi.org/10.1016/j.comnet.2022.109365},
	doi = {10.1016/J.COMNET.2022.109365},
	timestamp = {Sun, 13 Nov 2022 17:53:49 +0100},
	biburl = {https://dblp.org/rec/journals/cn/Masoudi-Sobhanzadeh22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A botnet, which is a collection of devices polluted by malicious software programs, is among the top security challenges in the Internet of Things (IoT) environments. Therefore, to deal with such an abnormality in these environments, different machine learning-based studies, which have resulted in outstanding findings, have been carried out and applied to predict the botnets. However, the existing techniques may still suffer from three main limitations. First, some of them are not suitable for real-time applications because they spend a lot of time to determine the normal/abnormal traffic. Second, the functionality of some of the approaches is not satisfactory because they ignore/do not utilize the efficient feature selection methods. Third, these studies have usually focused on generating a binary botnet prediction model without taking the attack types into consideration. To reduce the botnet prediction time and address the second and third restrictions, the present study suggested a two-step machine learning method designed based on our previously developed optimization algorithm (WCC) and the support vector machine classifier. The outcomes indicated that the proposed method outperforms the existing approaches since it can precisely classify the data streams into their related groups and make a trade-off between the total number of the selected features and the performance of the prediction model. The results also showed that IP addresses, source ports as well as destination hosts-related features, and the total number of the transferred data streams and their statistical measurements are possible key factors in identifying botnet traffics.}
}
