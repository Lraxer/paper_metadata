@article{DBLP:journals/cn/PremalathaP24,
	author = {Premalatha Baskar and
                  P. Prakasam},
	title = {Optimal Energy-efficient Resource Allocation and Fault Tolerance scheme
                  for task offloading in IoT-FoG Computing Networks},
	journal = {Comput. Networks},
	volume = {238},
	pages = {110080},
	year = {2024},
	url = {https://doi.org/10.1016/j.comnet.2023.110080},
	doi = {10.1016/J.COMNET.2023.110080},
	timestamp = {Sun, 06 Oct 2024 21:22:04 +0200},
	biburl = {https://dblp.org/rec/journals/cn/PremalathaP24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Due to technology development in the recent past, it is observed that an exponential growth in the usage of high speed intelligent devices which includes smart objects, smart home, smart vehicles etc. Therefore, for the efficient transmission between different smart objects/devices situated across different regions, an effective communication is required and the corresponding technology is called as ‘Internet of Things (IoT)’. This leads to an issues in various aspects like, increase in complexity, low data rate & latency and security may reduce the performance of the existing technologies. Therefore, there is a huge requirement of advanced technology which may support ultra-low latency transmission for the task received from the devices. Fog computing (FC) is one of an emerging technology that can improve network performance and provide resource-constrained applications for the IoT devices. In this paper, the Optimal Energy-efficient Resource Allocation (OEeRA) algorithm is proposed based on Minimal Cost Resource Allocation (MCRA) and Fault Identification and Rectification (FIR) algorithms for effective task offloading of IoT-FoG computing networks. The MCRA algorithm is proposed to assign at least one FN and Resource Block (RB) for each device, and also it ensures that each FN is connected with one or more RBs and devices. The leftover RBs are collected and stored in the buffer to replace the faulty RBs, as proposed in the FIR algorithm, which achieves better processing and response time with higher fault detection accuracy. The energy efficiency (EE) of the proposed OEeRA algorithm is computed through MCRA and FIR algorithms by varying FN, RB, and IoT devices. The performance analysis shows that the proposed algorithm achieved the maximum EE of 6.12 × 109 bit/J, 5.69 × 1010 bit/J, and 3.019 × 1010 (bit/J) for varying RBs, IoTs, and FNs, respectively.}
}


@article{DBLP:journals/cn/WuZCZSX24,
	author = {Yutong Wu and
                  Jianyue Zhu and
                  Xiao Chen and
                  Yu Zhang and
                  Yao Shi and
                  Yaqin Xie},
	title = {QoS-based resource allocation for uplink {NOMA} networks},
	journal = {Comput. Networks},
	volume = {238},
	pages = {110084},
	year = {2024},
	url = {https://doi.org/10.1016/j.comnet.2023.110084},
	doi = {10.1016/J.COMNET.2023.110084},
	timestamp = {Thu, 15 Aug 2024 07:54:35 +0200},
	biburl = {https://dblp.org/rec/journals/cn/WuZCZSX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Nowadays, several next-generation multiple access technologies are proposed, and non-orthogonal multiple access (NOMA) is one of the candidates. In NOMA systems, since the utilization of successive interference cancellation (SIC), the SIC order is one of the significant factors to be considered. In the literature, the SIC order is usually determined by the channel gains, which is not stable especially when the users are with similar channels. In this paper, we creatively propose the quality-of-service-based SIC order in the uplink NOMA system, and focus on the resource allocation to maximize the rate. Specifically, we first optimize the powers with given user grouping and provide solutions for different cases of channel gains. Furthermore, the Hungarian algorithm is jointly exploited with the optimized powers. Simulation results show that the proposed algorithm outperforms traditional orthogonal multiple access and even achieves similar rate with the exhaustive search.}
}


@article{DBLP:journals/cn/XiongWHZTZYL24,
	author = {Bing Xiong and
                  Jing Wu and
                  Qiaorong Huang and
                  Jinyuan Zhao and
                  Qiang Tang and
                  Jin Zhang and
                  Kun Yang and
                  Keqin Li},
	title = {Elastically accelerating lookup on virtual {SDN} flow tables for software-defined
                  cloud gateways},
	journal = {Comput. Networks},
	volume = {238},
	pages = {110092},
	year = {2024},
	url = {https://doi.org/10.1016/j.comnet.2023.110092},
	doi = {10.1016/J.COMNET.2023.110092},
	timestamp = {Sat, 10 Feb 2024 18:05:27 +0100},
	biburl = {https://dblp.org/rec/journals/cn/XiongWHZTZYL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent years, Software-Defined Networking has been gradually applied to cloud gateways to provide efficient, reliable and flexible data transmission services for various large-scale cloud platforms. However, massive concurrent accessing produces huge network traffic from tenants to cloud platforms, which aggregates at cloud gateways and brings serious performance bottlenecks regarding packet classification. To solve this problem, this paper proposes an elastically accelerated lookup method of virtual SDN flow tables for software-defined cloud gateways. The method caches active exact flows in virtue of network traffic locality, enabling most packets to directly hit the cache and bypass tuple space search, which significantly accelerates flow table lookup. Focusing on network traffic jitters, the cache adaptively adjusts its capacity according to the dynamic changes of the number of active exact flows to maintain high cache hit rates, aiming to achieve elastic acceleration of flow table lookup. Furthermore, we theoretically derive the performance metrics of our proposed method such as cache hit rates, cache yield rates and average search length, based on the Zipf distribution model of network traffic. Eventually, we evaluate the performance of our proposed elastically accelerated lookup method by experiments with real network traffic traces. Experimental results indicate that our proposed method outperforms existing cache-accelerated methods with stable cache hit rates around 80% and the speedup of average search length up to 2.84 even under network traffic jitters.}
}


@article{DBLP:journals/cn/DouQG24,
	author = {Songshi Dou and
                  Li Qi and
                  Zehua Guo},
	title = {Mitigating the impact of controller failures on QoS robustness for
                  software-defined wide area networks},
	journal = {Comput. Networks},
	volume = {238},
	pages = {110096},
	year = {2024},
	url = {https://doi.org/10.1016/j.comnet.2023.110096},
	doi = {10.1016/J.COMNET.2023.110096},
	timestamp = {Mon, 05 Feb 2024 20:24:12 +0100},
	biburl = {https://dblp.org/rec/journals/cn/DouQG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Emerging cloud services and applications pose different Quality of Service (QoS) requirements for the network, where Software-Defined Wide Area Networks (SD-WANs) play a crucial role in QoS provisioning by introducing network programmability into network flows to enable dynamic flow routing and ensure low data transmission latency for these applications. However, controller failures may happen in SD-WANs, and all programmable flows that the failed controller previously controlled will become offline and lose the network programmability, resulting in the degradation of QoS. Existing control recovery solutions propose to remap offline switches/flows to available active controllers but cannot promise good recovery performance due to the following two problems: (1) the recovery performance suffers from either coarse-grained remapping granularity or introducing extra processing delays, and (2) QoS robustness cannot be guaranteed in the design of recovery solution. To this end, we propose Predator, a QoS-aware network programmability recovery scheme that utilizes the P4 Runtime enabled by existing P4 switches to achieve fine-grained per-flow remapping without introducing extra delays. Specifically, our proposed Predator categorizes flows based on their QoS requirements and smartly recovers offline flows based on their priorities to guarantee the QoS robustness for high-priority flows. Simulation results under real-world topology demonstrate that our proposed Predator can improve the recovered network programmability of high-priority flows by up to 505.5%, and substantially reduce the communication overhead of high-priority flows, compared with baselines.}
}


@article{DBLP:journals/cn/AlHammadiLIA24,
	author = {Ikhlas Al{-}Hammadi and
                  Mingchu Li and
                  Sardar M. N. Islam and
                  Esmail Almosharea},
	title = {Collaborative computation offloading for scheduling emergency tasks
                  in SDN-based mobile edge computing networks},
	journal = {Comput. Networks},
	volume = {238},
	pages = {110101},
	year = {2024},
	url = {https://doi.org/10.1016/j.comnet.2023.110101},
	doi = {10.1016/J.COMNET.2023.110101},
	timestamp = {Mon, 05 Feb 2024 20:24:12 +0100},
	biburl = {https://dblp.org/rec/journals/cn/AlHammadiLIA24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Due to the growing demand for time-intensive tasks, several tasks coexist, some of which last for a long time or only occur once in a while, such as emergencies. Emergencies such as natural disasters, accidents or medical emergencies require immediate attention and often demand real-time execution. Such tasks are the most difficult to plan for and foresee. Planning, resource allocation, and clear communication between all involved parties and network layers are crucial for scheduling emergency tasks. In the extensive literature, when an emergency task triggers, it will be handled like any other regular task. If the deadline is missed, a catastrophe will ensue. They ignored the impact of insufficient mobile edge computing (MEC) capacity and network congestion, which might result in execution delays. Collaborative offloading, which involves distributing computation tasks across multiple servers, shows promise in enhancing MEC network performance, particularly in emergency scenarios. In this context, efficient task scheduling plays a vital role in minimizing the total execution time of regular tasks while meeting the deadlines of emergency tasks. Our proposed scheme utilizes a collaborative offloading approach to schedule emergency tasks in MEC networks, leveraging the computing capacity of edge-deployed MEC servers. By utilizing the software-defined networking (SDN)’s global view of the network, task requests are collected and allocated to suitable MEC servers capable of meeting the demands. To address key challenges, our scheme propose four scheduling algorithms to address the following issues: (i) ensuring tasks are assigned to the nearest MEC server with sufficient computational resources, (ii) controlling a threshold to prevent network congestion, (iii) selecting an optimal collaborative MEC server for executing overloaded tasks based on collaborative offloading decisions, and (iv) allocating resources for emergency tasks when triggered to meet urgent deadlines by stealing resources from regular tasks without compromising their deadlines. Extensive simulations were conducted to assess the effectiveness of the proposed scheme. The results clearly illustrate its enhanced performance in terms of the total execution time of regular tasks and the ability to meet deadlines for emergency tasks.}
}


@article{DBLP:journals/cn/WangMKLFLDZ24,
	author = {Ke Wang and
                  Xiaojuan Ma and
                  Heng Kang and
                  Zheng Lyu and
                  Baorui Feng and
                  Wenliang Lin and
                  Zhongliang Deng and
                  Yun Zou},
	title = {An efficient topology partitioning algorithm for system-level parallel
                  simulation of mega satellite constellation communication networks},
	journal = {Comput. Networks},
	volume = {238},
	pages = {110102},
	year = {2024},
	url = {https://doi.org/10.1016/j.comnet.2023.110102},
	doi = {10.1016/J.COMNET.2023.110102},
	timestamp = {Sat, 08 Jun 2024 13:14:22 +0200},
	biburl = {https://dblp.org/rec/journals/cn/WangMKLFLDZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Satellite Internet, as an important component of the integrated space-ground information network, is a hot research hotspot nowadays. Many scholars have undertaken research in the areas of constellation networking design, network protocol design, and communication performance assessment, and their main research tool is software simulation. Traditional stand-alone network simulation simulators based on OPNET or NS3 are constrained in the simulation efficiency of mega satellite networks because of the limitations of computer hardware conditions and software performance. Based on the above characteristics, we propose a parallel network simulation architecture based on low correlation between different areas of the global satellite network, and in order to improve the parallel network simulation performance, the network topology needs to be divided effectively. Therefore, firstly we consider CPU and memory resource consumption as a measure of topology partitioning performance indicators, propose a resource assessment algorithm and use the result of this assessment as the topology partitioning optimization objective; secondly, we propose a load balancing based intelligent topology partitioning algorithm (LBTP); thirdly, we propose a time slice algorithm (TSA) for parallel simulation in each time cycle. To demonstrate the algorithm proposed in this paper, we built a simulation platform based on the combination of STK (Satellite Tool Kit), OPNET and Proxmox VE, and experimentally verified that the proposed architecture and algorithm significantly improve the simulation efficiency.}
}


@article{DBLP:journals/cn/KashifK24,
	author = {Muhammad Kashif and
                  K{\"{u}}bra Kalkan},
	title = {EPIoT: Enhanced privacy preservation based blockchain mechanism for
                  internet-of-things},
	journal = {Comput. Networks},
	volume = {238},
	pages = {110107},
	year = {2024},
	url = {https://doi.org/10.1016/j.comnet.2023.110107},
	doi = {10.1016/J.COMNET.2023.110107},
	timestamp = {Sat, 10 Feb 2024 18:05:27 +0100},
	biburl = {https://dblp.org/rec/journals/cn/KashifK24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the increasing popularity of the Internet of things (IoT) and giving the end users the opportunity of collecting and analyzing the data by these IoT devices give rise to ultimate privacy concern and is attracting significant attention nowadays. These IoT devices may contain highly sensitive data and data sharing processes which may lead to security and privacy concerns. To surmount these issues, the interaction of IoT with blockchain for a secure transaction is accepted as a candidate solution. However, the innate behavior of blockchain containing complex mathematical proofs and consensus protocol requires high computational power making it less favorable for IoT devices to be connected with. Motivated by a private by-design framework and emphasizing greater control and setting of privacy preferences by the data owner, this paper complements our previous work on privacy preservation in IoT networks. In this paper, we design and propound a complete blockchain-based privacy-preserving framework by deploying service-oriented layers concepts and low computation cryptography, and a less complex consensus protocol to address the privacy concern. Moreover, this paper will unravel the complete end-to-end architecture of IoT-based blockchain purposely build for secure transactions in IoT networks. Security analysis is conducted using AVISPA tool to show that the proposed algorithms attain the desired security goals. This is followed by extensive simulation experiments and ultimate output results cultivating it much favorably for the deployment of IoT applications in real life.}
}


@article{DBLP:journals/cn/AlamATSM24,
	author = {Amjad Alam and
                  Kamran Ali and
                  Ramona Trestian and
                  Purav Shah and
                  Glenford Mapp},
	title = {Joint energy and spectral optimization in Heterogeneous Vehicular
                  Network},
	journal = {Comput. Networks},
	volume = {238},
	pages = {110111},
	year = {2024},
	url = {https://doi.org/10.1016/j.comnet.2023.110111},
	doi = {10.1016/J.COMNET.2023.110111},
	timestamp = {Sat, 08 Jun 2024 13:14:22 +0200},
	biburl = {https://dblp.org/rec/journals/cn/AlamATSM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the latest developments in both the automotive and communications industries, especially concerning the emerging 5G networks, IoV, and the adoption of Vehicle-to-Everything (V2X) connectivity, there has been a shift towards the establishment of Heterogeneous Vehicular Networks (HetVNets) environments. The rapid growth of data traffic and the drastic expansion of heterogeneous network infrastructure have resulted in a significant increase in energy consumption within wireless communication systems. Balancing energy efficiency and spectral efficiency has become a major challenge in Heterogeneous Vehicular networks, particularly concerning energy optimization, making the design of network systems considerably more challenging. Therefore, this paper attempts to optimize the energy utilized for each packet transmission, considering its stochastic nature and the optimized control parameters of two meta-heuristic algorithms-Particle Swarm Optimization and Artificial Bee Colony Optimization. The optimization process is executed using the Particle Bee Colony Swarm algorithm. Subsequently, a comparison is made with other proposed algorithms, namely LDOD, FO, RO, and MATO, in terms of energy efficiency and spectral efficiency. The performance analysis reveals that the numerical results outperform existing algorithms, demonstrating a 30.32% increase in spectral efficiency and 73.25% increase in energy efficiency.}
}


@article{DBLP:journals/cn/IslamPG24,
	author = {SK Hafizul Islam and
                  Krittibas Parai and
                  Daya Sagar Gupta},
	title = {{PF-IBDA:} Provably secure and pairing-free identity-based deniable
                  authentication protocol for {MANET} environments},
	journal = {Comput. Networks},
	volume = {238},
	pages = {110113},
	year = {2024},
	url = {https://doi.org/10.1016/j.comnet.2023.110113},
	doi = {10.1016/J.COMNET.2023.110113},
	timestamp = {Sun, 18 Feb 2024 17:03:25 +0100},
	biburl = {https://dblp.org/rec/journals/cn/IslamPG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Mobile Adhoc Network (MANET) is used in various real-time applications, such as e-voting, army tactical communication, health-care applications, disaster rescue, online message exchange, etc. However, source authentication and deniability are essential properties in such applications. Typically, these properties can be achieved using a deniable authentication (DA) protocol. With the help of a DA protocol, a mobile receiver node can directly verify the source, another mobile node, of a message without consulting a trusted third party (TTP). Recently, many identity-based deniable authentication (IBDA) protocols have been proposed. Most of these protocols are insecure and computationally expensive since they use costly operations, such as bilinear pairing and map-to-point hash function. We proposed a pairing-free identity-based deniable authentication (PF-IBDA) protocol for MANET environments. We proved that the PF-IBDA protocol could provide indistinguishability against adaptive chosen ciphertext attack (IND-CCA2) in the random oracle model (ROM) based on the hardness assumption of the elliptic curve computational Diffie–Hellman (ECCDH) problem. We have computed the execution time of PF-IBDA protocol in different security levels: 80-bit, 112-bit, 128-bit, 192-bit, and 256-bit on a mobile device using the JPBC library and compared it with the state-of-the-art IBDA protocols. We found that the proposed PF-IBDA protocol is more efficient than the existing IBDA protocols.}
}


@article{DBLP:journals/cn/LeLWH24,
	author = {Siqi Le and
                  Yingxu Lai and
                  Yipeng Wang and
                  Huijie He},
	title = {An adaptive classification and updating method for unknown network
                  traffic in open environments},
	journal = {Comput. Networks},
	volume = {238},
	pages = {110114},
	year = {2024},
	url = {https://doi.org/10.1016/j.comnet.2023.110114},
	doi = {10.1016/J.COMNET.2023.110114},
	timestamp = {Mon, 05 Feb 2024 20:24:11 +0100},
	biburl = {https://dblp.org/rec/journals/cn/LeLWH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent years, to address the classification problem of unknown traffic in open network environments, numerous deep learning (DL)-based classification techniques have been proposed. Among these techniques, the single threshold-based DL method has gained significant popularity. However, the classification boundary constructed by this method is inaccurate, thus leading to the misclassification of known and unknown traffic. In this paper, we propose an adaptive classification and updating method for accurate application-level classification of known and unknown traffic in open environments. We adaptively construct individualized and accurate decision boundaries for each class of known traffic, which avoids misclassification cases caused by a single threshold and achieves accurate separation of known and unknown traffic. To provide a more accurate feature representation for the construction of the decision boundary, we also introduce an additional angular loss function to guide the model in learning more accurate flow features. In addition, to cope with the constant emergence of new classes of traffic in real network environments, our proposed method adaptively updates the model to respond to changes in network traffic classes. The proposed method is evaluated on two datasets, and the experimental results show that our proposed method has excellent classification accuracy and outperforms the state-of-the-art unknown traffic classification methods.}
}


@article{DBLP:journals/cn/GuWZSYLL24,
	author = {Xiaolin Gu and
                  Wenjia Wu and
                  Yusen Zhou and
                  Aibo Song and
                  Ming Yang and
                  Zhen Ling and
                  Junzhou Luo},
	title = {{TEA-RFFI:} Temperature adjusted radio frequency fingerprint-based
                  smartphone identification},
	journal = {Comput. Networks},
	volume = {238},
	pages = {110115},
	year = {2024},
	url = {https://doi.org/10.1016/j.comnet.2023.110115},
	doi = {10.1016/J.COMNET.2023.110115},
	timestamp = {Sat, 10 Feb 2024 18:05:27 +0100},
	biburl = {https://dblp.org/rec/journals/cn/GuWZSYLL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recently, radio frequency fingerprints (RFFs) have been widely applied for smartphone identification, since RFFs are distinguishable and hard to imitate. Compared with other types of RFFs, carrier frequency offset (CFO) in Wi-Fi signals is more robust and practical. However, when many smartphones need to be identified, the probability of CFO collision is high due to the weak distinguishability of CFO, and thus the primitive CFO-based identification solution will perform poorly. Fortunately, we find that the CFO varies with crystal oscillator temperature. Inspired by the phenomenon, we can actively adjust the crystal oscillator temperature to increase the difference between Wi-Fi device fingerprints for CFO collision mitigation. Firstly, we propose a non-intrusive temperature sensing and adjustment solution, which can obtain crystal oscillator temperature accurately and actively adjust its temperature to specified values without any additional hardware. Then, we investigate the temperature selection problem which aims to maximize overall differences among all smartphones, and propose the corresponding algorithm that combines greedy strategy and simulated annealing to assign a proper temperature value to each smartphone for identification. Finally, we implement the TEA-RFFI system and conduct several sets of experiments under the cases of different positions, time periods and scenarios. Experimental results demonstrate that TEA-RFFI can effectively identify 20 smartphones with over 90% precision, recall and F1-score. Even when the smartphones are moving, our proposed system still can identify them with over 89% precision, recall and F1-score.}
}


@article{DBLP:journals/cn/LinW24,
	author = {Hsin{-}Tsung Lin and
                  Pi{-}Chung Wang},
	title = {Scalable packet classification based on rule categorization and cross-producting},
	journal = {Comput. Networks},
	volume = {238},
	pages = {110116},
	year = {2024},
	url = {https://doi.org/10.1016/j.comnet.2023.110116},
	doi = {10.1016/J.COMNET.2023.110116},
	timestamp = {Sat, 10 Feb 2024 18:05:27 +0100},
	biburl = {https://dblp.org/rec/journals/cn/LinW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Packet classification performs multidimensional point location upon fields in packet headers to categorize packets into multiple forwarding classes based on pre-defined rules. It plays an important role for the data plane of software-defined networking (SDN). Packet classification is also applied to support quality of service and network security. In this work, we propose an algorithm, Segregated Cross-producting, to improve the scalability of cross-producting in term of storage. Our algorithm starts by categorizing rules according to their length combinations, where the rules of the same length combination do not incur any storage penalty for cross-producting. Then, the algorithm selectively merges rules of different length combinations to improve the search performance. Our scheme is suitable for parallel implementation to further improve speed performance and can support real-time incremental updates. We extensively evaluate the performance of our scheme with rulesets of different sizes and characteristics. The experiment results show that our scheme can provide superior scalability for both speed and space performance.}
}


@article{DBLP:journals/cn/YangZLZL24,
	author = {Sijin Yang and
                  Lei Zhuang and
                  Julong Lan and
                  Jianhui Zhang and
                  Bingkui Li},
	title = {Reuse-based online joint routing and scheduling optimization mechanism
                  in deterministic networks},
	journal = {Comput. Networks},
	volume = {238},
	pages = {110117},
	year = {2024},
	url = {https://doi.org/10.1016/j.comnet.2023.110117},
	doi = {10.1016/J.COMNET.2023.110117},
	timestamp = {Sun, 04 Aug 2024 19:48:53 +0200},
	biburl = {https://dblp.org/rec/journals/cn/YangZLZL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Deterministic networks plan the entire network traffic and calculate the scheduling time to meet the critical traffic requirements of specific domains, enabling real-time and deterministic interaction of massive data. However, in dynamic industrial automation scenarios where devices undergo changes, existing mechanisms face challenges in quickly responding to dynamic transmission demand changes caused by rapid traffic migration. To address this issue, this paper proposes a reuse-based online scheduling mechanism that utilizes dynamic path planning of flows and coordinated scheduling of time slots to achieve deterministic transmission of dynamic flows. In the offline phase, the mechanism proposes a backbone link selection and a scalable intelligent routing strategy, constructs a set of routing and scheduling co-design constraints, and generates an offline scheduling table using an iterative scheduling algorithm. In the online scheduling phase, a reuse-based online scheduling algorithm is proposed to achieve rapid scheduling and deterministic transmission of dynamic real-time flows. It utilizes the offline scheduling results and the period offset of migrated flows. The reuse of offline scheduling results reduces computation time and expands the solution space. Experimental results demonstrate that the proposed mechanism achieves a maximum increase in scheduling success rate of 37.3% and reduces time costs by up to 66.6% compared to existing online scheduling algorithms.}
}


@article{DBLP:journals/cn/ZhangHAHCXZ24,
	author = {Ze Zhang and
                  Chingfang Hsu and
                  Man Ho Au and
                  Lein Harn and
                  Jianqun Cui and
                  Zhe Xia and
                  Zhuo Zhao},
	title = {PRLAP-IoD: {A} PUF-based Robust and Lightweight Authentication Protocol
                  for Internet of Drones},
	journal = {Comput. Networks},
	volume = {238},
	pages = {110118},
	year = {2024},
	url = {https://doi.org/10.1016/j.comnet.2023.110118},
	doi = {10.1016/J.COMNET.2023.110118},
	timestamp = {Fri, 19 Jul 2024 08:52:32 +0200},
	biburl = {https://dblp.org/rec/journals/cn/ZhangHAHCXZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent years, the industry and research have cast great attention to the Internet of Drones (IoD), which is becoming progressively popular since it can bring a great convenience to various application scenarios, such as national map exploration, public safety monitoring and automated military applications. In these scenarios, Unmanned Aerial Vehicles (UAVs) (called drones) will be used to collect private information. Due to the fact that the private information are very sensitive, and drones working in public places easily suffer from physical capture or tampering attacks, the primary concern is that this information could be collected by adversaries or unauthorized users. In addition, as resource-constrained devices, drones are mostly equipped with small memory and have limited computing power. Therefore, how to ensure robust security as much as possible while achieving lightweight computing and communication costs has become an urgent problem to be solved in this field. In this paper, we propose A PUF-based Robust and Lightweight Authentication Protocol for Drone-Gateway and Drone-Drone Communication (PRLAP-IoD) to address these issues. Both formal security validation using conventional tools (ROR Model and AVISPA) and other informal security analysis clearly demonstrate that PRLAP-IoD can not only provide physical security, but also defend against a variety of known attacks. Finally, compared with the recent Authentication and Key Agreement (AKA) schemes, PRLAP-IoD can attain a delicate balance between computation cost and communication cost in IoD environment.}
}


@article{DBLP:journals/cn/KankaneSM24,
	author = {Bhawna Kankane and
                  Sandeep Sharma and
                  Rajesh Mishra},
	title = {{\(\kappa\)}-Coverage Reliability for Wireless Multihop Network incorporating
                  Boundary Effect},
	journal = {Comput. Networks},
	volume = {238},
	pages = {110119},
	year = {2024},
	url = {https://doi.org/10.1016/j.comnet.2023.110119},
	doi = {10.1016/J.COMNET.2023.110119},
	timestamp = {Sat, 10 Feb 2024 18:05:27 +0100},
	biburl = {https://dblp.org/rec/journals/cn/KankaneSM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Coverage is one of the crucial performance measures for Wireless Multihop Networks (WMN) and is widely explored by researchers. The coverage performance of the network indicates how effectively the deployed network is able to provide the required coverage for a given period of time. The coverage performance of a finite network is influenced by different factors such as the presence of obstacles in the signal propagation path, the shape and size of the network deployment region, sensor node characteristics, and many others. Therefore, it is necessary to compute the performance of the network before its actual deployment in the desired region. The existing paper proposes an analytical solution for the network coverage considering sensor node failure and boundary effect using three different sensing models i.e., Boolean, Shadow Fading, and Elfes, separately. The Boolean Sensing Model (BSM) is deterministic and ignores the channel randomness, whereas the other two are probabilistic sensing models and are more realistic as they also consider the channel randomness caused by environmental factors. In the existing research, coverage estimation is determined separately for each individual model. However, coverage estimation for all three models and coverage reliability under boundary conditions have not been explored in the literature yet. Coverage reliability is another crucial metric determining how long a network can provide the required coverage. This paper aims to compute the Network Coverage Reliability (NCR) of a WMN deployed in given environments and with sensor node failure conditions. We have proposed an analytical solution to estimate the NCR of a WMN deployed in a finite circular region considering boundary effect using all three models viz., BSM, Shadowing & Multipath Fading (SMF), and Elfes Sensing Model (ESM) assuming sensor node failure condition. The Mean Time to Failure (MTTF) parameter has been determined for all three models and based on that the value of NCR is estimated. The proposed work considers\nκ\n-coverage reliability with\n1\n≤\nκ\n≤\n3\nwhere\nκ\nis the number of distinct sensor node required to cover the target and render desired NCR for different path fading and non-fading sensing models. The analytical results are validated through simulation runs and found to be consistent. Further, we have analyzed the impact of different parameters, such as the number of sensor node, sensing range, SMF parameters, sensor failure rate, and required reliability on the\nκ\n-coverage and\nκ\n-coverage reliability, referred to as NCR.}
}


@article{DBLP:journals/cn/YangRYS24,
	author = {Xiaodu Yang and
                  Sijie Ruan and
                  Yinliang Yue and
                  Bo Sun},
	title = {PETNet: Plaintext-aware encrypted traffic detection network for identifying
                  Cobalt Strike {HTTPS} traffics},
	journal = {Comput. Networks},
	volume = {238},
	pages = {110120},
	year = {2024},
	url = {https://doi.org/10.1016/j.comnet.2023.110120},
	doi = {10.1016/J.COMNET.2023.110120},
	timestamp = {Sat, 10 Feb 2024 18:05:27 +0100},
	biburl = {https://dblp.org/rec/journals/cn/YangRYS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cobalt Strike is the most prevalent attack tool abused by cyber-criminals to achieve command and control on victim hosts over HTTPS traffics. It appears in many ransomware attacks and espionage attacks, threatening public privacy and national security. Therefore, it is of significant value to detect Cobalt Strike HTTPS traffics effectively. However, existing methods could be easily deceived by variable infrastructures or disguised certificates used by attackers, or do not adequately capture the multi-aspect information and their interrelations in encrypted traffics. To overcome these limitations, in this paper, we propose a Plaintext-aware Encrypted Traffic Detection Network (PETNet) to identify Cobalt Strike HTTPS traffics, which contains three main modules: (1) Meta Information Modeling, which parses handshake payloads into semantically explicit identity-agnostic meta features, avoiding being disturbed by infrastructures or certificates; (2) Sequential Information Modeling, which models the interaction between attackers and victims via a Transformer encoder, and captures the interrelations among multi-aspects of traffics by a meta-information-guided attention mechanism, realizing configuration-aware encoding of encrypted contents; (3) Fusion & Prediction, which fuses the interrelated meta information and sequential information to make the final prediction. We conduct extensive experiments on a close-world and four open-world datasets. PETNet outperforms the best baseline by 53.42% in F1-score on average, and remains robust to the concept drift issue during the test period of 14 months, proving its effectiveness and generalization ability.}
}


@article{DBLP:journals/cn/WangTY24,
	author = {Rui Wang and
                  Gang Tian and
                  Shi Ying},
	title = {MicroCM: {A} cloud monitoring architecture for microservice invocation},
	journal = {Comput. Networks},
	volume = {238},
	pages = {110121},
	year = {2024},
	url = {https://doi.org/10.1016/j.comnet.2023.110121},
	doi = {10.1016/J.COMNET.2023.110121},
	timestamp = {Thu, 25 Jan 2024 09:25:21 +0100},
	biburl = {https://dblp.org/rec/journals/cn/WangTY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the complex operating environment, it is difficult to find the root of the issue when there are some time-consuming or error performance issues when executing the request. Aiming at resolving the above challenge, this paper designs and implements a cloud monitoring architecture for microservice invocation MicroCM, by monitoring and tracking the service invocation procedure to get performance data of each link in the transaction request, so as to support the localization of the performance bottleneck in the microservice applications. The monitoring architecture covers the whole process from data acquisition, data transmission, data storage to data display. The monitoring system is designed and implemented according to the proposed cloud monitoring architecture. Finally, the monitoring system is applied to an actual case in this paper. It introduces the process of deployment and configuration of the monitoring system, and monitors a specific scene to verify the functionality implemented by the system. It also conducts a performance impact experiment for this monitoring system by using pressure testing. From the results, the monitoring system presents the process of transaction request executions completely and can locate the time-consuming performance issue effectively. In addition, the system generates low interference.}
}


@article{DBLP:journals/cn/KumarA24,
	author = {Neeraj Kumar and
                  Rifaqat Ali},
	title = {A smart contract-based robotic surgery authentication system for healthcare
                  using 6G-Tactile Internet},
	journal = {Comput. Networks},
	volume = {238},
	pages = {110133},
	year = {2024},
	url = {https://doi.org/10.1016/j.comnet.2023.110133},
	doi = {10.1016/J.COMNET.2023.110133},
	timestamp = {Sun, 06 Oct 2024 21:22:03 +0200},
	biburl = {https://dblp.org/rec/journals/cn/KumarA24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {An intelligent robotic surgical system, utilizing the capabilities of 6G-enabled Tactile Internet (TI) and blockchain technology, holds remarkable promise for providing remote healthcare services in real-time. This system has the potential to deliver high-quality and reliable healthcare services with a focus on responsiveness. It holds considerable benefits for society, particularly in terms of achieving exceptionally accurate surgical diagnoses. Yet, contemporary robotic surgery systems face challenges such as security, privacy, reliability, latency, and the costly implications of blockchain-based storage. These issues curtail the immediate global implementation of tactile internet in surgical procedures. In order to address the previously mentioned concerns, we present a new solution referred to as “A Smart Contract-Based Robotic Surgery Authentication System for Healthcare Using 6G-Tactile Internet”. It is an innovative framework for intelligent and blockchain-driven tactile internet. By incorporating a smart contract, we aim to effectively tackle the challenges associated with security, privacy, and the transparency. The introduced approach also effectively thwarts the implementation of malicious commands that might be transmitted by an unauthorized individual. The utilization of the 6G communication channel substantially reduces the latency challenges associated with exchanging surgical commands. The security of the suggested protocol is formally showcased through the utilization of the Real-Or-Random Oracle (ROR) model and Scyther simulation tool. Furthermore, an informal security analysis is conducted to validate and support the findings from the formal security analyses. We conduct simulations of the proposed protocol utilizing the Multi-precision Integer and Rational Arithmetic Cryptographic Library (MIRACL). Moreover, the performance and comparative analysis illustrate that the presented solution outperforms currently existing approaches.}
}


@article{DBLP:journals/cn/ChakourMDB24,
	author = {Imane Chakour and
                  Sajida Mhammedi and
                  Cherki Daoui and
                  Mohamed Baslam},
	title = {Unlocking QoS Potential: Integrating IoT services and Monte Carlo
                  Control for heterogeneous IoT device management in gateways},
	journal = {Comput. Networks},
	volume = {238},
	pages = {110134},
	year = {2024},
	url = {https://doi.org/10.1016/j.comnet.2023.110134},
	doi = {10.1016/J.COMNET.2023.110134},
	timestamp = {Thu, 25 Jan 2024 09:25:21 +0100},
	biburl = {https://dblp.org/rec/journals/cn/ChakourMDB24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The exponential surge in IoT devices has presented significant challenges in managing network traffic and maintaining Quality of Service (QoS) in IoT networks. To tackle these challenges, ongoing efforts are focused on developing innovative solutions that leverage advanced traffic management techniques, robust QoS mechanisms, and enhanced security protocols. Addressing these obstacles is crucial for the continued growth and success of the IoT system, enabling seamless integration of smart devices and revolutionizing multiple industries and sectors by providing unparalleled connectivity and intelligence. This article proposes an innovative approach to enhance the management of heterogeneous IoT devices and ensure Quality of Service (QoS) in IoT networks. Integrating device categories into the QoS policy aims to optimize overall performance while addressing the diverse QoS requirements of different device categories. The benefits of considering device categories include tailored resource allocation, improved user satisfaction, customized QoS handling, and scalability. The proposed approach utilizes the Monte Carlo Control algorithm to learn an optimal QoS policy through simulations of traffic scenarios. Our paper highlights Monte Carlo Control’s (MCC) rapid learning in diverse IoT settings, peaking at 50 episodes, compared to Q-learning’s 100 episodes and dynamic programming’s 200 episodes. Specifically, in audio IoT, MCC achieved 730 packets/second throughput with a 50 ms delay, outperforming QL (723 packets/second, 134 ms) and DP (700 packets/second, 171 ms). These results underscore MCC’s vital role in elevating IoT Quality of Service, making it pivotal for system performance and user experience optimization.}
}
