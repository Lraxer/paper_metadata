@article{DBLP:journals/cn/MaoZHBK21,
	author = {Qian Mao and
                  Lin Zhang and
                  Fei Hu and
                  Elizabeth Serena Bentley and
                  Sunil Kumar},
	title = {Deep Learning (DL)-based adaptive transport layer control in {UAV}
                  Swarm Networks},
	journal = {Comput. Networks},
	volume = {201},
	pages = {108511},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108511},
	doi = {10.1016/J.COMNET.2021.108511},
	timestamp = {Mon, 06 Dec 2021 17:33:14 +0100},
	biburl = {https://dblp.org/rec/journals/cn/MaoZHBK21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper focuses on the congestion control issues in Unmanned Aerial Vehicle (UAV) Swarm Networks (USNs). In a USN, many network factors can cause segment loss, including dynamic swarming, high mobility, and link fading loss. With traditional transport layer protocols such as Transmission Control Protocol (TCP), these losses are interpreted as congestion events and will cause the data sending rate being decreased dramatically, therefore impacting throughput. In this paper, a learning-based adaptive network coding scheme is proposed to handle segment loss. In this scheme, a certain amount of redundancy is attached to the original data. If the segment loss is caused by random factors (such as radio interference), the lost segments are retrieved by decoding. However, if the loss is caused by congestion, the sender will retransmit the lost segments and decrease the sending rate. The coding rate is a critical factor, which should guarantee that the random loss can be retrieved by decoding while the congestion loss triggers retransmission and sending rate deduction. To achieve this goal, a Deep Learning (DL) algorithm is proposed, which comprehensively considers the wireless network conditions and dynamically optimizes the coding rate. Our experimental results show that the DL-based network coding scheme provides improved throughput and end-to-end delay compared to the TCP and general network coding schemes.}
}


@article{DBLP:journals/cn/AkterDLK21,
	author = {Rubina Akter and
                  Van{-}Sang Doan and
                  Jae{-}Min Lee and
                  Dong{-}Seong Kim},
	title = {{CNN-SSDI:} Convolution neural network inspired surveillance system
                  for UAVs detection and identification},
	journal = {Comput. Networks},
	volume = {201},
	pages = {108519},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108519},
	doi = {10.1016/J.COMNET.2021.108519},
	timestamp = {Sun, 12 Nov 2023 02:17:56 +0100},
	biburl = {https://dblp.org/rec/journals/cn/AkterDLK21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent years, the availability of commercial unmanned air vehicles (UAVs) has increased enormously because of device miniaturization and low cost. However, the abuse of UAVs needs to be investigated to prevent serious security threats for civilians. Therefore, this paper presents a convolutional neural network-based surveillance system for drone detection and its type identification, namely CNN-SSDI. The network architecture is cleverly designed based on deep convolution layers to successfully learn all intrinsic feature maps of radio-frequency signals that are collected from three different types of drones. Further, a detailed comparative analysis of various kernel impairments of the convolution layer structure was investigated under various performance metrics evaluation and higher accuracy in drone surveillance systems. According to the empirical results, CNN-SSDI can detect a UAV with 99.8% accuracy and recognize drone types with an accuracy of 94.5%, which outperforms other existing drone detection and identification techniques.}
}


@article{DBLP:journals/cn/ZhaoCDGZT21,
	author = {Yuyu Zhao and
                  Guang Cheng and
                  Yu Duan and
                  Zhouchao Gu and
                  Yuyang Zhou and
                  Lu Tang},
	title = {Secure IoT edge: Threat situation awareness based on network traffic},
	journal = {Comput. Networks},
	volume = {201},
	pages = {108525},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108525},
	doi = {10.1016/J.COMNET.2021.108525},
	timestamp = {Mon, 03 Jan 2022 22:01:37 +0100},
	biburl = {https://dblp.org/rec/journals/cn/ZhaoCDGZT21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Threat situation awareness is one of the new major technologies to avoid network attacks and ensure equipment security. Facing the current IoT network architecture which is characterized by end equipments’ complex services, huge traffic and computing marginalization, real time threat situation awareness based on network traffic can effectively warn and clean latent threat. However, the existing threat situation awareness methods are mostly unitary and dependent on the central node for collection, detection and cleaning. First, it takes too much bandwidth and is not suitable for high-speed scenes. Second, the transmission of traffic or log leads to poor privacy and risk of leakage. Most of all, the perception time is too long, which leads to the performance degradation. This paper proposes a threat situation awareness architecture based on IoT edge and network traffic. Firstly, this paper designs an edge computing device SIE based on CPU and FPGA, the FPGA pipeline is used to analyze the traffic and summarize it in real time. A fast threat situation detection method deployed on SIE’s CPU is proposed which uses flow entropy algorithm to generate situation information. Secondly, this paper introduces the threat situation understanding method based on machine learning. It improves the AdaBoost algorithm and uses uploaded situation information to judge the threat in the traffic. Finally, the method obtains the defensive measure according to the threat intelligence. It can issue the SIE for situation projection and completes threat situation awareness closed loop. Experimental results on KDD99, UNSW-NB15 show that under the premise of ensuring the normal business of IoT equipment and the second level early warning ability, the proposed method can still show good performance under the recognition recall rate, success rate of cleaning threat and other indicators.}
}


@article{DBLP:journals/cn/MaYCM21,
	author = {Baolin Ma and
                  Chao Yang and
                  Mingzhe Chen and
                  Jianfeng Ma},
	title = {GramMatch: An automatic protocol feature extraction and identification
                  system},
	journal = {Comput. Networks},
	volume = {201},
	pages = {108528},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108528},
	doi = {10.1016/J.COMNET.2021.108528},
	timestamp = {Wed, 15 Dec 2021 10:28:58 +0100},
	biburl = {https://dblp.org/rec/journals/cn/MaYCM21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Network protocol identification, or traffic classification, plays a key role in field of network monitoring, management, and optimization. Deep Packet Inspection (DPI) technology is the most popular and effective way of protocol identification. However, the accuracy of deep packet inspection often depends on the selection of protocol features, which is a complex task. To cope with the ever-increasing types of network protocols and identify traffic of them, we propose a basic model of protocol traces, and propose GramMatch, an automatic protocol feature extraction and identification system based on the model. It first aligns packets in the protocol flows by similarity with order, and then uses n-gram’s statistical features for keyword segmentation and gets keywords’ correlated characteristic as the protocol features. Finally, it performs protocol identification based on features extracted. We test GramMatch on eleven commonly used protocols and compare it with other algorithms and DPI programs. Our results prove that GramMatch is an effective, broadly applicable and better protocol feature extraction and identification system which can identify the network traces of a protocol with a weighted precision reached up to 99.81%, and a weighted recall reached up to 98.21%.}
}


@article{DBLP:journals/cn/YuCWW21,
	author = {Chuan Yu and
                  Shuhui Chen and
                  Fei Wang and
                  Ziling Wei},
	title = {Improving 4G/5G air interface security: {A} survey of existing attacks
                  on different {LTE} layers},
	journal = {Comput. Networks},
	volume = {201},
	pages = {108532},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108532},
	doi = {10.1016/J.COMNET.2021.108532},
	timestamp = {Mon, 28 Aug 2023 21:39:18 +0200},
	biburl = {https://dblp.org/rec/journals/cn/YuCWW21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The 4G/Long Term Evolution (LTE) has become the dominant mobile access technology worldwide so far, while the development of the 5G/NR (New Radio) cellular network is also accelerating. Like the previous generations of mobile networks, the LTE network has encountered many security problems during its practical implementation and use process, which are exploited by various wild attacks. Given the similarities between 5G and LTE in the protocol stack of air interface, it is an excellent opportunity to secure 5G mobile networks by reviewing existing attacks against LTE from the perspective of protocol layers.}
}


@article{DBLP:journals/cn/ZhangZ21,
	author = {Zhishuo Zhang and
                  Shijie Zhou},
	title = {A decentralized strongly secure attribute-based encryption and authentication
                  scheme for distributed Internet of Mobile Things},
	journal = {Comput. Networks},
	volume = {201},
	pages = {108553},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108553},
	doi = {10.1016/J.COMNET.2021.108553},
	timestamp = {Mon, 28 Aug 2023 21:39:21 +0200},
	biburl = {https://dblp.org/rec/journals/cn/ZhangZ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Internet of Things (IoT) networks has been widely deployed as the distributed computing and communication component in the smart city. The security problems in the distributed IoT-assisted computing architecture are still noteworthy and has not been solved satisfactorily. So in this paper, to design and build an access control and admission detection model for the distributed IoT environment, we propose an IND-CCA-secure multi-authority ciphertext-policy ABE (MA-CP-ABE) scheme with outsourced decryption (OD) and progressive mode attribute-based authentication (ABAuthen). In our authenticaiton algorithm, by using the zero knowledge proof, the user’s secret will be protected from leaking out to the server. And due to the randomness of the authentication message, our authentication algorithm can resist the impersonation attacks by the malicious server. Finally, by the theoretical analysis and performance evaluation for our scheme with other state-of-art schemes, we can observe that our encryption and authentication schemes are both efficient and applicable for the distributed IoT-assisted cloud computing.}
}


@article{DBLP:journals/cn/CandelaLV21,
	author = {Massimo Candela and
                  Valerio Luconi and
                  Alessio Vecchio},
	title = {A worldwide study on the geographic locality of Internet routes},
	journal = {Comput. Networks},
	volume = {201},
	pages = {108555},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108555},
	doi = {10.1016/J.COMNET.2021.108555},
	timestamp = {Wed, 15 Dec 2021 10:28:57 +0100},
	biburl = {https://dblp.org/rec/journals/cn/CandelaLV21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The topology of the Internet and its geographic properties received significant attention during the last years, not only because they have a deep impact on the performance experienced by users, but also because of legal, political, and economic reasons. In this paper, the global Internet is studied in terms of path locality, where a path is defined as local if it does not cross the borders of the region where the source and destination hosts are located. The phenomenon is studied from the points of view of two metrics, one based on the size of the address space of the autonomous systems where the endpoints are located and the other one on the amount of served population. Results show that the regions of the world are characterized by significant differences in terms of path locality. The main elements contributing to the path locality, and non-locality, of the regions and countries, are identified and discussed. Finally, we present the most significant dependency relationships between countries caused by non-local paths.}
}


@article{DBLP:journals/cn/PalmaDM21,
	author = {Noelia P{\'{e}}rez Palma and
                  Falko Dressler and
                  Vincenzo Mancuso},
	title = {Precise: Predictive Content Dissemination Scheme exploiting realistic
                  mobility patterns},
	journal = {Comput. Networks},
	volume = {201},
	pages = {108556},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108556},
	doi = {10.1016/J.COMNET.2021.108556},
	timestamp = {Sat, 25 Dec 2021 15:50:40 +0100},
	biburl = {https://dblp.org/rec/journals/cn/PalmaDM21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Device-to-Device (D2D) communications have expanded the way of managing available network resources to efficiently distribute data between users. D2D exploits communication alternatives, in Opportunistic Networks, based on short range wireless radio technologies such as Bluetooth and WiFi-Direct. Besides, nowadays in most urban areas, realistic human mobility is characterized by often repeated patterns that can be used to accurately predict the next visited regions—we call these regions hotspots (or Replication Zones (RZs)). In this work, we present Predictive Content Dissemination Scheme (Precise), to explore and combine the D2D paradigm along with real mobility and predictions focused on the dissemination of content among hotspots. To analyze the viability of such scheme, we show simulation results and evaluate the average content availability, lifetime and delivery delay, storage usage and network utilization metrics. We compare the performance of Precise with state-of-the-art approaches, such as Epidemic, restricted Epidemic, and Proximity-Interest-Social (PIS) routing protocols. Our results underline the need for smart usage of communication opportunities and storage. We demonstrate that Precise allows for a neat reduction in network activity by decreasing the number of data exchanges by up to 92%, requiring the use of up to 50% less of on-device storage. This comes at negligible costs. In particular, the delivery delay with Precise shows an increase with respect to epidemic dissemination schemes that varies from 0.03 s in the most dynamic case to at most 1.91 s for the least dynamic case, and which however does not hinder the possibility to use Precise for real-time applications. Regarding how contents are spread, we observe that Precise requires 2% to 20% less mobile users to carry them within a target hotspot, especially under slow dynamics. This however does not impact on the probability that mobile users entering the hotspots obtain contents, and barely shortens the lifetime of contents in our experiments from 100 min down to about 95, in the worst case. This demonstrates that the reduction of content availability among mobile users with Precise is either negligible or not impactful, thus guaranteeing the dissemination of contents as with legacy epidemic dissemination protocols.}
}


@article{DBLP:journals/cn/ArranzTKGBF21,
	author = {Roberto Torre Arranz and
                  Muhammad Tayyab and
                  Georgios P. Koudouridis and
                  Xavier Gelabert and
                  Riccardo Bassoli and
                  Frank H. P. Fitzek},
	title = {Power efficient mobile small cell placement for network-coded cooperation
                  in UDNs},
	journal = {Comput. Networks},
	volume = {201},
	pages = {108559},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108559},
	doi = {10.1016/J.COMNET.2021.108559},
	timestamp = {Sun, 04 Aug 2024 19:48:53 +0200},
	biburl = {https://dblp.org/rec/journals/cn/ArranzTKGBF21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Ultra-dense Networks (UDNs) massively populate areas with base stations of diverse capabilities, thus increasing the network capacity. Moreover, the radio access network (RAN) architecture moves towards small infrastructure elements such as mobile small cells (MSCs). In this context, Network-coded Cooperation (NCC) leverages the interplay between network coding and cooperative relaying to reliably offload cellular traffic to MSCs and reduce the power consumption in the network. Despite the research done separately on NCC and smart MSC deployment, there is a scarceness of works addressing the smart and on-demand deployment, activation, and deactivation of MSCs to leverage the benefits of both NCC and MSCs. To fill this gap, in this paper, we: (1) estimate the traffic density of New York by adopting an urban zoning (UZ) model; (2) provide a methodology for the on-demand deployment of base stations and MSCs according to a stochastic geometry model; (3) propose two radio resource management (RRM) models, one random and one smart, for the placement and on-demand creation of MSCs, and (4) compare the power consumption of the proposed architecture with 4G edge computing. The results show that the smart RRM model overperforms the random model five-fold in terms of number of pico base stations required, which impact on the power consumed in the network. Moreover, the results show that the smart model achieves between 6%–25% power savings in comparison to 4G edge computing, the random model, and two approaches form the related work, respectively.}
}


@article{DBLP:journals/cn/DavamiARR21,
	author = {Fatemeh Davami and
                  Sahar Adabi and
                  Ali Rezaee and
                  Amir Masoud Rahmani},
	title = {Distributed scheduling method for multiple workflows with parallelism
                  prediction and {DAG} prioritizing for time constrained cloud applications},
	journal = {Comput. Networks},
	volume = {201},
	pages = {108560},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108560},
	doi = {10.1016/J.COMNET.2021.108560},
	timestamp = {Thu, 23 Jun 2022 20:03:26 +0200},
	biburl = {https://dblp.org/rec/journals/cn/DavamiARR21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Fog computing is an emerging popular paradigm that extends the availability of resources to the network's edge in order to improve the quality metrics of existing Cloud-based applications. However, scheduling workflow applications with time-constraints are complex regarding the count of resources, physical topology of clusters, and the structure of the task graph of the workflows. Adding Fog resources to the intricate problem space of Cloud-based scheduling needs even more time-consuming and complicated algorithms. In this paper, a multi-criteria Mamdani fuzzy algorithm is proposed to analyze the workflow graphs with the assistance of a Long-Short Term Memory neural network parallelism prediction module. The group-based priority assignment schema performed by the fuzzy inference system assigns a priority value to workflows to indicate the relative precedence of requests. Distributed schedulers then send the workflows to target sites according to their current workloads. The whole process is performed in a decentralized manner to prevent any bottlenecks. We have used an extensive software simulation study to compare the proposed algorithm in real workloads with two recent and notable algorithms. The simulation results confirm the proposed algorithm's superiority in fulfilling time-constraints, resource utilization, and overall application scheduling success rate.}
}


@article{DBLP:journals/cn/LuCSHZ21,
	author = {Lu Jie and
                  Hongchang Chen and
                  Penghao Sun and
                  Tao Hu and
                  Zhen Zhang},
	title = {OrderSketch: An Unbiased and Fast Sketch for Frequency Estimation
                  of Data Streams},
	journal = {Comput. Networks},
	volume = {201},
	pages = {108563},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108563},
	doi = {10.1016/J.COMNET.2021.108563},
	timestamp = {Tue, 18 Oct 2022 08:35:31 +0200},
	biburl = {https://dblp.org/rec/journals/cn/LuCSHZ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Estimating the frequency of each distinct item in data streams is a fundamental problem in data mining. The speed of existing algorithms is not fast enough, and at the same time, some algorithms improve accuracy through complex configuration, which is a heavy burden for users. To address this issue, we propose a new sketch, OrderSketch, which has a simple structure and operation that is effortless to understand and use. The OrderSketch is significantly faster than existing algorithms while maintaining high accuracy. We theoretically prove that OrderSketch can provide unbiased estimation and then give an error bound of our algorithm. To verify the effectiveness and efficiency of OrderSketch, we compare it with five other widely used and excellent performance algorithms. Experimental results show that OrderSketch has 3 times higher insertion speed compared with the state-of-the-art work. We have released our source codes at Github [1].}
}


@article{DBLP:journals/cn/AtifGQN21,
	author = {Syed Muhammad Atif and
                  Nicolas Gillis and
                  Sameer Qazi and
                  Imran Naseem},
	title = {Structured nonnegative matrix factorization for traffic flow estimation
                  of large cloud networks},
	journal = {Comput. Networks},
	volume = {201},
	pages = {108564},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108564},
	doi = {10.1016/J.COMNET.2021.108564},
	timestamp = {Mon, 28 Aug 2023 21:39:18 +0200},
	biburl = {https://dblp.org/rec/journals/cn/AtifGQN21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Network traffic matrix estimation is an ill-posed linear inverse problem: it requires to estimate the unobservable origin destination traffic flows,\nX\n, given the observable link traffic flows,\nY\n, and a binary routing matrix,\nA\n, which are such that\nY\n=\nA\nX\n. This is a challenging but vital problem as accurate estimation of OD flows is required for several network management tasks. In this paper, we propose a novel model for the network traffic matrix estimation problem which maps high-dimension OD flows to low-dimension latent flows with the following three constraints: (1) nonnegativity constraint on the estimated OD flows, (2) autoregression constraint that enables the proposed model to effectively capture temporal patterns of the OD flows, and (3) orthogonality constraint that ensures the mapping between low-dimensional latent flows and the corresponding link flows to be distance preserving. The parameters of the proposed model are estimated with a training algorithm based on Nesterov accelerated gradient and generally shows fast convergence. We validate the proposed traffic flow estimation model on two real backbone IP network datasets, namely Internet2 and GÉANT. Empirical results show that the proposed model outperforms the state-of-the-art models not only in terms of tracking the individual OD flows but also in terms of standard performance metrics. The proposed model is also found to be highly scalable compared to the existing state-of-the-art approaches.}
}


@article{DBLP:journals/cn/WangLLMX21,
	author = {Bin Wang and
                  Fagui Liu and
                  Weiwei Lin and
                  Zhenjiang Ma and
                  Dishi Xu},
	title = {Energy-efficient collaborative optimization for {VM} scheduling in
                  cloud computing},
	journal = {Comput. Networks},
	volume = {201},
	pages = {108565},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108565},
	doi = {10.1016/J.COMNET.2021.108565},
	timestamp = {Fri, 09 Dec 2022 16:50:05 +0100},
	biburl = {https://dblp.org/rec/journals/cn/WangLLMX21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Energy-efficient resource scheduling has become a hot issue in the field of cloud computing. However, there is an inevitable conflict between energy-saving and QoS optimization. In real-world scenarios, the volatility of cloud task arrival will cause the optimization problem to become more difficult. To achieve a better trade-off between these two goals, a novel resource scheduling framework based on collaborative optimization is proposed for the cloud computing environment. Based on the Lyapunov optimization method, the optimization problem can be solved explicitly in each time slice. We build a multi virtual machine queuing model and analyze the relationships between the task queues’ backlog and the system energy consumption. We also introduce a method of using stacked denoising auto-encoder for extracting the QoS features to improve the constraints of the collaborative optimization objective function. Finally, we propose an efficient resource scheduling strategy to give full play to the processing capabilities of the virtual machine. Experimental results show that, compared with other advanced energy-saving strategies, our scheduling strategy can effectively reduce the energy consumption of the cloud data center while guaranteeing QoS, and reduce the total scheduling time cost of data center by more than 20%.}
}


@article{DBLP:journals/cn/SalahdineOLHZW21,
	author = {Fatima Salahdine and
                  Johnson Opadere and
                  Qiang Liu and
                  Tao Han and
                  Ning Zhang and
                  Shaohua Wu},
	title = {A survey on sleep mode techniques for ultra-dense networks in 5G and
                  beyond},
	journal = {Comput. Networks},
	volume = {201},
	pages = {108567},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108567},
	doi = {10.1016/J.COMNET.2021.108567},
	timestamp = {Tue, 21 Mar 2023 21:08:29 +0100},
	biburl = {https://dblp.org/rec/journals/cn/SalahdineOLHZW21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The proliferation of mobile users with an attendant rise in energy consumption mainly at the base station has requested new ways of achieving energy efficiency in cellular networks. Many approaches have been proposed to reduce the power consumption at the base stations in response to the contribution of energy cost to the increase of OPEX of the mobile operators and the rise of the carbon footprint on global climate. As a springboard to the application of sleep mode methods in ultra-dense cellular networks, this paper provides a comprehensive survey of the base station sleep mode strategies in heterogeneous mobile networks from perspectives of modeling and algorithm design. Specifically, the sleep mode enabling strategies and sleep wake-up schemes are reviewed. The base station sleep-mode techniques in ultra-dense networks are further discussed as well as the challenges and possible solutions.}
}


@article{DBLP:journals/cn/FarhadiRAH21,
	author = {Babak Farhadi and
                  Amir Masoud Rahmani and
                  Parvaneh Asghari and
                  Mehdi Hosseinzadeh},
	title = {Friendship selection and management in social internet of things:
                  {A} systematic review},
	journal = {Comput. Networks},
	volume = {201},
	pages = {108568},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108568},
	doi = {10.1016/J.COMNET.2021.108568},
	timestamp = {Sun, 06 Oct 2024 21:22:03 +0200},
	biburl = {https://dblp.org/rec/journals/cn/FarhadiRAH21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Social Internet of Things (SIoT) paradigm integrates the Internet of Things (IoT) and human social networks. SIoT network plays an essential role in establishing social friendships between smart devices. Any physical object deployed on the SIoT environment will access the required service utilizing its social friendships. Discovering desirable and efficient services among SIoT smart devices is possible only if we create, select, and manage social friendships intelligently and reliably. However, despite the significant importance of the thrust area of social friendship selection and management in the SIoT network, there is no systematic and comprehensive research study about exclusively analyzing and reviewing all the key strategies of this research field. Therefore, this survey paper investigates the state-of-the-art SIoT friendship selection and management strategies based on the Systematic Literature Review (SLR) methodology. It achieves this target by looking at the journal and conference papers published on social friendship selection and Relationship Management (RM) scope between 2013 and December 2020. We propose a novel technical taxonomy to categorize the state-of-the-art studies into the five categories in which social relationship selection and management play a significant role: structure-based, community-based, ontology-based, recommendation-based, and other strategies. In each category, the relevant research studies are presented and described. Also, a summary of the benefits and drawbacks of the reviewed studies is provided, and a comprehensive comparison of studies based on some evaluation metrics is made. Finally, we outline new emerging challenges and discuss and identify future research directions and open issues.}
}


@article{DBLP:journals/cn/GarettoLN21,
	author = {Michele Garetto and
                  Emilio Leonardi and
                  Giovanni Neglia},
	title = {Content placement in networks of similarity caches},
	journal = {Comput. Networks},
	volume = {201},
	pages = {108570},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108570},
	doi = {10.1016/J.COMNET.2021.108570},
	timestamp = {Wed, 15 Dec 2021 10:28:58 +0100},
	biburl = {https://dblp.org/rec/journals/cn/GarettoLN21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Similarity caching systems have recently attracted the attention of the scientific community, as they can be profitably used in many application contexts, like multimedia retrieval, advertising, object recognition, recommender systems and online content-match applications. In such systems, a user request for an object\no\n, which is not in the cache, can be (partially) satisfied by a similar stored object\no\n’, at the cost of a loss of user utility. In this paper we make a first step into the novel area of similarity caching networks, where requests can be forwarded along a path of caches to get the best efficiency–accuracy tradeoff. The offline problem of content placement can be easily shown to be NP-hard, while different polynomial algorithms can be devised to approach the optimal solution in discrete cases. As the content space grows large, we propose a continuous problem formulation whose solution exhibits a simple structure in a class of tree topologies. We verify our findings using synthetic and realistic request traces.}
}


@article{DBLP:journals/cn/QianL21,
	author = {Bing Qian and
                  Shun Lu},
	title = {Detection of mobile network abnormality using deep learning models
                  on massive network measurement data},
	journal = {Comput. Networks},
	volume = {201},
	pages = {108571},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108571},
	doi = {10.1016/J.COMNET.2021.108571},
	timestamp = {Wed, 13 Nov 2024 19:32:36 +0100},
	biburl = {https://dblp.org/rec/journals/cn/QianL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent years, with the continuous growth of mobile network users, the traditional methods based on expert experiences and threshold analysis find it hard to meet the need of network maintenance. These methods expose a lot of weakness, such as subjectivity, differences, and inconsistency. This paper proposes a deep learning method to make use of massive mobile data and replace the expert system. Network measurement data and pseudo labels are leveraged to train the supervised learning model, which assists in the feature selection for the deep learning model. Through extensive experiments and analysis, our method is proved to be effective in abnormality detection and achieves better performance than the traditional expert system.}
}


@article{DBLP:journals/cn/LiangFSLLLW21,
	author = {Shuang Liang and
                  Zhiyi Fang and
                  Geng Sun and
                  Chi Lin and
                  Jiahui Li and
                  Songyang Li and
                  Aimin Wang},
	title = {Charging {UAV} deployment for improving charging performance of wireless
                  rechargeable sensor networks via joint optimization approach},
	journal = {Comput. Networks},
	volume = {201},
	pages = {108573},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108573},
	doi = {10.1016/J.COMNET.2021.108573},
	timestamp = {Wed, 26 Jun 2024 19:56:33 +0200},
	biburl = {https://dblp.org/rec/journals/cn/LiangFSLLLW21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Wireless power transfer based on charging unmanned aerial vehicles (CUAVs) is a promising method for enhancing the lifetime of wireless rechargeable sensor networks (WRSNs). However, how to deploy the CUAVs so that enhancing the charging efficiency is still a challenge. In this work, we formulate a CUAV deployment optimization problem (CUAVDOP) to jointly increase the number of the sensor nodes that within the charging scopes of CUAVs, improve the minimum charging efficiency in the network and reduce the motion energy consumptions of CUAVs. Moreover, the formulated CUAVDOP is analyzed and proven as NP-hard. Then, we propose an improved firefly algorithm (IFA) to solve the formulated CUAVDOP. IFA introduces three improved items that are the opposition-based learning model, attraction model and adaptive step size factor to enhance the performance of conventional firefly algorithm, so that making it more suitable for solving the formulated CUAVDOP. Simulation results demonstrate that the proposed algorithm is effective for dealing with the formulated joint optimization problem. Moreover, the superiority of IFA is verified by tests.}
}


@article{DBLP:journals/cn/Braeken21,
	author = {An Braeken},
	title = {Device-to-device group authentication compatible with 5G {AKA} protocol},
	journal = {Comput. Networks},
	volume = {201},
	pages = {108575},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108575},
	doi = {10.1016/J.COMNET.2021.108575},
	timestamp = {Wed, 15 Dec 2021 10:28:57 +0100},
	biburl = {https://dblp.org/rec/journals/cn/Braeken21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Device-to-device (D2D) communication in 5G can offload large amounts of data from the core network and offer smaller delays in communication, making advantage of the proximity between the devices. Specific attention should be given to a dedicated authentication process as there are significant challenges with respect to security and privacy. We propose the first anonymous group D2D authentication and key agreement protocol, which can be integrated into the existing 5G-AKA protocol with only a few adaptations. No additional initialization or new implementations of security algorithms are required for the user equipment. After a successful run of the protocol, the devices in the group can derive a secure group key and a secret key shared with each other member of the group. Both from a computational and a communication perspective, the scheme is comparable with state-of-the-art related solutions. Moreover, our proposed scheme satisfies several security features, which are not currently available in the existing schemes in literature.}
}


@article{DBLP:journals/cn/YangJZWLLFX21,
	author = {Ye Yang and
                  Haiyang Jiang and
                  Guangxing Zhang and
                  Xin Wang and
                  Yilong Lv and
                  Xing Li and
                  Serge Fdida and
                  Gaogang Xie},
	title = {{S2H:} Hypervisor as a setter within Virtualized Network {I/O} for
                  {VM} isolation on cloud platform},
	journal = {Comput. Networks},
	volume = {201},
	pages = {108577},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108577},
	doi = {10.1016/J.COMNET.2021.108577},
	timestamp = {Fri, 10 Mar 2023 09:00:13 +0100},
	biburl = {https://dblp.org/rec/journals/cn/YangJZWLLFX21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Virtualized Network I/O (VNIO) plays a key role in providing the network connectivity to cloud services, as it delivers packets for Virtual Machines (VMs). Existing para-virtualized solutions accelerate the virtual Switch (vSwitch) data transfer via memory-sharing mechanism, that unfortunately impairs the memory isolation barrier among VMs. In this paper, we categorize existing para-virtualized solutions into two types: VM to vSwitch (V2S) and vSwitch to VM (S2V), according to the memory-sharing strategy. We then analyze their individual VM isolation issues, that is, a malicious VM may access other ones’ data by exploiting the shared memory. To solve this issue, we propose a new S2H memory sharing scheme, which shares the I/O memory from vSwitch to Hypervisor. The S2H scheme can guarantee both VM isolation and network performance as the hypervisor acts as a “setter” between VM and vSwitch for packet delivery. To show that S2H can be implemented easily and efficiently, we implement the prototype based on the de-facto para-virtualization standard vHost-User solution. Extensive experimental results show that S2H not only guarantees the isolation but also holds the comparable throughput with the same CPU cores configured, when comparing with the native vHost-User solution.}
}


@article{DBLP:journals/cn/SariS21,
	author = {T. Tolga Sari and
                  G{\"{o}}khan Se{\c{c}}inti},
	title = {Chain {RTS/CTS} scheme with Opportunistic Channel Allocation},
	journal = {Comput. Networks},
	volume = {201},
	pages = {108581},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108581},
	doi = {10.1016/J.COMNET.2021.108581},
	timestamp = {Sat, 25 Dec 2021 15:50:40 +0100},
	biburl = {https://dblp.org/rec/journals/cn/SariS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Current Wi-Fi standards lack in terms of providing reliable multi-hop links for bandwidth-hungry applications. As a result, aerial networks which need reliable & high bandwidth multi-hop communication links, fail to maintain QoS levels. In this paper, we take a deeper look at our earlier work, Chain RTS/CTS, which makes channel reservations by repeating the RTS frame of the source of the e2e link towards the destination node using alternating channels. After receiving the RTS frame, destination node starts backward CTS chain where CTS frames are repeated similarly using the same route with forward RTS chain towards the source node of e2e link. Additionally, we introduce Opportunistic Channel Allocation designed to increase fairness when operating at 5 GHz band. Our simulations show 37% throughput improvement in multi-hop links with 68% increased link setup time when compared to simple channel hopping enhancement scheme for single e2e connection. When there are multiple concurrent e2e connections, our solution improves the throughput by 27% compared to Classical Channel Hopping (which alternates channels at each hop) with only 11% lower Jain’s Fairness index.}
}


@article{DBLP:journals/cn/AbidLB21,
	author = {Khaled Abid and
                  Hicham Lakhlef and
                  Abdelmadjid Bouabdallah},
	title = {A survey on recent contention-free {MAC} protocols for static and
                  mobile wireless decentralized networks in IoT},
	journal = {Comput. Networks},
	volume = {201},
	pages = {108583},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108583},
	doi = {10.1016/J.COMNET.2021.108583},
	timestamp = {Wed, 15 Dec 2021 10:28:57 +0100},
	biburl = {https://dblp.org/rec/journals/cn/AbidLB21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Medium Access Control (MAC) protocols for wireless decentralized networks in IoT have attracted a lot of attention in both academic and industrial fields. They aim to coordinate access among IoT devices to the shared wireless medium. More specifically, contention-free MAC protocols are known to be more efficient than contention-based ones in the case of high traffic load and dense networks. To face the main communication challenges between IoT devices such as collisions and conflicts as well as mobility, it is crucial to design an efficient MAC protocol. To do so, several solutions have been proposed in the literature. Among recent proposed solutions, Machine Learning (ML) algorithms and game theory models were used to revolutionize the communication in IoT networks, especially for devices with high mobility degree. In our survey, we first start by studying the challenges and requirements of communication in wireless networks. Then, we provide a comprehensive survey on recent contention-free MAC protocols existing in the literature. Next, we compare these solutions based on important metrics such as QoS, robustness, fairness etc., and discuss the relationship between MAC protocols, network type and network mobility. Finally, we investigate a future research direction to solve a major problem, which is the network disruption and delay tolerance in IoT wireless mobile networks.}
}


@article{DBLP:journals/cn/SharmaGSSK21,
	author = {Abhishek Sharma and
                  Amik Garg and
                  Sanjay Kumar Sharma and
                  Vibhav Kumar Sachan and
                  Parvin Kumar},
	title = {Performance optimization for {UWB} communication network under {IEEE}
                  802.15.4a channel conditions},
	journal = {Comput. Networks},
	volume = {201},
	pages = {108585},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108585},
	doi = {10.1016/J.COMNET.2021.108585},
	timestamp = {Tue, 13 Aug 2024 08:07:43 +0200},
	biburl = {https://dblp.org/rec/journals/cn/SharmaGSSK21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The manuscript presents a performance optimization methodology for UWB signaling under IEEE 802.15.4a channel conditions using pulse shaping. IEEE 802.1.5.4a is widely adapted for wireless personal area network (WPAN), body area network (BAN) as networking standard. The modified pulse shaping is specifically analyzed for the outdoor and industrial IEEE 802.15.4a channel conditions. The pulse shaping is also validated for the effect of interference levels offered to the co-existing Wireless MAN-SCa and Wireless MAN-OFDM (orthogonal frequency-division multiplexing) signaling. The performance has been evaluated for the Gaussian pulse shaping in a multi-user environment. The results for the pulse optimization have been validated for the line of sight and non-line of sight environment to investigate the capability of the UWB pulse for data transmission in multi user scenarios.}
}


@article{DBLP:journals/cn/RenYM21,
	author = {Qiuning Ren and
                  Chao Yang and
                  Jianfeng Ma},
	title = {App identification based on encrypted multi-smartphone sources traffic
                  fingerprints},
	journal = {Comput. Networks},
	volume = {201},
	pages = {108590},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108590},
	doi = {10.1016/J.COMNET.2021.108590},
	timestamp = {Mon, 28 Aug 2023 21:39:17 +0200},
	biburl = {https://dblp.org/rec/journals/cn/RenYM21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The smartphone app identification technology based on traffic fingerprints has begun to play an important role in monitoring malware and assisting network management with the smartphone security issues getting more attention. Smartphones connected to the Internet are often produced by multiple manufacturers, belong to multiple models and use a variety of operating systems. But current researches cannot achieve high-accuracy app identification while using datasets collected from traffic sources of different smartphone. In this paper, we propose an app identification system which use frequency distribution fingerprints to identify apps from encrypted multi-smartphone source traffic. The key idea of our work is to convert the occurrence frequency of traffic stream attribute values (e.g. TCP stream length and SSL/TLS handshake message type) into the format of frequency distribution. We use the random forest algorithm to identify apps from the frequency distributions extracted from the encrypted traffic collected from different three smartphones. In addition, we explore the impact of the app browsing contents, app behaviors, individual differences between smartphones of the same model and brand differences on the performance of our identification system. Our work achieves 99.3% TPR and 0.2% FPR performance on the datasets collected from two different brands of smartphones. Additionally, we show that the variety of app behaviors has the most significant impact on our identification performance, even more than the brand differences.}
}


@article{DBLP:journals/cn/WaziraliAA21,
	author = {Raniyah Wazirali and
                  Rami Ahmad and
                  Ashraf Abdel{-}Karim Helal Abu{-}Ein},
	title = {Sustaining accurate detection of phishing URLs using {SDN} and feature
                  selection approaches},
	journal = {Comput. Networks},
	volume = {201},
	pages = {108591},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108591},
	doi = {10.1016/J.COMNET.2021.108591},
	timestamp = {Mon, 03 Jan 2022 22:01:38 +0100},
	biburl = {https://dblp.org/rec/journals/cn/WaziraliAA21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Phishing is an online fraud that deceives visitors by impersonating a legitimate website to steal their confidential or personal information. This is a well-known form of cybercrime. With the aim of detecting phishing sites, several phishing site detection techniques have recently been created. However, it fails to achieve the desired goal and has a large number of drawbacks, including low accuracy, long learning curve, and low-power embedded hardware. For covering such drawbacks, this work proposes an efficient URLs Phishing detection technique. Our technique depends on Software Defined Network (SDN) technology, clustering and feature method, and Conventional Neural Network (CNN) algorithm. Feature selection technique is based on Recursive Feature Elimination (RFE) with Support Vector Machine (SVM) algorithm. The SDN is used to transfer the URLs phishing detection process out of the user's hardware to the controller layer, continuously train on new data, and then send its outcomes to the SDN-Switches. RFE-SVM and CNN are used to increase accuracy of phishing detection. Therefore, the proposal model does not require retrieving the content of the target website or using any third-party services. It captures the information and sequential patterns of URL strings without requiring a prior knowledge about phishing, and then uses the sequential pattern features to quickly classify the actual URL. The experimental results showed that our proposal highlighted the robustness and accuracy in distinguishing between phishing and legitimate sites. Our suggestion achieves 99.5% phishing detection accuracy.}
}


@article{DBLP:journals/cn/LiuLLMT21,
	author = {Yuan Liu and
                  Yixiao Lan and
                  Boyang Li and
                  Chunyan Miao and
                  Zhihong Tian},
	title = {Proof of Learning (PoLe): Empowering neural network training with
                  consensus building on blockchains},
	journal = {Comput. Networks},
	volume = {201},
	pages = {108594},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108594},
	doi = {10.1016/J.COMNET.2021.108594},
	timestamp = {Mon, 28 Aug 2023 21:39:20 +0200},
	biburl = {https://dblp.org/rec/journals/cn/LiuLLMT21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The advent of neural network (NN) based deep learning, especially the recent development of the automatic design of networks, has brought unprecedented performance gains at heavy computational cost. On the other hand, in order to generate a new consensus block, Proof of Work (PoW) based blockchain systems routinely perform a huge amount of computation that does not achieve practical purposes but to solving a difficult cryptographic hash puzzle problem.In this study, we propose a new consensus mechanism, Proof of Learning (PoLe), which directs the computation spent for block consensus toward optimization of neural networks. In our design, the training and testing data are released to the entire blockchain network and the consensus nodes train NN models on the data, which serves as the proof of learning. As a core component of PoLe, we design a secure mapping layer (SML) to prevent consensus nodes from cheating, which can be straightforwardly implemented as a linear NN layer. When the consensus on the blockchain network is achieved, a new block is appended to the blockchain. We experimentally compare the PoLe protocol with Proof of Work (PoW) and show that PoLe can achieve a more stable block generation rate, which leads to more efficient transaction processing. Experimental evaluation also shows the PoLe can achieve a stable block generation rate without significantly sacrificing training performance.}
}


@article{DBLP:journals/cn/KumarJ21,
	author = {Sanjeev Kumar and
                  B. Janet},
	title = {Distinguishing malicious programs based on visualization and hybrid
                  learning algorithms},
	journal = {Comput. Networks},
	volume = {201},
	pages = {108595},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108595},
	doi = {10.1016/J.COMNET.2021.108595},
	timestamp = {Wed, 15 Dec 2021 10:28:58 +0100},
	biburl = {https://dblp.org/rec/journals/cn/KumarJ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Modern malware threats demand a robust and scalable detection system. This paper presents a novel proactive monitoring and analysis architecture called malware threat intelligence system (MTIS) to collect and classify real-world samples of modern malware families. Microsoft Window‘s portable executable (PE) files are systematically labeled using clustering and AVClass engine. These labeled malware samples are visualized into grayscale images, which are further utilized for the extraction of textural features. This paper uses local descriptors (LBP, DSIFT, GLCM) and global descriptors(GIST) to extract local and global textural features from a grayscale image. Malware images are distinguished using a hybrid approach of machine learning methods and a proposed convolutional neural network (CNN) employed with early stopping configurations. Results have demonstrated that the proposed architecture detects modern and real-world malware samples with better classification accuracy without code reversing and domain expertise. Four machine learning algorithms, namely, K-nearest neighbors (k-NN), Support vector machine(SVM), Naive Bayes(NB), and Random forest, are compared systematically, with different image resolutions and data split, enabling efficient model selection. Deep learning of MTIS (DL-MTIS) is compared with former methods and with CNN+GIST, CNN with the whole image as inputs, and k-NN+GIST method, and it is observed to be superior in performance. The results also reveal that the proposed method is resilient to packed and encrypted malware samples.}
}


@article{DBLP:journals/cn/ShindeMT21,
	author = {Swapnil Sadashiv Shinde and
                  Dania Marabissi and
                  Daniele Tarchi},
	title = {A network operator-biased approach for multi-service network function
                  placement in a 5G network slicing architecture},
	journal = {Comput. Networks},
	volume = {201},
	pages = {108598},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108598},
	doi = {10.1016/J.COMNET.2021.108598},
	timestamp = {Wed, 15 Dec 2021 10:28:58 +0100},
	biburl = {https://dblp.org/rec/journals/cn/ShindeMT21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The 5G communication standard is characterized by an increased softwarization, allowing a higher flexibility able to cope with different requirements and services. In particular, Network Function Virtualization (NFV) is a recently introduced technology that enables a software implementation of different network functions exploiting virtualization techniques, hence, enabling their flexible deployment upon system requirements. Boosted by NFV, the concept of network slicing is gaining great attention in 5G networks. The idea is that physical communication and computing resources are sliced in multiple end-to-end logical networks, each one tailored to best support a specific service. The advantages of NFV, in the network slicing context, are even more evident in distributed computing environments, such as the edge-to-cloud continuum, recently introduced for enabling a flexible deployment of multiple functions. In particular, thanks to the introduction of cloud-native technologies, based on the usage of containerization and microservice technologies, the virtual network functions (VNFs) deployment and their orchestration is an easy operation, allowing the on-the-fly network configuration. Gaining from the NFV, Network Slicing and Edge-to-Cloud continuum paradigms, we propose a new network function allocation problem for multi-service 5G networks, able to deploy network functions on a distributed computing environment depending on the service requests. The proposed approach jointly considers Radio Access Network (RAN) and Core Network (CN) functions and, differently from other approaches, introduces an option able to bias the function placement depending on the service requirements, allowing a fast-and-easy operator-side deployment of the network functions. We propose to solve the problem through a Genetic Algorithm able to approach the optimal solution but with reduced complexity and execution time. The performance is compared with two other heuristic algorithms and with an exhaustive search algorithm, introduced as benchmarks, showing the benefits of the selected solution in terms of performance, flexibility and complexity.}
}


@article{DBLP:journals/cn/MiuccioPR21,
	author = {Luciano Miuccio and
                  Daniela Panno and
                  Salvatore Riolo},
	title = {A DNN-based estimate of the {PRACH} traffic load for massive IoT scenarios
                  in 5G networks and beyond},
	journal = {Comput. Networks},
	volume = {201},
	pages = {108608},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108608},
	doi = {10.1016/J.COMNET.2021.108608},
	timestamp = {Mon, 26 Jun 2023 20:51:09 +0200},
	biburl = {https://dblp.org/rec/journals/cn/MiuccioPR21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The massive Internet of Things (IoT) scenario refers to a huge number of Machine Type Communications (MTC) characterized by sporadic transmissions of small-sized packets. In order to manage the uplink radio resource allocation in cellular networks, several access schemes have been proposed. These schemes are mainly based on a grant-based Random Access (RA) procedure and proper load-aware access controls, e.g., Access Class Barring (ACB) techniques, dynamic uplink radio resource allocation, and so on. The development of an efficient approach to estimate the traffic load is extremely important for the proper functioning of these access schemes. With the ever-increasing number of transmitting MTC devices, expected with Beyond 5G (B5G) and 6G networks, additional challenges to obtain a correct real-time traffic load estimation are posed. Deep learning techniques, in this context, offer learning ability and optimization capability to properly support this scenario. In this paper, we propose a current access attempts estimation, based on Deep Neural Network (DNN), which accepts as input only the information really available at the next generation Node B (gNB). The network was trained and tested with a dataset properly created and composed by more than 21 million points. The DNN-based traffic load estimation method is then compared with other benchmark schemes available in the literature, in terms of regression accuracy, both in a static analysis, which considers a stand-alone RA cycle, and through a long-term analysis with a time-varying offered load. The latter analysis was performed both by adopting a theoretical arrival process proposed by 3GPP, and by using traces of real traffic data.}
}


@article{DBLP:journals/cn/Rodrigues21,
	author = {Carlo Kleber da Silva Rodrigues},
	title = {Analyzing Blockchain integrated architectures for effective handling
                  of IoT-ecosystem transactions},
	journal = {Comput. Networks},
	volume = {201},
	pages = {108610},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108610},
	doi = {10.1016/J.COMNET.2021.108610},
	timestamp = {Wed, 15 Dec 2021 10:28:57 +0100},
	biburl = {https://dblp.org/rec/journals/cn/Rodrigues21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The IoT ecosystem envisions a new world fully integrated by smart devices exchanging data to enable more automated, accurate, and timely decisions. Nonetheless, this idealized scenario may be only implemented if the system database allow smart devices’ transactions to be efficiently processed and security is guaranteed. To tackle this challenge, this paper then analyzes three Blockchain integrated architectures, covering an assemblage of different popular IoT-application scenarios. The performance evaluation is based on analytical queueing models, simulations, and theoretical discussion. The results show that efficiency and security requirements may be met when the Blockchain system is suitably configured, mainly observing a trade-off between data integrity and response time. In this sense, our main contribution is to yield valuable subsidies which can act as guidance for the development of real IoT-ecosystem projects. At last, general conclusions and directions for further research close this paper.}
}


@article{DBLP:journals/cn/DhoogeVWVT21,
	author = {Laurens D'hooge and
                  Miel Verkerken and
                  Tim Wauters and
                  Bruno Volckaert and
                  Filip De Turck},
	title = {Hierarchical feature block ranking for data-efficient intrusion detection
                  modeling},
	journal = {Comput. Networks},
	volume = {201},
	pages = {108613},
	year = {2021},
	url = {https://doi.org/10.1016/j.comnet.2021.108613},
	doi = {10.1016/J.COMNET.2021.108613},
	timestamp = {Wed, 15 Dec 2021 10:28:58 +0100},
	biburl = {https://dblp.org/rec/journals/cn/DhoogeVWVT21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The intrusion detection field has been increasing the adoption of newer datasets after relying mainly on KDD99 and NSL-KDD. Both the height and the width of the newer datasets have increased substantially since they are geared towards evaluation by machine learning methods. The feature sets however are most often statistics, derived either from the packets, or more commonly from the (reconstructed) flows. The ease with which connected clusters of features can be extracted as well as the tendency to be overinclusive to provide researchers with as much data as possible has introduced significant bloat in the datasets. In order to improve the effective and efficient use of the datasets, this article proposes a hybrid feature selection mechanism based on a first-pass filter method and a second-pass embedded method with a central role for statistical testing to identify hierarchies of dominant feature sets. The non-destructive approach allows for the hierarchies to be inspected, interpreted and related to each other. The proposed approach is validated by constructing the feature hierarchies at three different resolutions for all recent datasets published by the Canadian Institute for Cybersecurity (IDS2017, DoS2017, IDS2018 and DDoS2019, millions of samples, 76 features). Three standard supervised learners were given increasing access to the feature (blocks) in terms of their hierarchical position. The results show that attack classes with a clear network component can be detected with cross-validated balanced accuracy, precision and recall above 99%, even when the classification model has been built from just 1 to 4 features, while additionally under a very restrictive sampling regimen: training (0.8%), validation (0.2%) and testing (99%). When selecting models only for classification performance more attack classes are detected more reliably, and while this increases feature use to an average of 12, this is still preferable over using the datasets’ standard set of 76 features.}
}
