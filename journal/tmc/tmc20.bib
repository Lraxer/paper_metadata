@article{DBLP:journals/tmc/Zhang21,
	author = {Qian Zhang},
	title = {A Message From the Editor-in-Chief},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {1},
	pages = {1},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.3035951},
	doi = {10.1109/TMC.2020.3035951},
	timestamp = {Thu, 17 Dec 2020 18:29:11 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/Zhang21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Presents the introductory editorial for this issue of the publication.}
}


@article{DBLP:journals/tmc/XiaHMJ21,
	author = {Qing Xia and
                  Zahed Hossain and
                  Michael J. Medley and
                  Josep Miquel Jornet},
	title = {A Link-Layer Synchronization and Medium Access Control Protocol for
                  Terahertz-Band Communication Networks},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {1},
	pages = {2--18},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2940441},
	doi = {10.1109/TMC.2019.2940441},
	timestamp = {Thu, 17 Dec 2020 18:29:12 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/XiaHMJ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, a link-layer synchronization and medium access control (MAC) protocol for very-high-speed wireless communication networks in the Terahertz (THz) band is presented. The protocol relies on a receiver-initiated handshake to guarantee synchronization between transmitter and receiver. Two scenarios are considered, namely, a macroscale scenario, where nodes utilize rotating directional antennas to periodically sweep the space while overcoming the distance problem at THz frequencies, and a nanoscale scenario, where nano-devices require energy harvesting systems to operate. Both scenarios are implemented on a centralized and an ad-hoc network architecture. A carrier-based physical layer is considered for the macro-scenario, whereas the physical layer for the nano-scenario is based on a femtosecond-long pulse-based modulation scheme with packet interleaving. The performance of the proposed MAC protocol is analytically investigated in terms of delay, throughput and probability of successful packet delivery, and compared to that of an adapted Carrier Sense Multiple Access with Collision Avoidance (CSMA/CA) with and without handshake. The results are validated by means of extensive simulations with ns-3, in which all the necessary THz elements have been implemented. The results show that the proposed protocol can maximize the successful packet delivery probability without compromising the achievable throughput in THz-band communication networks.}
}


@article{DBLP:journals/tmc/SaputraHND21,
	author = {Yuris Mulya Saputra and
                  Dinh Thai Hoang and
                  Diep N. Nguyen and
                  Eryk Dutkiewicz},
	title = {A Novel Mobile Edge Network Architecture with Joint Caching-Delivering
                  and Horizontal Cooperation},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {1},
	pages = {19--31},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2938510},
	doi = {10.1109/TMC.2019.2938510},
	timestamp = {Thu, 17 Dec 2020 18:29:11 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/SaputraHND21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Mobile edge caching/computing (MEC) has been emerging as a promising paradigm to provide ultra-high rate, ultra-reliable, and/or low-latency communications in future wireless networks. In this paper, we introduce a novel MEC network architecture that leverages the optimal joint caching-delivering with horizontal cooperation among mobile edge nodes (MENs). To that end, we first formulate the content-access delay minimization problem by jointly optimizing the content caching and delivering decisions under various network constraints (e.g., network topology, storage capacity and users' demands at each MEN). However, the strongly mutual dependency between the decisions makes the problem a nested dual optimization that is proved to be NP-hard. To deal with it, we propose a novel transformation method to transform the nested dual problem to an equivalent mixed-integer nonlinear programming (MINLP) optimization problem. Then, we design a centralized solution using an improved branch-and-bound algorithm with the interior-point method to find the joint caching and delivering policy which is within 1 percent of the optimal solution. Since the centralized solution requires the full network topology and information from all MENs, to make our solution scalable, we develop a distributed algorithm which allows each MEN to make its own decisions based on its local observations. Extensive simulations demonstrate that the proposed solutions can reduce the total average delay for the whole network up to 40 percent compared with other current caching policies. Furthermore, the proposed solutions also increase the cache hit ratio for the network up to 4 times, thereby dramatically reducing the traffic load on the backhaul network.}
}


@article{DBLP:journals/tmc/JinZZ21,
	author = {Rong Jin and
                  Kai Zeng and
                  Kai Zhang},
	title = {A Reassessment on Friendly Jamming Efficiency},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {1},
	pages = {32--47},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2940941},
	doi = {10.1109/TMC.2019.2940941},
	timestamp = {Thu, 16 Dec 2021 17:33:12 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/JinZZ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the rapid and continuous growth of various types of wireless devices in IoT, securing the communications among heterogeneous devices becomes an emerging issue. A physical layer security scheme, called “friendly jamming”, has drawn great attention recently owing to its ability to protect the confidentiality of the communication as well as to enable message authentication and access control for those already employed, unencrypted, weakly encrypted, or resource constrained devices. We notice that in a large number of cases in which friendly jamming are preferable, the transmitting signals to be protected have varying spectrum utilization at symbol level. In this paper, we rebuild secrecy capacity models and re-evaluate the jamming efficiency by taking this micro time scale non-stationary characteristic into consideration. Our reassessments reveal that jamming efficiency is greatly overestimated in the existing literature. The second part of our work further proposes a waveform design on jamming signal as a means to enhance the jamming efficiency. The basic idea is to consider both time and frequency domain structure of the transmitting signal when designing the jamming signal, making both time and frequency bandwidth largely match to each other. We discuss the implementation details for jamming common QAM and PSK modulated signals. Both simulations and proof-of-concept experiments validate the theoretical correctness of our reassessment and practical effectiveness of our method.}
}


@article{DBLP:journals/tmc/ZhouXCX21,
	author = {Tongqing Zhou and
                  Bin Xiao and
                  Zhiping Cai and
                  Ming Xu},
	title = {A Utility Model for Photo Selection in Mobile Crowdsensing},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {1},
	pages = {48--62},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2941927},
	doi = {10.1109/TMC.2019.2941927},
	timestamp = {Thu, 17 Dec 2020 18:29:12 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/ZhouXCX21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Existing mobile photo crowdsensing approaches focus on the participant-to-server photo pre-selection, i.e., reducing the photo redundancy from participants to a server. The server may still receive plenty of photos for a target area. Yet, another important problem is to select a proper photo subset of an area from the server to a requester. This is a challenging problem because the selected subset with a small size should attain both coverage on the PoIs - Points of Interest (i.e., photo coverage of the area) and quality on the views (i.e., view quality). In this paper, we propose a novel and generic server-to-requester photo selection approach even when there are neither photo shooting direction information nor reference photos. A utility model is designed to measure photo merits of coverage and quality by exploiting photos' spatial distribution and visual representativeness. We present two photo selection schemes, basic and PoI number-aware, to maximize the photo selection utility with multiple levels of granularity. Experimental results on real-world datasets show that our basic scheme outperforms the baselines by an average of 33% and 18.7% on photo coverage and view quality, respectively. Our PoI number-aware scheme can yield an additionally 44.8 percent improvement on the photo coverage performance.}
}


@article{DBLP:journals/tmc/LiQRYCZ21,
	author = {Lingxiang Li and
                  Tony Q. S. Quek and
                  Ju Ren and
                  Howard H. Yang and
                  Zhi Chen and
                  Yaoxue Zhang},
	title = {An Incentive-Aware Job Offloading Control Framework for Multi-Access
                  Edge Computing},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {1},
	pages = {63--75},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2941934},
	doi = {10.1109/TMC.2019.2941934},
	timestamp = {Mon, 25 Mar 2024 12:48:07 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/LiQRYCZ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper considers a scenario in which an access point (AP) is equipped with a server of finite computing power, and serves multiple resource-hungry users by charging users a price. This price helps to regulate users' behavior in offloading jobs to the AP. However, existing works on pricing are based on abstract concave utility functions, giving no dependence on physical layer parameters. To that end, we first introduce a novel utility function, which measures the cost reduction by offloading as compared with executing jobs locally. Based on this utility function we then formulate two offloading games, with one maximizing individuals interest and the other maximizing the overall systems interest. We analyze the structural property of the games and admit in closed-form the Nash Equilibrium and the Social Equilibrium for the homogeneous user case, respectively. The proposed expressions are functions of user parameters such as the weights of time and energy, the distance from the AP, thus constituting an advancement over prior economic works that have considered only abstract functions. Finally, we propose an optimal price-based scheme, with which we prove that the interactive decision-making process with self-interested users converges to a Nash Equilibrium point equal to the Social Equilibrium point.}
}


@article{DBLP:journals/tmc/NamLSL21,
	author = {Wooseung Nam and
                  Joohyun Lee and
                  Ness B. Shroff and
                  Kyunghan Lee},
	title = {An Inter-Data Encoding Technique that Exploits Synchronized Data for
                  Network Applications},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {1},
	pages = {76--92},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2940578},
	doi = {10.1109/TMC.2019.2940578},
	timestamp = {Thu, 17 Dec 2020 18:29:11 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/NamLSL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In a variety of network applications, there exists a significant amount of shared data between two end hosts. Examples include data synchronization services that replicate data from one node to another. Given that shared data may have a high correlation with new data to transmit, we question how such shared data can be best utilized to improve the efficiency of data transmission. To answer this, we develop an inter-data encoding technique, SyncCoding, that effectively replaces bit sequences of the data to be transmitted with the pointers to their matching bit sequences in the shared data so called references. By doing so, SyncCoding can reduce data traffic, speed up data transmission, and save energy consumption for transmission. Our evaluations of SyncCoding implemented in Linux show that it outperforms existing popular encoding techniques, Brotli, LZMA, Deflate, and Deduplication. The gains of SyncCoding over those techniques in the perspective of data size after compression in a cloud storage scenario are about 12.5, 20.8, 30.1, and 66.1 percent, and are about 78.4, 80.3, 84.3, and 94.3 percent in a web browsing scenario, respectively.}
}


@article{DBLP:journals/tmc/KumarSDS21,
	author = {Pankaj Kumar and
                  Prabhleen Singh and
                  Sam Darshi and
                  Samar Shailendra},
	title = {Analysis of Drone Assisted Network Coded Cooperation for Next Generation
                  Wireless Network},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {1},
	pages = {93--103},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2939308},
	doi = {10.1109/TMC.2019.2939308},
	timestamp = {Sun, 02 Oct 2022 15:51:34 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/KumarSDS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, use of drone as a relay node in Network Coded Cooperation (NCC) for upcoming wireless networks is proposed to achieve additional diversity as well as improve throughput. Unlike static relay cases, in drone assisted scenarios, better performance can be achieved simply by changing the position of relay. In order to quantify the network performance in drone assisted NCC, analytical closed form expression of outage probability has been calculated using two approaches namely, Analytical and Semi-analytical. Using a generalized system model, Probability Density Function (PDF) of Signal to Noise Ratio (SNR) of the path from source to destination via drone (relay) is derived. Closed form expression for outage probability in absence of direct link is also investigated. By analyzing Analog Network Coding (ANC) noise, statistical parameters of variance of ANC-noise have been obtained. Analytical findings have been verified through extensive simulations using MATLAB. Effects of drone height on system performance is also investigated through simulations. Framework presented here can be useful while analysing networks having resource constraint devices. PDF of SNR of relay path can be utilized for performing diversity calculations. Two outage expressions derived may be useful in determining system parameters for achieving any particular Quality of Service (QoS) in next generation wireless networks. Valuable insights obtained through the analysis of optimum height of drone are conducive while deploying the nodes in deterministic fashion for NCC.}
}


@article{DBLP:journals/tmc/SadhuZSP21,
	author = {Vidyasagar Sadhu and
                  Saman A. Zonouz and
                  Vincent Sritapan and
                  Dario Pompili},
	title = {CollabLoc: Privacy-Preserving Multi-Modal Collaborative Mobile Phone
                  Localization},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {1},
	pages = {104--116},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2937775},
	doi = {10.1109/TMC.2019.2937775},
	timestamp = {Thu, 17 Dec 2020 18:29:11 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/SadhuZSP21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Mobile location-based services are important context-aware services that are more and more used for enforcing security policies, for supporting indoor room navigation, and for providing personalized assistance. However, a major problem still remains unaddressed-the lack of solutions that work across buildings while not using additional infrastructure and also accounting for privacy and reliability needs. A privacy-preserving, multi-modal, cross-building, collaborative localization platform is proposed based on Wi-Fi Received Signal Strength Indicator (RSSI) (existing infrastructure), Cellular RSSI, sound, light, and geo-magnetic levels, that enables sub-room level localization. The solution is fully based on mobile phones and existing Wi-Fi infrastructure, and has privacy inherently built into it via cryptographically-secured onion routing and perturbation/randomization techniques. It also exploits the idea of weighted collaboration to increase the reliability as well as to limit the effect of noisy devices (due to sensor noise/privacy). The solution has been analyzed in terms of latency overhead due to onion-routing, request load on phones, privacy-accuracy tradeoffs, optimum parameters, granularity, different classification algorithms using real location data collected at multiple indoor and outdoor locations via an Android application. The additional features other than Wi-Fi RSSI values are shown to increase the accuracy to a maximum of 15 percent, while considering Geo-magnetic field is shown to enhance the granularity from 2.5 m to ≈1 m, a 60 percent improvement.}
}


@article{DBLP:journals/tmc/ZhaoWVMY21,
	author = {Jie Zhao and
                  Xin Wang and
                  Harish Viswanathan and
                  Arjuna Madanayake and
                  Guangxue Yue},
	title = {Compressed Beam Alignment with Out-of-Band Assistance in Millimeter
                  Wave Cellular Networks},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {1},
	pages = {117--129},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2941474},
	doi = {10.1109/TMC.2019.2941474},
	timestamp = {Thu, 17 Dec 2020 18:29:12 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/ZhaoWVMY21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Network transmission over millimeter-wave (mmW) bands has a big potential to provide orders of higher bandwidth. However, beamforming is generally needed to compensate for the high path loss. As mmW antennas have a potentially large number of candidate beamforming directions, to achieve high network throughput, the finding of a high gain direction between a base station and each mobile in the mmW network may involve a large overhead if training signals are directly sent along all possible directions or according to a large volume of codebook. Taking advantage of the block sparse characteristics of the mmW channel and coexistence of legacy antennas, we propose a comprehensive design for more efficient beam direction finding. Different from existing compressive-sensing-based schemes which just take a random subset of directions to measure, taking advantage of the path clustering feature of the mmW channel, we develop a self-adaptive block sparse algorithm which can benefit from preliminary channel estimation during each iteration of the problem solving to significantly improve the overall channel estimation accuracy thus the beam alignment gain. We also explore two methods to exploit co-located legacy antennas to provide further guidance for transmission direction finding. Simulation results indicate that our proposed beam alignment scheme outperforms the baseline and peer schemes in terms of the beamforming gain and training cost. By taking advantage of the block sparse properties of mmW channel, our proposed design is able to achieve the transmission throughput comparable with the exhaustive direction search at much lower overhead.}
}


@article{DBLP:journals/tmc/LiuDZCWL21,
	author = {Chi Harold Liu and
                  Zipeng Dai and
                  Yinuo Zhao and
                  Jon Crowcroft and
                  Dapeng Wu and
                  Kin K. Leung},
	title = {Distributed and Energy-Efficient Mobile Crowdsensing with Charging
                  Stations by Deep Reinforcement Learning},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {1},
	pages = {130--146},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2938509},
	doi = {10.1109/TMC.2019.2938509},
	timestamp = {Sun, 02 Oct 2022 15:51:34 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/LiuDZCWL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Mobile crowdsensing (MCS) represents a new sensing paradigm that utilizes the smart mobile devices to collect and share data. Traditional MCS systems mainly leverages the people carried smartphones and other wearable devices which are constrained by the limited sensing capability and battery power. With the popularity of unmanned vehicles like unmanned aerial vehicles (UAVs) and driverless cars, they can provide much more reliable, accurate and cost-efficient sensing services due to to their equipped more powerful sensors. In this paper, we propose a distributed control framework for energy-efficient and DIstributed VEhicle navigation with chaRging sTations, called “e-Divert”. It is a distributed multi-agent deep reinforcement learning (DRL) solution, which uses a convolutional neural network (CNN) to extract useful spatial features as the input to the actor-critic network to produce a real-time action. Also, e-Divert incorporates a distributed prioritized experience replay for better exploration and exploitation, and a long short-term memory (LSTM) enabled N-step temporal sequence modeling module. The solution fully explores the spatiotemporal nature of the considered scenario for better vehicle cooperation and competition between themselves and charging stations, to maximize the energy efficiency, data collection ratio, geographic fairness, and minimize the energy consumption simultaneously. Through extensive simulations, we find an appropriate set of hyperparameters that achieve the best performance, i.e., 5 actors in Ape-X architecture, priority exponent 0.5, and LSTM sequence length 3. Finally, we compare with four baselines including one state-of-the-art approach MADDPG. Results show that our proposed e-Divert significantly improves the energy efficiency, as compared to MADDPG, by 3.62 and 2.36 times on average when varying different numbers of vehicles and charging stations, respectively.}
}


@article{DBLP:journals/tmc/JiangSLCQH21,
	author = {Haotian Jiang and
                  James Starkman and
                  Yu{-}Ju Lee and
                  Huan Chen and
                  Xiaoye Qian and
                  Ming{-}Chun Huang},
	title = {Distributed Deep Learning Optimized System over the Cloud and Smart
                  Phone Devices},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {1},
	pages = {147--161},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2941492},
	doi = {10.1109/TMC.2019.2941492},
	timestamp = {Thu, 17 Dec 2020 18:29:12 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/JiangSLCQH21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Deep learning has been becoming a promising focus in data mining research. With deep learning techniques, researchers can discover deep properties and features of events from quantitative mobile sensor data. However, many data sources are geographically separated and have strict privacy, security, and regulatory constraints. Upon releasing the privacy-sensitive data, these data sources generally no longer physically possess their data and cannot interfere with the way their personal data being used. Therefore, it is necessary to explore distributed data mining architecture which is able to conduct consensus learning based on needs. Accordingly, we propose a distributed deep learning optimized system which contains a cloud server and multiple smartphone devices with computation capabilities and each device is served as a personal mobile data hub for enabling mobile computing while preserving data privacy. The proposed system keeps the private data locally in smartphones, shares trained parameters, and builds a global consensus model. The feasibility and usability of the proposed system are evaluated by three experiments and related discussion. The experimental results show that the proposed distributed deep learning system can reconstruct the behavior of centralized training. We also measure the cumulative network traffic in different scenarios and show that the partial parameter sharing strategy does not only preserve the performance of the trained model but also can reduce network traffic. User data privacy is protected on two levels. First, local private training data do not need to be shared with other people and the user has full control of their personal training data all the time. Second, only a small fraction of trained gradients of the local model are selected for sharing, which further reduces the risk of information leaking.}
}


@article{DBLP:journals/tmc/SepulcreG21,
	author = {Miguel Sepulcre and
                  Javier Goz{\'{a}}lvez},
	title = {Heterogeneous {V2V} Communications in Multi-Link and Multi-RAT Vehicular
                  Networks},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {1},
	pages = {162--173},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2939803},
	doi = {10.1109/TMC.2019.2939803},
	timestamp = {Thu, 17 Dec 2020 18:29:11 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/SepulcreG21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Connected and automated vehicles will enable advanced traffic safety and efficiency applications thanks to the dynamic exchange of information between vehicles, and between vehicles and infrastructure nodes. Connected vehicles can utilize IEEE 802.11p for vehicle-to-vehicle (V2V) and vehicle-to-infrastructure (V2I) communications. However, a widespread deployment of connected vehicles and the introduction of connected automated driving applications will notably increase the bandwidth and scalability requirements of vehicular networks. This paper proposes to address these challenges through the adoption of heterogeneous V2V communications in multi-link and multi-RAT vehicular networks. In particular, the paper proposes the first distributed (and decentralized) context-aware heterogeneous V2V communications algorithm that is technology and application agnostic, and that allows each vehicle to autonomously and dynamically select its communications technology taking into account its application requirements and the communication context conditions. This study demonstrates the potential of heterogeneous V2V communications, and the capability of the proposed algorithm to satisfy the vehicles' application requirements while approaching the estimated upper bound network capacity.}
}


@article{DBLP:journals/tmc/WangRYZ21,
	author = {Bo Wang and
                  Fengyuan Ren and
                  Jiahai Yang and
                  Chao Zhou},
	title = {Improving the Performance of Online Bitrate Adaptation with Multi-Step
                  Prediction Over Cellular Networks},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {1},
	pages = {174--187},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2939124},
	doi = {10.1109/TMC.2019.2939124},
	timestamp = {Tue, 18 Oct 2022 08:35:31 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/WangRYZ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Video streaming over mobile is flourishing, and most commercial players use adaptive bitrate (ABR) streaming to deliver video in varying network conditions. Using network capacity and buffer occupancy as system states, ABR algorithms adjust bitrate based on the instantaneous system states, which is able to adapt to network changes in real-time and ensure high quality of experience (QoE). However, they are incapable of providing good QoE over mobile. Due to the high dynamic characteristics of cellular network, the system states change rapidly over time. The instantaneous state-based adaptation can induce significant video quality fluctuation which greatly degrades QoE. In this paper, we propose an online ABR algorithm called MSPC to provide good QoE in cellular network. To balance the conflict between rapid adaptation and smooth bitrate, MSPC utilizes the multi-step prediction of future system states to select bitrates instead of the instantaneous current states. At the same time, it controls the buffer occupancy to eliminate the impact of prediction error on performance. We implement MSPC on a reference video player with performance evaluated based on realistic cellular traces. Experimental results show that MSPC reduces the bitrate change of existing online algorithms by 62.4 percent on average while maintaining high bitrates and achieving zero rebuffering over 97.83 percent of all tested sessions.}
}


@article{DBLP:journals/tmc/YanSCL21,
	author = {Li Yan and
                  Haiying Shen and
                  Kang Chen and
                  Guoxin Liu},
	title = {MobileCopy: Improving Data Availability and File Search Efficiency
                  in Delay Tolerant Networks against Correlated Node Failure},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {1},
	pages = {188--203},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2939792},
	doi = {10.1109/TMC.2019.2939792},
	timestamp = {Thu, 17 Dec 2020 18:29:11 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/YanSCL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {So far, there is no file replication method that tries to reduce data loss in correlated node failures, which however are common in Disruption Tolerant Networks (DTNs). In this paper, we propose a distributed file replication method (called MobileCopy) in DTNs, which aims to achieve low probability of totally losing a file at the expense of having a high number of impacted files in an individual large-scale correlated node failure. MobileCopy is designed for community-based file sharing systems. It has two main components: i) data loss resistant and popularity aware file replication, and ii) distributed hash table (DHT)-based file replica indexing. MobileCopy considers file popularity to determine the number of replicas of a file in each community. Through limiting the possible combination of candidate replica holders, MobileCopy greatly reduces the probability of node failures that will lead to data loss, i.e., losing all replicas of a file. Moreover, MobileCopy enables nodes to efficiently store and fetch the placement information of file replicas through competition based file replication and considering node mobility throughput among communities. Extensive trace-driven experiments demonstrate the effectiveness of MobileCopy against correlated node failures compared with previous methods.}
}


@article{DBLP:journals/tmc/WangYWLCKH21,
	author = {Shuai Wang and
                  Zhimeng Yin and
                  Shuai Wang and
                  Zhijun Li and
                  Yongrui Chen and
                  Song Min Kim and
                  Tian He},
	title = {Networking Support for Bidirectional Cross-Technology Communication},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {1},
	pages = {204--216},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2938524},
	doi = {10.1109/TMC.2019.2938524},
	timestamp = {Wed, 01 Sep 2021 17:26:24 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/WangYWLCKH21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recent research on physical layer cross technology communication (PHY-CTC) brings a timely answer for escalated wireless coexistence and open spectrum movement. PHY-CTC achieves direct communication among heterogeneous wireless technologies (e.g.,WiFi, Bluetooth, and ZigBee) in physical layer and thus brings communication support for coexistence service such as spectrum management and IoT device control. To put PHY-CTC into service, however, there still exists a gap due to its transmission failure and asymmetric link (i.e., one-way PHY-CTC) issues. In this paper, we propose NetCTC – the first networking support design for PHY-CTC to establish feedbacks (e.g., ACKs) and thus meet the upper layer networking requirements in heterogeneous unicast, multicast and broadcast. The core design of NetCTC is a real-time interaction mechanism which achieves reliable, transmission efficient and concurrent interactive communication among heterogeneous devices. We implement and evaluate NetCTC on commodity devices and the USRP-N210 platform. Our extensive evaluation demonstrates that NetCTC achieves reliable bidirectional cross technology communication under a full range of wireless configurations including stationary, mobile and duty-cycled settings.}
}


@article{DBLP:journals/tmc/ZhangWWWBZL21,
	author = {Feng Zhang and
                  Chenshu Wu and
                  Beibei Wang and
                  Min Wu and
                  Daniel Bugos and
                  Hangfang Zhang and
                  K. J. Ray Liu},
	title = {{SMARS:} Sleep Monitoring via Ambient Radio Signals},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {1},
	pages = {217--231},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2939791},
	doi = {10.1109/TMC.2019.2939791},
	timestamp = {Thu, 14 Oct 2021 09:27:12 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/ZhangWWWBZL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We present the model, design, and implementation of SMARS, the first practical Sleep Monitoring system that exploits Ambient Radio Signals to recognize sleep stages and assess sleep quality. This will enable a future smart home that monitors daily sleep in a ubiquitous, non-invasive and contactless manner, without instrumenting the subject's body or the bed. The key enabler underlying SMARS is a statistical model that accounts for all reflecting and scattering multipaths, allowing highly accurate and instantaneous breathing estimation with best-ever performance achieved on commodity devices. On this basis, SMARS then recognizes different sleep stages, including wake, rapid eye movement (REM), and non-REM (NREM), which was previously only possible with dedicated hardware. We implement a real-time system on commercial WiFi chipsets and deploy it in 6 homes, resulting in 32 nights of data in total. Our results demonstrate that SMARS yields a median absolute error of 0.47 breaths per minute (BPM) and a 95 percent-tile error of only 2.92 BPM for breathing estimation, and detects breathing robustly even when a person is 10 meters away from the link, or behind a wall. SMARS achieves a sleep staging accuracy of 88 percent, outperforming the prevalent unobtrusive commodity solutions using bed sensor or UWB radar. The performance is also validated upon a public sleep dataset of 20 patients. By achieving promising results with merely a single commodity RF link, we believe that SMARS will set the stage for a practical in-home sleep monitoring solution.}
}


@article{DBLP:journals/tmc/SinhaM21,
	author = {Abhishek Sinha and
                  Eytan H. Modiano},
	title = {Throughput-Optimal Broadcast in Wireless Networks with Point-to-Multipoint
                  Transmissions},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {1},
	pages = {232--246},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2940025},
	doi = {10.1109/TMC.2019.2940025},
	timestamp = {Mon, 22 Feb 2021 15:13:30 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/SinhaM21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We consider the problem of efficient packet dissemination in wireless networks with point-to-multipoint wireless broadcast channels. We propose a dynamic policy, which achieves the broadcast capacity of the network. This policy is obtained by first transforming the original multi-hop network into a precedence-relaxed virtual single-hop network and then finding an optimal broadcasting policy for the relaxed network. The resulting policy is shown to be throughput-optimal for the original wireless network using a sample-path argument. We also prove the NP-completeness of the finite-horizon broadcasting problem, which is in contrast with the polynomial-time solvability of the problem with point-to-point channels. Illustrative simulation results demonstrate the efficacy of the proposed broadcast policy in achieving the full broadcast capacity with low delay.}
}


@article{DBLP:journals/tmc/AlamRM21,
	author = {Mohammad Arif Ul Alam and
                  Nirmalya Roy and
                  Archan Misra},
	title = {Tracking and Behavior Augmented Activity Recognition for Multiple
                  Inhabitants},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {1},
	pages = {247--262},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2936382},
	doi = {10.1109/TMC.2019.2936382},
	timestamp = {Sat, 09 Apr 2022 12:29:16 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/AlamRM21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We develop CACE (Constraints And Correlations mining Engine), a framework that significantly improves the recognition accuracy of complex daily activities in multi-inhabitant smarthomes. CACE views the implicit relationships between the activities of multiple people as an asset, and exploits such constraints and correlations in a hierarchical fashion, taking advantage of both personspecific sensor data (generated by wearable devices) and person-independent ambient sensor data (generated by ambient sensors). To effectively utilize such couplings, CACE first uses a multi-target particle filtering approach over ambient sensors captured movement data, to identify the number of distinct users and infer individual-specific movement trajectories. We then utilize a Hierarchical Dynamic Bayesian Network (HDBN)-based model for activity recognition. This model utilizes the inter-and-intra individual correlations and constraints, at both micro-activity and macro-activity levels, to recognize individual activities accurately. These constraints are learnt automatically using data-mining techniques, and help to dramatically reduce the computational complexity of HDBN-based inferencing. Empirical studies using a real-world testbed of five multi-inhabitant smarthomes shows that CACE is able to achieve an activity recognition accuracy of 95%, with a 16-fold reduction in computational overhead compared to traditional hybrid classification approaches.}
}


@article{DBLP:journals/tmc/FangML21,
	author = {Song Fang and
                  Ian D. Markwood and
                  Yao Liu},
	title = {Wireless-Assisted Key Establishment Leveraging Channel Manipulation},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {1},
	pages = {263--275},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2939529},
	doi = {10.1109/TMC.2019.2939529},
	timestamp = {Thu, 17 Dec 2020 18:29:12 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/FangML21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Wireless communication is easily eavesdropped due to the broadcast nature of the wireless medium. This has spurred extensive research into secret key establishment using physical layer characteristics of wireless channels. In all these schemes, the secret keys directly originate from the physical features of the real wireless channel, which is highly dependent on the communication environment nearby. Also, previous schemes require performing information reconciliation, which increases both the costs and the risk of key leakage. In this paper, we exhibit a novel wireless key establishment method allowing the transmitter to specify arbitrary content as the key and cause the receiver to obtain the same key leveraging a channel manipulation technique. We furthermore enable the transmitter to apply error-correction code to the key, so that the receiver can automatically correct any mismatched bits without sending key-related information back to the transmitter over the public channel. Experimental results demonstrate that our key establishment method reaches a success rate as high as 91.0 percent for establishing a 168-bit key between the transmitter and the receiver, and meanwhile the chance that the eavesdropper can infer the key in meter-order range of the receiver is subdued into the range of 0~0.10 percent.}
}


@article{DBLP:journals/tmc/ZhangHZ21,
	author = {Meng Zhang and
                  Jianwei Huang and
                  Rui Zhang},
	title = {Wireless Power Transfer with Information Asymmetry: {A} Public Goods
                  Perspective},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {1},
	pages = {276--291},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2941205},
	doi = {10.1109/TMC.2019.2941205},
	timestamp = {Sat, 06 Aug 2022 22:05:46 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/ZhangHZ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Wireless power transfer (WPT) technology enables a cost-effective and sustainable energy supply in wireless networks. However, the broadcast nature of wireless signals makes them non-excludable public goods, which leads to potential free-riders among energy receivers. In this study, we formulate the wireless power provision problem as a public goods provision problem, aiming to maximize the social welfare of a system of an energy transmitter (ET) and all the energy users (EUs), while considering their heterogeneous valuations, private information, and self-interested behaviors. We propose a two-phase all-or-none scheme involving a low-complexity Power And Taxation (PAT) mechanism, which ensures voluntary participation, truthfulness, budget balance, and social optimality at every Nash equilibrium (NE). We propose a distributed PAT (D-PAT) algorithm to reach an NE, and prove its convergence by connecting the structure of NEs and that of the optimal solution to a related optimization problem. We further extend the analysis to a multi-channel system, which brings a further challenge of non-strictly concave agents' payoffs. We propose a Multi-Channel PAT (M-PAT) mechanism and a distributed M-PAT (D-MPAT) algorithm to address the challenge. Simulation results show that, our design is most beneficial when there are more EUs and more homogeneous channel gains.}
}


@article{DBLP:journals/tmc/WangDZLZCS21,
	author = {Shangguang Wang and
                  Chuntao Ding and
                  Ning Zhang and
                  Xiulong Liu and
                  Ao Zhou and
                  Jiannong Cao and
                  Xuemin Shen},
	title = {A Cloud-Guided Feature Extraction Approach for Image Retrieval in
                  Mobile Edge Computing},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {2},
	pages = {292--305},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2944371},
	doi = {10.1109/TMC.2019.2944371},
	timestamp = {Tue, 21 Mar 2023 21:12:54 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/WangDZLZCS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Mobile Edge Computing (MEC) can facilitate various important image retrieval applications for mobile users by offloading partial computation tasks from resource-limited mobile devices to edge servers. However, existing related works suffer from two major limitations. (i) High network bandwidth cost: they need to extract numerous features from the image and upload these feature data to the cloud server. (ii) Lowretrieval accuracy: they separate the feature extraction processes from the image data set in the cloud server, thus unable to provide effective features for accurate image retrieval. In this paper, we propose a cloud-guided feature extraction approach for mobile image retrieval. In the proposed approach, the cloud server first leverages the relationships among labeled images in the data set to learn a projection matrix P. Then, it uses the matrix P to extract discriminative features from the image data set and form a low-dimensional feature data set. Following that, the cloud server sends the matrix P to the edge server and uses it to multiply the image χ. The result PTχ, i.e., image features, is uploaded to the cloud server to find the label of the image with the most similar multiplying result. The label is regarded as the retrieval result and returned to the mobile user. In the cloud-guided feature extraction approach, the matrix P can extract a small number of effective image features, which not only reduces network traffic but also improves retrieval accuracy. We have implemented a prototype system to validate the proposed approach and evaluate its performance by conducting extensive experiments using a real MEC environment and data set. The experimental results show that the proposed approach reduces the network traffic by nearly 93 percent and improves the retrieval accuracy by nearly 6.9 percent compared with the state-of-the-art image retrieval approaches in MEC.}
}


@article{DBLP:journals/tmc/SagduyuSE21,
	author = {Yalin E. Sagduyu and
                  Yi Shi and
                  Tugba Erpek},
	title = {Adversarial Deep Learning for Over-the-Air Spectrum Poisoning Attacks},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {2},
	pages = {306--319},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2950398},
	doi = {10.1109/TMC.2019.2950398},
	timestamp = {Tue, 26 Jan 2021 08:44:53 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/SagduyuSE21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {An adversarial deep learning approach is presented to launch over-the-air spectrum poisoning attacks. A transmitter applies deep learning on its spectrum sensing results to predict idle time slots for data transmission. In the meantime, an adversary learns the transmitter's behavior (exploratory attack) by building another deep neural network to predict when transmissions will succeed. The adversary falsifies (poisons) the transmitter's spectrum sensing data over the air by transmitting during the short spectrum sensing period of the transmitter. Depending on whether the transmitter uses the sensing results as test data to make transmit decisions or as training data to retrain its deep neural network, either it is fooled into making incorrect decisions (evasion attack) or the transmitter's algorithm is retrained incorrectly for future decisions (causative attack). Both attacks are energy efficient and hard to detect (stealth) compared to jamming the long data transmission period, and substantially reduce the throughput. A dynamic defense is designed for the transmitter that deliberately makes a small number of incorrect transmissions (selected by the confidence score on channel classification) to manipulate the adversary's training data. This defense effectively fools the adversary (if any) and helps the transmitter sustain its throughput with or without an adversary present.}
}


@article{DBLP:journals/tmc/LeeJH21,
	author = {Gunwoo Lee and
                  Suk Hoon Jung and
                  Dongsoo Han},
	title = {An Adaptive Sensor Fusion Framework for Pedestrian Indoor Navigation
                  in Dynamic Environments},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {2},
	pages = {320--336},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2946809},
	doi = {10.1109/TMC.2019.2946809},
	timestamp = {Thu, 27 Jul 2023 08:18:51 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/LeeJH21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Indoor navigation is a representative application of an indoor positioning system that uses a variety of equipment, including smartphones with various sensors. Many indoor navigation systems utilize Wi-Fi signals, as well as a variety of inertial sensors, such as a 3D accelerometer, digital compass, gyroscope, and barometer, to improve the accuracy of user location tracking. The inertial sensors are vulnerable to changes in the surrounding environments and sensitive to users behavior, but little research has been conducted on sensor fusion under these conditions. In this paper, we propose a dynamic sensor fusion framework (DSFF) that provides accurate user tracking results by dynamically calibrating inertial sensor readings in a sensor fusion process. The proposed method continually learns the errors and biases of each sensor due to the changes in user behavior patterns and surrounding environments. The learned patterns are then dynamically applied to the user tracking process to yield accurate results. The results of experiments conducted in both a single-story and a multi-story building confirm that DSFF provides accurate tracking results. The scalability of the DSFF will enable it to provide more accurate tracking results with various sensors, both existing and under development.}
}


@article{DBLP:journals/tmc/YuLCZK21,
	author = {Jiadi Yu and
                  Li Lu and
                  Yingying Chen and
                  Yanmin Zhu and
                  Linghe Kong},
	title = {An Indirect Eavesdropping Attack of Keystrokes on Touch Screen through
                  Acoustic Sensing},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {2},
	pages = {337--351},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2947468},
	doi = {10.1109/TMC.2019.2947468},
	timestamp = {Tue, 26 Jan 2021 08:44:53 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/YuLCZK21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper demonstrates the feasibility of a side-channel attack to infer keystrokes on touch screen leveraging an off-the-shelf smartphone. Although there exist some studies on keystroke eavesdropping attacks on touch screen, they are mainly direct eavesdropping attacks, i.e., require the device of victims compromised to provide side-channel information for the adversary, which are hardly launched in practical scenarios. In this work, we show the practicability of an indirect eavesdropping attack, KeyListener, which infers keystrokes on QWERTY keyboards of touch screen leveraging audio devices on a smartphone. We investigate the attenuation of acoustic signals, and find that a user's keystroke fingers can be localized through the attenuation of acoustic signals received by the microphones in the smartphone. We then utilize the attenuation of acoustic signals to localize each keystroke, and further analyze errors induced by ambient noises. To improve the accuracy of keystroke localization, KeyListener further tracks finger movements during inputs through phase change and Doppler effect to reduce errors of acoustic signal attenuation-based keystroke localization. In addition, a binary tree-based search approach is employed to infer keystrokes in a context-aware manner. The proposed keystroke eavesdropping attack is robust to various environments without the assistance of additional infrastructures. Extensive experiments demonstrate that the accuracy of keystroke inference in top-5 candidates can approach 90 percent with a top-5 error rate of around 6 percent, which is a strong indication of the possible user privacy leakage of inputs on QWERTY keyboard.}
}


@article{DBLP:journals/tmc/LuRCPP21,
	author = {Zongqing Lu and
                  Swati Rallapalli and
                  Kevin Chan and
                  Shiliang Pu and
                  Thomas La Porta},
	title = {Augur: Modeling the Resource Requirements of ConvNets on Mobile Devices},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {2},
	pages = {352--365},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2946538},
	doi = {10.1109/TMC.2019.2946538},
	timestamp = {Tue, 09 Feb 2021 13:58:55 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/LuRCPP21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Convolutional Neural Networks (ConvNets/CNNs) have revolutionized the research in computer vision, due to their ability to capture complex patterns, resulting in high inference accuracies. However, the increasingly complex nature of these neural networks means that they are particularly suited for server computers with powerful GPUs. We envision that deep learning applications will be eventually widely deployed on mobile devices, e.g., smartphones, self-driving cars, and drones. Therefore, in this paper, we aim to understand the resource requirements of CNNs on mobile devices in terms of compute time, memory, and power. First, by deploying several popular CNNs on different mobile CPUs and GPUs, we measure and analyze the performance and resource usage for the CNNs on a layerwise granularity. Our findings point out the potential ways of optimizing the CNN pipelines on mobile devices. Second, we model resource requirements of core computations of CNNs. Finally, based on the measurement and modeling, we build and evaluate our modeling tool, Augur, which takes a CNN configuration (descriptor) as the input and estimates the compute time, memory, and power requirements of the CNN, to give insights about whether and how efficiently a CNN can be run on a given mobile platform.}
}


@article{DBLP:journals/tmc/CarlosGWCM21,
	author = {Manuel Ricardo Carlos and
                  Luis Carlos Gonz{\'{a}}lez{-}Gurrola and
                  Johan Wahlstr{\"{o}}m and
                  Raymundo Cornejo and
                  Fernando Mart{\'{\i}}nez{-}Reyes},
	title = {Becoming Smarter at Characterizing Potholes and Speed Bumps from Smartphone
                  Data - Introducing a Second-Generation Inference Problem},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {2},
	pages = {366--376},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2947443},
	doi = {10.1109/TMC.2019.2947443},
	timestamp = {Tue, 13 Apr 2021 10:56:11 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/CarlosGWCM21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Much has been said regarding the automatic identification of roadway obstacles by analyzing data collected from inertial sensors either fixed to the vehicle or embedded into the drivers' smartphones. Literature is vast in models to, given a record of sensor readings, determine if the sample corresponds to a pothole or speed bump, even with scores beyond 90% in performance. Acknowledging this advance, this article considers the next-generation version of this problem. Specifically, we investigate questions such as: what physical properties of roadway obstacles could be inferred from the same sensor readings? or, what are the best schemes to model this profile problem? To approach these questions we built the first obstacle-detailed data set that is composed of accelerometer and gyroscope readings of 163 potholes and 101 speed bumps. This data set is the first of its kind, since it specifies ground truth labels that correspond to potholes' depths and also, functional status (OK - Not OK) for speed bumps. We approach this fine-grained characterization using three different learning schemes, as a Regression, Classification and Learning to Rank tasks. Results are encouraging, reporting a RMSE for pothole's depth prediction of up to 1.68 cm and classification performance of 0.89 in AUC score. In summary, after more than 10 years of analysis, struggles and achievements, it is time for the community to become smarter and start profiling roads with real detail.}
}


@article{DBLP:journals/tmc/ChenSZX21,
	author = {Lixing Chen and
                  Cong Shen and
                  Pan Zhou and
                  Jie Xu},
	title = {Collaborative Service Placement for Edge Computing in Dense Small
                  Cell Networks},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {2},
	pages = {377--390},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2945956},
	doi = {10.1109/TMC.2019.2945956},
	timestamp = {Thu, 20 Jun 2024 15:06:43 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/ChenSZX21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Mobile Edge Computing (MEC) pushes computing functionalities away from the centralized cloud to the proximity of data sources, thereby reducing service provision latency and saving backhaul network bandwidth. Although computation offloading for MEC systems has been extensively studied in the literature, service placement is an equally, if not more, important design topic of MEC, yet receives much less attention. Service placement refers to configuring the service platform and storing the related libraries/databases at the edge server, e.g., MEC-enabled Base Station (BS), which enables corresponding computation tasks to be executed. Due to the limited computing resource, the edge server can host only a small number of services and hence which services to host has to be judiciously decided to maximize the system performance. In this paper, we investigate collaborative service placement in MEC-enabled dense small cell networks. An efficient decentralized algorithm, called CSP (Collaborative Service Placement), is proposed where a network of small cell BSs optimize service placement decisions collaboratively to address a number of challenges in MEC systems, including service heterogeneity, spatial demand coupling, and decentralized coordination. CSP is developed based on parallel Gibbs sampling by exploiting the graph coloring on the small cell network. The algorithm significantly improves the time efficiency compared to conventional Gibbs sampling, yet guarantees provable convergence and optimality. CSP is further extended to work with selfish BSs, where BSs are allowed to choose “to cooperate” or “not to cooperate.” We employ coalitional game to investigate the strategic behaviors of selfish BSs and design a coalition formation scheme to form stable BS coalitions using merge-and-split rules. Simulations results show that CSP can effectively reduce edge system operational cost for both cooperative and selfish BSs.}
}


@article{DBLP:journals/tmc/YaoWWW21,
	author = {Lin Yao and
                  Yuqi Wang and
                  Xin Wang and
                  Guowei Wu},
	title = {Cooperative Caching in Vehicular Content Centric Network Based on
                  Social Attributes and Mobility},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {2},
	pages = {391--402},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2944829},
	doi = {10.1109/TMC.2019.2944829},
	timestamp = {Wed, 05 Jan 2022 14:30:51 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/YaoWWW21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Communications in vehicular ad-hoc network (VANET) are subject to performance degradation as results of channel fading and intermittent network connectivity. The emerging Vehicular Content Centric Network (VCCN) is promising in supporting the needs of contents and alleviating the communication problems in VANET. Specifically, to improve the cache hit ratio and reduce the access delay of content retrieval, it helps to choose the appropriate vehicles to cache the frequently accessed data items. In this paper, we propose a Cooperative Caching scheme based on Social Attributes and Mobility Prediction (CCSAMP) for VCCN. CCSAMP is based on the observation that vehicles move around and are liable to contact each other according to drivers' common interests or social similarities. A caching node sharing more social attributes with the content requester is more likely to be interested in the same contents and distribute the contents to others with similar interests. Furthermore, a caching node that frequently meets other nodes is a better candidate to keep cache copies. To increase the network performance, CCSAMP also exploits the regularity of vehicle moving behaviors to predict the chance for a vehicle to reach hot zones based on Hidden Markov Model (HMM). We evaluate CCSAMP through the ONE simulator to demonstrate its higher cache hit ratio and lower content access delay compared to other state-of-the-art schemes.}
}


@article{DBLP:journals/tmc/SunWDH21,
	author = {Guodong Sun and
                  Yanan Wang and
                  Xingjian Ding and
                  Rong Hu},
	title = {Cost-Fair Task Allocation in Mobile Crowd Sensing With Probabilistic
                  Users},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {2},
	pages = {403--415},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2950921},
	doi = {10.1109/TMC.2019.2950921},
	timestamp = {Mon, 28 Aug 2023 21:39:16 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/SunWDH21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Mobile crowd sensing (MCS) is a new paradigm for urban-scale monitoring. This article concentrates on the Cost-Fair Task Allocation (CFA) problem for the MCS scenario where the collaboration of multiple probabilistic mobilephone users is needed to yield more reliable observation. CFA aims to allocate sensing tasks to users so that the sensing costs undertaken by all users are as balancing as possible, while the requirement of the requester for data reliability can be satisfied. CFA is greatly important to MCS campaigns in terms of reliability and sustainability. We design two algorithms to solve the CFA problem in the offline and online cases, respectively. Specifically, we propose a novel penalty-based model to reformulate the offline CFA problem, and based on this model, we design an offline algorithm, which can yield a computation-efficient\nε\n-solution with any small\nε>0\n. For the online case, we design a polynomial-time approximation algorithm, which struggles to allocate each of the sequentially arriving tasks to users as fairly as possible, and can achieve an upper-bounded competitiveness relative to the optimal CFA solution. Finally, we conduct extensive numeric analyses to validate the performance of our algorithms under diverse experimental setups.}
}


@article{DBLP:journals/tmc/RaveendranGJTPS21,
	author = {Neetu Raveendran and
                  Yunan Gu and
                  Chunxiao Jiang and
                  Nguyen Hoang Tran and
                  Miao Pan and
                  Lingyang Song and
                  Zhu Han},
	title = {Cyclic Three-Sided Matching Game Inspired Wireless Network Virtualization},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {2},
	pages = {416--428},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2947522},
	doi = {10.1109/TMC.2019.2947522},
	timestamp = {Sat, 29 Oct 2022 22:00:05 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/RaveendranGJTPS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Wireless network virtualization is basically the abstraction, isolation, and sharing of wireless resources among different entities. Consequently, virtualization provides great flexibility and higher network efficiency, and enables easier migration to new technologies in wireless networks. Traditionally, a wireless network virtualization controller manages the virtual resources (including radio resources and infrastructure resources) known as slices which are available to the Service Providers (SPs). The SPs then allocate their purchased resources to serve their subscribed mobile users. Such a centralized allocation decouples the Quality-of-Service (QoS) management by the SPs from the virtual resource management by the controller. In this paper, we propose a matching based wireless network virtualization resource allocation mechanism: a distributed three-sided (3D) matching between radio resources, physical infrastructure and mobile users. The Restricted Three-sided Matching with Size and Cyclic preference model (R-TMSC) is implemented to obtain a stable solution. Simulation results show that our proposed spectrum-oriented and user-oriented algorithms outperform the traditional resource allocation schemes. The spectrum-oriented algorithm enhances the user throughput and the system performance, within a lesser run time. Furthermore, for an increasing number of users, the proposed algorithms serve more users than traditional methods.}
}


@article{DBLP:journals/tmc/DavasliogluSES21,
	author = {Kemal Davaslioglu and
                  Sohraab Soltani and
                  Tugba Erpek and
                  Yalin E. Sagduyu},
	title = {DeepWiFi: Cognitive WiFi with Deep Learning},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {2},
	pages = {429--444},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2949815},
	doi = {10.1109/TMC.2019.2949815},
	timestamp = {Tue, 26 Jan 2021 08:44:53 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/DavasliogluSES21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We present the DeepWiFi protocol, which hardens the baseline WiFi (IEEE 802.11ac) with deep learning and sustains high throughput by mitigating out-of-network interference. DeepWiFi is interoperable with baseline WiFi and builds upon the existing WiFi's PHY transceiver chain without changing the MAC frame format. Users run DeepWiFi for: i) RF front end processing; ii) spectrum sensing and signal classification; iii) signal authentication; iv) channel selection and access; v) power control; vi) modulation and coding scheme (MCS) adaptation; and vii) routing. DeepWiFi mitigates the effects of probabilistic, sensing-based, and adaptive jammers. RF front end processing applies a deep learning-based autoencoder to extract spectrum-representative features. Then a deep neural network is trained to classify waveforms reliably as idle, WiFi, or jammer. Utilizing channel labels, users effectively access idle or jammed channels, while avoiding interference with legitimate WiFi transmissions (authenticated by machine learning-based RF fingerprinting) resulting in higher throughput. Users optimize their transmit power for low probability of intercept/detection and their MCS to maximize link rates used by backpressure algorithm for routing. Supported by embedded platform implementation, DeepWiFi provides major throughput gains compared to baseline WiFi and another jamming-resistant protocol, especially when channels are likely to be jammed and the signal-to-interference-plus-noise-ratio is low.}
}


@article{DBLP:journals/tmc/YangLTCWF21,
	author = {Song Yang and
                  Fan Li and
                  Stojan Trajanovski and
                  Xu Chen and
                  Yu Wang and
                  Xiaoming Fu},
	title = {Delay-Aware Virtual Network Function Placement and Routing in Edge
                  Clouds},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {2},
	pages = {445--459},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2942306},
	doi = {10.1109/TMC.2019.2942306},
	timestamp = {Tue, 07 May 2024 20:24:40 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/YangLTCWF21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Mobile Edge Computing (MEC) offers a way to shorten the cloud servicing delay by building the small-scale cloud infrastructures at the network edge, which are in close proximity to the end users. Moreover, Network Function Virtualization (NFV) has been an emerging technology that transforms from traditional dedicated hardware implementations to software instances running in a virtualized environment. In NFV, the requested service is implemented by a sequence of Virtual Network Functions (VNF) that can run on generic servers by leveraging the virtualization technology. Service Function Chaining (SFC) is defined as a chain-ordered set of placed VNFs that handles the traffic of the delivery and control of a specific application. NFV therefore allows to allocate network resources in a more scalable and elastic manner, offer a more efficient and agile management and operation mechanism for network functions and hence can largely reduce the overall costs in MEC. In this paper, we study the problem of how to place VNFs on edge and public clouds and route the traffic among adjacent VNF pairs, such that the maximum link load ratio is minimized and each user's requested delay is satisfied. We consider this problem for both totally ordered SFCs and partially ordered SFCs. We prove that this problem is NP-hard, even for the special case when only one VNF is requested. We subsequently propose an efficient randomized rounding approximation algorithm to solve this problem. Extensive simulation results show that the proposed approximation algorithm can achieve close-to-optimal performance in terms of acceptance ratio and maximum link load ratio.}
}


@article{DBLP:journals/tmc/ZhaoLTTQ21,
	author = {Yangming Zhao and
                  Xin Liu and
                  Lai Tu and
                  Chen Tian and
                  Chunming Qiao},
	title = {Dynamic Service Entity Placement for Latency Sensitive Applications
                  in Transportation Systems},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {2},
	pages = {460--472},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2947465},
	doi = {10.1109/TMC.2019.2947465},
	timestamp = {Wed, 26 May 2021 16:52:01 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/ZhaoLTTQ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the development of applications on end devices, such as cell phones and tablets, more and more passengers would like to have entertainment on these end devices when they are cruising on vehicles. Due to the limited computation ability of the end devices, some of these applications have back-end components on the edge clouds, which are realized by Service Entities (SEs). In this work, we propose a system named DSEP to Dynamically determine the SEPlacement, such that the maximum latency experienced by the passengers can be minimized. To this end, we first train two sequential neural networks to predict the position of each individual vehicle, and propose an efficient algorithm based on optimization relaxation and Lagrange decomposition to determine the SE placement. Through extensive real-data driven simulations, we find that with the two sequential neural networks proposed in this paper, there are less than 1 percent errors on estimating where the passengers will access the edge cloud system. When the computation resources in the edge cloud are limited, DSEP can reduce the response latency by up to 43 percent compared with the nearest placement scheme. Even averaging the performance improvement over all simulation settings, DSEP can reduce the response latency by 16 percent.}
}


@article{DBLP:journals/tmc/YounisTP21,
	author = {Ayman Younis and
                  Tuyen X. Tran and
                  Dario Pompili},
	title = {Energy-Efficient Resource Allocation in C-RANs with Capacity-Limited
                  Fronthaul},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {2},
	pages = {473--487},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2942597},
	doi = {10.1109/TMC.2019.2942597},
	timestamp = {Tue, 26 Jan 2021 08:44:53 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/YounisTP21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cloud Radio Access Network (C-RAN) is a key architecture for 5G cellular wireless network that aims at improving spectral and energy efficiency of the network by uniting traditional RAN with cloud computing. In this paper, a novel resource allocation scheme that optimizes the network energy efficiency of a C-RAN is designed. First, an energy consumption model that characterizes the computation energy of the BaseBand Unit (BBU) is introduced based on empirical results collected from a programmable C-RAN testbed. Then, an optimization problem is formulated to maximize the energy efficiency of the network, subject to practical constraints including Quality of Service (QoS) requirement, radio remote head transmit power, and fronthaul capacity limits. The formulated Network Energy Efficiency Maximization (NEEM) problem jointly considers the tradeoff among the network accumulated data rate, BBU power consumption, fronthaul cost, and beamforming design. To deal with the non-convexity and mixed-integer nature of the problem, we utilize successive convex approximation methods to transform the original problem into the equivalent Weighted Sum-Rate (WSR) maximization problem. We then propose a provably-convergent iterative method to solve the resulting WSR problem. Extensive simulation results coupled with real-time experiments on a small-scale C-RAN testbed show the effectiveness of our proposed resource allocation scheme and its advantages over existing approaches.}
}


@article{DBLP:journals/tmc/PanL21,
	author = {Meng{-}Shiuan Pan and
                  Kuan{-}Ying Li},
	title = {ezNavi: An Easy-to-Operate Indoor Navigation System Based on Pedestrian
                  Dead Reckoning and Crowdsourced User Trajectories},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {2},
	pages = {488--501},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2946821},
	doi = {10.1109/TMC.2019.2946821},
	timestamp = {Tue, 26 Jan 2021 08:44:53 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/PanL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recently, researchers have paid attention to designing indoor navigation services for smartphone users. Conventional indoor navigation systems highly rely on well-known indoor information and prior training phase for localization, and thus it is time- and labor-consuming to bootstrap indoor navigation services. Without too much prior configurations, the proposed indoor navigation system, called ezNavi , utilizes trajectory information (reported by users) to generate indoor pathway and point of interests (POIs). The proposed system consists of a front-end mobile application (APP) and a back-end server. The mobile APP infers users’ walking trajectories according to sensory values from smartphones. The back-end server processes crowdsourced trajectories with the help of deployed Bluetooth low energy beacon devices, and then produces pathways of the indoor environment. After obtaining more trajectories, the ezNavi can further refine the derived pathways to provide more efficient guidance services for users. Our experiment and prototyping results reveal that the ezNavi can effectively derive users’ walking trajectories, produces indoor pathways, and indicates directions for users.}
}


@article{DBLP:journals/tmc/ZhangGHDH21,
	author = {Tianyu Zhang and
                  Tao Gong and
                  Song Han and
                  Qingxu Deng and
                  Xiaobo Sharon Hu},
	title = {Fully Distributed Packet Scheduling Framework for Handling Disturbances
                  in Lossy Real-Time Wireless Networks},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {2},
	pages = {502--518},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2950913},
	doi = {10.1109/TMC.2019.2950913},
	timestamp = {Wed, 27 Mar 2024 07:44:16 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/ZhangGHDH21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Along with the rapid growth of Industrial Internet-of-Things (IIoT) applications and their penetration into many industry sectors, real-time wireless networks (RTWNs) have been playing a more critical role in providing real-time, reliable, and secure communication services for such applications. A key challenge in RTWN management is how to ensure real-time Quality of Services (QoS) especially in the presence of unexpected disturbances and lossy wireless links. Most prior work takes centralized approaches for handling disturbances, which are slow and subject to single-point failure, and do not scale. To overcome these drawbacks, this article presents a fully distributed packet scheduling framework called FD-PaS . FD-PaS aims to provide guaranteed fast response to unexpected disturbances while achieving minimum performance degradation for meeting the timing and reliability requirements of all critical tasks. To combat the scalability challenge, FD-PaS incorporates several key advances in both algorithm design and data link layer protocol design to enable individual nodes to make on-line decisions locally without any centralized control. Our extensive simulation and testbed results have validated the correctness of the FD-PaS design and demonstrated its effectiveness in providing fast response for handling disturbances while ensuring the designated QoS requirements.}
}


@article{DBLP:journals/tmc/HuangZGL21,
	author = {Pei Huang and
                  Xiaonan Zhang and
                  Linke Guo and
                  Ming Li},
	title = {Incentivizing Crowdsensing-Based Noise Monitoring with Differentially-Private
                  Locations},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {2},
	pages = {519--532},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2946800},
	doi = {10.1109/TMC.2019.2946800},
	timestamp = {Thu, 01 Feb 2024 20:40:31 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/HuangZGL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Mobile crowd sensing is a technique where a crowd sensing server outsources sensing tasks to the crowd for mobile data collection. In mobile crowd sensing, some tasks require location information to achieve their objectives, such as road monitoring, indoor floor plan reconstruction, and smart transportation. This required information incurs severe concerns on location privacy leakage and threatens workers’ properties as well as public safety. In some cases, even sensing data itself can be used as auxiliary information resulting in location privacy breaches. Many existing works apply differential privacy mechanisms for location privacy preservation to tackle this problem, but they cannot efficiently fulfill privacy goals because each worker only considers his own privacy. As a consequence, the accumulated privacy budget will lower down the composed privacy level of all the workers’ locations. In addition, deploying differential privacy is costly for workers and it will degrade the quality of data required in crowd sensing tasks. How to balance the cost and provide accurate aggregated data while fulfilling privacy objectives becomes a challenging issue. In this paper, we propose a group-differentially-private game-theoretical solution, which addresses these limitations in a privacy-preserving and efficient way. Our scheme enables the indistinguishability of workers’ locations and sensing data without the help of a trusted entity while meeting the accuracy demands of crowd sensing tasks. The effectiveness and efficiency of our scheme are thoroughly evaluated based on real-world datasets.}
}


@article{DBLP:journals/tmc/Gonzalez-DiazGO21,
	author = {Sergio Gonzalez{-}Diaz and
                  Andres Garcia{-}Saavedra and
                  Antonio de la Oliva and
                  Xavier Costa{-}P{\'{e}}rez and
                  Robert Gazda and
                  Alain Mourad and
                  Thomas Dei{\ss} and
                  Josep Mangues{-}Bafalluy and
                  Paola Iovanna and
                  Stefano Stracca and
                  Phillip Leithead},
	title = {Integrating Fronthaul and Backhaul Networks: Transport Challenges
                  and Feasibility Results},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {2},
	pages = {533--549},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2948641},
	doi = {10.1109/TMC.2019.2948641},
	timestamp = {Tue, 26 Jan 2021 08:44:53 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/Gonzalez-DiazGO21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In addition to CPRI, new functional splits have been defined in 5G creating diverse fronthaul transport bandwidth and latency requirements. These fronthaul requirements shall be fulfilled simultaneously together with the backhaul requirements by an integrated fronthaul and backhaul transport solution. In this paper, we analyze the technical challenges to achieve an integrated transport solution in 5G and propose specific solutions to address these challenges. These solutions have been implemented and verified with pre-commercial equipment. Our results confirm that an integrated fronthaul and backhaul transport dubbed Crosshaul can meet all the requirements of 5G fronthaul and backhaul in a cost-efficient manner.}
}


@article{DBLP:journals/tmc/HokazonoKZSNM21,
	author = {Yuki Hokazono and
                  Aoi Koizuka and
                  Guibing Zhu and
                  Makoto Suzuki and
                  Yoshiaki Narusue and
                  Hiroyuki Morikawa},
	title = {IoTorch: Reliable LED-to-Camera Communication Against Inter-Frame
                  Gaps and Frame Drops},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {2},
	pages = {550--564},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2943148},
	doi = {10.1109/TMC.2019.2943148},
	timestamp = {Tue, 26 Jan 2021 08:44:53 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/HokazonoKZSNM21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {LED-to-camera communication for smartphones promises to enable low-cost, small-size, and intuitive data access to Internet-of-things (IoT) devices. However, for fast and reliable communication under the rolling shutter effect, the packet losses caused by inter-frame gaps and frame drops must be dealt with. In this paper, we introduce LED-to-camera communication between a commercial smartphone and an IoT device with LED flashlight, where the user can intuitively acquire the desired data transmitted from the IoT device to the smartphone. Specifically, we present IoTorch, a fast and reliable LED-to-camera communication that efficiently prevents the packet losses. IoTorch consists of two core mechanisms: 1) a minimum-repetition one-way reliable transmission focusing on the periodicity of inter-frame gaps and 2) an acknowledgement mechanism to overcome frame drops by using a smartphone's built-in flash focusing on its delay characteristics. Additionally, we propose an optimization method to increase the throughput up to 2.92 kbps (i.e., 2.43 times faster than that of the state-of-the-art method that overcomes the inter-frame gaps). Furthermore, we realize a remote wake-up function by using the smartphone's flash as the data transmission trigger. To demonstrate the benefit of IoTorch, we present a sensor data viewer using Arduino and a smartphone console system on TelosB.}
}


@article{DBLP:journals/tmc/EshratifarAP21,
	author = {Amir Erfan Eshratifar and
                  Mohammad Saeed Abrishami and
                  Massoud Pedram},
	title = {JointDNN: An Efficient Training and Inference Engine for Intelligent
                  Mobile Cloud Computing Services},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {2},
	pages = {565--576},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2947893},
	doi = {10.1109/TMC.2019.2947893},
	timestamp = {Tue, 26 Jan 2021 08:44:54 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/EshratifarAP21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Deep learning models are being deployed in many mobile intelligent applications. End-side services, such as intelligent personal assistants, autonomous cars, and smart home services often employ either simple local models on the mobile or complex remote models on the cloud. However, recent studies have shown that partitioning the DNN computations between the mobile and cloud can increase the latency and energy efficiencies. In this paper, we propose an efficient, adaptive, and practical engine, JointDNN, for collaborative computation between a mobile device and cloud for DNNs in both inference and training phase. JointDNN not only provides an energy and performance efficient method of querying DNNs for the mobile side but also benefits the cloud server by reducing the amount of its workload and communications compared to the cloud-only approach. Given the DNN architecture, we investigate the efficiency of processing some layers on the mobile device and some layers on the cloud server. We provide optimization formulations at layer granularity for forward- and backward-propagations in DNNs, which can adapt to mobile battery limitations and cloud server load constraints and quality of service. JointDNN achieves up to 18 and 32 times reductions on the latency and mobile energy consumption of querying DNNs compared to the status-quo approaches, respectively.}
}


@article{DBLP:journals/tmc/LiLJ21,
	author = {Bin Li and
                  Jia Liu and
                  Bo Ji},
	title = {Low-Overhead Wireless Uplink Scheduling for Large-Scale Internet-of-Things},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {2},
	pages = {577--587},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2949291},
	doi = {10.1109/TMC.2019.2949291},
	timestamp = {Tue, 25 Jan 2022 14:05:08 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/LiLJ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the rapid growth of Internet-of-Things (IoT) applications in recent years, there is a strong need for wireless uplink scheduling algorithms that determine when and which subset of a large number of users should transmit to the central controller. Different from the downlink case, the central controller in the uplink scenario typically has very limited information about the users. On the other hand, periodically collecting all such information from a large number of users typically incurs a prohibitively high communication overhead. This motivates us to investigate the development of an efficient and low-overhead uplink scheduling algorithm that is suitable for large-scale IoT applications. Specifically, we first characterize a capacity outer bound subject to the sampling constraint where only a small subset of users are allowed to use control channels for system state reporting at each time. Next, we relax the sampling constraint and propose a joint sampling and transmission algorithm, which utilizes full knowledge of channel state distributions and instantaneous queue lengths to achieve the capacity outer bound. The insights obtained from this capacity-achieving algorithm allow us to develop a low-overhead scheduling algorithm that can strictly satisfy the sampling constraint with asymptotically diminishing throughput loss.}
}


@article{DBLP:journals/tmc/ChenZWXXZLW21,
	author = {Zhe Chen and
                  Guorong Zhu and
                  Sulei Wang and
                  Yuedong Xu and
                  Jie Xiong and
                  Jin Zhao and
                  Jun Luo and
                  Xin Wang},
	title = {{\textdollar}M{\^{}}3{\textdollar}M3: Multipath Assisted Wi-Fi Localization
                  with a Single Access Point},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {2},
	pages = {588--602},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2950315},
	doi = {10.1109/TMC.2019.2950315},
	timestamp = {Wed, 26 Jul 2023 17:00:17 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/ChenZWXXZLW21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Owing to the ubiquitous penetration of Wi-Fi in our daily lives, Wi-Fi indoor localization has attracted intensive attentions in the last decade or so. Despite some significant progresses, the high accuracy of existing systems is still achieved at the cost of dense access point (AP) deployment. The more practical single AP localization is largely left as an open problem because the hardware-induced time delay “contaminates” the measurement of signal propagation time in the air. In this article, we design and implement M 3 to tackle this challenge with commodity Wi-Fi cards. M 3 exploits a multipath-assisted approach that turns the harmful multipath from foe to friend to enable single AP localization: a device can be pinpointed through the combination of azimuths and the relative time of flight (ToF) of Line-of-Sight (LoS) signal and reflection signals, eliminating the need for multiple APs along with their absolute ToF measurements. M 3 further utilizes frequency hopping to combine multiple channels to form a virtually wider-spectrum channel for higher ToF resolution. As a prominent feature of M 3 , the channels do not need to be adjacent. Comprehensive experiments demonstrate that M 3 outperforms the state-of-the-art systems and achieves a median localization accuracy of 71 cm in three environments with a single AP.}
}


@article{DBLP:journals/tmc/PratapMD21,
	author = {Ajay Pratap and
                  Rajiv Misra and
                  Sajal K. Das},
	title = {Maximizing Fairness for Resource Allocation in Heterogeneous 5G Networks},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {2},
	pages = {603--619},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2948877},
	doi = {10.1109/TMC.2019.2948877},
	timestamp = {Thu, 14 Oct 2021 09:27:12 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/PratapMD21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this article, we first formulate the joint resource allocation, interference minimization, user-level, and cell-level fairness for maximum resource reuse in 5G heterogeneous small cell networks as an NP-hard problem. We then propose three algorithms - centralized, distributed, and randomized distributed algorithms - to efficiently solve the formulated resource allocation problem while minimizing interference, maximizing fairness, and resource reuse. Through extensive real data analysis and network simulations, we show that our proposed solutions outperform state-of-the-art schemes, namely interfering model (INT) and distributed random access (DRA), for both low and high-density 5G networks.}
}


@article{DBLP:journals/tmc/XuLTCH21,
	author = {Fengli Xu and
                  Yong Li and
                  Zhen Tu and
                  Shuhao Chang and
                  Hongjia Huang},
	title = {No More than What {I} Post: Preventing Linkage Attacks on Check-in
                  Services},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {2},
	pages = {620--633},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2947416},
	doi = {10.1109/TMC.2019.2947416},
	timestamp = {Tue, 26 Jan 2021 08:44:53 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/XuLTCH21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the flourishing of location based social networks, posting check-ins has become a common practice to document one's daily life. Users usually do not consider check-in records as violations of their privacy. However, through analyzing two real-world check-in datasets, our study shows that check-in records are vulnerable to linkage attacks. Specifically, adversary is able to uniquely re-identify over 52~66 percent users in other anonymous mobility datasets and 60~80 percent users have more than 60 percent probability leaking unreported mobility records. In addition, we further demonstrate that the privacy sensitivity of check-in records can be more accurately measured by including the information of additional mobility data compared with only looking at check-ins. Based on this observation, we design a partition-and-group framework to integrate the information of check-ins and additional mobility data to attain a novel privacy criterion-k τ,l -anonymity. It ensures adversaries with arbitrary background knowledge cannot use check-ins to re-identify users in other anonymous datasets or learning unreported mobility records. The proposed framework achieves favorable performance against state-of-art baseline in terms of improving check-in utility by 24~57 percent while providing stronger privacy guarantee at the same time. We believe this study will open a new angle in attaining both privacy-preserving and useful check-in services.services.}
}


@article{DBLP:journals/tmc/JiangHZL21,
	author = {Chengkun Jiang and
                  Yuan He and
                  Xiaolong Zheng and
                  Yunhao Liu},
	title = {OmniTrack: Orientation-Aware {RFID} Tracking With Centimeter-Level
                  Accuracy},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {2},
	pages = {634--646},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2949412},
	doi = {10.1109/TMC.2019.2949412},
	timestamp = {Tue, 20 Dec 2022 21:20:07 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/JiangHZL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {RFID tracking attracts a lot of research efforts in recent years. Most of the existing approaches, however, adopt an orientation-oblivious model. When tracking a target whose orientation changes, those approaches suffer from serious accuracy degradation. In order to achieve target tracking with pervasive applicability in various scenarios, in this article, we propose OmniTrack, an orientation-aware RFID tracking approach. Our study presents a generic model that discribes the linear relationship between the tag orientation and the phase change of the backscattered signals. Based on this finding, we propose an orientation-aware phase model to explicitly quantify the respective impact of the read-tag distance and the tag's orientation. OmniTrack addresses practical challenges in tracking the location and orientation of a mobile tag. Our experimental results demonstrate that OmniTrack achieves centimeter-level location accuracy and has significant advantages in tracking targets with varing orientations, compared to the state-of-the-art approaches.}
}


@article{DBLP:journals/tmc/ZhaoYM21,
	author = {Cong Zhao and
                  Shusen Yang and
                  Julie A. McCann},
	title = {On the Data Quality in Privacy-Preserving Mobile Crowdsensing Systems
                  with Untruthful Reporting},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {2},
	pages = {647--661},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2943468},
	doi = {10.1109/TMC.2019.2943468},
	timestamp = {Fri, 15 Jul 2022 08:17:58 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/ZhaoYM21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The proliferation of mobile smart devices with ever improving sensing capacities means that human-centric Mobile Crowdsensing Systems (MCSs) can economically provide a large scale and flexible sensing solution. The use of personal mobile devices is a sensitive issue, therefore it is mandatory for practical MCSs to preserve private information (the user's true identity, precise location, etc.) while collecting the required sensing data. However, well intentioned privacy protection techniques also conceal autonomous, or even malicious, behaviors of device owners (termed as self-interested), where the objectivity and accuracy of crowdsensing data can therefore be severely threatened. The issue of data quality due to untruthful reporting in privacy-preserving MCSs has been yet to produce solutions. Bringing together game theory, algorithmic mechanism design, and truth discovery, we develop a mechanism to guarantee and enhance the quality of crowdsensing data without jeopardizing the privacy of MCS participants. Together with solid theoretical justifications, we evaluate the performance of our proposal with extensive real-world MCS trace-driven simulations. Experimental results demonstrate the effectiveness of our mechanism on both enhancing the quality of the crowdsensing data and eliminating the motivation of MCS participants, even when their privacy is well protected, to report untruthfully.}
}


@article{DBLP:journals/tmc/QianWJS21,
	author = {Li Ping Qian and
                  Yuan Wu and
                  Bo Ji and
                  Xuemin Sherman Shen},
	title = {Optimal ADMM-Based Spectrum and Power Allocation for Heterogeneous
                  Small-Cell Networks with Hybrid Energy Supplies},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {2},
	pages = {662--677},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2948014},
	doi = {10.1109/TMC.2019.2948014},
	timestamp = {Tue, 25 Jan 2022 14:05:08 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/QianWJS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Powering cellular networks with hybrid energy supplies is not only environment-friendly but can also reduce the on-grid energy consumption, thus being emerging as a promising solution for green networking. Intelligent management of spectrum and power can increase the network utility in cellular networks with hybrid energy supplies, usually at the cost of higher energy consumption. Unlike prior studies on either the network utility maximization or on-grid energy cost minimization, this paper studies the joint spectrum and power allocation problem that maximizes the system revenue in a heterogeneous small-cell network with hybrid energy supplies. Specifically, the system revenue is considered as the difference between the network utility and on-grid energy cost. By developing the convexity of the optimization problem through transformation and reparameterization, we propose a joint spectrum and power allocation algorithm based on the primal-dual arguments to obtain the optimal solution by iteratively solving the primal and dual sub-problems of the convex optimization problem. To solve the primal sub-problem, we further propose the Lagrangian maximization based on the alternating direction method of multipliers (ADMM), and derive the optimal solution in the closed-form expression at each iteration. It is shown that the proposed joint spectrum and power allocation algorithm approaches the global optimality at the rate of 1=n with n being the number of iterations. Also, the proposed ADMM-based Lagrangian maximization algorithm approaches the primal optimal solution with the time complexity of O(1=ε r ) iterations with ε r being the termination parameter. Simulation results show that in comparison with the power control with equal frequency allocation algorithm and frequency allocation with equal power allocation algorithms the proposed algorithm increases the system revenue by over 20 and 60 percent without consuming more on-grid energy when the proportional fairness utility and the weighted sum rate utility are considered with the approximate system parameter settings, respectively. Meanwhile, in comparison with the full frequency reuse case, the proposed algorithm increases the system revenue by 20 percent at least in terms of the weighted sum rate utility, although it achieves the similar system revenue when considering the proportional fairness utility. Simulation results also show that our proposed algorithm can perform well under the realistic fast fading channel conditions.}
}


@article{DBLP:journals/tmc/ZhangLM21,
	author = {Linbo Zhang and
                  Tong Liu and
                  Mehul Motani},
	title = {Optimal Multicasting Strategies in Underwater Acoustic Networks},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {2},
	pages = {678--690},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2944158},
	doi = {10.1109/TMC.2019.2944158},
	timestamp = {Tue, 26 Jan 2021 08:44:53 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/ZhangLM21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recent advances in underwater networking exploit the large propagation delays in underwater channels to schedule transmissions which increase the performance of underwater acoustic sensor networks (UASNs). The underwater channel is broadcast in nature so it supports broadcast and multicast transmissions. In this paper, we discuss novel scheduling strategies, based on TDMA (Time Division Multiple Access), for UASNs where packets may be bound for multiple destinations. The main contributions are to establish an upper bound on the throughput of multicast networks, in which each packet has the same number of intended destinations, by exploiting large propagation delays, and explore network topologies that can achieve this bound. As an example, we study the throughput of unicast and multicast ring networks, including the properties of optimal, valid, perfect and fair transmission schedules. Further, several algorithms to find fair and optimal schedules for unicast and multicast ring networks are presented. Finally, we perform extensive simulations for uniform ring networks, as well as more general ring networks, in both noiseless and noisy underwater channels. Simulation results verify that the proposed algorithms can effectively determine the optimal schedules for ring networks, which achieve the maximum possible throughput and asymptotically approach the upper bound on the throughput of multicasting UASNs.}
}


@article{DBLP:journals/tmc/XuLXLH21,
	author = {Dianlei Xu and
                  Yong Li and
                  Tong Xia and
                  Jianbo Li and
                  Pan Hui},
	title = {Portfolio Optimization in Traffic Offloading: Concept, Model, and
                  Algorithms},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {2},
	pages = {691--706},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2946811},
	doi = {10.1109/TMC.2019.2946811},
	timestamp = {Tue, 26 Jan 2021 08:44:53 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/XuLXLH21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Due to explosive growth of mobile data over the overburdened cellular network, opportunistic offloading is proposed to transmit the traffic originally transmitted through infrastructure network to delay-tolerant device-to-device networks at the edge of mobile networks. Existing offloading schemes mainly focus on selecting a subset of mobile nodes to work as offloadees, who first download the contents through the infrastructure, and then transmit them to subscriber nodes. However, when there is large amount of contents to be offloaded, and if all contents are disseminated through only one fixed set of offloadees every time, it may result in the risk of extreme cases that only extremely few nodes received the content, even if the expectation is large. This is like putting all of your eggs in one basket. To deal with this problem, we introduce an economic concept, conditional value at risk (CVaR) to measure the risk in offloadee set selection. CVaR is a widely used risk assessment measure for investments, which provides a unified and comprehensive risk evaluation framework for complex investment portfolio. We propose an algorithm to compute a portfolio over multiple offloadee sets with a guarantee on CVaR. Moreover, we prove the feasibility of our methodology from the mathematical point of view. Extensive evaluations with real-world traces show that our proposed offloading scheme can obtain a portfolio with significantly better CVaR, i.e., 91.53 percent performance gain at most, compared with the state-of-the-art solutions.}
}


@article{DBLP:journals/tmc/SanguanpuakNRL21,
	author = {Tachporn Sanguanpuak and
                  Dusit Niyato and
                  Nandana Rajatheva and
                  Matti Latva{-}aho},
	title = {Radio Resource Sharing and Edge Caching with Latency Constraint for
                  Local 5G Operator: Geometric Programming Meets Stackelberg Game},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {2},
	pages = {707--721},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2948630},
	doi = {10.1109/TMC.2019.2948630},
	timestamp = {Tue, 26 Jan 2021 08:44:53 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/SanguanpuakNRL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The rapidly increasing demand in indoor small cell networks has given rise to the concept of local 5G operator (OP) for local service delivery. In this regard, we develop a novel game-theoretic framework with geometric programming to model and analyze cache-enabled small cell base stations (SBSs) with infrastructure sharing for local 5G OP networks. In such a network, the local 5G OP provides wireless network in indoor area and rent out the infrastructure which are RAN and cache storage to multiple mobile network operators (MNOs) while guarantee the quality-of-experience (QoE) at the users (UEs) of MNOs. We formulate a Stackelberg game model where the local 5G OP is the leader and the MNOs are the followers. The local 5G OP aims to maximize its profit by optimizing its infrastructure rental fee, and the MNOs aim to minimize their renting cost of infrastructure by minimizing the cache intensity subject to latency constraint at each UE. Here, the cache intensity is defined as the product of the number of SBSs per unit area and the number of popular files stored in each SBS. The optimization problems of the local 5G OP and the MNOs are transformed into geometric programming. Accordingly, the subgame perfect equilibrium of Stackelberg game is obtained through the succesive geometric programming (SGP) method. Since the MNOs share their rented infrastructure, for cost sharing, we apply the concept of Shapley value to divide the cost among the MNOs. We show that the cost sharing problem can be mapped into a simplified “airport runway cost sharing problem”, in which the Shapley value can be computed efficiently. Finally, we present an extensive performance evaluation that reveals interesting insights into designing resource sharing with edge caching in local 5G OP networks.}
}


@article{DBLP:journals/tmc/BuXGLHCYL21,
	author = {Yanling Bu and
                  Lei Xie and
                  Yinyin Gong and
                  Jia Liu and
                  Bingbing He and
                  Jiannong Cao and
                  Baoliu Ye and
                  Sanglu Lu},
	title = {RF-3DScan: RFID-based 3D Reconstruction on Tagged Packages},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {2},
	pages = {722--738},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2943853},
	doi = {10.1109/TMC.2019.2943853},
	timestamp = {Mon, 28 Aug 2023 21:39:16 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/BuXGLHCYL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Currently, the logistic industry has introduced 3D reconstruction to monitor the package placement in the warehouse. Previous 3D reconstruction solutions mainly utilize computer vision or sensor-based methods, which are restricted to the line-of-sight or the battery life. Therefore, we propose a passive RFID-based solution, called RF-3DScan, to perform 3D reconstruction on tagged packages, including the package orientation and the package stacking. The basic idea is that a moving antenna can obtain RF-signals from the tags attached on packages with the 1D linear mobile scanning. Through extracting phase differences to build angle profiles for each tag, RF-3DScan derives their relative positions, further determines the package orientation and the coarse-grained package stacking. By simply performing the 2D scanning, RF-3DScan can provide the fine-grained package stacking determination. We implement a prototype system of RF-3DScan and evaluate its performance in real settings. Our experiment results show that RF-3DScan can achieve about 92.5 percent identification accuracy of the bottom face, and an average error about 4.08° of thethe rotation angle. For the package stacking, 1D scanning can achieve the comparable performance in comparison with 2D scanning.}
}


@article{DBLP:journals/tmc/WangXCJBF21,
	author = {Ju Wang and
                  Jie Xiong and
                  Xiaojiang Chen and
                  Hongbo Jiang and
                  Rajesh Krishna Balan and
                  Dingyi Fang},
	title = {Simultaneous Material Identification and Target Imaging with Commodity
                  {RFID} Devices},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {2},
	pages = {739--753},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2946072},
	doi = {10.1109/TMC.2019.2946072},
	timestamp = {Tue, 26 Jan 2021 08:44:53 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/WangXCJBF21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Material identification and target imaging play an important role in many applications. This paper introduces TagScan, a system that can identify the material type and image the horizontal cut of a target simultaneously with cheap commodity Radio-Frequency IDentification (RFID) devices. The key intuition is that different materials and/or target sizes cause different amounts of phase and RSS (Received Signal Strength) changes, when radio frequency (RF) signal penetrates through the target. Multiple challenges need to be addressed before we can turn the idea into a functional system, including (i) indoor environments exhibit rich multipath which breaks the linear relationship between the phase change and the propagation distance inside a target; (ii) without knowing either material type or target size, trying to obtain these two information simultaneously is challenging; and (iii) stitching pieces of the propagation distances inside a target for an image estimate is non-trivial. We propose solutions to all the challenges and evaluate the system's performance in three different environments. TagScan is able to achieve higher than 94 percent material identification accuracies for 10 liquids and differentiates even very similar objects such as Coke and Pepsi. TagScan can accurately estimate the horizontal cut images of more than one target behind a wall.}
}


@article{DBLP:journals/tmc/LiuWZCWWXL21,
	author = {Yunhao Liu and
                  Jiliang Wang and
                  Yunting Zhang and
                  Linsong Cheng and
                  Weiyi Wang and
                  Zhao Wang and
                  Weimin Xu and
                  Zhenjiang Li},
	title = {Vernier: Accurate and Fast Acoustic Motion Tracking Using Mobile Devices},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {2},
	pages = {754--764},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2945955},
	doi = {10.1109/TMC.2019.2945955},
	timestamp = {Tue, 20 Dec 2022 21:20:07 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/LiuWZCWWXL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Acoustic motion tracking has been viewed as a promising user interaction technique in many scenarios such as Virtual Reality (VR), Smart Appliance, video gaming, etc. Existing acoustic motion tracking approaches, however, suffer from long window of accumulated signal and time-consuming signal processing. They are inherently difficult to achieve both high accuracy and low delay. In this paper, we present Vernier, an efficient and accurate acoustic tracking method based on commodity mobile devices. We design a new approach to efficiently and accurately derive phase change and thus moving distance. Vernier significantly reduces the tracking delay/overhead by removing the complicated frequency analysis and long window of signal accumulation, while keeping a high tracking accuracy. We implement Vernier on Android, and evaluate its performance with COTS mobile devices including Samsung Galaxy S7 and Sony L50t. Experimental results show that Vernier outperforms previous approaches with a tracking error less than 4 mm. The tracking speed achieves 3× improvement to the previous phase based approaches and 10× to Doppler Effect based approaches. Vernier is also validated in applications like controlling and drawing, and we believe it is generally applicable in many real applications.}
}


@article{DBLP:journals/tmc/ChenLMGDL21,
	author = {Mozi Chen and
                  Kezhong Liu and
                  Jie Ma and
                  Yu Gu and
                  Zheng Dong and
                  Cong Liu},
	title = {{SWIM:} Speed-Aware WiFi-Based Passive Indoor Localization for Mobile
                  Ship Environment},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {2},
	pages = {765--779},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2947667},
	doi = {10.1109/TMC.2019.2947667},
	timestamp = {Tue, 14 Jun 2022 09:15:03 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/ChenLMGDL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Accurate and pervasive device-free indoor localization with meter-level resolution is critical for large cruise and passenger ships due to safety-critical rescue and evacuation requirements when accidents occur. However, existing localization techniques would severely suffer on ships because of their unique mobility characteristics. In this paper, we take the first attempt to build a ubiquitous passive localization system using WiFi fingerprints for the mobile ship environment. By conducting extensive experiments and measurements during several cruise trips, we identified a major influence factor on the fingerprints in the mobile environment: varying the ship speeds may significantly change the patterns of fingerprints at runtime. Since it may be too expensive to identify the fingerprints associated with different speeds, we propose an efficient localization method, namely SWIM, which calibrates the fingerprints from only a single-speed scenario to multiple-speed scenarios using a signal reconstruction analysis. SWIM is designed to learn the predictive fingerprint variation introduced by environmental speed changes and reconstruct the original fingerprints to adapt to the runtime speed scenarios. We have implemented and extensively evaluated SWIM on actual cruise ships. Experimental results demonstrate that SWIM improves localization accuracy from 63.2 to 82.9 percent, while reducing the overall system deployment cost by 87 percent.}
}


@article{DBLP:journals/tmc/KaltiokallioHP21,
	author = {Ossi Kaltiokallio and
                  Roland Hostettler and
                  Neal Patwari},
	title = {A Novel Bayesian Filter for RSS-Based Device-Free Localization and
                  Tracking},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {3},
	pages = {780--795},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2953474},
	doi = {10.1109/TMC.2019.2953474},
	timestamp = {Thu, 27 Jul 2023 08:18:51 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/KaltiokallioHP21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Received signal strength based device-free localization applications utilize a model that relates the measurements to position of the wireless sensors and person, and the underlying inverse problem is solved either using an imaging method or a nonlinear Bayesian filter. In this paper, it is shown that the Bayesian filters nearly reach the posterior Cramer-Rao bound and they are superior with respect to imaging approaches in terms of localization accuracy because the measurements are directly related to position of the person. However, Bayesian filters are known to suffer from divergence issues and in this paper, the problem is addressed by introducing a novel Bayesian filter. The developed filter augments the measurement model of a Bayesian filter with position estimates from an imaging approach. This bounds the filter's measurement residuals by the position errors of the imaging approach and as an outcome, the developed filter has robustness of an imaging method and tracking accuracy of a Bayesian filter. The filter is demonstrated to achieve a localization error of 0.11 m in a 75 m 2 open indoor deployment and an error of 0.29 m in a 82 m 2 apartment experiment, decreasing the localization error by 30-48 percent with respect to a state-of-the-art imaging method.}
}


@article{DBLP:journals/tmc/WangLGWTJ21,
	author = {Huandong Wang and
                  Yong Li and
                  Chen Gao and
                  Gang Wang and
                  Xiaoming Tao and
                  Depeng Jin},
	title = {Anonymization and De-Anonymization of Mobility Trajectories: Dissecting
                  the Gaps Between Theory and Practice},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {3},
	pages = {796--815},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2952774},
	doi = {10.1109/TMC.2019.2952774},
	timestamp = {Thu, 04 Mar 2021 15:40:35 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/WangLGWTJ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Human mobility trajectories are increasingly collected by ISPs to assist academic research and commercial applications. Meanwhile, there is a growing concern that individual trajectories can be de-anonymized when the data is shared, using information from external sources (e.g., online social networks). To understand this risk, prior works either estimate the theoretical privacy bound or simulate de-anonymization attacks on synthetically created datasets. However, it is not clear how well the theoretical estimations are preserved in practice. In this article, we collected a large-scale ground-truth trajectory dataset from 2,161,500 users of a cellular network, and two matched external trajectory datasets from a large social network (56,683 users) and a check-in/review service (45,790 users) on the same user population. The two sets of large ground-truth data provide a rare opportunity to extensively evaluate a variety of de-anonymization algorithms (nine in total). We find that their performance in the real-world dataset is far from the theoretical bound. Further analysis shows that most algorithms have under-estimated the impact of spatio-temporal mismatches between the data from different sources, and the high sparsity of user generated data also contributes to the under-performance. Based on these insights, we propose four new algorithms that are specially designed to tolerate spatial or temporal mismatches (or both) and model location contexts and time contexts. Extensive evaluations show that our algorithms achieve more than 17 percent performance gain over the best existing algorithms, confirming our insights. Further, we propose two new location-privacy preserving mechanisms utilizing the spatio-temporal mismatches to better protect users’ privacy against the de-anonymization attack. Evaluation results show that our proposed mechanisms can reduce the performance of de-anonymization attacks by over 8.0 percent, demonstrating the effectiveness of our insights.}
}


@article{DBLP:journals/tmc/WangFZ21,
	author = {Lei Wang and
                  Li Feng and
                  Maciej J. Zawodniok},
	title = {{ARPAP:} {A} Novel Antenna-Radiation-Pattern-Aware Power-Based Positioning
                  in {RF} System},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {3},
	pages = {816--829},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2959983},
	doi = {10.1109/TMC.2019.2959983},
	timestamp = {Tue, 02 Mar 2021 11:25:36 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/WangFZ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Traditional power-based localization methods suffer from low accuracy in the practical application environment. The main challenges are the antenna directivity and fading effect. Conventional methods assume omnidirectional antenna directivity such that the solution is the intersections of multiple circle-shape contours. This strong assumption results in significant localization error in practical non-isotropic antenna applications. In this article, a novel antenna radiation-pattern-aware power-based positioning (ARPAP) scheme is proposed. It reduces the antenna directivity effect by including the antenna pattern into the localization system model. It reduces the bias error that introduced by power measurement through estimating the line-of-sight (LoS) component in received signal strength (RSS). Moreover, the error mode for the proposed ARPAP system, along with the theoretical limit, Cramer-Rao Bound (CRB), and bias of the proposed positioning system are derived. The Pearson correlation coefficient between the proposed error model and simulation result shows a high similarity score. The proposed positioning scheme and analytic error model are instantiated for the cellular network. Both analytical model and simulation results demonstrate the superiority of the proposed method over traditional methods.}
}


@article{DBLP:journals/tmc/PanL21a,
	author = {Haoyuan Pan and
                  Soung Chang Liew},
	title = {Backbone-Assisted Wireless Local Area Network},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {3},
	pages = {830--845},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2953895},
	doi = {10.1109/TMC.2019.2953895},
	timestamp = {Tue, 02 Mar 2021 11:25:36 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/PanL21a.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This article presents a cross-layer design of backbone-assisted wireless local area network (WLAN) for dense WLAN deployment. The popularity of 802.11-based WLANs leads to dense WLAN deployment in geographically limited space, including dense access points (AP) and dense users. With dense APs, an AP could overhear packets destined for other APs. Backbone-assisted WLAN is a new system architecture where cooperative APs share the overheard packets through a backbone network, thereby reducing packet retransmission and improving system throughput. Conventional WLAN, such as Wi-Fi, uses Stop-and-Wait ARQ. This article argues that Stop-and-Wait does not work well with backbone-assisted WLAN because of large backbone delays. We first show that with a variant of Selective Repeat ARQ tailored for backbone-assisted WLAN, a single-user backbone-assisted WLAN system can achieve substantial throughput improvement over that with Stop-and-Wait ARQ. Then, we put forth a new system architecture targeted for dense users, referred to as network-coded backbone-assisted WLAN, in which multiple users are allowed to transmit simultaneously. A distinguishing feature of this system is the joint use of physical-layer network-coding (PNC) decoding and multiuser decoding (MUD) in multipacket reception. This article is the first attempt to design an ARQ for multiuser backbone-assisted WLAN. Our overall system design solves a PNC sequence obfuscation problem and addresses long packet latency in Selective Repeat ARQ. Experiments on our software-defined radio prototype indicate that network-coded Ethernet-backbone-assisted WLAN can achieve high system throughput and low packet latency. Specifically, the system throughput can outperform an MUD-only multiuser WLAN and a single-user WLAN by 60 and 100 percent, respectively. Overall, we believe that network-coded backbone-assisted WLAN is a viable solution for boosting throughput and reducing latency in dense WLAN environments.}
}


@article{DBLP:journals/tmc/ShaoRL21,
	author = {Chenglong Shao and
                  Heejun Roh and
                  Wonjun Lee},
	title = {BuSAR: Bluetooth Slot Availability Randomization for Better Coexistence
                  With Dense Wi-Fi Networks},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {3},
	pages = {846--860},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2955080},
	doi = {10.1109/TMC.2019.2955080},
	timestamp = {Mon, 21 Mar 2022 12:11:40 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/ShaoRL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The last decade has witnessed the ever-increasing deployment of Wi-Fi networks and the explosion of Bluetooth-based applications. As a result, the coexistence of Bluetooth piconets with highly-dense Wi-Fi networks is a common phenomenon currently. Unlike Wi-Fi that conducts carrier sensing before channel access, Bluetooth adopts frequency hopping based on a predefined hop sequence, which inevitably incurs considerable cross-technology interference to Wi-Fi. While the Adaptive Frequency Hopping technique is standardized for interference reduction, it does not perform well in current practice where densely-deployed Wi-Fi networks commonly cover the whole 2.4 GHz unlicensed spectrum. In this context, this article presents BuSAR, a novel approach to account for the coexistence problem between Bluetooth piconets and dense Wi-Fi networks. BuSAR embodies the first work to aim at mitigating the cross-technology interference between Bluetooth and highly-dense Wi-Fi networks in a distributed manner. At the heart of BuSAR lies a subtle technique called Bluetooth slot availability randomization, which exploits the redundancy of erroneous Bluetooth packets for better Bluetooth/Wi-Fi coexistence. With BuSAR adopted, multiple Bluetooth piconets are guaranteed to operate independently and only a lightweight algorithm is needed to be implemented at each Bluetooth device. Both theoretical analysis and experimental results validate the feasibility and superiority of BuSAR.}
}


@article{DBLP:journals/tmc/ZhangZWYHPLY21,
	author = {Kai Zhang and
                  Yi Zhao and
                  Chenshu Wu and
                  Chaofan Yang and
                  Kehong Huang and
                  Chunyi Peng and
                  Yunhao Liu and
                  Zheng Yang},
	title = {ChromaCode: {A} Fully Imperceptible Screen-Camera Communication System},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {3},
	pages = {861--876},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2956493},
	doi = {10.1109/TMC.2019.2956493},
	timestamp = {Tue, 20 Dec 2022 21:20:07 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/ZhangZWYHPLY21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Hidden screen-camera communication techniques emerge as a new paradigm that embeds data imperceptibly into regular videos while remaining unobtrusive to human viewers. Three key goals on imperceptible, high rate, and reliable communication are desirable but conflicting, and existing solutions usually made a trade-off among them. In this paper, we present the design and implementation of CHROMACODE, a screen-camera communication system that achieves all three goals simultaneously. In our design, we consider for the first time color space for perceptually uniform lightness modifications. On this basis, we design an outcome-based adaptive embedding scheme, which adapts to both pixel lightness and regional texture. Last, we propose a concatenated code scheme for robust coding and devise multiple techniques to overcome various screen-camera channel errors. Our prototype and experiments demonstrate that CHROMACODE achieves remarkable raw throughputs of >700 kbps, data goodputs of 120 kbps with BER of 0.05, and with fully imperceptible flicker for viewing proved by user study, which significantly outperforms previous works.}
}


@article{DBLP:journals/tmc/ZhouCYWWC21,
	author = {Yipeng Zhou and
                  Jiawen Chen and
                  Guoqiao Ye and
                  Di Wu and
                  Jessie Hui Wang and
                  Min Chen},
	title = {Collaboratively Replicating Encoded Content on RSUs to Enhance Video
                  Services for Vehicles},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {3},
	pages = {877--892},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2960022},
	doi = {10.1109/TMC.2019.2960022},
	timestamp = {Tue, 02 Mar 2021 11:25:35 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/ZhouCYWWC21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the development of smart cities, Internet services will be pervasively accessible for moving vehicles. It is envisioned that the video content demand of vehicles will explode in the near future. However, the strategy to efficiently distribute video content in large-scale vehicular networks is still absent due to challenges arising from the huge video population, heavy bandwidth consumption, heterogeneous user devices, and vehicles’ mobility. In this work, we propose to collaboratively replicate video content on Roadside Units (RSUs) to enhance video distribution services based on the fact that the contact period between moving vehicles and a single RSU is not long enough to complete video downloading. In our design, a video file is split into multiple chunks. Each RSU replicates a small number of original chunks and chunks encoded by network coding. Replicating encoded chunks can reduce redundancy of chunks on different RSUs so that RSUs can complement each other better, whereas original chunks can be transrated to chunks with lower bitrates flexibly to fit in users’ devices. Therefore, we replicate both original and encoded chunks on RSUs to take advantages of both sides. Stochastic models are employed to analyze chunk download processes and a convex optimization problem is formulated to determine the optimal partition of space allocated to each kind of chunks. Furthermore, we extend our strategy to support video streaming services and empirically prove that the influence caused by limitations of network coding is moderate. In the end, we conduct extensive simulations which not only validate the accuracy of our models but also demonstrate that our strategy can effectively boost video distribution services.}
}


@article{DBLP:journals/tmc/WangXYXWH21,
	author = {Zhong{-}qin Wang and
                  Min Xu and
                  Ning Ye and
                  Fu Xiao and
                  Ruchuan Wang and
                  Haiping Huang},
	title = {Computer Vision-Assisted 3D Object Localization via {COTS} {RFID}
                  Devices and a Monocular Camera},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {3},
	pages = {893--908},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2954830},
	doi = {10.1109/TMC.2019.2954830},
	timestamp = {Mon, 12 Apr 2021 17:09:00 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/WangXYXWH21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In most RFID localization systems, acquiring a reader antenna's position at each sampling time is challenging, especially for those antenna-carrying robot or drone systems with unpredictable trajectories. In this article, we present RF-MVO that fuses RFID and computer vision for stationary RFID localization in 3D space by attaching a light-weight 2D monocular camera to two reader antennas in parallel. First, the existing monocular visual odometry only recovers a camera/antenna trajectory in the camera view from 2D images. By combining it with RF phase, we design a model to estimate a scale factor for real-world trajectory transformation, along with spatial directions of an RFID tag relative to a virtual antenna array due to the mobility of each antenna. Then we propose a novel RFID localization algorithm that does not require exhaustively searching all possible positions within the pre-specified region. Second, to speed up the searching process and improve localization accuracy, we propose a coarse-to-fine optimization algorithm. Third, we introduce the concept of horizontal dilution of precision (HDOP) to measure the confidence level of localization results. Our experiments demonstrate the effectiveness of proposed algorithms and show RF-MVO can achieve 6.23 cm localization error.}
}


@article{DBLP:journals/tmc/YuDCLTH21,
	author = {Nan Yu and
                  Haipeng Dai and
                  Guihai Chen and
                  Alex X. Liu and
                  Bingchuan Tian and
                  Tian He},
	title = {Connectivity-Constrained Placement of Wireless Chargers},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {3},
	pages = {909--927},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2954306},
	doi = {10.1109/TMC.2019.2954306},
	timestamp = {Tue, 02 Mar 2021 11:25:36 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/YuDCLTH21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this article, we first study the problem of Connected wIReless Charger pLacEment (CIRCLE). That is, given a fixed number of directional wireless chargers and candidate positions, determining the placement position and orientation angle for each charger under connectivity constraint for wireless chargers such that the overall charging utility is maximized. To address CIRCLE problem, we first consider a relaxed version of CIRCLE (CIRCLE-R for short). We prove that CIRCLE-R falls into the realm of maximizing a submodular set function subject to a connectivity constraint, and propose an algorithm whose approximation ratio is at least 1.5 times better than that of the state-of-the-art algorithm. Next, we reduce the solution space for CIRCLE from infinite to finite, and propose an algorithm with a constant approximation ratio to address CIRCLE. Besides, we consider a variant of CIRCLE, CIRCLE-NB, and propose an approximation algorithm to address it. We conduct both simulation experiments and field experiments to verify our theoretical findings. The results show that our algorithm can outperform comparison algorithms by 83.35 percent.}
}


@article{DBLP:journals/tmc/HuWCZL21,
	author = {Qin Hu and
                  Shengling Wang and
                  Xiuzhen Cheng and
                  Junshan Zhang and
                  Weifeng Lv},
	title = {Cost-Efficient Mobile Crowdsensing With Spatial-Temporal Awareness},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {3},
	pages = {928--938},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2953911},
	doi = {10.1109/TMC.2019.2953911},
	timestamp = {Thu, 10 Mar 2022 09:31:32 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/HuWCZL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A cost-efficient deal that can achieve high sensing quality with a low reward is the permanent goal of the requestor in mobile crowdsensing, which heavily depends on the quantity and quality of the workers. However, the spatial diversity and temporal dynamics lead to heterogeneous worker supplies, making it hard for the requestor to utilize a homogeneous pricing strategy to realize a cost-efficient deal from a systematic point of view. Therefore, a cost-efficient deal calls for a cost-efficient pricing strategy, boosting the whole sensing quality with less operation (computation) cost. However, the state-of-the-art studies ignore the dual cost-efficient demands of large-scale sensing tasks. Hence, we propose a combinatorial pinning zero-determinant (ZD) strategy, which empowers the requestor to utilize a single strategy within its feasible range to minimize the total expected utilities of the workers throughout all sensing regions for each time interval, without being affected by the strategies of the workers. Through turning the worker-customized strategy to an interval-customized one, the proposed combinatorial pinning ZD strategy reduces the number of pricing strategies required by the requestor from O(n 3 ) to O(n). Besides, it extends the application scenarios of the classical ZD strategy from two-player simultaneous-move games to multiple-heterogeneous-player sequential-move ones, where a leader can determine the linear relationship of the players' expected utilities. Such an extension enriches the theoretical hierarchy of ZD strategies, broadening their application scope. Extensive simulations based on real-world data verify the effectiveness and efficiency of the proposed scheme.}
}


@article{DBLP:journals/tmc/WangGZYZS21,
	author = {Shangguang Wang and
                  Yan Guo and
                  Ning Zhang and
                  Peng Yang and
                  Ao Zhou and
                  Xuemin Shen},
	title = {Delay-Aware Microservice Coordination in Mobile Edge Computing: {A}
                  Reinforcement Learning Approach},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {3},
	pages = {939--951},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2957804},
	doi = {10.1109/TMC.2019.2957804},
	timestamp = {Tue, 21 Mar 2023 21:12:56 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/WangGZYZS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As an emerging service architecture, microservice enables decomposition of a monolithic web service into a set of independent lightweight services which can be executed independently. With mobile edge computing, microservices can be further deployed in edge clouds dynamically, launched quickly, and migrated across edge clouds easily, providing better services for users in proximity. However, the user mobility can result in frequent switch of nearby edge clouds, which increases the service delay when users move away from their serving edge clouds. To address this issue, this article investigates microservice coordination among edge clouds to enable seamless and real-time responses to service requests from mobile users. The objective of this work is to devise the optimal microservice coordination scheme which can reduce the overall service delay with low costs. To this end, we first propose a dynamic programming-based offline microservice coordination algorithm, that can achieve the globally optimal performance. However, the offline algorithm heavily relies on the availability of the prior information such as computation request arrivals, time-varying channel conditions and edge cloud's computation capabilities required, which is hard to be obtained. Therefore, we reformulate the microservice coordination problem using Markov decision process framework and then propose a reinforcement learning-based online microservice coordination algorithm to learn the optimal strategy. Theoretical analysis proves that the offline algorithm can find the optimal solution while the online algorithm can achieve near-optimal performance. Furthermore, based on two real-world datasets, i.e., the Telecom's base station dataset and Taxi Track dataset from Shanghai, experiments are conducted. The experimental results demonstrate that the proposed online algorithm outperforms existing algorithms in terms of service delay and migration costs, and the achieved performance is close to the optimal performance obtained by the offline algorithm.}
}


@article{DBLP:journals/tmc/LiXW21,
	author = {Lingkun Li and
                  Pengjin Xie and
                  Jiliang Wang},
	title = {Enabling 3D Ambient Light Positioning with Mobile Phones and Battery-Free
                  Chips},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {3},
	pages = {952--964},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2956128},
	doi = {10.1109/TMC.2019.2956128},
	timestamp = {Tue, 02 Mar 2021 11:25:36 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/LiXW21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Visible Light Positioning (VLP) has attracted much research effort recently. Most existing VLP approaches require special designed light or receiver, collecting light information or strict user operation (e.g., horizontally holding the mobile phone). This incurs a high deployment, maintenance and usage cost. We present RainbowLight, a low-cost ambient light 3D localization approach that is easy to deploy in today's buildings. Our key finding is that light through a chip of polarizer and birefringence material produces specific interference and light spectrum at different directions to the chip. We derive a model to characterize the relation for direction, light interference, and spectrum. Exploiting the model, RainbowLight calculates the direction to a chip after taking a photo containing the chip. With multiple chips, RainbowLight designs a direction intersection based method to derive the location. We implement RainbowLight and extensively evaluate its performance in various environments. The evaluation results show that RainbowLight achieves an average localization error of 3.3 cm in 2D and 9.6 cm in 3D for light on, and an error of 7.4 cm in 2D and 20.5 cm in 3D for light off scenario in the daytime.}
}


@article{DBLP:journals/tmc/SunLCWZTL21,
	author = {Geng Sun and
                  Yanheng Liu and
                  Zhaoyu Chen and
                  Aimin Wang and
                  Ying Zhang and
                  Daxin Tian and
                  Victor C. M. Leung},
	title = {Energy Efficient Collaborative Beamforming for Reducing Sidelobe in
                  Wireless Sensor Networks},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {3},
	pages = {965--982},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2955948},
	doi = {10.1109/TMC.2019.2955948},
	timestamp = {Wed, 26 Jun 2024 19:56:33 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/SunLCWZTL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Collaborative beamforming (CB) in wireless sensor networks (WSNs) based on a virtual node antenna array (VNAA) can increase the transmission distance and enhance the energy efficiency of sensor nodes. However, a VNAA cannot be pre-designed like the conventional antenna arrays due to the randomly deployed sensor nodes, thereby causing a high sidelobe level (SLL) which increases the interferences. In this article, we formulate a hybrid discrete and continuous optimization problem (HDCOP) for reducing the maximum SLL. HDCOP requires to solve both the discrete and the continuous problems simultaneously, and we propose both centralized and consensus-based distributed CB strategies for solving HDCOP. For the centralized strategy, we convert HDCOP into two sub-optimization problems, and propose a discrete cuckoo search (CS) algorithm for the node location selection optimization and a continuous CS algorithm to optimize the excitation current weights of the selected nodes. For the distributed strategy, we propose a parallel distributed CS algorithm to solve the discrete and continuous parts of HDCOP simultaneously. Moreover, we propose two operating mechanisms based on these two algorithms. Simulation results verify the effectiveness of the proposed strategies for reducing the maximum SLL of CB in WSNs. Moreover, the proposed CB strategies have better performance in terms of the energy efficiency compared with other approaches such as the cross-entropy optimization-based method.}
}


@article{DBLP:journals/tmc/ShahidMAKPM21,
	author = {Adnan Shahid and
                  Vasilis Maglogiannis and
                  Irfan Ahmed and
                  Kwang Soon Kim and
                  Eli De Poorter and
                  Ingrid Moerman},
	title = {Energy-Efficient Resource Allocation for Ultra-Dense Licensed and
                  Unlicensed Dual-Access Small Cell Networks},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {3},
	pages = {983--1000},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2953845},
	doi = {10.1109/TMC.2019.2953845},
	timestamp = {Wed, 07 Dec 2022 23:02:49 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/ShahidMAKPM21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this study, an energy-efficient self-organized framework for sub-channel allocation and power allocation is presented for ultra-dense small cell networks, which can operate in both licensed and unlicensed bands. In order to protect legacy WiFi devices (operating in unlicensed bands), we consider the Long-Term Evolution (LTE) operation in unlicensed bands based on Carrier Sense Adaptive Transmission (CSAT), in which 'ON' and 'OFF' duty cycle approach is utilized. On the other hand, there are severe interference management problems among small cells (operating in licensed and unlicensed bands) and between macro cells and small cells (operating in licensed bands) due to co-channel and ultra-dense deployment of small cells. This article proposes a self-organized optimization framework for the allocation of sub-channels and power levels by exploiting a non-cooperative game with the objective to maximize the energy efficiency of dual-access small cells without creating harmful impact on coexisting network entities including macro cell users, small cell users, and legacy WiFi devices. Simulation results show that the proposed scheme outperforms (6 and 11 percent) and (8 and 18 percent) the round-robin and the spectrum-efficient schemes, respectively, for two different small cell scenarios. In addition, it is shown that for less channel state information (CSI) estimation errors ς = 0.02, the maximum performance degradation of the proposed scheme is reasonably small (5.5 percent) as compared to the perfect CSI.}
}


@article{DBLP:journals/tmc/ZhangWHJC21,
	author = {Xiaomei Zhang and
                  Yibo Wu and
                  Lifu Huang and
                  Heng Ji and
                  Guohong Cao},
	title = {Expertise-Aware Truth Analysis and Task Allocation in Mobile Crowdsourcing},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {3},
	pages = {1001--1016},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2955688},
	doi = {10.1109/TMC.2019.2955688},
	timestamp = {Tue, 03 May 2022 15:10:01 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/ZhangWHJC21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In mobile crowdsourcing, the accuracy of the collected data is usually hard to ensure. Researchers have proposed techniques to identify truth from noisy data by inferring and utilizing the reliability of mobile users, and allocate tasks to users with higher reliability. However, they neglect the fact that a user may only have expertise on some problems (in some domains), but not others, and hence causing two problems: low estimation accuracy in truth analysis and ineffective task allocation. To address these problems, we propose Expertise-aware Truth Analysis and Task Allocation (ETA 2 ), which can effectively infer user expertise, and then estimate truth and allocate tasks based on the inferred expertise. ETA 2 relies on a novel semantic analysis method to identify the expertise, and an expertise-aware truth analysis method to find the truth. For expertise-aware task allocation in ETA 2 , we formalize and solve two problems based on the optimization objectives: max-qualitytask allocation which maximizes the probability fortasks to be allocated to users with high expertise and min-costtask allocation which minimizes the cost of task allocation while ensuring high-quality data are collected. Experimental results based on two real-world datasets and one synthetic dataset demonstrate that ETA 2 significantly outperforms existing solutions.}
}


@article{DBLP:journals/tmc/ZhaiLZZC21,
	author = {Xiangping Bryce Zhai and
                  Xin Liu and
                  Chunsheng Zhu and
                  Kun Zhu and
                  Bing Chen},
	title = {Fast Admission Control and Power Optimization With Adaptive Rates
                  for Communication Fairness in Wireless Networks},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {3},
	pages = {1017--1026},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2954126},
	doi = {10.1109/TMC.2019.2954126},
	timestamp = {Tue, 02 Mar 2021 11:25:36 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/ZhaiLZZC21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Along with the exponentially increasing quantity of intelligent terminals connected to the Internet, the spectrum competition among users becomes more and more severe in wireless networks. The network have not the ability to satisfy all communication requirements due to the significantly increasing users and demanded rates. Energy-aware admission control has been proved to be an efficient way to tackle the infeasibility caused by the severe spectrum competition among users. However, the traditional admission control is limited by gradually removing chosen users, and pays less attention to the fairness. In this article, we elaborate the concept of the fairness in a max-min optimization problem with respect to the transmission rates, by leveraging the model of bit error rates with Q-function for general fading communications. Then, we make use of the max-min rate fairness to smartly determine the subset of users to be admitted in wireless networks. Meanwhile, the overall energy consumption is minimized and the network fairness is guaranteed. In particular, the algorithms can tackle more than one user at each iteration. Numerical evaluations show the effectiveness of the algorithms.}
}


@article{DBLP:journals/tmc/PendaoM21,
	author = {Cristiano G. Pend{\~{a}}o and
                  Adriano J. C. Moreira},
	title = {FastGraph Enhanced: High Accuracy Automatic Indoor Navigation and
                  Mapping},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {3},
	pages = {1027--1045},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2955653},
	doi = {10.1109/TMC.2019.2955653},
	timestamp = {Tue, 02 Mar 2021 11:25:36 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/PendaoM21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {FastGraph is a novel positioning approach recently proposed to address the challenges of positioning in large spaces. Wi-Fi-based indoor positioning solutions often require complex and time-consuming deployments. Fingerprinting, as one of most used approaches, relies on a radio map, usually created by manual site survey, a process unpractical even for small spaces. Moreover, the site survey has to be repeated frequently due to the changes in the radio environment. Wi-Fi-based solutions are also frequently discarded for applications such as indoor vehicle navigation due to limited accuracy. This article introduces FastGraph Enhanced, a new version of FastGraph, able to provide high accuracy positioning, opening new fields of application, such as navigation for autonomous vehicles. In FastGraph Enhanced, the 3D Force-Directed Graph-Based method, used to model the radio environment, is extended with new algorithms, allowing to improve, among other aspects, the positioning performance. The core advantages of FastGraph are maintained, not requiring previous calibration or knowledge about the space. The proposed solution was evaluated in real world, with very significative improvements in positioning accuracy when compared with the basic version of FastGraph (from around 5m to 0.5m), and with state-of-the-art solutions.}
}


@article{DBLP:journals/tmc/WangZFX21,
	author = {Zhimin Wang and
                  Qinglin Zhao and
                  Li Feng and
                  Fangxin Xu},
	title = {How Much Benefit Can Dynamic Frequency Scaling Bring to WiFi?},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {3},
	pages = {1046--1063},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2958323},
	doi = {10.1109/TMC.2019.2958323},
	timestamp = {Tue, 02 Mar 2021 11:25:36 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/WangZFX21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Dynamic frequency scaling (DFS) is a state-of-the-art power-saving technique. Various DFS-based WiFi schemes have been proposed for power saving. These schemes demonstrated the power-saving feasibility of DFS via hardware implementation or simulation. This paper is the first that proposes a general theoretical framework to evaluate the performance of these schemes, where we use Queuing theory to analyze the system throughput and use Semi-Markov theory to quantify the power consumption. In addition, we adopt the energy efficiency (i.e., the throughput per energy cost) to compare the gains of these schemes. This efficiency measure can be used to make a trade-off between system throughput and power consumption and therefore help us choose appropriate parameter settings. Extensive simulations verify that our theoretical model is very accurate and our theoretical results well match with universal software radio peripheral (USRP) experiment results. Our study shows that DFS can greatly improve the energy efficiency of WiFi networks even under low SNR conditions; for example, when SNR = 9.7 dB (i.e., the basic requirement for decoding packets in WiFi), the improvement is around 25 percent for 802.11b at rate 11 Mb/s and 16 percent for 802.11 ac at rate 1300 Mb/s. Our study also shows that DFS can be well integrated with other commonly used power-saving mechanisms to improve energy efficiency further.}
}


@article{DBLP:journals/tmc/LiangGZWPZL21,
	author = {Yu Liang and
                  Jidong Ge and
                  Sheng Zhang and
                  Jie Wu and
                  Lingwei Pan and
                  Tengfei Zhang and
                  Bin Luo},
	title = {Interaction-Oriented Service Entity Placement in Edge Computing},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {3},
	pages = {1064--1075},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2952097},
	doi = {10.1109/TMC.2019.2952097},
	timestamp = {Tue, 02 Mar 2021 11:25:35 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/LiangGZWPZL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Distributed Interactive Applications (DIAs) such as virtual reality and multiplayer online game usually require fast processing of tremendous data and timely exchange of delay-sensitive action data and metadata. This makes traditional mobile-based or cloud-based solutions no longer effective. Thanks to edge computing, DIA Service Providers (DSPs) can rent resources from Edge Infrastructure Providers (EIPs) to place service entities that store user states and run computation-intensive tasks. One fundamental problem for a DSP is to decide where to place service entities to achieve low-delay pairwise interactions between DIA users, under the constraint that the total placement cost is no more than a specified budget threshold. In this article, we formally model the service entity placement problem and prove that it is NP-complete by a polynomial reduction from the set cover problem. We present GPA, an efficient algorithm for service entity placement, and theoretically analyze its performance. We evaluated GPA with both real-world data trace-driven simulations, and observed that GPA performs close to the optimal algorithm and generally outperforms the baseline algorithm. We also output a curve showing the trade-off between the weighted average interaction delay and the budget threshold, so that a DSP can choose the right balance.}
}


@article{DBLP:journals/tmc/YiHC21,
	author = {Changyan Yi and
                  Shiwei Huang and
                  Jun Cai},
	title = {Joint Resource Allocation for Device-to-Device Communication Assisted
                  Fog Computing},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {3},
	pages = {1076--1091},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2952354},
	doi = {10.1109/TMC.2019.2952354},
	timestamp = {Tue, 02 Mar 2021 11:25:36 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/YiHC21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, joint resource management for device-to-device (D2D) communication assisted multi-tier fog computing is studied. In the considered system model, each subscribed mobile end user can choose to offload its computation task to either an edge server deployed at the base station via the cellular connection or one nearby third-party fog node via the direct D2D connection. After receiving offloading requests from all end users, the network operator determines the optimal management of the fog computing system, including both computation and communication resource allocations, according to its service agreements with end users, energy cost of edge-server processing and total expense in renting third-party fog nodes. With the objective of maximizing the network management profit, a joint multi-dimensional resource optimization problem, integrating link scheduling, channel assignment and power control, is formulated. An optimal solution algorithm is proposed based on the idea of branch-and-price for addressing this complicated mixed integer nonlinear programming problem. To facilitate the practical implementation in large-scale systems, a suboptimal greedy algorithm with significantly reduced computational complexity is also developed. Simulation results examine the efficiency of the proposed D2D-assisted fog computing framework, and demonstrate the superiority of the proposed resource allocation algorithm over the counterparts.}
}


@article{DBLP:journals/tmc/AsheralievaN21,
	author = {Alia Asheralieva and
                  Dusit Niyato},
	title = {Learning-Based Mobile Edge Computing Resource Management to Support
                  Public Blockchain Networks},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {3},
	pages = {1092--1109},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2959772},
	doi = {10.1109/TMC.2019.2959772},
	timestamp = {Tue, 02 Mar 2021 11:25:36 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/AsheralievaN21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We consider a public blockchain realized in the mobile edge computing (MEC) network, where the blockchain miners compete against each other to solve the proof-of-work puzzle and win a mining reward. Due to limited computing capabilities of their mobile terminals, miners offload computations to the MEC servers. The MEC servers are maintained by the service provider (SP) that sells its computing resources to the miners. The SP aims at maximizing its long-term profit subject to miners' budget constraints. The miners decide on their hash rates, i.e., computing powers, simultaneously and independently, to maximize their payoffs without revealing their decisions to other miners. As such, the interactions between the SP and miners are modeled as a stochastic Stackelberg game under private information, where the SP assigns the price per unit hash rate, and miners select their actions, i.e., hash rate decisions, without observing actions of other miners. We develop a hierarchical learning framework for this game based on fully- and partially-observable Markov decision models of the decision processes of the SP and miners. We show that the proposed learning algorithms converge to stable states in which miners' actions are the best responses to the optimal price assigned by the SP.}
}


@article{DBLP:journals/tmc/WuHXNBQ21,
	author = {Di Wu and
                  Xin Huang and
                  Xiaofeng Xie and
                  Xiang Nie and
                  Lichun Bao and
                  Zhijin Qin},
	title = {{LEDGE:} Leveraging Edge Computing for Resilient Access Management
                  of Mobile IoT},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {3},
	pages = {1110--1125},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2954872},
	doi = {10.1109/TMC.2019.2954872},
	timestamp = {Tue, 02 Mar 2021 11:25:36 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/WuHXNBQ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Due to the blooming of Internet of Things (IoT), heterogeneous IoT mobile devices emerge to connect the network infrastructure. Traditional mobile access system faces several challenges arising from these IoT devices: 1) centralized controllers are distant from the end devices, 2) inefficient access control of heterogeneous IoT devices, and 3) insufficient authentication and monitoring for IoT devices. In order to tackle the challenges from IoT devices on mobile access control and scalable access monitoring, we present LEDGE, an agile and secured software-defined edge computing system for resilient access management of mobile IoT. In a nutshell, our LEDGE is a synergy of an efficient location authentication method to secure communication between each IoT mobile device and access point (AP) pair, an optimal AP assignment scheme to satisfy IoT flow requests, a Personal AP protocol for scalable access, and a deep learning model for anomaly detection. We prototype our system, and realistic testbed experiments demonstrate that LEDGE could achieve promising results in mobile IoT.}
}


@article{DBLP:journals/tmc/AlexandriSBSTD21,
	author = {Talmon Alexandri and
                  Ziv Zemah Shamir and
                  Eyal Bigal and
                  Aviad P. Scheinin and
                  Dan Tchernov and
                  Roee Diamant},
	title = {Localization of Acoustically Tagged Marine Animals in Under-Ranked
                  Conditions},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {3},
	pages = {1126--1137},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2959765},
	doi = {10.1109/TMC.2019.2959765},
	timestamp = {Sun, 02 Oct 2022 15:51:34 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/AlexandriSBSTD21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A key technology in the movement tracking of marine animals is localization using acoustic transmitters. These are attached to marine animals and are detected by an array of receivers. Then, offline localization is performed by multilateration. However, due to the transmitter's low power and environmental conditions, emissions may be detected by only a limited number of receivers, causing localization ambiguities to arise. This work proposes a solution for such localization ambiguities. The proposed method assumes that the position of acoustically-tagged marine animals follows a hidden Markov model, such that localization ambiguities can probabilistically be resolved using a Forward-Backward algorithm. Our method is able to extrapolate the positions in a data series, as long as one sample in that series is picked up by three receivers, or if the identity of the receivers changes during tracking. Performance analysis shows that the localization accuracy of our method approaches the Cramér-Rao lower bound. Furthermore, to demonstrate the suitability of our method in a real sea environment, we have established a testbed that operated for three months, demonstrating localization of 20 acoustically-tagged sandbar sharks. Compared to the available solutions, roughly 20 times more location estimates were made; thereby, significantly increasing the impact of the test-site.}
}


@article{DBLP:journals/tmc/JinHWXCG21,
	author = {Ling Jin and
                  Boyuan He and
                  Guangyao Weng and
                  Haitao Xu and
                  Yan Chen and
                  Guanyu Guo},
	title = {MAdLens: Investigating Into Android In-App Ad Practice at {API} Granularity},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {3},
	pages = {1138--1155},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2953609},
	doi = {10.1109/TMC.2019.2953609},
	timestamp = {Thu, 05 May 2022 08:42:54 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/JinHWXCG21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In-app advertising has served as the major revenue source for millions of app developers in the mobile Internet ecosystem. Ad networks play an important role in app monetization by providing third-party libraries for developers to choose and embed into their apps. Various ad mediations help developers manage all of the ad libraries used in apps to show the best available ad among received ads from different ad network servers. However, developers lack guidelines on how to choose from hundreds of ad networks or ad mediations and various ad features to maximize their revenues without hurting the user experience of their apps. Our work aims to provide app developers guidelines on the selection of ad networks, ad mediations, and ad placement by observing current common practices. To this end, we investigate 838 unique APIs from 207 ad networks which are extracted from 277,616 Android apps, develop a methodology of ad type classification based on UI interaction and behavior, and perform a large scale measurement study of in-app ads with static analysis techniques at the API granularity. We found that developers have more choices about ad networks than several years before. Most developers are conservative about ad placement and about 77 percent of the apps contain at most one ad library. Besides, the likeliness of an app containing ads depends on the app category to which it belongs. Furthermore, we propose a terminology and classify mobile ads into five ad types: Embedded, Popup, Notification, Offerwall, and Floating. Also, our research shows that it is a better solution for developers to integrate ad libraries with ad mediation feature in their apps because it may avoid bad ratings and improve user experience. And in our findings, more than 95 percent of embedded, popup, notification, and offer ads locate in the zero activity (main activity), the first activity and the second activity of Android apps. More interestingly, developers tend to put high aggressive ads on activities which need deeper user interaction. Our research is the first to reveal the preference of both developers and users for ad networks, ad mediation feature and ad types.}
}


@article{DBLP:journals/tmc/FerngCLTZ21,
	author = {Huei{-}Wen Ferng and
                  Jia{-}Ying Chen and
                  MohammadAmin Lotfolahi and
                  Ying{-}Tsu Tseng and
                  Si{-}Yuan Zhang},
	title = {Messages Classification and Dynamic Batch Verification Scheme for
                  VANETs},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {3},
	pages = {1156--1172},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2952105},
	doi = {10.1109/TMC.2019.2952105},
	timestamp = {Tue, 02 Mar 2021 11:25:35 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/FerngCLTZ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Under a high-density traffic environment in a vehicular ad hoc network (VANET), many safety messages will not be verified in time and then get dropped. To touch such an issue appropriately, we aim at improving the efficiency of message verification and the number of verified safety messages. In our proposed scheme, messages are properly classified and prioritized first so that more important basic safety messages can be verified earlier. To improve batch verification, a dynamic batch verification scheme with an adjustable batch size is designed accordingly. The batch size is halved when failures of batch verification occur consecutively over a certain threshold to improve the efficiency of batch verification. On the contrary, the batch size is doubled when successes of batch verification occur consecutively over a certain threshold to increase the messages in a batch to be verified. For a failure of batch verification, a divide-and-conquer approach is utilized to find the illegitimate message(s). Via analysis, the superiority of our design over some closely related schemes in terms of verification delay and number of verified basic safety messages etc. is successfully demonstrated. By simulation, performance of our design and some closely related schemes is further investigated in realistic scenarios.}
}


@article{DBLP:journals/tmc/KadotaM21,
	author = {Igor Kadota and
                  Eytan H. Modiano},
	title = {Minimizing the Age of Information in Wireless Networks with Stochastic
                  Arrivals},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {3},
	pages = {1173--1185},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2959774},
	doi = {10.1109/TMC.2019.2959774},
	timestamp = {Mon, 22 Feb 2021 15:13:30 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/KadotaM21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We consider a wireless network with a base station serving multiple traffic streams to different destinations. Packets from each stream arrive to the base station according to a stochastic process and are enqueued in a separate (per stream) queue. The queueing discipline controls which packet within each queue is available for transmission. The base station decides, at every time t, which stream to serve to the corresponding destination. The goal of scheduling decisions is to keep the information at the destinations fresh. Information freshness is captured by the Age of Information (AoI) metric. In this paper, we derive a lower bound on the AoI performance achievable by any given network operating under any queueing discipline. Then, we consider three common queueing disciplines and develop both an Optimal Stationary Randomized policy and a Max-Weight policy under each discipline. Our approach allows us to evaluate the combined impact of the stochastic arrivals, queueing discipline and scheduling policy on AoI. We evaluate the AoI performance both analytically and using simulations. Numerical results show that the performance of the Max-Weight policy is close to the analytical lower bound.}
}


@article{DBLP:journals/tmc/KongLL21,
	author = {Xiangqi Kong and
                  Ning Lu and
                  Bin Li},
	title = {Optimal Scheduling for Unmanned Aerial Vehicle Networks With Flow-Level
                  Dynamics},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {3},
	pages = {1186--1197},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2952848},
	doi = {10.1109/TMC.2019.2952848},
	timestamp = {Mon, 24 Jan 2022 14:27:48 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/KongLL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Unmanned Aerial Vehicle (UAV) Networks have recently attracted great attention as being able to provide convenient and fast wireless connections. One central question is how to allocate a limited number of UAVs to provide wireless services across a large number of regions, where each region has dynamic arriving flows and flows depart from the system once they receive the desired amount of service (referred to as the flow-level dynamic model). In this article, we propose a MaxWeight-type scheduling algorithm taking into account sharp flow-level dynamics that efficiently redirect UAVs across a large number of regions. However, in our considered model, each flow experiences an independent fading channel and will immediately leave the system once it completes its service, which makes its evolution quite different from the traditional queueing model for wireless networks. This poses significant challenges in our performance analysis. Nevertheless, we incorporate sharp flow-dynamic into the Lyapunov-drift analysis framework, and successfully establish both throughput and heavy-traffic optimality of the proposed algorithm. Extensive simulations are performed to validate the effectiveness of our proposed algorithm.}
}


@article{DBLP:journals/tmc/ChenT21,
	author = {Kongyang Chen and
                  Guang Tan},
	title = {SatProbe: Low-Energy and Fast Indoor/Outdoor Detection via Satellite
                  Existence Sensing},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {3},
	pages = {1198--1211},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2954873},
	doi = {10.1109/TMC.2019.2954873},
	timestamp = {Tue, 02 Mar 2021 11:25:35 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/ChenT21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Indoor-outdoor (IO) detection provides very useful hints for a mobile device to perform context-aware services. To that end, GPS presents a viable solution by relating a device's IO status with its positioning performance, which depends on the device's exposure to the open sky. This approach, however, is prohibitively expensive in terms of energy consumption and response time. Recent work has thus been focused on exploiting low-energy sensors such as light, cellular, and magnetic sensors to infer the IO status indirectly, at the cost of reduced adaptability or manual labeling effort. In this article, we propose a new method to address these problems. Our method, called SatProbe, reverts to the GPS approach for its directness and robustness, but avoids its drawback by extracting only the number of visible satellites from the raw GPS data, instead of going through extensive computation to obtain a final position. This metric provides a clear indicator of the IO status, yet can be obtained with great efficiency. Experiments on 79 raw GPS traces with 2595 detection points across a variety of environments show that SatProbe produces a 14.2 percent improvement in detection accuracy, with a 98.8 percent reduction in both energy use and detection time, in comparison with the standard GPS method.}
}


@article{DBLP:journals/tmc/LuoZCYLYS21,
	author = {Guiyang Luo and
                  Haibo Zhou and
                  Nan Cheng and
                  Quan Yuan and
                  Jinglin Li and
                  Fangchun Yang and
                  Xuemin Shen},
	title = {Software-Defined Cooperative Data Sharing in Edge Computing Assisted
                  5G-VANET},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {3},
	pages = {1212--1229},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2953163},
	doi = {10.1109/TMC.2019.2953163},
	timestamp = {Tue, 21 Mar 2023 21:12:55 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/LuoZCYLYS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {It is widely recognized that connected vehicles have the potential to further improve the road safety, transportation intelligence and enhance the in-vehicle entertainment. By leveraging the 5G enabled Vehicular Ad hoc NETworks (VANET) technology, which is referred to as 5G-VANET, a flexible software-defined communication can be achieved with ultra-high reliability, low latency, and high capacity. Many enabling applications in 5G-VANET rely on sharing mobile data among vehicles, which is still a challenging issue due to the extremely large data volume and the prohibitive cost of transmitting such data using 5G cellular networks. This article focuses on efficient cooperative data sharing in edge computing assisted 5G-VANET. First, to enable efficient cooperation between cellular communication and Dedicated Short-Range Communication (DSRC), we first propose a software-defined cooperative data sharing architecture in 5G-VANET. The cellular link allows the communications between OpenFlow enabled vehicles and the Controller to collect contextual information, while the DSRC serves as the data plane, enabling cooperative data sharing among adjacent vehicles. Second, we propose a graph theory based algorithm to efficiently solve the data sharing problem, which is formulated as a maximum weighted independent set problem on the constructed conflict graph. Specifically, considering the continuous data sharing, we propose a balanced greedy algorithm, which can make the content distribution more balanced. Furthermore, due to the fixed amount of computing resources allocated to this software-defined cooperative data sharing service, we propose an integer linear programming based decomposition algorithm to make full use of the computing resources. Extensive simulations in NS3 and SUMO demonstrate the superiority and scalability of the proposed software-defined architecture and cooperative data sharing algorithms.}
}


@article{DBLP:journals/tmc/XuDL21,
	author = {Xinping Xu and
                  Lingjie Duan and
                  Minming Li},
	title = {Strategic Learning Approach for Deploying UAV-Provided Wireless Services},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {3},
	pages = {1230--1241},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2953726},
	doi = {10.1109/TMC.2019.2953726},
	timestamp = {Tue, 02 Mar 2021 11:25:36 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/XuDL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Unmanned Aerial Vehicle (UAV) have emerged as a promising technique to rapidly provide wireless services to a group of mobile users simultaneously. The article aims to address a challenging issue that each user is selfish and may misreport his location or preference for changing the optimal UAV location to be close to himself. Using algorithmic game theory, we study how to determine the final location of a UAV in the 3D space, by ensuring all selfish users' truthfulness in reporting their locations for learning purpose. To minimize the social service cost in this UAV placement game, we design strategyproof mechanisms with the approximation ratios, when comparing to the social optimum. We also study the obnoxious UAV placement game to maximally keep their social utility, where each incumbent user may misreport his location to keep the UAV away from him. Moreover, we present the dual-preference UAV placement game by considering the coexistence of the two groups of users above, where users can misreport both their locations and preference types (favorable or obnoxious) towards the UAV. Finally, we extend the three games above to include multiple UAVs and design strategyproof mechanisms with provable approximation ratios.}
}


@article{DBLP:journals/tmc/VenkatnarayanMS21,
	author = {Raghav H. Venkatnarayan and
                  Shakir Mahmood and
                  Muhammad Shahzad},
	title = {WiFi based Multi-User Gesture Recognition},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {3},
	pages = {1242--1256},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2954891},
	doi = {10.1109/TMC.2019.2954891},
	timestamp = {Tue, 02 Mar 2021 11:25:36 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/VenkatnarayanMS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {WiFi based gesture recognition has received significant attention overthe past few years. However, the key limitation of prior WiFi based gesture recognition systems is that they cannot recognize the gestures of multiple users performing them simultaneously. In this article, we address this limitation and propose WiMU, a WiFi based Multi-User gesture recognition system. The key idea behind WiMU is that when it detects that some users have performed some gestures simultaneously, it first automatically determines the number of simultaneously performed gestures (Na) and then, using the training samples collected from a single user, generates virtual samples for various plausible combinations of Na gestures. The key property of these virtual samples is that the virtual samples for any given combination of gestures are identical to the real samples that would result from real users performing that combination of gestures. WiMU compares the detected sample against these virtual samples and recognizes the simultaneously performed gestures. We implemented and extensively evaluated WiMU using commodity WiFi devices. Our results show that WiMU recognizes 2, 3, 4, 5, 6, 7, and 8 simultaneously performed gestures with accuracies of 95.6, 94.9, 93.9, 92.7, 91.6, 91.0, and 90.1 percent, respectively.}
}


@article{DBLP:journals/tmc/WangLGZDS21,
	author = {Xiujun Wang and
                  Zhi Liu and
                  Yan Gao and
                  Xiao Zheng and
                  Zhe Dang and
                  Xiaojun Shen},
	title = {A Near-Optimal Protocol for the Grouping Problem in {RFID} Systems},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {4},
	pages = {1257--1272},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2962125},
	doi = {10.1109/TMC.2019.2962125},
	timestamp = {Fri, 28 May 2021 13:40:17 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/WangLGZDS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Radio frequency identification (RFID) has been widely used in many fields such as object tracking and inventory management. For RFID systems, grouping is a fundamental issue which can support efficient multicast transmissions, dynamic tag management, and accurate aggregate queries. Existing grouping protocols have drawbacks of unknown theoretical communication time, high computational cost on the server end and inability to deal with unexpected tags which are those tags whose IDs have not been collected by readers. In this paper, we would like to address the above limitations and consider a more general grouping problem that allows an arbitrary number of unexpected tags to present. Our objective is to design a protocol that guarantees the reader to efficiently and correctly notify each known tag of its group-ID, while the probability that an unexpected tag is mistakenly notified of any group-ID is smaller than a pre-determined value. In this paper, we first obtain a lower bound on the communication time for solving this generalized grouping problem. Then, we propose a near-optimal protocol, called OPT-G, and prove that its communication time approximately equals the lower bound. Finally, we report extensive simulation results that demonstrate OPT-G's near-optimal performance and its superiority over existing baseline schemes.}
}


@article{DBLP:journals/tmc/LiuZJYLCL21,
	author = {Xiulong Liu and
                  Jiuwu Zhang and
                  Shan Jiang and
                  Yanni Yang and
                  Keqiu Li and
                  Jiannong Cao and
                  Jiangchuan Liu},
	title = {Accurate Localization of Tagged Objects Using Mobile RFID-Augmented
                  Robots},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {4},
	pages = {1273--1284},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2962129},
	doi = {10.1109/TMC.2019.2962129},
	timestamp = {Tue, 23 Mar 2021 14:13:20 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/LiuZJYLCL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper studies the problem of tag localization using RFID-augmented robots, which is practically important for promising warehousing applications, e.g., automatic item fetching and misplacement detection. Existing RFID localization systems suffer from one or more of following limitations: requiring specialized devices; only 2D localization is enabled; having blind zone for mobile localization; low scalability. In this paper, we use Commercial Off-The-Shelf (COTS) robot and RFID devices to implement a Mobile RF-robot Localization (MRL) system. Specifically, when the RFID-augmented robot moves along the straight aisle in a warehouse, the reader keeps reading the target tag via two vertically deployed antennas ( Z1 and Z2) and returns the tag phase data with timestamps to the server. We take three points in the phase profile of antenna Z1 and leverage the spatial and temporal changes inherent in this phase triad to construct an equation set. By solving it, we achieve the location of target tag relative to the trajectory of antenna Z1. Based on different phase triads, we can have candidate locations of the target tag with different accuracy. Then, we propose theoretical analysis to quantify the deviation of each localization result. A fine-grained localization result can be achieved by assigning larger weights to the localization results with smaller deviations. Similarly, we can also calculate the relative location of target tag with respect to the trajectory of antenna Z2. Leveraging the geometric relationships among target tag and antenna trajectories, we eventually calculate the location of target tag in 3D space. We perform various experiments to evaluate the performance of the MRL system and results show that the proposed MRL system can achieve high accuracy in both 2D and 3D localization.}
}


@article{DBLP:journals/tmc/CaoGLXDCL21,
	author = {Chenhong Cao and
                  Yi Gao and
                  Yang Luo and
                  Mingyuan Xia and
                  Wei Dong and
                  Chun Chen and
                  Xue Liu},
	title = {AdSherlock: Efficient and Deployable Click Fraud Detection for Mobile
                  Applications},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {4},
	pages = {1285--1297},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2966991},
	doi = {10.1109/TMC.2020.2966991},
	timestamp = {Mon, 16 Jan 2023 17:00:33 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/CaoGLXDCL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Mobile advertising plays a vital role in the mobile app ecosystem. A major threat to the sustainability of this ecosystem is click fraud, i.e., ad clicks performed by malicious code or automatic bot problems. Existing click fraud detection approaches focus on analyzing the ad requests at the server side. However, such approaches may suffer from high false negatives since the detection can be easily circumvented, e.g., when the clicks are behind proxies or globally distributed. In this paper, we present AdSherlock, an efficient and deployable click fraud detection approach at the client side (inside the application) for mobile apps. AdSherlock splits the computation-intensive operations of click request identification into an offline procedure and an online procedure. In the offline procedure, AdSherlock generates both exact patterns and probabilistic patterns based on URL (Uniform Resource Locator) tokenization. These patterns are used in the online procedure for click request identification and further used for click fraud detection together with an ad request tree model. We implement a prototype of AdSherlock and evaluate its performance using real apps. The online detector is injected into the app executable archive through binary instrumentation. Results show that AdSherlock achieves higher click fraud detection accuracy compared with state of the art, with negligible runtime overhead.}
}


@article{DBLP:journals/tmc/GoudarziWPB21,
	author = {Mohammad Goudarzi and
                  Huaming Wu and
                  Marimuthu Palaniswami and
                  Rajkumar Buyya},
	title = {An Application Placement Technique for Concurrent IoT Applications
                  in Edge and Fog Computing Environments},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {4},
	pages = {1298--1311},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2967041},
	doi = {10.1109/TMC.2020.2967041},
	timestamp = {Tue, 23 Mar 2021 14:13:21 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/GoudarziWPB21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Fog/Edge computing emerges as a novel computing paradigm that harnesses resources in the proximity of the Internet of Things (IoT) devices so that, alongside with the cloud servers, provide services in a timely manner. However, due to the ever-increasing growth of IoT devices with resource-hungry applications, fog/edge servers with limited resources cannot efficiently satisfy the requirements of the IoT applications. Therefore, the application placement in the fog/edge computing environment, in which several distributed fog/edge servers and centralized cloud servers are available, is a challenging issue. In this article, we propose a weighted cost model to minimize the execution time and energy consumption of IoT applications, in a computing environment with multiple IoT devices, multiple fog/edge servers and cloud servers. Besides, a new application placement technique based on the Memetic Algorithm is proposed to make batch application placement decision for concurrent IoT applications. Due to the heterogeneity of IoT applications, we also propose a lightweight pre-scheduling algorithm to maximize the number of parallel tasks for the concurrent execution. The performance results demonstrate that our technique significantly improves the weighted cost of IoT applications up to 65 percent in comparison to its counterparts.}
}


@article{DBLP:journals/tmc/EbrahimiSHA21,
	author = {Dariush Ebrahimi and
                  Sanaa Sharafeddine and
                  Pin{-}Han Ho and
                  Chadi Assi},
	title = {Autonomous {UAV} Trajectory for Localizing Ground Objects: {A} Reinforcement
                  Learning Approach},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {4},
	pages = {1312--1324},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2966989},
	doi = {10.1109/TMC.2020.2966989},
	timestamp = {Tue, 23 Mar 2021 14:13:21 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/EbrahimiSHA21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Disaster management, search and rescue missions, and health monitoring are examples of critical applications that require object localization with high precision and sometimes in a timely manner. In the absence of the global positioning system (GPS), the radio received signal strength index (RSSI) can be used for localization purposes due to its simplicity and cost-effectiveness. However, due to the low accuracy of RSSI, unmanned aerial vehicles (UAVs) or drones may be used as an efficient solution for improved localization accuracy due to their agility and higher probability of line-of-sight (LoS). Hence, in this context, we propose a novel framework based on reinforcement learning (RL) to enable a UAV (agent) to autonomously find its trajectory that results in improving the localization accuracy of multiple objects in shortest time and path length, fewer signal-strength measurements (waypoints), and/or lower UAV energy consumption. In particular, we first control the agent through initial scan trajectory on the whole region to 1) know the number of nodes and estimate their initial locations, and 2) train the agent online during operation. Then, the agent forms its trajectory by using RL to choose the next waypoints in order to minimize the average location errors of all objects. Our framework includes detailed UAV to ground channel characteristics with an empirical path loss and log-normal shadowing model, and also with an elaborate energy consumption model. We investigate and compare the localization precision of our approach with existing methods from the literature by varying the UAV's trajectory length, energy, number of waypoints, and time. Furthermore, we study the impact of the UAV's velocity, altitude, hovering time, communication range, number of maximum RSSI measurements, and number of objects. The results show the superiority of our method over the state-of-art and demonstrates its fast reduction of the localization error.}
}


@article{DBLP:journals/tmc/VitaleCMT21,
	author = {Christian Vitale and
                  Carla{-}Fabiana Chiasserini and
                  Francesco Malandrino and
                  Senay Semu Tadesse},
	title = {Characterizing Delay and Control Traffic of the Cellular {MME} With
                  IoT Support},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {4},
	pages = {1325--1336},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2964677},
	doi = {10.1109/TMC.2020.2964677},
	timestamp = {Tue, 23 Mar 2021 14:13:21 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/VitaleCMT21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {One of the main use cases for advanced cellular networks is represented by massive Internet-of-things (MIoT), i.e., an enormous number of IoT devices that transmit data toward the cellular network infrastructure. To make cellular MIoT a reality, data transfer and control procedures specifically designed for the support of IoT are needed. For this reason, 3GPP has introduced the Control Plane Cellular IoT optimization, which foresees a simplified bearer instantiation, with the Mobility Management Entity (MME) handling both control and data traffic. The performance of the MME has therefore become critical, and properly scaling its computational capability can determine the ability of the whole network to tackle MIoT effectively. In particular, considering virtualized networks and the need for an efficient allocation of computing resources, it is paramount to characterize the MME performance as the MIoT traffic load changes. We address this need by presenting compact, closed-form expressions linking the number of IoT sources with the rate at which bearers are requested, and such a rate with the delay incurred by the IoT data. We show that our analysis, supported by testbed experiments and verified through large-scale simulations, represents a valuable tool to make effective scaling decisions in virtualized cellular core networks.}
}


@article{DBLP:journals/tmc/YueX21,
	author = {Jing Yue and
                  Ming Xiao},
	title = {Coding for Distributed Fog Computing in Internet of Mobile Things},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {4},
	pages = {1337--1350},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2963668},
	doi = {10.1109/TMC.2019.2963668},
	timestamp = {Thu, 28 Oct 2021 13:52:50 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/YueX21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Internet of Mobile Things (IoMTs) refers to the interconnection of mobile devices, for example, mobile phones, vehicles, robots, etc. For mobile data, strong extra processing resources are normally required due to the limited physical resources of the mobile devices in IoMTs. Due to latency or bandwidth limitations, it may be infeasible to transfer a large amounts of mobile data to remote server for processing. Thus, distributed computing is one of the potential solutions to overcome these limitations. We consider the device mobility in IoMTs. Two situations of the movement position of the mobile devices, i.e., unpredictable and predictable, are considered. In addition, three possible relative positions between the two server sets which respectively correspond to the positions of a mobile device for computation tasks offloading and for output results receiving, i.e., within the same server sets, with two different server sets and with two adjacent server sets, are studied. Coded schemes with high flexibility and low complexity are proposed based on Fountain codes to reduce the total processing time and latency of the distributed fog computing process in IoMTs for the above different situations. The latency related performance, i.e., the computation, the communication and the transmission loads, is analyzed. We also compare of the Fountain code-based and the uncoded schemes and numerical results demonstrate that shorter total processing time and lower latency can be achieved by the Fountain code-based schemes.}
}


@article{DBLP:journals/tmc/ChenLWMT21,
	author = {Changhao Chen and
                  Chris Xiaoxuan Lu and
                  Johan Wahlstr{\"{o}}m and
                  Andrew Markham and
                  Niki Trigoni},
	title = {Deep Neural Network Based Inertial Odometry Using Low-Cost Inertial
                  Measurement Units},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {4},
	pages = {1351--1364},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2960780},
	doi = {10.1109/TMC.2019.2960780},
	timestamp = {Mon, 28 Aug 2023 21:39:15 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/ChenLWMT21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Inertial measurement units (IMUs) have emerged as an essential component in many of today's indoor navigation solutions due to their low cost and ease of use. However, despite many attempts for reducing the error growth of navigation systems based on commercial-grade inertial sensors, there is still no satisfactory solution that produces navigation estimates with long-time stability in widely differing conditions. This paper proposes to break the cycle of continuous integration used in traditional inertial algorithms, formulate it as an optimization problem, and explore the use of deep recurrent neural networks for estimating the displacement of a user over a specified time window. By training the deep neural network using inertial measurements and ground truth displacement data, it is possible to learn both motion characteristics and systematic error drift. As opposed to established context-aided inertial solutions, the proposed method is not dependent on either fixed sensor positions or periodic motion patterns. It can reconstruct accurate trajectories directly from raw inertial measurements, and predict the corresponding uncertainty to show model confidence. Extensive experimental evaluations demonstrate that the neural network produces position estimates with high accuracy for several different attachments, users, sensors, and motion types. As a particular demonstration of its flexibility, our deep inertial solutions can estimate trajectories for non-periodic motion, such as the shopping trolley tracking. Further more, it works in highly dynamic conditions, such as running, remaining extremely challenging for current techniques.}
}


@article{DBLP:journals/tmc/FengNLWK21,
	author = {Shaohan Feng and
                  Dusit Niyato and
                  Xiao Lu and
                  Ping Wang and
                  Dong In Kim},
	title = {Dynamic Model for Network Selection in Next Generation HetNets With
                  Memory-Affecting Rational Users},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {4},
	pages = {1365--1379},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2965450},
	doi = {10.1109/TMC.2020.2965450},
	timestamp = {Tue, 23 Mar 2021 14:13:21 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/FengNLWK21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recently, due to the staggering growth of wireless data traffic, heterogeneous networks have drawn tremendous attention due to the capabilities of enhancing the capacity/coverage and reducing energy consumption for the next generation wireless networks. In this paper, we study a long-run user-centric network selection problem in the 5G heterogeneous network, where the network selection strategies of the users can be investigated dynamically. Unlike the conventional studies on the long-run model, we incorporate the memory effect and consider the fact that the decision-making of the users is affected by their memory, i.e., their past service experience. Namely, the users select the network based on not only their instantaneous achievable service experience but also their past service experience within their memory. Specifically, we model and study the interaction among the users in the framework of fractional evolutionary game based on the classical evolutionary game theory and the concept of the power-law memory. We analytically prove that the equilibrium of the fractional evolutionary game exists, is unique and uniformly stable. We also numerically demonstrate the stability of the fractional evolutionary equilibrium. Extensive simulations have been conducted to evaluate the performance of the fractional evolutionary game. The numerical results have revealed some insightful findings. For example, the user in the fractional evolutionary game with positive memory effect can achieve a higher cumulative utility compared with the user in the fractional evolutionary game with negative memory effect. Moreover, the fractional evolutionary game with positive memory effect can reduce the loss in the user's cumulative utility caused by the small-scale fading.}
}


@article{DBLP:journals/tmc/MoubayedSHLB21,
	author = {Abdallah Moubayed and
                  Abdallah Shami and
                  Parisa Heidari and
                  Adel Larabi and
                  Richard Brunner},
	title = {Edge-Enabled {V2X} Service Placement for Intelligent Transportation
                  Systems},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {4},
	pages = {1380--1392},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2965929},
	doi = {10.1109/TMC.2020.2965929},
	timestamp = {Tue, 23 Mar 2021 14:13:21 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/MoubayedSHLB21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Vehicle-to-everything (V2X) communication and services have been garnering significant interest from different stakeholders as part of future intelligent transportation systems (ITSs). This is due to the many benefits they offer. However, many of these services have stringent performance requirements, particularly in terms of the delay/latency. Multi-access/mobile edge computing (MEC) has been proposed as a potential solution for such services by bringing them closer to vehicles. Yet, this introduces a new set of challenges such as where to place these V2X services, especially given the limit computation resources available at edge nodes. To that end, this work formulates the problem of optimal V2X service placement (OVSP) in a hybrid core/edge environment as a binary integer linear programming problem. To the best of our knowledge, no previous work considered the V2X service placement problem while taking into consideration the computational resource availability at the nodes. Moreover, a low-complexity greedy-based heuristic algorithm named “Greedy V2X Service Placement Algorithm” (G-VSPA) was developed to solve this problem. Simulation results show that the OVSP model successfully guarantees and maintains the QoS requirements of all the different V2X services. Additionally, it is observed that the proposed G-VSPA algorithm achieves close to optimal performance while having lower complexity.}
}


@article{DBLP:journals/tmc/ZhangWL21,
	author = {Lei Zhang and
                  Feng Wang and
                  Jiangchuan Liu},
	title = {Enhancing Dynamic-Viewport Mobile Applications with Screen Scrolling},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {4},
	pages = {1393--1407},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2959524},
	doi = {10.1109/TMC.2019.2959524},
	timestamp = {Tue, 23 Mar 2021 14:13:20 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/ZhangWL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The pervasive penetration of mobile smart devices has significantly enriched Internet applications and undoubtedly reshaped the way that users access Internet services. Different from traditional desktop applications, mobile Internet applications require users to input via touch screens and view outputs on the displays with considerably limited size. The significant conflict between the limited-size of touch screens and the richness of online media contents widely exists in dynamic-viewport mobile applications, a class of mobile Internet applications that download contents beyond the user's viewing region (referred to as viewport). As dynamic-viewport mobile applications usually use HTTP for content downloading, to improve their quality of experience (QoE) and cost efficiency, in this paper, we present a Mobile-Friendly HTTP middleware (MF-HTTP), which can interpret user touch screen inputs and optimize the HTTP downloading of media objects for such applications. We first demystify screen scrolling in mobile operating systems and precisely break down the viewport moving process. We identify the key influential factors for media object downloading and develop an optimal download scheme. Towards building a practical middleware, we further discuss and address the implementation issues in detail. We implement a MF-HTTP prototype based on Android platforms and evaluate the performance of MF-HTTP by conducting concrete case studies on two representative dynamic-viewport mobile applications, namely, web browsing and 360-degree video streaming.}
}


@article{DBLP:journals/tmc/HarwahyuCLS21,
	author = {Ruki Harwahyu and
                  Ray{-}Guang Cheng and
                  Da{-}Hao Liu and
                  Riri Fitri Sari},
	title = {Fair Configuration Scheme for Random Access in NB-IoT with Multiple
                  Coverage Enhancement Levels},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {4},
	pages = {1408--1419},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2962422},
	doi = {10.1109/TMC.2019.2962422},
	timestamp = {Thu, 27 Jul 2023 08:18:51 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/HarwahyuCLS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Narrowband Internet of Things (NB-IoT) is a new technology developed to support low-power wide area networks (LPWAN) services. To extend its coverage and decrease its transmission power, devices in one NB-IoT cell are divided into several coverage enhancement (CE) levels with different random access configuration. This potentially results in unfair access, especially when massive number of devices in different CE levels simultaneously accessing the network. This work presents an effective strategy to configure the random access in NB-IoT to yield fair performance across CE levels. An analytical model is used to estimate the performance of each CE level and overall system performance in term of normalized throughput and average access delay. Simulation is incorporated to verify the accuracy of the model. Different practical assumptions of fair system are explored and examined in the experiment. The result shows that the analytical model is accurate under various loads. Additionally, the proposed search strategy is proven to be able to obtain the configuration which yield acceptable throughput fairly for all CE levels.}
}


@article{DBLP:journals/tmc/FanWSLL21,
	author = {Xiaoyi Fan and
                  Feng Wang and
                  Danyang Song and
                  Yuhe Lu and
                  Jiangchuan Liu},
	title = {GazMon: Eye Gazing Enabled Driving Behavior Monitoring and Prediction},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {4},
	pages = {1420--1433},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2962764},
	doi = {10.1109/TMC.2019.2962764},
	timestamp = {Mon, 15 May 2023 12:09:15 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/FanWSLL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Automobiles have become one of the necessities of modern life, but also introduced numerous traffic accidents that threaten drivers and other road users. Most state-of-the-art safety systems are passively triggered, reacting to dangerous road conditions or driving maneuvers only after they happen and are observed, which greatly limits the last chances for collision avoidances. Timely tracking and predicting the driving maneuvers calls for a more direct interface beyond the traditional steering wheel/brake/gas pedal. In this paper, we argue that a driver's eyes are the interface, as it is the first and the essential window that gathers external information during driving. Our experiments suggest that a driver's gaze patterns appear prior to and correlate with the driving maneuvers for driving maneuver prediction. We accordingly present GazMon, an active driving maneuver monitoring and prediction framework for driving assistance applications. GazMon extracts the gaze information through a front-camera and analyzes the facial features, including facial landmarks, head pose, and iris centers, through a carefully constructed deep learning architecture. Both our on-road experiments and driving simulator based evaluations demonstrate the superiority of our GazMon on predicting driving maneuvers as well as other distracted behaviors. It is readily deployable using RGB cameras and allows reuse of existing smartphones towards more safely driving.}
}


@article{DBLP:journals/tmc/FuchsSG21,
	author = {Adel Fuchs and
                  Ariel Stulman and
                  Andrei V. Gurtov},
	title = {IoT and HIP's Opportunistic Mode},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {4},
	pages = {1434--1448},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2967044},
	doi = {10.1109/TMC.2020.2967044},
	timestamp = {Tue, 23 Mar 2021 14:13:21 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/FuchsSG21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Key sharing has always been a complex issue. It became even more challenging for the Internet of Things (IoT), where a trusted third party for global management rarely exists. With authentication and confidentiality lacking, things resort to a leap of faith (LoF) paradigm where it is assumed that no attacker is present during the initial configuration. In this paper we focus on the Host Identity Protocol (HIP), specifically designed to provide mobility and multihoming capabilities. Although HIP is normally based on many strict security mechanisms (e.g., DNSSEC), it also provides a better than nothing opportunistic mode, based on the LoF paradigm, which is to be used when other more trusted mechanisms are not available. In this paper, we analyze different MiTM attacks which might occur under this opportunistic mode. Taking advantage of HIP's multihoming capabilities, we propose two key spraying techniques which strengthen the opportunistic mode's security. The first technique spreads the four key-exchange messages among different networks, while the second spreads fractions of one of those messages. Evaluation of these techniques is provided, demonstrating the major benefit of our proposal.}
}


@article{DBLP:journals/tmc/FanJLQGLFW21,
	author = {Guiyun Fan and
                  Haiming Jin and
                  Qihong Liu and
                  Wei Qin and
                  Xiaoying Gan and
                  Huan Long and
                  Luoyi Fu and
                  Xinbing Wang},
	title = {Joint Scheduling and Incentive Mechanism for Spatio-Temporal Vehicular
                  Crowd Sensing},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {4},
	pages = {1449--1464},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2960328},
	doi = {10.1109/TMC.2019.2960328},
	timestamp = {Mon, 28 Aug 2023 21:39:16 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/FanJLQGLFW21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recent years have witnessed the rising popularity of urban vehicular crowd sensing (UVCS) systems that leverage drivers’ mobile devices equipped with on-board sensors for various urban sensing tasks. Because of the importance of ensuring satisfactory spatio-temporal sensing coverage in such UVCS systems, most existing work has focus on designing efficient scheduling mechanisms to maximize the task completion rate under drivers’ traveling constraints. Different from prior work, we propose Hector, a joint trajectory scheduling and incentive mechanism for spatio-temporal UVCS systems, which concentrates on capturing the interactive effects between scheduling and incentive mechanisms. Technically, we first reduce the dimensions of the original scheduling problem by mapping it into an augmented set cover problem with spatio-temporal constraints. Then, based on reverse combinatorial auctions, we design Hector, whose incentive mechanism with the presence of uncertain future trajectory information makes scheduling and compensation decisions in real-time. Specifically, Hector is truthful , individual rational and computationally efficient . Furthermore, the social cost yielded by Hector is close-to-optimal, and the approximation ratio is H_m\n. The advantageous properties of Hector are verified by both rigorous theoretical analysis and extensive simulations based on the real world datasets in the Chinese city Shenzhen which consists of 726,000 taxi trajectories.}
}


@article{DBLP:journals/tmc/SunCWSYLC21,
	author = {Lichao Sun and
                  Bokai Cao and
                  Ji Wang and
                  Witawas Srisa{-}an and
                  Philip S. Yu and
                  Alex D. Leow and
                  Stephen Checkoway},
	title = {Kollector: Detecting Fraudulent Activities on Mobile Devices Using
                  Deep Learning},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {4},
	pages = {1465--1476},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2964226},
	doi = {10.1109/TMC.2020.2964226},
	timestamp = {Tue, 13 Dec 2022 09:59:50 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/SunCWSYLC21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the rapid growth in smartphone usage, preventing leakage of personal information and privacy has become a challenging task. One major consequence of such leakage is impersonation. This type of illegal usage is nearly impossible to prevent as existing preventive mechanisms (e.g., passcode and fingerprinting), are not capable of continuously monitoring usage and determining whether the user is authorized. Once unauthorized users can defeat the initial protection mechanisms, they would have full access to the devices including using stored passwords to access high-value websites. We present Kollector, a new framework to detect impersonation based on a multi-view bagging deep learning approach to capture sequential tapping information on the smart-phone's keyboard. We construct a sequential-tapping biometrics model to continuously authenticate the user while typing. We empirically evaluated our system using real-world phone usage sessions from 26 users over eight weeks. We then compared our model against commonly used shallow machine techniques and find that our system performs better than other approaches and can achieve an 8.42 percent equal error rate, a 94.24 percent accuracy and a 94.41 percent H-mean using only the accelerometer and only five keyboard taps. We also experiment with using only three keyboard taps and find that the system still yields high accuracy while giving additional opportunities to make more decisions that can result in more accurate final decisions.}
}


@article{DBLP:journals/tmc/KhoramnejadRPHV21,
	author = {Fahime Khoramnejad and
                  Mehdi Rasti and
                  Hossein Pedram and
                  Ekram Hossain and
                  Shahrokh Valaee},
	title = {Load Management, Power and Admission Control in Downlink Cellular
                  {OFDMA} Networks},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {4},
	pages = {1477--1493},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2962126},
	doi = {10.1109/TMC.2019.2962126},
	timestamp = {Tue, 23 Aug 2022 09:19:57 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/KhoramnejadRPHV21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We present a resource management framework for load-coupled downlink cellular OFDMA networks considering the load factor of an individual base station (BS) per resource block (RB), i.e., the number of adjacent sub-carriers (SCs), as the variable of interest in the resource management problem. The load factor of a BS per RB, which corresponds to the fraction of active SCs in the BS per RB, is an indicator of the level of resource consumption, and it affects the interference caused to that RB reused in other BSs, and thereby, results in a load-coupled OFDMA system. We first propose two distributed schemes to minimize: (i) the total load factor of the BSs (which would in turn increase the number of supportable users in the system), and (ii) the total downlink transmit power level of the BSs. Then, we derive the necessary and sufficient conditions for checking the feasibility of given target-rate requirements (also referred to as demand vector) for users. Accordingly, an iterative and distributed scheme is proposed to check the feasibility of a given demand vector. Next, for a priority-based load-coupled network, we propose a priority-based gradual removal algorithm to support the maximal number of low-priority users while satisfying the demands of the high-priority users. To evaluate the performance of our proposed schemes for resource management and admission control in load-coupled OFDMA networks, the theoretical investigations are complemented with Monte Carlo simulations.}
}


@article{DBLP:journals/tmc/LiZ21,
	author = {Xin Li and
                  Xinglin Zhang},
	title = {Multi-Task Allocation Under Time Constraints in Mobile Crowdsensing},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {4},
	pages = {1494--1510},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2962457},
	doi = {10.1109/TMC.2019.2962457},
	timestamp = {Sun, 06 Aug 2023 20:51:04 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/LiZ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Mobile crowdsensing (MCS) is a popular paradigm to collect sensed data for numerous sensing applications. With the increment of tasks and workers in MCS, it has become indispensable to design efficient task allocation schemes to achieve high performance for MCS applications. Many existing works on task allocation focus on single-task allocation, which is inefficient in many MCS scenarios where workers are able to undertake multiple tasks. On the other hand, many tasks are time-limited, while the available time of workers is also limited. Therefore, time validity is essential for both tasks and workers. To accommodate these challenges, this paper proposes a multi-task allocation problem with time constraints, which investigates the impact of time constraints to multi-task allocation and aims to maximize the utility of the MCS platform. We first prove that this problem is NP-complete. Then two evolutionary algorithms are designed to solve this problem. Finally, we conduct the experiments based on synthetic and real-world datasets under different experiment settings. The results verify that the proposed algorithms achieve more competitive and stable performance compared with baseline algorithms.}
}


@article{DBLP:journals/tmc/RostamiHPLV21,
	author = {Soheil Rostami and
                  Kari Heiska and
                  Oleksandr Puchko and
                  Kari Lepp{\"{a}}nen and
                  Mikko Valkama},
	title = {Novel Wake-up Scheme for Energy-Efficient Low-Latency Mobile Devices
                  in 5G Networks},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {4},
	pages = {1511--1528},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2964218},
	doi = {10.1109/TMC.2020.2964218},
	timestamp = {Wed, 16 Mar 2022 23:53:44 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/RostamiHPLV21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Improved mobile device battery lifetime and latency minimization are critical requirements for enhancing the mobile broadband services and user experience. Long-term evolution (LTE) networks have adopted discontinuous reception (DRX) as the baseline solution for prolonged battery lifetime. However, in every DRX cycle, the mobile device baseband processing unit monitors and decodes the control signaling, and thus, all instances without any actual data allocation leads to unnecessary energy consumption. This fact together with the long start-up and power-down times can prevent adopting frequent wake-up instants, which, in turn, leads to considerable latency. In this work, a novel wake-up scheme is described and studied, to tackle the trade-off between latency and battery lifetime in future 5G networks, seeking thus to facilitate an always-available experience, rather than always-on. Analytical and simulation-based results show that the proposed scheme is a promising approach to control the user plane latency and energy consumption, when the device is operating in the power saving mode. The aim of this article is to describe the overall wake-up system operating principle and the associated signaling methods, receiver processing solutions and essential implementation aspects. Additionally, the advantages compared to DRX-based systems are shown and demonstrated, through the analysis of the system energy-efficiency and latency characteristics, with special emphasis on future 5G-grade mobile devices.}
}


@article{DBLP:journals/tmc/HuangMQW21,
	author = {Baoqi Huang and
                  Guoqiang Mao and
                  Yong Qin and
                  Yun Wei},
	title = {Pedestrian Flow Estimation Through Passive WiFi Sensing},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {4},
	pages = {1529--1542},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2959610},
	doi = {10.1109/TMC.2019.2959610},
	timestamp = {Tue, 23 Mar 2021 14:13:20 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/HuangMQW21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In public places, even if pedestrians do not have their mobile devices connected with any WiFi access point (AP), WiFi probe requests will be broadcast, so that WiFi sniffers can be employed to crowdsource these WiFi probe packets for use. This paper tackles the problem of exploiting the passive WiFi sensing approach for pedestrian flow analysis. To be specific, a passive WiFi sensing model is first established based on a probabilistic analysis of interactions between WiFi sniffers and the moving pedestrian flow, capturing the main factors affecting pedestrian flow characteristics. On that basis, a sequential filtering algorithm is proposed based on the Rao-Blackwellized particle filter (RBPF) to produce simultaneous and efficient estimates of the pedestrian flow speed and pedestrian number utilizing the real-time sniffing results. In order to validate this study, an experimental pedestrian surveillance system using WiFi sniffers is deployed at the transfer channel of a metro station in Guangzhou, China. Extensive experiments are conducted to verify the passive sensing model, and confirm the effectiveness and advantages of the proposed algorithm. The pedestrian flow estimation not only helps to improve the safety and facility management and customer services, but also paves the way for introducing other novel applications.}
}


@article{DBLP:journals/tmc/SahaAALPSSKWH21,
	author = {Swetank Kumar Saha and
                  Shivang Aggarwal and
                  Hany Assasa and
                  Adrian Loch and
                  Naveen Muralidhar Prakash and
                  Roshan Shyamsunder and
                  Daniel Steinmetzer and
                  Dimitrios Koutsonikolas and
                  Joerg Widmer and
                  Matthias Hollick},
	title = {Performance and Pitfalls of 60 GHz WLANs Based on Consumer-Grade Hardware},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {4},
	pages = {1543--1557},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2967386},
	doi = {10.1109/TMC.2020.2967386},
	timestamp = {Tue, 23 Mar 2021 14:13:20 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/SahaAALPSSKWH21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Wireless networks operating in the 60 GHz band have the potential to provide very high throughput but face a number of challenges (e.g., high attenuation, beam training, and coping with mobility) which are widely accepted but often not well understood in practice. Understanding these challenges, and especially their actual impact on consumer-grade hardware is fundamental to fully exploit the high physical layer rates in the 60 GHz band. To this end, we perform an extensive measurement campaign using two commercial off-the-shelf 60 GHz routers in real-world environments. Our results allow us to revisit a range of issues and provide much deeper insights into the reasons for specific performance compared to prior work on performance characterization. Further, our study goes beyond basic link characterization and explores for the first time practical considerations such as coverage and access point deployment. While some of our observations are expected, we also obtain highly surprising insights that challenge the prevailing wisdom in the community. We derive the shortcomings of current commercial 60 GHz devices, and the fundamental problems that remain open on the way to fast and efficient 60 GHz networking.}
}


@article{DBLP:journals/tmc/Prados-GarzonAR21,
	author = {Jonathan Prados{-}Garzon and
                  Pablo Ameigeiras and
                  Juan J. Ramos{-}Mu{\~{n}}oz and
                  Jorge Navarro{-}Ortiz and
                  Pilar Andres{-}Maldonado and
                  Juan M. L{\'{o}}pez{-}Soler},
	title = {Performance Modeling of Softwarized Network Services Based on Queuing
                  Theory With Experimental Validation},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {4},
	pages = {1558--1573},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2962488},
	doi = {10.1109/TMC.2019.2962488},
	timestamp = {Tue, 23 Mar 2021 14:13:21 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/Prados-GarzonAR21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Network Functions Virtualization facilitates the automation of the scaling of softwarized network services (SNSs). However, the realization of such a scenario requires a way to determine the needed amount of resources so that the SNSs performance requisites are met for a given workload. This problem is known as resource dimensioning, and it can be efficiently tackled by performance modeling. In this vein, this paper describes an analytical model based on an open queuing network of G/G/m queues to evaluate the response time of SNSs. We validate our model experimentally for a virtualized Mobility Management Entity (vMME) with a three-tiered architecture running on a testbed that resembles a typical data center virtualization environment. We detail the description of our experimental setup and procedures. We solve our resulting queueing network by using the Queueing Networks Analyzer (QNA), Jackson's networks, and Mean Value Analysis methodologies, and compare them in terms of estimation error. Results show that, for medium and high workloads, the QNA method achieves less than half of error compared to the standard techniques. For low workloads, the three methods produce an error lower than 10 percent. Finally, we show the usefulness of the model for performing the dynamic resource provisioning of the vMME experimentally.}
}


@article{DBLP:journals/tmc/FelembanMKLRCP21,
	author = {Noor Felemban and
                  Fidan Mehmeti and
                  Hana Khamfroush and
                  Zongqing Lu and
                  Swati Rallapalli and
                  Kevin S. Chan and
                  Thomas La Porta},
	title = {PicSys: Energy-Efficient Fast Image Search on Distributed Mobile Networks},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {4},
	pages = {1574--1589},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2963150},
	doi = {10.1109/TMC.2019.2963150},
	timestamp = {Tue, 23 Mar 2021 14:13:20 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/FelembanMKLRCP21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Mobile devices collect a large amount of visual data that are useful for many applications. Searching for an object of interest over a network of mobile devices can aid human analysts in a variety of situations. However, processing the information on these devices is a challenge owing to the high computational complexity of the state-of-the-art computer vision algorithms that primarily rely on Convolutional Neural Networks (CNNs). Thus, this paper builds PicSys, a system that enables answering visual search queries on a mobile network. The objective of the system is to minimize the maximum completion time over all devices while taking into account the energy consumption of mobile devices as well. First, PicSys carefully divides the computation into multiple filtering stages, such that only a small percentage of images need to run the entire CNN pipeline. Splitting such CNN computation into multiple stages requires understanding the intermediate CNN features and systematically trading off accuracy for the computation speed. Second, PicSys determines where to run each of the stages of the multi-stage pipeline to fully utilize the available resources. Finally, through extensive experimentation, system implementation, and simulation, we show that PicSys performance is close to optimal and significantly outperforms other standard algorithms.}
}


@article{DBLP:journals/tmc/HeZJYZL21,
	author = {Yuan He and
                  Yilun Zheng and
                  Meng Jin and
                  Songzhen Yang and
                  Xiaolong Zheng and
                  Yunhao Liu},
	title = {{RED:} RFID-Based Eccentricity Detection for High-Speed Rotating Machinery},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {4},
	pages = {1590--1601},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2962770},
	doi = {10.1109/TMC.2019.2962770},
	timestamp = {Tue, 20 Dec 2022 21:20:07 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/HeZJYZL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Eccentricity detection is a crucial issue for high-speed rotating machinery, which concerns the stability and safety of the machinery. Conventional techniques in industry for eccentricity detection are mainly based on measuring certain physical indicators, which are costly and hard to deploy. In this paper, we propose RED, a non-intrusive, low-cost, and real-time RFID-based eccentricity detection approach. Differing from the existing RFID-based sensing approaches, RED utilizes the temporal and phase distributions of tag readings as effective features for eccentricity detection. RED includes a Markov chain based model called RUM, which only needs a few sample readings from the tag to make a highly accurate and precise judgement. The design of RED further addresses practical issues, such as parameterizing the RUM model, making it robust to dynamic and noisy environments, and considering how the doppler shift may affect our system. We implement RED with COTS RFID reader and tags, and evaluate its performance across various scenarios. The overall accuracy is 93.6 percent and the detection latency is 0.68 seconds in average.}
}


@article{DBLP:journals/tmc/LiangMZL21,
	author = {Wei Liang and
                  Chaofan Ma and
                  Meng Zheng and
                  Longxiang Luo},
	title = {Relay Node Placement in Wireless Sensor Networks: From Theory to Practice},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {4},
	pages = {1602--1613},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2962674},
	doi = {10.1109/TMC.2019.2962674},
	timestamp = {Tue, 23 Mar 2021 14:13:20 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/LiangMZL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The increasingly wide utilization of Wireless Sensor Networks (WSNs) in industrial applications outstands the significance of the Delay Constrained Relay Node Placement (DCRNP) problem. Existing algorithms to the DCRNP problem are designed based on the ideal geometric disk wireless channel model, and no real-world deployments are performed to verify the effectiveness of these algorithms. However, the unreliable and unpredictable wireless links in WSNs may lead these algorithms to fail in practice. Therefore, we first conduct extensive real-world deployments under the guidance of existing algorithms to evaluate their performance and to gain some insights for designing practical deployment algorithms. The results exhibit that the WSNs built by existing algorithms have a favorable performance in end-to-end delay but a poor performance in reliability, which is mainly due to the lack of methods ensuring high-quality links. To this end, we first devise a Set-Covering-based Algorithm (SCA) which figures out the DCRNP problem while ensuring the quality of each link better than a given threshold. As our experiments also show that the fault-tolerant topology can significantly improve network reliability, we then design a k-Set-Covering-based Algorithm (kSCA) to build fault-tolerant WSNs based on the methodology of SCA. Furthermore, the elaborate analysis proves that both SCA and kSCA are polynomial-time algorithms, and their approximation ratios are both O(ln n), where n is the number of sensor nodes. Finally, extensive experiments are performed under the guidance of SCA and kSCA to demonstrate the effectiveness of these two algorithms.}
}


@article{DBLP:journals/tmc/LiAYYL21,
	author = {Ping Li and
                  Zhenlin An and
                  Lei Yang and
                  Panlong Yang and
                  Qiongzheng Lin},
	title = {{RFID} Harmonic for Vibration Sensing},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {4},
	pages = {1614--1626},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2963152},
	doi = {10.1109/TMC.2019.2963152},
	timestamp = {Tue, 23 Mar 2021 14:13:21 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/LiAYYL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Conventional vibration sensing systems, equipped with specific sensors (e.g., accelerometer) and communication modules, are either expensive or cumbersome to deploy. Recently research community revisits this classic topic by taking advantage of off-the-shelf RFIDs. However, limited by low reading rate and long wavelength, current RFID based solutions can only sense low-frequency (e.g., below 100 Hz) mechanical vibrations with larger amplitude (e.g., >5 mm). To address the issue, this work presents TagSound, an RFID-based vibration sensing system that explores a tag's harmonic backscattering to recover high-frequency and tiny mechanical vibrations accurately. The key innovations are in two aspects: harmonics based sensingand a newrecovery scheme. We implement TagSound with USRP platforms. Our comprehensive evaluation shows (i) TagSound can achieve a mean error of 0.37 Hz when detecting vibrations at frequencies below 100 Hz, and a mean error of 4.2 Hz even when the vibration frequency is up to 2500 Hz. (ii) TagSound can achieve a Hz-level frequency estimation even when the vibration amplitude is only 2 mm.}
}


@article{DBLP:journals/tmc/ErogluAGP21,
	author = {Yusuf Said Eroglu and
                  Chethan Kumar Anjinappa and
                  Ismail G{\"{u}}ven{\c{c}} and
                  Nezih Pala},
	title = {Slow Beam Steering and {NOMA} for Indoor Multi-User Visible Light
                  Communications},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {4},
	pages = {1627--1641},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2960495},
	doi = {10.1109/TMC.2019.2960495},
	timestamp = {Tue, 23 Mar 2021 14:13:20 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/ErogluAGP21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Visible light communication (VLC) is an emerging technology that enables broadband data rates using the visible spectrum. In this paper, considering slow beam steering where VLC beam directions are assumed to be fixed during a transmission frame, we find the steering angles that simultaneously serve multiple users within the frame duration and maximize the data rates. This is achieved by solving a non-convex optimization problem using a grid-based search and majorization-minimization (MM) procedure. Subsequently, we consider multiple steerable beams with a larger number of users in the network and propose an algorithm to cluster users and serve each cluster with a separate beam. We optimize the transmit power of each beam to maximize the data rates. Finally, we propose a non-orthogonal multiple access (NOMA) scheme for the beam steering and user clustering scenario, to further increase the data rates of the users. The simulation results show that the proposed beam steering method can efficiently serve a high number of users, and with power optimization, a sum rate gain up to thirteen times is possible. The simulation results for NOMA suggests an additional 10 Mbps sum rate gain for each NOMA user pair.}
}


@article{DBLP:journals/tmc/KimuraS21,
	author = {Tatsuaki Kimura and
                  Hiroshi Saito},
	title = {Spatio-Temporal Correlation of Interference in {MANET} Under Spatially
                  Correlated Shadowing Environment},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {4},
	pages = {1642--1655},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2959990},
	doi = {10.1109/TMC.2019.2959990},
	timestamp = {Tue, 23 Mar 2021 14:13:20 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/KimuraS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Correlation of interference affects spatio-temporal aspects of various wireless mobile systems, such as retransmission, multiple antennas and cooperative relaying. In this paper, we study the spatial and temporal correlation of interference in mobile ad-hoc networks under a correlated shadowing environment. By modeling the node locations as a Poisson point process with an i.i.d. mobility model and considering Gudmundson (1991)'s spatially correlated shadowing model, we theoretically analyze the relationship between the correlation distance of log-normal shadowing and the spatial and temporal correlation coefficients of interference. Since the exact expressions of the correlation coefficients are intractable, we obtain their simple asymptotic expressions as the variance of log-normal shadowing increases. We found in our numerical examples that the asymptotic expansions can be used as tight approximate formulas and useful for modeling general wireless systems under spatially correlated shadowing.}
}


@article{DBLP:journals/tmc/ZhouWYLJCW21,
	author = {Man Zhou and
                  Qian Wang and
                  Jingxiao Yang and
                  Qi Li and
                  Peipei Jiang and
                  Yanjiao Chen and
                  Zhibo Wang},
	title = {Stealing Your Android Patterns via Acoustic Signals},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {4},
	pages = {1656--1671},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2960778},
	doi = {10.1109/TMC.2019.2960778},
	timestamp = {Mon, 01 May 2023 13:02:08 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/ZhouWYLJCW21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Pattern lock is an essential authentication method on mobile devices. Recent works on cracking pattern locks either require additional network facilities (e.g., WiFi hotspots) or suffer from strict constraints (e.g., physical closeness to the victim and good lighting). Being too susceptible to environment settings, these attacks are less effective in practice and cannot scale to a large number of users. To address these concerns, in this paper, we propose PatternListener+, a practical attack on pattern locks using the speakers and microphones on mobile devices. The speaker plays inaudible acoustic signals, which are reflected by the fingertip when the victim is drawing the pattern, and then recorded by the microphone. The recorded acoustic signals contain rich information of the fingertip motion that can be leveraged to infer the pattern. We carefully design a series of algorithms to eliminate the dynamic and static interferences, segment acoustic signals into fragments corresponding to all pattern lines, and recover each line composed of the pattern according to the signals. Finally, we recover the candidate pattern by mapping all line candidates into grid patterns with a tree structure. We implement a PatternListener+ prototype using off-the-shelf smartphones, and extensive experiments confirm the effectiveness and robustness of PatternListener+. The attack success rate is over 90 percent on 120 patterns in five attempts.}
}


@article{DBLP:journals/tmc/GaoZZS21,
	author = {Jie Gao and
                  Shan Zhang and
                  Lian Zhao and
                  Xuemin Shen},
	title = {The Design of Dynamic Probabilistic Caching with Time-Varying Content
                  Popularity},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {4},
	pages = {1672--1684},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2967038},
	doi = {10.1109/TMC.2020.2967038},
	timestamp = {Tue, 21 Mar 2023 21:12:55 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/GaoZZS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we design dynamic probabilistic caching for the scenario when the instantaneous content popularity may vary with time while it is possible to predict the average content popularity over a time window. Based on the average content popularity, optimal content caching probabilities can be found, e.g., from solving optimization problems, and existing results in the literature can implement the optimal caching probabilities via static content placement. The objective of this work is to design dynamic probabilistic caching that: i) converge (in distribution) to the optimal content caching probabilities under time-invariant content popularity, and ii) adapt to the time-varying instantaneous content popularity under time-varying content popularity. Achieving the above objective requires a novel design of dynamic content replacement because static caching cannot adapt to varying content popularity while classic dynamic replacement policies, such as LRU, cannot converge to target caching probabilities (as they do not exploit any content popularity information). We model the design of dynamic probabilistic replacement policy as the problem of finding the state transition probability matrix of a Markov chain and propose a method to generate and refine the transition probability matrix. Extensive numerical results are provided to validate the effectiveness of the proposed design.}
}


@article{DBLP:journals/tmc/ZhaoLWLC21,
	author = {Tianming Zhao and
                  Jian Liu and
                  Yan Wang and
                  Hongbo Liu and
                  Yingying Chen},
	title = {Towards Low-Cost Sign Language Gesture Recognition Leveraging Wearables},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {4},
	pages = {1685--1701},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2962760},
	doi = {10.1109/TMC.2019.2962760},
	timestamp = {Tue, 23 Mar 2021 14:13:21 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/ZhaoLWLC21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Different from traditional gestures, sign language gestures involve a lot of finger-level gestures without wrist or arm movements. They are hard to detect using existing motion sensors-based approaches. We introduce the first low-cost sign language gesture recognition system that can differentiate fine-grained finger movements using the Photoplethysmography (PPG) and motion sensors in commodity wearables. By leveraging the motion artifacts in PPG, our system can accurately recognize sign language gestures when there are large body movements, which cannot be handled by the traditional motion sensor-based approaches. We further explore the feasibility of using both PPG and motion sensors in wearables to improve the sign language gesture recognition accuracy when there are limited body movements. We develop a gradient boost tree (GBT) model and deep neural network-based model (i.e., ResNet) for classification. The transfer learning technique is applied to ResNet-based model to reduce the training effort. We develop a prototype using low-cost PPG and motions sensors and conduct extensive experiments and collect over 7000 gestures from 10 adults in the static and body-motion scenarios. Results demonstrate that our system can differentiate nine finger-level gestures from the American Sign Language with an average recognition accuracy over 98 percent.}
}


@article{DBLP:journals/tmc/DingLCMLZ21,
	author = {Ming Ding and
                  David L{\'{o}}pez{-}P{\'{e}}rez and
                  Youjia Chen and
                  Guoqiang Mao and
                  Zihuai Lin and
                  Albert Y. Zomaya},
	title = {Ultra-Dense Networks: {A} Holistic Analysis of Multi-Piece Path Loss,
                  Antenna Heights, Finite Users and {BS} Idle Modes},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {4},
	pages = {1702--1713},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2960223},
	doi = {10.1109/TMC.2019.2960223},
	timestamp = {Tue, 23 Mar 2021 14:13:21 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/DingLCMLZ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We discover a new capacity scaling law in ultra-dense networks under practical system assumptions, such as a general multi-piece path loss model, a non-zero base station to user equipment antenna height difference, and a finite user equipment density. The intuition and implication of this new capacity scaling law are completely different from those found in the year 2011. That law indicated that the increase of the interference power caused by a denser network would be exactly compensated by the increase of the signal power due to the reduced distance between transmitters and receivers, and thus, network capacity should grow linearly with network densification. However, we find that both the signal and interference powers become bounded in practical ultra-dense networks, which leads to a constant capacity scaling law. Moreover, our new discovery on the constant capacity scaling law indicates three network optimization problems respectively for base station deployment, user equipment scheduling and base station coordination. These three optimization problems are justified and solved in this paper, shedding new light on the deployment and optimization of ultra-dense networks.}
}


@article{DBLP:journals/tmc/HanXYZCL21,
	author = {Fei Han and
                  Lei Xie and
                  Yafeng Yin and
                  Hao Zhang and
                  Guihai Chen and
                  Sanglu Lu},
	title = {Video Stabilization for Camera Shoot in Mobile Devices via Inertial-Visual
                  State Tracking},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {4},
	pages = {1714--1729},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2961313},
	doi = {10.1109/TMC.2019.2961313},
	timestamp = {Wed, 17 Jul 2024 17:18:23 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/HanXYZCL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Due to the sudden movement during the camera shoot, the videos retrieved from the hand-held mobile devices often suffer from undesired frame jitters, leading to the loss of video quality. In this paper, we present a video stabilization solution in mobile devices via inertial-visual state tracking. Specifically, during the video shoot, we use the gyroscope to estimate the rotation of camera, and use the structure-from-motion among the image frames to estimate the translation of camera. We build a camera projection model by considering the rotation and translation of the camera, and the camera motion model to depict the relationship between the inertial-visual state and the camera's 3D motion. By fusing the inertial measurement (IMU)-based method and the computer vision (CV)-based method, our solution is robust to the fast movement and violent jitters, moreover, it greatly reduces the computation overhead in video stabilization. In comparison to the IMU-based solution, our solution can estimate the translation in a more accurate manner, since we use the feature point pairs in adjacent image frames, rather than the error-prone accelerometers, to estimate the translation. In comparison to the CV-based solution, our solution can estimate the translation with less number of feature point pairs, since the number of undetermined degrees of freedom in the 3D motion directly reduces from 6 to 3. We implemented a prototype system on smart glasses and smart phones, and evaluated the performance under real scenarios, i.e., the human subjects used mobile devices to shoot videos while they were walking, climbing or riding. The experiment results show that our solution achieves 32 percent better performance than the state-of-art solutions in regard to video stabilization. Moreover, the average processing time latency is 32.6ms, which is lower than the conventional inter-frame time interval, i.e., 33ms, and thus meets the real-time requirement for online processing.}
}


@article{DBLP:journals/tmc/WangSDWHLWG21,
	author = {Lei Wang and
                  Ke Sun and
                  Haipeng Dai and
                  Wei Wang and
                  Kang Huang and
                  Alex X. Liu and
                  Xiaoyu Wang and
                  Qing Gu},
	title = {WiTrace: Centimeter-Level Passive Gesture Tracking Using {OFDM} Signals},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {4},
	pages = {1730--1745},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2019.2961885},
	doi = {10.1109/TMC.2019.2961885},
	timestamp = {Fri, 11 Nov 2022 12:59:50 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/WangSDWHLWG21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Gesture tracking is a basic Human-Computer Interaction mechanism to control devices, such as IoT and VR/AR devices. However, prior OFDM signal based systems focus on gesture recognition and provide results with insufficient accuracy, and thus, cannot be applied for high-precision gesture tracking. In this paper, we propose a CSI based device-free gesture tracking system, called WiTrace, which leverages the CSI values extracted from OFDM signals to enable accurate gesture tracking. For 1D tracking, WiTrace derives the phase of the signals reflected by the hand from the composite signals, and measures the phase changes to obtain the movement distance. For 2D tracking, WiTrace proposes the first CSI based scheme to accurately estimate the initial position, and adopts the Kalman Filter based on continuous Wiener process acceleration model to further filter out tracking noise. Our results show that WiTrace achieves an average accuracy of 6.23 cm for initial position estimation and achieves cm-level accuracy with average tracking errors of 1.46 cm and 2.09 cm for 1D tracking and 2D tracking, respectively.}
}


@article{DBLP:journals/tmc/WangQSDHCXZ21,
	author = {Ge Wang and
                  Chen Qian and
                  Longfei Shangguan and
                  Han Ding and
                  Jinsong Han and
                  Kaiyan Cui and
                  Wei Xi and
                  Jizhong Zhao},
	title = {Corrections to "HMO: Ordering {RFID} Tags With Static Devices in Mobile
                  Environments"},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {4},
	pages = {1746},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2021.3050539},
	doi = {10.1109/TMC.2021.3050539},
	timestamp = {Fri, 21 Oct 2022 19:54:49 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/WangQSDHCXZ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Presents corrections to the acknowledgement section for the above named article.}
}


@article{DBLP:journals/tmc/GuptaGBD21,
	author = {Ashish Gupta and
                  Hari Prabhat Gupta and
                  Bhaskar Biswas and
                  Tanima Dutta},
	title = {A Fault-Tolerant Early Classification Approach for Human Activities
                  Using Multivariate Time Series},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {5},
	pages = {1747--1760},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2973616},
	doi = {10.1109/TMC.2020.2973616},
	timestamp = {Thu, 29 Apr 2021 15:13:53 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/GuptaGBD21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Activity classification has been an interesting area of research for many years, to better understand human behavior. Recent advancements in embedded computing systems allowed the emergence of several state-of-art solutions for human activity classification using sensors of a smartphone. The sensors generate temporal sequences of observations for human activity, which is called as Multivariate Time Series (MTS). Current state-of-art solutions for human activity classification suffer from two major limitations: first, the length of testing MTS should be equal to the training MTS and second, the MTS should not have any faulty time series. In real-time applications, it is desirable to classify a human activity using an incomplete MTS as early as possible. In this work, we propose a fault-tolerant early classification of MTS (FECM) approach to address these limitations. FECM builds a set of classification models using MTS training dataset. The approach employs Gaussian Process classifier to estimate minimum required length of time series, which is used to predict a class label of new MTS. Further, FECM uses an Auto Regressive Integrated Moving Average model to identify faulty time series in the new MTS. Finally, we conduct an experiment to evaluate the performance of FECM using accuracy and earliness metrics.}
}


@article{DBLP:journals/tmc/ChangCZHC21,
	author = {Shan Chang and
                  Hang Chen and
                  Hongzi Zhu and
                  Xinggang Hu and
                  Di Cao},
	title = {CoSafe: Securing Mobile Devices through Mutual Mobility Consistency
                  Verification},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {5},
	pages = {1761--1772},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2974222},
	doi = {10.1109/TMC.2020.2974222},
	timestamp = {Thu, 29 Apr 2021 15:13:53 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/ChangCZHC21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As mobile devices play increasingly important roles in our daily lives, it is of great significance to protect personal mobile devices from being lost. Noticing the trend that one person normally carries more than one mobile device, we propose an innovative scheme, called CoSafe , to detect device loss by verifying the motion consistency between a pair of devices. The rationale is that the vibrations perceived on devices carried by the same person should be tightly coupled whereas a lost device would show distinct mobility characteristics from others. Specifically, CoSafe compares the mobility consistency between a pair of devices on three levels, where coarse features (i.e., the mobility state and motion periodicity) are first compared to give fast response and more complex comparison on subtle feature (i.e., the relative phase) is conducted only when needed. In this way, CoSafe can instantly respond and introduce very low computation and communication costs. We implement CoSafe on a Commercial-Off-The-Shelf Android smartphone and a smartwatch, and conduct both trace-driven simulations and real-world experiments to evaluate the performance of CoSafe. The results show that CoSafe achieves a mean false negative ratio and false positive ratio of 1.46 and 3.12 percent, respectively, even under sophisticated stealing attacks.}
}


@article{DBLP:journals/tmc/ChenNYNWZ21,
	author = {Longbiao Chen and
                  Thi Mai Trang Nguyen and
                  Dingqi Yang and
                  Michele Nogueira and
                  Cheng Wang and
                  Daqing Zhang},
	title = {Data-Driven {C-RAN} Optimization Exploiting Traffic and Mobility Dynamics
                  of Mobile Users},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {5},
	pages = {1773--1788},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2971470},
	doi = {10.1109/TMC.2020.2971470},
	timestamp = {Thu, 29 Apr 2021 15:13:53 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/ChenNYNWZ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The surging traffic volumes and dynamic user mobility patterns pose great challenges for cellular network operators to reduce operational costs and ensure service quality. Cloud-radio access network (C-RAN) aims to address these issues by handling traffic and mobility in a centralized manner, separating baseband units (BBUs) from base stations (RRHs) and sharing BBUs in a pool. The key problem in C-RAN optimization is to dynamically allocate BBUs and map them to RRHs under cost and quality constraints, since real-world traffic and mobility are difficult to predict, and there are enormous numbers of candidate RRH-BBU mapping schemes. In this work, we propose a data-driven framework for C-RAN optimization. First, we propose a deep-learning-based Multivariate long short term memory (MuLSTM) model to capture the spatiotemporal patterns of traffic and mobility for accurate prediction. Second, we formulate RRH-BBU mapping with cost and quality objectives as a set partitioning problem, and propose a resource-constrained label-propagation (RCLP) algorithm to solve it. We show that the greedy RCLP algorithm is monotone suboptimal with worst-case approximation guarantee to optimal. Evaluations with real-world datasets from Ivory Coast and Senegal show that our framework achieves a BBU utilization above 85.2 percent, with over 82.3 percent of mobility events handled with high quality, outperforming the traditional and the state-of-the-art baselines.}
}


@article{DBLP:journals/tmc/WuYYZRL21,
	author = {Kaishun Wu and
                  Qiang Yang and
                  Baojie Yuan and
                  Yongpan Zou and
                  Rukhsana Ruby and
                  Mo Li},
	title = {EchoWrite: An Acoustic-Based Finger Input System Without Training},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {5},
	pages = {1789--1803},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2973094},
	doi = {10.1109/TMC.2020.2973094},
	timestamp = {Thu, 11 Aug 2022 13:29:14 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/WuYYZRL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recently, wearable devices have become increasingly popular in our lives because of their neat features and stylish appearance. However, their tiny sizes bring about new challenges to human-device interaction such as texts input. Although some novel methods have been put forward, they possess different defects and are not applicable to deal with the problem. As a result, we propose an acoustic-based texts-entry system, i.e., EchoWrite, by which texts can be entered with a finger writing in the air without wearing any additional device. More importantly, different from many previous works, EchoWrite runs in a training-free style which reduces the training overhead and improves system scalability. We implement EchoWrite with commercial devices and conduct comprehensive experiments to evaluate its texts-entry performance. Experimental results show that EchoWrite enables users to enter texts at a speed of 7.5 WPM without practice, and 16.6 WPM after about 30-minute practice. This speed is better than touch screen-based method on smartwatches, and comparable with previous related works. Moreover, EchoWrite provides favorable user experience of entering texts.}
}


@article{DBLP:journals/tmc/WangD21,
	author = {Xuehe Wang and
                  Lingjie Duan},
	title = {Economic Analysis of Unmanned Aerial Vehicle {(UAV)} Provided Mobile
                  Services},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {5},
	pages = {1804--1816},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2973088},
	doi = {10.1109/TMC.2020.2973088},
	timestamp = {Thu, 29 Apr 2021 15:13:53 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/WangD21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Due to its agility and mobility, the unmanned aerial vehicle (UAV) is a promising technology to provide high-quality mobile services (e.g., fast Internet access, edge computing, and local caching) to ground users. The Internet service providers (ISPs) directly or commission the third-party UAV firms to provide UAV-provided services (UPS) to improve and make up for the shortage of their current mobile services for additional profit. Yet the UAV has limited energy storage and needs to fly to serve users locally, requiring an optimal energy allocation for balancing both hovering time and service capacity. For profit-maximizing purpose, when hovering in a hotspot, how the UAV should dynamically price its capacity-limited UPS according to randomly arriving users with private service valuations is another question. This paper first introduce a threshold-based assignment policy to show how the UAV decides to serve the users or not under complete information that a user’s service valuation can be observed when he arrives. Following this benchmark, we analyze the UAV’s optimal pricing under incomplete information about the users’ random arrival and private service valuations. It is proved that the UAV should ask for a higher price if the leftover hovering time is longer or its service capacity is smaller, and its expected profit approaches to that under complete user information if the hovering time is sufficiently large. Then, based on the optimal pricing, the energy allocation to hovering time and service capacity in a hotspot is optimized. We show that as the hotspot’s user occurrence rate increases, a shorter hovering time or a larger service capacity should be allocated. Finally, when a UAV faces multiple hotspot candidates with different user occurrence rates and flying distances, we prove that it is optimal to deploy the UAV to serve a single hotspot, by taking the optimal pricing and energy allocation of each hotspot into consideration. With multiple UAVs, however, this result can be reversed with UAVs’ forking deployment to different hotspots, especially when hotspots are more symmetric or the UAV number is large. Perhaps surprisingly, more UAVs may be deployed to the second-best hotspot rather than the first-best one.}
}


@article{DBLP:journals/tmc/WangLWCC21,
	author = {Xia Wang and
                  Jia Liu and
                  Yanyan Wang and
                  Xingyu Chen and
                  Lijun Chen},
	title = {Efficient Tag Grouping via Collision Reconciliation and Data Compression},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {5},
	pages = {1817--1831},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2972386},
	doi = {10.1109/TMC.2020.2972386},
	timestamp = {Thu, 29 Apr 2021 15:13:53 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/WangLWCC21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In RFID systems, tag grouping is to inform each tag in the interrogator's RF field which group it belongs to by assigning them a group ID. With this information, the reader can write the same data into a group of tags in one transmission by taking their shared group ID as the destination address, which plays a vital role in improving inventory efficiency. Existing work proposes some efficient protocols but suffers from two defects: slot waste and data redundancy. To address these problems, we in this paper propose a two-phase grouping scheme that improves the grouping efficiency via slot reuse as well as data compression. For slot waste, we try to reconcile collision slots and turn some of them into useful again by re-assigning a new slot to collision tags, which increases the number of useful slots and reduces slot waste. For data redundancy, we encode group IDs with lossless coding algorithms and reduce the data redundancy caused by repetitive transmission of group IDs. Two coding methods, Huffman coding and arithmetic coding , are adopted to shorten the length of the bit vector comprised by group IDs. Theoretical analyses and extensive simulations show that our best protocol improves the time efficiency by 51.9 percent compared with the state-of-the-art.}
}


@article{DBLP:journals/tmc/YuZYZLCDL21,
	author = {Dongxiao Yu and
                  Yifei Zou and
                  Jiguo Yu and
                  Yong Zhang and
                  Feng Li and
                  Xiuzhen Cheng and
                  Falko Dressler and
                  Francis C. M. Lau},
	title = {Implementing The Abstract {MAC} Layer in Dynamic Networks},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {5},
	pages = {1832--1845},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2971599},
	doi = {10.1109/TMC.2020.2971599},
	timestamp = {Thu, 10 Mar 2022 09:31:32 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/YuZYZLCDL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Dynamicity is one of the most challenging, yet, key aspects of wireless networks. It can come in many guises, such as churn (node insertion/deletion) and node mobility. Although the study of dynamic networks has been popular in distributed computing domain, previous works considered only partial factors causing dynamicity. In this work, we propose a dynamic model that is comprehensive to include crucial dynamic factors on nodes and links. Our model defines dynamicity in terms of localized topological changes in the vicinity of each node, rather than a global view of the whole network. Obviously, a localized dynamic model suits distributed algorithm studies better than a global one. The proposed dynamic model makes use of the more realistic SINR model to describe wireless interference, instead of the oversimplified graph-based models adopted by most existing research. Under the proposed dynamic model, we develop an efficient distributed algorithm accomplishing local broadcast services in the abstract MAC layer that was first presented by Kuhn et al. [24] . Our solution paves the way for many new fast algorithms to solve high-level problems in dynamic networks, such as consensus, single-message broadcast, and multiple-message broadcast. Extensive simulation studies indicate that our algorithm exhibits good performance in realistic environments with dynamic network behaviors.}
}


@article{DBLP:journals/tmc/XuLJKXZ21,
	author = {Wenzheng Xu and
                  Weifa Liang and
                  Xiaohua Jia and
                  Haibin Kan and
                  Yinlong Xu and
                  Xinming Zhang},
	title = {Minimizing the Maximum Charging Delay of Multiple Mobile Chargers
                  Under the Multi-Node Energy Charging Scheme},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {5},
	pages = {1846--1861},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2973979},
	doi = {10.1109/TMC.2020.2973979},
	timestamp = {Thu, 29 Apr 2021 15:13:53 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/XuLJKXZ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Wireless energy charging has emerged as a very promising technology for prolonging sensor lifetime in wireless rechargeable sensor networks (WRSNs). Existing studies focused mainly on the one-to-one charging scheme that a single sensor can be charged by a mobile charger at each time, this charging scheme however suffers from poor charging scalability and inefficiency. Recently, another charging scheme, the multi-node charging scheme that allows multiple sensors to be charged simultaneously by a mobile charger, becomes dominant, which can mitigate charging scalability and improve charging efficiency. However, most previous studies on this multi-node energy charging scheme focused on the use of a single mobile charger to charge multiple sensors simultaneously. For large scale WRSNs, it is insufficient to deploy only a single mobile charger to charge many lifetime-critical sensors, and consequently sensor expiration durations will increase dramatically. To charge many lifetime-critical sensors in large scale WRSNs as early as possible, it is inevitable to adopt multiple mobile chargers for sensor charging that can not only speed up sensor charging but also reduce expiration times of sensors. This however poses great challenges to fairly schedule the multiple mobile chargers such that the longest charging delay among sensors is minimized. One important constraint is that no sensor can be charged by more than one mobile charger at any time due to the fact that the sensor cannot receive any energy from either of the chargers or the overcharging will damage the recharging battery of the sensor. Thus, finding a closed charge tour for each of the multiple chargers such that the longest charging delay is minimized is crucial. In this paper we address the challenge by formulating a novel longest charging delay minimization problem. We first show that the problem is NP-hard. We then devise the very first approximation algorithm with a provable approximation ratio for the problem. We finally evaluate the performance of the proposed algorithms through experimental simulations. Experimental results demonstrate that the proposed algorithm is promising, and outperforms existing algorithms in various settings.}
}


@article{DBLP:journals/tmc/XiaoYYZLD21,
	author = {Ning Xiao and
                  Panlong Yang and
                  Yubo Yan and
                  Hao Zhou and
                  Xiang{-}Yang Li and
                  Haohua Du},
	title = {Motion-Fi{\textdollar}{\^{}}+{\textdollar}+: Recognizing and Counting
                  Repetitive Motions With Wireless Backscattering},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {5},
	pages = {1862--1876},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2971996},
	doi = {10.1109/TMC.2020.2971996},
	timestamp = {Thu, 29 Apr 2021 15:13:53 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/XiaoYYZLD21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Driven by a wide range of real-world applications, several ground-breaking RF-based motion-recognition systems were proposed to detect and/or recognize macro/micro human movements. These systems often suffer from various interferences caused by multiple-users moving simultaneously, resulting in extremely low recognition accuracy. Even if the repetitive motions are fairly well detectable through the wireless signals in theory, in reality they get blended into various other system noises during the motion. Moreover, irregular motion patterns among users will lead to expensive computation cost for motion recognition. To tackle these challenges, we propose a novel wireless sensing system, called Motion-Fi$\\ ^+$+ , which marries battery-free wireless backscattering and device-free sensing in one clean sheet. Motion-Fi$\\ ^+$+ is an accurate, interference tolerable motion-recognition system, which counts repetitive motions without using scenario-dependent templates or profiles and enables multi-user performing certain motions simultaneously because of the relatively short transmission range of backscattered signals and dedicated signal separation method. We implement a backscattering wireless platform to validate our design in various scenarios for over 6 months when different persons, distances and orientations are incorporated. In our experiments, the periodicity in motions could be recognized without any learning or training process, and the accuracy of counting such motions can be achieved within 5 percent count error. With little efforts in learning the patterns, our method could achieve 95.2 percent motion-recognition accuracy for a variety of 7 typical motions. Moreover, by leveraging the periodicity of motions, the recognition accuracy could be further improved to nearly 100 percent with only three repetitions. Our experiments also show that the motions of multiple persons separating by around $ 2$ meters cause little accuracy reduction in the counting process.}
}


@article{DBLP:journals/tmc/BoukAEP21,
	author = {Safdar Hussain Bouk and
                  Syed Hassan Ahmed and
                  Yongsoon Eun and
                  Kyung{-}Joon Park},
	title = {Multimodal Named Data Discovery With Interest Broadcast Suppression
                  for Vehicular {CPS}},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {5},
	pages = {1877--1891},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2971479},
	doi = {10.1109/TMC.2020.2971479},
	timestamp = {Thu, 29 Apr 2021 15:13:53 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/BoukAEP21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cyber-physical system (CPS) provides a well-organized integration between communication , computation , and control (3C) technologies. CPS has been widely used in the vehicular networks and it requires to discover multimodal data from the physical system to make appropriate decisions and actions, for example, congestion warnings, applying brakes, adjusting speed limits, etc. Information discovery and availability at individual network elements is one of the fundamental foundations of CPS. In this paper, we proposed two multimodal network information discovery schemes for vehicular CPS using the Named Data Networking (NDN). One of the proposed schemes simply modifies the pull-based NDN communication mechanism to discover multimodal multi-hop data from the network and the other scheme uses the Interest broadcast suppression (IBS) mechanism. The proposed Interest broadcast suppression scheme adapts the holding time technique to defer the Interest forwarding and its computation involves the hop-count, distance, and other network parameters. Simulation results show that the proposed schemes discover about 172 and 162 percent more multimodal information from approximately 283 and 210 percent more network area by suppressing approximately 50 percent of the Interest broadcast storm in highway and the urban traffic scenarios, respectively.}
}


@article{DBLP:journals/tmc/XuGXLRW21,
	author = {Zichuan Xu and
                  Wanli Gong and
                  Qiufen Xia and
                  Weifa Liang and
                  Omer F. Rana and
                  Guowei Wu},
	title = {NFV-Enabled IoT Service Provisioning in Mobile Edge Clouds},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {5},
	pages = {1892--1906},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2972530},
	doi = {10.1109/TMC.2020.2972530},
	timestamp = {Thu, 29 Apr 2021 15:13:53 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/XuGXLRW21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Conventional Internet of Things (IoT) applications involve data capture from various sensors in environments, and the captured data then is processed in remote clouds. However, some critical IoT applications (e.g., autonomous vehicles) require a much lower response latency and more secure guarantees than those offered by remote clouds today. Mobile edge clouds (MEC) supported by the network function virtualization (NFV) technique have been envisioned as an ideal platform for supporting such IoT applications. Specifically, MECs enable to handle IoT applications in edge networks to shorten network latency, and NFV enables agile and low-cost network functions to run in low-cost commodity servers as virtual machines (VMs). One fundamental problem for the provisioning of IoT applications in an NFV-enabled MEC is where to place virtualized network functions (VNFs) for IoT applications in the MEC, such that the operational cost of provisioning IoT applications is minimized. In this paper, we first address this fundamental problem, by considering a special case of the IoT application placement problem, where the IoT application and VNFs of each service request are consolidated into a single location (gateway or cloudlet), for which we propose an exact solution and an approximation algorithm with a provable approximation ratio. We then develop a heuristic algorithm that controls the resource violation ratios of edge clouds in the network. For the IoT application placement problem for IoT applications where their VNFs can be placed to multiple locations, we propose an efficient heuristic that jointly places the IoT application and its VNFs. We finally study the performance of the proposed algorithms by simulations and implementations in a real test-bed, Experimental results show that the performance of the proposed algorithms outperform their counterparts by at least 10 percent.}
}


@article{DBLP:journals/tmc/DengXTKYZD21,
	author = {Shuiguang Deng and
                  Zhengzhe Xiang and
                  Javid Taheri and
                  Mohammad Ali Khoshkholghi and
                  Jianwei Yin and
                  Albert Y. Zomaya and
                  Schahram Dustdar},
	title = {Optimal Application Deployment in Resource Constrained Distributed
                  Edges},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {5},
	pages = {1907--1923},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2970698},
	doi = {10.1109/TMC.2020.2970698},
	timestamp = {Thu, 29 Apr 2021 15:13:53 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/DengXTKYZD21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The dramatically increasing of mobile applications make it convenient for users to complete complex tasks on their mobile devices. However, the latency brought by unstable wireless networks and the computation failures caused by constrained resources limit the development of mobile computing. A popular approach to solve this problem is to establish a mobile service provisioning system based on a mobile edge computing (MEC) paradigm. In the MEC paradigm, plenty of machines are placed at the edge of the network so that the performance of applications can be optimized by using the involved microservice instances deployed on them. In this paper, we explore the deployment problem of microserivce-based applications in the MEC environment and propose an approach to help to optimize the cost of application deployment with the constraints of resources and the requirement of performance. We conduct a series of experiments to evaluate the performance of our approach. The result shows that our approach can improve the average response time of mobile services.}
}


@article{DBLP:journals/tmc/ZhaoTLZ21,
	author = {Bowen Zhao and
                  Shaohua Tang and
                  Ximeng Liu and
                  Xinglin Zhang},
	title = {{PACE:} Privacy-Preserving and Quality-Aware Incentive Mechanism for
                  Mobile Crowdsensing},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {5},
	pages = {1924--1939},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2973980},
	doi = {10.1109/TMC.2020.2973980},
	timestamp = {Thu, 29 Apr 2021 15:13:53 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/ZhaoTLZ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Providing appropriate monetary rewards is an efficient way for mobile crowdsensing to motivate the participation of task participants. However, a monetary incentive mechanism is generally challenging to prevent malicious task participants and a dishonest task requester. Moreover, prior quality-aware incentive schemes are usually failed to preserve the privacy of task participants. Meanwhile, most existing privacy-preserving incentive schemes ignore the data quality of task participants. To tackle these issues, we propose a privacy-preserving and data quality-aware incentive scheme, called PACE. In particular, data quality consists of the reliability and deviation of data. Specifically, we first propose a zero-knowledge model of data reliability estimation that can protect data privacy while assessing data reliability. Then, we quantify the data quality based on the deviation between reliable data and the ground truth. Finally, we distribute monetary rewards to task participants according to their data quality. To demonstrate the effectiveness and efficiency of PACE, we evaluate it in a real-world dataset. The evaluation and analysis results show that PACE can prevent malicious behaviors of task participants and a task requester, and achieves both privacy-preserving and data quality measurement of task participants.}
}


@article{DBLP:journals/tmc/FiryagunaKGM21,
	author = {Fadhil Firyaguna and
                  Jacek Kibilda and
                  Carlo Galiotto and
                  Nicola Marchetti},
	title = {Performance Analysis of Indoor mmWave Networks With Ceiling-Mounted
                  Access Points},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {5},
	pages = {1940--1950},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2972282},
	doi = {10.1109/TMC.2020.2972282},
	timestamp = {Thu, 29 Apr 2021 15:13:53 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/FiryagunaKGM21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The objective of the Enhanced Mobile Broadband use case in 5G networks is to deliver high capacity access to densely populated areas, like city centres, transportation hubs or convention centres. Millimetre-wave communications are the go-to technology to realise that objective, yet due to weak outdoor-to-indoor penetration, outdoor deployments will not suffice and dedicated indoor deployments will be necessary. In this article, we study dense deployments of millimetre-wave access points mounted on the ceiling, with directional antennas pointing downwards to illuminate selected spots on the ground. In this setup, the signal propagation is primarily limited by human body blockages. Therefore, we develop a body blockage model and derive an expression for the probability of blockage. Using the developed expressions and our simulation framework, we assess the impact of densification and body blockage on the achievable performance. We find that both coverage and area spectral efficiency curves exhibit non-trivial behaviour with respect to the access point density and that there is an optimal beamwidth-density configuration that only maximises either coverage or area spectral efficiency. Such optimal configuration changes depending on the body blockage probability, leading to a necessity for network designers to carefully consider their intended application and scenario.}
}


@article{DBLP:journals/tmc/HuangZY21,
	author = {Qinlong Huang and
                  Zhicheng Zhang and
                  Yixian Yang},
	title = {Privacy-Preserving Media Sharing with Scalable Access Control and
                  Secure Deduplication in Mobile Cloud Computing},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {5},
	pages = {1951--1964},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2970705},
	doi = {10.1109/TMC.2020.2970705},
	timestamp = {Thu, 29 Apr 2021 15:13:53 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/HuangZY21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Benefiting from cloud computing and mobile devices, a huge number of media contents, such as videos are shared in mobile networks. Although scalable video coding can be utilized to provide flexible adaptation, the cloud poses a serious threat to media privacy. In this paper, we propose a privacy-preserving multi-dimensional media sharing scheme named SMACD in mobile cloud computing. First, each media layer is encrypted with an access policy based on attribute-based encryption, which guarantees media confidentiality as well as fine-grained access control. Then, we present a multi-level access policy construction with secret sharing scheme. It ensures that the mobile consumers who obtain a media layer at a higher access level must satisfy the access trees of its child layers at the lower access level, which is compatible with the characteristics of multi-dimensional media and also reduces the complexity of access policies. Moreover, we introduce decentralized key servers to achieve both intra-server and inter-server deduplication by associating different access policies into the same encrypted media. Finally, we conduct experimental evaluation on mobile device and cloud platform with real-world datasets. The results indicate that SMACD protects media privacy against cloud media center and unauthorized parties, while incurring less computational and storage cost.}
}


@article{DBLP:journals/tmc/LinNLG21,
	author = {Jiaping Lin and
                  Jianwei Niu and
                  Xuefeng Liu and
                  Mohsen Guizani},
	title = {Protecting Your Shopping Preference With Differential Privacy},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {5},
	pages = {1965--1978},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2972001},
	doi = {10.1109/TMC.2020.2972001},
	timestamp = {Sat, 31 Jul 2021 17:05:18 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/LinNLG21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Online banks may disclose consumers’ shopping preferences due to various attacks. With differential privacy, each consumer can disturb his consumption amount locally before sending it to online banks. However, directly applying differential privacy in online banks will incur problems in reality because existing differential privacy schemes do not consider handling the noise boundary problem. In this paper, we propose an Optimized Differential prIvate Online tRansaction scheme (O-DIOR) for online banks to set boundaries of consumption amounts with added noises. We then revise O-DIOR to design a RO-DIOR scheme to select different boundaries while satisfying the differential privacy definition. Moreover, we provide in-depth theoretical analysis to prove that our schemes are capable to satisfy the differential privacy constraint. Finally, to evaluate the effectiveness, we have implemented our schemes in mobile payment experiments. Experimental results illustrate that the relevance between the consumption amount and online bank amount is reduced significantly, and the privacy losses are less than 0.5 in terms of mutual information.}
}


@article{DBLP:journals/tmc/YangLCCZC21,
	author = {Yanbing Yang and
                  Jun Luo and
                  Chen Chen and
                  Zequn Chen and
                  Wen{-}De Zhong and
                  Liangyin Chen},
	title = {Pushing the Data Rate of Practical {VLC} via Combinatorial Light Emission},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {5},
	pages = {1979--1992},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2971204},
	doi = {10.1109/TMC.2020.2971204},
	timestamp = {Thu, 29 Apr 2021 15:13:53 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/YangLCCZC21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Visible light communication (VLC) systems relying on commercial-off-the-shelf (COTS) devices have gathered momentum recently, due to the pervasive adoption of LED lighting and mobile devices. However, the achievable throughput by such practical systems is still several orders below those claimed by controlled experiments with specialized devices. In this paper, we engineer CoLight aiming to boost the data rate of the VLC system purely built upon COTS devices. CoLight adopts COTS LEDs as its transmitter, but it innovates in its simple yet delicate driver circuit wiring an array of LED chips in a combinatorial manner. Consequently, modulated signals can directly drive the on-off procedures of individual chip groups, so that the spatially synthesized light emissions exhibit a varying luminance following exactly the modulation symbols. To obtain a readily usable receiver, CoLight interfaces a COTS PD with a smartphone through the audio jack, and it also has an alternative MCU-driven circuit to emulate a future integration into the phone. The evaluations on CoLight are both promising and informative: they demonstrate a throughput up to 80 kbps at a distance of 2 m, while suggesting various potentials to further enhance the performance.}
}


@article{DBLP:journals/tmc/BanWJ21,
	author = {Buri Ban and
                  Hongyi Wu and
                  Miao Jin},
	title = {Resilient Routing for Wireless Sensor Networks on High Genus Surfaces},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {5},
	pages = {1993--2006},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2974195},
	doi = {10.1109/TMC.2020.2974195},
	timestamp = {Thu, 29 Apr 2021 15:13:53 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/BanWJ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper considers a fundamental problem of designing routing scheme resilient to node or link failures for wireless sensor networks deployed on a surface of a complex-connected three-dimensional (3D) setting. Instead of heuristically detouring around the failed path, we borrow homotopy, an important topological concept, to effectively create and evaluate the diversity of alternative paths. We propose a tessellation-free and GPS-free method to compute paths with different homotopy types on surface networks. A source node greedily forwards a packet to its destination based on the computed nodes’ virtual planar coordinates. When the current path fails, the source node can flexibly choose another greedy path from a different homotopy type to deliver the packet. The proposed algorithms are distributed and scalable to both the size and genus number of a surface network. We evaluate the performance of the proposed routing scheme under three different failure models. Simulation results show that our method achieves the best performance under geographically correlated failure models compared with other resilient routing schemes. We also compare our routing scheme with existing state-of-the-art ones specifically designed for surface networks when a network is failure free. Our method achieves the lowest stretch factor.}
}


@article{DBLP:journals/tmc/AnLYG21,
	author = {Zhenlin An and
                  Qiongzheng Lin and
                  Lei Yang and
                  Yi Guo},
	title = {Revitalizing Ultrasonic Positioning Systems for Ultrasound-Incapable
                  Smart Devices},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {5},
	pages = {2007--2024},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2973159},
	doi = {10.1109/TMC.2020.2973159},
	timestamp = {Thu, 29 Apr 2021 15:13:53 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/AnLYG21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {An ultrasonic positioning system (UPS) has demonstrated its high accuracy for years. However, few of the developed solutions have been deployed in practice to satisfy the localization demand of today’s smart devices, which lack ultrasonic sensors and were considered as being “deaf” to ultrasound. A recent finding demonstrates that ultrasound may be audible to the smart devices under certain conditions due to their microphone’s nonlinearity. Inspired by this insight, this work revisits the ultrasonic positioning technique and builds a practical UPS, called UPS+, for ultrasound-incapable smart devices. The core concept is to deploy two types of indoor beacon devices, which will advertise ultrasonic beacons at two different ultrasonic frequencies respectively. Their superimposed beacons are downconverted to a low-frequency by exploiting the nonlinearity effect at the receiver’s microphone. This underlying property functions as an implicit ultrasonic downconverter without inflicting harm to the hearing system of humans. We demonstrate UPS+, a fully functional UPS prototype, with centimeter-level localization accuracy using custom-made beacon hardware and well-designed algorithms.}
}


@article{DBLP:journals/tmc/ChenGLLX21,
	author = {Menggang Chen and
                  Songtao Guo and
                  Kai Liu and
                  Xiaofeng Liao and
                  Bin Xiao},
	title = {Robust Computation Offloading and Resource Scheduling in Cloudlet-Based
                  Mobile Cloud Computing},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {5},
	pages = {2025--2040},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2973993},
	doi = {10.1109/TMC.2020.2973993},
	timestamp = {Thu, 29 Apr 2021 15:13:53 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/ChenGLLX21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Mobile cloud computing (MCC) as an emerging computing paradigm enables mobile devices to offload their computation tasks to nearby resource-rich cloudlets so as to augment computation capability and reduce energy consumption of mobile devices. However, due to the mobility of mobile devices and the admission of cloudlets, the connection between mobile devices and cloudlets may be unstable, which will affect offloading decision, even cause offloading failure. To address such an issue, in this paper, we propose a robust computation offloading strategy with failure recovery (RoFFR) in an intermittently connected cloudlet system aiming to reduce energy consumption and shorten application completion time. We first provide an optimal cloudlet selection policy when multiple cloudlets are available near mobile devices. Furthermore, we formulate the RoFFR problem as two optimization problems, i.e., local execution cost minimization problem and offloading execution cost minimization problem while satisfying the task-dependency requirement and application completion deadline constraint. By solving both optimization problems, we present a distributed RoFFR algorithm for CPU clock frequency configuration in local execution and transmission power allocation and data rate control in cloudlet execution. Experimental results in a real testbed show that our distributed RoFFR algorithm outperforms several baseline policies and existing offloading schemes in terms of application completion cost and offloading data rate.}
}


@article{DBLP:journals/tmc/LiuNL21,
	author = {Xiuming Liu and
                  Edith Cheuk{-}Han Ngai and
                  Jiangchuan Liu},
	title = {Secure Information Fusion using Local Posterior for Distributed Cyber-Physical
                  Systems},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {5},
	pages = {2041--2054},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2969352},
	doi = {10.1109/TMC.2020.2969352},
	timestamp = {Thu, 29 Apr 2021 15:13:53 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/LiuNL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In modern distributed cyber-physical systems (CPS), information fusion often plays a key role in automate and self-adaptive decision making process. However, given the heterogeneous and distributed nature of modern CPSs, it is a great challenge to operate CPSs with the compromised data integrity and unreliable communication links. In this paper, we study the distributed state estimation problem under the false data injection attack (FDIA) with probabilistic communication networks. We propose an integrated ”detection + fusion” solution, which is based on the Kullback-Leibler divergences (KLD) between local posteriors and therefore does not require the exchange of raw sensor data. For the FDIA detection step, the KLDs are used to cluster nodes in the probability space and to partition the space into secure and insecure subspaces. By approximating the distribution of the KLDs with a general\nχ\n2\ndistribution and calculating its tail probability, we provide an analysis of the detection error rate. For the information fusion step, we discuss the potential risk of double counting the shared prior information in the KLD-based consensus formulation method. We show that if the local posteriors are updated from the shared prior, the increased number of neighbouring nodes will lead to the diminished information gain. To overcome this problem, we propose a near-optimal distributed information fusion solution with properly weighted prior and data likelihood. Finally, we present simulation results for the integrated solution. We discuss the impact of network connectivity on the empirical detection error rate and the accuracy of state estimation.}
}


@article{DBLP:journals/tmc/WangHWRWW21,
	author = {Zhibo Wang and
                  Yuting Huang and
                  Xinkai Wang and
                  Ju Ren and
                  Qian Wang and
                  Libing Wu},
	title = {SocialRecruiter: Dynamic Incentive Mechanism for Mobile Crowdsourcing
                  Worker Recruitment With Social Networks},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {5},
	pages = {2055--2066},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2973958},
	doi = {10.1109/TMC.2020.2973958},
	timestamp = {Mon, 25 Mar 2024 12:48:07 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/WangHWRWW21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Worker recruitment is an important problem in mobile crowdsourcing (MCS), which aims to find sufficient and suitable participants to perform tasks. However, existing worker recruitment approaches mainly focus on how to select the most suitable workers for tasks from a large worker pool, while the recruitment problem under insufficient workers (e.g., a new MCS system) has not been well addressed. In this paper, we focus on the insufficient participation problem of MCS systems with limited number of workers, and propose to leverage social network to recruit workers for task completion as well as expanding the worker pool. To this end, we propose a dynamic incentive mechanism, called SocialRecruiter, to encourage workers on the MCS platform to propagate tasks through social networks, so that inviting friends to join in the MCS platform to further propagate and complete tasks. Motivated by the SIR epidemic model, we propose a novel task-specific epidemic model to characterize the status change of users for task propagation and completion through social networks. In order to encourage task completion and propagation, the propagating reward and completing reward are provided according to workers’ actions. In particular, in order to maximize the task completion within the financial budget, the propagating and completing rewards are dynamically updated at each cycle according to real-time worker recruitment progress. The extensive experimental results on two real-world datasets demonstrate that SocialRecruiter outperforms the state-of-the-art approaches in terms of worker recruitment and task completion.}
}


@article{DBLP:journals/tmc/CaiPHZL21,
	author = {Chao Cai and
                  Henglin Pu and
                  Menglan Hu and
                  Rong Zheng and
                  Jun Luo},
	title = {{SST:} Software Sonic Thermometer on Acoustic-Enabled IoT Devices},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {5},
	pages = {2067--2079},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2970902},
	doi = {10.1109/TMC.2020.2970902},
	timestamp = {Wed, 10 Jul 2024 16:47:46 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/CaiPHZL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Temperature is an important data source for weather forecasting, agriculture irrigation, anomaly detection, etc. While temperature measurement can be achieved via low-cost yet standalone hardware with reasonable accuracy, integrating thermal sensing into ubiquitous computing devices is highly non-trivial due to the design requirement for specific heat isolation and proper device layout. In this paper, we present the first integrated thermometer using commercial-off-the-shelf acoustic-enabled devices. Our software sonic thermometer (SST) utilizes on-board dual microphones on commodity mobile devices to estimate sound speed, which has a known relation with temperature. To precisely measure temperature via sound speed, we propose a chirp mixing approach to circumvent low sampling rates on commodity hardware and design a pipeline of signal processing blocks to handle channel distortions. SST, for the first time, empowers ubiquitous computing devices with thermal sensing capability. It is portable and cost-effective, making it competitive with current thermometers using dedicated hardware. SST is potential to facilitate many interesting applications such as large-scale distributed thermal sensing, yielding high temporal/spatial resolutions with unimaginable low costs. We implement SST on a commodity platform and results show that SST achieves a median accuracy of\n0.5\n∘\nC\neven at varying humidity levels.}
}


@article{DBLP:journals/tmc/WangZHZWRL21,
	author = {Zhibo Wang and
                  Jing Zhao and
                  Jiahui Hu and
                  Tianqing Zhu and
                  Qian Wang and
                  Ju Ren and
                  Chao Li},
	title = {Towards Personalized Task-Oriented Worker Recruitment in Mobile Crowdsensing},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {5},
	pages = {2080--2093},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2973990},
	doi = {10.1109/TMC.2020.2973990},
	timestamp = {Mon, 25 Mar 2024 12:48:07 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/WangZHZWRL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Worker recruitment in mobile crowdsensing systems aims to recruit the most suitable users to perform tasks with high quality and in real-time. Many worker recruitment or task matching mechanisms have been proposed, especially for crowdsourcing platforms, where content information of tasks from the implicit feedback of workers' attendance is extensively exploited to help workers find preferred tasks efficiently. Different from traditional crowdsourcing systems, tasks in mobile crowdsensing systems are usually time-sensitive and location-dependent which also play a crucial role in worker recruitment. However, these context information have not been effectively explored for user recruitment in mobile crowdsensing systems. In this paper, we propose a novel personalized task-oriented worker recruitment mechanism for mobile crowdsensing systems based on a careful characterization of workers' preference. In particular, we fully exploit the content information (e.g., task category, task description) together with the context information (e.g., task time, task location) from the implicit feedback of workers' attendance to accurately model workers' preference on tasks. Moreover, we regard the task-worker fitness prediction as a binary classification problem and utilize the Logit model to integrate the heterogeneous factors into a single framework to predict the matching probability of each task-worker pair. Finally, the workers with the highest matching probability are recruited proactively for each new task. Extensive experiments on real-world datasets demonstrate that the proposed mechanism achieves better performance than the benchmarks.}
}


@article{DBLP:journals/tmc/ZhangDOYZZR21,
	author = {Yige Zhang and
                  Aaron Yi Ding and
                  J{\"{o}}rg Ott and
                  Mingxuan Yuan and
                  Jia Zeng and
                  Kun Zhang and
                  Weixiong Rao},
	title = {Transfer Learning-Based Outdoor Position Recovery With Cellular Data},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {5},
	pages = {2094--2110},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2968899},
	doi = {10.1109/TMC.2020.2968899},
	timestamp = {Mon, 28 Aug 2023 21:39:17 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/ZhangDOYZZR21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Telecommunication (Telco) outdoor position recovery aims to localize outdoor mobile devices by leveraging measurement report (MR) data. Unfortunately, Telco position recovery requires sufficient amount of MR samples across different areas and suffers from high data collection cost. For an area with scarce MR samples, it is hard to achieve good accuracy. In this paper, by leveraging the recently developed transfer learning techniques, we design a novel Telco position recovery framework, called TLoc, to transfer good models in the carefully selected source domains (those fine-grained small subareas) to a target one which originally suffers from poor localization accuracy. Specifically, TLoc introduces three dedicated components: 1) a new coordinate space to divide an area of interest into smaller domains, 2) a similarity measurement to select best source domains, and 3) an adaptation of an existing transfer learning approach. To the best of our knowledge, TLoc is the first framework that demonstrates the efficacy of applying transfer learning in the Telco outdoor position recovery. To exemplify, on the 2G GSM and 4G LTE MR datasets in Shanghai, TLoc outperforms a non-transfer approach by 27.58 and 26.12 percent less median errors, and further leads to 47.77 and 49.22 percent less median errors than a recent fingerprinting approach NBL.}
}


@article{DBLP:journals/tmc/KhorovKSA21,
	author = {Evgeny M. Khorov and
                  Artem N. Krasilov and
                  Ilya Selnitskiy and
                  Ian F. Akyildiz},
	title = {A Framework to Maximize the Capacity of 5G Systems for Ultra-Reliable
                  Low-Latency Communications},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {6},
	pages = {2111--2123},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2976055},
	doi = {10.1109/TMC.2020.2976055},
	timestamp = {Sun, 16 May 2021 00:13:29 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/KhorovKSA21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Providing Ultra-Reliable Low-Latency Communications (URLLC) is one of the key challenges for 5G systems, which requires the redesign of both radio access technologies and the architectures. While 3GPP and the research community focus mainly on radio low layer functionality and architectural changes that enable URLLC, this article proposes a novel cross-layer framework that extends the already standardized 5G solutions to support a very massive number of users/flows in the system. The framework consists of a scheduler, a congestion avoidance algorithm, and a new traffic management algorithm, which together achieve the maximum capacity of 5G systems for URLLC, i.e., they maximize the load at which the reliability and latency requirements are satisfied for at least 99 percent of the users. Extensive performance evaluation results demonstrate that the proposed framework achieves the network capacity very close to the upper bound.}
}


@article{DBLP:journals/tmc/MalikKKS21,
	author = {Adeel Malik and
                  Joongheon Kim and
                  Kwang Soon Kim and
                  Won{-}Yong Shin},
	title = {A Personalized Preference Learning Framework for Caching in Mobile
                  Networks},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {6},
	pages = {2124--2139},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2975786},
	doi = {10.1109/TMC.2020.2975786},
	timestamp = {Sun, 16 May 2021 00:13:29 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/MalikKKS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper comprehensively studies a content-centric mobile network based on a preference learning framework, where each mobile user is equipped with a finite-size cache. We consider a practical scenario where each user requests a content file according to its own preferences, which is motivated by the existence of heterogeneity in file preferences among different users. Under our model, we consider a single-hop-based device-to-device (D2D) content delivery protocol and characterize the average hit ratio for the following two file preference cases: the personalized file preferences and the common file preferences. By assuming that the model parameters such as user activity levels, user file preferences, and file popularity are unknown and thus need to be inferred, we present a collaborative filtering (CF) -based approach to learn these parameters. Then, we reformulate the hit ratio maximization problems into a submodular function maximization and propose two computationally efficient algorithms including a greedy approach to efficiently solve the cache allocation problems. We analyze the computational complexity of each algorithm. Moreover, we analyze the corresponding level of the approximation that our greedy algorithm can achieve compared to the optimal solution. Using a real-world dataset, we demonstrate that the proposed framework employing the personalized file preferences brings substantial gains over its counterpart for various system parameters.}
}


@article{DBLP:journals/tmc/AcarAUA21,
	author = {Abbas Acar and
                  Hidayet Aksu and
                  A. Selcuk Uluagac and
                  Kemal Akkaya},
	title = {A Usable and Robust Continuous Authentication Framework Using Wearables},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {6},
	pages = {2140--2153},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2974941},
	doi = {10.1109/TMC.2020.2974941},
	timestamp = {Sun, 16 May 2021 00:13:29 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/AcarAUA21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {One-time login process in conventional authentication systems does not guarantee that the identified user is the actual user throughout the session. However, it is necessary to re-verify the user identity periodically throughout a login session, which is lacking in existing one-time login systems. Continuous authentication, which re-verifies the user identity without breaking the continuity of the session, can address this issue. However, existing methods for Continuous Authentication are either not reliable or not usable. In this paper, we introduce a usable and reliable Wearable-Assisted Continuous Authentication (WACA), which relies on the sensor-based keystroke dynamics and the authentication data is acquired through the built-in sensors of a wearable (e.g., smartwatch) while the user is typing. The acquired data is periodically and transparently compared with the registered profile of the initially logged-in user with one-way classifiers. With this, WACA continuously ensures that the current user is the user who logged-in initially. We implemented the WACA framework and evaluated its performance extensively on real devices with real users. The empirical evaluation of WACA reveals that WACA is feasible, and its error rate is as low as 1 percent with 30 seconds of processing time and 2-3 percent for 20 seconds. The computational overhead is minimal. Furthermore, WACA is capable of identifying insider threats with very high accuracy (99.2 percent) and also robust against powerful adversaries such as imitation and statistical attackers. We believe that this work has practical and far-reaching implications for the future of the usable authentication field.}
}


@article{DBLP:journals/tmc/FanXCYGSNH21,
	author = {Xiaochen Fan and
                  Chaocan Xiang and
                  Chao Chen and
                  Panlong Yang and
                  Liangyi Gong and
                  Xudong Song and
                  Priyadarsi Nanda and
                  Xiangjian He},
	title = {BuildSenSys: Reusing Building Sensing Data for Traffic Prediction
                  With Cross-Domain Learning},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {6},
	pages = {2154--2171},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2976936},
	doi = {10.1109/TMC.2020.2976936},
	timestamp = {Sun, 16 May 2021 00:13:29 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/FanXCYGSNH21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the rapid development of smart cities, smart buildings are generating a massive amount of building sensing data by the equipped sensors. Indeed, building sensing data provides a promising way to enrich a series of data-demanding and cost-expensive urban mobile applications. In this paper, as a preliminary exploration, we study how to reuse building sensing data to predict traffic volume on nearby roads. Compared with existing studies, reusing building sensing data has considerable merits of cost-efficiency and high-reliability. Nevertheless, it is non-trivial to achieve accurate prediction on such cross-domain data with two major challenges. First, relationships between building sensing data and traffic data are not unknown as prior, and the spatio-temporal complexities impose more difficulties to uncover the underlying reasons behind the above relationships. Second, it is even more daunting to accurately predict traffic volume with dynamic building-traffic correlations, which are cross-domain, non-linear, and time-varying. To address the above challenges, we design and implement BuildSenSys, a first-of-its-kind system for nearby traffic volume prediction by reusing building sensing data. Our work consists of two parts, i.e., Correlation Analysis and Cross-domain Learning. First, we conduct a comprehensive building-traffic analysis based on multi-source datasets, disclosing how and why building sensing data is correlated with nearby traffic volume. Second, we propose a novel recurrent neural network for traffic volume prediction based on cross-domain learning with two attention mechanisms. Specifically, a cross-domain attention mechanism captures the building-traffic correlations and adaptively extracts the most relevant building sensing data at each predicting step. Then, a temporal attention mechanism is employed to model the temporal dependencies of data across historical time intervals. The extensive experimental studies demonstrate that BuildSenSys outperforms all baseline methods with up to 65.3 percent accuracy improvement (e.g., 2.2 percent MAPE) in predicting nearby traffic volume. We believe that this work can open a new gate of reusing building sensing data for urban traffic sensing, thus establishing connections between smart buildings and intelligent transportation.}
}


@article{DBLP:journals/tmc/CheungHHS21,
	author = {Man Hon Cheung and
                  Fen Hou and
                  Jianwei Huang and
                  Richard Southwell},
	title = {Distributed Time-Sensitive Task Selection in Mobile Crowdsensing},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {6},
	pages = {2172--2185},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2975569},
	doi = {10.1109/TMC.2020.2975569},
	timestamp = {Mon, 31 Jan 2022 07:49:06 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/CheungHHS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the rich set of embedded sensors installed in smartphones, we are witnessing the emergence of many innovative commercial mobile crowdsensing applications, which combine the power of mobile technology with crowdsourcing to effectively collect time-sensitive and location-dependent information. Motivated by these real-world applications, we consider the distributed task selection problem for heterogeneous users with different initial locations, destinations, costs, speeds, and reputation levels. We design a Bayesian asynchronous task selection (BATS) algorithm to help the users plan their task selections based on the incomplete information of the task popularity statistics. We prove its convergence and characterize the computation time for the users' updates. As a performance benchmark, we consider the ideal case that the service provider centrally allocates the tasks to the users for social surplus maximization. We show that it is an NP-hard problem and propose a greedy centralized algorithm with a lower complexity as the benchmark performance. Simulation results suggest that the BATS scheme achieves the highest Jain's fairness index and coverage, while yielding a user payoff similar to that with the greedy centralized benchmark. Finally, we evaluate the schemes based on some real-world movement time and distance data from Google Maps.}
}


@article{DBLP:journals/tmc/WuZHL21,
	author = {Chenshu Wu and
                  Feng Zhang and
                  Yuqian Hu and
                  K. J. Ray Liu},
	title = {GaitWay: Monitoring and Recognizing Gait Speed Through the Walls},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {6},
	pages = {2186--2199},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2975158},
	doi = {10.1109/TMC.2020.2975158},
	timestamp = {Sun, 16 May 2021 00:13:29 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/WuZHL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Interests in monitoring and recognizing gait have surged significantly over the past decades. Traditional approaches rely on camera array, floor sensors (e.g., pressure mats), or wearables (e.g., accelerometers), none of which are suitable for continuous and ubiquitous everyday use. In this article, we present GaitWay, the first system that monitors and recognizes an individual's gait through the walls via wireless radios. GaitWay passively and unobtrusively monitors an individual's gait speed by a single pair of commodity WiFi transceivers, without requiring the user to wear any device or walk on a restricted walkway. On this basis, GaitWay automatically identifies stable walking periods, extracts physically plausible and environmentally irrelevant speed features, and accordingly recognizes a subject's gait. Built upon a distinct rich-scattering multipath model, GaitWay can capture one's gait speed when one is\n>\n>10 meters away behind the walls. We conduct experiments in a typical indoor space and perform eight sessions of data collection with 11 subjects across six months, resulting in\n>\n>5,000 gait instances. The results show that GaitWay achieves a median 0.12 m/s and 90%tile 0.35 m/s error in speed estimation, with a mean error of 3.36 cm in stride lengths. Further, it achieves a verification rate of 90.4% and a recognition rate of 81.2% for five users and 69.8% for 11 users, confirming its comfort and accuracy for continuous and ubiquitous use.}
}


@article{DBLP:journals/tmc/FujihashiKOW21,
	author = {Takuya Fujihashi and
                  Toshiaki Koike{-}Akino and
                  Philip V. Orlik and
                  Takashi Watanabe},
	title = {High-Throughput Visual {MIMO} Systems for Screen-Camera Communications},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {6},
	pages = {2200--2211},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2977042},
	doi = {10.1109/TMC.2020.2977042},
	timestamp = {Fri, 19 May 2023 17:27:53 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/FujihashiKOW21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Screen-camera communications, using a liquid crystal display (LCD) screen and camera image sensors, have been attractive variants of visible light communications (VLC) since any external light-emitting modules and photo detectors are required for recent mobile devices, which are usually equipped with display and camera. A major issue in screen-camera communications is a performance loss in transmission rate due to nonlinear channel impairments with ambient noise. To improve transmission rates, we investigate the impact of nonlinear channel equalization, nonbinary channel coding, probabilistic shaping, and nonlinear precoding for high-order modulation schemes. Experimental evaluations using an LCD screen and camera demonstrate that our proposed scheme achieves 3.8-3.3 times higher transmission rates compared to existing schemes for a communication distance of 60-160 cm.}
}


@article{DBLP:journals/tmc/BadriR21,
	author = {Simin Badri and
                  Mehdi Rasti},
	title = {Interference Management and Duplex Mode Selection in In-Band Full
                  Duplex {D2D} Communications: {A} Stochastic Geometry Approach},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {6},
	pages = {2212--2223},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2977899},
	doi = {10.1109/TMC.2020.2977899},
	timestamp = {Sun, 16 May 2021 00:13:29 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/BadriR21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this article, we present a new approach for managing the interference on cellular users through optimum mode selection between half-duplex (HD) and in-band full-duplex (IBFD) in such a way that device-to-device (D2D) throughput is maximized, while the quality of service (QoS) of the cellular users is guaranteed in terms of delay. To present a comprehensive view and analyse of the proposed approach in a large network, we use Poisson point process that enables us to model a large network with random parameters in such a way that is highly compatible with reality. Also, to model the cellular users' delay, we use the queuing theory and Markov processes. Unlike other related works, the mode selection between HD and IBFD is considered as a decision variable and its optimal value is obtained. The results show that in comparison with the related works, our proposed approach leads to improvements in the D2D throughput, while through proper interference management, the impact on the cellular users' throughput is negligible. Moreover, the QoS of the cellular users is guaranteed by keeping the delay below a certain threshold.}
}


@article{DBLP:journals/tmc/WangLG21,
	author = {Fangxin Wang and
                  Jiangchuan Liu and
                  Wei Gong},
	title = {Multi-Adversarial In-Car Activity Recognition Using RFIDs},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {6},
	pages = {2224--2237},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2977902},
	doi = {10.1109/TMC.2020.2977902},
	timestamp = {Thu, 31 Mar 2022 08:37:34 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/WangLG21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In-car human activity recognition opens a new opportunity toward intelligent driving behavior detection and touchless human-car interaction. Among the many sensing technologies (e.g., using cameras and wearable sensors), radio frequency identification (RFID) exhibits unique advantages given its low cost, easy deployment, and less privacy concerns. Existing RFID-based solutions for activity recognition are mostly confined to working in stable indoor spaces. The inside space of a car however is much more compact and complex, not to mention the fast-changing driving conditions. All these introduce non-negligible noises that pollute the activity-related information, and the existence of various car models in the market further complicates the problem. In this article, we for the first time closely examine the distinct factors that affect the RFID-based in-car activity recognition. We present RF-CAR, a novel RFID-based tag-free solution that well adapts to different in-car environments. RF-CAR smartly filters the domain-specific features in RF signals and retains activity-related features to the maximum extent. It then integrates a deep learning architecture and an advanced multi-adversarial domain adaptation network for training and prediction. With only one-time pre-training, RF-CAR can adapt to new data domains such as new driving conditions, car models, and human subjects for robust activity recognition. We also demonstrate that it is readily deployable in cars with commercial off-the-shelf (COTS) RFID devices. Our extensive experiments suggest that RF-CAR achieves an overall recognition accuracy of around 95 percent, which significantly outperforms the state-of-the-art solutions.}
}


@article{DBLP:journals/tmc/ZhangLWC21,
	author = {Ming Zhang and
                  Hancheng Lu and
                  Feng Wu and
                  Chang Wen Chen},
	title = {NOMA-Based Scalable Video Multicast in Mobile Networks With Statistical
                  Channels},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {6},
	pages = {2238--2253},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2977639},
	doi = {10.1109/TMC.2020.2977639},
	timestamp = {Wed, 25 Oct 2023 22:40:54 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/ZhangLWC21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {To cope with rapid growth of video services, we propose a non-orthogonal multiple access (NOMA) based scalable video multicast (NOMA-SVM) framework for mobile networks, by exploiting NOMA's specific potential in scalable video multicast transmission. We consider statistical channels, instead of channels with perfect estimation, in the proposed NOMA-SVM framework in order to capture the realistic channel behaviors. As quality of experience (QoE) is a better metric than throughput for video transmission, QoE-driven power allocation is performed among multiple video layers in the proposed NOMA-SVM framework, in which users can decode video with quality proportional to their channel conditions. Specifically, we formulate the power allocation problem with the goal to maximize the average QoE over all users while guaranteeing the basic services of these users. To solve such a non-convex discrete problem, an optimal algorithm is developed based on the hidden monotonicity of the problem. A suboptimal algorithm is also proposed with much lower complexity in order to meet the practical needs. Simulation results show that the proposed algorithms outperform existing orthogonal multiple access (OMA) and NOMA based algorithms under various multicast scenarios in terms of QoE.}
}


@article{DBLP:journals/tmc/ChenLZZ21,
	author = {Ying Chen and
                  Rongpeng Li and
                  Zhifeng Zhao and
                  Honggang Zhang},
	title = {On the Capacity of Fractal {D2D} Social Networks with Hierarchical
                  Communications},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {6},
	pages = {2254--2268},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2975783},
	doi = {10.1109/TMC.2020.2975783},
	timestamp = {Sun, 16 May 2021 00:13:29 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/ChenLZZ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The maximum capacity of fractal D2D (device-to-device) social networks with both direct and hierarchical communications is studied in this paper. Specifically, the fractal networks are characterized by the direct social connection and the self-similarity. First, for a fractal D2D social network with direct social communications, it is proved that the maximum capacity is\nΘ(\n1\nnlogn\n√\n)\nif a user communicates with one of his/her direct contacts randomly, where\nn\ndenotes the total number of users in the network, and it can reach up to\nΘ(\n1\nlogn\n)\nif any pair of social contacts with distance\nd\ncommunicate according to the probability in proportion to\nd\n−β\n. Second, since users might get in touch with others without direct social connections through the inter-connected multiple users, the fractal D2D social network with these hierarchical communications is studied as well, and the related capacity is further derived. Our results show that this capacity is mainly affected by the correlation exponent\nϵ\nof the fractal structure. The capacity is reduced in proportional to\n1\nlogn\nif\n2<ϵ<3\n, while the reduction coefficient is\n1\nn\nif\nϵ>3\n.}
}


@article{DBLP:journals/tmc/YangAQP21,
	author = {Howard H. Yang and
                  Ahmed Arafa and
                  Tony Q. S. Quek and
                  H. Vincent Poor},
	title = {Optimizing Information Freshness in Wireless Networks: {A} Stochastic
                  Geometry Approach},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {6},
	pages = {2269--2280},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2977010},
	doi = {10.1109/TMC.2020.2977010},
	timestamp = {Sun, 16 May 2021 00:13:29 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/YangAQP21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Optimization of information freshness in wireless networks has usually been performed based on queueing analysis that captures only the temporal traffic dynamics associated with the transmitters and receivers. However, the effect of interference, which is mainly dominated by the interferers' geographic locations, is not well understood. In this paper, we leverage a spatiotemporal model, which allows one to characterize the age of information (AoI) from a joint queueing-geometry perspective, for the design of a decentralized scheduling policy that exploits local observation to make transmission decisions that minimize the AoI. To quantify the performance, we also derive accurate and tractable expressions for the peak AoI. Numerical results reveal that: i) the packet arrival rate directly affects the service process due to queueing interactions, ii) the proposed scheme can adapt to traffic variations and largely reduce the peak AoI, and iii) the proposed scheme scales well as the network grows in size. This is done by adaptively adjusting the radio access probability at each transmitter to the change of the ambient environment.}
}


@article{DBLP:journals/tmc/WuHCCZWR21,
	author = {Kaishun Wu and
                  Yandao Huang and
                  Wenqiang Chen and
                  Lin Chen and
                  Xinyu Zhang and
                  Lu Wang and
                  Rukhsana Ruby},
	title = {Power Saving and Secure Text Input for Commodity Smart Watches},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {6},
	pages = {2281--2296},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2976007},
	doi = {10.1109/TMC.2020.2976007},
	timestamp = {Sat, 09 Apr 2022 12:29:16 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/WuHCCZWR21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Smart wristband has become a dominant device in the wearable ecosystem, providing versatile functions such as fitness tracking, mobile payment, and transport ticketing. However, the small form-factor, low-profile hardware interfaces and computational resources limit their capabilities in security checking. Many wristband devices have recently witnessed alarming vulnerabilities, e.g., personal data leakage and payment fraud, due to the lack of authentication and access control. To fill this gap, we propose a secure text pin input system, namely Taprint, which extends a virtual number pad on the back of a user's hand. Taprint builds on the key observation that the hand “landmarks”, especially finger knuckles, bear unique vibration characteristics when being tapped by the user herself. It thus uses the tapping vibrometry as biometrics to authenticate the user, while distinguishing the tapping locations. Taprint reuses the inertial measurement unit in the wristband, “overclocks” its sampling rate with the cubic spline interpolation to extrapolate fine-grained features, and further refines the features to enhance the uniqueness and reliability. Extensive experiments on 128 users demonstrate that Taprint achieves a high accuracy (96 percent) of keystrokes recognition. It can authenticate users, even through a single-tap, at extremely low error rate (2.2 percent), and under various practical usage disturbances.}
}


@article{DBLP:journals/tmc/ZhangXLYCS21,
	author = {Yuan Zhang and
                  Chunxiang Xu and
                  Hongwei Li and
                  Kan Yang and
                  Nan Cheng and
                  Xuemin Shen},
	title = {{PROTECT:} Efficient Password-Based Threshold Single-Sign-On Authentication
                  for Mobile Users against Perpetual Leakage},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {6},
	pages = {2297--2312},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2975792},
	doi = {10.1109/TMC.2020.2975792},
	timestamp = {Mon, 28 Aug 2023 21:39:16 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/ZhangXLYCS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Password-based single-sign-on authentication has been widely applied in mobile environments. It enables an identity server to issue authentication tokens to mobile users holding correct passwords. With an authentication token, one can request mobile services from related service providers without multiple registrations. However, if an adversary compromises the identity server, he can retrieve users' passwords by performing dictionary guessing attacks (DGA) and can overissue authentication tokens to break the security. In this paper, we propose a password-based threshold single-sign-on authentication scheme dubbed PROTECT that thwarts adversaries who can compromise identity server(s), where multiple identity servers are introduced to authenticate mobile users and issue authentication tokens in a threshold way. PROTECT supports key renewal that periodically updates the secret on each identity server to resist perpetual leakage of the secret. Furthermore, PROTECT is secure against off-line DGA: a credential used to authenticate a user is computed from the password and a server-side key. PROTECT is also resistant to online DGA and password testing attacks in an efficient way. We conduct a comprehensive performance evaluation of PROTECT, which demonstrates the high efficiency on the user side in terms of computation and communication and proves that it can be easily deployed on mobile devices.}
}


@article{DBLP:journals/tmc/MaxhuniHMSOM21,
	author = {Alban Maxhuni and
                  Pablo Hernandez{-}Leal and
                  Eduardo F. Morales and
                  Luis Enrique Sucar and
                  Venet Osmani and
                  Oscar Mayora},
	title = {Unobtrusive Stress Assessment Using Smartphones},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {6},
	pages = {2313--2325},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2974834},
	doi = {10.1109/TMC.2020.2974834},
	timestamp = {Tue, 01 Jun 2021 08:35:41 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/MaxhuniHMSOM21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Stress assessment is a complex issue and numerous studies have examined factors that influence stress in working environments. Research studies have shown that monitoring individuals' behaviour parameters during daily life can also help assess stress levels. In this study, we examine assessment of work-related stress using features derived from sensors in smartphones. In particular, we use information from physical activity levels, location, social-interactions, social-activity, and application usage during working days. Our study included 30 employees chosen from two different private companies, monitored over a period of 8 weeks in real work environments. The findings suggest that information from phone sensors shows important correlation with employees perceived stress level. Second, we used machine learning methods to classify perceived stress levels based on the analysis of information provided by smartphones. We used decision trees obtaining 67.57 percent accuracy and 71.73 percent after applying a semi-supervised method. Our results show that stress levels can be monitored in unobtrusive manner, through analysis of smartphone data.}
}


@article{DBLP:journals/tmc/KalitaK21,
	author = {Alakesh Kalita and
                  Manas Khatua},
	title = {Channel Condition Based Dynamic Beacon Interval for Faster Formation
                  of 6TiSCH Network},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {7},
	pages = {2326--2337},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2980828},
	doi = {10.1109/TMC.2020.2980828},
	timestamp = {Tue, 15 Jun 2021 17:22:48 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/KalitaK21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Industrial applications of Internet of Things (IoT) demand high reliability, deterministic latency, and high scalability with energy efficiency to the communication and networking protocols. 6TiSCH is a time slotted channel hopping (TSCH) medium access control (MAC) protocol running under the IPv6 enabled higher layer protocols for industrial IoT (IIoT). In this paper, we theoretically analyze the network formation protocol in 6TiSCH network. Analysis reveals that the performance of the 6TiSCH network degrades when a pledge (new node) joins as it increases channel congestion by allowing to transmit beacon message. On the other hand, beacon transmission is essential to expand or reorganize the present network topology. To overcome this performance tradeoff, a channel condition based dynamic beacon interval (C2DBI) scheme is proposed in which beacon transmission interval varies with channel congestion status during network formation. Channel congestion status is estimated by each joined node in distributed manner, and subsequently changes its beacon generation interval to best fit with present condition. Finally the performance of C2DBI is compared with the minimal configuration standard and few other benchmark protocols. Analytical, simulation and real testbed results show that the proposed scheme outperforms the state of the art protocols in terms of joining time and energy consumption during network formation.}
}


@article{DBLP:journals/tmc/ZhangGBLTSL21,
	author = {Yuanxing Zhang and
                  Yushuo Guan and
                  Kaigui Bian and
                  Yunxin Liu and
                  Hu Tuo and
                  Lingyang Song and
                  Xiaoming Li},
	title = {{EPASS360:} QoE-Aware 360-Degree Video Streaming Over Mobile Devices},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {7},
	pages = {2338--2353},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2978187},
	doi = {10.1109/TMC.2020.2978187},
	timestamp = {Tue, 15 Jun 2021 17:22:48 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/ZhangGBLTSL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The 360-degree video streaming system delivers a monocular panoramic video surrounding the user, and the user can change the viewing direction of mobile devices to see different parts of the video through the “viewport”. Due to the limited network bandwidth, playbacks of high-resolution 360-degree videos often suffer from rebuffering, while too much bandwidth is wasted in delivering those out-of-viewport parts that the user never watches. In this article, we present an Ensemble Prediction and Allocation based Streaming System, named as EPASS360, for delivering high Quality of Experience (QoE) 360-degree videos. The prediction model takes advantages of ensemble learning, providing high accuracy on the prediction of viewports. The allocation model divides a video into tiles, and allocates high resolution to tiles where a user's viewpoint may appear in the future by solving the QoE-aware optimization problem. Trace-driven emulation on real-world datasets shows that EPASS360 enhances the QoE in various scenarios compared to state-of-the-art streaming approaches. Experiments on the head-mounted device and the hand-held device over real-world Internet confirm the high user experience of EPASS360.}
}


@article{DBLP:journals/tmc/JinHZFXXC21,
	author = {Meng Jin and
                  Yuan He and
                  Xiaolong Zheng and
                  Dingyi Fang and
                  Dan Xu and
                  Tianzhang Xing and
                  Xiaojiang Chen},
	title = {Exploiting Interference Fingerprints for Predictable Wireless Concurrency},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {7},
	pages = {2354--2366},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2978205},
	doi = {10.1109/TMC.2020.2978205},
	timestamp = {Thu, 05 Aug 2021 12:15:58 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/JinHZFXXC21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Operating in unlicensed ISM bands, ZigBee devices often yield poor performance due to the interference from ever increasing wireless devices in the 2.4 GHz band. Our empirical results show that, a specific interference is likely to have different influence on different outbound links of a ZigBee sender, which indicates the chance of concurrent transmissions. Based on this insight, we propose Smoggy-Link, a practical protocol to exploit the potential concurrency for adaptive ZigBee transmissions under harsh interference. Smoggy-Link maintains an accurate link model to quantify and trace the relationship between interference and link qualities of the sender's outbound links. With such a link model, Smoggy-Link can translate low-cost interference information to the fine-grained spatiotemporal link state. The link information is further utilized for adaptive link selection and intelligent transmission schedule. We implement and evaluate a prototype of our approach with TinyOS and TelosB motes. The evaluation results show that Smoggy-Link has consistent improvements in both throughput and packet reception ratio under interference from various interferers.}
}


@article{DBLP:journals/tmc/GuoS21,
	author = {Tao Guo and
                  Alberto Su{\'{a}}rez},
	title = {Fine-Grained Frequency Reuse in Centralized Small Cell Networks},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {7},
	pages = {2367--2378},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2981032},
	doi = {10.1109/TMC.2020.2981032},
	timestamp = {Sat, 13 Nov 2021 20:53:27 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/GuoS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Interference management for Small Cell (SC) networks has drawn great attention from both academia and industry due to its importance in Long-Term Evolution (LTE) and emerging 5G networks. Although various approaches have been proposed in the literature, many of them face practical limitations such as showing gains only in specific scenarios, relying on ideal fronthaul, or becoming computationally intractable as the network size increases. In this paper, a novel framework is proposed for interference management in centralized SC networks by jointly utilizing graph theory and optimization theory. It extends the classic center-edge frequency reuse schemes into a more fine-grained scale, thus capturing the complex interference relationships in SC networks. The cell-level resource partition can be semi-statically updated according to the traffic dynamics while existing Medium Access Control (MAC) schedulers can be used for subframe-level resource allocation, not requiring fiber fronthaul. LTE system-level simulation results show that the proposed scheme can significantly improve both cell edge and mean user throughput with practical complexity.}
}


@article{DBLP:journals/tmc/ZhaoMJ21,
	author = {Dong Zhao and
                  Huadong Ma and
                  Xinna Ji},
	title = {Generalized Lottery Trees: Budget-Balanced Incentive Tree Mechanisms
                  for Crowdsourcing},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {7},
	pages = {2379--2394},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2979459},
	doi = {10.1109/TMC.2020.2979459},
	timestamp = {Mon, 28 Aug 2023 21:39:16 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/ZhaoMJ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Incentive mechanism design has aroused extensive attention for crowdsourcing applications in recent years. Most research assumes that participants are already in the system and aware of the existence of crowdsourcing tasks. Whereas in real-life scenarios without this assumption, it is more effective to leverage incentive tree mechanisms that incentivize both users' direct contributions and solicitations to other users. Although such mechanisms have been investigated, we are the first to propose budget-balanced incentive tree mechanisms, called generalized lottrees, which require the total payout to be equal to the announced budget, while guaranteeing several desirable properties including continuing contribution incentive, continuing solicitation incentive, value proportional to contribution, unprofitable solicitor bypassing, and unprofitable Sybil attack. Moreover, three types of generalized lottree mechanisms, 1-Pachira, K-Pachira and Sharing-Pachira, are presented for supporting diversified requirements. A solid theoretical guideline on the mechanism selection is provided based on the Cumulative Prospect Theory. Both extensive simulations and realistic experiments with 82 users are conducted to confirm our theoretical analysis.}
}


@article{DBLP:journals/tmc/LahadILKM21,
	author = {Bachir Lahad and
                  Marc Ibrahim and
                  Samer Lahoud and
                  Kinda Khawam and
                  Steven Martin},
	title = {Joint Modeling of {TDD} and Decoupled Uplink/Downlink Access in 5G
                  HetNets With Multiple Small Cells Deployment},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {7},
	pages = {2395--2411},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2979447},
	doi = {10.1109/TMC.2020.2979447},
	timestamp = {Tue, 15 Jun 2021 17:22:48 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/LahadILKM21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Due to highly variant traffic in downlink (DL) and uplink (UL) in heterogeneous networks (HetNets), dynamic time-division duplexing (TDD) is proposed to dynamically allocate UL and DL resources. Under the same circumstances, downlink and uplink decoupled access (DUDA) is introduced to balance between UL and DL transmissions and to further improve the system performance. Rather than belonging to a specific cell, a mobile user can receive the downlink traffic from one base station (BS) and send uplink traffic through another BS. In this article, we analytically investigate a joint TDD and DUDA statistical model with multiple small cells deployment. This model is based on a geometric probability approach. Taking all possible TDD subframes combinations between the macro and small cells, coupled and decoupled cell associations strategies are investigated in details. We derive analytical expressions for the capacity and the interference, considering a network of one macro cell and multiple small cells. We build on the derived capacity expressions to measure the decoupling gain and thus, identify the location of the interferer small cell where the decoupled mode maintains a higher gain in both DL and UL. Monte-Carlo simulations results are presented to validate the accuracy of the statistical model.}
}


@article{DBLP:journals/tmc/ChenCCG21,
	author = {Quan Chen and
                  Zhipeng Cai and
                  Lianglun Cheng and
                  Hong Gao},
	title = {Low-Latency Data Aggregation Scheduling for Cognitive Radio Networks
                  With Non-Predetermined Structure},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {7},
	pages = {2412--2426},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2979710},
	doi = {10.1109/TMC.2020.2979710},
	timestamp = {Tue, 15 Jun 2021 17:22:48 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/ChenCCG21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Data aggregation is a fundamental yet popular operation in wireless networks where the sink needs to obtain the combined information of the whole network. However, the problem of minimum latency aggregation scheduling (MLAS) is not well studied in cognitive radio networks. Few studies have addressed this issue and most previous aggregation methods all assume that a fixed-structure based aggregation tree is constructed in advance, which may result in the selection of a node with limited spectrum opportunities as the parent by many nodes and by extension results in a large latency. Thus, the MLAS problem in cognitive radio networks (MLAS-CR) without the above limitation is investigated in this paper. First, the MLAS-CR problem with primary social behaviors where the activity of primary users can be predicted is studied. To make full use of the limited spectrum opportunities, we integrate the construction of the aggregation tree, and the computation of a conflict-free schedule simultaneously, without any predetermined structures. Second, the MLAS-CR problem without the above assumption is also investigated. To reduce the latency, a two-way aggregation scheduling method is proposed to adaptively choose the parent with only current channel information. To further reduce the latency, we also introduce a new data aggregation mode for CRN, i.e., Data Aggregation Scheduling in The Dark, to utilize the spectrum opportunities of scheduled nodes. Finally, the theoretical analysis and simulation results verify that the proposed algorithms have high performance in terms of latency.}
}


@article{DBLP:journals/tmc/ChiaraviglioDLG21,
	author = {Luca Chiaraviglio and
                  Fabio D'Andreagiovanni and
                  William Liu and
                  Jairo A. Guti{\'{e}}rrez and
                  Nicola Blefari{-}Melazzi and
                  Kim{-}Kwang Raymond Choo and
                  Mohamed{-}Slim Alouini},
	title = {Multi-Area Throughput and Energy Optimization of UAV-Aided Cellular
                  Networks Powered by Solar Panels and Grid},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {7},
	pages = {2427--2444},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2980834},
	doi = {10.1109/TMC.2020.2980834},
	timestamp = {Tue, 15 Jun 2021 17:22:48 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/ChiaraviglioDLG21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Small cells (SCs) mounted on top of Unmanned Aerial Vehicles (UAVs) can be used to boost the radio capacity in hotspot zones. However, UAV-SCs are subject to tight battery constraints, resulting in frequent recharges operated at the ground sites. To meet the UAV-SCs energy demanded to the ground sites, the operator leverages a set of Solar Panels (SPs) and grid connection. In this work, we demonstrate that both i) the level of throughput provided to a set of areas and ii) the amount of energy that is exchanged with the grid by the ground sites play a critical role in such UAV-aided cellular network. We then formulate the J-MATE model to jointly optimize the energy and throughput through revenue and cost components. In addition, we design the BBSR algorithm, which is able to retrieve a solution even for large problem instances. We evaluate J-MATE and BBSR over a realistic scenario composed of dozens of areas and multiple ground sites, showing that: i) both J-MATE and BBSR outperform previous approaches targeting either the throughput maximization or the energy minimization, and ii) the computation time and the memory occupation of BBSR are reduced up to five orders of magnitude compared to J-MATE.}
}


@article{DBLP:journals/tmc/KoufosD21,
	author = {Konstantinos Koufos and
                  Carl P. Dettmann},
	title = {Outage in Motorway Multi-Lane VANETs With Hardcore Headway Distance
                  Using Synthetic Traces},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {7},
	pages = {2445--2456},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2980232},
	doi = {10.1109/TMC.2020.2980232},
	timestamp = {Tue, 15 Jun 2021 17:22:48 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/KoufosD21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper we analyze synthetic mobility traces generated for three-lane unidirectional motorway traffic to find that the locations of vehicles along a lane are better modeled by a hardcore point process instead of the widely-accepted Poisson point process (PPP). In order to capture the repulsion between successive vehicles while maintaining a level of analytical tractability, we make a simple extension to PPP: We model the inter-vehicle distance along a lane equal to the sum of a constant hardcore distance and an exponentially distributed random variable. We calculate the J-function and the Ripley's K-function for this hardcore point process. We fit its parameters to the available traces, and we illustrate that the higher the average speed along a lane, the more prominent the hardcore component becomes. In addition, we consider a transmitter-receiver link on the same lane, and we generate simple formulae for the moments of interference under reduced Palm measure for that lane, and without conditioning for other lanes. We illustrate that under Rayleigh fading a shifted-gamma approximation for the distribution of interference per lane provides a very good fit to the simulated outage probability using the synthetic traces, while the fit using the PPP is poor.}
}


@article{DBLP:journals/tmc/WangZLJ21,
	author = {Huandong Wang and
                  Sihan Zeng and
                  Yong Li and
                  Depeng Jin},
	title = {Predictability and Prediction of Human Mobility Based on Application-Collected
                  Location Data},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {7},
	pages = {2457--2472},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2981441},
	doi = {10.1109/TMC.2020.2981441},
	timestamp = {Tue, 15 Jun 2021 17:22:48 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/WangZLJ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the modern information society, analysis of human mobility becomes increasingly essential in various areas such as city planning and resource management. With users’ historical trajectories, the inherent patterns of their movements can be extracted and utilized to accurately predict the future movements. Plenty of previous work adopted traditional Markov model, which suffers when the trajectory becomes sparse or it shows distinct mobility patterns in different time of day. In this paper, based on an app-collected dataset of 100,000 individuals’ actively uploaded location information, we comprehensively analyze the mobility and predictability of each user. To approach the theoretical predictability and overcome the shortcomings of traditional Markov model, we propose a time-variant Markov model based on Gibbs sampling for mobility prediction. Specifically, we model human mobility as several interconnected Markov chains, each chain corresponds to a movement pattern of a period of time. Then, we adopt Gibbs sampling method to simultaneously recover the missing part of trajectories and train the Markov chains, in order to solve the unevenly distribution and the high missing rate. Results show that our prediction algorithm can achieve 11.2 percent higher prediction accuracy than the benchmark method, especially on sparse trajectories. In addition, we discover a high correlation between prediction accuracy and predictability, with correlation coefficient reaching 0.81. Finally, we investigate various factors including spatial and temporal resolution, orders of Markov models, and radius of gyration, in order to further explore the predictability under different circumstances.}
}


@article{DBLP:journals/tmc/KhodaeiP21,
	author = {Mohammad Khodaei and
                  Panos Papadimitratos},
	title = {Scalable {\&} Resilient Vehicle-Centric Certificate Revocation
                  List Distribution in Vehicular Communication Systems},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {7},
	pages = {2473--2489},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2981887},
	doi = {10.1109/TMC.2020.2981887},
	timestamp = {Tue, 15 Jun 2021 17:22:48 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/KhodaeiP21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In spite of progress in securing vehicular communication (VC) systems, there is no consensus on how to distribute certificate revocation lists (CRLs). The main challenges lie exactly in (i) crafting an efficient and timely distribution of CRLs for numerous anonymous credentials, pseudonyms, (ii) maintaining strong privacy for vehicles prior to revocation events, even with honest-but-curious system entities, (iii) and catering to computation and communication constraints of on-board units with intermittent connectivity to the infrastructure. Relying on peers to distribute the CRLs is a double-edged sword: abusive peers could “pollute” the process, thus degrading the timely CRLs distribution. In this paper, we propose a vehicle-centric solution that addresses all these challenges and thus closes a gap in the literature. Our scheme radically reduces CRL distribution overhead: each vehicle receives CRLs corresponding only to its region of operation and its actual trip duration. Moreover, a “fingerprint” of CRL `pieces' is attached to a subset of (verifiable) pseudonyms for fast CRL `piece' validation (while mitigating resource depletion attacks abusing the CRL distribution). Our experimental evaluation shows that our scheme is efficient, scalable, dependable, and practical: with no more than 25 KB/s of traffic load, the latest CRL can be delivered to 95 percent of the vehicles in a region (15×15 KM) within 15s, i.e., more than 40 times faster than the state-of-the-art. Overall, our scheme is a comprehensive solution that complements standards and can catalyze the deployment of secure and privacy-protecting VC systems.}
}


@article{DBLP:journals/tmc/ZhangBCZFLL21,
	author = {Jian Zhang and
                  Hongliang Bi and
                  Yanjiao Chen and
                  Qian Zhang and
                  Zhaoyuan Fu and
                  Yunzhe Li and
                  Zeyu Li},
	title = {SmartSO: Chinese Character and Stroke Order Recognition With Smartwatch},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {7},
	pages = {2490--2504},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2980842},
	doi = {10.1109/TMC.2020.2980842},
	timestamp = {Tue, 15 Jun 2021 17:22:48 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/ZhangBCZFLL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Following the correct stroke order while writing Chinese characters composed of strokes plays an important role in handwriting efficiency and quality, especially for early education. Most existing systems use image processing techniques for character and stroke order recognition, which is sensitive to lighting conditions. In this paper, we present the design, implementation and evaluation of SmartSO, which utilizes the inertial sensors of an off-the-shelf smartwatch for Chinese character and stroke order recognition. SmartSo first identifies the Chinese character written by the user, based on which SmartSo decides whether the stroke order is written correctly to help improve users' writing behavior. The biggest challenge for stroke order recognition is that some Chinese characters have repeated strokes (strokes of the same type), e.g., with two same horizontal strokes, and it is challenging to differentiate the writing order of such strokes given only the detected stroke composition (number and type of strokes). To mitigate this problem, we further analyze the hand movement between two adjacent strokes (referred to as direction motion) and propose a novel algorithm to recognize stroke order based on direction motion information. Finally, we build a fully functional prototype of SmartSO, and extensive experiments confirm its effectiveness and robustness.}
}


@article{DBLP:journals/tmc/DuTL21,
	author = {Wan Du and
                  Panrong Tong and
                  Mo Li},
	title = {UniLoc: {A} Unified Mobile Localization Framework Exploiting Scheme
                  Diversity},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {7},
	pages = {2505--2517},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2979857},
	doi = {10.1109/TMC.2020.2979857},
	timestamp = {Tue, 15 Jun 2021 17:22:48 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/DuTL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Current localization schemes on mobile devices are experiencing great diversity that is mainly shown in two aspects: the large number of available localization schemes and their diverse performance. This paper presents UniLoc, a unified framework that gains improved performance from multiple localization schemes by exploiting their diversity. UniLoc predicts the localization error of each scheme online based on an error model and real-time context. It further combines the results of all available schemes based on the error prediction results and an ensemble learning algorithm. The combined result is more accurate than any individual schemes. With the flexible design of error modeling and ensemble learning, UniLoc can easily integrate a new localization scheme. The energy consumption of UniLoc is low, since its computation, including both error prediction and ensemble learning, only involves simple linear calculation. Our experience with extensive experiments tells that such easy aggregation incurs little overhead in integrating and training a localization scheme, but gains substantially from the scheme diversity. UniLoc outperforms individual localization schemes by 1.6× in a variety of environments, including > 89% new places where we did not train the error models.}
}


@article{DBLP:journals/tmc/BrandFSBHT21,
	author = {Peter Brand and
                  Joachim Falk and
                  Jonathan Ah Sue and
                  Johannes Brendel and
                  Ralph Hasholzner and
                  J{\"{u}}rgen Teich},
	title = {Adaptive Predictive Power Management for Mobile {LTE} Devices},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {8},
	pages = {2518--2535},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2988651},
	doi = {10.1109/TMC.2020.2988651},
	timestamp = {Wed, 03 Nov 2021 08:27:12 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/BrandFSBHT21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Reducing the energy consumption of mobile phones is a crucial design goal for cellular modem solutions for LTE and 5G NR standards. Most dynamic power management techniques targeting mobile devices proposed so far, however, are purely reactive in powering down and up system components. Promising approaches extend this, by predicting information from the cell and the communication protocol to take decisions proactively. In this paper, we present a complete proactive power management approach for the modem based on on-line grant prediction. In this context, we define proactive policies that allow a mobile device to go to sleep states more often compared to reactive power management systems, e.g., in time slots of predicted transmission inactivity in a cell. Furthermore, we propose and compare two algorithmic solutions to this proactive grant prediction problem, one a feed-forward neural network and one a SARSA-λ reinforcement agent. As the implementation of these machine learning techniques also creates additional energy and resource costs, both approaches are carefully designed, optimized, and evaluated not only in terms of prediction accuracy, but also in terms of overall energy savings. Notably, our predictor implementations are able to achieve up to 17 percent in overall energy savings on real-world traces.}
}


@article{DBLP:journals/tmc/BhattiFWGWC21,
	author = {Shahzad Sarwar Bhatti and
                  Jiahao Fan and
                  Kangrui Wang and
                  Xiaofeng Gao and
                  Fan Wu and
                  Guihai Chen},
	title = {An Approximation Algorithm for Bounded Task Assignment Problem in
                  Spatial Crowdsourcing},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {8},
	pages = {2536--2549},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2984380},
	doi = {10.1109/TMC.2020.2984380},
	timestamp = {Mon, 28 Aug 2023 21:39:16 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/BhattiFWGWC21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Spatial crowdsourcing, a human-centric compelling paradigm in performing spatial tasks, has drawn rising attention. Task assignment is of paramount importance in spatial crowdsourcing. Existing studies often use heuristics of various kinds to solve task assignment problems. These schemes usually only apply some specific cases, once the environment changes, the efficiency of the algorithms is significantly reduced. In this paper, we first introduce a taxonomy of task assignment in spatial crowdsourcing. Next, we design an approximation algorithm and get an efficient solution for the important problem, namely, Bounded and Heterogeneous Task Assignment (BHTA), such that the sum of the rewards of workers is maximized subject to multiple constraints. We prove that the BHTA problem is NP-hard. Subsequently, we propose a constant-ratio approximation algorithm based on partition and shifting method to achieve the assignment solution. To meet with the workers' dynamism, we further devise a greedy algorithm and provide theoretical guarantee. Experiments on synthetic and real datasets demonstrate the efficiency of our strategy over previous methods. So far as we know, this paper is the first attempt to give a constant-ratio approximation for such task assignment problems in spatial crowdsourcing.}
}


@article{DBLP:journals/tmc/LyuRNTLT21,
	author = {Xinchen Lyu and
                  Chenshan Ren and
                  Wei Ni and
                  Hui Tian and
                  Ren Ping Liu and
                  Xiaofeng Tao},
	title = {Distributed Online Learning of Cooperative Caching in Edge Cloud},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {8},
	pages = {2550--2562},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2983924},
	doi = {10.1109/TMC.2020.2983924},
	timestamp = {Tue, 13 Jul 2021 13:26:44 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/LyuRNTLT21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cooperative caching can unify storage across edge clouds and provide efficient delivery of popular contents under effective content placement. However, the placement and delivery are non-trivial in cooperative caching due to the decentralized property of edge clouds, as well as the temporal and spatial correlation of the placement. We propose a new distributed online learning approach to jointly optimize content placement and delivery without the a-priori knowledge on file popularity and link availability. Content placement and delivery can be asymptotically optimized in real-time by running distributed online learning at individual edge servers by exploiting stochastic gradient descent (SGD). The proposed approach can allow operations at different timescales by integrating mini-batch learning for farsighted content placement. The optimality loss, stemming from the different timescales, can asymptotically reduce, as the SGD stepsize declines. Simulations confirm that the proposed approach outperforms existing techniques in terms of cache hit ratio and cost effectiveness. Insights are shed on the optimal placement of popular contents.}
}


@article{DBLP:journals/tmc/ShokryEY21,
	author = {Ahmed Shokry and
                  Moustafa Elhamshary and
                  Moustafa Youssef},
	title = {DynamicSLAM: Leveraging Human Anchors for Ubiquitous Low-Overhead
                  Indoor Localization},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {8},
	pages = {2563--2575},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2984320},
	doi = {10.1109/TMC.2020.2984320},
	timestamp = {Tue, 13 Jul 2021 13:26:44 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/ShokryEY21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We present DynamicSLAM: an indoor localization technique that eliminates the need for the daunting calibration step. DynamicSLAM is a novel Simultaneous Localization And Mapping (SLAM) framework that iteratively acquires the feature map of the environment while simultaneously localizing users relative to this map. Specifically, we employ the phone inertial sensors to keep track of the user's path. To compensate for the error accumulation due to the low-cost inertial sensors, DynamicSLAM leverages unique points in the environment (anchors) as observations to reduce the estimated location error. DynamicSLAM introduces the novel concept of mobile human anchors that are based on the encounters with other users in the environment, significantly increasing the number and ubiquity of anchors and boosting localization accuracy. We present different encounter models and show how they are incorporated in a unified probabilistic framework to reduce the ambiguity in the user location. Furthermore, we present a theoretical proof for system convergence and the human anchors ability to reset the accumulated error. Evaluation of DynamicSLAM using different Android phones shows that it can provide a localization accuracy with a median of 1.1m. This accuracy outperforms the state-of-the-art techniques by 55 percent, highlighting DynamicSLAM promise for ubiquitous indoor localization.}
}


@article{DBLP:journals/tmc/CaiDL21,
	author = {Zhipeng Cai and
                  Zhuojun Duan and
                  Wei Li},
	title = {Exploiting Multi-Dimensional Task Diversity in Distributed Auctions
                  for Mobile Crowdsensing},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {8},
	pages = {2576--2591},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2987881},
	doi = {10.1109/TMC.2020.2987881},
	timestamp = {Tue, 13 Jul 2021 13:26:44 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/CaiDL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {To promote development of Mobile Crowdsensing Systems (MCSs), numerous auction schemes have been proposed to motivate mobile users' participation. But, task diversity of MCSs has not been fully explored by most existing works. To further exploit task diversity and improve performance of MCSs, in this paper, we investigate the joint problem of sensing task assignment and schedule with considering multi-dimensional task diversity, including partial fulfillment, bilaterally-multi-schedule, attribute diversity, and price diversity. First, task owner-centric auction model is formulated and two distributed auction schemes (CPAS and TPAS) are proposed such that each task owner can locally process auction procedure. Then, mobile user-centric auction model is established and two distributed auction schemes (VPAS and DPAS) are developed to facilitate local auction implementation. These four auction schemes differ in their approaches to determine winners and compute payments. We further rigorously prove that all the four auction schemes (CPAS, TPAS, VPAS, and DPAS) are computationally-efficient, individually-rational, and incentive-compatible and that both CPAS and TPAS are budget-feasible. Finally, we comprehensively evaluate the effectiveness of CPAS, TPAS, VPAS, and DPAS via comparing with the state-of-the-art in real-data experiments.}
}


@article{DBLP:journals/tmc/XieTLP21,
	author = {Tian Xie and
                  Guan{-}Hua Tu and
                  Chi{-}Yu Li and
                  Chunyi Peng},
	title = {How Can IoT Services Pose New Security Threats In Operational Cellular
                  Networks?},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {8},
	pages = {2592--2606},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2984192},
	doi = {10.1109/TMC.2020.2984192},
	timestamp = {Tue, 07 Mar 2023 08:43:30 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/XieTLP21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Carriers are rolling out Internet of Things (IoT) services including various IoT devices and use scenarios. Compared with conventional non-IoT devices such as smartphones and tablets, IoT devices have limited network capabilities (e.g., low rates) and specific use scenarios (e.g., inside vehicles only). These specialized use scenarios lead to carries often offering cheaper device access fees for IoT devices. However, the aforementioned disparity of service charging between IoT and non-IoT devices may lead to security issues. In this work, we conduct the first empirical security study on cellular IoT service charging over two major US carriers and make three major contributions. First, we discover four security vulnerabilities and analyze their root causes, which help us identify two significant security threats, IoT masquerading and IoT use scenario abuse. Second, we devise three proof-of-concept attacks and assess their real-world impact. We determine that they can be exploited to allow adversaries to pay 43.75-80.00 percent less for cellular data services. Third, we analyze the challenges in addressing these vulnerabilities and develop an anti-abuse solution to mitigate attack incentives. The solution is standard-compliant and can be used immediately in practice. Our prototype and evaluation confirm its effectiveness.}
}


@article{DBLP:journals/tmc/LyuRCYLZS21,
	author = {Feng Lyu and
                  Ju Ren and
                  Nan Cheng and
                  Peng Yang and
                  Minglu Li and
                  Yaoxue Zhang and
                  Xuemin Sherman Shen},
	title = {LeaD: Large-Scale Edge Cache Deployment Based on Spatio-Temporal WiFi
                  Traffic Statistics},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {8},
	pages = {2607--2623},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2984261},
	doi = {10.1109/TMC.2020.2984261},
	timestamp = {Mon, 25 Mar 2024 12:48:07 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/LyuRCYLZS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Widespread and large-scale WiFi systems have been deployed in many corporate locations, while the backhual capacity becomes the bottleneck in providing high-rate data services to a tremendous number of WiFi users. Mobile edge caching is a promising solution to relieve backhaul pressure and deliver quality services by proactively pushing contents to access points (APs). However, how to deploy cache in large-scale WiFi system is not well studied yet quite challenging since numerous APs can have heterogeneous traffic characteristics, and future traffic conditions are unknown ahead. In this paper, given the cache storage budget, we explore the cache deployment in a large-scale WiFi system, which contains 8,000 APs and serves more than 40,000 active users, to maximize the long-term caching gain. Specifically, we first collect two-month user association records and conduct intensive spatio-temporal analytics on WiFi traffic consumption, gaining two major observations. First, per AP traffic consumption varies in a rather wide range and the proportion of AP distributes evenly within the range, indicating that the cache size should be heterogeneously allocated in accordance to the underlying traffic demands. Second, compared to a single AP, the traffic consumption of a group of APs (clustered by physical locations) is more stable, which means that the short-term traffic statistics can be used to infer the future long-term traffic conditions. We then propose our cache deployment strategy, named LeaD (i.e., Large-scale WiFi Edge cAche Deployment), in which we first cluster large-scale APs into well-sized edge nodes, then conduct the stationary testing on edge level traffic consumption and sample sufficient traffic statistics in order to precisely characterize long-term traffic conditions, and finally devise the TEG (Traffic-wEighted Greedy) algorithm to solve the long-term caching gain maximization problem. Extensive trace-driven experiments are carried out, and the results demonstrate that LeaD is able to achieve the near-optimal caching performance and can outperform other benchmark strategies significantly.}
}


@article{DBLP:journals/tmc/LiBLH21,
	author = {Tong Li and
                  Tristan Braud and
                  Yong Li and
                  Pan Hui},
	title = {Lifecycle-Aware Online Video Caching},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {8},
	pages = {2624--2636},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2984364},
	doi = {10.1109/TMC.2020.2984364},
	timestamp = {Tue, 13 Jul 2021 13:26:44 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/LiBLH21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The current explosion of video traffic compels service providers to deploy caches at edge networks. Nowadays, most caching systems store data with a high programming voltage corresponding to the largest possible ‘expiry date’, typically on the order of years, which maximizes the cache damage. However, popular videos rarely exhibit lifecycles longer than a couple of months. Consequently, the programming voltage can instead be adapted to fit the lifecycle and mitigate the cache damage accordingly. In this paper, we propose LiA-cache, a Lifecycle-Aware caching policy for online videos. LiA-cache finds both near-optimal caching retention times and cache eviction policies by optimizing traffic delivery cost and cache damage cost conjointly. We first investigate temporal patterns of video access from a real-world dataset covering 10 million online videos collected by one of the largest mobile network operators in the world. We next cluster the videos based on their access lifecycles and integrate the clustering into a general model of the caching system. Specifically, LiA-cache analyzes videos and caches them depending on their cluster label. Compared to other popular policies in real-world scenarios, LiA-cache can reduce cache damage up to 90 perce, while keeping a cache hit ratio close to a policy purely relying on video popularity.}
}


@article{DBLP:journals/tmc/TaoS21,
	author = {Xi Tao and
                  Wei Song},
	title = {Profit-Oriented Task Allocation for Mobile Crowdsensing With Worker
                  Dynamics: Cooperative Offline Solution and Predictive Online Solution},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {8},
	pages = {2637--2653},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2983688},
	doi = {10.1109/TMC.2020.2983688},
	timestamp = {Tue, 13 Jul 2021 13:26:44 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/TaoS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Mobile crowdsensing (MCS) is a new paradigm of data collection with large-scale sensing. A group of mobile users are recruited as workers to move around in a specific region and carry out sensing tasks. A challenging problem of MCS is task allocation, especially when the MCS platform needs to assign tasks to selected workers among a large user pool and consider mixed spatial and temporal features, including locations and time windows of tasks, and trajectories and arrival time of workers. In this paper, we take into account these features and study the task allocation problem that assigns tasks to workers over time and guarantees the tasks are accomplished before their deadlines. We consider an offline scenario where the MCS platform is informed of all the information of tasks and workers in advance, and an online scenario where the platform does not know the information of workers before they enter the system. For the offline scenario, we provide a cooperative ant colony algorithm with swarm intelligence to approximate the optimal solution in large-scale cases. For the online scenario with incomplete information, we propose several online algorithms, among which the predictive online algorithm exploits historical records of workers and performs the best. Finally, we conduct simulations and evaluate the differences among the online solutions and offline solutions. The results show that the proposed online solutions can approach the offline optimal solution in small-scale cases, and its approximation obtained by the cooperative offline solution in large-scale cases.}
}


@article{DBLP:journals/tmc/GedawyHHH21,
	author = {Hend Gedawy and
                  Karim Habak and
                  Khaled A. Harras and
                  Mounir Hamdi},
	title = {{RAMOS:} {A} Resource-Aware Multi-Objective System for Edge Computing},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {8},
	pages = {2654--2670},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2984134},
	doi = {10.1109/TMC.2020.2984134},
	timestamp = {Tue, 13 Jul 2021 13:26:44 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/GedawyHHH21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Mobile and IoT devices are becoming increasingly capable computing platforms that are often underutilized. In this paper, we propose RAMOS, a system that leverages the idle compute cycles in a group of heterogeneous mobile and IoT devices that can be clustered to form an edge FemtoCloud. At the heart of this system, we formulate a multi-objective, resource-aware task assignment and scheduling problem. The scheduler runs in two main modes; latency-minimization and energy-efficiency. Under the latency-minimization mode, it strives to maximize the computational throughput of the constructed FemtoCloud while maintaining the energy consumption below an operator specified threshold. Under the energy-efficient mode, it minimizes the total energy consumed in the FemtoCloud while meeting defined tasks deadlines. Due to the NP-Completeness of this scheduling problem, we design a set of heuristics to solve it. We implement a prototype of our system and use it to evaluate its performance and efficiency. Our results demonstrate the system's ability to meet different scheduling objectives while adhering to pre-specified time and energy constraints. Compared to other schedulers, RAMOS achieves 10 to 40 percent completion time improvement under latency minimization mode and up to 30 percent more energy-efficiency under the energy-efficient mode.}
}


@article{DBLP:journals/tmc/XieLWYW21,
	author = {Yadong Xie and
                  Fan Li and
                  Yue Wu and
                  Song Yang and
                  Yu Wang},
	title = {Real-Time Detection for Drowsy Driving via Acoustic Sensing on Smartphones},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {8},
	pages = {2671--2685},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2984278},
	doi = {10.1109/TMC.2020.2984278},
	timestamp = {Tue, 13 Jul 2021 13:26:44 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/XieLWYW21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Drowsy driving is one of the biggest threats to driving safety, which has drawn much public attention in recent years. Thus, a simple but robust system that can remind drivers of drowsiness levels with off-the-shelf devices (e.g., smartphones) is very necessary. With this motivation, we explore the feasibility of using acoustic sensors on smartphones to detect drowsy driving. Through analyzing real driving data to study characteristics of drowsy driving, we find some unique patterns of Doppler shift caused by three typical drowsy behaviours (i.e., nodding, yawning and operating steering wheel), among which operating steering wheels is also related to drowsiness levels. Then, a real-time Drowsy Driving Detection system named D 3 -Guard is proposed based on the acoustic sensing abilities of smartphones. We adopt several effective feature extraction methods, and carefully design a high-accuracy detector based on LSTM networks for the early detection of drowsy driving. Besides, measures to distinguish drowsiness levels are also introduced in the system by analyzing the data of operating steering wheel. Through extensive experiments with five drivers in real driving environments, D 3 -Guard detects drowsy driving actions with an average accuracy of 93.31%, as well as classifies drowsiness levels with an average accuracy of 86%.}
}


@article{DBLP:journals/tmc/SekanderTH21,
	author = {Silvia Sekander and
                  Hina Tabassum and
                  Ekram Hossain},
	title = {Statistical Performance Modeling of Solar and Wind-Powered {UAV} Communications},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {8},
	pages = {2686--2700},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2983955},
	doi = {10.1109/TMC.2020.2983955},
	timestamp = {Tue, 23 Aug 2022 09:19:58 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/SekanderTH21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We develop novel statistical models of the harvested energy from renewable energy sources considering harvest-store-consume (HSC) architecture. We consider three renewable energy harvesting scenarios, i.e., (i) harvesting from the solar power, (ii) harvesting from the wind power, and (iii) hybrid solar and wind power. In this context, we first derive the closed-form expressions for the density functions and moments of the harvested power solar and wind power. Then, we calculate the probability of energy outage at UAVs and signal-to-noise ratio (SNR) outage at ground cellular users. The energy outage occurs when the UAV is unable to support the flight consumption and transmission consumption from its battery power and the harvested power. Due to the intricate distribution of the hybrid solar and wind power, we derive novel closed-form expressions for the moment generating function (MGF) of the harvested solar power and wind power. Then, we apply Gil-Pelaez inversion to evaluate the energy outage at the UAV and SNR outage at the ground users. In addition, we formulate the SNR outage minimization problem and obtain closed-form solutions for the transmit power and flight time of the UAV. Furthermore, we demonstrate the application of moments in computing novel metrics such as the probability of charging the UAV battery within the flight time, average UAV battery charging time, probability of energy outage at UAVs, and the probability of eventual energy outage (i.e., the probability of energy outage in a finite duration of time) at UAVs. Numerical results validate the analytical expressions and reveal interesting insights related to the optimal flight time and transmit power of the UAV as a function of the harvested energy.}
}


@article{DBLP:journals/tmc/ZhouEYY21,
	author = {Qian Zhou and
                  Mohammed Elbadry and
                  Fan Ye and
                  Yuanyuan Yang},
	title = {Towards Fine-Grained Access Control in Enterprise-Scale Internet-of-Things},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {8},
	pages = {2701--2714},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2984700},
	doi = {10.1109/TMC.2020.2984700},
	timestamp = {Tue, 13 Jul 2021 13:26:44 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/ZhouEYY21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Scalable, fine-grained access control for Internet-of-Things is needed in enterprise environments, where tens of thousands of users need to access smart objects which have a similar or larger order of magnitude. Existing solutions offer all-or-nothing access, or require all access to go through a cloud backend, greatly impeding access granularity, robustness and scale. In this paper, we propose Heracles, an IoT access control system which achieves robust, fine-grained access control and responsive execution at enterprise scale. Heracles adopts a capability-based approach using secure, unforgeable tokens that describe the authorizations of users, to either individuals or collections of objects in single or bulk operations. It has a 3-tier architecture to provide centralized policy and distributed execution desired in enterprise environments. Extensive analysis and performance evaluation on a testbed prove that Heracles achieves fine-grained access control and responsive execution at enterprise scale. Compared with systems using access control list, Heracles eliminates or reduces by 10x-100x the updating overhead under frequent changes of subject memberships and policies. Besides, Heracles achieves responsive execution: it takes 0.57 second to access 18 objects which are scattered 1-9 hops away, and execution on a 1-hop or 2-hop object needs only 0.07 or 0.13 second respectively.}
}


@article{DBLP:journals/tmc/TomarMJ21,
	author = {Abhinav Tomar and
                  Lalatendu Muduli and
                  Prasanta K. Jana},
	title = {A Fuzzy Logic-Based On-Demand Charging Algorithm for Wireless Rechargeable
                  Sensor Networks With Multiple Chargers},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {9},
	pages = {2715--2727},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2990419},
	doi = {10.1109/TMC.2020.2990419},
	timestamp = {Thu, 12 Aug 2021 17:50:54 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/TomarMJ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Mobile chargers have greatly promoted the wireless rechargeable sensor networks (WRSNs). While most recent works have focused on recharging the WRSNs in an on-demand fashion, little attention has been paid on joint consideration of multiple mobile chargers (MCs) and multi-node energy transfer for determining the charging schedule of energy-hungry nodes. Moreover, most of the schemes leave out the contemplation of multiple network attributes while making scheduling decisions and even they overlook the issue of ill-timed charging response to the nodes with uneven energy consumption rates. In this paper, we address the aforesaid issues together and propose a novel scheduling scheme for on-demand charging in WRSNs. We first present an efficient network partitioning method for distributing the MCs so as to evenly balance their workload. We next adopt the fuzzy logic which blends various network attributes for determining the charging schedule of the MCs. We also formulate an expression to determine the charging threshold for the nodes that vary depending on their energy consumption rate. Extensive simulations are conducted to demonstrate the effectiveness and competitiveness of our scheme. The comparison results reveal that the proposed scheme improves charging performance compared to the state-of-the-art schemes with respect to various performance metrics.}
}


@article{DBLP:journals/tmc/ChenYLJHX21,
	author = {Jianhai Chen and
                  Deshi Ye and
                  Zhenguang Liu and
                  Shouling Ji and
                  Qinming He and
                  Yang Xiang},
	title = {A Truthful and Near-Optimal Mechanism for Colocation Emergency Demand
                  Response},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {9},
	pages = {2728--2744},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2990425},
	doi = {10.1109/TMC.2020.2990425},
	timestamp = {Thu, 12 Aug 2021 17:50:54 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/ChenYLJHX21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Demand response (DR) has been widely adopted as a strategic plan of the electricity market in maintaining power grid reliability, sustainability, and stability. In a typical emergency DR (EDR) that arises in colocation data centers, participating tenants can reduce their power consumption when the supply of electricity is a shortage and be rewarded with financial compensation. In this paper, we study a mechanism design problem of motivating tenants for colocation EDR (MEDR). To solve the MEDR problem, we present a truthful Fully Polynomial-Time Approximation Scheme (FPTAS) which is theoretically proved deterministic, truthful and near-optimal, and can be approximated within 1 + ϵ for any given ϵ > 0, while the running time is in the polynomial of the number of tenants n and ε. To speed up the calculation of the payments, we further study the Vickrey-Clarke-Groves (VCG) based mechanism. Moreover, we build a MEDR auction system (MEDRAS) and implement all mechanism algorithms for a colocation data center. Comprehensive and detailed experiments have been implemented to validate the efficiency of our proposed mechanisms.}
}


@article{DBLP:journals/tmc/YangCBLQ21,
	author = {Bo Yang and
                  Xuelin Cao and
                  Joshua Bassey and
                  Xiangfang Li and
                  Lijun Qian},
	title = {Computation Offloading in Multi-Access Edge Computing: {A} Multi-Task
                  Learning Approach},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {9},
	pages = {2745--2762},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2990630},
	doi = {10.1109/TMC.2020.2990630},
	timestamp = {Thu, 12 Aug 2021 17:50:54 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/YangCBLQ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Multi-access edge computing (MEC) has already shown great potential in enabling mobile devices to bear the computation-intensive applications by offloading some computing jobs to a nearby access point (AP) integrated with a MEC server (MES). However, due to the varying network conditions and limited computational resources of the MES, the offloading decisions taken by a mobile device and the computational resources allocated by the MES can be formulated as a mixed-integer nonlinear programming (MINLP) problem, which may not be optimized with the lowest cost. In this paper, we propose a novel offloading framework for the multi-server MEC network where each AP is equipped with an MES assisting mobile users (MUs) in executing computation-intensive jobs via offloading. Specifically, we formulate the offloading decision problem as a multiclass classification problem and formulate the MES computational resource allocation problem as a regression problem. Then a multi-task learning based feedforward neural network (MTFNN) model is designed and trained to jointly optimize the offloading decision and computational resource allocation. Numerical results show that the proposed MTFNN outperforms the conventional optimization method in terms of inference accuracy and computational complexity.}
}


@article{DBLP:journals/tmc/XiongZZNZ21,
	author = {Zehui Xiong and
                  Jun Zhao and
                  Yang Zhang and
                  Dusit Niyato and
                  Junshan Zhang},
	title = {Contract Design in Hierarchical Game for Sponsored Content Service
                  Market},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {9},
	pages = {2763--2778},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2991060},
	doi = {10.1109/TMC.2020.2991060},
	timestamp = {Thu, 12 Aug 2021 17:50:54 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/XiongZZNZ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With a sponsored content scheme of mobile services, a content provider can encourage end users/subscribers to access its contents, e.g., with an advertisement, by paying part of the data price to the network operator. As a result, the content provider and end users are both actively engaged into the sponsored content ecosystem. As such, a key challenge is how to provide proper sponsorship given the content demand from the users and the service fee charged by the network operator. Furthermore, the information asymmetry between the content provider and users makes the sponsorship problem more challenging. In this paper, we propose a Stackelberg game-based framework to tackle this challenge. In the framework, the network operator, as the leader, determines the data price first, and the content provider as well as users, as the followers, make the decisions on sponsorship and content demand based on the data price, respectively. We model the interaction between the content provider and the users as a contract game in the presence of asymmetric information. In the contract game, the content provider designs a contract that contains its sponsorship strategies toward all types of users. We then derive the necessary and sufficient conditions of feasible contracts and obtain an optimal contract to maximize the profit of the content provider. Taking into account the optimal contract of contract game, we also investigate the optimal pricing of the network operator through backward induction. We prove that the Stackelberg equilibrium is unique under a mild condition and present the numerical results to illustrate some important properties of the equilibrium.}
}


@article{DBLP:journals/tmc/ZhaoXWXHZ21,
	author = {Hui Zhao and
                  Mingjun Xiao and
                  Jie Wu and
                  Yun Xu and
                  He Huang and
                  Sheng Zhang},
	title = {Differentially Private Unknown Worker Recruitment for Mobile Crowdsensing
                  Using Multi-Armed Bandits},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {9},
	pages = {2779--2794},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2990221},
	doi = {10.1109/TMC.2020.2990221},
	timestamp = {Thu, 12 Aug 2021 17:50:54 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/ZhaoXWXHZ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Mobile crowdsensing is a new paradigm by which a platform can recruit mobile workers to perform some sensing tasks by using their smart mobile devices. In this paper, we focus on a privacy-preserving unknown worker recruitment issue. The platform needs to recruit some workers without knowing the qualities of them completing tasks. Meanwhile, these quality information also needs to be protected from disclosure. To tackle these challenges, we model the unknown worker recruitment as a Differentially Private Multi-Armed Bandit (DP-MAB) game by seeing each worker as an arm of DP-MAB and the task completion quality contributed by each worker as the reward of pulling arm. Then, recruiting workers is equivalent to designing a bandit policy of pulling DP-MAB arms. Under this model, we propose a Differentially Private ϵ-First-based arm-pulling (DPF) algorithm and a Differentially Private UCB-based arm-pulling (DPU) algorithm, which can achieve the nearly optimal expected accumulative rewards under a given budget. We also analyze the regrets of the DPF and DPU algorithms and prove that both of them are δ-differentially private on the task completion qualities (δ > 0δ). Finally, we conduct extensive simulations to verify the significant performances of DPF and DPU based on both the real-trace and synthetic datasets.}
}


@article{DBLP:journals/tmc/GhazalianAA21,
	author = {Reza Ghazalian and
                  Ali Aghagolzadeh and
                  Seyed Mehdi Hosseini Andargoli},
	title = {Energy Optimization of Wireless Visual Sensor Networks With the Consideration
                  of the Desired Target Coverage},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {9},
	pages = {2795--2807},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2990596},
	doi = {10.1109/TMC.2020.2990596},
	timestamp = {Thu, 12 Aug 2021 17:50:54 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/GhazalianAA21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Wireless visual sensor networks (WVSN) have recently seen dramatic growth with technology development. These networks consist of a number of smart visual sensors (VSes) that can collect visual information, i.e., images and video captured in a network area. Optimizing the energy consumption and coverage are important contradictory challenges in WVSNs since increase in coverage leads to increase in energy consumption. Therefore, optimization of energy consumption by maintaining image quality defined by user or operator located in sink [quality of experience (QoE)] to be used in target tracking applications is addressed in this paper. The target coverage as well as the quality of the received image of the target are considered as the desired QoE. The novel two-dimensional target coverage model is also presented mathematically. This model is described as a function of the VS inherent parameters, the target position and the visual sensor position. Based on a convex optimization framework, a heuristic approach for the VS selection and the focal length adjustment is suggested to solve the optimization problem while maintaining high image quality. Simulation results are presented to verify the capability and efficiency of the proposed method in comparison with the optimal method (Exhaustive search method).}
}


@article{DBLP:journals/tmc/IslamPBM21,
	author = {Nabiul Islam and
                  Saswati Pal and
                  Sasitharan Balasubramaniam and
                  Sudip Misra},
	title = {Energy-Aware Tracking of Mobile Targets by Bacterial Nanonetworks},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {9},
	pages = {2808--2819},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2990134},
	doi = {10.1109/TMC.2020.2990134},
	timestamp = {Mon, 05 Feb 2024 20:23:20 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/IslamPBM21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The functioning of bacterial nanonetworks as a ”drug delivery system” requires the engineered bacteria to track the targets, such as harmful micro-organisms, pathogens, or chemical weapons, to release drug molecules effectively. The coordinated and intelligent movement of energy-constrained engineered bacteria is desired for successful tracking of mobile targets. In this work, first, we analyze the energy consumption by engineered bacteria for releasing molecules and propagating for the tracking process. Then we show that the events of the release of molecules by engineered bacteria and their propagation are interlinked in such a way that the strategy of releasing attractants upon detecting the target is coupled to the energy available with the engineered bacteria. Based on the finding, we propose an energy-aware algorithm, named as EnPoS, which probabilistically selects a group of engineered bacteria among the deployed bacterial population to release signaling molecules over a particular time period in order for engineered bacteria to track the mobile targets. The simulation results show better performance of the proposed algorithm as compared with the basic algorithm incorporating continuous releasing of signaling molecules, concerning the energy expenses, mean displacement over time, and distribution of the engineered bacteria around the targets.}
}


@article{DBLP:journals/tmc/JiangLJJLLLXL21,
	author = {Hongbo Jiang and
                  Wenping Liu and
                  Guoyin Jiang and
                  Yufu Jia and
                  Xingjun Liu and
                  Zhicheng Lui and
                  Xiaofei Liao and
                  Jing Xing and
                  Daibo Liu},
	title = {Fly-Navi: {A} Novel Indoor Navigation System With On-the-Fly Map Generation},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {9},
	pages = {2820--2834},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2990446},
	doi = {10.1109/TMC.2020.2990446},
	timestamp = {Thu, 12 Aug 2021 17:50:54 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/JiangLJJLLLXL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Existing studies on indoor navigation often require such a pre-deployment as floor map, localization system and/or additional (customized) hardwares, or human motion traces, making them prohibitive when the situation deviates from these requirements (e.g., navigating a crowd of panicking people where no localization system or motion traces are available). The main observation inspiring our work without reliance on such pre-deployment is that when there are sufficient participants (e.g., a crowd of panicking people), the WiFi signatures collected by participants can serve as the fingerprints (referred to as location fingerprints) of their unknown locations. By computing relative positions of these location fingerprints we can connect them to form a global map. Such a map reflects the topology of the underlying walkable space and thus holds the potential of offering a navigation path for any intended users. Based on this observation, we design Fly-Navi, a crowdsourcing based indoor navigation system via on-the-fly map generation, and primarily designed for indoor environments with rectilinear and narrow corridors. Specifically, each participant uploads sensory data, and the server then generates a global map (on-the-fly map) through a series of operations such as local map generation, local map stitch and edge computation. On top of the global map, Fly-Navi computes a navigation path to the given destination and tracks the progress. We implement the prototype of Fly-Navi and our experiments show that Fly-Navi can quickly generate a correct global map with the 80-percentile of between-fingerprint distance error less than 3 meters, which is important for computing turning points of the map and hereon offering turn-by-turn instructions, and correctly navigate the intended users to their destinations.}
}


@article{DBLP:journals/tmc/SamirEASG21,
	author = {Moataz Samir and
                  Dariush Ebrahimi and
                  Chadi Assi and
                  Sanaa Sharafeddine and
                  Ali Ghrayeb},
	title = {Leveraging UAVs for Coverage in Cell-Free Vehicular Networks: {A}
                  Deep Reinforcement Learning Approach},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {9},
	pages = {2835--2847},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2991326},
	doi = {10.1109/TMC.2020.2991326},
	timestamp = {Thu, 12 Aug 2021 17:50:54 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/SamirEASG21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The success in transitioning towards smart cities relies on the availability of information and communication technologies that meet the demands of this transformation. The terrestrial infrastructure presents itself as a preeminent component in this change. Unmanned aerial vehicles (UAVs) empowered with artificial intelligence (AI) are expected to become an integral component of future smart cities that provide seamless coverage for vehicles on highways with poor cellular infrastructure. Motivated by the above, in this paper, we introduce UAVs cell-free network for providing coverage to vehicles entering a highway that is not covered by other infrastructure. However, UAVs have limited energy resources and cannot serve the entire highway all the time. Furthermore, the deployed UAVs have insufficient knowledge about the environment (e.g., the vehicles' instantaneous location). Therefore, it is challenging to control a swarm of UAVs to achieve efficient communication coverage. To address these challenges, we formulate the trajectories decisions making as a Markov decision process (MDP) where the system state space considers the vehicular network dynamics. Then, we leverage deep reinforcement learning (DRL) to propose an approach for learning the optimal trajectories of the deployed UAVs to efficiently maximize the vehicular coverage, where we adopt Actor-Critic algorithm to learn the vehicular environment and its dynamics to handle the complex continuous action space. Finally, simulations results are provided to verify our findings and demonstrate the effectiveness of the proposed design and show that during the mission time, the deployed UAVs adapt their velocities in order to cover the vehicles.}
}


@article{DBLP:journals/tmc/YuLW21,
	author = {Yiding Yu and
                  Soung Chang Liew and
                  Taotao Wang},
	title = {Non-Uniform Time-Step Deep Q-Network for Carrier-Sense Multiple Access
                  in Heterogeneous Wireless Networks},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {9},
	pages = {2848--2861},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2990399},
	doi = {10.1109/TMC.2020.2990399},
	timestamp = {Thu, 12 Aug 2021 17:50:54 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/YuLW21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper investigates a new class of carrier-sense multiple access (CSMA) protocols that employ deep reinforcement learning (DRL) techniques, referred to as carrier-sense deep-reinforcement learning multiple access (CS-DLMA). The goal of CS-DLMA is to enable efficient and equitable spectrum sharing among a group of co-located heterogeneous wireless networks. Existing CSMA protocols, such as the medium access control (MAC) protocol of WiFi, are designed for a homogeneous network in which all nodes adopt the same protocol. Such protocols suffer from severe performance degradation in a heterogeneous environment where there are nodes adopting other MAC protocols. CS-DLMA aims to circumvent this problem by making use of DRL. In particular, this paper adopts α-fairness as the general objective of CS-DLMA. With α-fairness, CS-DLMA can achieve a range of different objectives (e.g., maximizing sum throughput, achieving proportional fairness, or achieving max-min fairness) when coexisting with other MACs by changing the value of α. A salient feature of CS-DLMA is that it can achieve these objectives without knowing the coexisting MACs through a learning process based on DRL. The underpinning DRL technique in CS-DLMA is deep Q-network (DQN). However, the conventional DQN algorithms are not suitable for CS-DLMA due to their uniform time-step assumption. In CSMA protocols, time steps are non-uniform in that the time duration required for carrier sensing is smaller than the duration of data transmission. This paper introduces a non-uniform time-step formulation of DQN to address this issue. Our simulation results show that CS-DLMA can achieve the general α-fairness objective when coexisting with TDMA, ALOHA, and WiFi protocols by adjusting its own transmission strategy. Interestingly, we also find that CS-DLMA is more Pareto efficient than other CSMA protocols, e.g., p-persistent CSMA, when coexisting with WiFi. Although this paper focuses on the use of our non-uniform time-step DQN formulation in wireless networking, we believe this new DQN formulation can also find use in other domains.}
}


@article{DBLP:journals/tmc/WuWW21,
	author = {Ji{-}Yan Wu and
                  Kaishun Wu and
                  Ming Wang},
	title = {Power-Constrained Quality Optimization for Mobile Video Chatting With
                  Coding-Transmission Adaptation},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {9},
	pages = {2862--2876},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2990374},
	doi = {10.1109/TMC.2020.2990374},
	timestamp = {Thu, 12 Aug 2021 17:50:54 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/WuWW21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Mobile video chatting has emerged as an important Internet multimedia application that greatly enriches interpersonal communications. Mobile power efficiency is crucial to the service quality and time of video chatting on battery-limited smartphones. However, the power characteristics of the video coding and data communication are highly complex due to the time-varying network conditions and dynamic mobile energy features. This incurs crucial challenges to maintaining the low power dissipation of mobile chatting application while streaming satisfactory-quality videos. To address these challenges, this paper presents a joinT cOding-tranSmission Optimization (TOSO) protocol at application layer that performs machine learning based adaptation of the video bit rate and FEC (Forward Error Correction) coding parameters. By taking advantage of analytical and empirical models characterizing the quality-power relationship, TOSO is able to maximize video quality subject to a specified upper bound of power consumption in mobile chat application. This distinguishing feature prevents the video chat from draining battery too quickly. Moreover, it allows the smartphone operating system or the mobile user to define a desired video chat duration given the remaining battery, avoiding unpleasant conversation disruption due to battery depletion. Extensive experiments based on the Linphone platform and Exata network emulator show that TOSO outperforms baseline approaches by 29.3 percent in power conservation while achieving the same video quality level.}
}


@article{DBLP:journals/tmc/NieminenJ21,
	author = {Raine Nieminen and
                  Kimmo J{\"{a}}rvinen},
	title = {Practical Privacy-Preserving Indoor Localization Based on Secure Two-Party
                  Computation},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {9},
	pages = {2877--2890},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2990871},
	doi = {10.1109/TMC.2020.2990871},
	timestamp = {Wed, 15 Dec 2021 10:30:42 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/NieminenJ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We present a privacy-preserving indoor localization scheme based on received signal strength measurements, e.g., from WiFi access points. Our scheme preserves the privacy of both the client's location and the service provider's database by using secure two-party computation instantiated with known cryptographic primitives, namely, Paillier encryption and garbled circuits. We describe a number of optimizations that reduce the computation and communication overheads of the scheme and provide theoretical evaluations of these overheads. We also demonstrate the feasibility of the scheme by developing a proof-of-concept implementation for Android smartphones and commodity servers. This implementation allows us to validate the practical performance of our scheme and to show that it is feasible for practical use in certain types of indoor localization applications.}
}


@article{DBLP:journals/tmc/LiuYZXO21,
	author = {Xuan Liu and
                  Jiangjin Yin and
                  Shigeng Zhang and
                  Bin Xiao and
                  Bo Ou},
	title = {Time-Efficient Target Tags Information Collection in Large-Scale {RFID}
                  Systems},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {9},
	pages = {2891--2905},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2992256},
	doi = {10.1109/TMC.2020.2992256},
	timestamp = {Thu, 12 Aug 2021 17:50:54 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/LiuYZXO21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {By integrating the micro-sensor on RFID tags to obtain the environment information, the sensor-augmented RFID system greatly supports the applications that are sensitive to environment. To quickly collect the information from all tags, many researchers dedicate on well arranging tag replying orders to avoid the signal collisions. Compared to from all tags, collecting information from a part of tags (i.e., target tags) is more challenging because the collecting process is interfered by useless replying from non-target tags. The existing works of target tag information collection are designed for single reader systems. However, they cannot work efficiently in more common multi-reader scenarios, where each reader lacks knowledge of tag distribution among all readers. In this paper, we propose time-efficient protocols to collect target tag information in multi-reader systems. The high efficiency of our protocol is enabled by two novel designs. First, we develop a technique that quickly detects and silences non-target tags without a priori knowledge of which tags are in the readers’ interrogation regions. Second, we design an allocation vector to efficiently arrange the replying order of only target tags. Different from previous bit-vector based approaches that make use of only singleton slots, our allocation vector approach also makes use of collision slots to speed up target tag information collection. We further propose an enhancement protocol which can reconcile the collision slots with higher probability and therefore collect information from more target tags simultaneously. The extensive simulation results demonstrate that our protocols significantly outperform the state-of-the-art protocols in terms of time-efficiency.}
}


@article{DBLP:journals/tmc/CastagnoMSM21,
	author = {Paolo Castagno and
                  Vincenzo Mancuso and
                  Matteo Sereno and
                  Marco Ajmone Marsan},
	title = {A Simple Model of {MTC} Flows Applied to Smart Factories},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {10},
	pages = {2906--2923},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2993223},
	doi = {10.1109/TMC.2020.2993223},
	timestamp = {Thu, 16 Sep 2021 18:03:39 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/CastagnoMSM21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper we develop a simple, yet accurate, performance model to understand if and how evolutions of standard cellular network protocols can be exploited to allow large numbers of machine type devices to access transmission resources with short latency, and we apply our model to the performance analysis of smart factory radio access networks. The model results shed light on the problems resulting from the application of evolved standard access procedures and help understand how many devices can be served per base station with specified latency targets. In addition, considering the simultaneous presence of different traffic classes, we investigate the effectiveness of prioritised access, exploiting access class barring techniques. Our model shows that, even with the sub-millisecond time slots foreseen in LTE Advanced Pro and 5G, a base station can accommodate at most few thousand devices to guarantee access latency below 100 ms with high transmission success probability. Lower access latency, of the order of 10 ms, can be achieved only with base stations serving an unrealistically small numbers of devices. This calls for a rethinking of wireless access strategies to avoid excessive latency in ultra-dense cell deployments within smart factory's infrastructures.}
}


@article{DBLP:journals/tmc/PaulWX21,
	author = {Prosanta Paul and
                  Hongyi Wu and
                  Chunsheng Xin},
	title = {{BOOST:} {A} User Association and Scheduling Framework for Beamforming
                  mmWave Networks},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {10},
	pages = {2924--2935},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2992623},
	doi = {10.1109/TMC.2020.2992623},
	timestamp = {Thu, 16 Sep 2021 18:03:39 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/PaulWX21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The millimeter wave (mmWave) band offers vast bandwidth and plays a key role for next generation wireless networks. However, the mmWave network raises a great challenge for user association and scheduling, due to the limited power budget and beamformers, diverse user traffic loads, user quality of service requirement, etc. In this paper, we propose a novel framework for user association and scheduling in multi-base station mmWave networks, termed the clustering Based dOwnlink UE assOciation, Scheduling, beamforming with power allocaTion (BOOST). The objective is to reduce the downlink network transmission time, subject to the base station power budget, number of beamformers, user traffic loads, and the quality of service requirement at users. We compare BOOST with three state-of-the-art user scheduling schemes. On average, BOOST reduces the transmission time by 37, 30, and 26 percent, and achieves a sum rate gain of 56, 43, and 34 percent, respectively.}
}


@article{DBLP:journals/tmc/Mosavat-Jahromi21,
	author = {Hamed Mosavat{-}Jahromi and
                  Yue Li and
                  Yuanzhi Ni and
                  Lin Cai},
	title = {Distributed and Adaptive Reservation {MAC} Protocol for Beaconing
                  in Vehicular Networks},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {10},
	pages = {2936--2948},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2992045},
	doi = {10.1109/TMC.2020.2992045},
	timestamp = {Thu, 16 Sep 2021 18:03:39 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/Mosavat-Jahromi21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In vehicular ad hoc networks (VANETs), beacon broadcasting plays a critical role in improving road safety and avoiding hazardous situations. How to ensure reliability and scalability of beacon broadcasting is a difficult and open problem, due to high mobility, dynamic network topology, hidden terminal, and varying density in both the time and location domains. In this paper, wireless resources are divided into basic resource units in the time and frequency domains, and a distributed and adaptive reservation based MAC protocol (DARP) is proposed to solve the above problem. For decentralized control in VANETs, each vehicle's channel access is coordinated with its neighbors to solve the hidden terminal problem. To ensure the reliability of beacon broadcasting, different kinds of preambles are applied in DARP to support distributed reservation, detect beacon collisions, and resolve collisions. Once a vehicle reserves a resource unit successfully, it will not release it until collision occurs due to topology change. The protocol performance in terms of access collision probability and access delay are analyzed. Based on the analysis, protocol parameters, including transmission power and time slots duration, can be adjusted to reduce collision probability and enhance reliability and scalability. Using NS-3 with vehicle traces generated by simulation of urban mobility (SUMO), simulation results show that the proposed DARP protocol can achieve the design goals of reliability and scalability, and it substantially outperforms the existing standard solutions.}
}


@article{DBLP:journals/tmc/KoP21,
	author = {Haneul Ko and
                  Sangheon Pack},
	title = {Distributed Device-to-Device Offloading System: Design and Performance
                  Optimization},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {10},
	pages = {2949--2960},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2994138},
	doi = {10.1109/TMC.2020.2994138},
	timestamp = {Thu, 16 Sep 2021 18:03:39 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/KoP21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In task offloading systems, it is imperative to guarantee that an offloaded task is completed within a pre-specified deadline. In this paper, we propose a distributed device-to-device (D2D) offloading system (DDOS) in which a task owner opportunistically broadcasts an offloading request that includes its mobility level and task completion deadline. After receiving the request, mobile devices in the vicinity of the task owner employ a constraint stochastic game to decide, in a distributed manner, whether to accept the request or not. We devise a best response dynamics-based algorithm (BRDA) to obtain a multi-policy constrained Nash equilibrium. Evaluation results demonstrate that DDOS can guarantee a high on-time task completion probability, as well as a low energy consumption.}
}


@article{DBLP:journals/tmc/00060ZTC21,
	author = {Fan Wu and
                  Shuo Yang and
                  Zhenzhe Zheng and
                  Shaojie Tang and
                  Guihai Chen},
	title = {Fine-Grained User Profiling for Personalized Task Matching in Mobile
                  Crowdsensing},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {10},
	pages = {2961--2976},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2993963},
	doi = {10.1109/TMC.2020.2993963},
	timestamp = {Tue, 02 Jan 2024 17:01:00 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/00060ZTC21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In mobile crowdsensing, finding the best match between tasks and users is crucial to ensure both the quality and effectiveness of a crowdsensing system. Existing works usually assume a centralized task assignment by the crowdsensing platform, without addressing the need of fine-grained personalized task matching. In this paper, we argue that it is essential to match tasks to users based on a careful characterization of both the users' preference and reliability. To that end, we propose a personalized task recommender system for mobile crowdsensing, which recommends tasks to users based on a recommendation score that jointly takes each user's preference and reliability into consideration. We first present a hybrid preference metric to characterize users' preference by exploiting their implicit feedback. Then, to profile users' reliability levels, we formalize the problem as a semi-supervised learning model, and propose an efficient block coordinate descent algorithm to solve the problem. For some tasks that lack users' historical information, we further propose a matrix factorization method to infer the users' reliability levels on those tasks. We conduct extensive experiments to evaluate the performance of our system, and the evaluation results demonstrate that our system can achieve superior performance to the benchmarks in both user profiling and personalized task recommendation.}
}


@article{DBLP:journals/tmc/OkegbileMA21,
	author = {Samuel Dayo Okegbile and
                  Bodhaswar T. Maharaj and
                  Attahiru Sule Alfa},
	title = {Interference Characterization in Underlay Cognitive Networks With
                  Intra-Network and Inter-Network Dependence},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {10},
	pages = {2977--2991},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2993408},
	doi = {10.1109/TMC.2020.2993408},
	timestamp = {Thu, 16 Sep 2021 18:03:39 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/OkegbileMA21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Interference modeling in cognitive radio network is important to ensure adequate coverage in the network. A reliable interference model, however, depends on accurately characterizing the distribution of users. In this paper, the dependence between primary and secondary networks is examined in order to capture more system parameters related to system characterization. Hence, two cases are considered - primary user (PU) interference control and PU with secondary user (SU) interference control mechanisms. Under PU interference control, distributions of PUs follow the Matern hard core process while the distribution of SUs follow the Poisson hole process (PHP). However, under PU with SU interference control, the distribution of active SUs follow a modified PHP. Bound and approximate expressions were derived for coverage probability at both primary and secondary networks, while simple yet accurate expressions were obtained to depict the number of simultaneous active users supported for the two cases. The tight closeness between the bound and the approximate expressions shows the reliability of the presented theoretical analysis. Furthermore, the bipolar network model assumption was relaxed while the case of independence assumption among users was also considered. Numerical result showed close tightness when the bipolar network model assumption was relaxed while the independence assumption was shown to overestimate users' coverage probability.}
}


@article{DBLP:journals/tmc/BozorgchenaniMT21,
	author = {Arash Bozorgchenani and
                  Farshad Mashhadi and
                  Daniele Tarchi and
                  Sergio A. Salinas Monroy},
	title = {Multi-Objective Computation Sharing in Energy and Delay Constrained
                  Mobile Edge Computing Environments},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {10},
	pages = {2992--3005},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2994232},
	doi = {10.1109/TMC.2020.2994232},
	timestamp = {Thu, 16 Sep 2021 18:03:39 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/BozorgchenaniMT21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In a mobile edge computing (MEC) network, mobile devices, also called edge clients, offload their computations to multiple edge servers that provide additional computing resources. Since the edge servers are placed at the network edge, e.g., cell-phone towers, transmission delays between edge servers and edge clients are shorter compared to those of cloud computing. In addition, edge clients can offload their tasks to other nearby edge clients with available computing resources by exploiting the Fog Computing (FC) paradigm. A major challenge in MEC and FC networks is to assign the tasks from edge clients to edge servers, as well as to other edge clients, in such a way that their tasks are completed with minimum energy consumption and minimum processing delay. In this paper, we model task offloading in MEC as a constrained multi-objective optimization problem (CMOP) that minimizes both the energy consumption and task processing delay of the mobile devices. To solve the CMOP, we design an evolutionary algorithm that can efficiently find a representative sample of the best trade-offs between energy consumption and task processing delay, i.e., the Pareto-optimal front. Compared to existing approaches for task offloading in MEC, we see that our approach finds offloading decisions with lower energy consumption and task processing delay.}
}


@article{DBLP:journals/tmc/Shaham00DL021,
	author = {Sina Shaham and
                  Ming Ding and
                  Bo Liu and
                  Shuping Dang and
                  Zihuai Lin and
                  Jun Li},
	title = {Privacy Preservation in Location-Based Services: {A} Novel Metric
                  and Attack Model},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {10},
	pages = {3006--3019},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2993599},
	doi = {10.1109/TMC.2020.2993599},
	timestamp = {Mon, 20 Sep 2021 17:04:44 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/Shaham00DL021.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recent years have seen rising needs for location-based services in our everyday life. Aside from the many advantages provided by these services, they have caused serious concerns regarding the location privacy of users. Adversaries can monitor the queried locations by users to infer sensitive information, such as home addresses and shopping habits. To address this issue, dummy-based algorithms have been developed to increase the anonymity of users, and thus, protecting their privacy. Unfortunately, the existing algorithms only assume a limited amount of side information known by adversaries, which may face more severe challenges in practice. In this paper, we develop an attack model termed as Viterbi attack, which represents a realistic privacy threat on user trajectories. Moreover, we propose a metric called transition entropy that enables the evaluation of dummy-based algorithms, followed by developing a robust algorithm that can defend users against the Viterbi attack while maintaining significantly high performance in terms of the traditional metrics. We compare and evaluate our proposed algorithm and metric on a publicly available dataset published by Microsoft, i.e., Geolife dataset.}
}


@article{DBLP:journals/tmc/GuanKM21,
	author = {Zhangyu Guan and
                  Hovannes Kulhandjian and
                  Tommaso Melodia},
	title = {Stochastic Channel Access in Underwater Networks With Statistical
                  Interference Modeling},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {10},
	pages = {3020--3033},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2993026},
	doi = {10.1109/TMC.2020.2993026},
	timestamp = {Thu, 16 Sep 2021 18:03:39 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/GuanKM21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Designing efficient medium access control protocols for underwater acoustic sensor networks (UW-ASNs) is a major challenge because of the spatial and temporal interference uncertainty caused by asynchronous transmissions and by the low propagation speed of sound. To address these challenges, in this article we propose a new approach for distributed underwater medium access based on lightweight and asynchronous distributed algorithms that optimize the access probability profile over a series of time slots based on a new statistical physical interference model. The latter is based on measuring the level of interference at multiple instants of time in each time slot in order to capture the effects of temporal uncertainty and of unaligned interference. At each measurement instant, the statistical properties of time-varying interference are represented by a Gamma probability distribution. The model is validated through extensive channel measurement experiments conducted with an underwater acoustic testbed in Lake LaSalle. Based on this model, we formulate the problem of queue-aware stochastic channel access. The objective is to maximize the sum throughput of a set of concurrent and mutually interfering source-destination pairs by letting the transmitters adjust their own transmission probability profiles, without collaborating with each other, over a series of time slots based on a statistical characterization of interference obtained through past observations. We propose an iterative distributed solution algorithm for this problem based on a best-response strategy. At each iteration, each node individually solves a non-convex optimization problem of logarithmic complexity. The performance of the proposed distributed algorithm is evaluated by comparing it with two alternative distributed schemes and with the global optimum obtained through a newly-developed centralized globally optimal solution algorithm. Results indicate that by jointly taking the queueing and multi-slot optimization into consideration considerable improvement in terms of sum-throughput can be achieved by the proposed distributed algorithm.}
}


@article{DBLP:journals/tmc/Jiao0N0K21,
	author = {Yutao Jiao and
                  Ping Wang and
                  Dusit Niyato and
                  Bin Lin and
                  Dong In Kim},
	title = {Toward an Automated Auction Framework for Wireless Federated Learning
                  Services Market},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {10},
	pages = {3034--3048},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2994639},
	doi = {10.1109/TMC.2020.2994639},
	timestamp = {Thu, 16 Sep 2021 18:03:39 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/Jiao0N0K21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In traditional machine learning, the central server first collects the data owners' private data together and then trains the model. However, people's concerns about data privacy protection are dramatically increasing. The emerging paradigm of federated learning efficiently builds machine learning models while allowing the private data to be kept at local devices. The success of federated learning requires sufficient data owners to jointly utilize their data, computing and communication resources for model training. In this article, we propose an auction-based market model for incentivizing data owners to participate in federated learning. We design two auction mechanisms for the federated learning platform to maximize the social welfare of the federated learning services market. Specifically, we first design an approximate strategy-proof mechanism which guarantees the truthfulness, individual rationality, and computational efficiency. To improve the social welfare, we develop an automated strategy-proof mechanism based on deep reinforcement learning and graph neural networks. The communication traffic congestion and the unique characteristics of federated learning are particularly considered in the proposed model. Extensive experimental results demonstrate that our proposed auction mechanisms can efficiently maximize the social welfare and provide effective insights and strategies for the platform to organize the federated training.}
}


@article{DBLP:journals/tmc/Xue00RL0SH21,
	author = {Wanli Xue and
                  Chengwen Luo and
                  Yiran Shen and
                  Rajib Rana and
                  Guohao Lan and
                  Sanjay Jha and
                  Aruna Seneviratne and
                  Wen Hu},
	title = {Towards a Compressive-Sensing-Based Lightweight Encryption Scheme
                  for the Internet of Things},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {10},
	pages = {3049--3065},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2992737},
	doi = {10.1109/TMC.2020.2992737},
	timestamp = {Thu, 16 Sep 2021 18:03:39 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/Xue00RL0SH21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Internet of Things (IoT) is flourishing and has penetrated deeply into people's daily life. With the seamless connection to the physical world, IoT provides tremendous opportunities to a wide range of applications. However, potential risks exist when the IoT system collects sensor data and uploads it to the Cloud. The leakage of private data can be severe with curious database administrator or malicious hackers who compromise the Cloud. In this work, we propose Kryptein, a compressive-sensing-based lightweight encryption scheme for Cloud-enabled IoT systems to secure the interaction between the IoT devices and the Cloud. Kryptein supports random compressed encryption, statistical computation over cipher, and accurate raw data decryption. According to our evaluation based on two real datasets, Kryptein provides strong protection to the data. It is 250 times faster than other state-of-the-art systems and incurs 120 times less energy consumption. The performance of Kryptein is also measured on off-the-shelf IoT devices, and the result shows Kryptein can run efficiently on IoT devices. After comparing with other state-of-the-art lightweight ciphers on IoT (Simon and Speck), IoT system with Kryptein is expected to have a much more longevity with about 35 percent extended lifetime. Further, experiments illustrated IoT data variance will not affect Kryptein's accuracy in a long term usage, and Krpytein is also able to support basic analytics tasks like machine learning (e.g., classification).}
}


@article{DBLP:journals/tmc/FuHZDPGZM21,
	author = {Hao Fu and
                  Pengfei Hu and
                  Zizhan Zheng and
                  Aveek K. Das and
                  Parth H. Pathak and
                  Tianbo Gu and
                  Sencun Zhu and
                  Prasant Mohapatra},
	title = {Towards Automatic Detection of Nonfunctional Sensitive Transmissions
                  in Mobile Applications},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {10},
	pages = {3066--3080},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2992253},
	doi = {10.1109/TMC.2020.2992253},
	timestamp = {Tue, 19 Sep 2023 16:49:26 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/FuHZDPGZM21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {While mobile apps often need to transmit sensitive information out to support various functionalities, they may also abuse the privilege by leaking the data to unauthorized third parties. This makes us question: Is the given transmission required to fulfill the app functionality? In this paper, we make the first attempt to automatically identify suspicious transmissions from app visual interfaces, including app names, descriptions, and user interfaces. We design and implement a novel framework called FlowIntent to detect nonfunctional transmissions at both software and network levels. During the exercising of the given apps, FlowIntent automatically detects privacy-sharing transmissions and determines their purposes by utilizing the fact that mobile users rely on visible app interface to perceive the functionality of the app at certain context. The characterizations of nonfunctional network traffic are then summarized to provide network level protection. FlowIntent not only reduces the false alarms caused by traditional taint analysis, but also captures the sensitive transmissions missed by widely-used taint analysis system TaintDroid. Evaluation using 2125 sharing flows collected from more than a thousand running instances shows that our approach achieves about 94 percent accuracy in detecting nonfunctional transmissions.}
}


@article{DBLP:journals/tmc/OzcanR21,
	author = {Yigit {\"{O}}zcan and
                  Catherine Rosenberg},
	title = {Uplink Scheduling in Multi-Cell {OFDMA} Networks: {A} Comprehensive
                  Study},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {10},
	pages = {3081--3098},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2994354},
	doi = {10.1109/TMC.2020.2994354},
	timestamp = {Thu, 16 Sep 2021 18:03:39 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/OzcanR21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper proposes a comprehensive study of uplink scheduling in multi-cell OFDMA networks. We first focus on two scenarios for the homogeneous case, one without and one with a Cloud-RAN (C-RAN), and explore how to design efficient practical uplink schedulers for those scenarios. To compute the best achievable performance (BAP) under complete information, we study a centralized multi-cell scheduler. To this end, we formulate an MINLP problem and show how to solve it quasi-optimally. Then, we study the performance of an existing practical local benchmark scheduler (LBM) in terms of goodput and losses. We compare its performance to BAP and show that LBM only yields 44 percent of BAP. To reduce this performance gap, we propose two practical enhancements for LBM, one per scenario. The enhanced scheduler for the first scenario yields 51 percent of BAP (70 percent for the second). To reduce the gap further, we propose a new scheduler inspired by soft-frequency reuse (SFR). Its performance is 69 percent (resp. 83 percent) of BAP. It outperforms LBM by 56 percent for the scenario without C-RAN (84 percent with C-RAN). We finally extend our SFR-based scheduler to heterogeneous networks and show that it outperforms LBM by 53 percent for the scenario without C-RAN (96 percent with C-RAN).}
}


@article{DBLP:journals/tmc/BartoliniCMK21,
	author = {Novella Bartolini and
                  Andrea Coletta and
                  Gaia Maselli and
                  Al{\'{a}} F. Khalifeh},
	title = {A Multi-Trip Task Assignment for Early Target Inspection in Squads
                  of Aerial Drones},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {11},
	pages = {3099--3116},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2994529},
	doi = {10.1109/TMC.2020.2994529},
	timestamp = {Fri, 21 Jan 2022 22:01:10 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/BartoliniCMK21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Fleets of cooperative drones are a powerful tool in monitoring critical scenarios requiring early anomaly discovery and intervention. Due to limited energy availability and application requirements, drones may visit target points in consecutive trips, with recharging and data offloading in between. To capture timeliness of intervention and prioritize early coverage, we propose the new notion of Weighted Progressive Coverage, which is based on the definition of time dependent weights. Weighted progressive coverage generalizes classic notions of coverage, as well as a new notion of accumulative coverage specifically designed to address trip scheduling. We show that weighted progressive coverage maximization is NP-hard and propose an efficient polynomial algorithm, called Greedy and Prune (GaP), with guaranteed approximation. By means of simulations we show that GaP performs close to the optimal solution and outperforms a previous approach in all the considered performance metrics, including coverage, average inspection delay, energy consumption, and computation time, in a wide range of application scenarios. Through prototype experiments we also confirm the theoretical and simulation analysis, and demonstrate the applicability of our algorithm in real scenarios.}
}


@article{DBLP:journals/tmc/LiHHFCC21,
	author = {Songyuan Li and
                  Shibo He and
                  Kang Hu and
                  Lingkun Fu and
                  Shuo Chen and
                  Jiming Chen},
	title = {Operation State Scheduling Towards Optimal Network Utility in RF-Powered
                  Internet of Things},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {11},
	pages = {3117--3130},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2995256},
	doi = {10.1109/TMC.2020.2995256},
	timestamp = {Wed, 03 Nov 2021 08:27:12 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/LiHHFCC21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {RF power transfer is becoming a reliable solution to energy supplement of Internet of Things (IoT) in recent years, thanks to the emerging off-the-shelf wireless charging and sensing platforms. However, as a core component of IoT, sensor nodes mounted with these platforms can not work and harvest energy simultaneously, due to the low-manufacture-cost requirement. This leads to a new design challenge of optimally scheduling sensor nodes’ operation states: working or recharging, to achieve a desirable network utility. In our design, we first consider a single-hop special case of small-scale networks. We transform the operation state scheduling problem into a linear programming problem, and obtain an optimal analytical solution. Then a general case of large-scale multi-hop networks is investigated. The multi-hop operation state scheduling problem is proved to be NP-hard. We show that the spatiotemporal coupling caused by time-varying network topology makes the problem quite challenging. Based on Lyapunov optimization technique, we design a State Scheduling Algorithm (SSA) with a proved performance guarantee. Our algorithm decouples the primal problem by defining a dynamic energy threshold vector, which successfully schedules each sensor node to the desirable state according to its energy level. To verify our design, the SSA is implemented on a Powercast wireless charging and sensing testbed, achieving about 85 percent of the theoretical optimal with quite low time complexity. Furthermore, numerous simulation results demonstrate that the SSA outperforms the baseline algorithms and achieves good performance under different network settings.}
}


@article{DBLP:journals/tmc/XieTYLPZLL21,
	author = {Tian Xie and
                  Guan{-}Hua Tu and
                  Bangjie Yin and
                  Chi{-}Yu Li and
                  Chunyi Peng and
                  Mi Zhang and
                  Hui Liu and
                  Xiaoming Liu},
	title = {The Untold Secrets of WiFi-Calling Services: Vulnerabilities, Attacks,
                  and Countermeasures},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {11},
	pages = {3131--3147},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2995509},
	doi = {10.1109/TMC.2020.2995509},
	timestamp = {Fri, 28 Apr 2023 23:58:24 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/XieTYLPZLL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Since 2016, all of four major U.S. operators have rolled out Wi-Fi calling services. They enable mobile users to place cellular calls over Wi-Fi networks based on the 3GPP IMS technology. Compared with conventional cellular voice solutions, the major difference lies in that their traffic traverses untrusted Wi-Fi networks and the Internet. This exposure to insecure networks can cause the Wi-Fi calling users to suffer from security threats. Its security mechanisms are similar to the VoLTE, because both of them are supported by the IMS. They include SIM-based security, 3GPP AKA, IPSec, etc. However, are they sufficient to secure Wi-Fi calling services? Unfortunately, our study yields a negative answer. We conduct the first security study on the operational Wi-Fi calling services in three major U.S. operators networks using commodity devices. We disclose that current Wi-Fi calling security is not bullet-proof and uncover three vulnerabilities. By exploiting the vulnerabilities, we devise two proof-of-concept attacks: telephony harassment or denial of voice service and user privacy leakage; both of them can bypass the existing security defenses. We have confirmed their feasibility using real-world experiments, as well as assessed their potential damages and proposed a solution to address all identified vulnerabilities.}
}


@article{DBLP:journals/tmc/KongLYCT21,
	author = {Hao Kong and
                  Li Lu and
                  Jiadi Yu and
                  Yingying Chen and
                  Feilong Tang},
	title = {Continuous Authentication Through Finger Gesture Interaction for Smart
                  Homes Using WiFi},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {11},
	pages = {3148--3162},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2994955},
	doi = {10.1109/TMC.2020.2994955},
	timestamp = {Wed, 03 Nov 2021 08:27:11 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/KongLYCT21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The development of smart homes has advanced the concept of user authentication to not only protecting user privacy but also facilitating personalized services to users. Along this direction, we propose to integrate user authentication with human-computer interactions between users and smart household appliances through widely-deployed WiFi infrastructures, which is non-intrusive and device-free. In this paper, we propose FingerPass which leverages channel state information (CSI) of surrounding WiFi signals to continuously authenticate users through finger gestures in smart homes. FingerPass separates the user authentication process into two stages, login and interaction, to achieve high authentication accuracy and low response latency simultaneously. In the login stage, we develop a deep learning-based approach to extract behavioral characteristics of finger gestures for highly accurate user identification. For the interaction stage, to provide continuous authentication in real time for satisfactory user experience, we design a verification mechanism with lightweight classifiers to continuously authenticate the user’s identity during each interaction of finger gestures. Experiments in real environments show that FingerPass can achieve the authentication accuracies of 90.6 percent under in-domain scenarios and 87.6 percent under cross-domain scenarios, as well as 186.6\\;ms response time during interactions.}
}


@article{DBLP:journals/tmc/DaiSLZZC21,
	author = {Haipeng Dai and
                  Ke Sun and
                  Alex X. Liu and
                  Lijun Zhang and
                  Jiaqi Zheng and
                  Guihai Chen},
	title = {Charging Task Scheduling for Directional Wireless Charger Networks},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {11},
	pages = {3163--3180},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2997602},
	doi = {10.1109/TMC.2020.2997602},
	timestamp = {Wed, 22 Nov 2023 12:10:46 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/DaiSLZZC21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper studies the problem of c H arging t A sk S cheduling for direc T ional wireless charg E r networks (HASTE), i.e., given a set of rotatable directional wireless chargers on a 2D area and a series of offline (online) charging tasks, scheduling the orientations of all the chargers with time in a centralized offline (distributed online) fashion to maximize the overall charging utility for all the tasks. We prove that HASTE is NP-hard. Then, we prove that a relaxed version of HASTE falls within the realm of maximizing a submodular function subject to a partition matroid constraint, and propose a centralized offline algorithm that achieves\n(1−ρ)(1−\n1\ne\n)\napproximation ratio to address HASTE where\nρ\nis the switching delay of chargers. Further, we propose a distributed online algorithm and prove it achieves\n1\n2\n(1−ρ)(1−\n1\ne\n)\ncompetitive ratio. We conduct simulations and field experiments on a testbed consisting of eight off-the-shelf power transmitters and 8 rechargeable sensor nodes. The results show that our distributed online algorithm achieves 92.97 percent of the optimal charging utility, and outperforms the comparison algorithms by up to 15.28 percent in terms of charging utility.}
}


@article{DBLP:journals/tmc/LiuXDLGC21,
	author = {Kai Liu and
                  Ke Xiao and
                  Penglin Dai and
                  Victor C. S. Lee and
                  Songtao Guo and
                  Jiannong Cao},
	title = {Fog Computing Empowered Data Dissemination in Software Defined Heterogeneous
                  VANETs},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {11},
	pages = {3181--3193},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2997460},
	doi = {10.1109/TMC.2020.2997460},
	timestamp = {Tue, 16 Aug 2022 23:09:33 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/LiuXDLGC21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper makes the first effort on proposing a fog computing empowered architecture together with a dedicated scheduling algorithm for data dissemination in software defined heterogeneous vehicular ad-hoc networks (VANETs). Specifically, the architecture supports both the logically centralized control via the cloud node in the core network and the distributed data dissemination via the fog nodes at the network edge. A problem called fog assisted cooperative service (FACS) is formulated, which takes network coding and vehicular caching into consideration, and aims at minimizing the overall service delay via the cooperation of vehicle-to-cloud (V2C), vehicle-to-fog (V2F) and vehicle-to-vehicle (V2V) communications. Further, we derive an equivalence problem of FACS and prove that FACS is NP-hard. On this basis, we propose a Clique Searching based Scheduling (CSS) algorithm at the SDN controller, which considers the heterogeneous communication interfaces and vehicle mobility in scheduling, and enables the collaborative data encoding and transmission among the cloud, fog nodes and vehicles. The complexity analysis demonstrates the feasibility of the proposed algorithm. Finally, we build the simulation model and give a comprehensive performance evaluation based on real vehicular trajectories extracted from different time and space. The simulation results conclusively demonstrate the superiority of the proposed solution.}
}


@article{DBLP:journals/tmc/YucelYB21,
	author = {Fatih Yucel and
                  Murat Yuksel and
                  Eyuphan Bulut},
	title = {QoS-Based Budget Constrained Stable Task Assignment in Mobile Crowdsensing},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {11},
	pages = {3194--3210},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2997280},
	doi = {10.1109/TMC.2020.2997280},
	timestamp = {Wed, 03 Nov 2021 08:27:11 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/YucelYB21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {One of the key problems in mobile crowdsensing (MCS) systems is the assignment of tasks to users. Most of the existing work aim to maximize a predefined system utility (e.g., quality of service or sensing), however, users (i.e., task requesters and performers/workers) may value different parameters and hence find an assignment unsatisfying if it is produced disregarding these parameters that define their preferences. While several studies utilize incentive mechanisms to motivate user participation in different ways, they do not take individual user preferences into account either. To address this issue, we leverage Stable Matching Theory which can help obtain a satisfying matching between two groups of entities based on their preferences. However, the existing approaches to find stable matchings do not work in MCS systems due to the many-to-one nature of task assignments and the budget constraints of task requesters. Thus, we first define two different stability conditions for user happiness in MCS systems. Then, we propose three efficient stable task assignment algorithms and discuss their stability guarantees in four different MCS scenarios. Finally, we evaluate the performance of the proposed algorithms through extensive simulations using a real dataset, and show that they outperform the state-of-the-art solutions.}
}


@article{DBLP:journals/tmc/GuWSL21,
	author = {Zhaoquan Gu and
                  Yuexuan Wang and
                  Tong Shen and
                  Francis C. M. Lau},
	title = {On Heterogeneous Sensing Capability for Distributed Rendezvous in
                  Cognitive Radio Networks},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {11},
	pages = {3211--3226},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2997077},
	doi = {10.1109/TMC.2020.2997077},
	timestamp = {Wed, 03 Nov 2021 08:27:12 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/GuWSL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cognitive radio networks (CRNs) have been proposed to solve the spectrum scarcity problem. One of their fundamental procedures is to construct a communication link on a common channel for the users, which is referred to as rendezvous . In reality, the capability to sense the spectrum may vary from user to user. We study distributed rendezvous for heterogeneous sensing capabilities in this paper. The licensed spectrum is divided into $n$ channels, $U = \\lbrace 1,2,\\ldots,n\\rbrace$ . We denote the sensing capability of user $i$ as $C_i \\subseteq U$ and the set of available channels (i.e., the channels not occupied by paying users) as $V_i \\subseteq C_i$ . Due to hardware differences, the users may have different sensing capabilities: $C_i \\ne C_j$ , and this is called heterogeneous sensing capability . In this paper, we propose efficient algorithms for two scenarios: the fully available scenario where $V_i = C_i$ and the partially available scenario where $V_i \\subseteq C_i$ . Our idea is to utilize two ‘pointers’ to traverse the sensing capability set, which sets our algorithms apart from the extant rendezvous algorithms. Considering any two neighboring users $a, b$ , we propose the Traversing Pointer (TP) algorithm that guarantees rendezvous in $O(\\max \\lbrace |C_a|,|C_b|\\rbrace \\log \\log n)$ time slots for the fully available scenario. This result is only $O(\\log \\log n)$ larger than the theoretical lower bound. Moreover, it removes an $O(\\min \\lbrace |C_a|,|C_b|\\rbrace)$ factor when compared to the state-of-the-art result ( $O(|C_a||C_b|)$ in S.-H. Wu et al. For the partially available scenario, we propose the Moving Traversing Pointers (MTP) and Prime based Moving Traversing Pointers (P-MTP) algorithms that can guarantee rendezvous within $O((\\max \\lbrace |V_a|,|V_b|\\rbrace)^2\\log \\log n)$ and $O(|V_a||V_b|\\log \\log n)$ time slots respectively, where the latter one combines the pointers and a common technique of plugging in a prime number. The proposed algorithms work more efficiently than the previous best result ( $O(|C_a||C_b|)$ in C.-C. Wu et al. under various circumstances. We also conduct extensive simulations and the results corroborate our analyses.}
}


@article{DBLP:journals/tmc/WangG21,
	author = {Haoyu Wang and
                  Wei Gong},
	title = {RF-Pen: Practical Real-Time {RFID} Tracking in the Air},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {11},
	pages = {3227--3238},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2997080},
	doi = {10.1109/TMC.2020.2997080},
	timestamp = {Wed, 03 Nov 2021 08:27:11 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/WangG21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Wireless tracing technologies have seen great potentials in many applications, including drawing and writing, gesture-based commanding, and gaming. Many state-of-the-art systems have recently been proposed along this line. However, none of them can strike a balance among hardware complexity, time delay, and accuracy in real-world scenarios. In this paper, we propose RF-Pen, a practical and complete RFID tracking system that achieves centimeter-level real-time tracing with 4 antennas. To do so, RF-Pen mainly employs two key designs, namely selective hologram and hybrid voting. Our selective hologram places antennas in large separation, which not only expedites the tracking process by producing a handful of good-quality candidate points but also maximizes tracing resolution. Nevertheless, a big challenge is ambiguity. To address this, we introduce hybrid voting that effectively integrates RSSI and phase measurements to evaluate the likelihood of all candidate points. This way, a precise initial position and fine-resolution tracing beams are located. We implement RF-Pen using off-the-shelf readers and tags and compare it against state-of-the-art systems. Results show that with a single reader of 4 antennas, RF-pen achieves a median trajectory error of 2.15 cm and a median position error of 12.8 cm, which are\n3.7×\nand\n4.1×\nbetter than RF-IDraw, respectively.}
}


@article{DBLP:journals/tmc/HuangSWB21,
	author = {Scott C.{-}H. Huang and
                  Elaine Y.{-}N. Sun and
                  Hsiao{-}Chun Wu and
                  Costas Busch},
	title = {The Paintbrush Coverage Problem},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {11},
	pages = {3239--3250},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2998406},
	doi = {10.1109/TMC.2020.2998406},
	timestamp = {Wed, 03 Nov 2021 08:27:12 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/HuangSWB21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Autonomous vehicles become more and more popular in our daily life. Mobile computing schemes to be installed on these vehicles have drawn a lot of recent research interest. In this paper, we address the important path-planning problem for autonomous vehicles. We introduce and formulate the novel paintbrush coverage problem . We present a theoretical study on the minimum trajectory length of a paintbrush to cover an arbitrary convex region, which is derived as a function of the area of the region and the size of the cover. Three commonly-used patrolling/scouting methods, namely boustrophedon, spiral, and sector, are manifested in details as the potential solutions to the paintbrush coverage problem. The theoretical minimum trajectory lengths any algorithm can achieve are also demonstrated as the benchmarks for different shapes of regions.}
}


@article{DBLP:journals/tmc/GuiLWC21,
	author = {Yongqiang Gui and
                  Hancheng Lu and
                  Feng Wu and
                  Chang Wen Chen},
	title = {Robust Video Broadcast for Users With Heterogeneous Resolution in
                  Mobile Networks},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {11},
	pages = {3251--3266},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2999195},
	doi = {10.1109/TMC.2020.2999195},
	timestamp = {Tue, 07 May 2024 20:24:41 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/GuiLWC21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recently, robust video transmission system that can eliminate the cliff effect in digital video transmission has attracted great interest from both academia and industry. By linearizing the whole system, robust video transmission is intrinsically scalable to channel conditions in mobile networks. However, the heterogeneity of user devices in terms of viewing resolution has not been well studied for robust video broadcast systems. In this paper, we propose a spatial scalability enabled robust video broadcast (SSRVB) system, aiming at accommodating diverse users with both heterogeneous resolutions and heterogeneous channel conditions. In SSRVB, a novel spatial decomposition method based on linear projection is first designed for robust video transmission. Then the transmission distortion minimization problem with joint subcarrier matching and power allocation is formulated. A near-optimal low-complexity subcarrier matching algorithm based on auction theory and an optimal power allocation strategy are also proposed. Furthermore, an iterative algorithm is designed to solve the problem of joint resource allocation. Simulation results demonstrate that SSRVB can achieve an average of 3 dB gain when compared with the reference schemes (i.e., ECast, MCast, discrete wavelet transform (DWT) based scheme, and scalable video coding (SVC) scheme) in terms of average peak signal-to-noise ratio under heterogeneous scenarios.}
}


@article{DBLP:journals/tmc/KangJ21,
	author = {Sunjung Kang and
                  Changhee Joo},
	title = {Low-Complexity Learning for Dynamic Spectrum Access in Multi-User
                  Multi-Channel Networks},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {11},
	pages = {3267--3281},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2999075},
	doi = {10.1109/TMC.2020.2999075},
	timestamp = {Wed, 03 Nov 2021 08:27:12 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/KangJ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In cognitive radio networks (CRNs), dynamic spectrum access allows (unlicensed) users to identify and access unused channels opportunistically, thus improves spectrum utilization. In this paper, we address the user-channel allocation problem in multi-user multi-channel CRNs without a prior knowledge of channel statistics. The result of channel access is stochastic with unknown distribution, and statistically different for each user. In deciding the channel for access, a user needs to either explore a channel to learn its statistics, or exploit the channel with the highest expected reward based on the information collected so far. Further, a channel should be accessed exclusively by one user at a time to avoid collision. Using multi-armed bandit framework, we develop two rate-optimal algorithms with low computational complexities of O(N)\nand O(NK)\n, respectively, where N\ndenotes the number of users and K\ndenotes the number of channels. Further, we extend the results and develop an algorithm that is amenable to implement in a distributed fashion.}
}


@article{DBLP:journals/tmc/LiuDNZLWL21,
	author = {Sicong Liu and
                  Junzhao Du and
                  Kaiming Nan and
                  Zimu Zhou and
                  Hui Liu and
                  Zhangyang Wang and
                  Yingyan Lin},
	title = {AdaDeep: {A} Usage-Driven, Automated Deep Model Compression Framework
                  for Enabling Ubiquitous Intelligent Mobiles},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {12},
	pages = {3282--3297},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2999956},
	doi = {10.1109/TMC.2020.2999956},
	timestamp = {Wed, 15 Dec 2021 10:30:41 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/LiuDNZLWL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recent breakthroughs in deep neural networks (DNNs) have fueled a tremendously growing demand for bringing DNN-powered intelligence into mobile platforms. While the potential of deploying DNNs on resource-constrained platforms has been demonstrated by DNN compression techniques, the current practice suffers from two limitations: 1) merely stand-alone compression schemes are investigated even though each compression technique only suit for certain types of DNN layers; and 2) mostly compression techniques are optimized for DNNs’ inference accuracy, without explicitly considering other application-driven system performance (e.g., latency and energy cost) and the varying resource availability across platforms (e.g., storage and processing capability). To this end, we propose AdaDeep, a usage-driven, automated DNN compression framework for systematically exploring the desired trade-off between performance and resource constraints, from a holistic system level. Specifically, in a layer-wise manner, AdaDeep automatically selects the most suitable combination of compression techniques and the corresponding compression hyperparameters for a given DNN. Thorough evaluations on six datasets and across twelve devices demonstrate that {\\sf AdaDeep}\ncan achieve up to 18.6\\times\nlatency reduction, 9.8\\times\nenergy-efficiency improvement, and 37.3\\times\nstorage reduction in DNNs while incurring negligible accuracy loss. Furthermore, {\\sf AdaDeep}\nalso uncovers multiple novel combinations of compression techniques.}
}


@article{DBLP:journals/tmc/ShenCL21,
	author = {Jiaxing Shen and
                  Jiannong Cao and
                  Xuefeng Liu},
	title = {BaG: Behavior-Aware Group Detection in Crowded Urban Spaces Using
                  WiFi Probes},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {12},
	pages = {3298--3310},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2999491},
	doi = {10.1109/TMC.2020.2999491},
	timestamp = {Wed, 15 Dec 2021 10:30:42 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/ShenCL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Group detection is gaining popularity as it enables variousXzX applications ranging from marketing to urban planning. Existing methods use received signal strength indicator (RSSI) to detect co-located people as groups. However, this approach might have difficulties in crowded urban spaces since many strangers with similar mobility patterns could be identified as groups. Moreover, RSSI is vulnerable to many factors like the human body attenuation and thus is unreliable in crowded scenarios. In this work, we propose a behavior-aware group detection system (BaG). BaG fuses people’s mobility information and smartphone usage behaviors. We observe that people in a group tend to have similar phone usage patterns. Those patterns could be effectively captured by the proposed feature: number of bursts (NoB). Unlike RSSI, NoB is more resilient to environmental changes as it only cares about receiving packets or not. Besides, both mobility and usage patterns correspond to the same underlying grouping information. We propose a detection method based on collective matrix factorization to reveal the hidden associations by factorizing mobility information and usage patterns simultaneously. Experimental results indicate BaG outperforms baseline approaches by 3.97\\% \\sim 15.79\\%\nin F-score. The proposed system could also achieve robust and reliable performance in scenarios with different levels of crowdedness.}
}


@article{DBLP:journals/tmc/LeeJC21,
	author = {Changsung Lee and
                  Jaewook Jung and
                  Jong{-}Moon Chung},
	title = {{DEFT:} Multipath {TCP} for High Speed Low Latency Communications
                  in 5G Networks},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {12},
	pages = {3311--3323},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.3000041},
	doi = {10.1109/TMC.2020.3000041},
	timestamp = {Wed, 15 Dec 2021 10:30:41 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/LeeJC21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Multipath TCP (MPTCP) is a promising solution that can provide high end-to-end throughput in fifth generation (5G) mobile networks. Many next-generation applications will require high throughput and low latency simultaneously, but the current MPTCP congestion control algorithms cannot reliably satisfy this requirement. In this paper, a novel MPTCP congestion control scheme named delay-equalized FAST (DEFT) is proposed to achieve high throughput and low end-to-end (E2E) delay in 5G networks. First, in order to achieve high throughput, DEFT includes a novel window control algorithm that shows fast responsiveness when the state of the millimeter-wave (mmWave) link changes from line-of-sight (LOS) to non-LOS (NLOS) and vice versa. Second, in order to achieve low E2E delay, DEFT includes a delay-equalizing algorithm which minimizes additional reordering delay in the receive buffer. The performance of DEFT was evaluated based on ns-3 simulation and was compared with wVegas, Balia, and delay-adapted LIA. Simulation results show that DEFT can provide a significant goodput gain and application-level E2E delay reduction for the range of interest.}
}


@article{DBLP:journals/tmc/MasoudiC21,
	author = {Meysam Masoudi and
                  Cicek Cavdar},
	title = {Device vs Edge Computing for Mobile Services: Delay-Aware Decision
                  Making to Minimize Power Consumption},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {12},
	pages = {3324--3337},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2999784},
	doi = {10.1109/TMC.2020.2999784},
	timestamp = {Wed, 15 Dec 2021 10:30:42 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/MasoudiC21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A promising technique to provide mobile applications with high computation resources is to offload the processing task to the cloud. Utilizing the abundant processing capabilities of the clouds, mobile edge computing enables mobile devices with limited batteries to run resource hungry applications and to save power. However, it is not always true that edge computing consumes less power compared to device computing. It may take more power for the mobile device to transmit a file to the cloud than running the task itself. This paper investigates the power minimization problem for the mobile devices by data offloading in multi-cell multi-user OFDMA mobile edge computing networks. We consider the maximum acceptable delay as QoS metric to be satisfied in our network. We formulate the problem as a mixed integer nonlinear problem which is converted into a convex form using D.C. approximation. To solve the converted optimization problem, we have proposed centralized and distributed algorithms for joint power allocation and channel assignment together with decision-making. Simulation results illustrate that by utilizing the proposed algorithms, considerable power savings can be achieved, e.g., about 60 percent for large bit stream size compared to local computing baseline.}
}


@article{DBLP:journals/tmc/LananteGR21,
	author = {Leonardo Lanante and
                  Chittabrata Ghosh and
                  Sumit Roy},
	title = {Hybrid {OFDMA} Random Access With Resource Unit Sensing for Next-Gen
                  802.11ax WLANs},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {12},
	pages = {3338--3350},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.3000503},
	doi = {10.1109/TMC.2020.3000503},
	timestamp = {Wed, 15 Dec 2021 10:30:42 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/LananteGR21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {IEEE 802.11ax partitions a regular 20MHz channel into smaller sub-channels called resource units to support simultaneous multiuser operation using orthogonal frequency division multiple access (OFDMA). Uplink OFDMA random access (UORA) in IEEE 802.11ax allows stations to transmit via a scheduled random access mechanism. UORA is initiated via a trigger frame which aside from serving as a synchronization mechanism, also informs stations which resource units are allowed for random access. Using the trigger frame information, the stations engage in an OFDMA backoff process to win access to a resource unit. Similar to slotted ALOHA, the maximum normalized throughput of UORA is only 37 percent due to high probability of collisions at high loads. To reduce collisions, we equip UORA with carrier sensing capability resulting in a new uplink hybrid UORA (H-UORA) OFDMA access mechanism. Unlike other multi-carrier CSMA methods previously proposed in literature, H-UORA is an easily implementable modification to current 802.11ax WLANs. We show that H-UORA can achieve a normalized throughput of at least 80 percent (which increases further depending on the buffering capabilities of the access point) using various numerical analysis and simulations.}
}


@article{DBLP:journals/tmc/ZhaoTLZC21,
	author = {Bowen Zhao and
                  Shaohua Tang and
                  Ximeng Liu and
                  Xinglin Zhang and
                  Wei{-}Neng Chen},
	title = {iTAM: Bilateral Privacy-Preserving Task Assignment for Mobile Crowdsensing},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {12},
	pages = {3351--3366},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2999923},
	doi = {10.1109/TMC.2020.2999923},
	timestamp = {Wed, 15 Dec 2021 10:30:41 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/ZhaoTLZC21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The minimum travel distance of task participants is one of the significant optimization objectives of privacy-preserving task assignment in mobile crowdsensing (MCS). However, when the travel distance is minimized, most of the previous schemes only focus on the task participant privacy and disregard the task requester privacy. Moreover, existing solutions usually only support the constraint of a single type, such as equality constraints or range constraints. In this paper, we propose a bilateral privacy-preserving Task Assignment mechanism for MCS (iTAM), which protects not only the task participants privacy but also the task requesters privacy and can minimize the travel distance. Furthermore, iTAM provides both equality and range constraints of task assignment by utilizing the Paillier cryptosystem. To accommodate the multiple relations between the task participants and the task, we propose the single/multiple task participants selection problems for a task requiring task participants to compete and cooperate. Experimental evaluations over synthetic and real-world data illustrate that iTAM is feasible and effective. Compared with the state-of-the-art, iTAM positively solves the optimal problem of travel distance. The complexities of iTAM are \\mathcal {O}(n)\nand \\mathcal {O}(n\\log n)\nfor a single and multiple task participants selection problems, respectively.}
}


@article{DBLP:journals/tmc/PoleseJKZDZ21,
	author = {Michele Polese and
                  Rittwik Jana and
                  Velin Kounev and
                  Ke Zhang and
                  Supratim Deb and
                  Michele Zorzi},
	title = {Machine Learning at the Edge: {A} Data-Driven Architecture With Applications
                  to 5G Cellular Networks},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {12},
	pages = {3367--3382},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2999852},
	doi = {10.1109/TMC.2020.2999852},
	timestamp = {Mon, 03 Jan 2022 22:06:55 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/PoleseJKZDZ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The fifth generation of cellular networks (5G) will rely on edge cloud deployments to satisfy the ultra-low latency demand of future applications. In this paper, we argue that such deployments can also be used to enable advanced data-driven and Machine Learning (ML) applications in mobile networks. We propose an edge-controller-based architecture for cellular networks and evaluate its performance with real data from hundreds of base stations of a major U.S. operator. In this regard, we will provide insights on how to dynamically cluster and associate base stations and controllers, according to the global mobility patterns of the users. Then, we will describe how the controllers can be used to run ML algorithms to predict the number of users in each base station, and a use case in which these predictions are exploited by a higher-layer application to route vehicular traffic according to network Key Performance Indicators (KPIs). We show that the prediction accuracy improves when based on machine learning algorithms that rely on the controllers’ view and, consequently, on the spatial correlation introduced by the user mobility, with respect to when the prediction is based only on the local data of each single base station.}
}


@article{DBLP:journals/tmc/NoscheseBCM21,
	author = {Matteo Noschese and
                  Fulvio Babich and
                  Massimiliano Comisso and
                  Chris Marshall},
	title = {Multi-Band Time of Arrival Estimation for Long Term Evolution {(LTE)}
                  Signals},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {12},
	pages = {3383--3394},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.3000105},
	doi = {10.1109/TMC.2020.3000105},
	timestamp = {Wed, 15 Dec 2021 10:30:42 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/NoscheseBCM21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper presents a method for estimating the time of arrival (ToA) of long term evolution (LTE) signals received on multiple separate transmission bands by the same base station (BS) mast. By exploiting the overall bandwidth occupied by the different signals and the correlation between the corresponding channel impulse responses, a higher precision is achieved with respect to the usually adopted single-band approach whenever the time-correlation among the bands is sufficiently high. The ToA estimation is carried out by generalizing the space-alternating generalized expectation-maximization (SAGE) algorithm to the multi-band context, proving that the availability of multiple bands provides a reduced standard deviation for the estimated ToA, with a limited increase of the computational cost. The main analyzed issue consists in the management of the asynchrony between transmitters belonging to distinct cellular operators, which is addressed by developing a suitable method to combine the contributions provided by the different bands. The method is validated by simulations in dual- and tri-band scenarios, and is further applied to real dual-band signals measured through a portable setup and experimentally acquired from an LTE BS mast covering multiple cells.}
}


@article{DBLP:journals/tmc/FarooqZ21,
	author = {Muhammad Junaid Farooq and
                  Quanyan Zhu},
	title = {QoE Based Revenue Maximizing Dynamic Resource Allocation and Pricing
                  for Fog-Enabled Mission-Critical IoT Applications},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {12},
	pages = {3395--3408},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.2999895},
	doi = {10.1109/TMC.2020.2999895},
	timestamp = {Wed, 15 Dec 2021 10:30:41 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/FarooqZ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Fog computing is becoming a vital component for Internet of things (IoT) applications, acting as its computational engine. Mission-critical IoT applications are highly sensitive to latency, which depends on the physical location of the cloud server. Fog nodes of varying response rates are available to the cloud service provider (CSP) and it is faced with a challenge of forwarding the sequentially received IoT data to one of the fog nodes for processing. Since the arrival times and nature of requests is random, it is important to optimally classify the requests in real-time and allocate available virtual machine instances (VMIs) at the fog nodes to provide a high QoE to the users and consequently generate higher revenues for the CSP. In this paper, we use a pricing policy based on the QoE of the applications as a result of the allocation and obtain an optimal dynamic allocation rule based on the statistical information of the computational requests. The developed solution is statistically optimal, dynamic, and implementable in real-time as opposed to other static matching schemes in the literature. The performance of the proposed framework has been evaluated using simulations and the results show significant improvement as compared with benchmark schemes.}
}


@article{DBLP:journals/tmc/SunQFZI21,
	author = {Yao Sun and
                  Shuang Qin and
                  Gang Feng and
                  Lei Zhang and
                  Muhammad Ali Imran},
	title = {Service Provisioning Framework for {RAN} Slicing: User Admissibility,
                  Slice Association and Bandwidth Allocation},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {12},
	pages = {3409--3422},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.3000657},
	doi = {10.1109/TMC.2020.3000657},
	timestamp = {Thu, 27 Jul 2023 08:18:51 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/SunQFZI21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Network slicing (NS) has been identified as one of the most promising architectural technologies for future mobile network systems to meet the extremely diversified service requirements of users. In radio access networks (RAN) slicing, service provisioning for slice users becomes much more complicated than that in traditional mobile networks, as the constraints of both user physical association with base station (BS) and logical association with NS should be considered. In other words, the user-BS-NS three layer association relationship should be addressed in provisioning tailored service for diversified use cases with various quality of service (QoS) requirements. Therefore, service provisioning in RAN slicing becomes an essential yet challenging issue for 5G and beyond systems. In this paper, we propose a unified framework for service provisioning in RAN slicing with aim of maximizing resource utilization while guaranteeing QoS of users. The framework consists of two steps. The first step is to identify a set of slice users whose QoS can be satisfied simultaneously; while the second step performs joint slice association and bandwidth allocation with aim to minimize bandwidth consumption. Numerical results show that in typical scenarios, our proposed service provisioning framework can achieve significant performance gain in terms of the number of serving users and wireless bandwidth utilization compared with traditional schemes.}
}


@article{DBLP:journals/tmc/SunHS21,
	author = {Li Sun and
                  Jing Hou and
                  Tao Shu},
	title = {Spatial and Temporal Contextual Multi-Armed Bandit Handovers in Ultra-Dense
                  mmWave Cellular Networks},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {12},
	pages = {3423--3438},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.3000189},
	doi = {10.1109/TMC.2020.3000189},
	timestamp = {Wed, 15 Dec 2021 10:30:42 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/SunHS21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Although millimeter wave (mmWave) is a promising technology in 5G communication, its severe path attenuation and susceptibility to line-of-sight (LOS) blockage result in much more unpredictable outages than traditional technologies. This special propagation property raises a significant challenge to the mobility management in mmWave cellular networks. Since conventional handover policies purely rely on the measurement of signal strength, they would cause a large number of unnecessary handovers due to the frequent short-term LOS blockage by obstacles, imposing high signaling and energy overhead. In this paper, we propose two novel handover mechanisms to reduce unnecessary handovers by carefully deciding the next base station (BS) a user should handover to, so that the new user-BS connection after the handover can last as long as possible. Without prior knowledge of user’s mobility and environment, the proposed handover mechanisms exploit the empirical distribution of user’s post-handover trajectory and LOS blockage, learned online through a multi-armed bandit (MAB) framework. Depending on the contexts extracted from RSS information, two different MAB problems for handover are formulated, which focus on spatial and space-time contexts, respectively, The results of numerical simulations demonstrate that the proposed contextual handover mechanisms significantly outperform existing counterparts on reducing handovers in all simulated scenarios.}
}


@article{DBLP:journals/tmc/DaiWLQLZ21,
	author = {Chenxin Dai and
                  Xiumin Wang and
                  Kai Liu and
                  Deyu Qi and
                  Weiwei Lin and
                  Pan Zhou},
	title = {Stable Task Assignment for Mobile Crowdsensing With Budget Constraint},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {12},
	pages = {3439--3452},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.3000234},
	doi = {10.1109/TMC.2020.3000234},
	timestamp = {Thu, 20 Jun 2024 15:06:43 +0200},
	biburl = {https://dblp.org/rec/journals/tmc/DaiWLQLZ21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In mobile crowdsensing, it is a challenge to assign tasks to appropriate smartphones. Existing task allocation mechanisms mainly aim at optimizing the global system performance, while ignoring the personal preferences of individual crowdsensing tasks and smartphone users. Nevertheless, in an open crowdsensing system, a task assignment is prone to be unstable if smartphone users or tasks have incentives to deviate from the global assignment, and seek for alternative choices to improve their own utilities. Besides that, during task competition, the rational smartphone users might choose to adjust their payments after the first few failures, which however, brings new challenges in achieving the stability. To address these issues, this paper constructs a distributed many-to-many matching model to capture the interaction between crowdsensing tasks and smartphone users, taking into account the budget constraints of tasks. Then, we design a stable matching algorithm to allocate the tasks to the users, and determine their payments. We prove that the proposed algorithm achieves several desirable properties including individual rationality, stability, and convergency. It is also proved that the proposed scheme achieves at least half of the optimal system efficiency when each smartphone provides homogeneous service quality. Finally, simulation results confirm the effectiveness of the proposed scheme.}
}


@article{DBLP:journals/tmc/YuLJGWYL21,
	author = {Lixing Yu and
                  Ming Li and
                  Wenqiang Jin and
                  Yifan Guo and
                  Qianlong Wang and
                  Feng Yan and
                  Pan Li},
	title = {{STEP:} {A} Spatio-Temporal Fine-Granular User Traffic Prediction
                  System for Cellular Networks},
	journal = {{IEEE} Trans. Mob. Comput.},
	volume = {20},
	number = {12},
	pages = {3453--3466},
	year = {2021},
	url = {https://doi.org/10.1109/TMC.2020.3001225},
	doi = {10.1109/TMC.2020.3001225},
	timestamp = {Wed, 15 Dec 2021 10:30:41 +0100},
	biburl = {https://dblp.org/rec/journals/tmc/YuLJGWYL21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {While traffic modeling and prediction are at the heart of providing high-quality telecommunication services in cellular networks and attract much attention, they have been approved as an extremely challenging task. Due to the diverse network demand of Internet-based apps, the cellular traffic from an individual user can have a wide dynamic range. Most existing methods, on the other hand, model traffic patterns as probabilistic distributions or stochastic processes and impose stringent assumptions over these models. Such assumptions may be beneficial at providing closed-form formula in evaluating prediction performances, but fall short for practice use. In this paper we propose STEP, a s patio- te mporal fine-granular user traffic p rediction mechanism for cellular networks. A deep graph convolution network, called GCGRN, is constructed. It is a novel combination of the graph convolution network (GCN) and gated recurrent units (GRU), which exploits graph neural network to learn an efficient spatio-temporal model from a user’s massive dataset for traffic prediction. The prototype of STEP has been implemented. Extensive experimental results demonstrate that our model outperforms the state-of-the-art time-series based approaches. Besides, STEP merely incurs mild energy consumption, communication overhead and system resource occupancy to mobile devices. Moreover, NS-3 based simulations validate the efficacy of STEP in reducing session dropping ratio in cellular networks.}
}
