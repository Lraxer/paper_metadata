@article{DBLP:journals/iot/RehmanSU23,
	author = {Mujeeb Ur Rehman and
                  Arslan Shafique and
                  Aminu Bello Usman},
	title = {Securing Medical Information Transmission Between IoT Devices: An
                  Innovative Hybrid Encryption Scheme Based on Quantum Walk, {DNA} Encoding,
                  and Chaos},
	journal = {Internet Things},
	volume = {24},
	pages = {100891},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100891},
	doi = {10.1016/J.IOT.2023.100891},
	timestamp = {Tue, 07 May 2024 20:25:59 +0200},
	biburl = {https://dblp.org/rec/journals/iot/RehmanSU23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The healthcare industry has undergone a transformation due to the widespread use of advanced communication technologies and wireless sensor networks such as the Internet of Medical Things (IoMT), Health Information Exchange Technology (HIET), Internet of Healthcare Things (IoHT) and Health IoT (HIoT). These technologies have led to an increase in the transmission of medical data, particularly medical imaging data, over various wireless communication channels. However, transmitting high-quality color medical images over insecure internet channels like the Internet and communication networks like 5G presents significant security risks that could threaten patients’ data privacy. Furthermore, this process can also burden the limited bandwidth of the communication channel, leading to delayed data transmission. To address security concerns in healthcare data, researchers have focused a lot of attention on medical image encryption as a means of protecting patient data. This paper presents a color image encryption scheme that integrates multiple encryption techniques, including alternate quantum random walks, controlled Rubik’s Cube transformations, and the integration of the Elliptic Curve Cryptosystem with Hill Cipher (ECCHC). The proposed scheme divides various plaintext images by creating a regular cube by layering planes of a fixed size. Each plane is rotated in an anticlockwise direction, followed by row, column and face swapping, and then DNA encoding is performed. The image cube encoded with DNA is combined with the chaotic cube through DNA addition, and a couple of random DNA sequences are chosen for DNA mutation. After undergoing DNA mutation, the encoded cube is then decoded using DNA. The proposed method has the theoretical capability of encrypting 2D images of unlimited size and number by utilizing an infinitely large cube. The proposed image encryption scheme has been rigorously tested through various experimental simulations and cyberattack analysis, which shows the efficiency and reliability of the proposed encryption scheme.}
}


@article{DBLP:journals/iot/Herrero23a,
	author = {Rolando Herrero},
	title = {Multifactor QoE scores in IoT topologies},
	journal = {Internet Things},
	volume = {24},
	pages = {100892},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100892},
	doi = {10.1016/J.IOT.2023.100892},
	timestamp = {Sat, 13 Jan 2024 17:37:23 +0100},
	biburl = {https://dblp.org/rec/journals/iot/Herrero23a.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Quality of Experience (QoE) is key to Internet of Things (IoT) applications. Indeed, depending on the nature of the application, different application message loss and latency requirements lead to different QoE metrics. In this context, and considering as inspiration the Mean Option Scores (MOS) typically associated with Real Time Communication (RTC), this paper introduces QoE scores that can be used to assess the performance of IoT applications. Taking into account physical, link, network, transport, and application layer features like the transmission rate, network layer loss and latency, the topology and the session layer protocol under consideration, linear regression mechanisms are used to estimate these QoE scores. Some of these features are regular system parameters while others are extracted from standard mechanisms and protocols used for traffic analysis as Key Performance Indicators (KPIs). This model is then trained and evaluated against a large number of Wireless Personal Area Network (WPAN) and Low Power Wide Area Network (LPWAN) architectures.}
}


@article{DBLP:journals/iot/RazzaqAMFR23,
	author = {Abdul Razzaq and
                  Aakash Ahmad and
                  Asad Waqar Malik and
                  Mahdi Fahmideh and
                  Rabie A. Ramadan},
	title = {Software engineering for internet of underwater things to analyze
                  oceanic data},
	journal = {Internet Things},
	volume = {24},
	pages = {100893},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100893},
	doi = {10.1016/J.IOT.2023.100893},
	timestamp = {Tue, 07 May 2024 20:25:59 +0200},
	biburl = {https://dblp.org/rec/journals/iot/RazzaqAMFR23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Internet of Things (IoTs) represents a networked collection of heterogeneous sensors – enabling seamless integration between systems, humans, devices, etc. – to support pervasive computing for smart systems. IoTs unify hardware (embedded sensors), software (algorithms to manipulate sensors), and wireless network (protocols that transmit sensor data) to develop and operationalize a wide range of smart systems and services. The Internet of Underwater Things (IoUTs for short) is a specific genre of IoTs in which data about ocean ecosystems is continuously ingested via underwater sensors. IoUTs referred to as context-sensing eyes and ears under the sea operationalize a diverse range of scenarios ranging from exploring marine life to analyzing water pollution and mining oceanic data. This paper proposes a layered architecture that (i) ingests oceanic data as a sensing layer, (ii) computes the correlation between the data as an analytics layer, and (iii) visualizes data for human decision support via the interface layer. We unify the concepts of software engineering (SE) and IoTs to exploit software architecture, underlying algorithms, and tool support to develop and operationalize IoUTs. A case study-based approach is used to demonstrate the sensors’ throughput, query response time, and algorithmic execution efficiency. We collected IoUT sensor data, involving 6 distinct sensors from two locations including the Arabian Sea, and the Red Sea for 60 days. Evaluation results indicate (i) sensors’ throughput (daily average: 10000–20000 KB data transmission), (ii) query response time (under 30 ms), (iii) and query execution performance (CPU utilization between 60%–80%). The solution exploits SE principles and practices for pattern-based architecting and validation of emerging and next-generation IoUTs in the context of smart oceans.}
}


@article{DBLP:journals/iot/TalebANC23,
	author = {Houssein Taleb and
                  Guillaume Andrieux and
                  Abbass Nasser and
                  Nour Charara},
	title = {Energy efficient selection of spreading factor in LoRaWAN-based {WBAN}
                  medical systems},
	journal = {Internet Things},
	volume = {24},
	pages = {100896},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100896},
	doi = {10.1016/J.IOT.2023.100896},
	timestamp = {Wed, 03 Jan 2024 08:34:13 +0100},
	biburl = {https://dblp.org/rec/journals/iot/TalebANC23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recently, the Internet of Things has been leading the technological revolution in several fields and applications. This revolution affected healthcare services adding more value to the concept of e-health. To improve the quality of these services, remote monitoring allows healthcare professionals to observe and diagnose their patients without being physically present. Since the spreading factor affects the energy consumption, the data rate, the receiver sensitivity and the time on air. A monitoring healthcare system using LoRa technology is proposed on this work to adopt the data transmission in a reliable and energy-efficient way. We propose a method to select the most convenient spreading factor based on the patients medical state. This method takes in consideration the distance to gateway, the packet error rate and the energy consumption requirements.}
}


@article{DBLP:journals/iot/FeijooAnazcoCGM23,
	author = {Anthony Feijoo{-}A{\~{n}}azco and
                  Dan Garc{\'{\i}}a{-}Carrillo and
                  Jes{\'{u}}s S{\'{a}}nchez G{\'{o}}mez and
                  Rafael Mar{\'{\i}}n{-}P{\'{e}}rez},
	title = {Innovative security and compression for constrained IoT networks},
	journal = {Internet Things},
	volume = {24},
	pages = {100899},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100899},
	doi = {10.1016/J.IOT.2023.100899},
	timestamp = {Mon, 17 Jun 2024 22:12:36 +0200},
	biburl = {https://dblp.org/rec/journals/iot/FeijooAnazcoCGM23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Low-Power Wide-Area Networks (LPWAN) are a type of wireless communication technologies that enable efficient data transfer between low-power devices. This article explores the challenges of ensuring security in LPWANs and proposes a solution that combines two key mechanisms: Object Security for Constrained RESTful Environments (OSCORE) and Static Context Header Compression (SCHC). LPWANs are increasingly being used in Internet of Things (IoT) applications, but the features that endow these technologies with low power consumption and long range also make it necessary to adapt protocols and innovate in the approaches to achieve security while maintaining communications viable in technologies like these, in some cases with severe limitations. OSCORE provides end-to-end security for constrained devices, while SCHC enables efficient IP-based transmission over LPWANs. By combining these two protocols, the proposed solution aims to address the security and efficiency challenges of LPWANs, ensuring that IoT devices and data are protected from unauthorized access and manipulation. The article also presents experimental results demonstrating the feasibility and effectiveness of the proposed approach using a real-life scenario, with industrial-grade hardware. The study concludes that the use of OSCORE and SCHC in LPWAN networks can significantly enhance the security and privacy of IoT devices.}
}


@article{DBLP:journals/iot/MatinIWHX23,
	author = {Abdul Matin and
                  Md. Rafiqul Islam and
                  Xianzhi Wang and
                  Huan Huo and
                  Guandong Xu},
	title = {AIoT for sustainable manufacturing: Overview, challenges, and opportunities},
	journal = {Internet Things},
	volume = {24},
	pages = {100901},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100901},
	doi = {10.1016/J.IOT.2023.100901},
	timestamp = {Thu, 02 May 2024 20:50:53 +0200},
	biburl = {https://dblp.org/rec/journals/iot/MatinIWHX23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The integration of IoT and AI has gained significant attention as an emerging means to digitize manufacturing industries and drive sustainability in the context of Industry 4.0. In recent times, there has been a merging of AI and IoT technologies to form an “Artificial Intelligence of Things” (AIoT) infrastructure. This integration aims to enhance various aspects such as human–machine interactions, operations in the field of IoT, big data analytics, and more. AIoT-based solutions offer numerous benefits to the manufacturing industry. These solutions improve efficiency, reduce waste, and enhance safety measures. By utilizing AIoT, manufacturers are able to achieve Industry 4.0 goals and increase productivity through automation, process optimization, and more informed decision-making. Additionally, the adoption of AI and IoT-based solutions in manufacturing companies has increased substantially. These solutions enable the early detection and prevention of defects in equipment, leading to the production of high-quality products. By minimizing waste, reducing costs, improving efficiency, and boosting productivity, manufacturers can further optimize their operations. Academic researchers and industry practitioners are currently prioritizing the development of highly advanced and streamlined AIoT-based solutions specifically designed for sustainable manufacturing. The primary objectives of this paper are (i) to provide a comprehensive overview of the domain-centric AIoT-based industry technology for sustainable manufacturing; (ii) to conduct a thorough survey of the existing research on AIoT-enabled manufacturing; (iii) to discuss the current challenges faced by AIoT in the context of sustainable manufacturing and explore the research prospects in this field. Therefore, this paper presents a systematic review of state-of-the-art AIoT-based techniques employed in industries for sustainable manufacturing and analyzes the key contributions and opportunities. Finally, the key challenges are explained for future research prospects.}
}


@article{DBLP:journals/iot/DuranPolancoS23,
	author = {Liliana Dur{\'{a}}n{-}Polanco and
                  Mario Siller},
	title = {A taxonomy for decision making in IoT systems},
	journal = {Internet Things},
	volume = {24},
	pages = {100904},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100904},
	doi = {10.1016/J.IOT.2023.100904},
	timestamp = {Sat, 13 Jan 2024 17:37:23 +0100},
	biburl = {https://dblp.org/rec/journals/iot/DuranPolancoS23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Semantic knowledge representations in the IoT can enable the vision of autonomic computing by providing a specification that enables interoperability and reasoning. Nevertheless, semantic representations in IoT have focused on describing the elements that compose it and their interactions, without addressing the challenges of the logical evolution of a system (updating and design of new algorithms). This work focuses on this gap, proposing the Taxonomy for Decision Making in IoT Systems (TDMIoT), a high-level characterization of decision-making processes in IoT developed following a conceptual-empirical methodological approach. TDMIoT considers a decision-making process a problem-solution association aiming to deliver a semantic representation that can be used as a design framework to support changes or even the design of new decision processes. A systematic review of the literature on decision-making processes in IoT application domains was conducted to evaluate the taxonomy as a classification scheme. A summary of the state-of-the-art decision-making process design approaches was generated from the classification of the selected studies through the systematic review. The classification showed design bias regarding the decision processes. For instance, most studies have focused on decision processes with prediction as an objective, and the most widely used algorithmic approach has been data-driven. In addition, the taxonomy was used to develop the COVID-19 Crowd Management project to test its usefulness as a design framework. In this regard, TDMIoT narrowed the search for decision models, validating its effectiveness in selecting an algorithmic approach for a given objective.}
}


@article{DBLP:journals/iot/JungNCK23,
	author = {Joong{-}Hwa Jung and
                  Hye{-}Been Nam and
                  Dong{-}Kyu Choi and
                  Seok{-}Joo Koh},
	title = {Use of {QUIC} for CoAP transport in IoT networks},
	journal = {Internet Things},
	volume = {24},
	pages = {100905},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100905},
	doi = {10.1016/J.IOT.2023.100905},
	timestamp = {Fri, 08 Mar 2024 13:22:13 +0100},
	biburl = {https://dblp.org/rec/journals/iot/JungNCK23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The QUIC protocol, formerly known as Quick UDP Internet Connection, has recently been standardized by the Internet Engineering Task Force (IETF). While initially designed to support the transport of Hypertext Transfer Protocol version 3 (HTTP/3) messages, QUIC can also be employed for various applications. This paper explores the effective utilization of the QUIC protocol for transporting Internet of Things (IoT) messages. Specifically, we propose a proxy-based scheme that leverages the multi-streaming features of QUIC to deliver Constrained Application Protocol (CoAP) messages. In the proposed scheme, multiple CoAP connections between IoT clients and a server are aggregated using client proxy and server proxy. Each CoAP connection is mapped onto a designated QUIC stream. It is noted that this proxy-based approach can be implemented without requiring modifications to existing CoAP applications at the client and server sides. Furthermore, we introduce a compressed mapping scheme from CoAP messages to QUIC streams to enhance performance within the proxy-based model. In testbed experimentation, the proposed QUIC-based CoAP transport scheme is compared with the existing UDP-based and TCP-based CoAP schemes in a variety of IoT network environment. From the experimentation results, we see that the proposed QUIC-based scheme can achieve 80% reduction in round-trip time and 9% increase in fast response rate, compared to the other candidate schemes. We can also see that the CoAP over QUIC scheme with compression provides a 10% performance gain over the case without compression.}
}


@article{DBLP:journals/iot/NishaU23,
	author = {Nisha and
                  Urvashi},
	title = {A systematic literature review of Internet of Video Things: Trends,
                  techniques, datasets, and framework},
	journal = {Internet Things},
	volume = {24},
	pages = {100906},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100906},
	doi = {10.1016/J.IOT.2023.100906},
	timestamp = {Mon, 05 Feb 2024 20:22:24 +0100},
	biburl = {https://dblp.org/rec/journals/iot/NishaU23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the last decade, Internet of Things (IoT) and machine learning (ML) have been used for developing semi or fully automated systems of any application. Due to the advancement in networking technologies, the contribution of video-based input is also rising for IoT systems. Hence, Internet of Video Things (IoVT) has been an emerging field to gain more human trust in the systems. IoVT is an integrated attempt of computer vision sensors, networking, video or image processing and information storage systems. In this paper, we have highlighted the literature evidence in the IoVT field. There is a need to analyze it in terms of different aspects, that enables the researchers to understand research trends in the field and lead them to future research directions. Therefore, this article presents a systematic literature review (SLR) in IoVT using various research publications, since its evolution. The study applies article selection criteria on different search methods and compares the relevant published articles. We have analyzed these filtered articles for identifying the study trends, their used techniques & frameworks for data processing and inputs or datasets used for their studies. At the end, various research opportunities and challenges have been framed in the field for future research references.}
}


@article{DBLP:journals/iot/AmadeoCGRSV23,
	author = {Marica Amadeo and
                  Franco Cicirelli and
                  Antonio Guerrieri and
                  Giuseppe Ruggeri and
                  Giandomenico Spezzano and
                  Andrea Vinci},
	title = {When edge intelligence meets cognitive buildings: The {COGITO} platform},
	journal = {Internet Things},
	volume = {24},
	pages = {100908},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100908},
	doi = {10.1016/J.IOT.2023.100908},
	timestamp = {Fri, 08 Mar 2024 13:22:13 +0100},
	biburl = {https://dblp.org/rec/journals/iot/AmadeoCGRSV23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Future buildings are complex systems that aim at improving the quality of life of their inhabitants and increasing safeness, security, and efficiency. In order to reach these goals, they require their own self-management and self-adaptation capabilities, thus becoming cognitive entities. However, developing cognitive buildings that exploit advanced Artificial Intelligence (AI) techniques in a distributed fashion is still a challenge. Indeed, they need to continuously collect and process a variety of environmental parameters, learn and predict the users’ needs and preferences, and then control a large number of heterogeneous devices. These operations may leverage the dynamic availability of edge and cloud computing resources.}
}


@article{DBLP:journals/iot/MogesLNDC23,
	author = {Teshager Hailemariam Moges and
                  Demeke Shumeye Lakew and
                  Ngoc Phi Nguyen and
                  Nhu{-}Ngoc Dao and
                  Sungrae Cho},
	title = {Cellular Internet of Things: Use cases, technologies, and future work},
	journal = {Internet Things},
	volume = {24},
	pages = {100910},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100910},
	doi = {10.1016/J.IOT.2023.100910},
	timestamp = {Sat, 13 Jan 2024 17:37:23 +0100},
	biburl = {https://dblp.org/rec/journals/iot/MogesLNDC23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Internet of Things (IoT) has revolutionized how we live and work by connecting everyday devices to the Internet. As the demand for IoT devices grows, a reliable and efficient communication infrastructure to support these devices has become crucial. Cellular IoT (CIoT) has emerged as a promising solution to this challenge, offering a low-cost, low-power, and scalable communication network for IoT devices. This paper presents a comprehensive overview of CIoT technology in response to the growing demand for IoT applications with low latency, high coverage, low power consumption, high device connection, and low cost. The four major CIoT technologies standardized by the Third Generation Partnership Project (3GPP) organization are investigated, including extended coverage global system for mobile communications IoT (EC-GSM-IoT), long-term evolution for machine-type communications (LTE-M), narrowband IoT (NB-IoT), and recently, new radio reduced capability (NR-RedCap). These technologies are analyzed regarding their fundamental focuses, features, use cases, requirements, and future work. In addition, we provide a comparative study of these types of IoT technology to assist researchers in understanding the available options and their potential limitations. Finally, open challenges are discussed to direct future research in the field.}
}


@article{DBLP:journals/iot/MengQMT23,
	author = {Yunyi Meng and
                  Zhiguo Qu and
                  Ghulam Muhammad and
                  Prayag Tiwari},
	title = {Secure and efficient data transmission based on quantum dialogue with
                  hyperentangled states in cloud office},
	journal = {Internet Things},
	volume = {24},
	pages = {100911},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100911},
	doi = {10.1016/J.IOT.2023.100911},
	timestamp = {Sat, 13 Jan 2024 17:37:23 +0100},
	biburl = {https://dblp.org/rec/journals/iot/MengQMT23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Quantum cloud computing facilitates the rapid processing of vast amounts of data and provides robust network services. To enhance the efficiency and security of data transmission in cloud computing, this study proposes a quantum cloud office model and presents a novel quantum dialogue protocol particularly designed for this model. The proposed protocol enables authenticated communication among office correspondents. Leveraging the unique properties of multiple quantum degrees of freedom, this protocol expands the channel capacity and enhances transmission efficiency. Compared to previous measurement-device-independent quantum dialogue (MDI-QD) protocols, this protocol not only further improves transmission efficiency but also enables mutual authentication between correspondents, effectively defending against the risk of man-in-the-middle attacks. The utilization of a cross-Kerr medium for Bell measurements offers a 50% increase in efficiency compared to linear optical equipment. This novel protocol is tailored to the data transmission process within the cloud office model, thereby enhancing the communication efficiency and reinforcing secure data transmission.}
}


@article{DBLP:journals/iot/KhattakYAKHI23,
	author = {Muhammad Ilyas Khattak and
                  Hui Yuan and
                  Ayaz Ahmad and
                  Ajmal Khan and
                  Ammar Hawbani and
                  Inamullah},
	title = {{TSM:} Temporal segmentation and modules-based computation offloading
                  using predictive analytics and {NR-V2X}},
	journal = {Internet Things},
	volume = {24},
	pages = {100912},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100912},
	doi = {10.1016/J.IOT.2023.100912},
	timestamp = {Sat, 13 Jan 2024 17:37:23 +0100},
	biburl = {https://dblp.org/rec/journals/iot/KhattakYAKHI23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recent increases in the usage of applications dependent on distributed computing have persuaded designers and entrepreneurs to utilize these solutions for diverse purposes, especially latency-constrained computation-intensive applications. Vehicular fog computing (VFC) is the innovative paradigm of distributed computing techniques, and therefore, a number of VFC offloading frameworks have been developed using AI-based advanced optimization procedures, with support from standards maintenance organizations like IEEE, 3rd Generation Partnership Project (3GPP), and some others. However, many of these strategies have not been adapted to specific application data and types, therefore these frameworks may function poorly despite their comprehensive offloading principles. Moreover, most computation offloading frameworks ignore the use of updated V2X protocols. We designed a temporal segmentation and modules (TSM)-based method specific for computation-intensive V2X applications that uses a four-tier hierarchy of resource-rich nodes and works in discrete time periods. TSM relies on status updates from previous time periods and uses predictive analytics to address the stochastic nature of vehicular networks using the latest 3GPP 5G V2X standards. Using an online modular computation offloading structure that heuristically manages the whole process, we were able to successfully and timely execute the latency-sensitive advanced vehicular applications. TSM supports computation-deficient devices in under a hundred milliseconds, makes use of smart vehicles’ processing units as fog nodes, and solves the optimization problem in short, discrete stages. We utilized Monte Carlo analysis, which confirmed that TSM outperformed the three other baseline methods.}
}


@article{DBLP:journals/iot/EdrisAKNCL23,
	author = {Ed Kamya Kiyemba Edris and
                  Mahdi Aiash and
                  Mohammad Ali Khoshkholghi and
                  Ranesh Naha and
                  Abdullahi Chowdhury and
                  Jonathan Loo},
	title = {Performance and cryptographic evaluation of security protocols in
                  distributed networks using applied pi calculus and Markov Chain},
	journal = {Internet Things},
	volume = {24},
	pages = {100913},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100913},
	doi = {10.1016/J.IOT.2023.100913},
	timestamp = {Fri, 08 Mar 2024 13:22:13 +0100},
	biburl = {https://dblp.org/rec/journals/iot/EdrisAKNCL23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The development of cryptographic protocols goes through two stages, namely, security verification and performance analysis. The verification of the protocol’s security properties could be analytically achieved using threat modelling, or formally using formal methods and model checkers. The performance analysis could be mathematical or simulation-based. However, mathematical modelling is complicated and does not reflect the actual deployment environment of the protocol in the current state of the art. Simulation software provides scalability and can simulate complicated scenarios, however, there are times when it is not possible to use simulations due to a lack of support for new technologies or simulation scenarios. Therefore, this paper proposes a formal method and analytical model for evaluating the performance of security protocols using applied pi-calculus and Markov Chain processes. It interprets algebraic processes and associates cryptographic operatives with quantitative measures to estimate and evaluate cryptographic costs. With this approach, the protocols are presented as processes using applied pi-calculus, and their security properties are an approximate abstraction of protocol equivalence based on the verification from ProVerif and evaluated using analytical and simulation models for quantitative measures. The interpretation of the quantities is associated with process transitions, rates, and measures as a cost of using cryptographic primitives. This method supports users’ input in analysing the protocol’s activities and performance. As a proof of concept, we deploy this approach to assess the performance of security protocols designed to protect large-scale, 5G-based Device-to-Device communications. We also conducted a performance evaluation of the protocols based on analytical and network simulator results to compare the effectiveness of the proposed approach.}
}


@article{DBLP:journals/iot/HammoudKSBB23,
	author = {Mohammed Hammoud and
                  Ekaterina Kovalenko and
                  Andrey Somov and
                  Ekaterina Bril and
                  Anna Baldycheva},
	title = {Deep learning framework for neurological diseases diagnosis through
                  near-infrared eye video and time series imaging algorithms},
	journal = {Internet Things},
	volume = {24},
	pages = {100914},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100914},
	doi = {10.1016/J.IOT.2023.100914},
	timestamp = {Mon, 05 Feb 2024 20:22:24 +0100},
	biburl = {https://dblp.org/rec/journals/iot/HammoudKSBB23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Internet of Things (IoT) solutions have greatly evolved recently with the application of Artificial Intelligence (AI). Indeed, AI enriches the IoT with intelligence capabilities. In particular, AI methods are highly effective in the scope of the Internet of Medical Things (IoMT) for the applications requiring decision support for doctors. In this work, we propose a Deep Learning (DL) framework for the classification of Parkinson’s disease (PD) and Progressive Supranuclear Palsy (PSP). In contrast to the state-of-the-art solutions relying on only the saccade test for the classification of these neurodegenerative diseases, we collect a dataset while the subjects perform five exercises including saccade, spontaneous nystagmus, optokinetic nystagmus, pursuit, and gaze test. We then extract the pupil features (coordinates, area, minor axis, and major axis) using the image segmentation DL model and represent them as images using Gramian Angular Difference Field (GADF) time series imagining algorithm. The resultant images are supplied to the proposed disease-detection model for running the classification procedure. The best classification results were obtained for the optokinetic exercise with the accuracy of 96.9%, 90.8%, and 96.9% for the left, right, and both eyes, respectively.}
}


@article{DBLP:journals/iot/YangHZX23,
	author = {Liming Yang and
                  Honglin Hu and
                  Ting Zhou and
                  Tianheng Xu},
	title = {Joint coded caching and {BS} sleeping strategy to reduce energy consumption
                  in 6G edge networks},
	journal = {Internet Things},
	volume = {24},
	pages = {100915},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100915},
	doi = {10.1016/J.IOT.2023.100915},
	timestamp = {Sat, 13 Jan 2024 17:37:23 +0100},
	biburl = {https://dblp.org/rec/journals/iot/YangHZX23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the coming sixth-generation mobile communication era, the intensive deployment of Internet of Things (IoT) devices and cellular networks is an irresistible trend, leading to system energy consumption and network traffic increasing sharply. Fortunately, edge caching as a promising technology to reduce system energy consumption and transmission latency is attracting wide attention. Although simply deploying cache in edge network and merely shutting down the idle base stations (BSs) during the idle periods can save certain energy to a certain extent, in this case, the contents with important mission cached in idle BSs cannot be accessed by users that will affect users’ experience. In this paper, we employ coded caching encoded by maximum distance separable (MDS) codes at the network edge, and we propose a joint coded caching and BS sleeping strategy, which utilizes the reconstruction feature of MDS codes to alleviate the impact of BS sleeping. Furthermore, the problem of minimizing energy consumption is studied, and we also design a discrete particle swarm optimization (DPSO) algorithm that is suitable to solve this mixed integer nonlinear programming problem. Simulation results reveal that energy consumption of the joint coded caching and BS sleeping strategy can be significantly decreased over 15.2% when compared with the current state-of-art strategy. Meanwhile, our proposed strategy can also improve the cache hit rate up to a maximum 11.1% compared with the existing strategies.}
}


@article{DBLP:journals/iot/EscaleiraCGBA23,
	author = {Pedro Escaleira and
                  Vitor A. Cunha and
                  Diogo Gomes and
                  Jo{\~{a}}o Paulo Barraca and
                  Rui L. Aguiar},
	title = {Moving Target Defense for the cloud/edge Telco environments},
	journal = {Internet Things},
	volume = {24},
	pages = {100916},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100916},
	doi = {10.1016/J.IOT.2023.100916},
	timestamp = {Fri, 08 Mar 2024 13:22:13 +0100},
	biburl = {https://dblp.org/rec/journals/iot/EscaleiraCGBA23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Internet of Things (IoT) paradigm has been one of the main contributors, in recent years, to the growth in the number of connected equipment. This fact has predominantly contributed to IoT being constrained by the 5th Generation Mobile Network (5G) progress and the promises this technology brings. However, this can be a double-edged sword. On the one hand, it will benefit from those progresses, but on the other, it will also be impacted by any security risk associated with 5G. One of the more serious security problems associated with it is the new wave of virtualization and softwarization of networks and analogous appliances, brought to light by paradigms such as Network Functions Virtualization (NFV) and Multi-access Edge Computing (MEC). Considering these predicaments, we propose a state-of-the-art Moving Target Defense (MTD) approach that defends Cloud-based Network Functions (CNFs) launched within MEC and NFV environments. Furthermore, our mechanism follows the famous Everything as a Service (XaaS) ideology, allowing any CNF provider to use this protection system, working agonistically. In the end, we created a Proof of Concept (PoC) of our proposed methodology, which we then used to conduct an extensive practical security analysis against the multiple phases of the Intrusion Kill Chain. Our final results have proven that our MTD as a Service (MTDaaS) approach can effectively delay and, in some cases, stop an attacker from achieving its objectives when trying to attack a CNF, even if the related vulnerability is a zero-day.}
}


@article{DBLP:journals/iot/AhamadH23,
	author = {Danish Ahamad and
                  Shabi Alam Hameed},
	title = {Two level blockchain-based privacy preservation framework in IoT with
                  heuristic fusion mechanism-aided deep learning architecture},
	journal = {Internet Things},
	volume = {24},
	pages = {100917},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100917},
	doi = {10.1016/J.IOT.2023.100917},
	timestamp = {Mon, 05 Feb 2024 20:22:24 +0100},
	biburl = {https://dblp.org/rec/journals/iot/AhamadH23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Internet of Things (IoT) connects more objects used in the modern world. To connect IoT nodes, it needs maintenance services, robustness, frictionless authentication, and high security. Blockchain emerges as a workable solution by providing those important features. Several authentication problems, maintenance, and security with IoT systems are solved because of blockchain technology. The blockchain-based IoT network is an open source, and everyone may see encrypted keys and transactional information. So, from this public network, anyone can take crucial information about users. A new blockchain-adopted IoT-based privacy preservation approach is developed to provide higher security with less utilization of the cost requirements. Here, two levels of data privacy is accomplished by utilizing the deep learning approach. The first level of privacy is used for authenticating a person, where the authentication among collected data is performed using Modified Adaboost and Long Short-Term Memory (MABLSTM), and the authenticated data is stored in the blockchain database. After that, the second level of privacy is obtained by performing data encoding with the encoder part of Autoencoder, and further Elliptic Curve Cryptography (ECC) is used to encrypt the data. Hence, the encrypted data is given to the data decryption process, and this has been subjected to the decoder part of the autoencoder to reconstruct the original data. Moreover, the parameters in the autoencoder and the parameters within the MABLSTM are optimized with the help of the developed Modified Levy Flight Distribution with Grasshopper Optimization (MLFD-GO). However, the parameters like LSTM and Adaboost are optimized with the help of the MLFD-GO algorithm to enhance the performance in terms of accuracy and precision for providing the higher level authentication scheme to provide high level security. Finally, the performance of the developed blockchain-based privacy preservation approach is validated over recently developed techniques.}
}


@article{DBLP:journals/iot/ZhangZWHCGG23,
	author = {Kun Zhang and
                  Yu Zhou and
                  Chaoyang Wang and
                  Haizhuang Hong and
                  Jing Chen and
                  Qian Gao and
                  Mostafa Ghobaei{-}Arani},
	title = {Towards an automatic deployment model of IoT services in Fog computing
                  using an adaptive differential evolution algorithm},
	journal = {Internet Things},
	volume = {24},
	pages = {100918},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100918},
	doi = {10.1016/J.IOT.2023.100918},
	timestamp = {Mon, 05 Feb 2024 20:22:24 +0100},
	biburl = {https://dblp.org/rec/journals/iot/ZhangZWHCGG23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Nowadays, fog computing has joined cloud computing as an emerging computing paradigm to provide resources at the edge of the network, as centralized clouds face challenges such as delay to process the unprecedented volume of data generated by Internet of Things (IoT) devices. Fog computing ensures the processing of real-time IoT applications at the edge of the network with low delay, as there is no need to transfer the entire data to a remote cloud. However, the main challenge is to deploy IoT services as components of IoT applications on fog nodes. Fog nodes are heterogeneous, distributed and resource-constrained, and this motivated us to solve the IoT Fog Service Placement (FSP) problem as a multi-objective optimization problem with evolutionary approaches. Here, we develop an Adaptive Differential Evolution (ADE) algorithm to solve FSP that originates from the MAPE-k (Monitor-Analyze-Plan-Execute over a shared knowledge) autonomous model. ADE considers a reproduction policy based on differential evolution-current-to-best, whose parameters are adjusted adaptively. The proposed method, ADE-FSP, transforms the multi-objective problem into a single-objective optimization problem with the perspective of minimizing deadline violation, resource loss and service cost as well as maximizing resource usage. Meanwhile, ADE-FSP ensures the automatic and efficient deployment of IoT services in the fog environment by considering the priority of services and the distribution of resource consumption. We analyze the proposed ADE-FSP from different perspectives on a simulated fog environment. Experimental results show that compared to state-of-the-art algorithms, ADE-FSP significantly improves delay (up to 5.6%) and resource usage (up to 13.2%).}
}


@article{DBLP:journals/iot/MunaHAHIF23,
	author = {Rabeya Khatun Muna and
                  Muhammad Iqbal Hossain and
                  Md. Golam Rabiul Alam and
                  Mohammad Mehedi Hassan and
                  Michele Ianni and
                  Giancarlo Fortino},
	title = {Demystifying machine learning models of massive IoT attack detection
                  with Explainable {AI} for sustainable and secure future smart cities},
	journal = {Internet Things},
	volume = {24},
	pages = {100919},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100919},
	doi = {10.1016/J.IOT.2023.100919},
	timestamp = {Sat, 13 Jan 2024 17:37:23 +0100},
	biburl = {https://dblp.org/rec/journals/iot/MunaHAHIF23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Smart cities rely heavily on Internet of Things (IoT) technology, which enables automation services through interconnected IoT devices. However, the widespread use of IoT applications in smart cities has resulted in security and privacy concerns that must be addressed to protect sensitive data. To safeguard smart cities from cyber attacks, learning theory-based automated attack-detection methods must be adopted. Various techniques have been proposed in the literature to create effective models for identifying IoT attacks. However, the majority of IoT detection algorithms have focused on only a few types of IoT attacks, and most IoT threat detection systems have used black-box deep learning models that lack interpretability to support their forecasts. This research aims to detect several types of large-scale attacks on IoT devices using the Extreme Gradient Boosting (XG-Boost) classifier and Explainable Artificial Intelligence (XAI) approaches. The proposed method not only improves the model’s performance but also increases trust in the model. The results of the experimental study on the IOTD20 dataset and XAI evaluation of each feature’s contribution to the model demonstrate that the proposed model can efficiently identify malicious attacks and threats, reducing IoT cybersecurity threats in smart cities.}
}


@article{DBLP:journals/iot/ZhangJZFRX23,
	author = {Rui Zhang and
                  Chengtian Jiang and
                  Junbo Zhang and
                  Jiteng Fan and
                  Jiayi Ren and
                  Hui Xia},
	title = {Reinvigorating sustainability in Internet of Things marketing: Framework
                  for multi-round real-time bidding with game machine learning},
	journal = {Internet Things},
	volume = {24},
	pages = {100921},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100921},
	doi = {10.1016/J.IOT.2023.100921},
	timestamp = {Tue, 07 May 2024 19:54:54 +0200},
	biburl = {https://dblp.org/rec/journals/iot/ZhangJZFRX23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Auction-based incentive mechanisms can satisfy the heterogeneous demands of both Demand Side Platforms (DSP) and Supply Side Platforms (SSP) in Internet of Things (IoT) marketing. However, DSP platforms often need help with two issues during the auction process: low enthusiasm and unreasonable bidding. To address these problems, we use the second-price sealed auction and propose a framework for multi-round real-time bidding with game machine learning. We introduce a multi-round advertising bidding mechanism incorporating reputation incentive rules to enhance DSP enthusiasm. The aim is to stimulate DSP participation and deter malicious DSP behavior, ensuring fairness and transparency in the bidding process. Subsequently, we design an auction screening model and adopt a multi-round auction format to ensure that only capable and willing advertising demand partners can participate, thus guaranteeing the reasonableness of DSP bids. Furthermore, we design a real-time bidding mechanism to adapt to the dynamic nature of the IoT marketing market. This mechanism transforms the problem of maximizing DSP revenue under budget constraints into a parameter adjustment problem based on a Markov Decision Process. We then utilize the Double Deep Q Network method to obtain the optimal bidding strategy for DSPs. Ultimately, the results demonstrate that our framework improves the final transaction price by 14.71%, increases the expected click-through rate by an average of 19.35%, and reduces the average cost per thousand impressions by 20.34%.}
}


@article{DBLP:journals/iot/LlopisFCIAW23,
	author = {Juan Alberto Llopis and
                  Antonio Jes{\'{u}}s Fern{\'{a}}ndez{-}Garc{\'{\i}}a and
                  Javier Criado and
                  Luis Iribarne and
                  Rosa Ayala and
                  James Z. Wang},
	title = {A deep learning model for natural language querying in Cyber-Physical
                  Systems},
	journal = {Internet Things},
	volume = {24},
	pages = {100922},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100922},
	doi = {10.1016/J.IOT.2023.100922},
	timestamp = {Sat, 13 Jan 2024 17:37:23 +0100},
	biburl = {https://dblp.org/rec/journals/iot/LlopisFCIAW23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As a result of technological advancements, the number of IoT devices and services is rapidly increasing. Due to the increasing complexity of IoT devices and the various ways they can operate and communicate, finding a specific device can be challenging because of the complex tasks they can perform. To help find devices in a timely and efficient manner, in environments where the user may not know what devices are available or how to access them, we propose a recommender system using deep learning for matching user queries in the form of a natural language sentence with Web of Things (WoT) devices or services. The Transformer, a recent attention-based algorithm that gets superior results for natural language problems, is used for the deep learning model. Our study shows that the Transformer can be a recommendation tool for finding relevant WoT devices in Cyber–Physical Systems (CPSs). With hashing as an encoding technique, the proposed model returns the relevant devices with a high grade of confidence. After experimentation, the proposed model is validated by comparing it with our current search system, and the results are discussed. The work can potentially impact real-world application scenarios when many different devices are involved.}
}


@article{DBLP:journals/iot/AliIFAKKBJUB23,
	author = {Usman Ali and
                  Mohd Yamani Idna Bin Idris and
                  Jaroslav Frnda and
                  Mohamad Nizam Bin Ayub and
                  Muhammad Asghar Khan and
                  Nauman Khan and
                  T. Rehannara Beegum and
                  Ahmed Abdulhadi Jasim and
                  Insaf Ullah and
                  Mohammad Babar},
	title = {Enhanced lightweight and secure certificateless authentication scheme
                  {(ELWSCAS)} for Internet of Things environment},
	journal = {Internet Things},
	volume = {24},
	pages = {100923},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100923},
	doi = {10.1016/J.IOT.2023.100923},
	timestamp = {Fri, 08 Mar 2024 13:22:13 +0100},
	biburl = {https://dblp.org/rec/journals/iot/AliIFAKKBJUB23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Internet of Things (IoT) is a fast-growing technology that enable existing systems to communicate with one another by using new devices such as sensors and other smart devices. The IoT devices such as wireless sensors and other smart devices are often very cheap, very small, and have limited power sources, memories, and processing capabilities. These devices are used in numerous critical applications, in which confidential information is sent across wireless channels among other devices participating in the system. This communication is vulnerable to multiple cyber-attacks due to the insecure wireless channel between them and without strong security mechanism, the important credential can be stolen by network attackers. One of the most important aspects of securing IoT communication is the authentication mechanism, used to validate the identity of authorized devices and users in IoT networks and to ensure data confidentiality, integrity, and authenticity for secure communication. Several authentication schemes for IoT environment have been proposed in the literature, none of these approaches entirely fulfil the necessary security and lightweight feature requirements. Some schemes fulfill the required security features but are unable to provide lightweight features. Similarly, other schemes provide lightweight features, but their security features are unsatisfactory. Therefore, it is necessary to design an effective security mechanism to ensure secure communication in IoT environments. In this paper, we propose Authenticated Encryption with Associated Data (AEAD) and Elliptic Curve Cryptography (ECC) based Enhanced Lightweight and Secure Certificateless Authentication Scheme (ELWSCAS) for IoT environment to fulfill the required security and lightweight performance features. The security of the proposed solution is evaluated using formal and informal security analysis. For formal security analysis we used RoR model and AVISPA tool. We have implemented the proposed solution in network simulator (NS3.35) by using Python and C++ to measure the network parameters such as throughput and packet delivery ratio (PDR). The computational and communication cost of the proposed scheme shows that in comparison to the existing state-of-the-art, our approach is considerably less costly and is a viable option for constrained IoT environment.}
}


@article{DBLP:journals/iot/HribernikK23,
	author = {Matevz Hribernik and
                  Anton Kos},
	title = {Exploring the applicability of haptic actuators in aquatic environments},
	journal = {Internet Things},
	volume = {24},
	pages = {100924},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100924},
	doi = {10.1016/J.IOT.2023.100924},
	timestamp = {Fri, 08 Mar 2024 13:22:13 +0100},
	biburl = {https://dblp.org/rec/journals/iot/HribernikK23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The use of high-tech wearable devices and real-time biomechanical feedback (RTBF) is widespread in modern sports and physical rehabilitation. While the use of kinematic sensors for RTBF is well established, the question of the most efficient and appropriate way to present feedback information to the user remains largely unanswered. The haptic modality has only been used in a limited number of relatively simple studies and applications, and it has never been studied in an aquatic environment. In this study, the main motivation was to design, develop, implement, and test an RTBF system for sports and physical rehabilitation with haptic actuators suitable for use in aquatic environments. The developed miniature remote-controlled device with vibration motors as actuators was tested to determine how people perceive the haptic modality in and out of water. The results of the exploratory study with 34 participants suggest that the feedback device can be further developed for future studies. The results show that both simple and complex haptic stimuli can be understood by athletes both outdoors and in water, as well as while standing and performing simple physical activities. This study tested the use of both head and waist mounted haptic actuators, with both showing similar and promising results. The results of this study provide evidence that haptic feedback can be perceived in water, highlighting the potential for real-time haptic interventions in aquatic environments. In summary, this study represents a significant contribution to the evolving field of RTBF in modern sport training and physical rehabilitation. The development of a haptic feedback device that can be worn during aquatic and other activities is a significant advance in the field of feedback actuators. This study provides a foundation for future usability studies and the development of haptic RTBF applications in both aquatic and outdoor environments.}
}


@article{DBLP:journals/iot/GarciaGonzalezRFL23,
	author = {Daniel Garcia{-}Gonzalez and
                  Daniel Rivero and
                  Enrique Fern{\'{a}}ndez{-}Blanco and
                  Miguel R. Luaces},
	title = {Deep learning models for real-life human activity recognition from
                  smartphone sensor data},
	journal = {Internet Things},
	volume = {24},
	pages = {100925},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100925},
	doi = {10.1016/J.IOT.2023.100925},
	timestamp = {Fri, 08 Mar 2024 13:22:13 +0100},
	biburl = {https://dblp.org/rec/journals/iot/GarciaGonzalezRFL23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Nowadays, the field of human activity recognition (HAR) is a remarkably hot topic within the scientific community. Given the low cost, ease of use and high accuracy of the sensors from different wearable devices and smartphones, more and more researchers are opting to do their bit in this area. However, until very recently, all the work carried out in this field was done in laboratory conditions, with very few similarities with our daily lives. This paper will focus on this new trend of integrating all the knowledge acquired so far into a real-life environment. Thus, a dataset already published following this philosophy was used. In this way, this work aims to be able to identify the different actions studied there. In order to perform this classification, this paper explores new designs and architectures for models inspired by the ones which have yielded the best results in the literature. More specifically, different configurations of Convolutional Neural Networks (CNN) and Long-Short Term Memory (LSTM) have been tested, but on real-life conditions instead of laboratory ones. It is worth mentioning that the hybrid models formed from these techniques yielded the best results, with a peak accuracy of 94.80% on the dataset used.}
}


@article{DBLP:journals/iot/AlaniMD23,
	author = {Mohammed M. Alani and
                  Lara Mauri and
                  Ernesto Damiani},
	title = {A two-stage cyber attack detection and classification system for smart
                  grids},
	journal = {Internet Things},
	volume = {24},
	pages = {100926},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100926},
	doi = {10.1016/J.IOT.2023.100926},
	timestamp = {Sat, 13 Jan 2024 17:37:23 +0100},
	biburl = {https://dblp.org/rec/journals/iot/AlaniMD23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As the adoption of Internet of Things (IoT) devices increases rapidly, industrial applications of IoT devices gain further popularity. Some of these applications, such as smart grids, are considered high-risk applications. In the past few years, smart grids became the target of many cyber attacks. In this paper, we present a two-stage system for the detection and classification of cyber attacks based on machine learning. The first stage of the proposed system focuses on detecting attacks efficiently and accurately. The second stage analyzes available data and predicts the specific attack class. The proposed system was tested using the DNP3 intrusion detection dataset, and delivered an\nscore of 0.9976 at the detection stage, and 0.9883 at the attack type classification stage.}
}


@article{DBLP:journals/iot/BhuvaK23,
	author = {Dipen R. Bhuva and
                  Sathish Kumar},
	title = {A novel continuous authentication method using biometrics for {IOT}
                  devices},
	journal = {Internet Things},
	volume = {24},
	pages = {100927},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100927},
	doi = {10.1016/J.IOT.2023.100927},
	timestamp = {Sat, 13 Jan 2024 17:37:23 +0100},
	biburl = {https://dblp.org/rec/journals/iot/BhuvaK23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this paper, we examine continuous authentication for IoT devices using real-time biometrics of a person's electrocardiogram (ECG) and electromyography (EMG). ECG is mainly used as a biometric identifier because it has specific features such as mathematical, morphological, and wavelet characteristics. EMG is a bio-signal defining a hand gesture of a person. Our authentication system would require no human interaction as it will have a continuous authentication schema. As soon as the user leaves a specific perimeter, the session will be killed by the system. In this paper, we propose a challenging and integrated methodology for developing, prototyping, and evaluating a continuous authentication scheme to ensure that currently insecure IoT networks are improved to have a high level of security with two layers of biometric security with continuous authentication to perform authentication in an automated manner. We used the dataset from PhysioNet for ECG, which contains samples of around 12 K for 298 people. We also used the EMG dataset available on the geostatic python library containing 150 K samples. In this experiment, we concluded that it is viable to use our continuous authentication for IoT devices with the lowest performance consumption and power consumption. The experimentation also demonstrates that the training model on two bio-signals helps obtain higher accuracy on continuous authentication within an average of 99.6%-99.99%. Our authentication schema can be implemented and integrated on any IoT device with having at least one wireless frequency that can receive and send a signal to the sender/authenticator.}
}


@article{DBLP:journals/iot/LakhanMAGMNMG23,
	author = {Abdullah Lakhan and
                  Mazin Abed Mohammed and
                  Karrar Hameed Abdulkareem and
                  Mohd Khanapi Abd Ghani and
                  Haydar Abdulameer Marhoon and
                  Jan Nedoma and
                  Radek Martinek and
                  Begonya Garcia{-}Zapirain},
	title = {Secure blockchain assisted Internet of Medical Things architecture
                  for data fusion enabled cancer workflow},
	journal = {Internet Things},
	volume = {24},
	pages = {100928},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100928},
	doi = {10.1016/J.IOT.2023.100928},
	timestamp = {Sat, 13 Jan 2024 17:37:23 +0100},
	biburl = {https://dblp.org/rec/journals/iot/LakhanMAGMNMG23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In today’s digital healthcare landscape, numerous clinical institutions collaborate to enhance healthcare quality in a ubiquitous fog and cloud environment. Data fusion plays a vital role in healthcare collaboration, enabling the integration of diverse healthcare sources. The primary advantage is the improvement of healthcare treatments and the availability of services throughout the network. However, despite these benefits, there is room for improvement in addressing various security issues regarding collaboration among clinical healthcare institutions to meet data fusion requirements. The primary challenge lies in processing lung cancer workflow data fusion on heterogeneous nodes while ensuring security in fog cloud networks. As a result, security emerges as a critical issue in the digital healthcare system operating within this ubiquitous environment. We present the secure Blockchain Internet of Medical Things (BIoMT) architecture for lung cancer workflow data fusion processing in fog cloud networks. The BIoMT architecture introduces the Blockchain Data Fusion Secure (BDFS) algorithm framework, which consists of task scheduling and blockchain validation schemes. The study aims to minimize the makespan of the lung workflow tasks based on security and deadline constraints in fog and cloud networks. We consider security at an advanced level, where runtime ransomware attacks are also identified in fog and cloud networks. Simulation results demonstrate that BDFS outperforms all existing BIoMT architectures regarding workflow processing while adhering to the specified constraints. Overall, the BDFS algorithm presented in the BIoMT architecture provides an efficient and secure solution for lung cancer workflow data fusion in fog cloud networks, contributing to the advancement of digital healthcare systems in a ubiquitous environment.}
}


@article{DBLP:journals/iot/CollaguazoVA23,
	author = {Adriana Collaguazo and
                  M{\'{o}}nica Villavicencio and
                  Alain Abran},
	title = {An activity-based approach for the early identification and resolution
                  of problems in the development of IoT systems in academic projects},
	journal = {Internet Things},
	volume = {24},
	pages = {100929},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100929},
	doi = {10.1016/J.IOT.2023.100929},
	timestamp = {Fri, 08 Mar 2024 13:22:13 +0100},
	biburl = {https://dblp.org/rec/journals/iot/CollaguazoVA23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The development of Internet of Things (IoT) systems in university courses encourages students to use multiple skills. Hence, the importance of applying teaching methods like Project Based Learning (PBL) in the development of these kinds of systems for integrating hardware and software components while facing numerous real-life problems. This study presents an activity-based Approach for the Early Identification and Resolution of problems, in a checklist format, to be used by students for preventing them from wasting time in IoT academic projects. The checklist is based on an adapted taxonomy of problems in IoT systems. This study analyzed problems identified in 48 projects carried out by 183 engineering students registered in two courses in 2020 and 2021. For designing the structured checklist, we categorized 14 types of IoT problems, analyzed root causes and solutions, and created and evaluated a taxonomy of problems.}
}


@article{DBLP:journals/iot/MuhozaBBG23,
	author = {Aim{\'{e}} Cedric Muhoza and
                  Emmanuel Bergeret and
                  Corinne Brdys and
                  Francis Gary},
	title = {Power consumption reduction for IoT devices thanks to Edge-AI: Application
                  to human activity recognition},
	journal = {Internet Things},
	volume = {24},
	pages = {100930},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100930},
	doi = {10.1016/J.IOT.2023.100930},
	timestamp = {Fri, 08 Mar 2024 13:22:13 +0100},
	biburl = {https://dblp.org/rec/journals/iot/MuhozaBBG23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Edge-AI uses Artificial Intelligence algorithms directly embedded on a device, contrary to a remote AI that uses an AI on a cloud or remote server for prediction. Recent improvements in microcontroller computing capabilities and enhanced deep learning algorithms and conversion frameworks made it easier to run small AI models directly on microcontroller units. Is the current interest in on-device AI justified in terms of its energy consumption on resource-constrained devices when compared to AI on the cloud? This study presents how an embedded deep convolutional neural network (DCNN) is used for real-time human activity recognition with more than 98% classification accuracy and its impact on battery life. Experiments conducted on a triaxial accelerometer with data collected and processed by an ARM Cortex-M4-based development board showed that energy consumption could be reduced up to 21% when inferences are run on an edge device versus using a remote server/cloud without compromising the overall classification precision and accuracy. We can reduce energy consumption by limiting data transmission by considering pseudo-real-time or non-real-time application scenarios.}
}


@article{DBLP:journals/iot/BeuranWZT23,
	author = {Razvan Beuran and
                  Jidong Wang and
                  Min Zhao and
                  Yasuo Tan},
	title = {IoT security training for system developers: Methodology and tools},
	journal = {Internet Things},
	volume = {24},
	pages = {100931},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100931},
	doi = {10.1016/J.IOT.2023.100931},
	timestamp = {Wed, 03 Jan 2024 08:34:13 +0100},
	biburl = {https://dblp.org/rec/journals/iot/BeuranWZT23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Opportunities, as well as challenges, accompany the development of new technologies, and the Internet of Things (IoT) is no exception. While most companies tout the benefits of IoT, challenges are often overlooked. Thus, IoT devices come in a variety of shapes, from small sensors to home routers and factory equipment, each with specific characteristics. While many of us own IoT devices, some may not even recognize them as such, let alone be able to manage them. This lead to a series of significant security incidents, such as the much-publicized Mirai botnet distributed denial-of-service cyberattack. The solution is to develop safer and more secure IoT systems, and in this paper we discuss first the methodology needed to train the developers of such systems for this purpose. We then present two training platforms that we designed and implemented following this methodology: IoTrain-Sim, which is based on the Cooja network simulator, and IoTrain-Lab, which uses the FIT IoT-LAB testbed as infrastructure. The two platforms include training content in the form of tutorials and predefined scenarios, both for fundamental and security IoT training, that the trainees can follow to gain an in-depth understanding of IoT via hands-on practice. The evaluation we conducted from functionality, performance and user perspectives demonstrates that our systems have several advantages compared to other approaches in terms of learner support, availability, extensibility, flexibility and scalability.}
}


@article{DBLP:journals/iot/ManasrehSN23,
	author = {Dmitry Manasreh and
                  Safaa Swaleh and
                  Munir Nazzal},
	title = {Evaluation of {BLE} beacon technology for time critical {I2V} communication
                  to support {CAV} deployment on urban roadways},
	journal = {Internet Things},
	volume = {24},
	pages = {100932},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100932},
	doi = {10.1016/J.IOT.2023.100932},
	timestamp = {Sat, 13 Jan 2024 17:37:23 +0100},
	biburl = {https://dblp.org/rec/journals/iot/ManasrehSN23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Road traffic accidents are on the rise. Most accidents are due to factors such as driver error and failure to obey traffic signs. Connected and automated vehicles (CAVs) are expected to reduce accidents and improve road safety by navigating safer and faster than traditional cars. Vehicle-to-everything (V2X) communication, which includes infrastructure-to-vehicle (I2V) and vehicle-to-vehicle (V2V) communication, can support the deployment of CAVs and enhance road safety for both human-only-driven and automated vehicles. Bluetooth Low Energy (BLE) beacons are a potential technology for I2V communication due to their low cost, compact size, low power consumption, mass compatibility with modern devices, and relatively large range. This study evaluated the potential of using BLE beacons as roadside units (RSUs) attached to traffic signs to deliver time-critical information to vehicles in urban road settings. To this end, the study utilized a CAV development platform to determine whether the vehicle was able to receive the beacon message far enough to take appropriate action while driving at the road's speed limit, taking into consideration road geometry and accounting for both dry and wet road conditions. In addition, the study tested several BLE beacon configurations to determine optimal configurations that achieved the required distance at all signs. The results of this study demonstrated that BLE beacons have the potential to be used in time sensitive I2V communications on urban roads. In addition, the optimal beacon configurations for the signs to be safely detected by CAVs were identified.}
}


@article{DBLP:journals/iot/WanQGLL23,
	author = {Ying Wan and
                  Qianqian Qu and
                  Lin Guo and
                  Limin Liu and
                  Jun Long},
	title = {Delay sensitive data transmission optimization for energy harvesting
                  relay satellite networks},
	journal = {Internet Things},
	volume = {24},
	pages = {100933},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100933},
	doi = {10.1016/J.IOT.2023.100933},
	timestamp = {Wed, 03 Jan 2024 08:34:13 +0100},
	biburl = {https://dblp.org/rec/journals/iot/WanQGLL23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Relay satellite network has become a promising architecture to provide rapid-response data offloading services for delay-sensitive space data. However, stochastic resources and dynamic inter-satellite contacts bring plenty of difficulties under delay constraints, which affects the transmission efficiency directly. In this paper, we first systematically analyze the data transmission process with delay guarantees and formulate a long-term stochastic optimization problem without a priori statistical knowledge. To tackle this problem, we first transform it into several sub-problems using a queue-stability-related technology. Then, we propose a transmission optimization with delay guarantees algorithm to maximize the system utility by optimizing resource allocation and channel assignment. Furthermore, we provide performance analysis to prove that the proposed algorithm can achieve long-term stability and approach near-optimal system utility. Finally, extensive simulations demonstrate the effectiveness of the proposed algorithm for system utility maximization and delay control.}
}


@article{DBLP:journals/iot/ZafarZHZIE23,
	author = {Samra Zafar and
                  Bakhtawar Zafar and
                  Xiaopeng Hu and
                  Nizam Hussain Zaydi and
                  Muhammad Ibrar and
                  Aiman Erbad},
	title = {{PBCLR:} Prediction-based control-plane load reduction in a software-defined
                  IoT network},
	journal = {Internet Things},
	volume = {24},
	pages = {100934},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100934},
	doi = {10.1016/J.IOT.2023.100934},
	timestamp = {Mon, 05 Feb 2024 20:22:24 +0100},
	biburl = {https://dblp.org/rec/journals/iot/ZafarZHZIE23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The exponential growth of devices and applications in Internet of Things (IoT) networks has caused control-plane traffic to escalate. Experts have suggested Software-Defined Networking (SDN) as a solution for complicated IoT network management. Nevertheless, SDN encounters obstacles in managing the substantial control-plane traffic many IoT devices produce. Prior findings have identified the dynamic switch migration technique as a viable solution for control plane load oscillation. However, their tendency to migrate switches during instances of controller overload restricts the efficiency of traditional migration strategies. As a result, these approaches lead to inefficiencies in the switch migration process, resulting in elevated latency. The present study introduces a prediction-based novel approach for mitigating the control-plane workload by leveraging the dynamic switch migration technique. The proposed method proactively and predictively migrates the switches anticipated to generate excessive control-plane traffic to an alternative controller. We use the learning technique along with time-series analysis to predict the future workload based on the historical control-plane traffic data. The proposed methodology is evaluated through simulation and the results demonstrate that the proposed method outperforms conventional techniques in enhancing load balancing efficacy on a distributed control plane and decreasing migration cost and controller response time by 30.6% on average.}
}


@article{DBLP:journals/iot/ShenLCYK23,
	author = {Guojiang Shen and
                  Pengfei Li and
                  Zhiyu Chen and
                  Yao Yang and
                  Xiangjie Kong},
	title = {Spatio-temporal interactive graph convolution network for vehicle
                  trajectory prediction},
	journal = {Internet Things},
	volume = {24},
	pages = {100935},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100935},
	doi = {10.1016/J.IOT.2023.100935},
	timestamp = {Sat, 13 Jan 2024 17:37:23 +0100},
	biburl = {https://dblp.org/rec/journals/iot/ShenLCYK23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Vehicle trajectory prediction is crucial in achieving safe and reliable autonomous driving decision-making. The accuracy of the prediction is affected by many different factors, such as the integrity and efficiency of vehicle-to-vehicle (V2V) data transfer, the complex environmental factors of the surrounding roads and the perception range of vehicle sensors. However, most existing methods cannot capture the dynamic interactive information of vehicles at different time steps. In this paper, we propose a Spatio-Temporal Interactive Graph Convolutional Network (STI-GCN) that predicts future trajectories by acquiring spatiotemporal features of vehicles. In the spatial dimension, we construct a kernel function based on spatial autocorrelation and use it as prior knowledge to describe the degree of mutual influence between vehicles in real traffic scenarios. In addition, the Gated Recurrent Unit (GRU) is used to dynamically capture the spatial features of vehicles to solve the dynamic making graph problem of vehicles in the real traffic scene. In the temporal dimension, we use a Convolutional Neural Network (CNN) to extract the temporal feature in the historical trajectory of the vehicle. Finally, we experimented with our method and existing methods on the public Next Generation Simulation (NGSIM) dataset. The experimental results show that the error of our model is reduced by about 10% compared with the state-of-the-art model. And it also improves about 10 times in two key metrics, namely the number of parameters and inference time.}
}


@article{DBLP:journals/iot/BakhshKAAAA23,
	author = {Shahid Allah Bakhsh and
                  Muhammad Almas Khan and
                  Fawad Ahmed and
                  Mohammed S. Alshehri and
                  Hisham Ali and
                  Jawad Ahmad},
	title = {Enhancing IoT network security through deep learning-powered Intrusion
                  Detection System},
	journal = {Internet Things},
	volume = {24},
	pages = {100936},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100936},
	doi = {10.1016/J.IOT.2023.100936},
	timestamp = {Fri, 08 Mar 2024 13:22:13 +0100},
	biburl = {https://dblp.org/rec/journals/iot/BakhshKAAAA23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The rapid growth of the Internet of Things (IoT) has brought about a global concern for the security of interconnected devices and networks. This necessitates the use of efficient Intrusion Detection System (IDS) to mitigate cyber threats. Deep learning (DL) techniques provides a promising approach to effectively detect irregularities in network traffic, enhancing IoT network security and reducing cyber threats. In this paper, DL-based IDS is proposed using Feed Forward Neural Networks (FFNN), Long Short-Term Memory (LSTM), and Random Neural Networks (RandNN) to protect IoT networks from cyberattacks. Each DL model has its potential benefit as reported in this paper. For example, the FFNN can handle complex IoT network traffic patterns, while the LSTM is good in capturing long-term dependencies present in the network traffic. With its random connections and flexible dynamics, the RandNN model uses its data learning ability to adapt and learn from network data. These algorithms boost cybersecurity by enabling defense mechanisms against challenging cyber threats and ensuring the security of sensitive data as IoT networks expand. The proposed technique exhibits superior performance when compared with the current state-of-the-art DL-IDS using the CIC-IoT22 dataset. An accuracy of 99.93 % is achieved for the FFNN model, 99.85 % for the LSTM model, and 96.42 % for the RandNN model in detecting intrusion. Moreover, the models have the potential to enhance intrusion detection in IoT networks by generating swift responses to security problems in IoT networks.}
}


@article{DBLP:journals/iot/ZahednejadG23,
	author = {Behnam Zahednejad and
                  Chong{-}zhi Gao},
	title = {A secure and efficient {AKE} scheme for IoT devices using {PUF} and
                  cancellable biometrics},
	journal = {Internet Things},
	volume = {24},
	pages = {100937},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100937},
	doi = {10.1016/J.IOT.2023.100937},
	timestamp = {Sat, 13 Jan 2024 17:37:23 +0100},
	biburl = {https://dblp.org/rec/journals/iot/ZahednejadG23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As the Internet of Things (IoT) continues to grow, there is an increasing need for secure and efficient authentication protocols for IoT devices. The design of IoT authentication schemes requires several essential features such as real two-factor security, Key Compromise Impersonation (KCI) resilience, and Perfect Forward Secrecy (PFS). In this paper, we perform a cryptanalysis of two state-of-the-art PUF-based Authentication and Key Exchange(AKE) schemes and show informally how they fail to achieve real two-factor security, PFS and suffer KCI, user traceability, and database attacks. To address these limitations, we propose an improved two-party AKE scheme between the user-device and the server based on a combination of a physically unclonable function (PUF) and a cancellable biometric (CB). Our proposed scheme provides real two-factor security, KCI resilience, PFS, and user untraceability, achieving all desired properties based on the Computational Diffie–Hellman (CDH) assumption in the random oracle model. To establish the security of our proposed scheme, we utilize formal analysis methods, including the RoR model and ProVerif, and perform an informal security analysis to demonstrate its resilience against potential attacks. Additionally, we analyze the computational and communication performance of our proposed scheme against related PUF-based schemes. Our proposed scheme exhibits a computational and communicational feasible overhead for deployment in the context of the IoT, with a lower magnitude than most previous related PUF-based schemes.}
}


@article{DBLP:journals/iot/Gulec23,
	author = {Omer Gulec},
	title = {Hybrid {FFBAT} optimized multi-hop routing in Internet of Nano-Things},
	journal = {Internet Things},
	volume = {24},
	pages = {100938},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100938},
	doi = {10.1016/J.IOT.2023.100938},
	timestamp = {Sat, 13 Jan 2024 17:37:23 +0100},
	biburl = {https://dblp.org/rec/journals/iot/Gulec23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Wireless Nano-Sensor Networks (WNSNs) are molecular-level networks consisting of nano-machines that have very limited energy capacity. Due to the high energy consumption of the nodes in WNSNs during the data transmission, energy-efficient routing algorithms may help to reduce overall energy consumption. On the other hand, metaheuristics are useful for solving problems such as routing, energy, security and connectivity for traditional sensor networks. Therefore, this study proposes a hybrid Firefly and BAT Optimization based energy-efficient multi-hop routing algorithm, namely nanoFFBAT, between nano-sensor nodes and randomly placed convenient nano-routers for WNSNs-supported Internet of Nano-Things (IoNT) applications. In this hybrid approach, Firefly optimization is used for selecting the most energy-efficient neighbor by a nano-sensor node based on the flashing behavior of fireflies on the way for forming multi-hop paths and the BAT algorithm is adapted for building energy-efficient routing path discovery in WNSNs and also finding the optimal solution in solution space. In addition, nanoFFBAT detects redundant nodes on the energy-efficient multi-hop routing paths and shortens these paths if there exists any neighbor node already has been selected. The results of nanoFFBAT are compared with the shortest path from a nano-node to the convenient nano-router, a genetic algorithm-based energy-efficient routing algorithm for sensor networks and a WNSN routing protocol in the literature. According to the experimental simulation results, nanoFFBAT saves 306.929 nJ on a path on average and prolongs network lifetime 16.298 times more on average compared to the mentioned algorithms.}
}


@article{DBLP:journals/iot/KimSH23,
	author = {Euiseok Kim and
                  Taehyeong Son and
                  Soonhoi Ha},
	title = {A novel hierarchical edge-based architecture for service oriented
                  IoT},
	journal = {Internet Things},
	volume = {24},
	pages = {100939},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100939},
	doi = {10.1016/J.IOT.2023.100939},
	timestamp = {Sat, 13 Jan 2024 17:37:23 +0100},
	biburl = {https://dblp.org/rec/journals/iot/KimSH23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {IoT (Internet of Things) is becoming increasingly prevalent in everyday life, with many commercialized IoT platforms available for use. In this paper, we propose a novel hierarchical IoT platform under a single administrating entity to provide scalability to an edge-based service-oriented IoT platform. To enable communication and resource sharing between edges while preserving the privacy benefit of the edge-based platform, a new type of service, called super service is introduced. And the scheduling problem of service requests to devices and a proposed solution are presented. To evaluate the proposed platform, a simulation framework is developed. Through a smart campus test-bed and extensive experiments with the simulation framework, the viability of the proposed platform is demonstrated.}
}


@article{DBLP:journals/iot/CarroLagoaBGEC23,
	author = {{\'{A}}ngel Carro{-}Lagoa and
                  Valent{\'{\i}}n Barral and
                  Miguel Gonz{\'{a}}lez{-}L{\'{o}}pez and
                  Carlos J. Escudero and
                  Luis Castedo},
	title = {Multicamera edge-computing system for persons indoor location and
                  tracking},
	journal = {Internet Things},
	volume = {24},
	pages = {100940},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100940},
	doi = {10.1016/J.IOT.2023.100940},
	timestamp = {Fri, 08 Mar 2024 13:22:13 +0100},
	biburl = {https://dblp.org/rec/journals/iot/CarroLagoaBGEC23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper presents an indoor person localization and tracking system that uses multiple smart cameras equipped with artificial intelligence (AI) accelerators serving as edge-computing nodes. Our main contributions are as follows: (a) the development of a new multicamera tracking system for indoor scenarios; (b) the release of a multitarget multicamera tracking dataset; and (c) the development of an annotation mechanism based on waypoints. The system can simultaneously track several individuals while preserving their privacy and anonymity, because no images or sensitive data are transmitted outside the edge nodes. Only the position and appearance of each person were transmitted to the central server. In addition, a multitarget multicamera tracking dataset was released. The dataset contains recordings from five cameras in an indoor scenario and is annotated with the real-world coordinates of individuals. Ground-truth annotations were semiautomatically generated using a mechanism in which people equipped with mobile phones followed specific paths with predefined waypoints. Software related to the ground-truth annotation mechanism has also been released as open source.}
}


@article{DBLP:journals/iot/BenrazekFKFS23,
	author = {Ala{-}Eddine Benrazek and
                  Brahim Farou and
                  Zineddine Kouahla and
                  Mohamed Amine Ferrag and
                  Hamid Seridi},
	title = {IoVT-based efficient solution for optimal active smart camera selection
                  in a tracking mission},
	journal = {Internet Things},
	volume = {24},
	pages = {100941},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100941},
	doi = {10.1016/J.IOT.2023.100941},
	timestamp = {Sat, 13 Jan 2024 17:37:23 +0100},
	biburl = {https://dblp.org/rec/journals/iot/BenrazekFKFS23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Nowadays, to ensure people’s and property’s safety, cities have dozens of cameras installed on almost every corner. However, the haphazard deployment of these cameras often results in overlapping fields of view, leading to redundant processing of the same events by multiple cameras. This situation requires more power, huge bandwidth, and more storage capacity for collecting, processing and distributing multimedia data over the network. To overcome these challenges, we propose a novel Internet of Video Things-based system that efficiently reduces the number of cameras involved in processing redundant events. The proposed system operates through a two-step process. Firstly, a leader is elected from a group of cameras based on the degree of overlap in their fields of view, serving as the coordinator. Secondly, the system intelligently selects suitable assistants from neighboring cameras to complement the leader’s vision when it becomes inadequate for effective object tracking. Consequently, only the leader and its assistants remain active, while other neighboring cameras remain in an inactive state. The evaluation demonstrates that our IoVT-based solution offers an efficient approach by minimizing redundancy, optimizing resource utilization and overcoming the challenges posed by the random installation of cameras in urban environments.}
}


@article{DBLP:journals/iot/ChakrabortyGKD23,
	author = {Anik Chakraborty and
                  Rittik Das Gupta and
                  Md. Zesanul Kabir and
                  Sourav Dhar},
	title = {Development of an IoT-enabled cost-effective asthma patient monitoring
                  system: Integrating health and indoor environment data with statistical
                  analysis and data visualization},
	journal = {Internet Things},
	volume = {24},
	pages = {100942},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100942},
	doi = {10.1016/J.IOT.2023.100942},
	timestamp = {Sat, 13 Jan 2024 17:37:23 +0100},
	biburl = {https://dblp.org/rec/journals/iot/ChakrabortyGKD23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This research aims to develop a cost-effective IoT-based remote health monitoring system tailored for asthma patients to provide real-time feedback and hence minimize the necessity of hospitalization. The system includes monitoring patient health indicators and indoor environmental parameters. This device consists of NodeMCU and Arduino microcontrollers along with sensors such as the max30100 for heart rate and oxygen level sensing, the ds18b20 for body temperature measurement, the dht11 for room temperature and humidity sensing, the optical dust sensor for tracking dust concentration, and the mq-135 gas sensor for detecting harmful gases. The study is divided into two major sections: the front end, which includes the hardware setup with microcontrollers, wires, and sensors, and the back end, which contains software-based database features for real-time monitoring, storage of patient records, and analyses of the collected data to extract valuable insights about the patient's condition. The Blynk IoT platform offers real-time tracking on mobile devices, while the ThingSpeak platform enables graphical depiction on a computer-friendly interface. A Google Spreadsheet database is used to store the acquired data. The system has an integrated alerting system that sends email/SMS alerts to patients and physicians when sensor readings exceed safe levels. A prototypic data analysis section is introduced to assess the collected data through descriptive analysis, graph charting, and box plot visualization. The health measures were examined for a single patient during a week, using statistical tests like ANOVA to detect changes and determine stability, while the environmental elements were assessed throughout a month, capturing trends and patterns. All health sensors were validated by utilizing paired sample t-tests to compare 15 patients' data to that of commercially available devices. This research provides a complete package that provides essential guidance for replicating the device, interpreting and presenting sensor data efficiently to assess the health of asthma patients. Additionally, it proposes future-oriented objective function optimization and enhanced data security measures. The source code of the proposed system is available on\nGitHub\n.}
}


@article{DBLP:journals/iot/FayyazRKK23,
	author = {Sana Fayyaz and
                  Muhammad Atif Ur Rehman and
                  Waqas Khalid and
                  Byung{-}Seo Kim},
	title = {{SHM-NDN:} {A} seamless hybrid mobility management scheme for named
                  data mobile ad hoc networks},
	journal = {Internet Things},
	volume = {24},
	pages = {100943},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100943},
	doi = {10.1016/J.IOT.2023.100943},
	timestamp = {Tue, 07 May 2024 20:25:59 +0200},
	biburl = {https://dblp.org/rec/journals/iot/FayyazRKK23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Named Data Networking (NDN), a counterpart of address-centric networking resolves consumer mobility issues to some extent, however, it confronts excessive bandwidth consumption and network congestion problems in Mobile Adhoc Networks (MANET) due to an inefficient default request re-transmission mechanism. The producer mobility in NDN-based MANET, on the other hand, poses even worse challenges owing to the continuous flooding of location advertisement messages in the network. This paper aims to address the aforementioned producer and consumer mobility issues in MANET and proposes SHM-NDN, a seamless hybrid mobility management scheme for NDN-based MANETs. The proposed scheme features new packet types and extends the functionality of wireless mobile FIB data structure to support efficient mobility management. Moreover, the SHM-NDN proposes a path recovery mechanism to deal with the network partitioning problem caused by a low signal-to-noise ratio and high congestion rate. Through an extensive simulation study, we demonstrate that SHM-NDN achieves on average 12.2% less bandwidth and energy consumption compared to CBILEM. Similarly, SHM-NDN also attains on average 25% less bandwidth and energy consumption compared to EEIF.}
}


@article{DBLP:journals/iot/GothesenHK23,
	author = {Sara G{\o}thesen and
                  Moutaz Haddara and
                  Karippur Nanda Kumar},
	title = {Empowering homes with intelligence: An investigation of smart home
                  technology adoption and usage},
	journal = {Internet Things},
	volume = {24},
	pages = {100944},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100944},
	doi = {10.1016/J.IOT.2023.100944},
	timestamp = {Fri, 08 Mar 2024 13:22:13 +0100},
	biburl = {https://dblp.org/rec/journals/iot/GothesenHK23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The increasing interconnectedness of the world, coupled with the proliferation of connected devices, networks, and intricate systems, has paved the way for unparalleled opportunities in automation and sophisticated digital transformation. This has also led to a global rise in the adoption of smart and intelligent technologies within the smart home market. Norway, being a technologically advanced country with digitally skilled citizens, presents a potential market for the widespread adoption of smart home technologies. However, there is a lack of research on the adoption of smart home technology (SHT), specifically in Norway. Hence, this study aims at investigating the factors that influence Norwegian consumers' intentions to adopt smart home technologies, as well as the diffusion of smart home adoption in the Norwegian market. Employing a mixed-methods research design, this study gathered insights from both consumers and vendors through ten qualitative interviews and a survey with 100 participants over the period of seven months. The findings of this study provide empirical evidence supporting the significance of hedonic motivation, perceived price value, and social influence in relation to the use and adoption of SHT.}
}


@article{DBLP:journals/iot/RodriguezRodriguezCR23,
	author = {Ignacio Rodr{\'{\i}}guez{-}Rodr{\'{\i}}guez and
                  Mar{\'{\i}}a Campo{-}Valera and
                  Jos{\'{e}}{-}V{\'{\i}}ctor Rodr{\'{\i}}guez},
	title = {Forecasting glycaemia for type 1 diabetes mellitus patients by means
                  of IoMT devices},
	journal = {Internet Things},
	volume = {24},
	pages = {100945},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100945},
	doi = {10.1016/J.IOT.2023.100945},
	timestamp = {Tue, 07 May 2024 20:25:59 +0200},
	biburl = {https://dblp.org/rec/journals/iot/RodriguezRodriguezCR23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The chronic metabolic condition, Type 1 diabetes mellitus (DM1), is marked by consistent hyperglycemia due to the body's inability to produce sufficient insulin. This necessitates the patient's daily monitoring of blood glucose fluctuations to discern a trend and predict future glycemia, subsequently dictating the amount of external insulin needed to regulate glycemia effectively. However, this technique often grapples with a degree of inaccuracy, presenting potential hazards. Nonetheless, contemporary advancements in information and communication technologies (ICT) coupled with novel biological signal sensors offer a refreshing perspective for DM1 management by enabling comprehensive, continual patient health evaluation. Herein, burgeoning technological disruptions such as Big Data, the internet of medical things (IoMT), cloud computing, and machine learning algorithms (ML) could serve pivotal roles in the effective control of DM1. This paper delves into the exploration of the latest IoMT-based methodologies for the unbroken surveillance of DM1 management, facilitating a profound characterization of diabetic patients. The fusion of wearable technologies with machine learning strategies has the potential to yield robust models for short-term blood glucose prediction. The ambition of this study is to develop precise, individual-centric prediction models harnessing an array of pertinent factors. The study applied modeling techniques to a comprehensive dataset comprising glycaemia-associated biological attributes, sourced from an expansive passive monitoring campaign involving 40 DM1 patients. Leveraging the Random Forest method, the resulting models can predict glucose levels over a 30-min time span with an average error as minimal as 18.60 mg/dL for six-hour data and 26.21 mg/dL for a 45-minute prediction horizon, offering also a good performance in the prediction delay.}
}


@article{DBLP:journals/iot/SoltanizadehF23,
	author = {Hediyeh Soltanizadeh and
                  Abolfazl Falahati},
	title = {Low complexity channel tracking algorithms for coordinated and uncoordinated
                  pilot access over high-rate internet of things},
	journal = {Internet Things},
	volume = {24},
	pages = {100946},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100946},
	doi = {10.1016/J.IOT.2023.100946},
	timestamp = {Wed, 03 Jan 2024 08:34:14 +0100},
	biburl = {https://dblp.org/rec/journals/iot/SoltanizadehF23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Given that high-rate internet-of-things (IoT) applications are supported by ubiquitous massive MIMO services, this paper introduces novel algorithms with significantly reduced complexity to estimate and track the channels of active and inactive devices, which can resolve intra-cell pilot collisions and utilize their information. Then, we propose an optimum coordinated access (O-CA) tracker whose complexity grows squarely with the number of devices instead of cubically. In addition, the error-boundedness and steady-state characteristics of O-CA are demonstrated. Although uncoordinated pilot access eliminates control signaling associated with active IoT devices, it needs the base station (BS) to identify the devices’ pilot transmission patterns (DPTPs). A low-complexity optimal uncoordinated access (O-UA) tracker is intended to contain DPTPs that expand exponentially, which is impractical. To this end, we derive an analytical closed-form solution for a near-optimal uncoordinated access (NO-UA) tracker that minimizes an upper bound on the error between O-UA and the simplified DPTPs. Consequently, the NO-UA results in significantly lower computational costs and superior estimation performance compared to existing trackers. Moreover, we derive the optimal linear uncoordinated access (OL-UA) tracker and its stability. Specifically, two heuristic trackers are introduced to detect DPTPs and track the devices’ channels. The simulation results and complexity analysis demonstrate that the designed trackers significantly reduce complexity compared with conventional trackers.}
}


@article{DBLP:journals/iot/AlmutairiB23,
	author = {Suzan Almutairi and
                  Ahmed Barnawi},
	title = {Federated learning vulnerabilities, threats and defenses: {A} systematic
                  review and future directions},
	journal = {Internet Things},
	volume = {24},
	pages = {100947},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100947},
	doi = {10.1016/J.IOT.2023.100947},
	timestamp = {Sat, 13 Jan 2024 17:37:23 +0100},
	biburl = {https://dblp.org/rec/journals/iot/AlmutairiB23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Today, a broad range of items, ranging from smartphones to smart cars are connected together via the Internet, also known as the Internet of Things (IoT). The IoT is powered by Machine Learning (ML) to facilitate client services and applications. Traditionally, centralized ML techniques require the collection and processing of enormous data sets, which may not be feasible in the context of realistic IoT applications scenarios, due to the exponential increase in IoT devices. Federated learning (FL) is a new paradigm of ML training that relies on decentralized collaborative learning, between various clients, where data is located locally with each client. FL has brings about many advantages, such as helping preserve privacy where the client's local data is retained locally to train the model. While FL has emerged as an attractive and promising training solution to protect clients’ privacy, it needs additional exploration to specify its potential security implications, as these may preclude its routine adoption. Existing FL algorithms, security and privacy techniques exhibit new vulnerabilities, which could be exploit by attackers to compromise the FL model. Thus, it is critical to increase awareness of the potential consequences associated with novel threats to FL models. Prior research has examined various FL concepts, such as algorithms, attacks, privacy, vulnerabilities, etc. However, these concepts were not encompassed in a single survey. To the best of our knowledge, this is the first survey combining analysis of FL security and privacy techniques by highlighting sources of FL vulnerabilities, possible attacks and privacy techniques, and presenting FL basics including data distribution and aggregation algorithms. We then present state of the art studies in FL attack studies, and privacy techniques for protecting against these attacks. Finally, we conclude by identifying FL challenges and future research directions to address current limitations.}
}


@article{DBLP:journals/iot/RenXZJKY23,
	author = {Yilong Ren and
                  Jianru Xiao and
                  Yanan Zhao and
                  Han Jiang and
                  Saru Kumari and
                  Haiyang Yu},
	title = {{PRS-HDMC:} An online participant recruitment scheme for vehicular
                  crowdsensing-enabled {HD} map collection},
	journal = {Internet Things},
	volume = {24},
	pages = {100948},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100948},
	doi = {10.1016/J.IOT.2023.100948},
	timestamp = {Wed, 03 Jan 2024 08:34:14 +0100},
	biburl = {https://dblp.org/rec/journals/iot/RenXZJKY23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The emergence of vehicular crowdsensing (VCS) brings new opportunities and possibilities for the collection of High-Definition (HD) maps. Unlike traditional mapping methods, VCS leverages ubiquitous vehicles and on-board cameras to collect data inexpensively and efficiently. Though promising, such a data collection mode still faces an unsolved problem of ensuring the availability and integrity of collected map data. To address this issue, this paper proposes PRS-HDMC, a participant recruitment scheme for VCS-enabled HD map collection. Specifically, we first analyze the unique requirements that distinguish HD map acquisition from other sensing tasks. On this basis, a metric participant contribution is proposed to describe the accuracy and content richness of the collected photo. Combining this metric with participant reliability and task coverage, we establish a novel quality of service (QoS) quantification system and develop the participant recruitment optimization model. Then, an improved greedy algorithm is proposed to recruit the appropriate vehicular set online according to their real-time locations, thereby maximizing the system QoS of each task round. Finally, we conduct extensive simulations based on a synthetic dataset under different settings. Experimental results demonstrate that the proposed scheme can guarantee the availability and integrity of collected map data, and outperforms all benchmarks.}
}


@article{DBLP:journals/iot/ChawlaM23,
	author = {Diksha Chawla and
                  Pawan Singh Mehra},
	title = {{QSMAH:} {A} novel quantum-based secure cryptosystem using mutual
                  authentication for healthcare in the internet of things},
	journal = {Internet Things},
	volume = {24},
	pages = {100949},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100949},
	doi = {10.1016/J.IOT.2023.100949},
	timestamp = {Sat, 13 Jan 2024 17:37:23 +0100},
	biburl = {https://dblp.org/rec/journals/iot/ChawlaM23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Healthcare in IoT provides many benefits, such as real-time data transfer and decision-making based on the information received from the patient's Body Sensor Nodes (BSNs). Many healthcare centers have adopted IoT-based devices such as heart monitoring implants and Electrocardiograms (ECG) for continuous patient monitoring in and out of hospitals. However, due to open Internet connectivity and lack of authentication, these devices may lead to several life-threatening risks. Recent advancements in Quantum Computing threatened the security of classical cryptographic primitives such as the RSA algorithm. The security and privacy of patient data are of utmost importance and are to be protected from existing vulnerabilities and futuristic Quantum attacks. Motivated by the abovementioned issues, we proposed the QSMAH protocol which ensures secure Key Agreement (KA) and Mutual Authentication (MA) based on Quantum Cryptography. Unlike classical authentication schemes, in our protocol, Quantum Teleportation and Quantum Entanglement are effectively utilized for secure data transfer among entities. The security of the proposed QSMAH protocol relies on a Quantum Key and Greenberger–Horne–Zeilinger (GHZ) states to achieve strong authentication. An extensive formal security analysis using BAN logic is provided to prove the goal of our protocol. The simulation of the proposed protocol is provided using Automated Validation of Internet Security Protocols and Applications (AVISPA). The results reflect that the security of our protocol cannot be tampered with by Quantum Shor's and Grover's algorithms. The security analysis proves that QSMAH is also resistant to classical attacks and futuristic Quantum attacks on cryptographic schemes.}
}


@article{DBLP:journals/iot/ChawlaM23a,
	author = {Diksha Chawla and
                  Pawan Singh Mehra},
	title = {A roadmap from classical cryptography to post-quantum resistant cryptography
                  for 5G-enabled IoT: Challenges, opportunities and solutions},
	journal = {Internet Things},
	volume = {24},
	pages = {100950},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100950},
	doi = {10.1016/J.IOT.2023.100950},
	timestamp = {Sat, 13 Jan 2024 17:37:23 +0100},
	biburl = {https://dblp.org/rec/journals/iot/ChawlaM23a.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {5th Generation(5G) -enabled Internet of Things (IoT) connects billions of devices for high-speed data transfer. The data collected fuel many automation applications such as smart cities, industrial automation 5.0, autonomous vehicles and healthcare sectors. However, the critical challenges concerning such an environment are Open Web Security and Mutual Authentication. The recent security protocols of IoT are based on hard mathematical cryptographic structures. Nevertheless, dependency on the security of classical cryptographic primitives is at risk of being broken by Quantum Computing. Recent Quantum attacks on IoT security have motivated us to survey Quantum-resistant solutions comprehensively. Therefore in this paper, we analysed how the technology shifts from classical cryptographic techniques towards quantum-enabled solutions to achieve end-to-end security. The main objective of this survey is to provide a systematic roadmap in the area of Quantum secured 5G-enabled IoT communication by covering current research on 5G-enabled IoT with its key enabling technologies, threats imposed on 5G-enabled IoT applications, state-of-the-art quantum-based solutions and initiatives. A detailed overview of the quantum computing preliminaries, Post Quantum Cryptography (PQC) schemes, Quantum Cryptography (QC), and Quantum Key Distribution (QKD) with their significant advantage in securing IoT-enabled communication over classical scenarios are also presented. Particularly, we emphasize Post-Quantum resistant techniques that must be used soon to secure 5G-enabled IoT communications. The comparative analysis of quantum-resistant schemes with classical cryptographic schemes in terms of key size, data size, time complexity and impact of quantum computers on these schemes are discussed. This paper identifies the technical challenges in Quantum-based schemes and provides future research directions to enable Post-Quantum resistant cryptography for secure communication in 5G-enabled IoT.}
}


@article{DBLP:journals/iot/WuBCZWXL23,
	author = {Guanlin Wu and
                  Weidong Bao and
                  Jiang Cao and
                  Xiaomin Zhu and
                  Ji Wang and
                  Wenhua Xiao and
                  Wenqian Liang},
	title = {Towards efficient long-horizon decision-making using automated structure
                  search method of hierarchical reinforcement learning for edge artificial
                  intelligence},
	journal = {Internet Things},
	volume = {24},
	pages = {100951},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100951},
	doi = {10.1016/J.IOT.2023.100951},
	timestamp = {Wed, 22 May 2024 17:19:07 +0200},
	biburl = {https://dblp.org/rec/journals/iot/WuBCZWXL23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Hierarchical reinforcement learning (HRL) is a promising approach for efficiently solving various long-horizon decision-making tasks in the Internet of Things (IoT) domain. However, HRL algorithms are known to rely on expert knowledge to preset an appropriate hierarchical structure for different IoT tasks, which leads to higher trial costs and limits its wider application. In this paper, we propose a new method called DHRL (Dynamic-Level Hierarchical Reinforcement Learning) and it is able to adaptively search for the optimal hierarchical structure while maintaining the generality of framework design. DHRL incorporates an embedded exploration and exploitation mechanism that effectively solves the challenges caused by dependence between different levels and achieves a balance between maximizing benefits and current evaluation accuracy. Nonetheless, the more exploration processes inevitably has a negative impact on the performance. To mitigate this influences, we propose a synchronous training architecture to support DHRL operating in a distributed and parallel manner, in which the adaptive evolutionary method is also introduced to accelerate the convergence. Extensive experimental evaluations are conducted to demonstrate the effectiveness of our theory and method.}
}


@article{DBLP:journals/iot/GharehchopoghABA23,
	author = {Farhad Soleimanian Gharehchopogh and
                  Benyamin Abdollahzadeh and
                  Saeid Barshandeh and
                  Bahman Arasteh},
	title = {A multi-objective mutation-based dynamic Harris Hawks optimization
                  for botnet detection in IoT},
	journal = {Internet Things},
	volume = {24},
	pages = {100952},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100952},
	doi = {10.1016/J.IOT.2023.100952},
	timestamp = {Sat, 13 Jan 2024 17:37:23 +0100},
	biburl = {https://dblp.org/rec/journals/iot/GharehchopoghABA23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The increasing trend toward using the Internet of Things (IoT) increased the number of intrusions and intruders annually. Hence, the integration, confidentiality, and access to digital resources would be threatened continually. The significance of security implementation in digital platforms and the need to design defensive systems to discover different intrusions made the researchers study updated and effective methods, such as Botnet Detection for IoT systems. Many problem space features and network behavior unpredictability made the Intrusion Detection System (IDS) the main problem in maintaining computer networks' security. Furthermore, many insignificant features have turned the feature selection (FS) problem into a vast IDS aspect. This paper introduces a novel binary multi-objective dynamic Harris Hawks Optimization (HHO) enhanced with mutation operator (MODHHO) and applies it to Botnet Detection in IoT. Afterward, the Feature Selection (FS) is undertaken, and the K-Nearest Neighbor (KNN), Support Vector Machine (SVM), Multilayer Perceptron (MLP), and Decision Tree (DT) classifiers are used to estimate the potential of the selected features in the precise detection of intrusions. The simulation results illustrated that the MODHHO algorithm performs well in Botnet Detection in IoT and is preferred to other approaches in its performance metrics. Besides, the computational complexity analysis results suggest that the MODHHO algorithm's overhead is more optimal than similar approaches. The MODHHO algorithm has performed better in comparison with other compared algorithms in all 5 data sets. In contrast with the machine learning methods of the proposed model in all five data sets, it has had a better error rate according to the AUC, G-mean, and TPR criteria. And according to the comparison made with filter-based methods, it has performed almost better in three datasets.}
}


@article{DBLP:journals/iot/ZerroukiOB23,
	author = {Fahem Zerrouki and
                  Samir Ouchani and
                  Hafida Bouarfa},
	title = {{T2S-MAKEP} and {T2T-MAKEP:} {A} PUF-based Mutual Authentication and
                  Key Exchange Protocol for IoT devices},
	journal = {Internet Things},
	volume = {24},
	pages = {100953},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100953},
	doi = {10.1016/J.IOT.2023.100953},
	timestamp = {Sat, 13 Jan 2024 17:37:23 +0100},
	biburl = {https://dblp.org/rec/journals/iot/ZerroukiOB23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Nowadays, more constrained devices are becoming connected, building an extensive Internet of Things (IoT) network, but suffering from many security issues. In particular, authentication has become a severe research challenge for IoT systems. Furthermore, confidentiality, integrity, and availability are considered the core underpinnings of information security in general. Unfortunately, deploying conventional authentication protocols for IoT devices in practice is challenging for two main reasons. First, IoT devices have limited memory capacity, processing power, and energy resources. Second, these protocols store secret keys in the IoT devices’ volatile memory, making them vulnerable to physical attacks. Luckily, Physical Unclonable Functions (PUF) has emerged as promising low-cost security primitive. A PUF eliminates the need to store secret keys in device memory, making it a potential alternative to deploying more secure and low-cost authentication protocol schemes for IoT systems. Thing-to-Thing (T2T) or direct connection between IoT devices represents a promising technique to enable things to communicate directly without the need for a trusted third party. This paper proposes two novel lightweight Mutual Authentication and Key Exchange Protocols (MAKEP) for IoT devices using PUF. The first scheme, called T2S-MAKEP, ensures secure communication for Thing-to-Server (T2S). The second, called T2T-MAKEP, allows two endpoints of resource-constrained IoT devices, each with an embedded PUF circuit, to communicate securely. Both proposed protocols, T2T-MAKEP and T2S-MAKEP, allow for robust authentication without storing any information on the device’s memory and simultaneously establish the session key exchange. Our proposed protocols have been verified and validated using the automatic security analysis checker, Verifpal.}
}


@article{DBLP:journals/iot/ZorgatiDA23,
	author = {Hela Zorgati and
                  Raoudha Ben Djemaa and
                  Ikram Amous},
	title = {Efficient IoT resource discovery approach based on {P2P} networks
                  and Fog Computing},
	journal = {Internet Things},
	volume = {24},
	pages = {100954},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100954},
	doi = {10.1016/J.IOT.2023.100954},
	timestamp = {Sat, 13 Jan 2024 17:37:23 +0100},
	biburl = {https://dblp.org/rec/journals/iot/ZorgatiDA23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Internet of Things (IoT) objects, their provided resources and services, as well as their users, and the requests for these resources, are increasing. Consequently, it is becoming extremely difficult for users to find a specific IoT resource that fits their needs. The sheer number and wide range of equipment in IoT, coupled with the lack of standardized and coherent resource descriptions, have a significant impact on resource discovery. In this context, we propose a Fog-based Distributed Semantic IoT resource discovery (FDS-RD) solution. FDS-RD leverages semantic technologies and two levels of peer-to-peer (P2P) networks to provide a semantic and scalable IoT resource discovery. Additionally, to support real-time applications, FDS-RD capitalizes on the Fog computing paradigm to reduce the discovery time. Experimental results demonstrate that the proposed solution enhances the performance of the discovery process by increasing the relevance of the discovered resources and reducing the response time.}
}


@article{DBLP:journals/iot/BaniataAK23,
	author = {Hamza Baniata and
                  Ahmad T. Anaqreh and
                  Attila Kert{\'{e}}sz},
	title = {Distributed scalability tuning for evolutionary sharding optimization
                  with Random-equivalent security in permissionless Blockchain},
	journal = {Internet Things},
	volume = {24},
	pages = {100955},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100955},
	doi = {10.1016/J.IOT.2023.100955},
	timestamp = {Fri, 08 Mar 2024 13:22:13 +0100},
	biburl = {https://dblp.org/rec/journals/iot/BaniataAK23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In spite of multiple advantages of the adoption of blockchain (BC), it still faces some integration challenges in modern applications, such as the Internet of Things. These challenges include low throughput rates in permissionless settings. To solve this challenge, several state-of-the-art works proposed sharding (i.e., partitioning) the BC infrastructure. Sharding the network into smaller shards improves the total system throughput, regardless of the node-shard assignment criteria. Most previous work applied a Random Sharding (RS) approach, i.e., randomly allocating nodes into predefined shards, to satisfy the required unpredictability property of node-shard allocation. In this paper, we propose a Blockchain Optimized and Secure Sharding (BOSS) protocol that aims to optimize the node-shard allocation resulting in increased throughput using a variant of the evolutionary Genetic Algorithm. The RS-equivalent levels of security and unpredictability are guaranteed by deploying a distributed random tuning mechanism for the intra-shard weight. We designed BOSS as an extension of the well-defined RS-based RapidChain protocol. We show that the proposed methods can be adapted to other sharding protocols that originally used RS techniques. We implemented and tested our protocol with more than 362,880 cases that covered seven configurable system and optimization parameters. Our evaluation revealed\n≈\n17\n%\naverage enhancement in scalability, along with a negligible\n<\n0\n.\n5\n%\nmean absolute difference in security levels. To the best of our knowledge, this is the first work that optimizes inter- and intra-shard scalability, with publicly verifiable solutions in permissionless BCs, while maintaining RS-equivalent security and unpredictability.}
}


@article{DBLP:journals/iot/KhanGRS23,
	author = {Sajjad Khan and
                  Jor{\~{a}}o Gomes and
                  Muhammad Habib Ur Rehman and
                  Davor Svetinovic},
	title = {Dynamic behavior assessment protocol for secure Decentralized Federated
                  Learning},
	journal = {Internet Things},
	volume = {24},
	pages = {100956},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100956},
	doi = {10.1016/J.IOT.2023.100956},
	timestamp = {Fri, 08 Mar 2024 13:22:13 +0100},
	biburl = {https://dblp.org/rec/journals/iot/KhanGRS23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Decentralized Federated Learning (DFL) is a prevalent approach to efficiently train deep learning models and preserve privacy by sharing model gradients instead of the local data. However, participants in the DFL may opt to adopt a dynamic behavior for personal gains. The existing DFL models cannot differentiate between the adaptive behavior of the participants in the massively distributed environments and assume that all the participants are honest. As a result, free riders or malicious participants remain undetected and not penalized. In this paper, we present a DFL architecture where decentralized participants assess the behavior of each other using the quality of gradients. A novel dynamic reputation assessment protocol is implemented to detect and eliminate participants with adaptive behavior. The proposed architecture is evaluated using behavior-based attacks in a decentralized environment by increasing the percentage of adaptive participants from 10% to 40%. The results show that our proposed protocol can effectively detect and eliminate participants with adaptive behavior from the DFL in only two rounds whereas centralized federated learning fails to detect behavior-based attacks.}
}


@article{DBLP:journals/iot/MaudetACD23,
	author = {S{\'{e}}bastien Maudet and
                  Guillaume Andrieux and
                  Romain Chevillon and
                  Jean{-}Fran{\c{c}}ois Diouris},
	title = {Practical evaluation of Wi-Fi HaLow performance},
	journal = {Internet Things},
	volume = {24},
	pages = {100957},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100957},
	doi = {10.1016/J.IOT.2023.100957},
	timestamp = {Fri, 26 Jan 2024 07:57:16 +0100},
	biburl = {https://dblp.org/rec/journals/iot/MaudetACD23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Wi-Fi HaLow is one of the wireless communication technologies especially developed for the IoT. Compared to the legacy, new mechanisms and new features have been designed to increase the communication range and decrease the energy consumption. Transmissions are carried out in sub-1 GHz frequency bands, which should allow a range of 1 km and a maximum data rate of 150 kbps at this distance. However, these properties have never been validated with real equipment because consumer solutions have only recently been proposed by manufacturers. In this paper, equipment integrating the Newracom NRC-7292 chip is used to make measurements, in order to compare with the theory and to validate the use of this technology in IoT domains. Several measurement campaigns (indoor and outdoor environments) show the good behavior of the Wi-Fi HaLow in terms of range (up to 1 km for 23 dBm), throughput (nearly 6 Mbps for a 2 MHz Bandwidth) and latency. These measurements also provide one of the first real-life propagation models for 802.11ah wireless communications.}
}


@article{DBLP:journals/iot/SekarFB23,
	author = {C. Sekar and
                  Vinod Ramesh Falmari and
                  M. Brindha},
	title = {Secure IoT-enabled sharing of digital medical records: An integrated
                  approach with reversible data hiding, symmetric cryptosystem, and
                  {IPFS}},
	journal = {Internet Things},
	volume = {24},
	pages = {100958},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100958},
	doi = {10.1016/J.IOT.2023.100958},
	timestamp = {Sat, 13 Jan 2024 17:37:23 +0100},
	biburl = {https://dblp.org/rec/journals/iot/SekarFB23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the digitizing medical field, secure sharing of patients’ medical records over the Internet while preserving privacy is critical. Medical image encryption safeguards healthcare, IoMT, and cloud services from increasing digital threats. Incorporating vital diagnostic data like blood pressure, haemoglobin levels, sugar levels, body temperature, and medical images such as X-rays, CT, and MRI scans, comprehensive medical records benefit from Internet of Things (IoT) technology. This research paper presents a secure solution for sharing medical records among medical experts. The system employs the tamper-proof InterPlanetary File System (IPFS) for secure storage and distribution. It establishes a cryptographic association between medical reports and images, enabling secure outsourcing and retrieval by authorized users. This is achieved through the use of the reversible data hiding technique based on the Parametric Binary Tree Labeling (PBTL) scheme, efficiently linking Medical Reports and Images. To ensure robust security, the Medical Report in PDF format is encrypted using the Advanced Encryption Standard (AES-256) for symmetric encryption, and the encrypted file is securely uploaded to IPFS, generating a hash value serving as a reliable reference for future use. Furthermore, IPFS treats the hash value as confidential information and embeds it into the medical image using a novel Algorithm to embed secrets. Subsequently, the embedded image undergoes encryption before being uploaded to IPFS. The extensive evaluation and comparison with existing systems affirm the effectiveness of the proposed method in ensuring security and privacy preservation. Various analyses, including image quality, sensitivity, security, correlation, quality, and attack robustness, demonstrate the efficiency and strength of the proposed approach.}
}


@article{DBLP:journals/iot/AbbasiPSC23,
	author = {Mahmoud Abbasi and
                  Javier Prieto and
                  Amin Shahraki and
                  Juan M. Corchado},
	title = {Industrial data monetization: {A} blockchain-based industrial IoT
                  data trading system},
	journal = {Internet Things},
	volume = {24},
	pages = {100959},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100959},
	doi = {10.1016/J.IOT.2023.100959},
	timestamp = {Fri, 08 Mar 2024 13:22:13 +0100},
	biburl = {https://dblp.org/rec/journals/iot/AbbasiPSC23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Internet of Things (IoT) devices utilized in manufacturing industries produce vast volumes of valuable data that can revolutionize productivity and sustainability. While existing centralized data marketplaces facilitate data trading, they are often marred by trust issues, a single point of failure, and significant security and privacy vulnerabilities. Addressing these critical shortcomings, this paper introduces a blockchain-based industrial data trading system that not only ensures secure and transparent data trading but also offers advantages over conventional systems. Unlike traditional marketplaces, our proposed system emphasizes trustworthiness by mitigating third-party risks, enhancing data integrity through decentralized storage, and employing graph technology for efficient blockchain querying. Further, with integrated access control, our system elevates security standards. Preliminary evaluations reveal the system’s potential to offer a more secure, transparent, auditable, and trustworthy data trading environment, distinctly outpacing the capabilities of current marketplaces.}
}


@article{DBLP:journals/iot/DiazSELCV23,
	author = {Guillermo D{\'{\i}}az and
                  Iker Sobr{\'{o}}n and
                  I{\~{n}}aki Eizmendi and
                  Iratxe Landa and
                  Johana Coyote and
                  Manuel V{\'{e}}lez},
	title = {Channel phase processing in wireless networks for human activity recognition},
	journal = {Internet Things},
	volume = {24},
	pages = {100960},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100960},
	doi = {10.1016/J.IOT.2023.100960},
	timestamp = {Fri, 08 Mar 2024 13:22:13 +0100},
	biburl = {https://dblp.org/rec/journals/iot/DiazSELCV23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The phase of the channel state information (CSI) is underutilized as a source of information in wireless sensing due to its sensitivity to synchronization errors of the signal reception. A linear transformation of the phase is commonly applied to correct linear offsets and, in a few cases, some filtering in time or frequency is carried out to smooth the data. This paper presents a novel processing method of the CSI phase to improve the accuracy of human activity recognition (HAR) in indoor environments. This new method, coined Time Smoothing and Frequency Rebuild (TSFR), consists of performing a CSI phase sanitization method to remove phase impairments based on a linear regression transformation method, then a time domain filtering stage with a Savitzky–Golay (SG) filter for denoising purposes and, finally, the phase is rebuilt, eliminating distortions in frequency caused by SG filtering. The TSFR method has been tested on five datasets obtained from experimental measurements, using three different deep learning algorithms, and compared against five other types of CSI phase processing. The results show an accuracy improvement using TSFR in all the cases. Concretely, accuracy performance higher than 90% in most of the studied scenarios has been achieved with the proposed solution. In few-shot learning strategies, TSFR outperforms the state-of-the-art performance from 35% to 85%.}
}


@article{DBLP:journals/iot/IqbalNHB23,
	author = {Adeel Iqbal and
                  Ali Nauman and
                  Riaz Hussain and
                  Muhammad Bilal},
	title = {Cognitive {D2D} communication: {A} comprehensive survey, research
                  challenges, and future directions},
	journal = {Internet Things},
	volume = {24},
	pages = {100961},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100961},
	doi = {10.1016/J.IOT.2023.100961},
	timestamp = {Fri, 08 Mar 2024 13:22:13 +0100},
	biburl = {https://dblp.org/rec/journals/iot/IqbalNHB23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The integration of cognitive radio and device-to-device (D2D) communication gives rise to Cognitive D2D (cD2D) communication, which offers numerous advantages, such as improved spectrum and energy efficiency, increased network throughput, and enhanced coverage. Although there are existing survey papers on cognitive networks and D2D communications, the topic of integrated cD2D communication has received limited attention. To bridge this gap in the literature, this paper presents a comprehensive survey of cD2D communication. We commence by introducing cD2D communication and highlighting the key research challenges in this field. Subsequently, we categorize the recent advancements in cD2D communications into eight major types of techniques and provide an in-depth review of the existing literature. Furthermore, we address several significant challenges associated with cD2D communications and discuss future applications that can benefit from this technology. Through our analysis, we aim to contribute to a deeper understanding of cD2D communication and provide insights into its potential for various domains.}
}


@article{DBLP:journals/iot/BashirSAMFKE23,
	author = {Rab Nawaz Bashir and
                  Mahlaqa Saeed and
                  Mohammed Al{-}Sarem and
                  Rashiq Marie and
                  Muhammad Faheem and
                  Abdelrahman Elsharif Karrar and
                  Bahaeldein Elhussein},
	title = {Smart reference evapotranspiration using Internet of Things and hybrid
                  ensemble machine learning approach},
	journal = {Internet Things},
	volume = {24},
	pages = {100962},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100962},
	doi = {10.1016/J.IOT.2023.100962},
	timestamp = {Fri, 08 Mar 2024 13:22:13 +0100},
	biburl = {https://dblp.org/rec/journals/iot/BashirSAMFKE23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Reference Evapotranspiration (ET\no\n) is the cornerstone of efficient water utilization for sustainability in agriculture. The standard Penman–Montieth (PM) approach of Reference Evapotranspiration (ET\no\n), is complex due to the involvement of an extensive set of climatic conditions. The existing solutions of simplification of ET\no\npredictions are not in accordance with the Penman–Montieth approach. A hybrid ensemble machine learning approach for simplification of ET\no\nprediction is proposed using the Internet of Things(IoT) based crop field sensed climatic data. The proposed hybrid ensemble model is implemented with an Artificial Neural Network (ANN) and regression models. The proposed solution is unique for its utilization of flexible climatic conditions and in accordance with the standard Penman–Montieth (PM) approach. The proposed solution is able to predict daily ET\no\nfrom only temperature and also can adjust ET\no\naccording to wind speed, humidity, and sunshine duration. The assessment of the proposed model exhibits a high coefficient of determination (R2) of 0.94 compared to 0.91 from the basic ANN model. The proposed hybrid ensemble model also exhibits a low RMSE of 0.86, MAE of 0.75 mm day−1, and MAPE of 15.05%, compared to 0.91, 0.75 mm day−1, and 20.40% from the basic ANN model. The ET\no\npredictions by the proposed hybrid ensemble model also exhibit a higher Pearson correlation coefficient of 0.917 with the ET\no\nby the Penman–Montieth (PM) approach, compared to 0.778 by the basic ANN model. The statistics reveal the accuracy and goodness of fit of the proposed hybrid ensemble machine learning model.}
}


@article{DBLP:journals/iot/SaadYG23,
	author = {Abubakar Saad and
                  Penghan Yan and
                  Robson E. De Grande},
	title = {MDP-based connectivity and availability models for Internet of Vehicles},
	journal = {Internet Things},
	volume = {24},
	pages = {100963},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100963},
	doi = {10.1016/J.IOT.2023.100963},
	timestamp = {Sat, 13 Jan 2024 17:37:23 +0100},
	biburl = {https://dblp.org/rec/journals/iot/SaadYG23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Smart and connected vehicles have enabled a series of services and applications in intelligent transportation. Such vehicles introduce a new paradigm that supports the Internet of Vehicles, where content and resource sharing happens dynamically through Vehicle to Everything (V2X) communication. Communication technologies, such as vehicular and cellular networks, are expected to reliably support connections and mobile computing. However, due to challenges related to highly dynamic topologies in urban environments, the feasibility and reliability of vehicular communications in real urban environments have been discussed in recent works. In light of solving the issues that originated from unstable connectivity, we propose an MDP-based connectivity model which estimates link stability for data delivery. Moreover, from analyses, it was evident that the predictability of individual vehicle connectivity directly depends on the repeatability of its connection patterns. Consequently, we propose an availability model which identifies the suitability of connectivity status to determine the vehicles that provide high availability conditioned on their mobility.}
}


@article{DBLP:journals/iot/RuzNietoEPS23,
	author = {Andres Ruz{-}Nieto and
                  Esteban Egea{-}L{\'{o}}pez and
                  Jose Maria Molina Garcia Pardo and
                  Jos{\'{e}} Santa},
	title = {A 3D simulation framework with ray-tracing propagation for LoRaWAN
                  communication},
	journal = {Internet Things},
	volume = {24},
	pages = {100964},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100964},
	doi = {10.1016/J.IOT.2023.100964},
	timestamp = {Fri, 08 Mar 2024 13:22:13 +0100},
	biburl = {https://dblp.org/rec/journals/iot/RuzNietoEPS23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The adoption of Low-Power Wide-Area Networks (LP-WAN) for interconnecting remote wireless sensors has become a reality in smart scenarios, covering communications needs of large Internet of Things (IoT) deployments. The correct operation and expected performance of such network scenarios, which can range hundreds or thousands of nodes and tens of squared kilometres, should be assessed before carrying out the deployment to save installation and maintenance costs. Common network planning tools can help to roughly study potential coverage, but network simulation offers fine-grained information about network performance. Nevertheless, current simulation frameworks include limited propagation models based on statistical and empirical measurements that do not consider scenario particularities, such as terrain elevation, buildings or vegetation. This is critical in urban settings. In this line, this paper presents a simulation framework including a network simulator, a 3D engine and a ray-tracing tool, which models realistically the performance of Long-Range Wide-Area Network (LoRaWAN) communication technology. We have evaluated the performance of the solution taking as reference experimental campaigns in the city of Cartagena (Spain), comparing data obtained when simulating with the commonly employed propagation models such as Okumura–Hata or path loss. Results indicate that our framework, set-up with data from open geographical information systems, accurately fits experimental values, reporting improvements between 10% and 50% in the error committed when estimating signal strength in challenging urban streets with signal obstruction, as compared with the better performing classical model, Okumura–Hata.}
}


@article{DBLP:journals/iot/AmiriZarandiKD23,
	author = {Mohammad Amiri{-}Zarandi and
                  Hadis Karimipour and
                  Rozita A. Dara},
	title = {A federated and explainable approach for insider threat detection
                  in IoT},
	journal = {Internet Things},
	volume = {24},
	pages = {100965},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100965},
	doi = {10.1016/J.IOT.2023.100965},
	timestamp = {Sat, 13 Jan 2024 17:37:23 +0100},
	biburl = {https://dblp.org/rec/journals/iot/AmiriZarandiKD23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {An insider threat is a malicious action launched by authorized personnel inside the organization. Since insider actions may only leave a small digital footprint in the system, it is considered a major cybersecurity challenge in different applications. Along with the rapid growth of the Internet of Things (IoT) and the extensive attack surface in this technology, many concerns have been raised regarding the potential insider threats in IoT environments. Several studies have been conducted on Machine Learning (ML)-based insider threat detection solutions which are focused on the models’ performance while the trustability of these models is neglected. Trustworthy Learning refers to a new trend in ML that focuses on ways to ensure that the data collection and data analysis procedures in ML techniques follow ethical applications and are trustable to human users. This approach enforces the acceptance and successful adoption of ML-based solutions. This study aims to propose an improved trustworthy insider threat detection method that ensures two of the trustworthy learning requirements: Privacy and Explainability. The proposed solution protects the privacy of the utilized data and is capable of explaining why certain behaviors are detected as a threat. The proposed solution also leverages data collaboration between different data owners to increase the volume of data used in the training process and enhance the performance of the ML model. Experimental results show the proposed solution outperforms the learning models trained by individual data holders.}
}


@article{DBLP:journals/iot/DuyQKTP23,
	author = {Phan The Duy and
                  Nguyen Huu Quyen and
                  Nghi Hoang Khoa and
                  Dung Tran Tuan and
                  Van{-}Hau Pham},
	title = {FedChain-Hunter: {A} reliable and privacy-preserving aggregation for
                  federated threat hunting framework in SDN-based IIoT},
	journal = {Internet Things},
	volume = {24},
	pages = {100966},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100966},
	doi = {10.1016/J.IOT.2023.100966},
	timestamp = {Sat, 13 Jan 2024 17:37:23 +0100},
	biburl = {https://dblp.org/rec/journals/iot/DuyQKTP23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the development of the Industrial Internet of Things (IIoT), cyber threats and attacks have become major issues and concerns in Industry 4.0 due to the negative impacts on the infrastructures and services across organizations. Nevertheless, due to the issues in preserving privacy and transparency, there is a lack of threat intelligence sharing among parties, leading to the low performance in uncovering malicious actors. In fact, the method of gathering and exploiting such data has been getting more crucial in a trend of machine learning (ML) adoption in cybersecurity. In this scenario, Federated Learning (FL) can assume a significant role in constructing an ML-based threat hunting solution for IIoT networks. This can be achieved by harnessing data resources from diverse parties, utilizing a local training strategy that eliminates the need for centralized data collection. Hence, this paper proposes FedChain-Hunter, a blockchain and FL-based threat-hunting framework to mutually seek cyber threats while ensuring data privacy and the transparency in the contribution of data owners. Specifically, Software Defined Networking (SDN) with programmable and flexible security orchestration is used to easily monitor and gather appropriate security events in the IIoT network. In addition, the Fully Homomorphic Encryption (HE) and Differential Privacy (DP) are integrated into the FL scheme to provide strong security and privacy-preserving aggregation for each ML model update. Also, the blockchain adoption offers the transparency, auditability for collaboration and contribution management through a decentralized platform. The experimental results on 5 datasets indicate that FedChain-Hunter can achieve high performance for cyber threat detection with security, reliability, and privacy guarantee.}
}


@article{DBLP:journals/iot/AzaddelNSJA23,
	author = {Mohammad Hadi Azaddel and
                  Mohmmad Amin Nourian and
                  Komeil ShahHosseini and
                  Suhardi Azliy Junoh and
                  Ahmad Akbari},
	title = {{SPOTTER:} {A} novel asynchronous and independent WiFi and {BLE} fusion
                  method based on particle filter for indoor positioning},
	journal = {Internet Things},
	volume = {24},
	pages = {100967},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100967},
	doi = {10.1016/J.IOT.2023.100967},
	timestamp = {Sat, 13 Jan 2024 17:37:23 +0100},
	biburl = {https://dblp.org/rec/journals/iot/AzaddelNSJA23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Although global positioning system (GPS) has largely solved the problem of outdoor navigation, indoor positioning systems have remained a challenging problem over the last two decades. Sensor fusion has emerged as a state-of-the-art approach, utilizing various mobile phone sensors, particularly WiFi and Bluetooth low energy (BLE). An integrated method is crucial for achieving the best accuracy and the lowest energy consumption. This paper categorizes the different WiFi and BLE incorporation architectures based on signal scanning location and comprehensively investigates their influence. We propose a novel asynchronous and independent WiFi and BLE fusion method based on a particle filter (SPOTTER), which includes a new architecture and fusion algorithm. Unlike previous works, SPOTTER conducts WiFi signal scanning on WiFi access points. The fusion algorithm integrates the outcomes of independent WiFi and BLE subsystems as sensor data employing enhanced particle filtering to reduce localization error and latency. Experimental results demonstrate that SPOTTER outperforms fingerprint-based fusion approaches by 27% in terms of positioning rate and significantly reduces WiFi and BLE interferences. Extensive experiments, including using different architectures and BLE beacon numbers, confirm SPOTTER’s 35% improvement in accuracy and precision compared to fingerprint-based fusion.}
}


@article{DBLP:journals/iot/BrotsisGKMKLV23,
	author = {Sotirios Brotsis and
                  Konstantinos{-}Panagiotis Grammatikakis and
                  Dimitrios Kavallieros and
                  Antonio I. Mazilu and
                  Nicholas Kolokotronis and
                  Konstantinos Limniotis and
                  Costas Vassilakis},
	title = {Blockchain meets Internet of Things (IoT) forensics: {A} unified framework
                  for IoT ecosystems},
	journal = {Internet Things},
	volume = {24},
	pages = {100968},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100968},
	doi = {10.1016/J.IOT.2023.100968},
	timestamp = {Sat, 13 Jan 2024 17:37:23 +0100},
	biburl = {https://dblp.org/rec/journals/iot/BrotsisGKMKLV23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the continuously increasing number of security incidents targeting sensors, embedded devices, and other electronics appliances and systems that comprise the so-called Internet of things (IoT), the field of IoT forensics emerged as a branch of digital forensics focusing on the investigation of attacks in the IoT ecosystem. Digital evidence authenticity, integrity, confidentiality, and privacy are among the factors affecting the investigation process in IoT forensics, which can be addressed by employing the blockchain as the means not only for the preservation of digital evidence, but also for other steps of a digital forensics investigation process. The high-level goal of the paper is three-fold: to establish a holistic IoT forensics process as a reference point against which blockchain integration patterns and best practices will be identified in order to yield a robust, widely accepted and scalable architecture of the blockchain-enabled solution; to integrate the blockchain with the proposed IoT forensics process for addressing the above challenges; and to evaluate the overall solution highlighting improvements and potential performance bottlenecks. The proposed blockchain-enabled platform leverages multi-access edge computing and has been implemented with Hyperledger Fabric on an extensive virtualized testbed providing a realistic smart home environment. A thorough evaluation was conducted with real cyber-attacks generating digital evidence at high rates for testing the platform’s behavior at high load. The experimental results showed that the proposed platform achieved high throughput, excessively low latency, and zero error rate in the operation of the blockchain network.}
}


@article{DBLP:journals/iot/UmranLAN23,
	author = {Samir M. Umran and
                  Songfeng Lu and
                  Zaid Ameen Abduljabbar and
                  Vincent Omollo Nyangaresi},
	title = {Multi-chain blockchain based secure data-sharing framework for industrial
                  IoTs smart devices in petroleum industry},
	journal = {Internet Things},
	volume = {24},
	pages = {100969},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100969},
	doi = {10.1016/J.IOT.2023.100969},
	timestamp = {Mon, 05 Feb 2024 20:22:24 +0100},
	biburl = {https://dblp.org/rec/journals/iot/UmranLAN23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Industry 4.0 efficiently enhances the manufacturing process in many aspects such as increasing system performance, productivity, cost reduction, and building large-scale systems with enable autonomous operation. Numerous heterogeneous devices and sensors are connecting to the internet network through the utilization of revolutionary techniques that transfer the manufacturing paradigm to intelligent processes. The traditional schemes adopted centralized architectures and complex encryption algorithms that suffer from several cyber-security threats and latency making them unsuitable for resource-constrained IoTs devices. In our work, we proposed a decentralized, low-power consumption, fast, scalable, secure, privacy-preserving, and trusting architecture-based private blockchain network/smart contract and interplanetary file system for the petroleum industry in Iraq. Our scheme improves blockchain performance by adopting the incremental aggregator subsector commitment instated of Merkle tree and a multi-chain proof of rapid authentication as consensus algorithms, which are specially designed for industrial IoTs applications. It provides a high level of security authentication and privacy preservation, P2P communication, remote access, immutability, traceability, and information backtracking. In addition to addressing the blockchain storage limitation and eliminating third-party dependencies by adopting an interplanetary file system (IPFS). Also provides an efficient data encryption mechanism at the perceptual layer by adopting a lightweight encryption algorithm with internet friendly ARM Cortex-M33 Microcontroller as clear in the experimental results. Moreover, our architecture succeeds in merging blockchain technology, IoTs, and an IPFS with the petroleum industry as an industrial application area, and provides an efficient framework that resists common cyber-security attacks by achieving data integrity, availability, and confidentiality.}
}


@article{DBLP:journals/iot/ChenSZLWWX23,
	author = {Yi Chen and
                  Xianhao Shen and
                  Panfeng Zhang and
                  Shaofang Lu and
                  Li Wang and
                  Zhen Wu and
                  Xiaolan Xie},
	title = {Joint optimization of {UAV-WPT} and mixed task offloading strategies
                  with shared mode in SAG-PIoT: {A} {MAD4PG} approach},
	journal = {Internet Things},
	volume = {24},
	pages = {100970},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100970},
	doi = {10.1016/J.IOT.2023.100970},
	timestamp = {Wed, 03 Jan 2024 08:34:14 +0100},
	biburl = {https://dblp.org/rec/journals/iot/ChenSZLWWX23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Space-Air-Ground Power Internet of Things (SAG-PIoT) is a promising paradigm for the development of emerging smart grid systems, and Unmanned Aerial Vehicle (UAV) wireless power transmission (UAV-WPT) is also a promising technology. Utilizing UAV and satellites as aerial base stations to assist in PIoT communication and task offloading can solve problems such as limited SAG-PIoT network coverage, limited computing capabilities, and difficulties in energy acquisition, ensuring the safe and stable operation of SAG-PIoT. In this paper, we propose a mixed offloading strategy coexisting with partial offloading and binary offloading under the UAV-WPT assisted power supply and shared offloading mode, and integrate a multi-agent distributed deep deterministic policy gradient (MAD4PG) framework. The UAV-WPT and task offloading problem is formulated as a joint optimization problem, and the MAD4PG algorithm is utilized to find the optimal strategy in task offloading for resource allocation and energy supplementation. Finally, a simulation model is constructed based on the actual data from the Belgian power grid. Compared to the state-of-the-art, a large number of experimental results show that our proposed method has significant advantages. It reduces task completion latency by 18.93 % and lowers energy consumption by 28.14 %.}
}


@article{DBLP:journals/iot/YaziciZNYYMLE23,
	author = {Adnan Yazici and
                  Dana Zhumabekova and
                  Aidana Nurakhmetova and
                  Zhanggir Yergaliyev and
                  Hakan Yekta Yatbaz and
                  Zaida Makisheva and
                  Michael Lewis and
                  Enver Ever},
	title = {A smart e-health framework for monitoring the health of the elderly
                  and disabled},
	journal = {Internet Things},
	volume = {24},
	pages = {100971},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100971},
	doi = {10.1016/J.IOT.2023.100971},
	timestamp = {Sat, 13 Jan 2024 17:37:23 +0100},
	biburl = {https://dblp.org/rec/journals/iot/YaziciZNYYMLE23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The healthcare sector is experiencing a significant transformation due to the widespread adoption of IoT-based systems, especially in the care of elderly and disabled individuals who can now be monitored through portable and wearable devices. The widespread implementation of IoT-based systems in the healthcare sector holds immense potential for improving care and ensuring the well-being of vulnerable populations. In our paper, we introduce an e-health framework that utilizes real-time data from inertial, ECG, and video sensors to monitor the health and activities of these individuals. Our framework employs edge computing for efficient analysis and generates notifications based on data analysis while prioritizing privacy by activating multimedia sensors only when necessary. To achieve accurate results, we evaluated each component of our framework separately. Using the MHEALTH dataset, our proposed machine learning model achieves accuracies of 99.97% for inertial sensors’ human activity recognition (HAR) and 99.14% for ECG sensors. We also evaluated our first-level inconsistency detection-based anomaly proposal mechanism using one user’s data, demonstrating its proof-of-concept. Furthermore, our video-based HAR and fall detection module achieve an accuracy of 86.97% on the well-known DMLSmartActions dataset. We successfully deployed our proposed HAR model with inertial sensors in a controlled experimental environment, yielding promising results with an accuracy of 96% and an F1 score of 90.52%. These evaluations validate the effectiveness of our framework in monitoring the health and activities of elderly and disabled individuals.}
}


@article{DBLP:journals/iot/SaidiKTK23,
	author = {Abdessamad Saidi and
                  Mohamed Hadj Kacem and
                  Imen Tounsi and
                  Ahmed Hadj Kacem},
	title = {A formal approach to specify and verify Internet of Things architecture},
	journal = {Internet Things},
	volume = {24},
	pages = {100972},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100972},
	doi = {10.1016/J.IOT.2023.100972},
	timestamp = {Mon, 05 Feb 2024 20:22:24 +0100},
	biburl = {https://dblp.org/rec/journals/iot/SaidiKTK23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Internet of Things (IoT) aims to interconnect the physical world with the digital world, presenting complex challenges that require accurate models to ensure implementation accuracy and minimize errors. In this paper, we propose a general approach for modeling, specifying, and verifying Internet of Things architectures using the Unified Modeling Language (UML), the Event-B formal method, and the Rodin platform. We propose a model-to-text transformation that generates semi-automatic formal specifications from UML component diagrams profiled with IoT concepts and UML sequence diagrams. The resulting Event-B code allows for formal verification of system properties by employing the powerful model checker and animator tools within the Rodin platform. Additionally, we evaluate the effectiveness of various IoT patterns within our approach. Our results demonstrate the benefits of employing IoT patterns, including cost reduction related to software development. The proposed approach contributes to the development of reliable and efficient IoT systems by ensuring valid models and verifying system properties.}
}


@article{DBLP:journals/iot/TausifDUILLB23,
	author = {Muhammad Tausif and
                  Sania Dilshad and
                  Qasim Umer and
                  Muhammad Waseem Iqbal and
                  Zohaib Latif and
                  Choonhwa Lee and
                  Rab Nawaz Bashir},
	title = {Ensemble learning-based estimation of reference evapotranspiration
                  (ETo)},
	journal = {Internet Things},
	volume = {24},
	pages = {100973},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100973},
	doi = {10.1016/J.IOT.2023.100973},
	timestamp = {Sat, 13 Jan 2024 17:37:23 +0100},
	biburl = {https://dblp.org/rec/journals/iot/TausifDUILLB23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Reference Evapotranspiration (ET\no\n) is crucial and influential in irrigation water management. Precise ET\no\nrate estimation is vital for successful agriculture water management. There are numerous techniques for ET\no\nrate simulation, but machine learning (ML) and deep learning (DL) approaches are currently popular. This study proposes an ensemble learning-based model for ET\no\nrate estimation. The proposed model leverages minimum meteorological parameters, i.e., minimum temperature (\nT\nm\ni\nn\n), maximum temperature (\nT\nm\na\nx\n), relative humidity (\nR\nH\n), and mean wind speed (\nW\nS\n) as input features. The proposed model employs Random Forest Bagging and Gradient Boosting models as bagging and boosting ensemble techniques for the accurate ET\no\nrate estimation. The 10-fold cross-validation method is leveraged for the evaluation of the proposed model. The performance results of the proposed model are compared with the baseline model of ET\no\nestimation, i.e., the Food and Agriculture Organization Penman–Monteith (FAO-56 PM) and off-the-shelf deep learning models. The performance results indicate that Random Forest Bagging is significant as it yields Gradient Boosting and baseline models with 93.15% f-measure and reduces Root Mean Squared Error (RMSE) and Mean Absolute Error (MAE) by 17% and 10%, respectively.}
}


@article{DBLP:journals/iot/AcostaGarciaAGGF23,
	author = {Laura Acosta{-}Garcia and
                  Juan Aznar{-}Poveda and
                  Antonio{-}Javier Garc{\'{\i}}a{-}S{\'{a}}nchez and
                  Joan Garc{\'{\i}}a{-}Haro and
                  Thomas Fahringer},
	title = {Dynamic transmission policy for enhancing LoRa network performance:
                  {A} deep reinforcement learning approach},
	journal = {Internet Things},
	volume = {24},
	pages = {100974},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100974},
	doi = {10.1016/J.IOT.2023.100974},
	timestamp = {Fri, 08 Mar 2024 13:22:13 +0100},
	biburl = {https://dblp.org/rec/journals/iot/AcostaGarciaAGGF23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Long Range (LoRa) communications, operating through the LoRaWAN protocol, have received increasing attention from the low-power and wide-area network communities. Efficient energy consumption and reliable communication performance are critical aspects of LoRa-based applications. However, current scientific literature tends to focus on minimizing energy consumption while disregarding channel changes affecting communication performance. Other works attain appropriate communication performance without adequately considering energy expenditure. To fill this gap, we propose a novel solution to maximize the energy efficiency of devices while considering the desired network performance. This is done using a maximum allowed Bit Error Rate (BER) that can be specified by users and applications. We characterize this problem as a Markov Decision Process and solve it using Deep Reinforcement Learning to dynamically and quickly select the transmission parameters that jointly satisfy energy and performance requirements over time. Moreover, we support different payload sizes, ensuring suitability for applications with varying packet lengths. The proposed selection of parameters is evaluated in three different scenarios by comparing it with the traditional Adaptive Data Rate (ADR) mechanism of LoRaWAN. The first scenario involves static nodes with varying BER requirements. The second one realistically simulates urban environments with mobile nodes and fluctuating channel conditions. Finally, the third scenario studies the proposed solution under dynamic frame payload length variations. These scenarios cover a wide range of operational conditions to ensure a comprehensive evaluation. The results of our experiments demonstrate that our proposal achieves a 60% improvement in performance metrics over the default ADR mechanism.}
}


@article{DBLP:journals/iot/GuoCLQLHC23,
	author = {Wei Guo and
                  Jinkai Cui and
                  Xingzhou Li and
                  Lifeng Qu and
                  Hongjie Li and
                  Aiqian Hu and
                  Tianyi Cai},
	title = {MistNet: {A} superior edge-cloud privacy-preserving training framework
                  with one-shot communication},
	journal = {Internet Things},
	volume = {24},
	pages = {100975},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100975},
	doi = {10.1016/J.IOT.2023.100975},
	timestamp = {Wed, 03 Jan 2024 08:34:14 +0100},
	biburl = {https://dblp.org/rec/journals/iot/GuoCLQLHC23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Classical federated learning methods aggregate decentralized data from different devices into a central location for efficient training. However, these approaches raise significant concerns regarding data privacy and requires extensive communication between edge devices and the cloud, leading to high communication costs. To conquer these challenges, we propose an edge-cloud privacy-preserving model training system that enables the cloud and edge devices to collaboratively perform deep neural network(DNN) training, namely MistNet, which has the following advantages. (1) Different from previous works that required frequent communication between the edge and cloud, MistNet requires only one-shot communication. (2) MistNet introduces the rigorous local differential privacy (LDP) technique to the intermediate feature maps, guaranteeing that the user’s local data and model parameters remain undisclosed. (3) In MistNet, the feature extractor is transferred from pre-trained models that are designed for similar application domains. This feature extractor remains fixed during training, thereby eliminating the requirement to synchronize feature extractors across different devices. Furthermore, we first design an object detection algorithm based on Yolov5 with the MistNet framework. Finally, the extensive experiments results on multiple models and datasets demonstrate that by choosing an appropriate partition layer and privacy budget, MistNet achieves lower communication and faster convergence, as well as acceptable model utility while greatly reducing privacy leakage from the released intermediate features. Our framework is primarily designed for image data and has already been applied to Plato. You can find the source code on GitHub page at\nhttps://github.com/TL-System/plato\n.}
}


@article{DBLP:journals/iot/SaiyedA23,
	author = {Makhduma Saiyed and
                  Irfan S. Al{-}Anbagi},
	title = {Flow and unified information-based DDoS attack detection system for
                  multi-topology IoT networks},
	journal = {Internet Things},
	volume = {24},
	pages = {100976},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100976},
	doi = {10.1016/J.IOT.2023.100976},
	timestamp = {Sat, 13 Jan 2024 17:37:23 +0100},
	biburl = {https://dblp.org/rec/journals/iot/SaiyedA23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Internet of Things (IoT) networks are vulnerable to Distributed Denial of Service (DDoS) attacks, which can degrade their Quality of Service (QoS). In general, DDoS attacks are classified into high- and low-volume attacks. Existing statistical-based methods for DDoS attack detection in IoT networks are effective only for high-volume or low-volume attacks, but not for both. The majority of research in this domain relies on single-dimensional analysis and static thresholds. In response to these limitations, this paper introduces a Flow and Unified Information-based DDoS (FLUID) attack detection system, a lightweight statistical approach, for DDoS attack detection in IoT networks. The FLUID system incorporates multi-dimensional analysis by integrating unified information and flow behavior to effectively identify both high- and low-volume DDoS attacks. FLUID utilizes entropy and distance metrics, such as Kullback–Leibler (KL) divergence and greedy bin-packing, as unified information measures to distinguish legitimate traffic from malicious activity. Additionally, it examines flow behavior to gain insights into network traffic patterns. Notably, the FLUID system maintains its lightweight nature through a streamlined set of network features and optimized computational efficiency. Evaluations on real-world IoT client/server and Event-Driven Architecture (EDA) testbeds with the ToN-IoT, CICIDS 2017, CICIDS 2019, and DoS/DDoS-MQTT-IoT datasets show that the FLUID system can achieve over 90% detection accuracy for both high- and low-volume DDoS attacks.}
}


@article{DBLP:journals/iot/GaberATAHL23,
	author = {Tarek Gaber and
                  Joseph Bamidele Awotunde and
                  Mohamed Torky and
                  Sunday Adeola Ajagbe and
                  Mohammad Hammoudeh and
                  Wei Li},
	title = {Metaverse-IDS: Deep learning-based intrusion detection system for
                  Metaverse-IoT networks},
	journal = {Internet Things},
	volume = {24},
	pages = {100977},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100977},
	doi = {10.1016/J.IOT.2023.100977},
	timestamp = {Fri, 08 Mar 2024 13:22:13 +0100},
	biburl = {https://dblp.org/rec/journals/iot/GaberATAHL23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Combining the metaverse and the Internet of Things (IoT) will lead to the development of diverse, virtual, and more advanced networks in the future. The integration of IoT networks with the metaverse will enable more meaningful connections between the 'real' and 'virtual' worlds, allowing for real-time data analysis, access, and processing. However, these metaverse-IoT networks will face numerous security and privacy threats. Intrusion Detection Systems (IDS) offer an effective means of early detection for such attacks. Nevertheless, the metaverse generates substantial volumes of data due to its interactive nature and the multitude of user interactions within virtual environments, posing a computational challenge for building an intrusion detection system. To address this challenge, this paper introduces an innovative intrusion detection system model based on deep learning. This model aims to detect most attacks targeting metaverse-IoT communications and combines two techniques: KPCA (Kernel Principal Component Analysis which was used for attack feature extraction and CNN (Convolutional Neural Networks for attack recognition and classification. The efficiency of this proposed IDS model is assessed using two widely recognized benchmark datasets, BoT-IoT and ToN-IoT, which contain various IoT attacks potentially targeting IoT communications. Experimental results confirmed the effectiveness of the proposed IDS model in identifying 12 classes of attacks relevant to metaverse-IoT, achieving a remarkable accuracy of\n99.8\n%\nand a False Negative Rate FNR less than\n0.2\n. Furthermore, when compared with other models in the literature, our IDS model demonstrates superior performance in attack detection accuracy.}
}


@article{DBLP:journals/iot/MishraCSB23,
	author = {Sushruta Mishra and
                  Soham Chakraborty and
                  Kshira Sagar Sahoo and
                  Muhammad Bilal},
	title = {Cogni-Sec: {A} secure cognitive enabled distributed reinforcement
                  learning model for medical cyber-physical system},
	journal = {Internet Things},
	volume = {24},
	pages = {100978},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100978},
	doi = {10.1016/J.IOT.2023.100978},
	timestamp = {Fri, 08 Mar 2024 13:22:13 +0100},
	biburl = {https://dblp.org/rec/journals/iot/MishraCSB23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The advent of the Internet of Things (IoT) has resulted in significant technical development in the healthcare sector, enabling the establishment of Medical Cyber–Physical Systems (MCPS). The increased number of MCPS generates a massive amount of privacy-sensitive data, hence it is important to enhance the security of devices and data transmission in MCPS. Earlier several research studies were undertaken in order to enhance security in healthcare, but none of them could adapt to changing behaviors of data attacks. Here the role of blockchain and Reinforcement Learning (RL) comes into play since it can adjust itself to the nature of changing attacks, thus preventing any kind of attacks. This work proposes a solution, named Cogni-Sec, which employs a decentralized cognitive blockchain and Reinforcement Learning architecture and addresses the security issue. Blockchain is incorporated in the approach for data storage and transmission to increase the degree of security in the MCPS modules. Hyperledger Fabric is applied as the blockchain base which shows transaction query results with nearly 10% increased throughput, 69% less memory consumption, and 15% lower CPU usage when compared to Ethereum. Further security risk at the block mining level within a blockchain network is reduced by introducing distributed Reinforcement Learning architecture in replacement for the miner nodes, which imitates the cognitive behavior of miners in a distributed environment. Different multi-agent learning systems have been evaluated for building the mining agent. Among these, the a3c agent in distributed learning setup yields the optimum cumulative reward with a median value of 54.5 and minimizes the maximum number of data threats.}
}


@article{DBLP:journals/iot/ZhuGZWJCO23,
	author = {Renjie Zhu and
                  Xin Guan and
                  Jun Zheng and
                  Ning Wang and
                  Haiyang Jiang and
                  Chen Cui and
                  Tomoaki Ohtsuki},
	title = {{DRL} based low carbon economic dispatch by considering power transmission
                  safety limitations in internet of energy},
	journal = {Internet Things},
	volume = {24},
	pages = {100979},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100979},
	doi = {10.1016/J.IOT.2023.100979},
	timestamp = {Sat, 13 Jan 2024 17:37:23 +0100},
	biburl = {https://dblp.org/rec/journals/iot/ZhuGZWJCO23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Economic dispatch, as a crucial method for ensuring the normal operation of power systems, is typically modeled as an optimization problem and solved using solvers. The introduction of low-carbon requirements has increased the complexity of the optimization problem, as economic dispatch now needs to consider effectively reducing the emission of . The utilization of renewable energy can mitigate carbon emissions during power system operation, but its inherent uncertainty poses safety risks to transmission lines between microgrids and the main grid. Hence, this paper explores the issue of low-carbon economic dispatch to ensure the reliability of power transmission. We introduce a two-stage low-carbon economic dispatch model grounded in deep reinforcement learning. In the first stage, we incorporate the transmission power limits between microgrids and the main grid as constraints, generate day-ahead dispatch strategies, and determine the weights of factors in the reward function. In the second stage, we employ two methods: adjusting the weight of the penalty for exceeding the transmission limits and adding conservative safety limit constraints, to solve the problem of transmission power exceeding limits caused by uncertainties of renewable energy and prediction errors. Three deep reinforcement learning algorithms, all rooted in the Actor–Critic structure, are employed to implement the two-stage economic dispatch model. Experimental results affirm the efficacy of the proposed model in mitigating the risk of transmission power exceeding its limit, reducing carbon emissions, and minimizing operational costs.}
}


@article{DBLP:journals/iot/GuanWCW23,
	author = {Zheng Guan and
                  Zengwen Wang and
                  Yu Cai and
                  Xue Wang},
	title = {Deep reinforcement learning based efficient access scheduling algorithm
                  with an adaptive number of devices for federated learning IoT systems},
	journal = {Internet Things},
	volume = {24},
	pages = {100980},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100980},
	doi = {10.1016/J.IOT.2023.100980},
	timestamp = {Sat, 13 Jan 2024 17:37:23 +0100},
	biburl = {https://dblp.org/rec/journals/iot/GuanWCW23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the widespread application of Internet of Things (IoT), its energy consumption is becoming a major concern. Federated Learning (FL) allows multiple low-power devices to collaboratively learn a shared model, which reduces the energy consumption of IoT systems. However, FL involves highly varied data structures and require large amounts of communication. The communication efficiency greatly affects the system performance. In this paper, we optimize communication efficiency in the device access layer. Considering the instability of IoT device network connections, we propose a Deep Reinforcement Learning (DRL) based Efficient Access Scheduling Algorithm (DRL-EASA). It can adapt to changes in IoT device numbers and densities and thus applicable to instantaneous dynamic FL IoT systems. In scale-changed scenarios, DRL-EASA constructs geospatial-oriented state spaces and utilizes learning algorithm to train access scheduling strategies, effectively decoupling device numbers from the algorithm’s network structure. Firstly, the geographic region is divided into grids and the User State Information (USI) is mapped into fixed-dimensional Geographic State Information Vectors (GSIV). Secondly, a Convolutional Neural Network (CNN) is used as an agent to extract interference feature information from GSIV, and the Proximal Policy Optimization (PPO) algorithm is utilized to train the agent. Finally, a random algorithm is employed to assist DRL in generating scheduling decisions, enhancing the algorithm’s generalization performance in high device density scenarios. Numerical results show that our approach optimizes access scheduling strategies for both uplink and downlink and demonstrates effective adaptability to dynamically changing device numbers and exhibits strong generalization performance across various device densities.}
}


@article{DBLP:journals/iot/TerneroMEEM23,
	author = {Juan A. Ternero and
                  Vicente Mayor and
                  Rafael Estepa and
                  Antonio Jose Estepa and
                  Germ{\'{a}}n Madinabeitia},
	title = {Minimizing energy consumption in 802.15.4 IoT devices with multilevel
                  xRPL (MxRPL)},
	journal = {Internet Things},
	volume = {24},
	pages = {100981},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100981},
	doi = {10.1016/J.IOT.2023.100981},
	timestamp = {Fri, 26 Jan 2024 07:57:16 +0100},
	biburl = {https://dblp.org/rec/journals/iot/TerneroMEEM23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {IoT devices using IEEE 802.15.4 radio links may offer adaptable transmit power. But, since transmit power determines coverage, the problem of choosing the optimal tx power for each node is intertwined with the routing problem.}
}


@article{DBLP:journals/iot/TajIKDMA23,
	author = {Soonh Taj and
                  Ali Shariq Imran and
                  Zenun Kastrati and
                  Sher Muhammad Daudpota and
                  Raheel Ahmed Memon and
                  Javed Ahmed},
	title = {IoT-based supply chain management: {A} systematic literature review},
	journal = {Internet Things},
	volume = {24},
	pages = {100982},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100982},
	doi = {10.1016/J.IOT.2023.100982},
	timestamp = {Fri, 08 Mar 2024 13:22:13 +0100},
	biburl = {https://dblp.org/rec/journals/iot/TajIKDMA23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Supply Chain Management (SCM) consists of handling and optimizing all the facets of the supply chain process of goods and services. Modern SCM is reaping the benefits from the emerging and growing Internet of Things (IoT) field. IoT technology can automate and digitalize the supply chain processes to get maximum operational efficiencies by reducing operating costs. The mass proliferation of IoT devices has revolutionized supply chains. IoT devices in the supply chain process track and trace shipments using the latest real-time monitoring technologies, including GPS. IoT devices are also used for asset management using NFC technology and RFID tags. Overall, IoT devices are used in almost every stage of the supply chain process. Research on IoT-based SCM is still in the growing phase. A lot of technical work is currently being published on IoT-based SCM, but a few Systematic Literature Reviews (SLRs) have been found for IoT-based SCM. The holistic view of IoT-based SCM with detailed analysis is still not reported in any review. This paper addresses this knowledge gap by presenting an SLR on IoT-based SCM with a detailed analysis of IoT-based SCM from 2018 to 2022. This review covers the aspects of IoT-based SCM, such as application domains, technologies, sensors, and devices used to implement IoT-based SCM systems. The SLR findings will assist future researchers and practitioners interested in IoT-based SCM by offering an in-depth study of the literature on IoT-based SCM, including helpful insights on challenges, benefits, and economic and business implications.}
}


@article{DBLP:journals/iot/AlAwami23,
	author = {Louai Al{-}Awami},
	title = {Edge deduplication for LoRaWAN using network coding},
	journal = {Internet Things},
	volume = {24},
	pages = {100983},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100983},
	doi = {10.1016/J.IOT.2023.100983},
	timestamp = {Sat, 13 Jan 2024 17:37:24 +0100},
	biburl = {https://dblp.org/rec/journals/iot/AlAwami23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {LoRaWAN is a promising access technology for LPWAN IoT applications. However, the scalability of LoRaWAN has been debated due to its ALOHA-like media access mechanism. While using multiple gateways in the network can improve scalability, it may result in huge increase in traffic. This study presents a novel scheme to improve LoRaWAN scalability when multiple gateways are used without incurring excess backhaul traffic. The proposed scheme uses interflow network coding to encode traffic moving from gateways to network servers. The performance of the proposed scheme is evaluated via simulations. The results show that tremendous bandwidth savings can be achieved using the proposed scheme while allowing deploying more gateways to improve network scalability.}
}


@article{DBLP:journals/iot/MershadC23,
	author = {Khaleel Mershad and
                  Omar Cheikhrouhou},
	title = {Lightweight blockchain solutions: Taxonomy, research progress, and
                  comprehensive review},
	journal = {Internet Things},
	volume = {24},
	pages = {100984},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100984},
	doi = {10.1016/J.IOT.2023.100984},
	timestamp = {Sat, 13 Jan 2024 17:37:24 +0100},
	biburl = {https://dblp.org/rec/journals/iot/MershadC23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The proliferation of resource-constrained devices has become prevalent across various digital applications, including smart homes, smart healthcare, and smart transportation, among others. However, the integration of these devices brings many security issues. To address these concerns, Blockchain technology has been widely adopted due to its robust security characteristics, including immutability, cryptography, and distributed consensus. However, implementing blockchain within these networks is highly challenging due to the limited resources of the employed devices and the resource-intensive requirements of the blockchain. To overcome these challenges, a multitude of researchers have proposed lightweight blockchain solutions specifically designed for resource-constrained networks. In this paper, we present a taxonomy of lightweight blockchain solutions proposed in the literature. More precisely, we identify five areas within the “lightweight” concept, namely, blockchain architecture, device authentication, cryptography model, consensus algorithm, and storage method. We discuss the various methods employed in each “lightweight” category, highlighting existing gaps and identifying areas for improvement. Our review highlights the missing points in existing systems and paves the way to building a complete lightweight blockchain solution for networks of resource-constrained devices.}
}


@article{DBLP:journals/iot/ZhangLTZGS23,
	author = {Sitong Zhang and
                  Yibing Li and
                  Yuan Tian and
                  Zitao Zhou and
                  Xiaoyu Geng and
                  Tuo Shi},
	title = {Dynamic redeployment of {UAV} base stations in large-scale and unreliable
                  environments},
	journal = {Internet Things},
	volume = {24},
	pages = {100985},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100985},
	doi = {10.1016/J.IOT.2023.100985},
	timestamp = {Mon, 05 Feb 2024 20:22:24 +0100},
	biburl = {https://dblp.org/rec/journals/iot/ZhangLTZGS23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The deployment of Unmanned Aerial Vehicles (UAVs) as aerial base stations (UAV-BSs) has emerged as a promising solution to enhance communication services provided to ground users. However, deploying UAV-BSs faces challenges including the cooperation of multiple UAVs, dynamic user distribution, low-reliability issues of UAVs, and efficient redeployment in large environments. Existing literature addresses some of these challenges but lacks a comprehensive approach. In this paper, we investigate all these challenges and propose a novel deployment framework with the objective of maximizing the quality of communication service by dynamically deploying UAV-BSs. The proposed framework employs a decentralized approach, allowing UAV-BSs to locally adjust their locations and rapidly respond to changes, thus ensuring stable and efficient service supply to ground users. In addition, we implement multiple simulation experiments to evaluate the performance of the proposed framework in solving the UAV-BSs redeployment problem in large and dynamic environments. The results demonstrate its ability to effectively improve the quality of communication services.}
}


@article{DBLP:journals/iot/NaumanAANADAK23,
	author = {Ali Nauman and
                  Nuha Alruwais and
                  Eatedal Alabdulkreem and
                  Nadhem Nemri and
                  Nojood O. Aljehane and
                  Ashit Kumar Dutta and
                  Mohammed Assiri and
                  Wali Ullah Khan},
	title = {Empowering smart cities: High-altitude platforms based Mobile Edge
                  Computing and Wireless Power Transfer for efficient IoT data processing},
	journal = {Internet Things},
	volume = {24},
	pages = {100986},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100986},
	doi = {10.1016/J.IOT.2023.100986},
	timestamp = {Tue, 07 May 2024 20:25:59 +0200},
	biburl = {https://dblp.org/rec/journals/iot/NaumanAANADAK23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This work presents an efficient framework that combines High Altitude Platform (HAP)-based Mobile Edge Computing (MEC) networks with Wireless Power Transfer (WPT) to optimize resource allocation and task offloading. With the proliferation of smart sensor nodes (IoT) generating real-time data, there is a pressing need to overcome device limitations, including finite battery life and computational resources. Our proposed framework leverages HAP-based MEC servers, offering on-demand computation and communication resources without extensive physical infrastructure. Additionally, WPT, through terrestrial networks, addresses IoT device battery constraints by enabling energy harvesting from nearby access points. The primary focus is joint optimization, aiming to maximize computing bits while minimizing energy consumption under system constraints. Given the optimization problem’s complexity, we employ a decomposition approach, breaking it into sub-problems. The first part handles mode selection and task segmentation, determining optimal placement and mode selection variables. The second part addresses resource allocation, optimizing transmission power, offloading time, energy harvesting time, and device computational resources. Numerical results demonstrate the framework’s effectiveness compared to relevant benchmark schemes. This approach holds promise for enhancing IoT device performance and energy efficiency in smart city applications.}
}


@article{DBLP:journals/iot/FanDGXZWS23,
	author = {Haonan Fan and
                  Qin Dong and
                  Naixuan Guo and
                  Jun Xue and
                  Rongrong Zhang and
                  Haobo Wang and
                  Mingfeng Shi},
	title = {Raspberry Pi-based design of intelligent household classified garbage
                  bin},
	journal = {Internet Things},
	volume = {24},
	pages = {100987},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100987},
	doi = {10.1016/J.IOT.2023.100987},
	timestamp = {Sat, 13 Jan 2024 17:37:24 +0100},
	biburl = {https://dblp.org/rec/journals/iot/FanDGXZWS23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Until now, waste pollution is a global problem. The first and foremost part of the solution is waste classification, as it can effectively reduce the output of waste, so it is particularly important to classify household garbage in the household. However, classification of household garbage is a difficult task for people, and there are not enough designs and researches on automatic garbage classification bins at home. In this study, we designed and built a light and convenient intelligent garbage bin using devices such as motors, turn plates and a camera for classifying household garbage. Compared with the traditional garbage classification methods, two improvements in the algorithm are made, including the combination of the EfficientNetB2 model with the parallel mixed-attention mechanism and the design of the background noise removal algorithm. Finally, the algorithm is disposed to the Raspberry Pi to compose the complete classification system. The accuracy of this classification system in the test set was 93.38% and the results show that this bin can effectively distinguish recyclable waste, kitchen waste, hazardous waste and other waste, and is suitable for daily life garbage identification at home.}
}


@article{DBLP:journals/iot/AimarettoD23a,
	author = {Lucas Aimaretto and
                  Diego Dujovne},
	title = {Enhancing end-to-end determinism and reliability in 6TiSCH networks
                  with disjoint leaf-based MPLS-like tunnels},
	journal = {Internet Things},
	volume = {24},
	pages = {100988},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100988},
	doi = {10.1016/J.IOT.2023.100988},
	timestamp = {Sat, 13 Jan 2024 17:37:24 +0100},
	biburl = {https://dblp.org/rec/journals/iot/AimarettoD23a.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Industrial multi-hop Internet of Things (IIoT) have strict reliability requirements and they are expected to have deterministic behavior. Reliability is associated with the network’s ability to provide the best goodput possible to the destination from the source application, while deterministic behavior implies that the packets must also arrive at the destination before the maximum allowable deadline defined by the application expires. Although a relevant number of proposals have arisen in recent years, none of them achieve both restrictions simultaneously. In this work, we propose a cross-layer approach to solve this problem, by combining three strategies: (i) the use of the preferred parents (PP) and alternative parents (AP) together with the PRE (Packet Replication and Elimination) technique at the routing level; (ii) the use of MPLS tunnels from the leafNode, improving the Data Plane, to control the energy consumption and (iii) the use of the BDPC (Bounded Delay Packet Control) algorithm. The combination of the former strategies show that the behavior of the packet flows improves the end-to-end Packet Delivery Rate of the packets arriving before the deadline by 2.04 times with respect to standard Minimum Scheduling Function reference network while simultaneously increasing the minimum average network lifetime by 1.5 times, with respect to the hop by hop uncontrolled usage of PRE.}
}


@article{DBLP:journals/iot/BlancoRVLF23,
	author = {Carlos Blanco and
                  David Garcia Rosado and
                  {\'{A}}ngel Jes{\'{u}}s Varela{-}Vaca and
                  Mar{\'{\i}}a Teresa G{\'{o}}mez{-}L{\'{o}}pez and
                  Eduardo Fern{\'{a}}ndez{-}Medina},
	title = {Onto-CARMEN: Ontology-driven approach for Cyber-Physical System Security
                  Requirements meta-modelling and reasoning},
	journal = {Internet Things},
	volume = {24},
	pages = {100989},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100989},
	doi = {10.1016/J.IOT.2023.100989},
	timestamp = {Fri, 08 Mar 2024 13:22:13 +0100},
	biburl = {https://dblp.org/rec/journals/iot/BlancoRVLF23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the last years, Cyber–physical systems (CPS) have attracted substantial mainstream, especially in the industrial sector, since they have become the focus of cyber-attacks. CPS are complex systems that encompass a great variety of hardware and software components with a countless number of configurations and features. For this reason, the construction, validation, and diagnosis of security in CPS become a major challenge. An invalid security requirement for the CPS can produce partial or incomplete configuration, even misconfigurations, and hence catastrophic consequences. Therefore, it is crucial to ensure the validation of the security requirements specification from the earlier design stages. To this end, Onto-CARMEN is proposed, a semantic approach that enables the automatic verification and diagnosis of security requirements according to the ENISA and OWASP recommendations. Our approach provides a mechanism for the specification of security requirements on top of ontologies, and automatic diagnosis through semantic axioms and SPARQL rules. The approach has been validated using security requirements from a real case study.}
}


@article{DBLP:journals/iot/MoradbeikieKRPL23,
	author = {Azin Moradbeikie and
                  Ahmad Keshavarz and
                  Habib Rostami and
                  Sara Paiva and
                  S{\'{e}}rgio Ivan Lopes},
	title = {A cost-effective LoRaWAN-based IoT localization method using fixed
                  reference nodes and dual-slope path-loss modeling},
	journal = {Internet Things},
	volume = {24},
	pages = {100990},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100990},
	doi = {10.1016/J.IOT.2023.100990},
	timestamp = {Fri, 26 Jan 2024 07:57:16 +0100},
	biburl = {https://dblp.org/rec/journals/iot/MoradbeikieKRPL23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recently, RSSI-based localization has gained popularity for outdoor localization within the IoT ecosystem due to its cost-effectiveness, low-power and low-cost deployment, and ability to operate loT nodes for years on a single battery. However, this approach typically sacrifices accuracy, resulting in location estimates in the tens or hundreds of meters. For example, LoRaWAN communications have been widely used in IoT applications, being an attractive solution due to their long-range coverage, low implementation cost, and higher autonomy. However, RSSI-based LoRaWAN location methods suffer from multipath and fading interference which results in the near-far problem, impacting ranging accuracy for short and long distances, and thus leading to an overall decrease in the localization accuracy. In this article, we address the low accuracy of RSSI based localization challenge for outdoor IoT node localization by computing the Path Loss (PL) parameters of LoRaWAN, for short and long distances separately, thus providing a dual-slope PL model. In addition, some IoT nodes in specific locations are adopted as Reference Nodes (RNs), whose main task is to estimate the interference effect on the transmitted signals dynamically. The proposed model has been evaluated using a publicly available LoRaWAN dataset collected in urban areas in the city of Antwerp, Belgium, which serves as a benchmark for the evaluation of the results. Its effectiveness is assessed by simulation and comparison to the state-of-the-art. In addition, results are compared with the derived Cramer–Rao Lower Bound (CRLB). The localization error achieves a median error of 117 m and a mean error of 236 m.}
}


@article{DBLP:journals/iot/BisantiMMPS23,
	author = {Giovanni Marco Bisanti and
                  Luca Mainetti and
                  Teodoro Montanaro and
                  Luigi Patrono and
                  Ilaria Sergi},
	title = {Digital twins for aircraft maintenance and operation: {A} systematic
                  literature review and an IoT-enabled modular architecture},
	journal = {Internet Things},
	volume = {24},
	pages = {100991},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100991},
	doi = {10.1016/J.IOT.2023.100991},
	timestamp = {Fri, 08 Mar 2024 13:22:13 +0100},
	biburl = {https://dblp.org/rec/journals/iot/BisantiMMPS23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Thanks to the rapid growth of the Industry 4.0 domain and the innovations brought by the Internet of Things paradigm, Digital Twins (DT) are increasingly gaining momentum in our society and various companies are moving towards their adoption in many application areas. One of them is the aerospace sector which has started to take advantage of their innovative services to enhance workers’ daily duties. Although different works already proposed solutions to apply the Digital Twin to the industrial domain, the airspace area has not yet completely benefited from its advantages. Digital Twins carve out an important role in the entire aircraft lifecycle management, in particular they provide value in the maintenance process by gathering status information for optimizing aircraft operations. This article aims to comprehensively analyse, by applying the systematic mapping method, the current state of the art on Digital Twin technology applied to aircraft operation and maintenance. The results give an overview about the innovations that the Digital Twins can bring in the specific current state of the art, by highlighting the modelling approach used for building the DT, and the most important extracted common information related to the most frequently adopted tools and the covered subsystems. As a further important contribution to the research community, this work provides a comprehensive modular architecture that acts as a summarizing artifact able to serve all the analysed works and discusses the open issues by pointing out some interesting research directions, that could lead to new and interesting future works and collaborations.}
}


@article{DBLP:journals/iot/NakamuraET23,
	author = {Shigenari Nakamura and
                  Tomoya Enokido and
                  Makoto Takizawa},
	title = {Assessment of energy consumption for information flow control protocols
                  in IoT devices},
	journal = {Internet Things},
	volume = {24},
	pages = {100992},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100992},
	doi = {10.1016/J.IOT.2023.100992},
	timestamp = {Sat, 13 Jan 2024 17:37:24 +0100},
	biburl = {https://dblp.org/rec/journals/iot/NakamuraET23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the IoT (Internet of Things), millions of devices are interconnected and devices support too poor computation resources to install enough security functions to protect from malicious accesses. Hence, devices have to be supported with access control mechanisms. The CBAC (Capability-Based Access Control) model is most useful to be as access control model for IoT devices because it is sufficient for each device to just check the capability of each access request. However, illegal and late information flows among devices and subjects occur. Types of IFC (Information Flow Control) protocols like the OI and TBOI protocols to prevent illegal and late types of information flows are proposed in our previous studies. A secure device supports the CBAC model and the IFC protocols. First, an EC (Energy Consumption) model is proposed to show how a secure device consumes the electric energy in this paper. By using the EC model, the IFC protocols are evaluated in terms of the energy consumed by secure devices. A secure device mostly consumes energy to check capability tokens of each access request. In the simulation, the energy consumed by secure devices to process access requests can be reduced by selecting only tokens required. About 69% and 73% of energy in the OI and TBOI protocols can be reduced by adopting the CTS (Capability Token Selection) algorithms, respectively.}
}


@article{DBLP:journals/iot/VitaleVMB23,
	author = {Francesco Vitale and
                  Fabrizio De Vita and
                  Nicola Mazzocca and
                  Dario Bruneo},
	title = {A Process Mining-based unsupervised Anomaly Detection technique for
                  the Industrial Internet of Things},
	journal = {Internet Things},
	volume = {24},
	pages = {100993},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100993},
	doi = {10.1016/J.IOT.2023.100993},
	timestamp = {Tue, 07 May 2024 20:25:58 +0200},
	biburl = {https://dblp.org/rec/journals/iot/VitaleVMB23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Industrial Internet of Things (IIoT) applications in Industry 4.0 collect and process Time Series (TS) originating from heterogeneous sources. Many data-driven techniques have been proposed over the years for unsupervised collective Anomaly Detection (AD) to detect anomalous TS and improve quality of service. These techniques build statistical and/or behavioral models through data-driven algorithms often based on machine and deep learning. However, these algorithms may have black-box behavior, may require too much computational effort, and may not be trustworthy. In order to address these challenges, this paper proposes and evaluates an unsupervised AD technique that pre-processes noisy and complex TS and detects anomalous patterns. Pre-processing handles TS complexity through Feature Extraction and Dimensionality Reduction based on Autoencoders (AEs), whereas anomalous patterns are classified through Process Mining (PM), which unsupervisedly captures TS patterns and compares unknown behavior to such patterns for collective AD. We apply the technique to a scale replica of an assembly plant adopted in a smart automotive factory to evaluate our technique with respect to several configurations to analyze their impact on both detection and timing performance. Our contribution improves and extends the existing state-of-the-art work in the literature regarding the application of PM to IIoT for collective AD in TS. Moreover, it compares the obtained results with a baseline approach based on AEs.}
}


@article{DBLP:journals/iot/BoujelbenBAE23,
	author = {Manel Boujelben and
                  Zeineb Benmessaoud and
                  Mohamed Abid and
                  Manel Elleuchi},
	title = {An efficient system for water leak detection and localization based
                  on IoT and lightweight deep learning},
	journal = {Internet Things},
	volume = {24},
	pages = {100995},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100995},
	doi = {10.1016/J.IOT.2023.100995},
	timestamp = {Wed, 03 Jan 2024 08:34:14 +0100},
	biburl = {https://dblp.org/rec/journals/iot/BoujelbenBAE23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Nowadays, Water Distribution Networks (WDNs) efficiency is limited due to leakage issues, which result in large water losses that exceed about one third of the input volume. Considering the problems of growing population and water scarcity especially in Africa and Asia continents, an urgent humanitarian need arisen to efficiently detect and localize pipeline water leaks. To address this need, this paper proposes an end-to-end system for leak detection and localization in water pipelines based on IoT and deep learning. The IoT solution is deployed allowing real time monitoring of pipelines by using non-invasive IoT devices equipped with acoustic sensors which are installed on the pipeline surface. A lightweight one-Dimensional Convolutional Neural Network (1D-CNN) classification model is embedded on these devices to detect leaks. This model uses raw audio signals generated by sensors as input information. Information about the detected leaks is then remotely transmitted using long range and low energy LoRaWAN protocol to the LoRa gateway. The gateway relays messages to a data processing Server. A 1D-CNN regression model has been then created and deployed in this server to directly estimate the 2D position of the leak. As an illustration, An IoT device prototype is designed and used as a case study to test the performance of the proposed system. We demonstrated that our proposal achieves an accuracy of 97 % for detecting leaks and can fix the 2D position of leak with an error of 0.0006 on the X coordinate and 0.0004 on the Y coordinate. Experiments confirm the effectiveness of the proposed solution.}
}


@article{DBLP:journals/iot/KhanZKMA23,
	author = {Sheharyar Khan and
                  Jiangbin Zheng and
                  Sohrab Khan and
                  Zafar Masood and
                  Muhammad Pervez Akhter},
	title = {Dynamic offloading technique for real-time edge-to-cloud computing
                  in heterogeneous {MEC-MCC} and IoT devices},
	journal = {Internet Things},
	volume = {24},
	pages = {100996},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100996},
	doi = {10.1016/J.IOT.2023.100996},
	timestamp = {Sat, 13 Jan 2024 17:37:24 +0100},
	biburl = {https://dblp.org/rec/journals/iot/KhanZKMA23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the realm of Mobile Cloud Computing (MCC), where mobile environments converge with cloud capabilities to address challenges related to performance, environmental considerations, and security, the complexity of task offloading intensifies with the growing number of cloud providers and application units. While Mobile Edge Computing (MEC) shows promise in enhancing MCC performance, the central research challenge revolves around efficiently determining when to offload computational tasks to the cloud or handle them locally at the edge. It involves finding the optimal balance between utilizing cloud resources and enhancing edge computing performance. This study aims to streamline the decision-making process, seeking a harmonious balance between optimal cloud resource utilization and improved edge computing performance. To this end, we introduce HECOM (Hybrid Edge-to-Cloud Offloading for Heterogeneous Computing), a strategic model that combines three decision-making algorithms and an efficient hybrid computation offloading method. HECOM swiftly identifies optimal offloading servers for individual application units, addressing the challenge of efficient offloading decision-making. Importantly, HECOM provides optimal solutions without waiting for all training processes to conclude. Evaluation results from experiments and simulations affirm that the proposed model exhibits impressive energy efficiency, reducing consumption by 25%, increasing offloading ratio by 30%, and minimizing latency and time delay by 15%, making it ideal for real-time applications. It significantly enhances network resource allocation and achieves a more balanced overall performance profile.}
}


@article{DBLP:journals/iot/HuynhTNLD23,
	author = {Hiep Xuan Huynh and
                  Anh Tuan Trinh and
                  Nhan Phuc Nguyen and
                  Tu Tran Lam and
                  Nghia Duong{-}Trung},
	title = {Monitoring and control system of environmental parameters in swiftlet
                  houses},
	journal = {Internet Things},
	volume = {24},
	pages = {100997},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100997},
	doi = {10.1016/J.IOT.2023.100997},
	timestamp = {Sat, 13 Jan 2024 17:37:24 +0100},
	biburl = {https://dblp.org/rec/journals/iot/HuynhTNLD23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Almost 23665 swiftlet houses across 63 provinces in Vietnam suffer vast losses of swiftlet nest production due to a lack of monitoring and controlling the suitable environmental parameters in their bird houses. Effectively managing the right factors, such as temperature, humidity, light intensity, sound level, and crowded level, significantly leads to the high production of swiftlet nests. Unfortunately, there are few relevant research in the literature. This research helps to improve economic efficiency in swiftlet nest house farming by applying modern technical methods to monitor essential environmental parameters in the swiftlet house combined with comparative analysis of collected data from real-time continuous sensors. The proposed three-module system can operate on Raspberry Pi, Android mobile applications, and web interface to automatically monitor the swiftlet house and raise warnings for unusual environmental conditions. Our proposed system has been deployed on the authors’ five swiftlet houses that strongly prove the capability and extendability.}
}


@article{DBLP:journals/iot/NguyenL23a,
	author = {Dat{-}Thinh Nguyen and
                  Kim{-}Hung Le},
	title = {The robust scheme for intrusion detection system in Internet of Things},
	journal = {Internet Things},
	volume = {24},
	pages = {100999},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.100999},
	doi = {10.1016/J.IOT.2023.100999},
	timestamp = {Sat, 13 Jan 2024 17:37:24 +0100},
	biburl = {https://dblp.org/rec/journals/iot/NguyenL23a.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Machine learning and deep learning-based anomaly intrusion detection systems (IDSs) have become prevalent in securing IoT networks due to their ability to monitor traffic and detect zero-day attacks. However, recent studies highlight the high vulnerability of these models to adversarial attacks, in which minor input perturbations can significantly decrease the detection accuracy. Although many studies have focused on adversarial attack and defense techniques for deep learning, machine learning, particularly decision trees, has received limited attention. In this study, we aim to assess the efficacy of the robust decision tree in adversarial IoT environments. Our first experiments reveal the robust decision tree’s sensitivity to the offset parameter. We thus propose a statistical approach to auto-select the offset value, enhancing model stability across varying attack offsets. Then, we present a robust scheme for IDSs in IoT environments. This approach employs the enhanced robust decision tree and a tabular deep learning model to detect and classify a range of cyber attacks. Our evaluation results on three popular IDS datasets—IoTID20, CIC-IDS-2017, and BOT-IoT—demonstrate that our proposed approach is robust under various adversarial attack conditions and achieves a consistent accuracy of over 95% in classifying different attack types.}
}


@article{DBLP:journals/iot/KherbacheAMR23,
	author = {Mehdi Kherbache and
                  Arsalan Ahmed and
                  Moufida Maimour and
                  Eric Rondeau},
	title = {Constructing a Network Digital Twin through formal modeling: Tackling
                  the virtual-real mapping challenge in IIoT networks},
	journal = {Internet Things},
	volume = {24},
	pages = {101000},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.101000},
	doi = {10.1016/J.IOT.2023.101000},
	timestamp = {Sat, 13 Jan 2024 17:37:24 +0100},
	biburl = {https://dblp.org/rec/journals/iot/KherbacheAMR23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Industrial Internet of Things (IIoT) presents numerous requirements, such as reliability, energy efficiency, and real-time performance, among others. Digital Twins technology addresses these needs by enabling the simulation, monitoring, and optimization of such systems. Specifically, Network Digital Twins (NDTs) have recently attracted significant attention from both the industrial and academic networking communities. Numerous research efforts focus on the challenge of network modeling in this context, as simulation tools can increase cost and computational complexity. In this paper, we explore the integration of the formal modeling technique, Petri-nets, within the context of NDTs to model the IIoT, enabling data-driven Petri-nets. We present an architecture based on open-source tools as a framework to encourage researchers to investigate this research direction. Furthermore, we validate the proposed architecture through a case study involving a small-scale network modeled with Timed Petri-Nets. The results demonstrate the model’s effectiveness in executing what-if scenarios based on the network’s operational parameters to predict the Packet Delivery Ratio and enable real-time fault detection. Lastly, we conduct a study on the IIoT observability by the NDT to address the challenge of virtual–real systems mapping in such a context.}
}


@article{DBLP:journals/iot/VhaduriDC23,
	author = {Sudip Vhaduri and
                  Sayanton V. Dibbo and
                  William Cheung},
	title = {Implicit IoT authentication using on-phone {ANN} models and breathing
                  data},
	journal = {Internet Things},
	volume = {24},
	pages = {101003},
	year = {2023},
	url = {https://doi.org/10.1016/j.iot.2023.101003},
	doi = {10.1016/J.IOT.2023.101003},
	timestamp = {Sat, 13 Jan 2024 17:37:24 +0100},
	biburl = {https://dblp.org/rec/journals/iot/VhaduriDC23.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The expansionist nature of the Internet of Things (IoT) with smart sensing has integrated smart technology into the fabric of daily life. From digital health check-ups and personal property access to financial transactions are conveniently performed with the help of smart technologies, such as smart wearables. Therefore, the security of these devices and the entire IoT-connected cyber–physical space accessible through smart wearables has become a burning question. While the current knowledge-based security approaches (e.g., pattern locks, passwords, or PINs) cause a recall burden to the user, conventional one-time biometric-based methods are not adaptable to the tiny wearables. Therefore, this work presents an implicit IoT authentication utilizing breathing patterns to verify a user through continuous microphone sensing. The core piece of this work is the Breathing data-driven TensorFlow Lite framework-supported on-phone authentication application (i.e., BTL Auth app), which consists of an audio processing pipeline (to perform filtering and feature computation) and an artificial neural network model to verify the target user. From our detailed analysis of sequential and non-sequential neural networks trained with static and dynamic audio features, we can achieve an average accuracy of up to .93 when authenticating a user from breathing patterns. Finally, the BTL Auth app needs around 64 KB of memory and 5 s to verify the user.}
}
