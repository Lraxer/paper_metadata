@article{DBLP:journals/iot/FerreiraSCNN24,
	author = {Ricardo S. Ferreira and
                  Carlos Sabino and
                  Michael Canesche and
                  Omar Paranaiba Vilela Neto and
                  Jos{\'{e}} Augusto Miranda Nacif},
	title = {AIoT tool integration for enriching teaching resources and monitoring
                  student engagement},
	journal = {Internet Things},
	volume = {26},
	pages = {101045},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2023.101045},
	doi = {10.1016/J.IOT.2023.101045},
	timestamp = {Sun, 19 Jan 2025 14:28:17 +0100},
	biburl = {https://dblp.org/rec/journals/iot/FerreiraSCNN24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Internet of Things (IoT) protocols and frameworks provide universal access to powerful computing resources regardless of geographical location or infrastructure limitations. Cloud-based platforms such as Google Colab are highlighted for hosting interactive educational materials and applications. Although Colab offers an interactive environment for various disciplines, there is a need to understand how students interact with computational notebooks. This work introduces an MQTT-based toolkit to measure student engagement during remote exercises. The software framework presented facilitates interactive computational notebooks that use IoT to deliver information and feedback to educators and students in a virtual remote environment. The approach integrates Google Colab, Node-RED, Machine Learning, and MQTT tools, creating an asynchronous interactive learning environment.}
}


@article{DBLP:journals/iot/BalciS24a,
	author = {Abdullah Balci and
                  Radosveta Sokullu},
	title = {Corrigendum to "Fairness aware deep reinforcement learning for
                  grant-free NOMA-IoT networks" [Internet of Things, Volume 25,
                  (2024),1-17]},
	journal = {Internet Things},
	volume = {26},
	pages = {101108},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101108},
	doi = {10.1016/J.IOT.2024.101108},
	timestamp = {Tue, 15 Oct 2024 13:53:00 +0200},
	biburl = {https://dblp.org/rec/journals/iot/BalciS24a.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{DBLP:journals/iot/ChesuhDABA24,
	author = {Lawrence Nforh Chesuh and
                  Ram{\'{o}}n {\'{A}}ngel Fern{\'{a}}ndez D{\'{\i}}az and
                  Jos{\'{e}}{-}Manuel Alija{-}P{\'{e}}rez and
                  Carmen Benavides{-}Cuellar and
                  H{\'{e}}ctor Alaiz{-}Moret{\'{o}}n},
	title = {Improve quality of service for the Internet of Things using Blockchain
                  {\&} machine learning algorithms},
	journal = {Internet Things},
	volume = {26},
	pages = {101123},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101123},
	doi = {10.1016/J.IOT.2024.101123},
	timestamp = {Tue, 24 Dec 2024 22:38:15 +0100},
	biburl = {https://dblp.org/rec/journals/iot/ChesuhDABA24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The quality of service (QoS) parameters in IoT applications plays a prominent role in determining the performance of an application. Considering the significance and popularity of IoT systems, it can be predicted that the number of users and IoT devices are going to increase exponentially shortly. Therefore, it is extremely important to improve the QoS provided by IoT applications to increase their adaptability. Majority of the IoT systems are characterized by their heterogeneous and diverse nature. It is challenging for these systems to provide high-quality access to all the connecting devices with uninterrupted connectivity. Considering their heterogeneity, it is equally difficult to achieve better QoS parameters. Artificial intelligence-based machine learning (ML) tools are considered a potential tool for improving the QoS parameters in IoT applications. This research proposes a novel approach for enhancing QoS parameters in IoT using ML and Blockchain techniques. The IoT network with Blockchain technology is simulated using an NS2 simulator. Different QoS parameters such as delay, throughput, packet delivery ratio, and packet drop are analyzed. The obtained QoS values are classified using different ML models such as Naive Bayes (NB), Decision Tree (DT), and Ensemble, learning techniques. Results show that the Ensemble classifier achieves the highest classification accuracy of 83.74 % compared to NB and DT classifiers.}
}


@article{DBLP:journals/iot/FirouziR24,
	author = {Ramin Firouzi and
                  Rahim Rahmani},
	title = {Delay-sensitive resource allocation for IoT systems in 5G {O-RAN}
                  networks},
	journal = {Internet Things},
	volume = {26},
	pages = {101131},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101131},
	doi = {10.1016/J.IOT.2024.101131},
	timestamp = {Mon, 09 Dec 2024 22:47:52 +0100},
	biburl = {https://dblp.org/rec/journals/iot/FirouziR24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The rapid advancement in sensors and communications has led to the expansion of the Internet of Things (IoT) services, where many devices need access to the transport network using fixed or wireless access technologies and mobile Radio Access Networks (RAN). However, supporting IoT in RAN is challenging as IoT services may produce many short and variable sessions, impacting the performance of mobile users sharing the same RAN. To address this issue, network slicing is a promising solution to support heterogeneous service segments sharing the same RAN, which is a crucial requirement of the upcoming fifth-generation (5G) mobile network. This paper proposes a two-level network slicing mechanism for enhanced mobile broadband (eMBB) and Ultra-Reliable and Low Latency communications (URLLC) in order to provide end-to-end slicing at the core and edge of the network with the aim of reducing latency for IoT services and mobile users sharing the same core and RAN using the O-RAN architecture. The problem is modeled at both levels as a Markov decision process (MDP) and solved using hierarchical reinforcement learning. At a high level, an SDN controller using an agent that has been trained by a Double Deep Q-network (DDQN) allocates radio resources to gNodeBs (next-generation NodeB, a 5G base station) based on the requirements of eMBB and URLLC services. At a low level, each gNodeB using an agent that has been trained by a DDQN allocates its pre-allocated resources to its end-users. The proposed approach has been demonstrated and validated through a real testbed. Notably, it surpasses the prevalent approaches in terms of end-to-end latency.}
}


@article{DBLP:journals/iot/NadimiShahrakiZVSM24,
	author = {Mohammad H. Nadimi{-}Shahraki and
                  Hoda Zamani and
                  Zahra Asghari Varzaneh and
                  Ali Safaa Sadiq and
                  Seyedali Mirjalili},
	title = {A systematic review of applying grey wolf optimizer, its variants,
                  and its developments in different Internet of Things applications},
	journal = {Internet Things},
	volume = {26},
	pages = {101135},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101135},
	doi = {10.1016/J.IOT.2024.101135},
	timestamp = {Tue, 24 Dec 2024 22:38:15 +0100},
	biburl = {https://dblp.org/rec/journals/iot/NadimiShahrakiZVSM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Internet of Things (IoT) shapes an organization of objects that can interface and share information with different devices using sensors, computer programs, and other innovations without human intervention. IoT problems deal with massive amounts of data with critical challenges such as complex and dynamic search spaces, multiple objectives and constraints, uncertainty, and noise that require an efficient optimizer to extract valuable insights. Grey wolf optimizer (GWO) is an efficient optimizer stimulated by the hunting mechanism of wolves. The increasing trend of applying GWO shows that although it is a simple algorithm with few control parameters, it effectively solves optimization problems, particularly in various IoT applications. Therefore, this study reviews applying GWO, its variants, and its developments in IoT applications. This systematic review uses the PRISMA methodology, including three fundamental phases: identification, evaluation, and reporting. In the identification phase, the target search problems are defined based on suitable keywords and alternative synonyms, and then 693 documents from 2014 to the end of 2023 are retrieved. The evaluation phase applies three screening steps to assess papers and choose 50 eligible papers for full-text reading. Finally, the reporting phase thoroughly examines and synthesizes the 50 eligible articles to identify key themes related to GWOs in IoT applications. The eligible GWOs are reviewed in the development, commercial, consumer, and industrial categories. The paper visualized the spreading of eligible GWOs according to their publisher, application, journal, and country and then suggested future directions for research.}
}


@article{DBLP:journals/iot/OktianLJLK24,
	author = {Yustus Eko Oktian and
                  Thi{-}Thu{-}Huong Le and
                  Uk Jo and
                  Agus Mahardika Ari Laksmono and
                  Howon Kim},
	title = {Secure decentralized firmware update delivery service for Internet
                  of Things},
	journal = {Internet Things},
	volume = {26},
	pages = {101136},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101136},
	doi = {10.1016/J.IOT.2024.101136},
	timestamp = {Mon, 09 Dec 2024 22:47:52 +0100},
	biburl = {https://dblp.org/rec/journals/iot/OktianLJLK24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the increasing number of Internet of Things devices, it is crucial to keep them up-to-date to prevent cyber attacks. Traditional centralized delivery is not suitable for scaling and also can be too expensive to run for small vendors. Thus, finding a fully secure, scalable, yet cost-efficient firmware update distribution strategy is always an open research problem. This paper tries to answer those problems by proposing Patchman, a secure decentralized firmware update delivery service for the Internet of Things ecosystem leveraging blockchain. When a new firmware patch is available, vendors make a bid in the smart contract for anyone to join as firmware distributors. For each successful delivery to targeted devices, distributors are rewarded with tokens. Meanwhile, devices gain a reputation score every time they successfully install an update. To ensure robustness and fairness, we develop secure fair exchange protocols using verifiable proof-of-delivery and proof-of-installation. Those proofs can be traded in the blockchain for rewards and reputation scores increase, proving that the proof-holders have successfully processed a firmware delivery and firmware installation task. This way, the firmware update delivery can be executed safely without centralized third-party control. Our evaluation results show that our implementation complies with the five security goals that we envision. We also have successfully punished malicious actions by confiscating their deposits and requiring them to pay up to four times of base deposit value when they join the next update task, ensuring the fairness of our protocol. Furthermore, we generate low processing delay overhead compared to existing works that rely on Zero-Knowledge Proofs. The gas usage consumption from our approach also produced a competitive result despite our works supporting more features than existing works, ensuring the efficiency of our proposal.}
}


@article{DBLP:journals/iot/KumarASS24,
	author = {Dharmendra Kumar and
                  Saurabh Agrawal and
                  Rajesh Kumar Singh and
                  Raj Kumar Singh},
	title = {IoT-enabled coordination for recommerce circular supply chain in the
                  industry 4.0 era},
	journal = {Internet Things},
	volume = {26},
	pages = {101140},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101140},
	doi = {10.1016/J.IOT.2024.101140},
	timestamp = {Tue, 22 Oct 2024 21:11:34 +0200},
	biburl = {https://dblp.org/rec/journals/iot/KumarASS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The current advances in integrating devices through the Internet of Things (IoT) have encouraged researchers to focus on the applications of IoT in the recommerce business. Recommerce and the circular economy are growing worldwide as customers and businesses prioritize sustainability. A lack of coordination between channel participants is a significant hurdle to successfully adopting Circular principles in the recommerce industry. This study explores the coordination issue for a circular supply chain consisting of a Web-based recommerce platform and an IoT-enabled original equipment manufacturer. The proposed study is analyzed using a mixed-method research strategy combining a case study with a game-theoretic model. We analyze the problem under a consignment contract with revenue sharing for different channel structures. We introduce a hybrid contract to coordinate the decentralized channel in a cooperative game model. The results show that the consignment contract cannot coordinate the business in a decentralized structure. The recommerce platform achieves perfect coordination through the hybrid contract and obtains a unique Pareto optimization. We are proposing a IoT-enabled system in which resources are not wasted, thereby providing a way for businesses to use the circular economy concept to achieve sustainability goals.}
}


@article{DBLP:journals/iot/RoyBDSH24,
	author = {Sandip Roy and
                  Abhishek Bisht and
                  Ashok Kumar Das and
                  Sachin Shetty and
                  M. Shamim Hossain},
	title = {Age of correlated information-optimal dynamic policy scheduling for
                  sustainable Green IoT devices: {A} multi-agent deep reinforcement
                  learning approach},
	journal = {Internet Things},
	volume = {26},
	pages = {101141},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101141},
	doi = {10.1016/J.IOT.2024.101141},
	timestamp = {Tue, 22 Oct 2024 21:11:34 +0200},
	biburl = {https://dblp.org/rec/journals/iot/RoyBDSH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The rapid progress in communication technologies and the widespread adoption of connected devices have given rise to various information-centric Internet-of-Things (IoT) systems, typically necessitating timely updates of information. Green IoT (G-IoT) strives to enhance the environment by reducing the power consumption of billions of devices engaged in extensive data exchange, addressing the substantial energy demand in the process. The Age of Correlated Information (AoCI) measures the freshness of information shared among two or more devices that contribute to the same decision-making process. Optimizing AoCI using Deep Reinforcement Learning (DRL) in IoT reduces energy consumption, optimizes resource utilization, and promotes environmentally conscious communication, contributing to the development of a sustainable G-IoT system. This paper focuses on scheduling the transmission of status update packets among interconnected G-IoT devices to minimize the application-specific long-term average AoCI. The problem is modeled as an NP-hard episodic Markov Decision Process (MDP), highlighting its computational complexity. To handle correlations and the curse of dimensionality, a multi-agent deep reinforcement learning algorithm, specifically the Multi-Agent Deep Deterministic Policy Grading (MADDPG) algorithm, is developed. The training progress displays episode rewards, with an environment designed to penalize multiple agents transmitting simultaneously or none at all, promoting cooperative behavior and minimizing the average age of correlated information. We provide comprehensive simulation results, including reward convergence, the learning process of actors and critics, and the resulting average AoCI with the number of episodes, demonstrating the effectiveness of the MADDPG algorithm.}
}


@article{DBLP:journals/iot/KarCSKC24,
	author = {Pushpendu Kar and
                  Lin Chen and
                  Weixue Sheng and
                  Chiew Foong Kwong and
                  David Chieng},
	title = {Advancing {NDN} security: Efficient identification of cache pollution
                  attacks through rank comparison},
	journal = {Internet Things},
	volume = {26},
	pages = {101142},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101142},
	doi = {10.1016/J.IOT.2024.101142},
	timestamp = {Mon, 09 Dec 2024 22:47:52 +0100},
	biburl = {https://dblp.org/rec/journals/iot/KarCSKC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Named Data Networking (NDN) is recognized as one of the most promising future Internet architectures, employing semantic classification to identify devices, thereby enhancing network usability, scalability, and resilience compared to traditional configurations. However, as an emergent technology, NDN necessitates further development, particularly in areas like enhancing signature privacy and data security. This paper primarily addresses the detection and mitigation of cache pollution attacks, a significant issue in the existing NDN mechanisms. Our proposed method involves generating real-time genuine and counterfeit corrupted ranked lists of requested packets. By comparing these lists, abnormal fluctuations in packet numbers and request rates—indicators of potential attacks—can be detected. A distinctive feature of our system is its ability to differentiate between normal attacks and certain emergency events, restraining only the former that addresses the challenge left unresolved by the Cache protection method based on Prefix Hierarchy for content-oriented network (CPMH) model, which is a state-of-the-art and widely used mechanism for protecting cache pollution attack in NDN. Simulation results confirm that the proposed mechanism effectively distinguishes between legitimate popular contents and malicious contents as well as increases a minimum of 10% cache hit ratio during attack situation compared to the CPMH.}
}


@article{DBLP:journals/iot/PradhanTM24,
	author = {Srikanta Pradhan and
                  Somanath Tripathy and
                  Rakesh Matam},
	title = {Towards optimal edge resource utilization: Predictive analytics and
                  reinforcement learning for task offloading},
	journal = {Internet Things},
	volume = {26},
	pages = {101147},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101147},
	doi = {10.1016/J.IOT.2024.101147},
	timestamp = {Tue, 22 Oct 2024 21:11:34 +0200},
	biburl = {https://dblp.org/rec/journals/iot/PradhanTM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Edge computing brings computation closer to the user devices. This proximity allows user devices with limited resources to execute complex and computation-intensive tasks on the edge, thus minimizing the latency in task execution. A typical edge device employs its resources for executing user tasks. When the resources are unavailable, the tasks are offloaded either to the network’s other edge devices or to the cloud. Selecting such an optimal location and adhering to various task requirements is a multiple-constraint optimization problem, and several works exist to addressing this issue. However, the majority of these works emphasize on determining the optimal location to offload tasks based on current resource availability and edge intelligence. In this work, we aim to predict the resource availability at the edge device before the task offloading decision is made. Further, we design a leader-based optimal task offloading decision approach where the edge-server uses a reinforcement learning model to determine such optimal location. We formulate a dynamic optimization problem to solve the optimal location issue in edge computing environment. The proposed reinforcement learning based technique maximizes the system utility by optimizing task offloading and resource allocation policies. Through experimental results, we show that our model achieves efficient edge resource utilization and better individual profit for edge devices. The results also show that resource idle time on edge devices is significantly lower as compared to the non-predictive models.}
}


@article{DBLP:journals/iot/GozuogluOG24,
	author = {Abdulkadir Gozuoglu and
                  Okan Ozgonenel and
                  Cenk Gezegin},
	title = {{CNN-LSTM} based deep learning application on Jetson Nano: Estimating
                  electrical energy consumption for future smart homes},
	journal = {Internet Things},
	volume = {26},
	pages = {101148},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101148},
	doi = {10.1016/J.IOT.2024.101148},
	timestamp = {Tue, 22 Oct 2024 21:11:34 +0200},
	biburl = {https://dblp.org/rec/journals/iot/GozuogluOG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Smart home applications have witnessed significant advancements, expanding beyond lighting control or remote monitoring to more sophisticated functionalities. Our study delves into pioneering an advanced energy management system tailored for forthcoming smart homes and grids. This system harnesses deep learning methodologies to predict consumer energy consumption. Leveraging a Wireless Fidelity (Wi-Fi) connection, we established an Internet of Things (IoT) network supported by Message Queuing Telemetry Transport (MQTT) for efficient data transfer. Our approach integrated the Jetson Nano Developer Kit for deep learning tasks, utilized Raspberry Pi as a home management server (HMS), and employed Espressif Systems' microcontrollers (ESP-01, NodeMCU, ESP32) to impart intelligence to household devices. Actual house measurements were collected and rigorously analyzed, demonstrating promising outcomes in deep learning, control, and monitoring applications. This management system's potential extends to empowering future smart homes and is a crucial component for demand-side energy management in forthcoming intelligent grids.}
}


@article{DBLP:journals/iot/HamoudaFBSG24,
	author = {Djallel Hamouda and
                  Mohamed Amine Ferrag and
                  Nadjette Benhamida and
                  Hamid Seridi and
                  Mohamed Chahine Ghanem},
	title = {Revolutionizing intrusion detection in industrial IoT with distributed
                  learning and deep generative techniques},
	journal = {Internet Things},
	volume = {26},
	pages = {101149},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101149},
	doi = {10.1016/J.IOT.2024.101149},
	timestamp = {Mon, 03 Mar 2025 22:14:48 +0100},
	biburl = {https://dblp.org/rec/journals/iot/HamoudaFBSG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In response to escalating cyber threats and privacy issues within the Industrial Internet of Things (IIoT), this research presents FedGenID, an advanced Federated Generative Intrusion Detection System, to safeguard IIoT networks. Our approach introduces a three-model framework: (1) a federated generative model, incorporating a Conditional Generative Adversarial Network (cGANs) for data augmentation, emphasizing only generator model updates to be shared among clients. This model uses a Wasserstein loss function with Gradient Penalty to amplify sample diversity, indicative of varying cyber threats. Concurrently, we address the issues of imbalanced and distributed data and deploy a data curation technique to align generated data within specific constraints. (2) A secondary model fine-tunes local Critics for enhanced resilience and detection of various adversarial attacks. (3) The third model focuses on precise cyber threat identification, leveraging augmented data for improved training under a synthetic federated learning schema, bolstering detection capability, especially against zero-day threats. Our evaluation of FedGenID, utilizing a novel industrial cybersecurity dataset, highlights its efficacy in non-IID, multi-class cyber threat detection and its resilience to adversarial attacks. Furthermore, we demonstrate how FedGenID can mitigate the negative impact of differential privacy-enhanced FL on model performance. The findings underscore FedGenID’s proficiency in detection accuracy, surpassing traditional FedID by 10% in the presence of zero-day attacks and high privacy regimes.}
}


@article{DBLP:journals/iot/TripathyBMNMM24,
	author = {Subhranshu Sekhar Tripathy and
                  Sujit Bebortta and
                  Mazin Abed Mohammed and
                  Jan Nedoma and
                  Radek Martinek and
                  Haydar Abdulameer Marhoon},
	title = {An SDN-enabled fog computing framework for wban applications in the
                  healthcare sector},
	journal = {Internet Things},
	volume = {26},
	pages = {101150},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101150},
	doi = {10.1016/J.IOT.2024.101150},
	timestamp = {Tue, 24 Dec 2024 22:38:15 +0100},
	biburl = {https://dblp.org/rec/journals/iot/TripathyBMNMM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {For healthcare systems utilizing Wireless Body Area Networks (WBANs), maintaining the network's diverse Quality of Service (QoS) metrics necessitates effective communication among Fog Computing resources. While fog nodes efficiently handle local requests with substantial processing resources, it is crucial to acknowledge the unpredictable availability of these nodes, potentially resulting in a decline in system performance. This study explores a software-defined fog architecture supporting different healthcare applications in Internet of Things (IoT) environment to ensure consistent specialized medical care amidst evolving health issues. Even minor delays, packet losses, or network overhead could adversely affect patient health. The article establishes a mathematical foundation based on transmitted and sensed data, ensuring each fog node executes an ideal quantity of processes. This study formulates an optimization problem to maximize the utility of fog nodes, leveraging the Lagrangian approach and Karush-Kuhn-Tucker conditions to streamline and resolve the optimization problem. Performance analysis demonstrates a significant reduction in delays by approximately 38 %, 29 %, and 32 %, along with energy savings of roughly 26.89 %, 12.16 %, and 22.50 %, compared to benchmark approaches. This study holds promise in healthcare, cloud-fog simulation, and WBANs, emphasizing the critical need for swift and accurate data processing.}
}


@article{DBLP:journals/iot/ArafatPB24,
	author = {Muhammad Yeasir Arafat and
                  Sung Bum Pan and
                  EunSang Bak},
	title = {{QQAR:} {A} Q-learning-based QoS-aware routing for IoMT-enabled wireless
                  body area networks for smart healthcare},
	journal = {Internet Things},
	volume = {26},
	pages = {101151},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101151},
	doi = {10.1016/J.IOT.2024.101151},
	timestamp = {Mon, 09 Dec 2024 22:47:52 +0100},
	biburl = {https://dblp.org/rec/journals/iot/ArafatPB24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recently, the Internet of Medical Things (IoMT) has gained broad acclaim in the academic and industrial sectors due to its use in integrating medical devices and healthcare systems. Wireless body area networks (WBANs) are a promising technology in smart healthcare for real-time patient monitoring and health data analysis by medical professionals. Efficient data transmission is essential in ensuring reliable and timely delivery of healthcare facilities. Healthcare services require reliable, delay-sensitive, energy- and congestion-aware communication, which makes it challenging to design a routing protocol. To address quality of services (QoS) in IoMT-enabled WBANs for healthcare, we propose Q-learning-based quality of services (QoS) aware routing (QQAR). Firstly, we used two-hop-based link reliability estimation to ensure link reliability from sources to sink nodes. Routing decisions using two-hop neighbor information guarantees successful packet delivery. Secondly, we differentiated the packets based on traffic priority, which assures the delivery of critical packets even in a congested network. Particularly, considering two-hop node velocity with energy balancing enhanced the guarantee of timely packet delivery before deadlines. In addition, the multi-sink approach enhanced network reliability. Finally, we utilized Q-learning to select suitable neighbor nodes for packet forwarding in a decentralized fashion. A multi-sink load balance and congestion control mechanism adjusts the routing decisions in the QQAR to avoid congestion. Our simulation and comparison results showed that QQAR outperforms the existing routing protocols across various performance metrics under distinct network conditions.}
}


@article{DBLP:journals/iot/PisaBVM24,
	author = {Ivan Pisa and
                  Guillem Boquet and
                  Xavier Vilajosana and
                  Borja Mart{\'{\i}}nez},
	title = {On the Generalization of Deep Learning Models for AoA Estimation in
                  Bluetooth Indoor Scenarios},
	journal = {Internet Things},
	volume = {26},
	pages = {101152},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101152},
	doi = {10.1016/J.IOT.2024.101152},
	timestamp = {Sun, 19 Jan 2025 14:28:17 +0100},
	biburl = {https://dblp.org/rec/journals/iot/PisaBVM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Indoor positioning remains as one of the major challenges of the Internet of Things (IoT), where assets are usually deployed over environments where the Global Navigation Satellite Systems (GNSS) are denied. Angle-of-arrival (AoA) estimation techniques are among the most prominent candidates to address this challenge and multiple techniques based on conventional signal processing, such as the Multiple Signal Classification (MUSIC) algorithm, have been extensively studied. However, they require a deep knowledge of the elements involved in the AoA system, such as the characterization of the receivers’ antennas. On the other hand, Deep Learning (DL) models are considered as promising solutions, as they can provide AoA estimations without resorting to a deep knowledge of the physical system. Instead, they only need to be trained with labeled AoA signal measurements. Nevertheless, in the training process, non-desired effects like overfitting appear, yielding models with poor generalization capabilities. Although these models have already been considered in the literature, the problem of DL models generalization has not been addressed in depth. Therefore, this manuscript first compares the performance of DL models to the MUSIC algorithm as a baseline, to then analyze their generalization to different situations. These include changing the position of the receivers within the same area, considering measurements at different time instants and deployments in new scenarios, specifically in locations different from the training one. The assessment showed that the generalization of the DL models is weak compared to the MUSIC algorithm, especially when applied to environments not previously observed.}
}


@article{DBLP:journals/iot/OliveiraCAS24,
	author = {Franklin Oliveira and
                  Daniel G. Costa and
                  Fl{\'{a}}vio Assis and
                  Ivanovitch Silva},
	title = {Internet of Intelligent Things: {A} convergence of embedded systems,
                  edge computing and machine learning},
	journal = {Internet Things},
	volume = {26},
	pages = {101153},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101153},
	doi = {10.1016/J.IOT.2024.101153},
	timestamp = {Mon, 09 Dec 2024 22:47:52 +0100},
	biburl = {https://dblp.org/rec/journals/iot/OliveiraCAS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This article comprehensively reviews the emerging concept of Internet of Intelligent Things (IoIT), adopting an integrated perspective centred on the areas of embedded systems, edge computing, and machine learning. With rapid developments in these areas, new solutions are emerging to address previously unsolved problems, demanding novel research and development paradigms. In this sense, this article aims to fulfil some important research gaps, laying down the foundations for cutting-edge research works following an ever-increasing trend based on embedded devices powered by compressed artificial intelligence models. For that, this article first traces the evolution of embedded devices and wireless communication technologies in the last decades, leading to the emergence of IoT applications in various domains. The evolution of machine learning and its applications, along with associated challenges and architectures, is also discussed. In this context, the concept of embedded machine learning (TinyML) is introduced within the context of the Internet of Intelligent Things paradigm, highlighting its unique characteristics and the process of developing and deploying such solutions. Furthermore, we perform an extensive state-of-the-art survey to identify very recent works that have implemented TinyML models on different off-the-shelf embedded devices, analysing the development of practical solutions and discussing recent research trends and future perspectives. By providing a comprehensive literature review across all layers of the Internet of Intelligent Things paradigm, addressing potential applications and proposing a new taxonomy to guide new development efforts, this article aims to offer a holistic perspective on this challenging and rapidly evolving research field.}
}


@article{DBLP:journals/iot/HahmA24,
	author = {Katie S. Hahm and
                  Brian W. Anthony},
	title = {Machine learning-based gait health monitoring for multi-occupant smart
                  homes},
	journal = {Internet Things},
	volume = {26},
	pages = {101154},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101154},
	doi = {10.1016/J.IOT.2024.101154},
	timestamp = {Tue, 22 Oct 2024 21:11:34 +0200},
	biburl = {https://dblp.org/rec/journals/iot/HahmA24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Biomarkers related to gait are indicators for many diseases and overall well-being. It is important to monitor gait and its changes over time. The current standard of practice for gait assessments is performed in clinical settings, which does not accurately reflect gait patterns in daily life. Internet-of-Things technologies enable an opportunity to bridge this disparity in gait measurements by bringing sensors cost effectively into the home environment. A smart home system is presented that uses the vibrations in the floor naturally created by footfalls to extract gait health information from the residents. A signal processing approach is presented to detect and characterize footfalls in two-walker scenarios with a 94% success rate of correctly identifying an individual’s footfall. An adapted Gaussian mixture model was developed to estimate step time asymmetry with a root-mean-square error of 0.019 s, or 3.4% of the average step time. A tracking machine learning method was used to estimate footfall locations with a root-mean-square error of 0.66 m. Lastly, a machine learning approach was implemented to estimate ground reaction forces with a root-mean-square error of 0.31 g, or 9.1% of the average ground truth force. As an ambient continuous gait monitoring system, the proposed floor sensing system may be used to enable early detection and early intervention of gait abnormalities.}
}


@article{DBLP:journals/iot/LeeKR24,
	author = {Seungwoon Lee and
                  Sijung Kim and
                  Byeong{-}Hee Roh},
	title = {Mixed Reality Virtual Device {(MRVD)} for seamless MR-IoT-Digital
                  Twin convergence},
	journal = {Internet Things},
	volume = {26},
	pages = {101155},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101155},
	doi = {10.1016/J.IOT.2024.101155},
	timestamp = {Tue, 22 Oct 2024 21:11:34 +0200},
	biburl = {https://dblp.org/rec/journals/iot/LeeKR24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Mixed Reality (MR) extends Augmented Reality (AR) by emphasizing real-time interactions and providing a more immersive experience with the seamless integration of contextual elements, such as spaces, situations, objects, and user behaviors. MR creates new opportunities across fields, such as the Internet of Things (IoT) and Digital Twins (DT), and advancements in Artificial Intelligence (AI). However, integrating these technologies poses challenges for data synchronization, particularly for MR devices with limited computing resources. This study proposes a novel architectural concept, called the MR virtual Device (MRVD), to address the problem. MRVD serves as a virtual counterpart to the MR physical device (MRPD), optimizing computation and communication using container technologies to enhance availability, portability, and scalability. By handling resource-intensive tasks, MRVD boosts performance and consistency, thereby improving the effectiveness and efficiency of the MR-IoT-DT convergence. Our experiments demonstrate MRVD’s concrete benefits in overcoming these challenges, offering a promising approach for future convergence applications.}
}


@article{DBLP:journals/iot/AhakonyeZSLKJ24,
	author = {Love Allen Chijioke Ahakonye and
                  Ahmad Zainudin and
                  Md Javed Ahmed Shanto and
                  Jae{-}Min Lee and
                  Dong{-}Seong Kim and
                  Tae Soo Jun},
	title = {A multi-MLP prediction for inventory management in manufacturing execution
                  system},
	journal = {Internet Things},
	volume = {26},
	pages = {101156},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101156},
	doi = {10.1016/J.IOT.2024.101156},
	timestamp = {Tue, 22 Oct 2024 21:11:34 +0200},
	biburl = {https://dblp.org/rec/journals/iot/AhakonyeZSLKJ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Artificial intelligence (AI) positively remodels industrial processes, notably inventory management (IM), from planning, scheduling, and optimization to logistics. Intelligent technologies such as AI have enabled innovative processes in the production line of manufacturing execution systems (MES), particularly in predicting IM. This study proposes a Multi-MLP model with LightGBM feature selection technique for MES IM prediction to enable high prediction accuracy, minimal computation cost, low prediction error, and minimum time cost. The proposed model is evaluated using publicly available Product Backorder datasets to prove its reliability. Investigating varying feature selection techniques results in identifying appropriate data features relevant to building an AI-based solution for the IM prediction in MES. The experiment results demonstrate efficient decision-making of the proposed system with a low error prediction MAE of 0.2331, MSE of 0.1225, and RMSE of 0.3504.}
}


@article{DBLP:journals/iot/SerraLBM24,
	author = {Aleix Llus{\`{a}} Serra and
                  Francisco del {\'{A}}gu{\`{\i}}la L{\'{o}}pez and
                  Jordi Bonet{-}Dalmau and
                  F. Xavier Moncunill{-}Geniz},
	title = {A new community business model for a free, open, and neutral network:
                  Considering the wireless to fiber transition},
	journal = {Internet Things},
	volume = {26},
	pages = {101157},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101157},
	doi = {10.1016/J.IOT.2024.101157},
	timestamp = {Tue, 24 Dec 2024 22:38:15 +0100},
	biburl = {https://dblp.org/rec/journals/iot/SerraLBM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Free, open, and neutral network (FONN) is an alternative to the prevailing proprietary ISP networks on the Internet. From the FONN manifesto, we conceive two main goals: to give freedom to users and to cooperate in building and maintaining the FONN infrastructure. However, the manifesto avoids talking about the business model of this infrastructure and neglects to give the appropriate role to each member of the community in building and maintaining this infrastructure. Moreover, current research misplaces FONN’s cooperation in the avoidance of the tragedy of the commons and also overlooks ownership. The move from wireless to fiber has amplified the consequences of not considering ownership or member roles. In order to fill the previous gaps, in this article we will first relate the objectives of this manifesto to the field of free software. Next we will argue that FONN’s cooperation should be placed in the avoidance of the tragedy of the anticommons. Inspired by free software we define a new business model for FONN besides discussing different ownership licenses. Furthermore, we state the roles of members and rigorously model the economic flow of construction and maintenance costs. The main implication of the proposed business model is that future FONNs will avoid the economic and organizational collapse of some current FONN communities, mainly because funding cannot be based solely on crowdfunding or volunteering. Yet, as an overall benefit, FONN avoids the duplication of infrastructure. This new business model has been used successfully in the fiber deployment of a FONN section.}
}


@article{DBLP:journals/iot/BhoiCVHRBH24,
	author = {Sachin Kumar Bhoi and
                  Sajib Chakraborty and
                  Boud Verbrugge and
                  Stijn Helsen and
                  Steven Robyns and
                  Mohamed El Baghdadi and
                  Omar Hegazy},
	title = {Intelligent data-driven condition monitoring of power electronics
                  systems using smart edge-cloud framework},
	journal = {Internet Things},
	volume = {26},
	pages = {101158},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101158},
	doi = {10.1016/J.IOT.2024.101158},
	timestamp = {Mon, 09 Dec 2024 22:47:52 +0100},
	biburl = {https://dblp.org/rec/journals/iot/BhoiCVHRBH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The ongoing revolution in industrial production- Industry 4.0, is driven by transformative technologies such as the Industrial Internet of Things (IIoT), Artificial Intelligence (AI), single-board computers, and 5G communication. As the trend towards IIoT continues, an increasing number of industrial drive systems and their fleets are being connected to the cloud. This enables the manufacturers to perform condition monitoring (CM) and streamlined maintenance activities. At the heart of these drive systems are Power Electronics Systems (PESs), which operate at high switching frequencies (10 kHz–1 MHz) to efficiently transfer electrical power and deliver it to a load in a controlled manner. However, due to their functionalities and the presence of semiconductor switches, PESs are susceptible to failure, necessitating effective condition monitoring (CM) for fault detection and improved lifetime. Link to this issue, to enable CM based on high-frequency data, an industrial site with multiple electric drives is required to record data up to 15TB/week. Therefore, there is a demand from industrial partners to establish intelligent communication between a fleet of physical systems and the cloud to reduce transmission, storage, and bandwidth costs, as well as to enable real-time fault detection and learning from fleet operations. This paper proposes an intelligent edge–cloud computing methodology to address the challenge of high-frequency data monitoring for PESs, focusing on novelty detection and selective data transmission to reduce transmission costs. The methodology involves developing a novel edge–cloud framework that incorporates a neural network-based novelty detector for selective data transmission from physical systems to the cloud. The proposed methodology is evaluated through hardware tests, demonstrating a significant reduction in data transmission (94%) and potential cost savings of up to €5.9k/year for a single remote system. 95.6% detection accuracy of the PQ phase is obtained during experimental tests over 590 samples. Thus, this paper contributes to the vision of the smart grid and IIoT by analyzing the Power Quality (PQ) monitoring problem of a three-phase grid and showcasing the capability of the proposed framework in terms of novelty detection and data transmission cost reduction. To conclude, the proposed intelligent edge–cloud computing methodology offers a promising solution for effective condition monitoring of PESs, with potential cost savings and improved fault detection capabilities. By leveraging advanced technologies and intelligent data-driven approaches, this framework advances the goals of Industry 4.0 and paves the way for efficient and reliable industrial operations in the digital age.}
}


@article{DBLP:journals/iot/AldosaryT24,
	author = {Abdallah Aldosary and
                  Muhammad Tanveer},
	title = {{PAAF-SHS:} {PUF} and authenticated encryption based authentication
                  framework for the IoT-enabled smart healthcare system},
	journal = {Internet Things},
	volume = {26},
	pages = {101159},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101159},
	doi = {10.1016/J.IOT.2024.101159},
	timestamp = {Tue, 22 Oct 2024 21:11:34 +0200},
	biburl = {https://dblp.org/rec/journals/iot/AldosaryT24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Internet of Things (IoT) is increasingly becoming a fundamental component of our everyday existence with the swift advancement in communication technology. Critical infrastructures, smart city monitoring, and smart healthcare systems (SHS) all make significant use of IoT-enabled devices. Nevertheless, the computing power of IoT devices utilized in SHS is constrained. These IoT devices gather sensitive patient data and send it to a medical server. Doctors use IoT-enabled devices to retrieve patient data that has been stored on the medical server using a public communication channel that is susceptible to different types of security attacks. In order to provide information security for IoT-enabled devices with limited resources, the NIST has developed an array of authenticated encryption algorithms. When compared to conventional security techniques, these authenticated encryption algorithms offer computational efficiency. The existing authentication schemes are developed by computationally expensive symmetric and asymmetric encryption schemes and are vulnerable to privileged insider and medical server key compromise attacks. Therefore, this paper introduces a physical unclonable function (PUF) and authenticated encryption (GIFT-COFB)-based authentication framework for IoT-enabled SHS, called PAAF-SHS. PAAF-SHS ensures secure encrypted communication between users and medical servers following mutual authentication. The PUF is incorporated within the medical server and the IoT-enabled device to improve resistance against insider attackers and potential compromises to the medical server key attack. Even in the case of a potential medical server key compromise attack, PAAF-SHS ensures that user-medical server communication remains confidential. The implementation of BAN logic ensures the logical exactitude of PAAF-SHS. Informal security analysis is conducted to validate PAAF-SHS’s resilience against impersonation, replay, and denial-of-service attacks. Security validation using Scyther is performed to illustrate the robustness of PAAF-SHS. Finally, performance evaluations demonstrate that the proposed PAAF-SHS achieves a significant reduction in computational and communication costs while enhancing security features.}
}


@article{DBLP:journals/iot/BazanMunozOAP24,
	author = {Adrian Bazan{-}Mu{\~{n}}oz and
                  Guadalupe Ortiz and
                  Juan Carlos Augusto and
                  Alfonso Garc{\'{\i}}a de Prado},
	title = {Taxonomy and software architecture for real-time context-aware collaborative
                  smart environments},
	journal = {Internet Things},
	volume = {26},
	pages = {101160},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101160},
	doi = {10.1016/J.IOT.2024.101160},
	timestamp = {Tue, 24 Dec 2024 22:38:15 +0100},
	biburl = {https://dblp.org/rec/journals/iot/BazanMunozOAP24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The widespread of Internet of Things (IoT) and the price reduction and ubiquity of telecommunications has led to the emergence of smart environments where devices are becoming increasingly smarter and everything is connected and from which society aims to benefit. The data obtained from IoT is rapidly processed in various domains for the achievement of smart cities and societies. However, in many cases, applications are not contextualized by using data from outside the domain but are only contextualized using data from the domain itself, missing the opportunity for further contextualization. The lack of common criteria for the integration of data from different application domains is one of the main reasons that significantly hinders the integration of third-party data into real-time processing and decision-making systems and thus, the context awareness of developed applications. Although the use of several taxonomies and ontologies for context awareness in various application domains have been proposed, in many cases they are highly domain specific and/or difficult to integrate with other systems, which makes it challenging to facilitate data sharing between different systems and their processing to achieve enhanced context awareness. We aim to contribute to the addressing of these limitations through a reusable and extensible multi-domain taxonomy targeted to collaborative IoT and smart environments, which is also automatically integrated into a software architecture with real-time complex event processing technologies. The proposed solution has been illustrated through a case study and performance tests have been carried out in different computing capacity scenarios, showing its feasibility and usefulness.}
}


@article{DBLP:journals/iot/BaouyaHGB24,
	author = {Abdelhakim Baouya and
                  Brahim Hamid and
                  Levent G{\"{u}}rgen and
                  Saddek Bensalem},
	title = {Rigorous Security Analysis of RabbitMQ Broker with Concurrent Stochastic
                  Games},
	journal = {Internet Things},
	volume = {26},
	pages = {101161},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101161},
	doi = {10.1016/J.IOT.2024.101161},
	timestamp = {Tue, 22 Oct 2024 21:11:34 +0200},
	biburl = {https://dblp.org/rec/journals/iot/BaouyaHGB24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Modern Internet of Things architectures encompass various computational logic and communication protocols. However, the security issues inherent in these systems pose significant risks, especially at the device edges. Addressing security threats on the deployed communication edges is imperative to ensure a robust and secure communication system. In this study, we propose an approach that utilizes the Concurrent Stochastic Game model (CSG) to specify the behavior of RabbitMQ Broker in the context of IoT systems precisely while considering potential data corruption attacks. For parametrizable evaluation, these attacks and their frequencies are learned. We implement the CSG model in PRISM games for automated analysis, leveraging reward Probabilistic Alternating Temporal Logic (rPATL) to model security requirements as game goals. Empirical validation of the work is presented via an industrial case study that shows how data corruption attacks can impact the sensed data in water dam infrastructure. This assessment gives valuable insights into the RabbitMQ deployment at the edge.}
}


@article{DBLP:journals/iot/InuwaD24,
	author = {Muhammad Muhammad Inuwa and
                  Resul Das},
	title = {A comparative analysis of various machine learning methods for anomaly
                  detection in cyber attacks on IoT networks},
	journal = {Internet Things},
	volume = {26},
	pages = {101162},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101162},
	doi = {10.1016/J.IOT.2024.101162},
	timestamp = {Tue, 22 Oct 2024 21:11:34 +0200},
	biburl = {https://dblp.org/rec/journals/iot/InuwaD24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This study explores the growing challenges of cybersecurity in the context of rapidly adopted Internet of Things (IoT) technologies, which have become increasingly susceptible to cyber threats. The widespread utilisation of IoT systems intensifies the complex interactions between devices and amplifies the traffic of data, creating various opportunities for cyber adversaries. Consequently, detecting and mitigating cyberattacks targeting IoT systems has emerged as a critical imperative in the field of cybersecurity.}
}


@article{DBLP:journals/iot/HamidogluGK24,
	author = {Ali Hamidoglu and
                  {\"{O}}mer Melih G{\"{u}}l and
                  Seifedine Nimer Kadry},
	title = {A game-theoretical approach for the adoption of government-supported
                  blockchain application in the IoT-enabled agricultural supply chain},
	journal = {Internet Things},
	volume = {26},
	pages = {101163},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101163},
	doi = {10.1016/J.IOT.2024.101163},
	timestamp = {Tue, 24 Dec 2024 22:38:15 +0100},
	biburl = {https://dblp.org/rec/journals/iot/HamidogluGK24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Establishing a reliable, cost-effective, and data-accessible supply chain is a requirement for all administrations. The significance of such a supply chain lies in its ability to strengthen national resiliency, ensure economic security, and foster sustainable growth. Governments know financial investments and subsidies in infrastructure, logistics, and technology are necessary for a robust supply chain. This paper proposes an IoT-enabled agricultural supply chain that integrates with a cooperative Nash game between two parties: telecommunications operators and agricultural enterprises. The aim is to establish cooperative decision-making procedures in advance of the integration of blockchain technology into the supply chain, which is regulated by the subsidy policy of the government. The Nash game yields a unique Nash equilibrium, indicating that both parties can engage in cooperative negotiations regarding their participation in the blockchain application to maximize their financial profits. To illustrate the efficacy of Nash collaboration in blockchain adoption, this study presents two scenarios where non-cooperative behavior is explored to analyze stakeholder responses in competitive contexts. Numerical results justify the theoretical findings and suggest Nash cooperation among stakeholders instead of competition in the blockchain-based agri-food market, which leads to a more accessible market environment that ultimately benefits consumers. Moreover, the positive and negative aspects of the deployment of the government-supported blockchain application are derived through sensitivity analyses conducted on subsidy rate, agricultural market price, subsidy amount, and blockchain market. Practical managerial implications are derived from the findings and observations to help policymakers formulate blockchain policies in agricultural supply chains supported by governments.}
}


@article{DBLP:journals/iot/DaTC24,
	author = {Thao Nguyen Da and
                  Phuong Nguyen Thanh and
                  Ming{-}Yuan Cho},
	title = {Novel cloud-AIoT fault diagnosis for industrial diesel generators
                  based hybrid deep learning {CNN-BGRU} algorithm},
	journal = {Internet Things},
	volume = {26},
	pages = {101164},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101164},
	doi = {10.1016/J.IOT.2024.101164},
	timestamp = {Tue, 15 Oct 2024 13:53:00 +0200},
	biburl = {https://dblp.org/rec/journals/iot/DaTC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The industrial diesel generator is essential to provide electric power during emergencies and requires accurate failure diagnosis in preventative maintenance services. This research presents a novel AIoT system-based hybrid deep learning algorithm for online monitoring of the anomaly conditions of 125 kW/250 kW industrial generators. Firstly, the IoT modules with different precise sensors are developed to be installed on 125 kW and 250 kW industrial generators to simulate other faults conditions in the laboratory. Then, the supervised learning operations are deployed to train deep learning algorithms with collected labeled data. The proposed algorithm, a hybrid convolution neural network bidirectional gate recurrent unit (CNN-BGRU), is deployed to extract deep features from long sequential historical signals and classify the anomaly conditions. The experiments in different 10 s, 20 s, and 30 s sampling frequencies are performed to evaluate and analyze with various benchmarks, which demonstrate efficiencies of the proposed CNN-BGRU method with other traditional deep learning algorithms, including RNN, CNN, GRU, LSTM, BRNN, and BGRU methods. The proposed hybrid method accomplishes the supreme augmentation of 29.43 % loss, 36.55 % validating loss, 25.86 % MAE, 27.00 % validating MAE, 16.78 % MSE, 20.64 % validating MSE, 6.36 % Pre, 25.34 % validating Pre, 17.30 % Rec, and 26.91 % validating Rec compared with state-of-the-art approaches. The AIoT system-based hybrid CNN-BGRU algorithm provides better improvement and higher accuracy in fault diagnosis of firefighting pumps for maintenance service in Industry 4.0.}
}


@article{DBLP:journals/iot/ThirumalKD24,
	author = {G. Thirumal and
                  Chiranjeev Kumar and
                  Praveen Kumar Donta},
	title = {Low discrepancy on non-linear sensor deployment in a time-critical
                  linear IIoT network},
	journal = {Internet Things},
	volume = {26},
	pages = {101165},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101165},
	doi = {10.1016/J.IOT.2024.101165},
	timestamp = {Mon, 03 Mar 2025 22:14:49 +0100},
	biburl = {https://dblp.org/rec/journals/iot/ThirumalKD24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Linear networks are characterized by their long and narrow topology, which transmits data in a linear manner. For time-critical linear IIoT networks, stable connectivity is paramount. A good deployment strategy ensures stable connectivity in the network and maximize the lifetime and coverage of the network. In order to achieve this goal, deployment strategies should address tunnelling effects in linear networks. The proposed method tackles three major issues: 1. minimizing tunnelling effects using non-linear sensor deployment method, 2. maximizing network coverage by introducing a modified Latin Hypercube Sequence (LHS), and 3. Minimizing data interference in the multichannel TSCH network using a neighbour count-based sensor node deployment technique. The simulation validates the efficacy of the suggested approach in prolonging the network’s lifespan by mitigating the tunnelling effect near the sink. Moreover, it optimally utilizes over 70% of the mean energy within the network system. This is a significant improvement over previous algorithms which often failed to even utilizing 40% of the energy, and many a times much lesser. In terms of network coverage, it surpasses other algorithms. Consequently, the proposed method delivers economic advantages by extending the network’s longevity, achieved through a higher number of nodes concentrated around the sink, and significantly reduces the tunnelling effect in the network.}
}


@article{DBLP:journals/iot/LuHZCZ24,
	author = {Jian Lu and
                  Tingting Huang and
                  Qi Zhang and
                  Xiaogai Chen and
                  Jian Zhou},
	title = {A lightweight vehicle detection network fusing feature pyramid and
                  channel attention},
	journal = {Internet Things},
	volume = {26},
	pages = {101166},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101166},
	doi = {10.1016/J.IOT.2024.101166},
	timestamp = {Tue, 15 Oct 2024 13:53:00 +0200},
	biburl = {https://dblp.org/rec/journals/iot/LuHZCZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Vehicle detection is an important supporting technology for the realization of intelligent transportation, autonomous driving, etc. Poor accuracy or low inference vehicle detectors are limited in application, this paper proposes a fast and accurate vehicle detector termed as MCE-SSD. First, the front-end feature extraction network VGG16 is replaced by MobileNetV3_Large, which reduces the number of parameters and computation, and increases the ability to extract high-dimensional features. Next, the BiFPN idea is used to construct a weighted bi-directional fusion network CBiFPN to obtain multi-dimensional vehicle features, while introducing ECA-Net in the feature extraction layer to re-calibrate the importance of different feature channels and further improve the model performance. In the end, CIoU is introduced to better regress the bounding box of the target vehicle, and DIoU-NMS is used to solve the problem of error suppression for dense targets. Compared with SSD, our proposed MCE-SSD improves mAP by 8.30% and 3.50% on KITTI dataset and BDD100K dataset, and with real-time inference (more than 40 FPS), it reports a better trade-off in terms of detection accuracy and speed, illustrating the effectiveness of our method.}
}


@article{DBLP:journals/iot/ChenGLGWCX24,
	author = {Jinyong Chen and
                  Mingliang Gao and
                  Qilei Li and
                  Xiangyu Guo and
                  Jianyong Wang and
                  Jing'an Cheng and
                  Xuening Xing},
	title = {Privacy-aware crowd counting by decentralized learning with parallel
                  transformers},
	journal = {Internet Things},
	volume = {26},
	pages = {101167},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101167},
	doi = {10.1016/J.IOT.2024.101167},
	timestamp = {Mon, 03 Mar 2025 22:14:47 +0100},
	biburl = {https://dblp.org/rec/journals/iot/ChenGLGWCX24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the rapid advancement of deep learning, the performance of crowd counting has improved significantly. Nonetheless, existing crowd counting models primarily depend on a broad dataset gathered from a variety of individuals for model training. However, this diverse dataset comes at the cost of compromising people’s privacy. Hence, the need to address privacy concerns when counting crowds in dense scenes is becoming increasingly apparent. To tackle this issue, we propose a novel framework called the Decentralized Learning with Parallel Transformer network (DLPTNet). Based on the federated learning mechanism, the DLPTNet adopts a decentralized learning framework that implements parameter sharing instead of data sharing. The DLPTNet consists of two pivotal modules, namely Halo Attention (HA) module and the Density-aware Transformer (DAT) module. The HA module has a large perception radius, which enhances its ability to perceive the context around the objects and extract more extensive information from local regions to address the occlusion issue in dense scenes. Meanwhile, the DAT module leverages the parallel mechanism of Density-aware Attention (DDA) to further capture long-range dependencies between different positions and thus gains learning of the correlations and density distributions of various regions within dense crowds globally.}
}


@article{DBLP:journals/iot/MomeniA24,
	author = {Maryam Momeni and
                  S. Mohammad J. Mirzapour Al{-}e{-}Hashem},
	title = {Collaboration of thermal sensors and drones in fighting wildfires;
                  Mathematical model and heuristic approach},
	journal = {Internet Things},
	volume = {26},
	pages = {101168},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101168},
	doi = {10.1016/J.IOT.2024.101168},
	timestamp = {Tue, 15 Oct 2024 13:53:00 +0200},
	biburl = {https://dblp.org/rec/journals/iot/MomeniA24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The forest temperature is monitored utilizing thermal sensors. In the event of a temperature increase, these sensors promptly notify firefighters, enabling timely intervention against fires. Drones offer a potential solution for fire containment by swiftly addressing them in their nascent stages, as identified by temperature fluctuations detected by these sensors. Alternatively, if left unchecked, the situation may necessitate protracted aerial operations like the deployment of fixed-wing air tankers, helicopters, smokejumpers, and rappellers. Regrettably, such measures consume invaluable time that could be better spent combating the blaze. Recent literature on wildfires underscores the significance of collaborative approaches and the seamless integration of contemporary technologies in mitigating the expenses associated with forest fires. This study builds upon the temperature data acquired through thermal sensors to propose an all-encompassing mathematical framework designed to identify and facilitate the early extinguishment of fires using drones. The initial step involves formulating the problem through a mixed-integer linear programming model. To solve the model within expansive dimensions, a heuristic approach inspired by Clark and Wright is posited. The efficacy of this algorithm is gauged through the resolution of diverse scenarios. Promisingly, the results show the viability of collaboration of thermal sensors and drones to accurately pinpoint and extinguish forest fires. The outcomes underscore not only the protective capabilities of the suggested methodology but also its cost-effectiveness. Moreover, the approach's pioneering nature is underscored as it offers a fiscally prudent strategy that rapidly curbs uncontrollable fires.}
}


@article{DBLP:journals/iot/AgarwalSNGA24,
	author = {Amit Agarwal and
                  Deorishabh Sahu and
                  Anuj Nautiyal and
                  Manan Gupta and
                  Pratham Agarwal},
	title = {Fusing crowdsourced data to an adaptive wireless traffic signal control
                  system architecture},
	journal = {Internet Things},
	volume = {26},
	pages = {101169},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101169},
	doi = {10.1016/J.IOT.2024.101169},
	timestamp = {Tue, 24 Dec 2024 22:38:15 +0100},
	biburl = {https://dblp.org/rec/journals/iot/AgarwalSNGA24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this study, a novel wireless adaptive traffic signal control System architecture is proposed, in which crowdsourced data is integrated to detect the traffic state on each approach of an intersection. Under the wireless architecture, the green signal timing is calculated using a travel time-based Max Pressure control algorithm, which is performed on a single-board computer (SBC, RPi 4). The resulting green timings are sent from SBC to the master controller (ESP32) over serial UART and then to the slave (ESP32) wirelessly using ESP-NOW; slave ESP32 is placed on each approach of the intersection. It integrates a fail-safe mechanism to avoid any vehicular conflicts. The proposed system architecture also embeds a crowdsourced data-based pre-emption of intersections for efficient movement of emergency vehicles. The efficacy of the proposed system is compared using a simulation tool with real-world data. With respect to actuated and Max Pressure based on traffic flow, the proposed algorithm reduces the total delay by 54.8% and 22.96%, respectively. Further, the total queue dissipation time decreases by 8.32% and 5.45%, respectively. It outperforms the actuated signal control as well as Max Pressure based on traffic flows. The capability of transforming existing traffic signal controllers into wireless adaptive traffic signal control systems makes it a very affordable and scalable solution.}
}


@article{DBLP:journals/iot/RoscaSA24,
	author = {Cosmina{-}Mihaela Rosca and
                  Adrian Stancu and
                  Andy{-}Valentin Ariciu},
	title = {Algorithm for child adoption process using artificial intelligence
                  and monitoring system for children},
	journal = {Internet Things},
	volume = {26},
	pages = {101170},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101170},
	doi = {10.1016/J.IOT.2024.101170},
	timestamp = {Tue, 24 Dec 2024 22:38:15 +0100},
	biburl = {https://dblp.org/rec/journals/iot/RoscaSA24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The child adoption process consists of a complex procedure in any country. The proposed software product focuses on solving particular adoption-related problems that were underscored by some researchers, such as relationship difficulties between the child and adoptive parents due to the type of matching process, lack of accessibility and transparency, high expenses and time-consuming for adoptive parents, and measuring the child\'s anxiety or stress in the trial adoption. Thus, the first software component computes the compatibility between the child and the parent, the second assesses the parent\'s readiness for adoption, and the third employs a bracelet to track the child\'s heart rate and monitor the progress of the trial adoption in real-time. The application "Adopt Platform" was built using C#, the ASP.NET and Entity Framework for Microsoft SQL database communication, and the Azure tool for artificial intelligence functions for English and Romanian languages. The paper incorporates two case studies, employing numerous tests to assess the accuracy of artificial intelligence services in recognizing forms and conducting sentiment analysis through the Azure tool. The results show that the Azure Form Recognizer effectively discerns data aligned with the Adopt Platform\'s specifications and handles images taken within a 30 cm range. Nevertheless, it imposes constraints: images should stay within a 30° tilt from the horizontal, be within a 30 cm distance, and not contain unrelated text in the backdrop. When evaluating text lengths across English and Romanian contexts, the Azure Sentiment Analysis exhibited an average performance metric of close to 57 %.}
}


@article{DBLP:journals/iot/GiannakidouRLAGMS24,
	author = {Sofia Giannakidou and
                  Panagiotis I. Radoglou{-}Grammatikis and
                  Thomas Lagkas and
                  Vasileios Argyriou and
                  Sotirios K. Goudos and
                  Evangelos K. Markakis and
                  Panagiotis G. Sarigiannidis},
	title = {Leveraging the power of internet of things and artificial intelligence
                  in forest fire prevention, detection, and restoration: {A} comprehensive
                  survey},
	journal = {Internet Things},
	volume = {26},
	pages = {101171},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101171},
	doi = {10.1016/J.IOT.2024.101171},
	timestamp = {Mon, 09 Dec 2024 22:47:52 +0100},
	biburl = {https://dblp.org/rec/journals/iot/GiannakidouRLAGMS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Forest fires are a persistent global problem, causing devastating consequences such as loss of human lives, harm to the environment, and substantial economic losses. To mitigate these impacts, the accurate prediction and early detection of forest fires is critical. In response to this challenge and living in the digital era of Artificial Intelligence (AI) and smart economies, there has been a growing interest in utilising AI mechanisms for forest fire management. This study provides an in-depth examination of the use of AI algorithms in the fight against forest fires. In particular, our paper starts with an overview of the forest fire problem, followed by a comprehensive review of various systems and approaches. This review includes a thorough analysis of the various works that have evaluated the factors that influence fire occurrence and severity, as well as those that focus on fire prediction and detection systems. The paper also explores the use of AI in adapting and restoring after the occurrence of forest fires. The paper concludes with an evaluation of the potential impact of AI on forest fire management and suggestions for future research directions, taking full advantage of novel technologies, such as 5G communications, Software Defined Networking (SDN), digital twins, federated learning and blockchain. Finally, the paper draws lessons and insights on the potential and limitations of AI in forest fire management, highlighting the need for further research and development in this field to maximise its impact and benefits.}
}


@article{DBLP:journals/iot/ImranMAS24,
	author = {Bilal Imran and
                  Muhammad Ahsan and
                  Ali Hammad Akbar and
                  Ghalib Asadullah Shah},
	title = {{D4GW:} {DTLS} for gateway multiplexed application to secure MQTT(SN)-based
                  pub/sub architecture},
	journal = {Internet Things},
	volume = {26},
	pages = {101172},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101172},
	doi = {10.1016/J.IOT.2024.101172},
	timestamp = {Mon, 24 Feb 2025 22:56:41 +0100},
	biburl = {https://dblp.org/rec/journals/iot/ImranMAS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {MQTT-SN a pub/sub application layer protocol is a well-established protocol in the Internet of Things (IoT) paradigm. MQTT-SN gateway application is available as an open-source contribution. Since the gateway receives unencrypted UDP traffic from sensor nodes and translates it to MQTT packets to be forwarded to the MQTT Broker, the first hop always remains vulnerable to potential cyber–physical attacks. This paper identifies potential threats to the current MQTT-SN gateway and provides security while remaining concurrent. We propose a secure gateway application, SecGW, that achieves concurrency while remaining as robust to vulnerabilities as a single BIOS. The performance of SecGW is evaluated by measuring system scalability, resilience, processing delay, and consumed power through the analysis of payload transactions and their types. The evaluation has been carried out on a low-powered IoT testbed. The results of the experimental setup show satisfactorily linear scalability of memory, fairly consistent delays, and an insignificant increase in security-attributable power consumption for an increasing number of connected clients. The packet-level analysis of traffic in an experimental setup demonstrates the resilience of SecGW through stage-wise identification and isolation of misbehaving clients.}
}


@article{DBLP:journals/iot/VCGRP24,
	author = {Juan M. N{\'{u}}{\~{n}}ez V. and
                  Juan M. Corchado and
                  Diana M. Giraldo and
                  Sara Rodr{\'{\i}}guez{-}Gonz{\'{a}}lez and
                  Fernando de la Prieta},
	title = {Recommendation system using bio-inspired algorithms for urban orchards},
	journal = {Internet Things},
	volume = {26},
	pages = {101173},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101173},
	doi = {10.1016/J.IOT.2024.101173},
	timestamp = {Mon, 09 Dec 2024 22:47:52 +0100},
	biburl = {https://dblp.org/rec/journals/iot/VCGRP24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {According to the Food and Agriculture Organization of the United Nations (FAO), climate change is exponentially affecting agricultural production worldwide, with food prices expected to increase by up to 90 percent by 2030 and hunger and malnutrition rates to rise by 2050. This paper presents the development of a platform based on the Internet of Things (IoT) for monitoring urban gardens as a strategy to mitigate hunger, promote food sovereignty and circular economy in areas of food shortage. To this end, an Internet of Things (IoT) architecture is proposed and implemented that involves a social design layer that allows an effective transfer of knowledge to communities and a recommendation system based on evolutionary computation to optimize and maximize the productivity of urban orchards, and thus contribute to the 2030 agenda of the Sustainable Development Goals (SDGs). Finally, three experiments in urban gardens are shown to validate evolutionary computation and artificial intelligence models, such as multiple linear regression, genetic algorithms, ant colony algorithms and spatial estimation and inference algorithms such as the Kriging algorithm. The productivity of urban lettuce orchards is increased between 25 and 45%.}
}


@article{DBLP:journals/iot/WahrstatterKS24,
	author = {Anton Wahrst{\"{a}}tter and
                  Sajjad Khan and
                  Davor Svetinovic},
	title = {OpenFL: {A} scalable and secure decentralized federated learning system
                  on the Ethereum blockchain},
	journal = {Internet Things},
	volume = {26},
	pages = {101174},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101174},
	doi = {10.1016/J.IOT.2024.101174},
	timestamp = {Mon, 09 Dec 2024 22:47:52 +0100},
	biburl = {https://dblp.org/rec/journals/iot/WahrstatterKS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Decentralized Federated Learning (FL) offers a paradigm where independent entities collaboratively train a machine learning model while preserving the privacy of their datasets. Integrating blockchain technology into decentralized FL frameworks is critical to establishing the trust necessary for user participation. However, existing FL systems using blockchain often struggle with scalability, latency, and privacy issues, particularly in permissionless blockchain contexts. This paper proposes OpenFL, a novel, collateral-backed reputation system implemented on the Ethereum blockchain. This system aims to foster trust among participants in a decentralized FL environment. We present a fully autonomous smart contract platform specifically tailored to facilitate FL processes among anonymous users. Furthermore, we address potential security concerns by detailing our strategies to mitigate various attack vectors. To validate our system’s efficacy, we conducted experiments on the Ethereum Ropsten testnet using the MNIST and CIFAR-10 datasets. Our findings demonstrate OpenFL’s capability to overcome the inherent limitations of permissionless blockchains while highlighting the significance of open-access protocols in this context. OpenFL can potentially broaden the participant base in trust-sensitive applications by reducing entry barriers, thus substantially contributing to decentralized machine learning.}
}


@article{DBLP:journals/iot/PapaioannouDKAIT24,
	author = {Alexios Papaioannou and
                  Asimina Dimara and
                  Stelios Krinidis and
                  Christos{-}Nikolaos Anagnostopoulos and
                  Dimosthenis Ioannidis and
                  Dimitrios Tzovaras},
	title = {Advanced proactive anomaly detection in multi-pattern home appliances
                  for energy optimization},
	journal = {Internet Things},
	volume = {26},
	pages = {101175},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101175},
	doi = {10.1016/J.IOT.2024.101175},
	timestamp = {Tue, 22 Oct 2024 21:11:34 +0200},
	biburl = {https://dblp.org/rec/journals/iot/PapaioannouDKAIT24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As far as home appliances are concerned, a major issue arises as malfunctions frequently go unnoticed by homeowners, consuming a significant amount of energy. Identifying this problem highlights the need for an error detection technique, which is vital to minimize energy waste while enhancing household appliance efficiency. This paper introduces an innovative method for advanced proactive anomaly detection in multi-pattern home appliances using variational autoencoders (VAE). Specifically, a CNN-LSTM based VAE integrating a novel dynamic threshold method is exploited for identifying abnormal consumption usage. The overall suggested framework is a complete integrated approach comprising a training and testing phase. Both phases are initiated from robust feature engineering to enhance the multipattern operation program classification. Additionally, a smoothing and decomposition process is applied to optimize the performance of the CNN-LSTM VAE. The efficacy of the method is evaluated on data from 26 different front-load washing machines, demonstrating its effectiveness in identifying anomaly points across various washing programs. Furthermore, compared to the same approach with a static threshold, the proposed method showed improvements of up to 11. 4% on the F1 score. Finally, simulated use case scenarios indicate a reduction of nearly 30% of energy consumption, due to error prevention. As a result, the suggested approach is a robust and applicable tool for energy and demand side management.}
}


@article{DBLP:journals/iot/NehaPST24,
	author = {Benazir Neha and
                  Sanjaya Kumar Panda and
                  Pradip Kumar Sahu and
                  David Taniar},
	title = {Energy and latency-balanced osmotic-offloading algorithm for healthcare
                  systems},
	journal = {Internet Things},
	volume = {26},
	pages = {101176},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101176},
	doi = {10.1016/J.IOT.2024.101176},
	timestamp = {Tue, 22 Oct 2024 21:11:34 +0200},
	biburl = {https://dblp.org/rec/journals/iot/NehaPST24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Healthcare has become an on-the-fly service that is available at one’s fingertips through smartphones, smart wearables, etc. Many a task related to health are solved on these devices. However, certain tasks require higher computational resources, leading to high energy consumption. Moreover, various latency-intensive tasks demand immediate actions and need to be completed within a stipulated time or a certain deadline. Offloading tasks to nearby edge devices or moving them to the cloud could be a viable solution to address the problem of latency and energy consumption. We present an offloading algorithm for healthcare systems by leveraging osmotic computing to handle compute-intensive, energy-consuming and latency-intensive tasks. The proposed algorithm is simulated and evaluated using various synthetic test cases to show its efficacy. We have analysed the performance of our proposed energy and latency-balanced osmotic-offloading (ELBO) algorithm in terms of average latency, success ratio, task failure rate and energy consumption.}
}


@article{DBLP:journals/iot/RatheeKC24,
	author = {Geetanjali Rathee and
                  Chaker Abdelaziz Kerrache and
                  Carlos T. Calafate},
	title = {A sustainable and trusted solution for IoT-based federated learning
                  using feedback behavior},
	journal = {Internet Things},
	volume = {26},
	pages = {101177},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101177},
	doi = {10.1016/J.IOT.2024.101177},
	timestamp = {Tue, 22 Oct 2024 21:11:34 +0200},
	biburl = {https://dblp.org/rec/journals/iot/RatheeKC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated learning is defined as one of the solutions that use distributed clients to train and aggregate the target model without sharing the private information of clients in the network. Hence, federated learning may easily handle and tackle the generated information in a more convenient, feasible and secure manner, while involving the intelligent devices to perform testing and training at the local edges. However, the design of such federated learning solutions faces multiple difficulties due to the cost and complexity of information computation, along with a high energy consumption. Furthermore, the identification of resource-constrained devices which ensures significant power consumption along with privacy and security to the devices makes it critical to attain a sustainable federated learning environment. The aim of this paper is to integrate feedback-based and objective trust models to accurately identify the behavior of communicating devices in the network. The secure transmission of information forwarded by trusted IoT devices is computed by the objective model. In addition, the energy consumption required for measuring the authenticity of a device can be further diminished using a behavior and feedback trusted model. In addition, the past history behavior and feedback received from neighboring devices may also contribute to achieving an efficient and sustainable security mechanism with reduced communication steps and computational delay in the network. The proposed solution is evaluated to analyze the feasibility and performance in terms of energy consumption and resource utilization, while also considering various security metrics for comparison against existing methods. The proposed mechanism out-performed 87% improvement in terms of security metrics in comparison of existing approaches.}
}


@article{DBLP:journals/iot/LiZWAY24,
	author = {Donghe Li and
                  Yijie Zhao and
                  Yiqun Wang and
                  Dou An and
                  Qingyu Yang},
	title = {The privacy preserving auction mechanisms in IoT-based trading market:
                  {A} survey},
	journal = {Internet Things},
	volume = {26},
	pages = {101178},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101178},
	doi = {10.1016/J.IOT.2024.101178},
	timestamp = {Sun, 19 Jan 2025 14:28:19 +0100},
	biburl = {https://dblp.org/rec/journals/iot/LiZWAY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Nowadays, the Internet of Things (IoT) technology has greatly promoted the transaction behavior. It has led to a shift from the traditional face-to-face, bartering business to today’s online virtual goods business, such as energy trading, spectrum, and so on. However, there exist two critical challenges in IoT-based trading market, which include “efficiency” and “safety”. “Efficiency” indicates a fair-trading decision-making rule, and “safety” indicates that the bidders’ privacy must be protected. To address the above challenges, numerous researchers are working on privacy-preserving auction mechanisms for IoT-based transactional markets, drawing insights from electronic auction theory and information security theory. However, a predominant focus on specific scenarios characterizes most existing works, lacking a comprehensive synthesis of the collective contributions to date. Therefore, this paper systematically elucidates privacy-preserving auction mechanisms for IoT-based transactional markets. Firstly, we expound the foundational knowledge of IoT-based auction markets, delving into auction theory and privacy theory through concise categorization. Secondly, we address both theoretical considerations (from the integration perspective of various privacy protection methods and auction mechanisms) and practical aspects (evaluating various real-world application scenarios). Each aspect undergoes meticulous scrutiny, providing practical assessments and prospects. Lastly, we propose future research directions. Key challenges include the absence of inference attack models for differential privacy, a dearth of algorithmic designs with privacy-preserving capabilities at the auction mechanism level, and the intricate balance between privacy and efficiency. Proposed solutions for future research directions include leveraging Bayesian inference and neural networks for effective attacks, designing autonomous privacy protection mechanisms, and addressing the privacy-efficiency trade-off through the application of Markov decision processes.}
}


@article{DBLP:journals/iot/FloresSalgadoAMB24,
	author = {Berenice Flores{-}Salgado and
                  Sergio Jesus Gonzalez Ambriz and
                  Ciro Mart{\'{\i}}nez{-}Garc{\'{\i}}a{-}Moreno and
                  Jessica Beltr{\'{a}}n},
	title = {IoT-based system for campus community security},
	journal = {Internet Things},
	volume = {26},
	pages = {101179},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101179},
	doi = {10.1016/J.IOT.2024.101179},
	timestamp = {Tue, 24 Dec 2024 22:38:15 +0100},
	biburl = {https://dblp.org/rec/journals/iot/FloresSalgadoAMB24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Improving on-campus security measures to ensure the well-being of students and staff results in a significant enhancement in the overall quality of life. This research proposes an Internet of Things (IoT)-based system that leverages sound recognition to detect distress screams and quickly notify a central unit. The system uses an IoT device, Arduino, to collect data from the environment, processes it, and sends the information to a central unit via a cloud IoT service over a Low Power Wide Area Network. The system uses The Things Network and Amazon Web Services platforms to enable communication. The system design considers the resource limitations of Arduino devices and low-power infrastructure. To achieve local detection within the Arduino, several Convolutional Neural Network architectures were compared and evaluated for their effectiveness in scream detection. We evaluated the performance of our models based on accuracy and F1 score, achieving our best results with an accuracy of 95% and an F1 score of 93.4% for the scream class. In addition, the reception coverage in the selected area covers different types of terrain. The results demonstrate the feasibility of implementing an IoT system specifically designed to detect dangerous situations through mobile devices on campus in the surrounding areas.}
}


@article{DBLP:journals/iot/FiccoGPR24,
	author = {Massimo Ficco and
                  Daniele Granata and
                  Francesco Palmieri and
                  Massimiliano Rak},
	title = {A systematic approach for threat and vulnerability analysis of unmanned
                  aerial vehicles},
	journal = {Internet Things},
	volume = {26},
	pages = {101180},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101180},
	doi = {10.1016/J.IOT.2024.101180},
	timestamp = {Tue, 22 Oct 2024 21:11:34 +0200},
	biburl = {https://dblp.org/rec/journals/iot/FiccoGPR24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The proliferation of Unmanned Aerial Vehicles (UAVs) is expected to experience a substantial rise in the next years, driven by their ever-increasing application across various domains. However, ensuring secure communication between UAVs and their ground stations is crucial to prevent the unauthorized disclosure of sensitive information that could jeopardize the mission’s integrity when exploited by malicious actors. Despite this importance, several UAV systems currently operate based on open-source command and control technologies, which have overlooked several security considerations while focusing on availability and safety. To address this concern, this study conducts a comprehensive security assessment of UAV-based systems starting with a systematic literature review whose main purpose is building a comprehensive catalog of threats associated with this technology. Particular attention has been paid to the MAVlink protocol, an open-source protocol commonly utilized for telemetry and command and control for multiple UAVs. Therefore, drawing upon the built catalog, a threat modeling and penetration testing technique has been employed to examine the MAVlink implementation on a real UAV. A threat model developed for a specific case study is also presented, leading to the discovery of four new vulnerabilities, some of which were successfully exploited through attacks. By shedding light on these vulnerabilities, this work seeks to encourage further investigation and research to develop robust security mechanisms for UAV communication systems. It is imperative to address these vulnerabilities proactively to enhance the overall security posture and safeguard against potential threats in the UAV ecosystem.}
}


@article{DBLP:journals/iot/KhanCGGMSSV24,
	author = {Irfanullah Khan and
                  Franco Cicirelli and
                  Emilio Greco and
                  Antonio Guerrieri and
                  Carlo Mastroianni and
                  Luigi Scarcello and
                  Giandomenico Spezzano and
                  Andrea Vinci},
	title = {Leveraging distributed {AI} for multi-occupancy prediction in Cognitive
                  Buildings},
	journal = {Internet Things},
	volume = {26},
	pages = {101181},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101181},
	doi = {10.1016/J.IOT.2024.101181},
	timestamp = {Mon, 03 Mar 2025 22:14:48 +0100},
	biburl = {https://dblp.org/rec/journals/iot/KhanCGGMSSV24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cognitive Buildings are autonomous smart environments capable of setting themselves according to some self-learned rules. Such rules are inferred according to, e.g., the inhabitants’ behaviors, users’ needs, and specific policies for optimizing security, energy, and comfort management. To do this, it is of foremost importance to gather information about users’ habits like room occupancy. Indeed, Cognitive Buildings can effectively exploit information about sensors in the different rooms, thus being able to detect, learn, and forecast the presence of users in the buildings and act in accordance with these predictions. In this direction, this paper proposes an innovative approach for multi-occupancy prediction in Cognitive Buildings, incorporating a multi-layer hierarchy for Federated Learning, the utilization of IoT devices at the Edge, the implementation of long short-term memory neural network models, and the exploitation of Edge Computing. The approach also introduces a versatile design template for developing real distributed systems for occupancy prediction. The proposed approach uses a distributed paradigm to safeguard data privacy so that the collected data is used to train separate local deep learning models, which are then merged in the Cloud. The paper validates the approach by providing a preliminary prototype realized at ICAR-CNR, Rende Italy, and presents a performance analysis, which shows that the occupancy is predicted with an 84.5% accuracy.}
}


@article{DBLP:journals/iot/HuangLH24,
	author = {Zhongchao Huang and
                  Jing Li and
                  Zhihai He},
	title = {Full-coverage unobtrusive health monitoring of elders at homes},
	journal = {Internet Things},
	volume = {26},
	pages = {101182},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101182},
	doi = {10.1016/J.IOT.2024.101182},
	timestamp = {Tue, 22 Oct 2024 21:11:34 +0200},
	biburl = {https://dblp.org/rec/journals/iot/HuangLH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Due to the fast increase of the elderly population, in-home eldercare has emerged as an important topic of research. Existing studies in intelligent health monitoring have yielded promising outcomes. Nevertheless, these approaches fall short of achieving round-the-clock, unobtrusive surveillance. Herein, we introduce a system offering full-dimensional and unobtrusive in-home health monitoring for elderly individuals living alone. We deploy smart sensors, including infrared, bed, sound, and physiological sensors, to provide all-around coverage of the elderly living space. The proposed system proficiently identifies activities such as cooking, coughing, snoring, talking, listening to music, and walking, while concurrently estimating the indoor location and providing intelligent sleep monitoring and assessment of physiological parameters. Our proposed algorithm has undergone evaluation using real-world data, encompassing a 30-day activity record of ten subjects aged 65 and older. The results demonstrate the remarkable effectiveness of our method, showcasing a high degree of accuracy in recognizing a diverse range of activities. This substantiates the practical implementation of our system in authentic homecare environments.}
}


@article{DBLP:journals/iot/AntwiBoasiakoZLKD24,
	author = {Emmanuel Antwi{-}Boasiako and
                  Shijie Zhou and
                  Yongjian Liao and
                  Eric Kuada and
                  Ebenezer Kwaku Danso},
	title = {Enhanced privacy-preserving distributed deep learning with application
                  to fog-based IoT},
	journal = {Internet Things},
	volume = {26},
	pages = {101183},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101183},
	doi = {10.1016/J.IOT.2024.101183},
	timestamp = {Thu, 14 Nov 2024 20:23:23 +0100},
	biburl = {https://dblp.org/rec/journals/iot/AntwiBoasiakoZLKD24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Generally, privacy-preserving distributed deep learning (PPDDL) solutions provided so far present a trade-off between privacy and efficiency/effectiveness, especially, in terms of high communication and run-time costs (i.e. efficiency) and declined accuracy (i.e. effectiveness). Additionally, not much attention has been paid to proposing privacy-preserving solutions that are multi-key compliant, able to extend to new participants and well fit for an unbounded number of participants as well as being post-quantum robust. Also, application of DDL to fog-based IoT needs more attention. To this effect, we present enhanced PPDDL by proposing two solutions (basic and advanced). The basic combines LWE-based additive homomorphic encryption and partial sharing, making it communication cost friendly. The advanced, however, uses a lattice-based fully dynamic multi-key fully homomorphic encryption (FHE) scheme and partial sharing with the additional advantages of being multi-key compliant, able to extend to new participants and well fit for an unbounded number of participants. Furthermore, we put our work in the context of Fog-Based IoT. Extensive experimental evaluations for the basic solution which also best suits the Fog-Based IoT, show that the PPDDL accuracy is maintained, recording accuracy of about 97% for the MNIST dataset. For a much deeper architecture, accuracy could reach about 99%. To assess the generalizability of the accuracy trend observed in the PPDDL, the proposed solution was also evaluated using the CIFAR-10 dataset with interesting results recorded in this study. This paper is innovative as it combines partial sharing and homomorphic encryption in DDL . Solutions are post-quantum robust and communication cost efficient.}
}


@article{DBLP:journals/iot/HaiderAK24,
	author = {Sami Ahmed Haider and
                  Khwaja Mutahir Ahmad and
                  Abdullah Aman Khan},
	title = {Efficient unmanned aerial vehicle-based data collection for IoT smart
                  farming},
	journal = {Internet Things},
	volume = {26},
	pages = {101184},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101184},
	doi = {10.1016/J.IOT.2024.101184},
	timestamp = {Mon, 03 Mar 2025 22:14:48 +0100},
	biburl = {https://dblp.org/rec/journals/iot/HaiderAK24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The extensive range of unmanned aerial vehicles (UAVs) is essential for efficiently gathering data in inaccessible areas. The data received is processed near the end-user to reduce processing delays that could affect time-sensitive applications. This study employs a novel method for data gathering and an effective scheduling framework for intelligent agricultural systems. The suggested paradigm for UAV-based IoT data collection encompasses three primary components: optimal UAV trajectory, data gathering, and data scheduling. These components are specifically designed to incorporate trajectory, energy efficiency, and resource optimization to improve performance. IoT sensors are strategically placed throughout the data collection process to ensure optimal clustering. The clustering is determined by considering various parameters such as distance, latency, energy usage, trust, and quality of service (QoS), among other important factors. The integration of the Lion Algorithm (LA) and Cat Mouse-Based Optimization (CMBO) techniques has led to the proposal of a unique optimization methodology called Lion Mated with Cats Optimization (LMCO). This approach aims to identify the optimal cluster head (CH) in a new and innovative way. To gather data from all clusters, the UAV plans the most efficient route, following a direct path while also avoiding any possible collisions via the LMCO model. The trajectory is computed using received signal strength indicator (RSSI) measurements. The base station (BS) receives the data transmitted by the UAV in close vicinity. Subsequently, the BS selects the most appropriate cloud node based on factors such as response rate, ideal five-fold power efficiency, quality of service (QoS), execution time, and availability. The simulation results are showcased to verify the effectiveness of the suggested approach and are compared with the existing model to demonstrate the superiority of the proposed method.}
}


@article{DBLP:journals/iot/SarkerALAMRI24,
	author = {Sujan Sarker and
                  Md. Tanvir Arafat and
                  Aiman Lameesa and
                  Mahbuba Afrin and
                  Md. Redowan Mahmud and
                  Md. Abdur Razzaque and
                  Tariq Iqbal},
	title = {{FOLD:} Fog-dew infrastructure-aided optimal workload distribution
                  for cloud robotic operations},
	journal = {Internet Things},
	volume = {26},
	pages = {101185},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101185},
	doi = {10.1016/J.IOT.2024.101185},
	timestamp = {Tue, 24 Dec 2024 22:38:15 +0100},
	biburl = {https://dblp.org/rec/journals/iot/SarkerALAMRI24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In our fast-paced, technology-driven world, multi-robot systems have emerged as crucial solutions to tackle contemporary challenges, from industrial automation to disaster response, especially where the scope of human interventions is significantly constrained. In such scenarios, a notable number of event-driven operations trigger robots to perform a substantial amount of tasks. Nonetheless, completion of the tasks proves challenging due to the limited computational capabilities inherent to many robotic systems. Although cloud computing solutions can be integrated to address these limitations by distributing the workload to clouds, ensuring optimized performance remains a formidable challenge due to the communication bottlenecks encountered by the robots. Moreover, the presence of robots’ energy constraints and stringent real-time service requirements further exacerbate this workload distribution problem. In response to the aforementioned challenges, this paper introduces a fog-dew-enabled robotic system designed to mitigate latency and energy consumption while orchestrating crucial workload distribution decisions among robots. The execution of decision-making tasks is conceptualized as a multi-objective optimization problem. Due to the NP-hardness of the multi-objective optimization, we propose an innovative solution based on a meta-heuristic Binary Particle Swarm Optimization algorithm. Through rigorous experimentation conducted via simulation within the iFogSim2 simulator, our results demonstrate that the proposed algorithm surpasses the current state-of-the-art in simultaneously optimizing latency and energy consumption.}
}


@article{DBLP:journals/iot/HamitiK24,
	author = {Enver Hamiti and
                  Bujar Krasniqi},
	title = {Experimental evaluation of {RF-EMF} emitted by electronic devices
                  of IoT systems and comparison with other wireless technologies},
	journal = {Internet Things},
	volume = {26},
	pages = {101186},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101186},
	doi = {10.1016/J.IOT.2024.101186},
	timestamp = {Tue, 22 Oct 2024 21:11:34 +0200},
	biburl = {https://dblp.org/rec/journals/iot/HamitiK24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Our paper presents a study of an environmental sensing system operating at 868 MHz, based on LoRa technology, the physical layer of the LoRaWAN. We utilized LoRa technology to monitor basic environmental parameters in various workplaces and to evaluate personal exposure to radiofrequency electromagnetic fields (RF-EMF) from IoT devices. The experimental campaign followed the IEC 62,232:2017 standard, measuring the power density of electromagnetic fields in specific microenvironments. Our measurements show that LoRa technology has lower values than traditional Wi-Fi and cellular wireless systems. In the LoRaWAN band, the highest temporal variation of average power density fluctuated between µW/m2 and 1320 µW/m2, while maximal values were 1893 µW/m2. Also, the cumulative distribution function fits with the lognormal distribution. We found that the power density values of RF-EMF emitted from LoRa technology comply with national and international guidelines for sensitive indoor microenvironments. Furthermore, increasing the usage of environmental sensing systems is not expected to affect the overall RF-EMF radiation levels soon.}
}


@article{DBLP:journals/iot/FazelNRMA24,
	author = {Elham Fazel and
                  Mahmoud Zahedian Nezhad and
                  Javad Rezazadeh and
                  Marjan Moradi and
                  John Ayoade},
	title = {IoT convergence with machine learning {\&} blockchain: {A} review},
	journal = {Internet Things},
	volume = {26},
	pages = {101187},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101187},
	doi = {10.1016/J.IOT.2024.101187},
	timestamp = {Tue, 24 Dec 2024 22:38:15 +0100},
	biburl = {https://dblp.org/rec/journals/iot/FazelNRMA24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Introduces the merging of the Internet of Things with cutting-edge technology, including blockchain concepts, machine learning algorithms, and AI-based wireless connectivity. Smart industries, intelligent transportation systems, and smart health are all made possible by this convergence system, which uses machine learning skills, blockchain-enabled secure transactions, and smart contracts. For instance, this convergence system, which relies on machine learning skills and secure transactions and smart contracts that benefit from blockchain techniques, plays a crucial role in developing smart industries, intelligent transit systems, and smart health. This paper provides a comprehensive overview of the convergence of IoT with blockchain and machine learning algorithms, as well as the convergence categories, IoT ecosystem, application fields, issues in structure design, and protocols. This study aims to address the technical challenges of IoT, including architecture, hardware, privacy and security, scalability, interoperability, and heterogeneity issues. The presented paper is novel regarding IoT convergence and its categorization with machine learning and blockchain.}
}


@article{DBLP:journals/iot/CaiCZGS24,
	author = {Zhi Cai and
                  Juntong Chen and
                  Wenbo Zhang and
                  Limin Guo and
                  Xing Su},
	title = {A novel real-time data driven method for floating vehicle speed trend
                  prediction},
	journal = {Internet Things},
	volume = {26},
	pages = {101188},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101188},
	doi = {10.1016/J.IOT.2024.101188},
	timestamp = {Wed, 16 Oct 2024 08:13:40 +0200},
	biburl = {https://dblp.org/rec/journals/iot/CaiCZGS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Traffic congestion in urban areas has become a major worldwide problem. As an important direction of the Intelligent Transportation System (ITS), traffic-speed prediction can help drivers better plan routes and shorten travel time according to IOT techniques, thereby effectively alleviating the problem of traffic congestion. Traffic speed changes dynamically over time, so forecasting using historical data may not be able to quickly adapt to sudden changes in traffic conditions, and predicted traffic conditions may lag behind. The use of real-time data can capture instantaneous changes in traffic conditions, which is more adaptable to different traffic scenarios. In order to further explore the advantages of using real-time data for traffic forecasting, a novel real-time Data Driven method for traffic Speed trend Prediction (2DSP) is proposed. The 2DSP method can predict the macro-level traffic speed trend (rising or falling) by using only near-real-time microscopic vehicle information, which effectively captures the dynamic changes in traffic speed. In addition, an adaptive time-slicing strategy based on traffic density is proposed. This strategy dynamically divides time slices based on traffic density, reducing the frequency of data processing and improving the user experience. The effectiveness of the 2DSP method is validated using two real traffic datasets of floating vehicles. The experimental results show that the 2DSP method has good potential for real-time traffic-speed trend prediction.}
}


@article{DBLP:journals/iot/BigelliCFL24,
	author = {Leonardo Bigelli and
                  Chiara Contoli and
                  Valerio Freschi and
                  Emanuele Lattanzi},
	title = {Privacy preservation in sensor-based Human Activity Recognition through
                  autoencoders for low-power IoT devices},
	journal = {Internet Things},
	volume = {26},
	pages = {101189},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101189},
	doi = {10.1016/J.IOT.2024.101189},
	timestamp = {Mon, 09 Dec 2024 22:47:52 +0100},
	biburl = {https://dblp.org/rec/journals/iot/BigelliCFL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Human activity recognition is increasingly recognized as a key task in many applications. However, gathering data from the variety of sensors commonly available on end devices risks compromising user’s privacy when signals are transmitted to more powerful computing units for inference offloading. It is therefore important to design and implement strategies that could prevent privacy breaches without impairing the capability of the system of recognizing activity patterns, and by taking into account the energy constraints of low-power devices. In this work, we propose an energy-aware approach aimed at preserving the privacy of users during inference of human activities. The proposed method is based on a deep learning autoencoder trained to process the signal in order to remove the most sensitive information regarding privacy attributes, without significantly impacting classification accuracy. We also perform a thorough architecture’s parameter tuning of the designed system to enable its implementation on a low-power platform, which we also characterize in terms of energy expenditure. Experimental results show that this system is capable of effectively transforming the signal in order to prevent the inference of sensitive attributes (i.e. weight, height, age, and gender) and it can be conveniently implemented on a constrained embedded system at different levels of the trade-off between accuracy and energy consumption. Indeed, a complete obfuscation of sensitive attributes can be achieved at the cost of a marginal reduction in classification accuracy (5% at most), with an expenditure of around 165 mJ for an execution time of around 30ms needed during the signal transformation step.}
}


@article{DBLP:journals/iot/ZhaoWZWKZYZLW24,
	author = {Xiaonan Zhao and
                  Qi Wang and
                  Min Zhang and
                  Zixian Wei and
                  Rui Ku and
                  Zihao Zhang and
                  Yang Yu and
                  Bo Zhang and
                  Yuan Liu and
                  Cheng Wang},
	title = {CSFF-YOLOv5: Improved YOLOv5 based on channel split and feature fusion
                  in femoral neck fracture detection},
	journal = {Internet Things},
	volume = {26},
	pages = {101190},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101190},
	doi = {10.1016/J.IOT.2024.101190},
	timestamp = {Tue, 22 Oct 2024 21:11:34 +0200},
	biburl = {https://dblp.org/rec/journals/iot/ZhaoWZWKZYZLW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Internet of Things has found extensive applications in the medical field, where the utilization of the You Only Look Once version 5 (YOLOv5) object detection network has played a crucial role. One notable application of the Internet of Things in healthcare is the detection of Femoral Neck Fractures (FNF) in pathology. Because of its subtle fissures, it is difficult to observe and is considerably hindered by treatment. Therefore, this paper proposes a new network model CSFF-YOLOv5 based on YOLOv5s network for the detection task of FNF. The network integrates the attention mechanism and channel split idea to make the network pay more attention to the parts of interest, better learn the feature information of fracture, and ensure the integrity of information through feature fusion to improve the detection accuracy of the network. Through a large number of ablation experiments to prove the performance of different modules, the experimental results show that compared with YOLOv5s, the detection effect of the method proposed in this paper is significantly improved, and there is a certain increase in precision, recall, F1, [email protected] and [email protected]:0.95, especially in the mAP@50:95 index, which is increased by 4.985%, which is enough to show that CSFF-YOLOv5 has a good detection effect on femoral neck data.}
}


@article{DBLP:journals/iot/AbououfSMO24,
	author = {Menatalla Abououf and
                  Shakti Singh and
                  Rabeb Mizouni and
                  Hadi Otrok},
	title = {Feature engineering and deep learning-based approach for event detection
                  in Medical Internet of Things (MIoT)},
	journal = {Internet Things},
	volume = {26},
	pages = {101191},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101191},
	doi = {10.1016/J.IOT.2024.101191},
	timestamp = {Tue, 22 Oct 2024 21:11:34 +0200},
	biburl = {https://dblp.org/rec/journals/iot/AbououfSMO24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Medical Internet of Things (MIoT) is becoming increasingly mainstream as their applications continue to grow. These applications include remote healthcare monitoring, drug storage, alarm systems, and medical wearable devices. Remote patient monitoring, especially using wearable devices, has improved the health and protection of numerous people, while avoiding unnecessary hospital visits. Ideally, healthcare monitoring systems should accurately and timely detect if the patient is entering a critical condition, and alert the concerned doctor accordingly. However, in practice, there are two kinds of alarms raised by such systems, namely, events and anomalies. Events are non-erroneous data that do not conform to the expected values, indicating abnormality in the patient’s condition. On the other hand, anomalies are erroneous data that may result from faulty sensors, electromagnetic interference, malicious attacks, or hardware tampering. These anomalies lead to false alarms which affect the decision making process and may cause danger to the patient’s life. Traditionally, wearable MIoTs, measuring different vitals, frequently communicate with the patient’s phone, or a local processing unit (LPU), in order to analyze and process the collected data. However, the increase in processing capabilities of IoT devices has made on-device event detection possible. This adds an extra layer of defense while avoiding unnecessary communication with LPU. In this paper, a healthcare monitoring system is proposed which compromises of two layers - (1) an online lightweight approach, based on multivariate long-short term memory (LSTM) autoencoder, embedded in each MIoT, that is able to detect data abnormality and alarms the LPU, (2) a correlation technique, at the LPU, that differentiates between anomalies and events, and alerts the patient’s doctor only in case of an event. Since a single sensor reading does not provide enough clinical insight to detect the full length of an event, a feature engineering approach is implemented to extract interpretable statistical, dynamic and physiological features that provide the clinical insight needed. The proposed approach is simulated using Medical Information Mart for Intensive Care (MIMIC) dataset for various vital signs, such as heart rate, systolic and diastolic blood pressure. It is compared with four benchmarks, where the results show the robustness of the model in differentiating between anomalies and events, with event detection sensitivity and specificity above 93%.}
}


@article{DBLP:journals/iot/ZhuT24,
	author = {Lin Zhu and
                  Long Tan},
	title = {Task offloading scheme of vehicular cloud edge computing based on
                  Digital Twin and improved {A3C}},
	journal = {Internet Things},
	volume = {26},
	pages = {101192},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101192},
	doi = {10.1016/J.IOT.2024.101192},
	timestamp = {Tue, 22 Oct 2024 21:11:34 +0200},
	biburl = {https://dblp.org/rec/journals/iot/ZhuT24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In traditional vehicle edge computing research, the limited computing resources of edge servers are not fully considered. At the same time, when using deep reinforcement learning (DRL) to solve vehicle edge computing problems, it is not fully considered that DRL requires a large amount of real-time data and is prone to gradient explosion or disappearance, over-fitting and local optimal solution problems. Therefore, this article proposes a digital twin (DT)-assisted vehicular cloud edge computing offloading solution. To solve the problem of limited edge server computing resources, this article proposes a vehicle, cloud, and edge server collaboration solution. In response to the problem that DRL requires a large amount of real-time data, this paper proposes a real-time data acquisition method based on DT technology. Aiming at the gradient explosion or disappearance, overfitting, and local optimal solution problems of the asynchronous dominant actor–critic (A3C) algorithm, this paper proposes an improved algorithm of A3C, which introduces the\nɛ\n-greedy strategy and dynamic baseline to increase the possibility of exploration and increase the generalization ability of the model through Dropout technology. During the training process, this article also uses the stochastic gradient descent (SGD) algorithm to accelerate the training process and reduce the computational complexity. The simulation results show that compared with other solutions, the improved algorithm proposed in this paper can effectively reduce the delay and energy consumption of offloading tasks at the vehicular edge cloud.}
}


@article{DBLP:journals/iot/KuznetsovRYKKD24,
	author = {Oleksandr Kuznetsov and
                  Alex Rusnak and
                  Anton Yezhov and
                  Kateryna Kuznetsova and
                  Dzianis Kanonik and
                  Oleksandr Domin},
	title = {Merkle trees in blockchain: {A} Study of collision probability and
                  security implications},
	journal = {Internet Things},
	volume = {26},
	pages = {101193},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101193},
	doi = {10.1016/J.IOT.2024.101193},
	timestamp = {Tue, 22 Oct 2024 21:11:35 +0200},
	biburl = {https://dblp.org/rec/journals/iot/KuznetsovRYKKD24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the rapidly evolving landscape of blockchain technology, ensuring the integrity and security of data is paramount. This study delves into the security aspects of Merkle Trees, a fundamental component in blockchain architectures, such as Ethereum. We critically examine the susceptibility of Merkle Trees to hash collisions, a potential vulnerability that poses significant risks to data security within blockchain systems. Despite their widespread application, the collision resistance of Merkle Trees and their robustness against preimage attacks have not been thoroughly investigated, leading to a notable gap in the comprehensive understanding of blockchain security mechanisms. Our research endeavors to bridge this gap through a meticulous blend of theoretical analysis and empirical validation. We scrutinize the probability of root collisions in Merkle Trees, considering various factors such as hash length and path length within the tree. Our findings reveal a direct correlation between the increase in path length and the heightened probability of root collisions, thereby underscoring potential security vulnerabilities. Conversely, we observe that an increase in hash length significantly reduces the likelihood of collisions, highlighting its critical role in fortifying security. The insights garnered from our research offer valuable guidance for blockchain developers and researchers, aiming to bolster the security and operational efficacy of blockchain-based systems.}
}


@article{DBLP:journals/iot/ParkK24,
	author = {Jiwoong Park and
                  Young{-}Bae Ko},
	title = {PedLoc: UWB-based pedestrian localization for autonomous vehicles},
	journal = {Internet Things},
	volume = {26},
	pages = {101194},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101194},
	doi = {10.1016/J.IOT.2024.101194},
	timestamp = {Tue, 22 Oct 2024 21:11:35 +0200},
	biburl = {https://dblp.org/rec/journals/iot/ParkK24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Perception is a key technology for autonomous vehicles. Current sensor-based approaches have limitations detecting pedestrians in non-line-of-sight environments. We propose PedLoc, a UWB-based pedestrian localization system that can accurately estimate the pedestrians’ position even in non-line-of-sight environments. PedLoc addresses the mobility, deployment, and obstacle challenges of existing UWB localization schemes in vehicular environments. We presents a overhearing based PedLoc protocol with a novel peak detection algorithm for vehicular environments. We have evaluated PedLoc through intensive experimentation on real world roads. Experimental results demonstrate that PedLoc outperforms existing solutions, successfully tracking pedestrians in complex road environments.}
}


@article{DBLP:journals/iot/MardiABB24,
	author = {Fatima Zahra Mardi and
                  Yassine Hadjadj Aoul and
                  Miloud Bagaa and
                  Nabil Benamar},
	title = {Resource Allocation for LoRaWAN Network Slicing: Multi-Armed Bandit-based
                  Approaches},
	journal = {Internet Things},
	volume = {26},
	pages = {101195},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101195},
	doi = {10.1016/J.IOT.2024.101195},
	timestamp = {Tue, 22 Oct 2024 21:11:35 +0200},
	biburl = {https://dblp.org/rec/journals/iot/MardiABB24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Wireless sensor networks have become increasingly popular in recent years due to the growing demand for Internet of Things (IoT) applications, including LoRaWAN networks. However, the effective allocation of resources remains a crucial challenge in LoRaWAN networks due to the limited bandwidth and the diverse demands for multiple services. This paper presents three novel resource allocation solutions for LoRaWAN network slicing to address this challenge. These solutions are based on the Multi-Armed Bandit (MAB) algorithm, which is known for balancing the exploration of available actions with the exploitation of optimal decisions. Our objective is to dynamically and efficiently allocate resources to network slices by treating the resource allocation as a MAB problem. This approach aims to maximize Packet Delivery Rate (PDR) performance while ensuring each service’s Service Level Agreement (SLA). The first solution, UCB-MAB, uses the Upper Confidence Bound (UCB) strategy to balance exploration and exploitation to improve network performance. The second solution, Q-UCB-MAB, continuously updates Q-values using the Q-learning update equation and incorporates the UCB strategy for further optimization. Finally, the third solution, ARIMA-UCB-MAB, leverages the predicted reward value from the Autoregressive Integrated Moving Average (ARIMA) model within the UCB framework to enhance network performance. Our results demonstrate that all three solutions offer efficient resource allocation in terms of PDR and SLA satisfaction. Specifically, the ARIMA-UCB-MAB solution outperforms the two other solutions.}
}


@article{DBLP:journals/iot/AttiyaEI24,
	author = {Ibrahim Attiya and
                  Mohamed E. Abd Elaziz and
                  Islam Issawi},
	title = {An improved hunger game search optimizer based IoT task scheduling
                  in cloud-fog computing},
	journal = {Internet Things},
	volume = {26},
	pages = {101196},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101196},
	doi = {10.1016/J.IOT.2024.101196},
	timestamp = {Tue, 24 Dec 2024 22:38:15 +0100},
	biburl = {https://dblp.org/rec/journals/iot/AttiyaEI24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Due to the rapid expansion of Internet of Things (IoT)-related applications, the utilization of cloud services is experiencing significant growth. Although cloud computing has proven its effectiveness in processing and storing data for various applications, it faces challenges in addressing certain requirements, such as the growing need for real-time or latency-sensitive applications and the limitations of network bandwidth. As a result, fog computing is often seen as a supplementary paradigm to cloud computing, providing additional capabilities and benefits to the traditional cloud paradigm, aiming to extend cloud services to edge devices and end-users. However, the limited capabilities of fog nodes require lighter tasks while other tasks that need more processing time are processed in the cloud. In the present research paper, we propose a novel algorithm that is customized for task scheduling within the context of cloud–fog computing on the Internet of Things (IoT) framework. Our approach builds upon the Hunger Game Search algorithm (HGS) as its foundation. To improve the exploitative capabilities of the HGS, our proposed method, called HGSMPA, incorporates the Marine Predator Algorithm (MPA). Through experimental evaluation using various workload traces, we have demonstrated the efficacy of HGSMPA. The findings reveal that HGSMPA surpasses alternative algorithms in terms of reducing energy consumption and minimizing the makespan time. Specifically, The empirical evaluation indicates that HGSMPA can reduce the makespan time by 19.31% for synthetic workloads and by 17.47% for real workloads as compared to similar scheduling algorithms. Moreover, HGSMPA can reduce energy consumption by 14.72% for synthetic workloads and by 17.68% for real workloads as compared to other methods.}
}


@article{DBLP:journals/iot/PrauzekKMK24,
	author = {Michal Prauzek and
                  Pavel Kr{\"{o}}mer and
                  Miroslav Mikus and
                  Jaromir Konecny},
	title = {Adaptive energy management strategy for solar energy harvesting IoT
                  nodes by evolutionary fuzzy rules},
	journal = {Internet Things},
	volume = {26},
	pages = {101197},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101197},
	doi = {10.1016/J.IOT.2024.101197},
	timestamp = {Tue, 24 Dec 2024 22:38:15 +0100},
	biburl = {https://dblp.org/rec/journals/iot/PrauzekKMK24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This study explores the integration of genetic programming (GP) and fuzzy logic to enhance control strategies for Internet of Things (IoT) nodes across varied locations. It is introduced a novel methodology for designing a fuzzy-based energy management controller that autonomously determines the most suitable controller structure and inputs. This approach is evaluated using a solar harvesting IoT model that leverages historical solar irradiance data, highlighting the methodology’s potential for diverse geographical applications and compatibility with low-performance microcontrollers. The findings demonstrate that the integration of GP with designed fitness function enables the dynamic learning and adaptation of control strategies, optimizing system behavior based on historical data. The experimental model showcases an ability to efficiently use historical datasets to derive optimal control strategies, with the fitness metric indicating consistent improvement throughout the learning phase. The results indicate that useful control strategies learned at a certain location may outperform a locally-trained control strategies and can be successfully re-applied in other locations.}
}


@article{DBLP:journals/iot/KangLZWDS24,
	author = {Yunchuan Kang and
                  Anfeng Liu and
                  Shaobo Zhang and
                  Tian Wang and
                  Mianxiong Dong and
                  Houbing Song},
	title = {{DWSP-MT:} Discovery of workers sensing preferences to match tasks
                  for improving data collection quality in {MCS}},
	journal = {Internet Things},
	volume = {26},
	pages = {101198},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101198},
	doi = {10.1016/J.IOT.2024.101198},
	timestamp = {Tue, 22 Oct 2024 21:11:35 +0200},
	biburl = {https://dblp.org/rec/journals/iot/KangLZWDS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Mobile CrowdSensing (MCS) is a new sensing paradigm that leverages the widespread use of mobile devices to collect data quickly and enable various key applications in the Internet of Things (IoT). Collecting high-quality data is essential for MCS to design and provide a high-quality service. However, it is difficult for the platform to detect dishonest workers who submit fake data. Therefore, MCS applications face a significant challenge. Although there are a number of studies on truth discovery, these studies mainly failed to consider the sensing preferences of workers, resulting in poor data quality enhancement. To overcome these issues, a Discovery of Workers Sensing Preferences to Match Tasks (DWSP-MT) scheme is proposed to improve the quality of MCS data collection. The DWSP-MT scheme primarily includes three components: 1) Unmanned Aerial Vehicles (UAVs) are employed to sense data as ground truth data and an unsupervised anomaly detection algorithm is adopted to identify the data truth of tasks submitted by unidentified workers. 2) The data truth of unidentified workers in historical tasks is evaluated to calculate their sensing preferences, which are used to identify trusted workers. 3) To improve the quality of data collection, a task assignment model based on the sensing preferences of trusted workers is proposed for the first time, which can ensure that tasks are assigned to their areas of most excellent expertise. At last, two open-access datasets were used to conduct experiments comparing the DWSP-MT scheme with existing truth discovery methods. The outcomes of these experiments indicate that our approach outperforms the state-of-the-art research and improves F1-score by 65.74 %, improves accuracy by 36.62 %, and reduces data bias by 60.61 %}
}


@article{DBLP:journals/iot/KarasonRMBT24,
	author = {Halld{\'{o}}r K{\'{a}}rason and
                  Pierluigi Ritrovato and
                  Nicola Maffulli and
                  Aldo R. Boccaccini and
                  Francesco Tortorella},
	title = {Wearable approaches for non-invasive monitoring of tendons: {A} scoping
                  review},
	journal = {Internet Things},
	volume = {26},
	pages = {101199},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101199},
	doi = {10.1016/J.IOT.2024.101199},
	timestamp = {Mon, 09 Dec 2024 22:47:52 +0100},
	biburl = {https://dblp.org/rec/journals/iot/KarasonRMBT24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The objective of this review is to explore and analyse current research on the use of wearable sensor technologies to evaluate rehabilitation and prevention strategies for tendinopathies and tendon injuries, and assess tendon biomechanics.}
}


@article{DBLP:journals/iot/BahacheCA24,
	author = {Anwar Noureddine Bahache and
                  Noureddine Chikouche and
                  Sedat Akleylek},
	title = {Securing Cloud-based Healthcare Applications with a Quantum-resistant
                  Authentication and Key Agreement Framework},
	journal = {Internet Things},
	volume = {26},
	pages = {101200},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101200},
	doi = {10.1016/J.IOT.2024.101200},
	timestamp = {Tue, 22 Oct 2024 21:11:35 +0200},
	biburl = {https://dblp.org/rec/journals/iot/BahacheCA24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A biosensor is a method for transmitting various physical phenomena, such as body temperature, electrocardiogram (ECG), pulse, blood pressure, electroencephalogram (EEG), and respiratory rate. This transmission occurs through the utilization of a Wireless Body Area Network (WBAN) when remotely diagnosing patients via Internet-of-Medical-Things (IoMT). However, the transmission of sensitive data from IoMT through WBAN via an insecure channel exposes it to various threats, necessitating the implementation of robust measures to guarantee security against potential adversaries. To address the security concerns associated with patient monitoring in healthcare systems and achieve the necessary security and privacy requirements during communication, a robust authentication framework is indispensable. Hence, it introduces an agile and robust post-quantum authentication framework for cloud-based healthcare applications, effectively mitigating the vulnerabilities identified in the recent literature. This framework is designed to protect against quantum attacks using the Kyber. A formal security verification of the proposed protocol is presented using AVISPA, as well as informally. Additionally, a comparison with the previous works is made regarding both performance and security. The comparison results conclusively show that our proposed framework is better regarding both measures.}
}


@article{DBLP:journals/iot/BisioGHLS24,
	author = {Igor Bisio and
                  Chiara Garibotto and
                  Halar Haleem and
                  Fabio Lavagetto and
                  Andrea Sciarrone},
	title = {RF/WiFi-based {UAV} surveillance systems: {A} systematic literature
                  review},
	journal = {Internet Things},
	volume = {26},
	pages = {101201},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101201},
	doi = {10.1016/J.IOT.2024.101201},
	timestamp = {Mon, 09 Dec 2024 22:47:52 +0100},
	biburl = {https://dblp.org/rec/journals/iot/BisioGHLS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The deployment of Unmanned Aerial Vehicles (UAVs) has gained increasing interest in various applications during recent years due to its multiple features. At the same time, the misuse of UAVs has also posed serious concerns related to privacy, safety, and security of individuals and organizations. This has caused the utmost demand for drone surveillance systems to monitor suspicious activities of any UAVs. In this context, this paper aims at presenting a systematic literature review of the most interesting works concerning the design and development of drone surveillance systems for target detection and tracking based upon RF/WiFi techniques. More specifically, the research tackles the addressed design issues and challenges, the employed methods and techniques. Furthermore, the methodology of the literature review is carefully described, and the performance assessment of relevant studies is explored and analyzed, based on specific criteria. Provided the analysis of state-of-the-art, future research trends are also highlighted in detail, in order to drive the scientific community to research and design novel and efficient drone surveillance systems based on RF/WiFi techniques.}
}


@article{DBLP:journals/iot/FanW24,
	author = {Shengwen Fan and
                  Junchao Wang},
	title = {Multi-dimension-precision chaotic encryption mechanism for Internet
                  of Things},
	journal = {Internet Things},
	volume = {26},
	pages = {101202},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101202},
	doi = {10.1016/J.IOT.2024.101202},
	timestamp = {Tue, 15 Oct 2024 13:53:01 +0200},
	biburl = {https://dblp.org/rec/journals/iot/FanW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The massive amount of information processed in the Internet of Things(IoT) environment requires effective encryption schemes to ensure secure transmission. However, traditional encryption methods such as Elliptic Curve Cryptography (ECC) or Data Encryption Standard (DES) are not suitable for IoT environments where large amounts of data need to be quickly encrypted. In this paper, a multi-precision encryption mechanism based on multi-dimensional chaotic system is proposed. Firstly, the proposed scheme uses floating-point, 32-bit, 24-bit, and 16-bit data accuracy respectively, which can effectively reduce the complexity through fixed-point calculation. Secondly, aiming at the problem that traditional chaotic dynamic analysis methods such as the Lyapunov index cannot be applied, an analysis scheme based on complexity measure is proposed. Finally, a free dimension encryption mechanism based on Logistic, Tent, and PWLCM is proposed. By adding random disturbance to a one-dimensional chaotic map, the weak randomness of the single chaotic sequence is overcome effectively. Finally, the security analysis of the encryption scheme is carried out, and the result proves that the scheme can effectively resist the common attack means. In the 3D chaotic system, the encryption effect of 24-bit data accuracy is close to floating point accuracy, which is suitable for the IoT environment with large data volume, high encryption efficiency, and vulnerability.}
}


@article{DBLP:journals/iot/GuoCLY24,
	author = {Wei Guo and
                  Hangjun Che and
                  Man{-}Fai Leung and
                  Zheng Yan},
	title = {Adaptive multi-view subspace learning based on distributed optimization},
	journal = {Internet Things},
	volume = {26},
	pages = {101203},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101203},
	doi = {10.1016/J.IOT.2024.101203},
	timestamp = {Tue, 22 Oct 2024 21:11:35 +0200},
	biburl = {https://dblp.org/rec/journals/iot/GuoCLY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As the rapid development of Internet of Things (IoT), information is collected from different sensors and stored in distributed devices which can be regarded as the multi-view data. There are currently numerous clustering algorithms designed to handle multi-view data. However, most of these algorithms still suffer from the following problems: They are designed to operate directly on raw data, which preserves excessive redundant information. They primarily focus on pairwise relationships between views, neglecting the intricate high-order connections among multiple views. The prior information of singular values is not taken into account in multiple views and different views are considered to have equal contributions for clustering. To efficiently address above problems, adaptive multi-view subspace learning based on distributed optimization (AMSLDO) is proposed in this paper. Specifically, the original multi-view data is projected to a low-dimensional space for subspace representation, and multiple representation matrices are stacked in a tensor with weighted tensor nuclear norm to obtain high-order correlations and discover the prior information of singular values. Furthermore, the consensus matrix is learned from different representation matrices through adaptive weights. Meanwhile, samples are partitioned into the ideal number of clusters through Laplacian rank constraint. An efficient distributed optimization algorithm based on the Alternating Direction Method of Multipliers (ADMM) framework is designed to solve the proposed model. Extensive experiments are conducted on six datasets, demonstrating the superiority of the proposed model compared with eleven state-of-the-art methods.}
}


@article{DBLP:journals/iot/LiuQHW24,
	author = {Senfa Liu and
                  Baiyou Qiao and
                  Donghong Han and
                  Gang Wu},
	title = {Task offloading method based on CNN-LSTM-attention for cloud-edge-end
                  collaboration system},
	journal = {Internet Things},
	volume = {26},
	pages = {101204},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101204},
	doi = {10.1016/J.IOT.2024.101204},
	timestamp = {Mon, 03 Mar 2025 22:14:48 +0100},
	biburl = {https://dblp.org/rec/journals/iot/LiuQHW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Most of the existing task offloading methods in edge computing environments do not fully utilize the processing capabilities of cloud servers and have high computational complexity, making them unsuitable for real-time processing tasks. To address this problem, we propose a cloud–edge–end collaborative task offloading method based on deep learning methods, combining Convolutional Neural Networks (CNN), Long Short-Term Memory (LSTM), and attention mechanisms. This method models the total cost of the cloud–edge–end collaboration system as a weighted sum function of the time delay and energy consumption of task execution. Then, with the objective of minimizing the total cost of the system, the task offloading problem is formulated as a mixed-integer joint optimization problem with offloading decision and bandwidth allocation, and two subproblems are decomposed from the optimization problem: one focuses on offloading decision and the other on bandwidth allocation. A CNN-LSTM-Attention neural network-based method is proposed to solve the optimal offloading decision efficiently. Based on this, the differential evolution algorithm is used to generate the optimal bandwidth allocation, resulting in efficient task offloading. The simulation experiment results demonstrate that our method enhances system performance and reduces the overall cost of the system, which is significantly better than existing methods.}
}


@article{DBLP:journals/iot/AljumahAU24,
	author = {Abdullah Aljumah and
                  Tariq Ahamed Ahanger and
                  Imdad Ullah},
	title = {Stochastic Game Network-inspired intelligent framework for quality
                  assessment in logistic industry},
	journal = {Internet Things},
	volume = {26},
	pages = {101205},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101205},
	doi = {10.1016/J.IOT.2024.101205},
	timestamp = {Tue, 22 Oct 2024 21:11:35 +0200},
	biburl = {https://dblp.org/rec/journals/iot/AljumahAU24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The widespread utilization of IoT-Fog-Cloud computing has revolutionized customer-oriented service delivery aspects in the global logistics industry. With industrial globalization, the logistics industry is often challenged to address quality issues. Moreover, with improper product management and transportation, the logistics industry has to face considerable financial loss. Conspicuously, a novel Stochastic Game Network (SGN) is proposed in the current study to ensure enhanced service product quality in the logistics industry. Specifically, the smart logistic industry-based decision-making framework is presented by incorporating several parameters of product quality. In the proposed method, each IoT device acts as a game player with a preset action set and strategy. Moreover, each IoT sensor at 4 levels of the logistic industry including Production Management Sensor (IMS), Inventory Management Sensor (IMS), Transportation Management Sensor (TMS), and Delivery Management Sensor (DMS) is incorporated as a game player node. Quality parameters are analyzed using the proposed Bayesian Belief Model (BBM) technique for effective classification. Moreover, Game-theoretic decision-making is used to automate enhanced product quality management and control units in IoT-based logistic industries for effective analysis and customer-oriented service delivery. For validation purposes, experimental results are compared with state-of-the-art decision-making techniques. Based on the results, the proposed model has registered enhanced statistical measures in terms of Precision (92.98%), Specificity (93.78%), Sensitivity (96.78%), Reliability (96.54%), and Stability (78%). To assess the theoretical efficacy of the proposed strategy, mathematical analysis is performed to quantify customer satisfaction. Conclusively, the proposed model presents an effective mechanism for quality assurance by incorporating stochastic behavior in the logistics industry.}
}


@article{DBLP:journals/iot/AlrashdiSAAH24,
	author = {Ibrahim Alrashdi and
                  Karam M. Sallam and
                  Ali Alqazzaz and
                  Bilal Arain and
                  Ibrahim A. Hameed},
	title = {A contrastive learning approach for enhanced robustness for strengthening
                  federated intelligence in internet of visual things},
	journal = {Internet Things},
	volume = {26},
	pages = {101206},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101206},
	doi = {10.1016/J.IOT.2024.101206},
	timestamp = {Mon, 03 Mar 2025 22:14:47 +0100},
	biburl = {https://dblp.org/rec/journals/iot/AlrashdiSAAH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As the Internet of Things (IoT) continues to grow, edge intelligence has developed as a favorable paradigm to enable effective and instantaneous processing of data at the network's edge. The deployment of an edge intelligence approach in untrusted environments exposes them to adversarial attacks, posing a substantial challenge to the reliability and confidentiality of the learned models especially in federated settings. Among these attacks, the white-box attacks are the most dangerous and challenging to defend in IoT systems. This study proposes a novel approach to robustify the federated edge intelligence technique by integrating the power of contrastive learning to enhance the model's ability to distinguish between clean and adversarial examples, thereby improving its robustness. Our robustification approach is based on two lines of defense. First, an elegant federated contrastive pretraining is introduced to robustify the model by adversarially training it using a label-free representation attack. Second, we introduce a novel Consistency Regularized Triplet (CRT) loss function that encourages the regularization of the federated edge intelligence model to learn discriminative representations while minimizing the influence of adversarial perturbations. The empirical evaluation of the Food-101 and CIFAR-100 datasets revealed that the proposed method outperformed the state-of-the-art robust methods on both standard accuracy and robustness accuracy.}
}


@article{DBLP:journals/iot/HassanZCIZSM24,
	author = {Eman Hassan and
                  Zhuowen Zou and
                  Hanning Chen and
                  Mohsen Imani and
                  Yahya H. Zweiri and
                  Hani H. Saleh and
                  Baker Mohammad},
	title = {Efficient event-based robotic grasping perception using hyperdimensional
                  computing},
	journal = {Internet Things},
	volume = {26},
	pages = {101207},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101207},
	doi = {10.1016/J.IOT.2024.101207},
	timestamp = {Mon, 09 Dec 2024 22:47:52 +0100},
	biburl = {https://dblp.org/rec/journals/iot/HassanZCIZSM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Grasping is fundamental in various robotic applications, particularly within industrial contexts. Accurate inference of object properties is a crucial step toward enhancing grasping quality. Dynamic and Active Vision Sensors (DAVIS), increasingly utilized for robotic grasping, offer superior energy efficiency, lower latency, and higher temporal resolution than traditional cameras. However, the data they generate can be complex and noisy, necessitating substantial preprocessing. In response to these challenges, we introduce GraspHD, an innovative end-to-end algorithm that leverages brain-inspired hyperdimensional computing (HDC) to learn about the size and hardness of objects and estimate the grasping force. This novel approach circumvents the need for resource-intensive pre-processing steps, capitalizing on the simplicity and inherent parallelism of HDC operations. Our comprehensive analysis reveals that GraspHD surpasses state-of-the-art approaches in terms of overall classification accuracy. We have also implemented GraspHD on an FPGA to evaluate system efficiency. The results demonstrate that GraspHD operates at a speed 10x faster and offers an energy efficiency 26x higher than existing learning algorithms while maintaining robust performance in noisy environments. These findings underscore the significant potential of GraspHD as a more efficient and effective solution for real-time robotic grasping applications.}
}


@article{DBLP:journals/iot/NetoMLRFV24,
	author = {Miguel Lino Ferreira Neto and
                  Carlos Montez and
                  {\'{E}}rico Le{\~{a}}o and
                  Ricardo J. Rabelo and
                  Angelus Fayran and
                  Francisco Vasques},
	title = {A lightweight {BPSO} mechanism for topology reconfiguration in data-driven
                  IIoT plants},
	journal = {Internet Things},
	volume = {26},
	pages = {101208},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101208},
	doi = {10.1016/J.IOT.2024.101208},
	timestamp = {Tue, 24 Dec 2024 22:38:15 +0100},
	biburl = {https://dblp.org/rec/journals/iot/NetoMLRFV24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Wireless Sensor Networks in large-area monitoring applications may be required to deal with emergency events, i.e., events from regions that suddenly require close attention. Nodes in these regions may demand increased data generation rates, and their communication with the base station (BS) should be prioritized. In this sense, a significant challenge is how to reconfigure the network to create paths that offer adequate Quality of Service (QoS) between these sensor nodes and the BSs. Depending on the network’s size, the computational complexity of this problem may become unacceptable; but a meta-heuristic approach could handle it. This work describes a lightweight Binary Particle Swarm Optimization (BPSO) mechanism for the topology reconfiguration of data-driven cluster-tree networks based on IEEE 802.15.4 standard. The goal of this mechanism, called CALiPSO, is to reduce the computational complexity when searching for a suitable network topological configuration that improves network QoS metrics. A simulation assessment and comparison with other approaches were conducted. It was demonstrated that CALiPSO can reconfigure a network of 125 nodes and create an appropriate cluster-tree with fewer cluster-heads in hotspot regions, while improving network QoS. Compared with heuristic and optimization methods, CALiPSO selects around 42% to 55% fewer CHs and forms trees 22% less depth. Concurrently, it diminishes communication delays by about 5% and decreases packet losses by 7.5%, without jeopardizing energy consumption.}
}


@article{DBLP:journals/iot/NetoTDIXRG24,
	author = {Euclides Carlos Pinto Neto and
                  Hamideh Taslimasa and
                  Sajjad Dadkhah and
                  Shahrear Iqbal and
                  Pulei Xiong and
                  Taufiq Rahman and
                  Ali A. Ghorbani},
	title = {CICIoV2024: Advancing realistic {IDS} approaches against DoS and spoofing
                  attack in IoV {CAN} bus},
	journal = {Internet Things},
	volume = {26},
	pages = {101209},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101209},
	doi = {10.1016/J.IOT.2024.101209},
	timestamp = {Mon, 09 Dec 2024 22:47:52 +0100},
	biburl = {https://dblp.org/rec/journals/iot/NetoTDIXRG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Considering the complexity of network traffic in IoV operations, methods that can identify complex patterns become useful. Machine learning fosters several techniques to enhance the detection, prevention, and mitigation of cyberattacks. However, important features are not addressed in the current state-of-the-art security datasets for IoV. For example, in the case of intra-vehicle communications, it is critical to consider the interaction among multiple Electronic Control Units (ECUs). Also, mimicking a realistic IoV environment is not simple since establishing a test environment requires considerable financial investment. Hence, there is a need for a testbed composed of several real ECUs in an IoV environment comprising network traffic. Thereupon, the main goal of this research is to propose a realistic benchmark dataset to foster the development of new cybersecurity solutions for IoV operations. To accomplish this, five attacks were executed against the fully intact inner structure of a 2019 Ford car, complete with all ECUs. However, the vehicle was immobile and incapable of causing any potential harm or injuries. Hence, all attacks were carried out on the vehicle without endangering the car’s driver or passengers. These attacks are classified as spoofing and Denial-of-Service (Dos) and were carried out through the Controller Area Network (CAN) protocol. This effort establishes a baseline complementary to existing contributions and supports researchers in proposing new IoV solutions to strengthen overall security using different techniques (e.g., Machine Learning — ML). The CICIoV2024 dataset has been published on CIC’s dataset page.}
}


@article{DBLP:journals/iot/SunWSLLF24,
	author = {Jiayu Sun and
                  Huiqiang Wang and
                  Jiayue Sun and
                  Hongwu Lv and
                  Jingyao Liu and
                  Guangsheng Feng},
	title = {An online integrated satellite-terrestrial IoT task offloading and
                  service deployment strategy},
	journal = {Internet Things},
	volume = {26},
	pages = {101210},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101210},
	doi = {10.1016/J.IOT.2024.101210},
	timestamp = {Tue, 15 Oct 2024 13:53:01 +0200},
	biburl = {https://dblp.org/rec/journals/iot/SunWSLLF24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As a core component of 6G networking, low earth orbit (LEO) satellite networks are considered a promising solution for providing network services in remote areas and have received considerable attention in recent years. Meanwhile, with the rapid development of IoT terminals and applications, an increasing emphasis has been placed on task offloading for real-time tasks. However, most existing works on task offloading for integrated satellite–terrestrial IoT (IST-IoT) applications are based on the assumption that the global task and network information is known, an assumption that is obviously not met in online real-time task offloading. In addition, current studies rarely consider the tradeoff among the task offloading volume, satellite endurance and wholesale cost of terrestrial resources, which are precisely the holistic issues that satellite network operators must confront. To address such issues, this study considers task offloading, service deployment and resource allocation in highly dynamic online task offloading scenarios with the goal of maximizing the average task offloading volume. Moreover, virtual queues are constructed in this study to account for the impacts of long-term satellite endurance and terrestrial network resource costs on task offloading. We first decouple the original problem to obtain a single-time-slot optimization problem within the Lyapunov optimization framework, and we then propose a 2-stage optimization approach based on deep reinforcement learning (DRL) to solve the complex single-time-slot mixed integer nonlinear programming (MINLP) problem. Simulation experiments demonstrate that our proposed algorithm can yield near-optimal solutions that show superior performance compared to existing results.}
}


@article{DBLP:journals/iot/TsokovK24,
	author = {Tsvetan Tsokov and
                  Hristo Kostadinov},
	title = {Dynamic network-aware container allocation in Cloud/Fog computing
                  with mobile nodes},
	journal = {Internet Things},
	volume = {26},
	pages = {101211},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101211},
	doi = {10.1016/J.IOT.2024.101211},
	timestamp = {Mon, 09 Dec 2024 22:47:52 +0100},
	biburl = {https://dblp.org/rec/journals/iot/TsokovK24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The massive adoption of movable devices, created a new use cases such as Internet of Things (IoT), autonomous vehicles, spacecraft computing, etc. Not only end users, but also computing infrastructures can change their location. The applications are composed of many interdependent microservices with specific resource requirements. Latest state of the art in Cloud/Fog infrastructures is considering only the computational and network (latency, bandwidth) resources during scheduling of microservices, but in a static way. The network variability when the nodes are moving in space is not considered. This leads to increased total latency, hindering the Quality of Service (QoS) and network costs. Many researchers are focused only on a theoretical level. This paper proposes a novel technique for network-aware dynamic allocation of interdependent microservices on moving infrastructure nodes, applicable in practice. It is composed of a generic MILP optimization model and implementation in a Cloud/Fog platform. Several examples with sample Edge-Native application are obtained. The results show reduction in the total end-to-end network latency compared to the latest state of the art.}
}


@article{DBLP:journals/iot/RahmanPMCK24,
	author = {Saifur Rahman and
                  Shantanu Pal and
                  Shubh Mittal and
                  Tisha Chawla and
                  Chandan K. Karmakar},
	title = {{SYN-GAN:} {A} robust intrusion detection system using GAN-based synthetic
                  data for IoT security},
	journal = {Internet Things},
	volume = {26},
	pages = {101212},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101212},
	doi = {10.1016/J.IOT.2024.101212},
	timestamp = {Mon, 09 Dec 2024 22:47:52 +0100},
	biburl = {https://dblp.org/rec/journals/iot/RahmanPMCK24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As technological communication progresses, diverse datasets are exchanged across distributed environments using the Internet of Things (IoT). However, the IoT environment is vulnerable to attacking and breaching data privacy or making a robust system worse by providing attack data. To address potential risks of attacks, researchers have been conducting experiments on network intrusion detection systems (NIDS) to mitigate threats effectively. The issue of data imbalance and associated data collection costs persists, hindering the ability of machine learning (ML) models to learn malicious behaviour effectively and consequently impacting the accuracy of network threat detection. Addressing these issues, our study explores the potential of using 100% synthetic data generated via Generative Adversarial Networks (GAN) for training ML models in Network Intrusion Detection Systems (NIDS). This approach reduces the dependency on real-world data significantly, paving the way for a more flexible and ethically convenient model-building process. For the UNSW-NB15 dataset, we achieved an accuracy of 90%, a precision of 91%, a recall of 90%, and an F1 score of 89%. For the NSL-KDD dataset, our results showed an accuracy of 84%, a precision of 85%, a recall of 84%, and an F1 score of 84%. For the BoT-IoT dataset, we attained perfect scores of 100% across all metrics. These outcomes indicate that the values obtained from our analysis demonstrate high performance, yielding comparative or superior results to previous studies. Therefore, our study successfully replicates real-world network intrusion detection data, showing new opportunities for the use of generative data in cyber security.}
}


@article{DBLP:journals/iot/SuRNMSS24,
	author = {Runbo Su and
                  Arbia Riahi and
                  Enrico Natalizio and
                  Pascal Moyal and
                  Amaury Saint{-}Jore and
                  Ye{-}Qiong Song},
	title = {Assessing intra- and inter-community trustworthiness in IoT: {A} role-based
                  attack-resilient dynamic trust management model},
	journal = {Internet Things},
	volume = {26},
	pages = {101213},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101213},
	doi = {10.1016/J.IOT.2024.101213},
	timestamp = {Mon, 03 Mar 2025 22:14:49 +0100},
	biburl = {https://dblp.org/rec/journals/iot/SuRNMSS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {IoT is regarded as the key technology for boosting the Industry 4.0 revolution. However, the introduction of high-intelligence devices and complex services raises new challenges for security in IoT. In this paper, a role-based attack-resilient trust management (TM) model for community-driven IoT is proposed at two different levels. First, the intra-community TM enables the IoT nodes within the same community to be monitored dynamically based on their service roles, namely service provider (SP) and service rater (SR). Second, the inter-community TM examines the trust between different communities in terms of cooperativeness. The proposed model has been simulated under various attacks on service. The numerical results show the effectiveness in evaluating both intra- and inter-community trustworthiness. Moreover, the preliminary results of implementation demonstrate the feasibility of the proposed model and also partly validate the proposed model in practice.}
}


@article{DBLP:journals/iot/TermosGBFJZ24,
	author = {Mortada Termos and
                  Zakariya Ghalmane and
                  Mohamed{-}el{-}Amine Brahmia and
                  Ahmad Fadlallah and
                  Ali Jaber and
                  Mourad Zghal},
	title = {{GDLC:} {A} new Graph Deep Learning framework based on centrality
                  measures for intrusion detection in IoT networks},
	journal = {Internet Things},
	volume = {26},
	pages = {101214},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101214},
	doi = {10.1016/J.IOT.2024.101214},
	timestamp = {Tue, 22 Oct 2024 21:11:35 +0200},
	biburl = {https://dblp.org/rec/journals/iot/TermosGBFJZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The increasing growth of the Internet of Things (IoT) with the diverse and dynamic nature of devices made detecting and preventing network intrusions more important and challenging. As new and sophisticated cyber-attacks are being used, there is an increasing need for advanced intrusion detection systems that can adapt to emerging threats. The majority of existing methods in the literature lack a comprehensive consideration of complex network features namely the centrality measures. Previous works overlooked the potential insights that can be obtained from the structured relationships within network traffic data. In this study, we propose an approach called Graph Deep Learning framework based on Centrality measures (GDLC). Our approach includes an algorithm to dynamically select the most appropriate centrality measures according to the network’s topological properties created from traffic data. After that, they are integrated with Artificial Intelligence (AI) techniques, specifically the deep learning models: CNN, LSTM, and GRU. We tested our methodology on multiple publicly available cybersecurity datasets, having different network structures and sizes. First, we employ the Susceptible Infectious Recovered (SIR) model to validate the importance of the added centrality measures in identifying the most influential nodes that can be the subject of intrusion attacks. Then, through extensive experimentation and evaluation, we test the effectiveness of our approach in improving the accuracy of the Network Intrusion Detection System (NIDS). The obtained results indicate a significant enhancement in detection rates, that can reach up to 7.7%. This improvement demonstrates the practical value of our proposed methodology and highlights its high capacity to adapt to varying network structures. Integrating AI and complex network features is a promising approach for enhancing the capabilities of the Network Intrusion Detection System, contributing to a more resilient cybersecurity framework.}
}


@article{DBLP:journals/iot/NRBBRIP24,
	author = {Mangala N and
                  Naveen D. R. and
                  Eswara Reddy B and
                  Rajkumar Buyya and
                  Venugopal K. R. and
                  S. Sitharama Iyengar and
                  L. M. Patnaik},
	title = {Secure pharmaceutical supply chain using blockchain in IoT cloud systems},
	journal = {Internet Things},
	volume = {26},
	pages = {101215},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101215},
	doi = {10.1016/J.IOT.2024.101215},
	timestamp = {Tue, 24 Dec 2024 22:38:15 +0100},
	biburl = {https://dblp.org/rec/journals/iot/NRBBRIP24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Supply Chain Management (SCM) systems require time sequencing, coordination and tracking the movement of goods and processes. Internet of Things (IoT) and Blockchain technologies are useful to develop a secure automated SCM. IoT devices with in-built sensors and actuators help to keep track of the state, location, temperature or other parameters of an entity, and control the automation of routine as well as hazardous tasks. Blockchain technology supports time-stamping, authentication, process coordination, non-repudiation, commercial transactions, and also provides security for transactions and storage. The pharmaceutical SCM demands accurate, immediate and secure control system. Additionally, the supply chain process data from IoTs is stored and processed in Cloud by Analytics applications, for business planning and improvement. An efficient and secure IoT-Cloud-Blockchain based system for both SCM automation and analytics has been proposed in this work. It leverages a hierarchical IoT, Mist, Edge, Fog, Cloud computing (IMEFC) architecture to enhance Communication-Response-Compute-Security-Storage (CRCSS) in the system. Blockchain technology provides security for the SCM transactions and data. The efficiency of the Blockchain is measured in terms of upload time, download time and transaction fees for Bitcoin, Ethereum and Filecoin platforms. The Filecoin blockchain platform is quicker and cost-effective for larger file sizes, compared to Ethereum and Bitcoin, making it suitable for Pharmaceutical SCM systems.}
}


@article{DBLP:journals/iot/ChungT24,
	author = {Kuo Cheng Chung and
                  Paul Juinn Bing Tan},
	title = {IoT-powered personalization: creating the optimal shopping experience
                  in digital twin VFRs},
	journal = {Internet Things},
	volume = {26},
	pages = {101216},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101216},
	doi = {10.1016/J.IOT.2024.101216},
	timestamp = {Tue, 22 Oct 2024 21:11:35 +0200},
	biburl = {https://dblp.org/rec/journals/iot/ChungT24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A digital twin is a virtual data model that accurately maps and simulates a physical entity. Consumers can use digital twin technology to try on clothes in virtual fitting rooms (VFRs), thereby expressing their individuality. The primary objective of this study is to enhance the understanding of consumers’ psychological state when shopping with VFRs. This will provide managers with a more comprehensive understanding of customer profiles and minimize the cognitive gap between managers and customers. This study primarily utilized Statistical Package for the Social Sciences (SPSS) and partial least squares- structural equation modeling (PLS-SEM) for analysis. The sample consisted of 356 participants from Taiwan, primarily users of VFRs. Bootstrapping of 50,00 iterations was employed to ascertain the significance of the hypotheses. The research reveals that psychological factors such as a sense of ownership control, rehearsability, and self-efficacy significantly enhance self-referencing. This, in turn, significantly influences purchase intentions within VFRs featuring digital avatars. Additionally, perceived augmentation moderates the relationship between a sense of ownership control and self-efficacy. Our primary contribution in this paper is to elucidate customers’ subjective experiences when using VFRs, thereby addressing the dearth of research on VFRs and providing practical insights for industry managers.}
}


@article{DBLP:journals/iot/AbangTAA24,
	author = {Jummai Enare Abang and
                  Haifa Takruri and
                  Rabab Al{-}Zaidi and
                  Mohammed Al{-}Khalidi},
	title = {Latency performance modelling in hyperledger fabric blockchain: Challenges
                  and directions with an IoT perspective},
	journal = {Internet Things},
	volume = {26},
	pages = {101217},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101217},
	doi = {10.1016/J.IOT.2024.101217},
	timestamp = {Mon, 09 Dec 2024 22:47:52 +0100},
	biburl = {https://dblp.org/rec/journals/iot/AbangTAA24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Blockchain is a decentralized and distributed ledger technology that enables secure and transparent recording of transactions across multiple participants. Hyperledger Fabric (HLF), a permissioned blockchain, enhances performance through its modular design and pluggable consensus. However, integrating HLF with enterprise applications introduces latency challenges. Researchers have proposed numerous latency performance modelling techniques to address this issue. These studies contribute to a deeper understanding of HLF’s latency by employing various modelling approaches and exploring techniques to improve network latency. However, existing HLF latency modelling studies lack an analysis of how these research efforts apply to specific use cases. This paper examines existing research on latency performance modelling in HLF and the challenges of applying these models to HLF-enabled Internet of Things (IoT) use cases. We propose a novel set of criteria for evaluating HLF latency performance modelling and highlight key HLF parameters that influence latency, aligning them with our evaluation criteria. We then classify existing papers based on their focus on latency modelling and the criteria they address. Additionally, we provide a comprehensive overview of latency performance modelling from various researchers, emphasizing the challenges in adapting these models to HLF-enabled IoT blockchain within the framework of our evaluation criteria. Finally, we suggest directions for future research and highlight open research questions for further exploration.}
}


@article{DBLP:journals/iot/GarahMK24,
	author = {Abdelhamid Garah and
                  Nader Mbarek and
                  Sergey Kirgizov},
	title = {Enhancing IoT data confidentiality and energy efficiency through decision
                  tree-based self-management},
	journal = {Internet Things},
	volume = {26},
	pages = {101219},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101219},
	doi = {10.1016/J.IOT.2024.101219},
	timestamp = {Mon, 09 Dec 2024 22:47:52 +0100},
	biburl = {https://dblp.org/rec/journals/iot/GarahMK24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Given the widespread deployment of IoT devices characterized by heterogeneity and energy limits, a greater emphasis on IoT data security within IoT environments has become required. This critical situation encouraged the deployment of lightweight encryption solutions to avoid additional attacks. These solutions, which are based on traditional encryption algorithms, are intended to fulfill the demands of resource-constrained devices while maintaining a high security level. In this research, we provide a novel IoT framework that uses lightweight cryptographic ciphers and the Autonomic Computing paradigm to self-manage the security of IoT devices. Our framework is based on a decision tree technique to guarantee the IoT data confidentiality by selecting and changing in an autonomic manner the most appropriate lightweight encryption algorithm to be used in order to improve energy efficiency by extending the lifespan of IoT devices and to provide an adapted security level according to IoT application type and IoT object state.}
}


@article{DBLP:journals/iot/ChengLL24,
	author = {Hanlei Cheng and
                  Sio{-}Long Lo and
                  Jing Lu},
	title = {A blockchain-enabled decentralized access control scheme using multi-authority
                  attribute-based encryption for edge-assisted Internet of Things},
	journal = {Internet Things},
	volume = {26},
	pages = {101220},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101220},
	doi = {10.1016/J.IOT.2024.101220},
	timestamp = {Tue, 22 Oct 2024 21:11:35 +0200},
	biburl = {https://dblp.org/rec/journals/iot/ChengLL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {More edge users opt to use Internet of Things (IoT) devices to collect their data (e.g., health data, social data, e-governance data, etc.), which are stored in central cloud service providers (CSPs). However, this compromises data privacy and creates issues with collusion attacks. Current ciphertext-policy attribute-based encryption (CP-ABE) schemes with and without blockchain have only partially addressed these issues. Ongoing challenges remain to be resolved, including large-universe attribute management, secret key verification, and malicious attribute authorities (AAs) tracking. Therefore, we propose a decentralized access control scheme (namely BLUMA-CPABE) integrating blockchain with multi-authority ciphertext-policy attribute-based encryption (MA-CP-ABE). The scheme not only supports large-universe, policy hiding, and AAs tracking, but it also utilizes on- and off-chain mechanisms to alleviate the computation burden of the blockchain. In addition, we develop a verifiable key distribution approach in which AAs are configured as blockchain consensus nodes capable of issuing, signing, validating, and disseminating secret keys as transactions on-chain. It guarantees the keys’ security and reliability. To incentivize authorities to control newly added attributes proactively for large-universe, we enhance the Proof-of-Authority (called PoA＋) consensus mechanism in multi-authority scenarios. It allows authorities to take turns proposing and confirming new blocks based on three contribution indicators: attribute management contribution, data decryption contribution, and block validation gain. The proposed scheme is proven statically secure while resisting collusion attacks. The experimental results demonstrate the feasibility and efficiency of our scheme.}
}


@article{DBLP:journals/iot/CaballeCS24,
	author = {Santi Caball{\'{e}} and
                  Nicola Capuano and
                  Victor Str{\"{o}}ele},
	title = {Special issue on artificial intelligence of things in education (AIoT
                  in education)},
	journal = {Internet Things},
	volume = {26},
	pages = {101221},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101221},
	doi = {10.1016/J.IOT.2024.101221},
	timestamp = {Mon, 03 Mar 2025 22:14:47 +0100},
	biburl = {https://dblp.org/rec/journals/iot/CaballeCS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{DBLP:journals/iot/LinC24,
	author = {Yu{-}Hsiu Lin and
                  Jian{-}Cheng Ciou},
	title = {A privacy-preserving distributed energy management framework based
                  on vertical federated learning-based smart data cleaning for smart
                  home electricity data},
	journal = {Internet Things},
	volume = {26},
	pages = {101222},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101222},
	doi = {10.1016/J.IOT.2024.101222},
	timestamp = {Tue, 22 Oct 2024 21:11:35 +0200},
	biburl = {https://dblp.org/rec/journals/iot/LinC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Nonintrusive load monitoring (NILM) is a part of home energy management systems ((H)EMSs), which can advance the systems to leverage and use gathered electricity data (load data) to achieve cost-effective load monitoring for efficient (residential) demand-side management (DSM). Load data monitored by existing (H)EMSs, whose load monitoring is based on intrusive load monitoring, can be used as a preliminary stage for NILM to be accelerated in energy management for the improvement of its practicality. However, they can be polluted. For example, power-consumption data gathered by appliance-level smart plugs may have an incorrect appliance label (a mislabeled appliance ID). Polluted data must be preprocessed through a data cleaning process before they are leveraged and used. Data-cleaning approaches that improve data quality should be developed considering a decentralized paradigm, because a centralized data-cleaning paradigm cannot be applied to future edge-based IoT applications. Additionally, preventing data leakage is paramount in data management for numerous field applications. This study develops a privacy-preserving distributed energy management framework based on vertical federated learning for smart data cleaning as a demonstrative application of smart home electricity data toward distributed NILM. The framework developed in this study with the advent of AI methodology can achieve smart data cleaning for further distributed NILM to be accelerated for its practical applications; its feasibility and effectiveness have been verified experimentally.}
}


@article{DBLP:journals/iot/ThakurGF24,
	author = {Dipanwita Thakur and
                  Antonella Guzzo and
                  Giancarlo Fortino},
	title = {Hardware-algorithm co-design of Energy Efficient Federated Learning
                  in Quantized Neural Network},
	journal = {Internet Things},
	volume = {26},
	pages = {101223},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101223},
	doi = {10.1016/J.IOT.2024.101223},
	timestamp = {Mon, 09 Dec 2024 22:47:52 +0100},
	biburl = {https://dblp.org/rec/journals/iot/ThakurGF24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The real-world implementation of federated learning (FL) for smart device-based applications necessitates energy-efficient convergent models due to resource-constrained devices. In the literature, deep learning (DL)–based models are frequently trained on FL to obtain high accuracy and quick convergence employing a 32-bit floating point precision level. However, such circumstances are not feasible for devices with limited resources. DL models demand a significant amount of processing power and energy, which has a noticeable negative impact on the environment. Hence, it is necessary to reduce the level of precision in DL models to enhance energy efficiency. In this paper, we propose a low-precision level green federated learning (GFL) model to maintain the balance of communication cycles, energy efficiency, and accuracy with an admissible convergence rate of the deep learning algorithms. Our proposed GFL framework achieves 98.04% server accuracy and 97.69% federated accuracy with a faster convergence rate and fewer communication rounds than state-of-the-art methods on the UCI human activity recognition dataset.}
}


@article{DBLP:journals/iot/HossainWBF24,
	author = {Md. Razon Hossain and
                  Md Whaiduzzaman and
                  Alistair Barros and
                  Colin J. Fidge},
	title = {Dynamic microservice placement in multi-tier Fog networks},
	journal = {Internet Things},
	volume = {26},
	pages = {101224},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101224},
	doi = {10.1016/J.IOT.2024.101224},
	timestamp = {Mon, 03 Mar 2025 22:14:48 +0100},
	biburl = {https://dblp.org/rec/journals/iot/HossainWBF24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Fog computing extends Cloud-like infrastructure to the Edge, advancing Industrial Internet-of-Things (IIoT) applications in which parts of business-oriented enterprise systems, decoupled via fine-grained microservices, can be deployed in Fog networks in proximity to sensor devices. It boosts the responsiveness to IIoT events significantly where timely decision-making and actions are required, particularly for problematic trends and anomalies. However, microservice placement is a non-trivial problem in IIoT settings, given the dynamic occurrence of different IIoT events and variable resource needs of microservices against resource-constrained, heterogeneous, and distributed Fog devices. The cost of matching and deploying microservices in real-time, highly dynamic, and contentious settings can easily exceed the benefit of just-in-time Edge deployments. Current studies largely focus on managing the microservice placement from Cloud servers and offloading to the Cloud when Fog devices are resource-deficient. Yet, there is a lack of research focusing on efficient Fog resource use and managing the placement at the edge to improve the responsiveness. The complexity increases when multiple inter-dependent microservices with similar priorities are required to be placed on the same Fog devices. To mitigate this, we develop a tiered framework for dynamic microservice placement, in which costly resource decision-making for microservices is dedicated to Master Fog devices and Citizen Fog devices are exclusively assigned to executing microservice requests. Firstly, we implement a priority-based algorithm in each Master Fog device to identify the high-priority Edge-required microservices. Secondly, we sort the Fog devices according to their resource availability and place the microservices based on their priority and dependencies. Thirdly, we implement the strategies for microservice placement, scaling and request escalation in each Master Fog, managing a small number of Citizen Fog devices. These exempt the Citizen Fog devices from common resource and communication management responsibilities and enable them to allocate more resources to Edge-required microservices with a higher number of instances. Finally, we implement and evaluate our framework in a simulated Fog environment. The results outperform state-of-the-art frameworks in terms of efficient resource utilisation, resulting in reduced Cloud dependency by one-third compared to other approaches and average application execution time by 65–70%.}
}


@article{DBLP:journals/iot/CostaSCFSSR24,
	author = {Wesley S. Costa and
                  Willian G. V. dos Santos and
                  Higor Camporez and
                  Menno Jan Faber and
                  Jair A. L. Silva and
                  Marcelo E. V. Segatto and
                  Helder R. O. Rocha},
	title = {Planning and resource allocation of a hybrid IoT network using artificial
                  intelligence},
	journal = {Internet Things},
	volume = {26},
	pages = {101225},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101225},
	doi = {10.1016/J.IOT.2024.101225},
	timestamp = {Mon, 09 Dec 2024 22:47:52 +0100},
	biburl = {https://dblp.org/rec/journals/iot/CostaSCFSSR24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper introduces a pioneering hybrid topology tailored for Internet of Things (IoT) applications, integrating mesh and star wireless sensor configurations. This hybridized approach aims to optimize energy consumption efficiency while ensuring comprehensive network coverage for sensor deployment. The formulation of the network strategy is rooted in empirical data collected from real sensors deployed across two neighboring municipalities within the State of Espírito Santo, Brazil. Specifically, our analysis encompasses 380 strategically positioned sensors throughout Vitória city, all intended for connectivity to a central gateway located in Vila Velha. To establish mesh network clusters, we employed the k-Medoids algorithm for clustering fusion, while the GA with a binary solution was utilized to determine the star network points. In this approach, Dijkstra and genetic algorithms with real solutions are incorporated to facilitate efficient resource allocation within the mesh (utilizing ZigBee) and star (utilizing LoRa) networks. These resource allocation strategies are devised with the overarching objective of minimizing energy consumption. The findings of this investigation demonstrate that through the implementation of planning and resource allocation algorithms, we were able to effectively reduce the number of mesh networks and allocate resources to each designated end-point sensor.}
}


@article{DBLP:journals/iot/GagoFRL24,
	author = {M. Carmen Fern{\'{a}}ndez Gago and
                  Davide Ferraris and
                  Rodrigo Roman and
                  Javier L{\'{o}}pez},
	title = {Trust interoperability in the Internet of Things},
	journal = {Internet Things},
	volume = {26},
	pages = {101226},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101226},
	doi = {10.1016/J.IOT.2024.101226},
	timestamp = {Mon, 09 Dec 2024 22:47:52 +0100},
	biburl = {https://dblp.org/rec/journals/iot/GagoFRL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Internet of Things (IoT) is a paradigm where entities or things are interconnected, often in heterogeneous contexts. As the interconnection happens, things establish collaborations with others, sometimes under uncertainty. Although trust can help us overcome this uncertainty, things might not be able to process the information about trust coming from other things: each thing could have its own trust model, which means its own way to understand and measure trust. If new trust relationships are to be established, it would be desirable to have a mechanism of interoperability that allows the things to process the information about the other things in terms of trust. In this paper, we describe an interoperability framework for tackling the trust interoperability issues in IoT, depending on the different types of trust models that might co-exist in the same IoT scenario.}
}


@article{DBLP:journals/iot/BaoLP24,
	author = {Yun Bao and
                  Pol Llagostera and
                  Llu{\'{\i}}s M. Pl{\`{a}}{-}Aragon{\'{e}}s},
	title = {Is Deep Learning useful for decision making in pig production?},
	journal = {Internet Things},
	volume = {26},
	pages = {101229},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101229},
	doi = {10.1016/J.IOT.2024.101229},
	timestamp = {Tue, 24 Dec 2024 22:38:15 +0100},
	biburl = {https://dblp.org/rec/journals/iot/BaoLP24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Numerous recent papers based on deep learning (DL) have been published covering a wide range of applications to pig production. These applications provide information susceptible of being used to make better decisions. However, the potential use as tools for supporting pig production decisions or the integration in existing or new decision models have not been explored yet. The goal of this systematic literature review (SLR) is to provide an overview of recent developments in cutting-edge DL methodologies proposed in pig production and how they can serve to improve decision making processes. The revised papers are analyzed under different dimensions: (1) authors and research institutions that have made the biggest contributions to DL for image processing, computer vision and other innovative applications in pig farms; (2) coverage of the echelons in the pig supply chain (3) technical aspects like data collection techniques, DL models, DL backbones, graphics processing units (GPUs), and evaluation metrics and (4) value of information. The review is briefly extended to DL applications in other livestock species not yet present in pig production to enrich the discussion. The revised applications suggest that DL is mostly applied to automatize data gathering and processing and to monitor animals or on farm activities. The current challenges and future research agenda are also identified envisioning the integration of DL and operational research(OR) methods as a way to produce more efficient decision-making support tools for the pig industry.}
}


@article{DBLP:journals/iot/HisseineCXA24,
	author = {Mahamat Ali Hisseine and
                  Deji Chen and
                  Yang Xiao and
                  Philip Kofi Alimo},
	title = {A review of digital object architecture and handle system: Development,
                  current applications and prospective},
	journal = {Internet Things},
	volume = {26},
	pages = {101230},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101230},
	doi = {10.1016/J.IOT.2024.101230},
	timestamp = {Mon, 03 Mar 2025 22:14:48 +0100},
	biburl = {https://dblp.org/rec/journals/iot/HisseineCXA24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the continuously growing data, humanity is engaging in a digital age. The importance of data is accentuated, and the future world will presumably be a world of digital objects. That circumstance makes people start thinking of a means to manage and efficiently identify data. The Digital Object Architecture (DOA) is a comprehensive architecture for managing digital objects with a persistent identifier assigned by the Handle System. They are applied in several sectors to manage data. However, their utilization faces some limitations. This paper provides a brief overview and explores their real-world application. It also analyzes those architectures’ challenges and suggest ideas for future research to overcome those challenges. To the best of our knowledge, this will be the first review that elucidates the DOA and the Handle System. The analysis reveals that most of the research focused on three areas: the IoT (Internet of Things) and IIoT (Industrial Internet of Things), educational domain and research, and multimedia content. There are also a few papers on the application in other sectors like logistics and supply chain, authorization, and authentication systems. The study also shows recent interest in the association of DOA and Handle Systems with blockchain.}
}


@article{DBLP:journals/iot/ToonyAAS24,
	author = {Ahmed A. Toony and
                  Fayez Alqahtani and
                  Yasser M. Alginahi and
                  Wael Said},
	title = {{MULTI-BLOCK:} {A} novel ML-based intrusion detection framework for
                  SDN-enabled IoT networks using new pyramidal structure},
	journal = {Internet Things},
	volume = {26},
	pages = {101231},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101231},
	doi = {10.1016/J.IOT.2024.101231},
	timestamp = {Tue, 24 Dec 2024 22:38:15 +0100},
	biburl = {https://dblp.org/rec/journals/iot/ToonyAAS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The ever-expanding Internet of Things (IoT) landscape faces significant security challenges due to limitations in traffic monitoring, device heterogeneity, and weak security practices, leaving networks vulnerable to multi-target and coordinated attacks like large-scale botnets and Distributed Denial-of-Service (DDoS). Existing intrusion detection systems can be computationally expensive and resource-intensive. This can be problematic for resource-constrained IoT devices with limited processing power, memory, and battery life. This paper proposes MULTI-BLOCK, a novel, multi-module framework that leverages machine learning, stateful P4 processing, and a Software-Defined Networking (SDN)-based multi-controller architecture. MULTI-BLOCK tackles critical management tasks within IoT networks, including synchronized communication, traffic monitoring, intrusion detection, and attack mitigation. This comprehensive framework comprises four modules. The first, the proposed pyramidal conceptually decentralized multi-controller structure (PCDMCS), introduces Decentralized Control Interfaces (DCIs) for real-time threat identification through a Decentralized Warning Conduit (DWC). The second module provides comprehensive network monitoring using P4-enabled 24-state tables. The third module leverages 30 new P4-extracted/calculated features and the Enhanced Weighted Ensemble Algorithm (EWEA) for enhanced anomaly detection. The final module presents a novel mitigation approach with 22 steps distributed across multiple controllers for scalability. Extensive evaluation using established IoT datasets (X-IIoTID, TON_IoT, and Edge-IIoTset) and diverse test scenarios (including single-victim and multi-victim attacks) demonstrates MULTI-BLOCK's exceptional performance, achieving high accuracy (99.75 %), precision (99.32 %), F1-score (99.53 %), recall (99.67 %), specificity (99.60 %), low false positive rates (FPR) (0.40 %), and low Average Detection Time (ADT) (2.11 ms). By offering a robust and adaptable solution against evolving threats, MULTI-BLOCK represents a significant advancement in IoT network security.}
}


@article{DBLP:journals/iot/JafariGMSLRAKMC24,
	author = {Amir Reza Jafari and
                  V{\'{\i}}ctor Gonz{\'{a}}lez and
                  Laura Mart{\'{\i}}n and
                  Luis S{\'{a}}nchez and
                  Jorge Lanza and
                  Syed Mohsan Raza and
                  Maira Alvi and
                  Kanawut Kaewnoparat and
                  Roberto Minerva and
                  No{\"{e}}l Crespi},
	title = {Data enrichment toolchain: {A} use-case for correlation analysis of
                  air quality, traffic, and meteorological metrics in Madrid's
                  smart city},
	journal = {Internet Things},
	volume = {26},
	pages = {101232},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101232},
	doi = {10.1016/J.IOT.2024.101232},
	timestamp = {Tue, 24 Dec 2024 22:38:15 +0100},
	biburl = {https://dblp.org/rec/journals/iot/JafariGMSLRAKMC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the era of burgeoning data diversity in heterogeneous sources, unlocking valuable insights becomes pivotal. Raw data often lack context and meaning, necessitating the deployment of services that link and enhance data, thereby extracting meaningful patterns and information. For example, exploring the significance of IoT sensors in measuring air quality across cities emphasizes the potential to establish connections between air quality and associated metrics like traffic intensity and meteorological conditions.}
}


@article{DBLP:journals/iot/BoquetBPDVM24,
	author = {Guillem Boquet and
                  Aleix Boquet{-}Pujadas and
                  Ivan Pisa and
                  Anand Dabak and
                  Xavier Vilajosana and
                  Borja Mart{\'{\i}}nez},
	title = {Indoor position estimation using angle of arrival measurements: An
                  efficient multi-anchor approach with outlier rejection},
	journal = {Internet Things},
	volume = {26},
	pages = {101236},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101236},
	doi = {10.1016/J.IOT.2024.101236},
	timestamp = {Mon, 09 Dec 2024 22:47:53 +0100},
	biburl = {https://dblp.org/rec/journals/iot/BoquetBPDVM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper addresses the inherent nonlinear problem in indoor position estimation utilizing Angle of Arrival (AoA) measurements. We investigate the influence of deployment geometry on system performance through both analytical methods and Monte-Carlo simulations, shedding light on the limitations of single and multi-anchor setups and underscoring the imperative for advanced multi-anchor localization methods. In response to this problem, we propose a multi-anchor solution with outlier rejection that efficiently considers the nonlinearity of the model. For each anchor, our approach approximates the probability distribution of the node position by leveraging a geometrically-derived unscented transformation of AoA estimates. The approximations are then integrated into a majority voting scheme, effectively eliminating outliers induced by multipath or other adverse effects. To derive the final enhanced position estimate, Bayesian inference is applied to fuse the selected information. Finally, the efficacy of the solution is validated conducting a comparative analysis against commonly used approaches in a real-world Bluetooth indoor localization system. The results obtained solely from high-level angular measurements underscore the practicality, robustness and high accuracy of the proposal.}
}


@article{DBLP:journals/iot/PaakkonenHPTB24,
	author = {Pekka P{\"{a}}{\"{a}}kk{\"{o}}nen and
                  Seppo Horsmanheimo and
                  Daniel Pakkala and
                  Lotta Tuomim{\"{a}}ki and
                  Jere Backman},
	title = {Reference architecture design and evaluation for digitalization of
                  underground mining},
	journal = {Internet Things},
	volume = {26},
	pages = {101238},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101238},
	doi = {10.1016/J.IOT.2024.101238},
	timestamp = {Mon, 09 Dec 2024 22:47:52 +0100},
	biburl = {https://dblp.org/rec/journals/iot/PaakkonenHPTB24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Digitalization of underground mining operations requires interaction and interoperability between multiple stakeholders and their technical systems. A reference architecture (RA) facilitating design of multi-stakeholder digital solutions for underground mining would be valuable design knowledge for mining industry digitalization activities and would facilitate the design of concrete architectures to the underground mining context. The main contribution of this work is RA design, which is missing in the current research literature. The RA has empirical foundation on the implementation architectures of two prototypes, which were demonstrated and evaluated in an underground mining environment. The prototypes were evaluated based on several design science research evaluation criteria (feasibility, efficiency, robustness, operability) for fulfilling architectural concerns of related stakeholders. Digital Twin-based modeling, MQTT-based messaging, high accuracy location monitoring of vehicles with Lidars, reliable communication with 5G SA network, and utilization of safety zones and safety messaging for enabling emergency stops were identified as important aspects for RA design. Digital Twin (DT)-based data models focusing on the modeling of mining site, moving vehicles, communication data, and related equipment for the underground mining context may be considered as an additional contribution of our study.}
}
