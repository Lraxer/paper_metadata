@article{DBLP:journals/iot/LeDLRKC24,
	author = {Kim{-}Ngoc Thi Le and
                  Thien{-}Binh Dang and
                  Duc{-}Tai Le and
                  Syed M. Raza and
                  Moonseong Kim and
                  Hyunseung Choo},
	title = {{VEAD:} Variance profile Exploitation for Anomaly Detection in real-time
                  IoT data streaming},
	journal = {Internet Things},
	volume = {25},
	pages = {100994},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2023.100994},
	doi = {10.1016/J.IOT.2023.100994},
	timestamp = {Mon, 25 Nov 2024 22:16:11 +0100},
	biburl = {https://dblp.org/rec/journals/iot/LeDLRKC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The explosion of online streaming services in the Internet-of-Things (IoT) ecosystem poses new difficulties in detecting anomalies in real-time and continuous data. The IoT data anomalies are classified into long-term and short-term, with unique characteristics that make it difficult to develop a common detection mechanism for both. The existing techniques require excessive training data and suffer from high variability. This paper overcomes these challenges by proposing a Variance profile Exploitation for Anomaly Detection (VEAD) scheme using discrete wavelet transform and k-means clustering. VEAD is initialized by a fast training phase with a single data segment, from which a sensor variance profile is created. This variance profile reflects the degree of deviation in the collected data from different sensors at a specific time period and is continuously updated by integrating new data segments for effective anomaly detection. Overlapping data collection in the detection phase shows correlations among consecutive data segments, leading to improved detection accuracy (ACC). The Intel Berkeley Research Lab dataset with injected synthetic anomalies is used to perform numerical experiments. A comparative performance evaluation with state-of-the-art methods confirms the effectiveness of VEAD in achieving a higher ACC and a lower false-positive rate (FPR). Notably, 95% and 97% ACCs are achieved in detecting long-term and short-term anomalies, respectively. The high specificity of VEAD is also revealed by the low FPR of at most 2% in all cases. The low computational complexity and fast anomaly detection make VEAD suitable for deployment in live systems with massive data streams.}
}


@article{DBLP:journals/iot/RubioCMCVL24,
	author = {Ana Rubio and
                  Rub{\'{e}}n Cantarero and
                  Alessandro Margara and
                  Gianpaolo Cugola and
                  David Villa and
                  Juan Carlos L{\'{o}}pez},
	title = {Commonsense reasoning and automatic generation of IoT contextual knowledge:
                  An Answer Set Programming approach},
	journal = {Internet Things},
	volume = {25},
	pages = {100998},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2023.100998},
	doi = {10.1016/J.IOT.2023.100998},
	timestamp = {Fri, 22 Mar 2024 08:58:41 +0100},
	biburl = {https://dblp.org/rec/journals/iot/RubioCMCVL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The increasing interest in searching for intelligent, proactive, and autonomous environments leads to the necessity of accessing contextual knowledge: knowledge about changes that occur in the environment and even about the capabilities of the devices that compose a specific deployment. This knowledge would allow carrying out commonsense reasoning (exhibit human-like comprehension) according to the current situation, enabling decision making and task planning. One of the most used forms of knowledge specification is ontologies, but ontological knowledge modeling is usually a manual process, making it a costly task. In addition, ontologies can be found that have been designed for specifying knowledge about IoT-related concepts, but many are overly complex or do not have an adequate orientation that allows modeling the system’s capabilities. There are many different types of reasoners, but Answer Set Solvers are of particular interest for commonsense reasoning. This paper proposes an ontology to represent contextual knowledge about IoT device capabilities, and an Answer Set Programming-based reasoner for the automatic generation of this knowledge. The main challenge is to demonstrate that contextual knowledge can be generated through commonsense reasoning processes implemented with Answer Set Programming, and that the resulting knowledge can be used for decision making (also through commonsense reasoning). This work shows how the generated knowledge is correct through different use cases, presents an application example that demonstrates the benefits of using the generated knowledge, and analyzes the reasoner performance to demonstrate that the execution time is adequate.}
}


@article{DBLP:journals/iot/MoznyMMSMKH24,
	author = {Radek Mozny and
                  Pavel Masek and
                  Dmitri Moltchanov and
                  Martin Stusek and
                  Petr Mlynek and
                  Yevgeni Koucheryavy and
                  Jiri Hosek},
	title = {Characterizing optimal {LPWAN} access delay in massive multi-RAT smart
                  grid deployments},
	journal = {Internet Things},
	volume = {25},
	pages = {101001},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2023.101001},
	doi = {10.1016/J.IOT.2023.101001},
	timestamp = {Sun, 04 Aug 2024 19:51:17 +0200},
	biburl = {https://dblp.org/rec/journals/iot/MoznyMMSMKH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Massive machine-type communications services penetrating the market, such as smart grids, differ from conventional services characterized by stochastic arrival patterns. Requiring permanent end device (ED) connectivity, control centers poll EDs over regular time intervals, leading to batch message arrivals that affect the mean access delay at the air interface. In addition, the smart grid requires high reliability and network availability that can be achieved by utilizing multiple radio access technologies in EDs. Radio access technologies (RATs), i.e., narrowband internet of things (NB-IoT) and long-term evolution machine type communication (LTE-M), have been identified as promising solutions for these use-cases. This work first reports results of an extensive performance evaluation measurement campaign showing that LTE-M can be considered a preferred option and NB-IoT as a possible backup solution for smart grids. We also show that none of the selected technologies can fully meet the requirements of smart grid use cases. We then develop a theoretical model and corresponding association algorithm for balancing traffic load between two low-power wide area network (LPWAN) technologies to minimize the mean access delay. Our results demonstrate that the optimized usage of multi-RAT EDs considerably increases the number of supported EDs operating in polling-based mode. For 500 EDs utilizing a single LTE-M technology, the mean access delay is over two seconds — contradicting the minimum requirements of smart grid applications. On the other hand, multi-RAT EDs running the developed algorithm increase the service capacity by up to six times (up to 3000 EDs) while still satisfying the two-second latency budget.}
}


@article{DBLP:journals/iot/MRHKC24,
	author = {Kiran M. and
                  Biplob Ray and
                  Jahan Hassan and
                  Aman Kashyap and
                  Varun Yarehalli Chandrappa},
	title = {Blockchain based secure Ownership Transfer Protocol for smart objects
                  in the Internet of Things},
	journal = {Internet Things},
	volume = {25},
	pages = {101002},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2023.101002},
	doi = {10.1016/J.IOT.2023.101002},
	timestamp = {Tue, 03 Dec 2024 17:09:08 +0100},
	biburl = {https://dblp.org/rec/journals/iot/MRHKC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Secure digital ownership transfer is critical for smart objects within the Internet of Things (IoT) ecosystem. This paper presents the Ownership Transfer Protocol (OTP), which leverages Physically Unclonable Function (PUF) and blockchain technology to ensure the secure transfer of ownership for smart objects in the IoT. The proposed protocol can securely track and trace smart objects during their movement in the IoT supply chain. Unlike the traditional Ownership Transfer (OT) architecture, the proposed architecture does not require a Trusted Third Party (TTP) and can support Partial Ownership Transfer (POT). The innovative use of immutable blockchain architecture enabled the proposed protocol to effectively support distributed environments and authenticate both the device and involved parties. The proposed protocol is evaluated for its robustness against common attacks outlined in this paper and implemented using the Ethereum blockchain. The testbed results on Ethereum confirm the optimal gas consumption of the proposed model. Furthermore, utilizing the security claim verification tool, Scyther, the experiment validates the security claim regarding the communication between the parties involved in the proposed protocol’s OT process.}
}


@article{DBLP:journals/iot/MohanSKA24,
	author = {Vamshi Sunku Mohan and
                  Sriram Sankaran and
                  Vireshwar Kumar and
                  Krishnashree Achuthan},
	title = {EP-CuMAC: Energy and performance-efficient integrity protection for
                  narrow-band IoT},
	journal = {Internet Things},
	volume = {25},
	pages = {101004},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2023.101004},
	doi = {10.1016/J.IOT.2023.101004},
	timestamp = {Mon, 01 Apr 2024 11:15:32 +0200},
	biburl = {https://dblp.org/rec/journals/iot/MohanSKA24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Narrowband Internet of Things (NB-IoT) is a LPWAN radio standard developed by 3GPP to provide devices with longer battery life and broader coverage. Many authors have proposed algorithms to maximise battery life by optimising devices’ Active periods. However, more research is required to develop integrity-protection algorithms for NB-IoT and study their impact on battery life. NB-IoT, being bandwidth-constrained, transmits data as truncated packets at discrete intervals to maximise battery life. However, truncated MACs reduce cryptographic strength leading to brute-force attacks. Cumulative MAC (CuMAC), generating 256-bit authentication tags by aggregating truncated MACs, alleviates this limitation. However, CuMAC is prone to replay attacks and reduced performance due to re-transmissions, resulting in delayed responses, packet loss and battery overhead. In this paper, we propose Energy-Performance CuMAC (EP-CuMAC) by modifying CuMAC to overcome inherent flaws and suit NB-IoT’s requirements. Feedback-based mechanism is developed to improve channel quality by regulating abnormal packet delays and SINR. Machine and deep learning algorithms predict and authenticate lost messages and tags to minimise re-transmissions. EP-CuMAC re-transmits the aggregated lost packets and new messages in upcoming Active state to reduce re-transmissions. Energy-performance-security trade-offs of EP-CuMAC are studied for various encryption parameters using ns-3 and Raspberry Pi. Although EP-CuMAC consumes approximately 17.73%, 33.33% and 45.59% power, memory and execution time, respectively and thrice the re-transmitted aggregated-packet authentication time compared to CuMAC, it has 68.42% enhanced packet delivery ratio and 66.66% higher security against replay attacks. Our analysis reveals that EP-CuMAC can effectively replace CuMAC as lightweight and performance-efficient alternative for NB-IoT.}
}


@article{DBLP:journals/iot/BelliBP24,
	author = {Dimitri Belli and
                  Paolo Barsocchi and
                  Filippo Palumbo},
	title = {Connectivity Standards Alliance Matter: State of the art and opportunities},
	journal = {Internet Things},
	volume = {25},
	pages = {101005},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2023.101005},
	doi = {10.1016/J.IOT.2023.101005},
	timestamp = {Sat, 08 Jun 2024 13:15:49 +0200},
	biburl = {https://dblp.org/rec/journals/iot/BelliBP24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Matter is an open-source, royalty-free connectivity standard developed by the Connectivity Standards Alliance (CSA-IoT). It aims to unify smart home devices and increase their compatibility across various ecosystems. Backed by major tech companies like Apple, Google, Amazon, and the Zigbee Alliance, Matter simplifies the development of IoT devices by providing a unified approach to connectivity. It offers a secure, reliable, and seamless way for devices to communicate and interact, regardless of the manufacturer.}
}


@article{DBLP:journals/iot/TradaceteAgredaGSHCS24,
	author = {Miguel Tradacete{-}{\'{A}}greda and
                  Enrique Santiso G{\'{o}}mez and
                  Francisco Javier Rodr{\'{\i}}guez Sanchez and
                  Pablo Jos{\'{e}} Hueros{-}Barrios and
                  Jos{\'{e}} Antonio Jim{\'{e}}nez Calvo and
                  Carlos Santos{-}P{\'{e}}rez},
	title = {High-performance IoT Module for real-time control and self-diagnose
                  {PV} panels under working daylight and dark electroluminescence conditions},
	journal = {Internet Things},
	volume = {25},
	pages = {101006},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2023.101006},
	doi = {10.1016/J.IOT.2023.101006},
	timestamp = {Sat, 08 Jun 2024 13:15:49 +0200},
	biburl = {https://dblp.org/rec/journals/iot/TradaceteAgredaGSHCS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This article examines the needs of future solar photovoltaic modules in relation to monitoring and optimizing their performance, and it presents the design of a new IoT module that aims to meet these needs. The proposed IoT Module provides a hardware and software platform applied to individual PV panels within PV strings. It introduces innovative capabilities such as real-time and precise monitoring at high rate for individual PV panels, local processing of collected information within the module, and active control actions at PV panel level. These actions include connection/disconnection and active bypass within the PV string, both during daylight generation and dark EL testing conditions. The IoT module allows each panel to acquire electrical and environmental data, trace I–V curves, reconfigure its connections within a PV string, and conduct individual EL testing. It also incorporates Wi-Fi and BLE communication protocols, enabling communication with other panels and IoT devices. Thus, it can coordinate certain reconfiguration actions and locally apply distributed algorithms for edge computing. As an example, a distributed algorithm for marginal partial-shading anomaly detection is included to demonstrate the abilities of the IoT Modules to self-diagnose and perform edge-computing processing. The functionality and performance of the IoT Module are verified through simulations and experimental tests. The results confirm that the designed IoT module provides a novel monitoring and management solution for PV panels, enabling them to enhance their performance and progress towards PV digitization.}
}


@article{DBLP:journals/iot/ZhengWCZHJ24,
	author = {Yali Zheng and
                  Chen Wu and
                  Peizheng Cai and
                  Zhiqiang Zhong and
                  Hongda Huang and
                  Yuqi Jiang},
	title = {Tiny-PPG: {A} lightweight deep neural network for real-time detection
                  of motion artifacts in photoplethysmogram signals on edge devices},
	journal = {Internet Things},
	volume = {25},
	pages = {101007},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2023.101007},
	doi = {10.1016/J.IOT.2023.101007},
	timestamp = {Sat, 08 Jun 2024 13:15:49 +0200},
	biburl = {https://dblp.org/rec/journals/iot/ZhengWCZHJ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Photoplethysmogram (PPG) signals are easily contaminated by motion artifacts in real-world settings, despite their widespread use in Internet-of-Things (IoT) based wearable and smart health devices for cardiovascular health monitoring. This study proposed a lightweight deep neural network, called Tiny-PPG, for accurate and real-time PPG artifact segmentation on IoT edge devices. The model was trained and tested on a public dataset, PPG DaLiA, which featured complex artifacts with diverse lengths and morphologies during various daily activities of 15 subjects using a watch-type device (Empatica E4). The model structure, training method and loss function were specifically designed to balance detection accuracy and speed for real-time PPG artifact detection in resource-constrained embedded devices. To optimize the model size and capability in multi-scale feature representation, the model employed depth-wise separable convolution and atrous spatial pyramid pooling modules, respectively. Additionally, the contrastive loss was also utilized to further optimize the feature embeddings. With additional model pruning, Tiny-PPG achieved state-of-the-art detection accuracy of 87.4% while only having 19,726 model parameters (0.15 megabytes), and was successfully deployed on an STM32 embedded system for real-time PPG artifact detection. Therefore, this study provides an effective solution for resource-constraint IoT smart health devices in PPG artifact detection.}
}


@article{DBLP:journals/iot/NavarroFAFLD24,
	author = {Jorge Navarro and
                  Rub{\'{e}}n R. Fern{\'{a}}ndez and
                  V{\'{\i}}ctor Ace{\~{n}}a and
                  Alberto Fern{\'{a}}ndez{-}Isabel and
                  Carmen Lancho and
                  Isaac Mart{\'{\i}}n de Diego},
	title = {Real-time classification of cattle behavior using Wireless Sensor
                  Networks},
	journal = {Internet Things},
	volume = {25},
	pages = {101008},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2023.101008},
	doi = {10.1016/J.IOT.2023.101008},
	timestamp = {Tue, 07 May 2024 20:25:59 +0200},
	biburl = {https://dblp.org/rec/journals/iot/NavarroFAFLD24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The detection of activity and behavioral patterns using accelerometers in humans has been a longstanding research. Progress in this field has been successfully transferred to the study of animal behavior thanks to the emergence of new Internet of Things (IoT) technologies such as Wireless Sensor Networks (WSNs) and the need for more complex behavioral information. All the systems proposed by the scientific community have been evaluated in terms of classification performance. However, not many studies consider the potential loss of accuracy undergone when these systems are deployed in WSNs, given the low computational capacities of their nodes and the need for a low energy consumption. This paper proposes a behavioral pattern classification system for four types of animal behavior in free-range grazing cattle along with an optimal and a restricted configuration thereof. The evaluation of this system takes into account its classification performance and its expected accuracy under the limited resources that WSNs can offer. The results show that the optimal configuration improves the performance of its alternatives by an average of 9% and the restricted configuration by an average of 6%. Moreover, as part of a WSN, the results demonstrate a flawless accuracy in the optimal and restricted configurations for walking (100% and 100%), almost perfect for grazing (98.39% and 98.59%), and acceptable for lying (79.03% and 69.01%) and standing (75.81% and 70.42%). In conclusion, the proposed system represents a powerful tool for analyzing complex behaviors in cattle through the use of WSNs.}
}


@article{DBLP:journals/iot/RamosSorrocheRSGE24,
	author = {Emilio Ramos{-}Sorroche and
                  Jesus Rubio{-}Aparicio and
                  Jos{\'{e}} Santa and
                  Carlos Guardiola and
                  Esteban Egea{-}L{\'{o}}pez},
	title = {In-cabin and outdoor environmental monitoring in vehicular scenarios
                  with distributed computing},
	journal = {Internet Things},
	volume = {25},
	pages = {101009},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2023.101009},
	doi = {10.1016/J.IOT.2023.101009},
	timestamp = {Sat, 08 Jun 2024 13:15:49 +0200},
	biburl = {https://dblp.org/rec/journals/iot/RamosSorrocheRSGE24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Accurate environmental monitoring is becoming the basis for assuring sustainable development in administrations at different levels, including cities and industry as key actors. However, current techniques rely on static stations that may not be representative of larger areas, for the case of outdoor scenarios, or even not considering indoor spaces where people can remain for long periods. This is the case of vehicles. The COVID-19 pandemic has remarked the importance of measuring air quality indoors, for instance. With the aim of solving this two-fold issue, this work proposes an in-cabin and outdoor air pollution monitoring system to assure healthy conditions when travelling, driving and operating vehicles, and to analyse the evolution of environmental parameters in cities. This effort is carried out exploiting distributed computing with micro-services, betting for an on-board hardware solution provided with sensors for measuring particulate matter, CO, CO\n, NO\n, O\n, temperature and humidity. While basic data pre-processing is carried out in this acquisition unit, edge processing is performed on a single board computer aboard and intermediary communication nodes in the network path from the vehicle to the cloud. Vehicle connectivity is provided by 4G cellular and Low-Power Wide-Area (LPWAN) networks. Global environmental perception is acquired by cloud-based software powered by machine learning and time series analysis. The whole solution has been validated and tested in the city of Cartagena (Spain), with good performance in terms of data collection, communication links and service offered.}
}


@article{DBLP:journals/iot/AhmedHH24,
	author = {Mohammed Mostafa Ahmed and
                  Ehab Ezat Hassanien and
                  Aboul Ella Hassanien},
	title = {A smart IoT-based monitoring system in poultry farms using chicken
                  behavioural analysis},
	journal = {Internet Things},
	volume = {25},
	pages = {101010},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2023.101010},
	doi = {10.1016/J.IOT.2023.101010},
	timestamp = {Fri, 22 Mar 2024 08:58:41 +0100},
	biburl = {https://dblp.org/rec/journals/iot/AhmedHH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Poultry farming is crucial to feeding the world's growing population. Birds' abnormal behaviour can harm the birds, and disease detection relies on poultry behaviour. Integrating Internet of Things (IoT) technology into poultry farming can revolutionize the way to monitor and manage poultry health. Feeding, preening, and dustbathing are poultry's daily routines. In response to the problem of detecting correct poultry behaviour and health status, this paper proposes a smart poultry monitoring system that leverages IoT sensors to detect and monitor chicken behaviour in poultry farms and provides valuable information to industry stakeholders for management decisions and individual poultry health status. The phases of the proposed system are data preprocessing, feature extraction, feature selection, and detection of poultry behaviour via different classification algorithms. An optimized synthetic minority over-sampling technique (SMOTE) via an artificial hummingbird algorithm (AHA) is applied to solve the data imbalance problem. The experimental results show that an optimized SMOTE obtains better accuracy with 97 % than other algorithms. Further, to attain accuracy in predicting poultry behaviours, Random Forest (RF) achieves superiority compared to other machine learning algorithms with an accuracy of 98 %.}
}


@article{DBLP:journals/iot/ChenCD24,
	author = {Xuechen Chen and
                  Chuang Chen and
                  Xiaoheng Deng},
	title = {Distributed soft video transmission based on hybrid digital and analog
                  scheme},
	journal = {Internet Things},
	volume = {25},
	pages = {101011},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2023.101011},
	doi = {10.1016/J.IOT.2023.101011},
	timestamp = {Fri, 22 Mar 2024 08:58:42 +0100},
	biburl = {https://dblp.org/rec/journals/iot/ChenCD24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This study presents a novel distributed soft video delivery scheme using hybrid digital and analog framework, which realizes a relatively lightweight encoder as well as good robustness. Specifically, after applying scalar quantization to the interframes, the scaled analog information (quantization error) and the scaled digital information (quantized source) are superimposed and then transmitted. In this way, the proposed scheme directly delivers pseudo-analog symbols over the orthogonal frequency division multiplexing (OFDM) channels and involves no complicated digital codec. Moreover, we utilize cross-frame correlation to implement a distributed paradigm which further reduces the encoder complexity since the complex motion estimation and compensation algorithms are transferred to the decoder. Accordingly, the power distortion optimization scheme, which resolve the allocation of power and the parameters optimization to achieve minimum transmission distortion, is proposed. To solve it, first, we formulate the power distortion expressions regarding quantization parameters and power allocation coefficients. Subsequently, we divide the problem into two sub-problems based on the fast coordinate descent method and further propose a greedy iterative algorithm to optimize them. We also develop a data-driven optimization algorithm based on deep learning that reduces the additional delay brought by the iterative optimization method. At the receiver, we estimate the quantization output and quantization error by the modified linear least squares estimation with the virtual noise variance. Based on the simulation results, the proposed framework has a better performance in terms of peak signal-to-noise ratio and structural similarity than the relevant cutting-edge schemes while maintaining good robustness.}
}


@article{DBLP:journals/iot/AygulMKKG24,
	author = {Kemal Aygul and
                  Mostafa Mohammadpourfard and
                  Mert Kesici and
                  Fatih Kucuktezcan and
                  Istemihan Genc},
	title = {Benchmark of machine learning algorithms on transient stability prediction
                  in renewable rich power grids under cyber-attacks},
	journal = {Internet Things},
	volume = {25},
	pages = {101012},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2023.101012},
	doi = {10.1016/J.IOT.2023.101012},
	timestamp = {Mon, 03 Mar 2025 22:14:47 +0100},
	biburl = {https://dblp.org/rec/journals/iot/AygulMKKG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This study addresses the problem of ensuring accurate online transient stability prediction in modern power systems that are increasingly dependent on smart grid technology and are thus susceptible to cyber-attacks. Despite technological advancements, a considerable gap remains in the resilience of machine learning algorithms for stability prediction, which are not yet adequately equipped to counter the sophisticated and evolving nature of cyber threats. The research further assesses how cyber-attacks, alongside the integration of renewable energy and topological changes, affect these machine learning-based methods. Employed online, transient stability prediction methods are vital for real-time monitoring and forecasting of power system behavior in response to disturbances. Recognizing that attackers can disrupt communication and consequently manipulate the power system, the study simulates various scenarios to test the robustness of the proposed algorithms. Findings indicate that under cyber-attacks, machine learning algorithms underperform, leading to a significant decrease in the accuracy of transient stability predictions compared to those in normal operating conditions. This underlines the pressing need for advanced cybersecurity measures to safeguard the predictive capabilities of power systems.}
}


@article{DBLP:journals/iot/SiddiqueADBAA24,
	author = {Ali Akbar Siddique and
                  Nada Alasbali and
                  Maha Driss and
                  Wadii Boulila and
                  Mohammed S. Alshehri and
                  Jawad Ahmad},
	title = {Sustainable collaboration: Federated learning for environmentally
                  conscious forest fire classification in Green Internet of Things (IoT)},
	journal = {Internet Things},
	volume = {25},
	pages = {101013},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2023.101013},
	doi = {10.1016/J.IOT.2023.101013},
	timestamp = {Sun, 04 Aug 2024 19:51:17 +0200},
	biburl = {https://dblp.org/rec/journals/iot/SiddiqueADBAA24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Forests are an invaluable natural resource, playing a crucial role in the regulation of both local and global climate patterns. Additionally, they offer a plethora of benefits such as medicinal plants, food, and non-timber forest products. However, with the growing global population, the demand for forest resources has escalated, leading to a decline in their abundance. The reduction in forest density has detrimental impacts on global temperatures and raises the likelihood of forest fires. To address these challenges, this paper introduces a Federated Learning framework empowered by the Internet of Things (IoT). The proposed framework integrates with an Intelligent system, leveraging mounted cameras strategically positioned in highly vulnerable areas susceptible to forest fires. This integration enables the timely detection and monitoring of forest fire occurrences and plays its part in avoiding major catastrophes. The proposed framework incorporates the Federated Stochastic Gradient Descent (FedSGD) technique to aggregate the global model in the cloud. The dataset employed in this study comprises two classes: fire and non-fire images. This dataset is distributed among five nodes, allowing each node to independently train the model on their respective devices. Following the local training, the learned parameters are shared with the cloud for aggregation, ensuring a collective and comprehensive global model. The effectiveness of the proposed framework is assessed by comparing its performance metrics with the recent work. The proposed algorithm achieved an accuracy of 99.27 % and stands out by leveraging the concept of collaborative learning. This approach distributes the workload among nodes, relieving the server from excessive burden. Each node is empowered to obtain the best possible model for classification, even if it possesses limited data. This collaborative learning paradigm enhances the overall efficiency and effectiveness of the classification process, ensuring optimal results in scenarios where data availability may be constrained.}
}


@article{DBLP:journals/iot/LeeKKY24,
	author = {Chanhyuk Lee and
                  Jisoo Kim and
                  Heedong Ko and
                  Byounghyun Yoo},
	title = {Addressing IoT storage constraints: {A} hybrid architecture for decentralized
                  data storage and centralized management},
	journal = {Internet Things},
	volume = {25},
	pages = {101014},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2023.101014},
	doi = {10.1016/J.IOT.2023.101014},
	timestamp = {Sat, 08 Jun 2024 13:15:49 +0200},
	biburl = {https://dblp.org/rec/journals/iot/LeeKKY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As blockchain and AI technologies advance, industrial applications increasingly rely on IoT devices for continuous, massive data collection. However, these devices have storage limitations when dealing with extensive data streams. The InterPlanetary File System (IPFS), a decentralized storage solution, addresses these constraints. However, IPFS's significant time requirement for data recording introduces a new challenge. Furthermore, its Content IDentifiers (CIDs) do not inherently convey the source device's identity or associated metadata, adding complexity to specific condition-based data retrieval. These factors hinder the discernment of the current data state, preventing IoT devices from clearing storage space by deleting unnecessary data. Consequently, this results in inadequate storage capacity for IoT devices, posing an obstacle to collecting and transmitting large data. Our study proposes a hybrid architecture to address these challenges, integrating the decentralized storage capabilities of IPFS with a centralized CID management system. This architecture employs Message Queuing Telemetry Transport (MQTT) for efficient CID transfer and a database for archiving CID values and associated metadata. Using the archived metadata, IoT devices determine the status of the data and perform tasks accordingly. This enables effective storage management for IoT devices by removing data that has already been uploaded and is safe for deletion. Our architecture demonstrates versatility, accommodating data of varying sizes, formats, and frequencies. We validated our approach through an extensive 100-hour experiment, successfully collecting 356 GB of data from diverse sensors. These results underscore the robustness and adaptability of our architecture, emphasizing its potential for a range of IoT applications.}
}


@article{DBLP:journals/iot/Alamer24,
	author = {Abdulrahman Alamer},
	title = {A privacy-preserving federated learning with a secure collaborative
                  for malware detection models using Internet of Things resources},
	journal = {Internet Things},
	volume = {25},
	pages = {101015},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2023.101015},
	doi = {10.1016/J.IOT.2023.101015},
	timestamp = {Fri, 22 Mar 2024 08:58:43 +0100},
	biburl = {https://dblp.org/rec/journals/iot/Alamer24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The rise in malware attacks presents a growing security threat in today’s digital landscape, emphasizing the need for advanced malware detection methodology. While numerous detection systems utilizing methodologies like machine learning (ML) have been developed, they often fail to detect new and unknown malware in real time. This is because their malware datasets are generated with a very limited source and are not dynamic for up-to-date malware. Thus, with of the growth of the Internet of Things, malware have also increasingly grown, which makes current malware detection systems outdated in a short time. Therefore, IoT device resources can be exploited for building malware datasets having various types of malware families. In addition, the approach of collecting data from IoT devices and training them in a centralized cloud (CC) server is no longer acceptable due to this approach incurs significant security and privacy issues. This paper proposes PPFL-SC, an efficient privacy-preserving federated learning with a secure collaborative supporting verification. A group-oblivious signcryption cryptography is designed to be used as a privacy-preserving technique for federated learning. The CC server aggregates data without compromising individual data privacy. Moreover, the Stackelberg incentive model is designed as an incentive mechanism for encouraging IoT devices to collaborate through their heterogeneous dataset in a malware detection model. Thus, the proposed incentive mechanism is capable of increasing the participation of IoT devices and decreasing their dropping out during model updating. A security analysis confirms that PPFL-SC fulfills all security requirements for privacy-preserving federated learning. Real-world dataset experiments validate the efficiency and practicality of the proposed PPFL-SC.}
}


@article{DBLP:journals/iot/IslamMDJS24,
	author = {Khondoker Ziaul Islam and
                  David Murray and
                  Dean Diepeveen and
                  Michael G. K. Jones and
                  Ferdous Sohel},
	title = {LoRa-based outdoor localization and tracking using unsupervised symbolization},
	journal = {Internet Things},
	volume = {25},
	pages = {101016},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2023.101016},
	doi = {10.1016/J.IOT.2023.101016},
	timestamp = {Sun, 04 Aug 2024 19:51:17 +0200},
	biburl = {https://dblp.org/rec/journals/iot/IslamMDJS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper proposes a long-range (LoRa)-based outdoor localization and tracking method. Our method presents an unsupervised localization approach that utilizes symbolized LoRa received signal features, such as RSSI, SNR, and path loss, where each symbol represents a system state. To identify the partitioning boundaries between the symbols in time series, we employ maximum entropy partitioning. The D-Markov machine is used to construct nondeterministic finite-state automata for extracting temporal patterns. We incorporate the Chinese restaurant process for online estimation, especially in scenarios with an unbounded number of probable areas around each LoRa gateway. An adaptive trilateration approach is then used to localize the target node from the estimated ranged radii of areas. The point-wise localization data was used for time-series continuous tracking. We collected a dataset using three LoRaWAN gateways, sensor nodes powered by single-use batteries, and a Chirpstack server on a sports oval. We thoroughly evaluated the proposed method from the perspectives of localization accuracy and tracking capability. Our method outperformed state-of-the-art machine learning-driven range-based and fingerprint-based localization techniques.}
}


@article{DBLP:journals/iot/HuynhLLLD24,
	author = {Hiep Xuan Huynh and
                  Bao Hoai Lam and
                  Hung Vu Cong Le and
                  Tam Thanh Le and
                  Nghia Duong{-}Trung},
	title = {Design of an IoT ultrasonic-vision based system for automatic fruit
                  sorting utilizing size and color},
	journal = {Internet Things},
	volume = {25},
	pages = {101017},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2023.101017},
	doi = {10.1016/J.IOT.2023.101017},
	timestamp = {Mon, 01 Apr 2024 11:15:32 +0200},
	biburl = {https://dblp.org/rec/journals/iot/HuynhLLLD24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {While integrating mechanical conveyor chains and object sorting automation with an Internet of Things (IoT) system can present exciting and challenging opportunities, the potential benefits of increased efficiency, real-time tracking, and predictive maintenance make it valuable. Machine learning techniques, precise computer vision, and ultrasonic technology have proven to be powerful tools for accurately detecting and differentiating fruits based on color and size. In light of this, a proposed solution is developing an automatic IoT system comprising a mechanical conveyor chain, wooden sorting trays, ultrasonic sensors, a fisheye camera, Raspberry Pi, and other necessary components. This system can detect and sort fruits such as apples, oranges, lemons, tangerines, bananas, and avocados into four customizable trays, with a sorting accuracy of 90%. Moreover, the system can be easily adapted and expanded to support more sorting trays and a more comprehensive range of agricultural products.}
}


@article{DBLP:journals/iot/RodriguezCNQ24,
	author = {Aurora Polo Rodr{\'{\i}}guez and
                  Filippo Cavallo and
                  Chris D. Nugent and
                  Javier Medina Quero},
	title = {Human activity mining in multi-occupancy contexts based on nearby
                  interaction under a fuzzy approach},
	journal = {Internet Things},
	volume = {25},
	pages = {101018},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2023.101018},
	doi = {10.1016/J.IOT.2023.101018},
	timestamp = {Mon, 03 Mar 2025 22:14:48 +0100},
	biburl = {https://dblp.org/rec/journals/iot/RodriguezCNQ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Multioccupation encompasses real-life environments in which people interact in the same common space. Recognizing activities in this context for each inhabitant has been challenging and complex. This work presents a fuzzy knowledge-based system for mining human activities in multi-occupancy contexts based on nearby interaction based on the Ultra-wideband. First, interest zone spatial location is modelled using a straightforward fuzzy logic approach, enabling discriminating short-term event interactions. Second, linguistic protoforms use fuzzy rules to describe long-term events for mining human activities in a multi-occupancy context. A data set with multimodal sensors has been collected and labelled to exhibit the application of the approach. The results show an encouraging performance (0.9 precision) in the discrimination of multiple occupations.}
}


@article{DBLP:journals/iot/DharKDS24,
	author = {Shalini Dhar and
                  Ashish Khare and
                  Ashutosh Dhar Dwivedi and
                  Rajani Singh},
	title = {Securing IoT devices: {A} novel approach using blockchain and quantum
                  cryptography},
	journal = {Internet Things},
	volume = {25},
	pages = {101019},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2023.101019},
	doi = {10.1016/J.IOT.2023.101019},
	timestamp = {Sat, 08 Jun 2024 13:15:49 +0200},
	biburl = {https://dblp.org/rec/journals/iot/DharKDS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper delves into the crucial challenge of safeguarding data sensitivity and preventing security breaches, which can result in substantial losses, including significant financial costs and potential loss of lives. Notably, the United States faces the highest financial burden, with data breaches costing approximately USD 5.09 million. With the proliferation of Internet of Things (IoT) devices, enormous volumes of data are collected from diverse sources. However, the inherent limitations in computational power and memory of IoT devices render them susceptible targets for malicious attacks. This study focuses on fortifying the security of multimedia data, encompassing audio, video, and images, obtained from IoT devices. Cutting-edge technologies such as blockchain and quantum cryptography are explored as promising avenues to bolster multimedia security and preserve privacy. Quantum Key Distribution (QKD) emerges as an alternative to classical encryption and key distribution methods, offering heightened data security. Simultaneously, blockchain leverages hash functions to augment the overall security posture. By harnessing the principles of quantum mechanics, QKD facilitates secure key exchange between involved parties for data encryption and decryption. Additionally, the paper introduces innovative methodologies to enhance the security, privacy, and anonymity of IoT devices.}
}


@article{DBLP:journals/iot/KadriABM24,
	author = {Mohamed Riadh Kadri and
                  Abdelkrim Abdelli and
                  Jalel Ben{-}Othman and
                  Lynda Mokdad},
	title = {Survey and classification of Dos and DDos attack detection and validation
                  approaches for IoT environments},
	journal = {Internet Things},
	volume = {25},
	pages = {101021},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2023.101021},
	doi = {10.1016/J.IOT.2023.101021},
	timestamp = {Mon, 03 Mar 2025 22:14:48 +0100},
	biburl = {https://dblp.org/rec/journals/iot/KadriABM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Internet of Things (IoT) has emerged over the past ten years as the newest technology trend that is luring researchers and developers from every sector of industry and academia. However, IoT is experiencing a number of security issues that are impeding its rapid development, especially those related to service availability, which has grown into a significant obstacle to be overcome. Denial of service (DoS) and Distributed Denial of Service (DDoS) attacks are among the threats that can disturb even inactivate the functionalities of the IoT networks, like their ability to collect, process, and transfer data. To date, many methods have been proposed to identify, detect, and mitigate such attacks in the IoT domain, while many surveys have been conducted to review and classify these solutions. However, to the best of our knowledge, none of them has conducted a holistic study to review, classify, and correlate both theoretical and practical aspects used in the design and validation of those approaches.}
}


@article{DBLP:journals/iot/SongLH24,
	author = {Qingling Song and
                  Lang Li and
                  Xiantong Huang},
	title = {{LELBC:} {A} low energy lightweight block cipher for smart agriculture},
	journal = {Internet Things},
	volume = {25},
	pages = {101022},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2023.101022},
	doi = {10.1016/J.IOT.2023.101022},
	timestamp = {Fri, 17 May 2024 21:39:29 +0200},
	biburl = {https://dblp.org/rec/journals/iot/SongLH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The massive collection and transmission of various crop and livestock data in smart agriculture leads to serious security concerns. Furthermore, many Internet of Things (IoT) devices in smart agriculture are battery-powered, with limited energy resources. Therefore, a low energy lightweight block cipher (LELBC) is proposed to overcome the data leakage problem during sensor data transmission in smart agriculture. Firstly, a new permutation substitution permutation (PSP) structure is proposed, taking into account the energy resource constraints of unified encryption and decryption (ED) circuits. It has highly consistent encryption and decryption and a good diffusion effect. Secondly, a 4-bit low energy involutive S-box is obtained based on a genetic algorithm. The proposed S-box has lower area and latency compared to the existing S-boxes. The experimental data show that LELBC consumes 1864 gate equivalents (GE) in area and 6.99\nμ\nJ/bit in energy (encryption + decryption) under the UMC\n0\n.\n18\nμ\nm\n1P6M process library. LELBC decreases energy and area consumption by 24.02% and 24.04%, respectively, compared to Midori. Finally, a temperature collection and encryption transmission platform is established. LELBC is deployed on the platform to encrypt the collected data, establishing the first line of defense for the secure transmission of smart agriculture sensor data.}
}


@article{DBLP:journals/iot/WiemeBH24,
	author = {Jorg Wieme and
                  Mathias Baert and
                  Jeroen Hoebeke},
	title = {Managing a QoS-enabled Bluetooth Mesh network using a Digital Twin
                  Network: An experimental evaluation},
	journal = {Internet Things},
	volume = {25},
	pages = {101023},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2023.101023},
	doi = {10.1016/J.IOT.2023.101023},
	timestamp = {Fri, 22 Mar 2024 08:58:41 +0100},
	biburl = {https://dblp.org/rec/journals/iot/WiemeBH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Bluetooth Mesh technology adds mesh topology capabilities to the Bluetooth ecosystem. To facilitate a more widespread deployment of Bluetooth Mesh networks within use cases that require meshing capabilities, it is important to strive towards an efficient management solution, based upon a variety of optimization strategies. This paper evaluates a novel approach leveraging the capabilities of a Digital Twin Network to enhance the performance of a Quality-of-Service-enabled Bluetooth Mesh network. The study explores various configurations, either based on expert-knowledge, algorithmically suggested or determined using the Digital Twin Network. Through a comprehensive evaluation process, the paper analyzes key metrics across these configurations. Notably, the Digital Twin Network-based configurations demonstrate robust performance, outperforming other configurations even in scenarios with concurrent application flows. The findings highlight the potential of the Digital Twin Network to effectively manage Bluetooth Mesh networks of diverse complexity and expose future research opportunities regarding reporting and monitoring overhead.}
}


@article{DBLP:journals/iot/MoreyGM24,
	author = {G. Eli Morey and
                  Michael Grebshtein and
                  Igor Makienko},
	title = {Vibration-based rotation speed estimation for Industrial IoT},
	journal = {Internet Things},
	volume = {25},
	pages = {101024},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2023.101024},
	doi = {10.1016/J.IOT.2023.101024},
	timestamp = {Mon, 01 Apr 2024 11:15:32 +0200},
	biburl = {https://dblp.org/rec/journals/iot/MoreyGM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Industrial Internet of Things (IIoT) uses wireless vibration sensors to predict machine health. In many cases, communication bandwidth and sensor processing resources are limited, and machine kinematics is not available at the sensor level. Consequently, only basic condition indicators, such as overall signal energy or peak-to-peak values, are computed at the sensor and transmitted to the cloud for further analysis. The behavior of these indicators is strongly influenced by machine speed, which is not available in many cases. This paper presents a novel and straightforward method for estimating machine relative speed based on vibrations, enhancing the interpretation of changes in basic condition indicators. The method does not require any prior knowledge about the machine's kinematics or expected speed changes. It was evaluated on simulated signals and wind turbine vibrations, providing a general solution for estimating varying rotating speed when no supplementary information is available. The method estimates rotating speed up to a constant factor in a set of signals (or signal segments) by optimally utilizing peak frequency statistics in the spectrum. The method demonstrates high accuracy under different operating conditions and noise and holds the potential to be used in a variety of IIoT applications.}
}


@article{DBLP:journals/iot/ChoKKCL24,
	author = {Anna Cho and
                  TaeYoung Kim and
                  Chang Kyung Kim and
                  Sieun Choi and
                  SuKyoung Lee},
	title = {IoT data dissemination scheme for reducing delay in multi-broker environments},
	journal = {Internet Things},
	volume = {25},
	pages = {101025},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2023.101025},
	doi = {10.1016/J.IOT.2023.101025},
	timestamp = {Mon, 01 Apr 2024 11:15:32 +0200},
	biburl = {https://dblp.org/rec/journals/iot/ChoKKCL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the rapid increase of Internet of Things (IoT) devices, an efficient communication protocol is needed to effectively manage the exchange and generation of data from these devices. Message Queuing Telemetry Transport (MQTT) is widely adopted in IoT systems due to its lightweight design and the support for topic-based publish–subscribe architectures. In MQTT, multiple IoT devices are connected to a server, referred to as a broker, to facilitate efficient data transmission and reduce network overhead. However, the traditional single-broker system is unable to efficiently support the massive number of IoT devices. Although a multi-broker system is proposed as a solution, the use of the flooding method for updating topics has generated a significant amount of inter-broker traffic, causing severe congestion in the brokers. As a result, this will lead to long topic update delay. To resolve this issue, in this paper, we propose a topic update dissemination scheme by considering the congestion in brokers. We formulate the topic update dissemination problem using the Lyapunov function, to minimize the topic update delay in the multi-broker system. To solve the problem, we propose a heuristic algorithm for the update dissemination forwarding decision. The simulation results show that the proposed algorithm can effectively reduce the topic update delay compared to other existing algorithms.}
}


@article{DBLP:journals/iot/WangZZH24,
	author = {Yue Wang and
                  Kai Zhang and
                  Xiaohu Zhao and
                  Xiaofei Hu},
	title = {{BTIA-IME:} {A} blockchain-based trusted interactive architecture
                  for intelligent manufacturing equipment},
	journal = {Internet Things},
	volume = {25},
	pages = {101026},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2023.101026},
	doi = {10.1016/J.IOT.2023.101026},
	timestamp = {Mon, 01 Apr 2024 11:15:32 +0200},
	biburl = {https://dblp.org/rec/journals/iot/WangZZH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the continuous development of artificial intelligence, big data, and blockchain technology, the intelligent manufacturing industry will enter a new 5.0 era. In Industry 5.0, attackers can take advantage of the hidden dangers of information transmission among infrastructure, such as smart factories (SF) and intelligent manufacturing equipment (IME), to steal private data, endanger personal safety, and harm the interests of factories. In order to avoid the above phenomenon, this paper proposes a blockchain-based trusted interactive architecture for intelligent manufacturing equipment (BTIA-IME) based on the device layer of the Industrial Internet of Things (IIoT). First, we design the key management smart contract (KMSC) and equipment management smart contract (EMSC) based on Elgamal to implement the IME trusted authentication mechanism that does not require three-party verification to ensure the credibility of IME in SF. Then, we design the data management smart contract (DMSC) based on Elgamal to store the privacy data structure through the “Blockchain-(InterPlanetary File System) IPFS” on-chain and off-chain storage modes to ensure the distributed and trusted storage of private data. After that, an access control list is constructed with the shared private data as the main body to implement the trusted access method of private data to ensure trusted access to private data. Finally, we perform simulation experiments on the proposed architecture. Theoretical and simulation experiments have proved that our proposed architecture is feasible.}
}


@article{DBLP:journals/iot/AmiriTA24,
	author = {Arman Amiri and
                  Madjid Tavana and
                  Hosein Arman},
	title = {An Integrated Fuzzy Analytic Network Process and Fuzzy Regression
                  Method for Bitcoin Price Prediction},
	journal = {Internet Things},
	volume = {25},
	pages = {101027},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2023.101027},
	doi = {10.1016/J.IOT.2023.101027},
	timestamp = {Sun, 06 Oct 2024 21:31:06 +0200},
	biburl = {https://dblp.org/rec/journals/iot/AmiriTA24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Predicting the prices of cryptocurrencies is more complicated than that of classical financial assets because they do not seem to have reached the maturity stage of their life. In addition, many known and unknown factors may affect Bitcoin prices; these factors and their importance seem to be changing faster than other financial assets. Therefore, the data used to predict the prices of cryptocurrencies can be considered big data challenging to manage due to their volume, variety, and variability. This study presents an integrated approach to managing the data when predicting the Bitcoin price. We first prepare a list of factors affecting the Bitcoin price. We then use the Fuzzy Analytic Network Process (FANP) to screen these factors and select the most important ones based on the experts’ opinions. The selected factors are considered independent variables affecting the Bitcoin price. Next, we extract a fuzzy regression model using the historical data in which the Bitcoin price is considered the dependent variable. Finally, this model is validated with different confidence levels, and the appropriate level is selected to predict the Bitcoin price. The results show that Bitcoin prices fall within the forecasting intervals obtained from the fuzzy regression model for a 99% confidence level. Unlike crisp regression models, the fuzzy regression model used in this study does not predict the Bitcoin price as a crisp value; instead, it predicts the price as an interval value. The contributions of this study are fourfold: (1) identifying the factors affecting the Bitcoin price and investigating their mutual impacts on each other; (2) determining the most influential factors using the FANP method; (3) using fear and greed as essential sentimental independent variables in regression to predict the Bitcoin price; (4) and predicting the Bitcoin price as an interval instead of a crisp value.}
}


@article{DBLP:journals/iot/LahmarZYLB24,
	author = {Ines Lahmar and
                  Aida Boussaada Zaier and
                  Mohamed Yahia and
                  Jaime Lloret and
                  Ridha Bouallegue},
	title = {Optimal data transmission for decentralized IoT and {WSN} based on
                  Type-2 Fuzzy Harris Hawks Optimization},
	journal = {Internet Things},
	volume = {25},
	pages = {101028},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2023.101028},
	doi = {10.1016/J.IOT.2023.101028},
	timestamp = {Mon, 03 Mar 2025 22:14:48 +0100},
	biburl = {https://dblp.org/rec/journals/iot/LahmarZYLB24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Due to the widespread availability of services and smart devices, the decentralized internet of things and wireless sensor network-based systems (DIoT and WSN) have drawn the attention of academics and researchers and are still under constant development. Many challenges face the DIoT and WSN networks and need to be solved. The main issue among these challenges is reducing energy consumption in order to increase network lifetime. Energy-efficient routing protocols and the clustering method are the best solutions to this problem. In this paper, Type-2 Fuzzy Harris Hawks Optimization (T2FHHO) is used to choose the best path (route) from the source (cluster head (CH)) to the destination nodes (base station (BS)). Along with this, we propose a new fitness function to find the next hop based on residual energy, distance, traffic, and buffer size. Then, we apply the T2FHHO method to get the best CH. This protocol seeks to increase the long-term reward earned by each node. The best path in terms of the minimum cost obtained using the proposed method is found. The two main contributions of this study are as follows: firstly, we present a new efficient routing approach that minimizes costs and maximizes efficiency. Secondly, we apply the T2FHHO to the network parameters of energy consumption, network lifetime, and convergence curves. The results indicate that T2FHHO outperforms competing methods. The proposed method holds the promise of significantly advancing the state of the art in energy-efficient routing for DIoT and WSN networks, with significant implications in various sectors and applications, ensuring extended network lifetimes and sustainable IoT implementations.}
}


@article{DBLP:journals/iot/SongBW24,
	author = {Yongchao Song and
                  Jiping Bi and
                  Xuan Wang},
	title = {Design and implementation of intelligent monitoring system for agricultural
                  environment in IoT},
	journal = {Internet Things},
	volume = {25},
	pages = {101029},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2023.101029},
	doi = {10.1016/J.IOT.2023.101029},
	timestamp = {Sun, 06 Oct 2024 21:31:06 +0200},
	biburl = {https://dblp.org/rec/journals/iot/SongBW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the context of population growth and limited resources, the efficiency and sustainability of agricultural production became particularly important. Smart agricultural technology and Internet of Things (IoT) technology have helped farmers with better management tools to improve crop yield and quality. This research takes the IoT as the core and combines sensor, actuator and cloud platform technologies to build a smart greenhouse control system. Environmental parameters such as temperature, humidity, and light are obtained through sensors. And it is uploaded to the cloud platform for storage and analysis. At the same time, light, ventilation, water, and fertilizer inside the greenhouse are controlled automatically by our system to achieve the best crop growth condition. System design adopts a modular design concept. We separately realize the functions of sensor, actuator and cloud platform, where data is transmitted via wireless communication and integrated together. The experimental results show that the cloud control system of smart agricultural greenhouse can effectively monitor the greenhouse environment, optimize efficiency of energy and resource utilization, and help farmers manage greenhouse conveniently and quickly.}
}


@article{DBLP:journals/iot/ParteMCM24,
	author = {Mario San Emeterio de la Parte and
                  Jos{\'{e}}{-}Fern{\'{a}}n Mart{\'{\i}}nez{-}Ortega and
                  Pedro Castillejo and
                  N{\'{e}}stor Lucas Mart{\'{\i}}nez},
	title = {Spatio-temporal semantic data management systems for IoT in agriculture
                  5.0: Challenges and future directions},
	journal = {Internet Things},
	volume = {25},
	pages = {101030},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2023.101030},
	doi = {10.1016/J.IOT.2023.101030},
	timestamp = {Sat, 08 Jun 2024 13:15:49 +0200},
	biburl = {https://dblp.org/rec/journals/iot/ParteMCM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Agri-Food sector is in a stressful situation due to the high demand for food from the growing population around the world. The agricultural sector is facing a challenging situation; it must increase production and reduce its impact on the environment by appropriately allocating resources, adapting to climate change, and avoiding food waste. Agriculture 5.0, as the fifth agricultural evolution, aims to offer a perfect symbiosis between agriculture, advanced technologies, and sustainability. The most advanced technologies in automation, monitoring, and decision support are driven by the collection and processing of large volumes of agricultural data, such as weather information, farm machinery, soil and crop conditions, and marketing demand for higher profits. Taking advantage of the technological paradigm of the Internet of Things, agricultural data provides information on spatial, temporal, and semantic dimensions. Spatio-temporal semantic data management systems have become the cornerstone for the achievement of Agriculture 5.0 through advanced Internet of Things technologies. This paper aims to review the current literature on spatio-temporal semantic data management systems for Agriculture 5.0. This paper uses a systematic literature review technique to study eleven representative spatio-temporal semantic data management systems. A comprehensive evaluation of the aspects of interoperability, accessibility, scalability, real-time operation capability, etc. is carried out. Based on the evaluation results, future challenges are detected and development trends and possible improvements are proposed for future research. Finally, a distributed architecture capable of satisfying the above needs and challenges is proposed. The paper aims to inspire further research and development efforts to improve the efficiency, accessibility, and performance of spatio-temporal semantic data management systems.}
}


@article{DBLP:journals/iot/BensonOECAA24,
	author = {Mfonobong Eleazar Benson and
                  Kennedy Chinedu Okafor and
                  Longinus Sunday Ezema and
                  Nkwachukwu Chukwuchekwa and
                  Bamidele Adebisi and
                  Okoronkwo Chukwunenye Anthony},
	title = {Heterogeneous cyber-physical network coexistence through interference
                  contribution rate and uplink power control algorithm {(ICR-UPCA)}
                  in 6G edge cells},
	journal = {Internet Things},
	volume = {25},
	pages = {101031},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2023.101031},
	doi = {10.1016/J.IOT.2023.101031},
	timestamp = {Sat, 08 Jun 2024 13:15:49 +0200},
	biburl = {https://dblp.org/rec/journals/iot/BensonOECAA24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Optimizing power control for interference mitigation at the network cell edge is pivotal in enhancing capacity within a heterogeneous cyber-physical infrastructure, such as smart cities, manufacturing, healthcare, energy grids, transportation, and agriculture, among others. In this paper, we consider the intricate dynamics of Internet of Things (IoT) 5/6G edge users, with a particular focus on the Interference Contribution Rate (ICR), where macro and femtocells are critical network infrastructures. Existing approaches has drawbacks such as computational complexity, overhead, and co-channel interference, among others. However, to fully address interference challenges from the coexistence of diverse network hierarchies, preserving the Quality of Service for femtocell users is prioritized. The paper concurrently enhances the handoff mechanism of cell edge users in the macro cell network. A two-tier heterogeneous network (HetNet) is utilized to initially assess the contribution of edge user equipment (UE) to interference levels during its active state while quantifying it as ICR. Game theory is used to formulate a cohesive model for the coexistence of macro cell (MUE) and femtocell users (FUE). ICR-based uplink power control and reference signal received quality (RSRQ)-based handoff algorithms are deployed to regulate interference levels and enhance the Signal-to-Interference-Noise Ratio (SINR) of the MUE at the cell edge. This is achieved through coordinated transmit power adjustments by both user types. Results indicate a 6.67 % channel capacity loss (interference tolerance) by the FUE, leading to a 12.5 % improvement, translating to approximately 4 Mbps and 1 Mbps channel enhancements, respectively. The MUE and FUE can effectively coordinate power control with minimal overhead, accepting compromises in network channel quality. This approach facilitates improved MUE data access rates while ensuring the preservation of FUE. We show that interference is successfully mitigated through power control in heterogeneous networks with lower computational complexity.}
}


@article{DBLP:journals/iot/ClementeLopezRM24,
	author = {Daniel Clemente{-}L{\'{o}}pez and
                  Jose de Jesus Rangel{-}Magdaleno and
                  Jes{\'{u}}s Manuel Mu{\~{n}}oz{-}Pacheco},
	title = {A lightweight chaos-based encryption scheme for IoT healthcare systems},
	journal = {Internet Things},
	volume = {25},
	pages = {101032},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2023.101032},
	doi = {10.1016/J.IOT.2023.101032},
	timestamp = {Mon, 01 Apr 2024 11:15:32 +0200},
	biburl = {https://dblp.org/rec/journals/iot/ClementeLopezRM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Internet of Things (IoT) has transformed the healthcare industry by enabling new services and capabilities through connected devices and sensors. These devices, such as smartwatches and fitness tracker bands, can monitor various health metrics such as heart rate, blood pressure, and sleep quality. However, the security of these systems is a critical concern, as the unauthorized disclosure or access of healthcare information could have serious consequences for patients. This information can include personal and medical data, diagnostic and treatment information, as well as private locations. Lightweight encryption schemes are commonly used in IoT systems to protect this sensitive data. These schemes are designed to be fast and efficient, allowing them to encrypt and decrypt data in real-time, which is important for systems with limited computing power or storage capacity. In the last decade, there has been a significant increase in research and development in chaos cryptography. Due to chaotic systems’ unpredictable and sensitive nature, they can provide robust cryptographic schemes for data transmission between embedded devices. This makes it difficult for attackers to intercept and manipulate the data. Therefore, this work proposes a chaos-based lightweight encryption scheme for IoT healthcare systems with a primary application in the encryption of wearable devices. The proposed encryption scheme is based on a\n2\nD\n4-scroll chaotic attractor system, uniquely characterized for this work. The scheme is tested on an ARM-based microcontroller for encrypting PPG (Photoplethysmogram) biosignal data. The obtained results show that the chaos-based lightweight encryption scheme effectively improves the security of healthcare IoT systems while maintaining the real-time flow of data.}
}


@article{DBLP:journals/iot/SisinniFGPRF24,
	author = {Emiliano Sisinni and
                  Alessandra Flammini and
                  Massimiliano Gaffurini and
                  Marco Pasetti and
                  Stefano Rinaldi and
                  Paolo Ferrari},
	title = {LoRaWAN end device disaggregation and decomposition by means of lightweight
                  virtualization},
	journal = {Internet Things},
	volume = {25},
	pages = {101033},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2023.101033},
	doi = {10.1016/J.IOT.2023.101033},
	timestamp = {Sat, 08 Jun 2024 13:15:49 +0200},
	biburl = {https://dblp.org/rec/journals/iot/SisinniFGPRF24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The LoRaWAN infrastructure has been designed to allow easy implementation of backends in mixed IoT scenario with both on premise and cloud servers. Some very popular providers offer the LoRaWAN backend in the form of SaaS, or the user can install containerized versions of the backends into his/her own servers. In this paper, the containerization of LoRaWAN end node is discussed, addressing different architectures for disaggregating the tasks and decomposing the stack levels from the hardware. Such an analysis leads to the introduction of a new fully virtual end node, that paves the way to innovative use of the LoRaWAN backend. The proposed container-based architecture is then applied to some general IoT use cases, which have been setup using a commercial, industrial-grade, framework for the experimental phase. The experimental evaluation, based on purposely defined metrics, takes into account the latency in transferring data among the different stack level and backend components. The focus is on comparing the performance of the proposed architecture in the diverse use cases, and on giving a clear overview of advantages and disadvantages of the possible choices. For instance, noticeable differences emerged when comparing containerization running directly on Operating System vs. containerization running inside virtual machine. Finally, a discussion about the use of the proposed solution for increasing LoRaWAN capabilities in terms of flexibility and performance (e.g., by means of multiple end nodes leveraging a single radio for redundancy purpose) is carried out.}
}


@article{DBLP:journals/iot/RivadeneiraBRBS24,
	author = {Jorge Eduardo Rivadeneira and
                  Guilherme Antonio Borges and
                  Andr{\'{e}} Rodrigues and
                  Fernando Boavida and
                  Jorge S{\'{a}} Silva},
	title = {A unified privacy preserving model with {AI} at the edge for Human-in-the-Loop
                  Cyber-Physical Systems},
	journal = {Internet Things},
	volume = {25},
	pages = {101034},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2023.101034},
	doi = {10.1016/J.IOT.2023.101034},
	timestamp = {Sat, 08 Jun 2024 13:15:49 +0200},
	biburl = {https://dblp.org/rec/journals/iot/RivadeneiraBRBS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the proliferation of personal Internet of Things (IoT) devices and their wide adoption among society, the original notion of IoT has been reshaped, giving rise to new IoT-based paradigms like Human-in-the-Loop Cyber-Physical Systems (HiTLCPS). While these systems can bring benefits and positively influence people, their pervasive nature raises significant privacy concerns, especially regarding the acquisition and processing of data. Although privacy-preserving mechanisms have been proposed for these implementations, the existing approaches tend to focus on either data acquisition or data processing. However, to date, no solution has encompassed the entire process. In this regard, this paper presents a unified privacy-preserving model for HiTLCPS. This approach integrates a human-centric mechanism to control and make data acquisition and sharing tasks transparent with a state inference process supported by Artificial Intelligence (AI) in the edge. A set of assessments were conducted in actual implementation to evaluate the feasibility of the model. Our findings reveal that our federated learning approach is a suitable solution compared to the traditional approach based on machine learning at the small cost of 3.27% of average accuracy. Finally, this paper concludes by providing a roadmap towards integrating HiTLCPS from diverse contexts, including a state inference process closer to the user domain.}
}


@article{DBLP:journals/iot/HimeurSABA24,
	author = {Yassine Himeur and
                  Aya Nabil Sayed and
                  Abdullah Alsalemi and
                  Faycal Bensaali and
                  Abbes Amira},
	title = {Edge {AI} for Internet of Energy: Challenges and perspectives},
	journal = {Internet Things},
	volume = {25},
	pages = {101035},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2023.101035},
	doi = {10.1016/J.IOT.2023.101035},
	timestamp = {Fri, 22 Mar 2024 08:58:42 +0100},
	biburl = {https://dblp.org/rec/journals/iot/HimeurSABA24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The digital landscape of the Internet of Energy (IoE) is on the brink of a revolutionary transformation with the integration of edge Artificial Intelligence (AI). This comprehensive review elucidates the promise and potential that edge AI holds for reshaping the IoE ecosystem. Commencing with a meticulously curated research methodology, the article delves into the myriad of edge AI techniques specifically tailored for IoE. The myriad benefits, spanning from reduced latency and real-time analytics to the pivotal aspects of information security, scalability, and cost-efficiency, underscore the indispensability of edge AI in modern IoE frameworks. As the narrative progresses, readers are acquainted with pragmatic applications and techniques, highlighting on-device computation, secure private inference methods, and the avant-garde paradigms of AI training on the edge. A critical analysis follows, offering a deep dive into the present challenges including security concerns, computational hurdles, and standardization issues. However, as the horizon of technology ever expands, the review culminates in a forward-looking perspective, envisaging the future symbiosis of 5G networks, federated edge AI, deep reinforcement learning, and more, painting a vibrant panorama of what the future beholds. For anyone vested in the domains of IoE and AI, this review offers both a foundation and a visionary lens, bridging the present realities with future possibilities.}
}


@article{DBLP:journals/iot/ChavesMD24,
	author = {Antonio Jes{\'{u}}s Chaves and
                  Cristian Mart{\'{\i}}n and
                  Manuel D{\'{\i}}az},
	title = {Towards flexible data stream collaboration: Federated Learning in
                  Kafka-ML},
	journal = {Internet Things},
	volume = {25},
	pages = {101036},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2023.101036},
	doi = {10.1016/J.IOT.2023.101036},
	timestamp = {Sat, 08 Jun 2024 13:15:49 +0200},
	biburl = {https://dblp.org/rec/journals/iot/ChavesMD24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated learning is applied in scenarios where organisations lack sufficient data volume for modelling their business logic and cannot share their data with external parties. Moreover, Industry 4.0 and IoT scenarios generate massive data streams, which normally are fed to ML/AI solutions for model training and prediction. However, in most cases, ML/AI frameworks are not prepared to work with these streaming pipelines. In this paper, we present an asynchronous federated learning solution based on the Kafka-ML data stream framework, which is able to combine federated learning and data stream capabilities within ML/AI applications. While most federated learning approaches are tailored to a specific ML model or a use case, the solution provided adapts itself to the availability of both data and ML models, achieving a flexible and dynamic federated learning solution. To validate its performance, an evaluation of the federated learning solution is carried out on different scenarios in a multi-node state-of-the-art infrastructure. Results show that this framework can work with multiple federated clients, being the resulting accuracy dependent on the amount of data and the behaviour of clients during training.}
}


@article{DBLP:journals/iot/MishraIZ24,
	author = {Nimish Mishra and
                  SK Hafizul Islam and
                  Sherali Zeadally},
	title = {A survey on security and cryptographic perspective of Industrial-Internet-of-Things},
	journal = {Internet Things},
	volume = {25},
	pages = {101037},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2023.101037},
	doi = {10.1016/J.IOT.2023.101037},
	timestamp = {Mon, 01 Apr 2024 11:15:32 +0200},
	biburl = {https://dblp.org/rec/journals/iot/MishraIZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Industrial-Internet-of-Things (IIoT) powers several applications in the modern world: smart city, smart grid, smart manufacturing, smart logistics management, etc. The increased connectivity and smartness bring a rich attack surface for adversaries. Past research efforts have extensively explored the security aspects of IIoT. Still, none of them took a cryptographic perspective of IIoT security, which is imperative because almost all modern cyber defenses are based on cryptographic primitives. We address this issue in this work. We present a cryptographic perspective of IIoT for the designers and developers. We review the desirable security properties and existing attacks against the IIoT infrastructure. We then review conventional cryptographic tools used to secure modern IIoT networks. Finally, we discuss shortcomings associated with traditional cryptography and recommend Post-Quantum Cryptography (PQC) techniques that could be integrated with IIoT. Finally, we present future research directions on using cryptography for IIoT environments.}
}


@article{DBLP:journals/iot/KaleemSBAT24,
	author = {Sarah Kaleem and
                  Adnan Sohail and
                  Muhammad Babar and
                  Awais Ahmad and
                  Muhammad Usman Tariq},
	title = {A hybrid model for energy-efficient Green Internet of Things enabled
                  intelligent transportation systems using federated learning},
	journal = {Internet Things},
	volume = {25},
	pages = {101038},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2023.101038},
	doi = {10.1016/J.IOT.2023.101038},
	timestamp = {Sun, 04 Aug 2024 19:51:17 +0200},
	biburl = {https://dblp.org/rec/journals/iot/KaleemSBAT24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the rapidly evolving Internet of Things domain, managing voluminous data streams while ensuring energy efficiency remains a cardinal challenge. Our research introduces a hybrid model designed specifically for an IoT system. This paper sheds light on our unique framework that emphasizes efficient communication and prioritizes energy conservation. The innovative model architecture is lightweight, fostering compatibility with resource-constrained devices and paving the way for personalized federated averaging during training. A crucial highlight of our methodology includes local training using lightweight optimization instead of traditional data transmission, reducing energy overheads considerably. Furthermore, we propose a novel approach for model aggregation using personalized energy-aware averaging. This process iteratively refines a global model by aggregating received updates, drastically reducing the data transfer compared to conventional methods. Lastly, we integrate an energy-aware updates management system, continually monitoring device energy metrics and making adaptive data transmission and model update decisions. The model ensures optimal participation in global updates by consistently monitoring devices’ energy metrics and setting adaptive thresholds. This study leverages the richly annotated Udacity Self-Driving Car Dataset provided by Roboflow to evaluate a novel federated learning model to optimize energy consumption for IoT systems. Our experiments simulate real-world collaborative learning scenarios using the TensorFlow Federated (TFF). Our focus on energy consumption evaluation revealed that our proposed model offers significant energy savings when analyzed based on data communication round time and individual node training duration. A comparative analysis between the proposed and traditional models uncovers substantial improvements in energy efficiency. In our experiments, the proposed approach demonstrated a commendable accuracy of 93.27%. Notably, the local communication time was streamlined to 1.21 s, while the global communication was efficiently clocked at 4.76 s. When compared to traditional methods, these results not only underscore the effectiveness and efficiency of our methodology in the context of IoT systems but also highlight its superior performance.}
}


@article{DBLP:journals/iot/ShangLWH24,
	author = {Zhendong Shang and
                  Zhaoying Li and
                  Qinzhang Wei and
                  Shuaibo Hao},
	title = {Livestock and poultry posture monitoring based on cloud platform and
                  distributed collection system},
	journal = {Internet Things},
	volume = {25},
	pages = {101039},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2023.101039},
	doi = {10.1016/J.IOT.2023.101039},
	timestamp = {Sun, 19 Jan 2025 14:28:17 +0100},
	biburl = {https://dblp.org/rec/journals/iot/ShangLWH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In order to realize automatic inspection of livestock health and welfare in large-scale intensive farming, a biological state monitoring system based on the IoT cloud platform and distributed data collection technology was designed. Through analysis, a one-dimensional description method of livestock spatial posture is established to determine the spatial posture of livestock by scanning the distance information in a typical cross-section of livestock by a single sensor. Through the distributed configuration of one master and multiple slave detection units, the master–slave hardware circuit was designed based on microprocessors, laser distance sensors, proximity switches, wireless transmission modules, etc. The master, slave and user-side cell phone programs were developed to realize the centralized monitoring of multiple breeding sites. Each slave uses an STC12C5A60S2 microprocessor and multiple sensors for real-time acquisition of status parameters of the organisms. These slave status parameters are packaged and sent to the host control unit via RS485 bus. The host packages the received status data into JSON format packets and sends them to Alibaba Cloud server through the serial port side of the IoT gateway. The IoT gateway follows the MQTT communication protocol to ensure the reliability of the connection and forwards the status monitoring results to the cloud server. The end-user can monitor the status of the organisms anytime and anywhere through the APP of the monitoring management platform and deal with abnormalities in time. After experimental verification, the system achieves remote acquisition, real-time reporting, data storage, polling monitoring and status alarm functions, and the monitoring accuracy reaches to meet the demand for biological status monitoring in intensive farming.}
}


@article{DBLP:journals/iot/WhiteWADB24,
	author = {David W. White and
                  Isaac Woungang and
                  Felix O. Akinladejo and
                  Sanjay Kumar Dhurandher and
                  Leonard Barolli},
	title = {A network communication speedup model using multiple fungible and
                  non-fungible paths},
	journal = {Internet Things},
	volume = {25},
	pages = {101040},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2023.101040},
	doi = {10.1016/J.IOT.2023.101040},
	timestamp = {Fri, 22 Mar 2024 08:58:41 +0100},
	biburl = {https://dblp.org/rec/journals/iot/WhiteWADB24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The advent of industry 5.0 has seen technologies such as cyber-physical systems, sensors, mobile devices and a host of others, connected to the Internet of Things (IoT). The sheer growth of the IoT and the data transmitted across it calls for faster speeds (speedup), which in turn are facilitated by more bandwidth and better use of existing bandwidth. Speedup itself is not new and has been extensively studied in the literature in high performance computing and related fields. In this paper, some methods to achieve theoretical speedup in network communications are explored and tested using simulations and extrapolations. We also explored the theoretical limits of speedup. Some theoretical limits of speedup are also proposed, along with a model to estimate the speedup that can be achieved using larger container sizes over the existing bandwidth. We have also proposed a way to estimate the speedup that can be achieved when more bandwidth is provided using multiple fungible and non-fungible paths. It is anticipated that our proposed speedup model will assist the manufacturers of IoT sensors and smart devices, as well as network administrators and software developers in determining what theoretical speedup can be achieved with a certain network configuration, and in building devices and software capable to achieve practical speedups as close as possible to the predicted theoretical speedups. This in turn will lead to faster response and data transmission times in IoT and other network applications that leverage the speedup achieved.}
}


@article{DBLP:journals/iot/KumariM24,
	author = {Punam Kumari and
                  Bhaskar Mondal},
	title = {Lightweight encryption with data and device integrity using {NLFSR}
                  and {PUF} for the Internet of Medical Things},
	journal = {Internet Things},
	volume = {25},
	pages = {101041},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2023.101041},
	doi = {10.1016/J.IOT.2023.101041},
	timestamp = {Mon, 03 Mar 2025 22:14:48 +0100},
	biburl = {https://dblp.org/rec/journals/iot/KumariM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Nowadays the Internet of Medical Things (IoMT) is in top demand; they communicate with each other in an IoT network, but there are various security issues including privacy preservation, data and device integrity, and authentication. The IoMT devices have challenges like limited computational power and resources, so conventional techniques are not suitable for them. This paper presents a lightweight stream cipher to ensure privacy protection, data integrity, and device integrity using a message authentication code (MAC). The stream cipher is designed using a nonlinear feedback shift register (NLFSR). The cipher is associated with a MAC generated by concatenating a physical unclonable function (PUF) response and the hash of the plaintext to protect the device and data integrity. The use of NLFSR and PUF makes the proposed scheme robust and lightweight for resource-constrained devices like MIoT. To evaluate the quality of the cipher the NIST 800-22 statistical test suite (NIST STS) is used, and results are compared with existing stream ciphers like Rivest cipher 4 (RC4), RC4 based on chaotic mapping (RCCM), and product algebra RCCM (PARCCM). All the tests and comparisons were performed using a Heart Disease Dataset. The scheme ensures the confidentiality and integrity of sensitive medical data which are critical for protecting patient privacy and regulatory compliance. The proposed scheme can also resist cloning attacks on the IoMT devices.}
}


@article{DBLP:journals/iot/GarcesJimenezRGRPSB24,
	author = {Alberto Garc{\'{e}}s{-}Jim{\'{e}}nez and
                  Andr{\'{e}} Rodrigues and
                  Jos{\'{e}} Manuel G{\'{o}}mez{-}Pulido and
                  Duarte M. G. Raposo and
                  Juan Antonio G{\'{o}}mez Pulido and
                  Jorge S{\'{a}} Silva and
                  Fernando Boavida},
	title = {Industrial Internet of Things embedded devices fault detection and
                  classification. {A} case study},
	journal = {Internet Things},
	volume = {25},
	pages = {101042},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2023.101042},
	doi = {10.1016/J.IOT.2023.101042},
	timestamp = {Sun, 04 Aug 2024 19:51:17 +0200},
	biburl = {https://dblp.org/rec/journals/iot/GarcesJimenezRGRPSB24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Industries transition to the Industry 4.0 paradigm requires solutions based on devices attached to machines that allow monitoring and control of industrial equipment. Monitoring is essential to ensure devices’ proper operation against different aggressions. We propose an approach to detect and classify faults that are typical in these devices, based on machine learning techniques that use energy, processing, and main application use as features. The proposal was validated using a dataset collected from a testbed executing a typical equipment monitoring application. The proposed machine learning pipeline uses a decision tree-based model for fault detection (with 99.4% accuracy, 99.7% precision, 99.6% recall, 75.2% specificity, and 99.7% F1) followed by a Semi-Supervised Graph-Based model (with 99.3% accuracy, 96.4% precision, 96.1% recall, 99.6% specificity, and 96.2% F1) for further fault classification. The obtained results demonstrate that machine learning techniques, based on easily obtainable metrics, help coping with common device faults.}
}


@article{DBLP:journals/iot/AbdelMalekA24,
	author = {Mai A. Abdel{-}Malek and
                  Mohamed Azab},
	title = {UAV-fleet management for extended NextG emergency support infrastructure
                  with QoS and cost aware},
	journal = {Internet Things},
	volume = {25},
	pages = {101043},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2023.101043},
	doi = {10.1016/J.IOT.2023.101043},
	timestamp = {Fri, 22 Mar 2024 08:58:42 +0100},
	biburl = {https://dblp.org/rec/journals/iot/AbdelMalekA24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The recent developments in Unmanned Aerial Vehicles (UAV)-assisted wireless communications demonstrated the valuable contributions UAVs could offer to support communication infrastructures under duress. However, due to the complicated and costly operation management, the use of UAVs was extremely limited to fixed pre-arranged deployment or short-term ad-hoc service support. Unfortunately, fixed deployments are not suitable for emergencies such as unexpected failures or overhead; a situation ad-hoc deployment would serve much better. The main obstacle facing ad-hoc deployment models is the increased cost of operation and complicated power management. This paper presents a reliable self and mission-aware multi-hop UAV operation management to support communication networks in case of infrastructure failure or overload for extended time and distances. The formalized optimization offers a solution to the operation management challenges for ad-hoc UAV deployment as a balanced multi-objective, multi-dimensional convex-optimization problem. The paper also provides the pre-flying numerical analysis and parameters to enable optimal mission-oriented extension coverage as a solution guiding the presented UAV operation management framework. The optimization problem is simulated for a 5G-sub 6 cellular network to assess the proposed framework’s efficiency and effectiveness in a coverage extension situation. Results showed that the proposed framework could facilitate extended flight time, overlay network support, and stable service provisioning.}
}


@article{DBLP:journals/iot/ZhaoXW24,
	author = {Jian Zhao and
                  Maolin Xu and
                  Xuezhu Wang},
	title = {A novel dataset based on indoor teacher-student interactive mode using
                  AIoT},
	journal = {Internet Things},
	volume = {25},
	pages = {101044},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2023.101044},
	doi = {10.1016/J.IOT.2023.101044},
	timestamp = {Mon, 01 Apr 2024 11:15:32 +0200},
	biburl = {https://dblp.org/rec/journals/iot/ZhaoXW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A novel dataset on teacher-student classroom behavior has been designed and implemented in this paper. The dataset, named Posture-based Teacher-Student Behavioral Engagement Pattern Dataset (PTPD), is realized using AIoT technology and consists of over 13,500 videos from more than 1,000 scenarios, providing convenience for spatio-temporal analysis. PTPD also fills the gap of high-quality datasets for classroom behavior analysis of teachers and students. Then, Alpha Pose, Open Pose, and ST-GCN algorithms are employed to evaluate the accuracy of the dataset. Experimental results demonstrate that the pose-based algorithms achieve an average estimation accuracy of 91.14%, while the ST-GCN algorithm achieves a teacher-student behavior recognition rate of 92.15%, confirming the effectiveness and high quality of this dataset.}
}


@article{DBLP:journals/iot/NkoroNLK24,
	author = {Ebuka Chinaechetam Nkoro and
                  Cosmas Ifeanyi Nwakanma and
                  Jae{-}Min Lee and
                  Dong{-}Seong Kim},
	title = {Detecting cyberthreats in Metaverse learning platforms using an explainable
                  {DNN}},
	journal = {Internet Things},
	volume = {25},
	pages = {101046},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2023.101046},
	doi = {10.1016/J.IOT.2023.101046},
	timestamp = {Tue, 07 May 2024 20:25:59 +0200},
	biburl = {https://dblp.org/rec/journals/iot/NkoroNLK24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The rapid integration of the Internet of Artificial Intelligence and Internet of Things (AI-IoT) technologies has given rise to a pivotal element of the upcoming digital era, the Metaverse. This confluence has significantly impacted virtual learning platforms by introducing enhanced, immersive, and interactive environments for learners, educators, and institutions. However, the growing reliance on Metaverse necessitates robust cybersecurity measures to detect and mitigate cyber threats and ensure the safety of users. This paper proposes an explainable deep neural network (DNN) designed to identify and address network intrusion attacks within Metaverse learning environments. By leveraging the latest cybersecurity IoT datasets and employing an effective feature selection method, this study provides a visually interpretable, trustworthy, and quantitative explanation of the network intrusion detection system (NIDS) model using Shapley Additive exPlanations (SHAP) and local interpretable model-agnostic explanation (LIME) explainability methods. The adopted explainable DNN, capable of processing network traffic features from interconnected Metaverse devices and IoT sensors, can facilitate accurate and comprehensible remediation of anomalous from benign activities within Metaverse. The NIDS model yields a high performing accuracy of 99.9% for establishing a more secure and trustworthy metaverse learning environment.}
}


@article{DBLP:journals/iot/GeLYLLM24,
	author = {Yifei Ge and
                  Zhuo Li and
                  Xuebin Yue and
                  Hengyi Li and
                  Qi Li and
                  Lin Meng},
	title = {IoT-based automatic deep learning model generation and the application
                  on Empty-dish Recycling Robots},
	journal = {Internet Things},
	volume = {25},
	pages = {101047},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2023.101047},
	doi = {10.1016/J.IOT.2023.101047},
	timestamp = {Mon, 01 Apr 2024 11:15:32 +0200},
	biburl = {https://dblp.org/rec/journals/iot/GeLYLLM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As a modern computer vision technology, deep learning (DL) revolutionizes our lives and reshapes our world with its high performance. Usually, to accomplish each task, researchers need to collect the dataset and modify the basic DL model to optimize the model. In addition, collecting the dataset is time-consuming, and building separate Artificial Intelligence (AI) models for each task is significantly ineffective Therefore, AI research faces challenges in realizing effective data collection and DL model generation. To solve these problems, we design an Internet of Things (IoT)-based automatic DL model generation strategy which also includes an IoT-based data collection method. In detail, we design an Android application that captures images and sends them to a cloud server to create a dataset. Additionally, we apply a two-level checking function to filter out anomalous data and ensure the dataset’s correctness. Next, the cloud server uses the dataset to train and generate a DL model automatically. We have prepared the state-of-the-art DL components in the cloud server and propose an automatic DL model creation process for model generation. We have applied the proposal to Empty-dish Recycling Robots for demonstration and evaluation purposes to easily understand the proposal and measure the performance. The experimental results show that the system successfully collects the dataset and automatically generates the DL model. Furthermore, the checking function deployed on Android devices requires only 0.84 MB and achieves 99.86% accuracy. During training, the time spent on each automatic DL model generation is evidently decreased by about 9.00% to 28.00%.}
}


@article{DBLP:journals/iot/GomezCarmonaCLG24,
	author = {Oihane G{\'{o}}mez{-}Carmona and
                  Diego Casado{-}Mansilla and
                  Diego L{\'{o}}pez{-}de{-}Ipi{\~{n}}a and
                  Javier Garc{\'{\i}}a{-}Zub{\'{\i}}a},
	title = {Human-in-the-loop machine learning: Reconceptualizing the role of
                  the user in interactive approaches},
	journal = {Internet Things},
	volume = {25},
	pages = {101048},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2023.101048},
	doi = {10.1016/J.IOT.2023.101048},
	timestamp = {Sat, 08 Jun 2024 13:15:49 +0200},
	biburl = {https://dblp.org/rec/journals/iot/GomezCarmonaCLG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The rise of intelligent systems and smart spaces has opened up new opportunities for human–machine collaborations. Interactive Machine Learning (IML) contribute to fostering such collaborations. Nonetheless, IML solutions tend to overlook critical factors such as the timing, frequency and workload that drive this interaction and are vital to adapting these systems to users’ goals and engagement. To address this gap, this work explores users’ expectations towards IML solutions in the context of an interactive hydration monitoring system for the workplace, which represents a challenging environment to implement intelligent solutions that can collaborate with individuals. The proposed system involves users in the learning process by providing feedback on the success of detecting their drinking gestures and enabling them to contribute with additional examples of their data. A qualitative study was conducted to evaluate this use case, where participants completed specific tasks with varying levels of involvement. This study provides promising insights into the potential of placing the Human-in-the-Loop (HitL) to adapt and reconceptualize the users’ role in interactive solutions, highlighting the importance of considering human factors in designing more effective and flexible collaborative systems between humans and machines.}
}


@article{DBLP:journals/iot/LinLWWXW24,
	author = {Shengsheng Lin and
                  Weiwei Lin and
                  Keyi Wu and
                  Songbo Wang and
                  Minxian Xu and
                  James Z. Wang},
	title = {Cocv: {A} compression algorithm for time-series data with continuous
                  constant values in IoT-based monitoring systems},
	journal = {Internet Things},
	volume = {25},
	pages = {101049},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2023.101049},
	doi = {10.1016/J.IOT.2023.101049},
	timestamp = {Mon, 03 Mar 2025 22:14:48 +0100},
	biburl = {https://dblp.org/rec/journals/iot/LinLWWXW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Sensor-generated time-series data now constitutes a significant and growing portion of the world’s data due to the rapid proliferation of the Internet of Things (IoT). The transmission and storage of such voluminous data have emerged as enormous challenges. Data compression and reduction strategies have been instrumental in mitigating these challenges to some extent. However, they have exhibited limitations when applied to real-time IoT-based monitoring systems. This stems from their failure to adequately consider the stringent requirements of real-time data transmission and the continuous constant-value redundancy within periodic monitoring data. Consequently, we introduce a dedicated compression algorithm tailored specifically for time-series data within periodic IoT-based monitoring systems, namely Cocv. It takes advantage of the continuous constant-value repetition of the time-series data to compress data by discarding redundant data points. It can not only compress static batches of data but also dynamically compress data streams to improve system performance in real-time IoT-based monitoring systems. The offline Cocv outperforms traditional compressors on gas-leak monitoring data with a compression ratio of 98.5%, maintaining a decent speed for both compression and decompression. In an actual IoT-based gas-leak monitoring system, the online Cocv improves handling capacity by 255%, reading speed by 728%, reduces bandwidth consumption by 94%, and storage space consumption by 98% compared to the original scheme.}
}


@article{DBLP:journals/iot/SarmentoRMNRMV24,
	author = {Eduardo Montagner de Moraes Sarmento and
                  Iran Freitas Ribeiro and
                  Pablo Rafael Neves Marciano and
                  Yru{\'{\i}} Giovan Neris and
                  Helder Roberto Oliveira Rocha and
                  Vin{\'{\i}}cius Fernandes Soares Mota and
                  Rodolfo da Silva Villa{\c{c}}a},
	title = {Forecasting energy power consumption using federated learning in edge
                  computing devices},
	journal = {Internet Things},
	volume = {25},
	pages = {101050},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2023.101050},
	doi = {10.1016/J.IOT.2023.101050},
	timestamp = {Mon, 15 Apr 2024 08:26:25 +0200},
	biburl = {https://dblp.org/rec/journals/iot/SarmentoRMNRMV24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Several studies in the literature propose using machine learning algorithms to forecast consumers’ energy consumption. However, such data is sensitive and has privacy constraints. On the other hand, federated learning is a technique in which the training of machine learning algorithms is performed locally, where the data is generated. In this context, this article presents a hybrid neural network architecture, named CNN-LSTM FED, trained using the public Smart* and The Building Data Genome Project 2 datasets. Additionally, an augmented Smart* dataset was generated using Generative Adversarial Networks (GANs). The performance of CNN-LSTM FED was evaluated by comparing it against the MultiLayer Perceptron (MLP), which serves as a baseline, and against a non-federated version of the CNN-LSTM FED, named CNN-LSTM. Our approach was able to generalize the model even when less than 1% of buildings participated in the modeling process, forecasting with good results the energy consumption of other buildings. Furthermore, the deployment of this architecture in an edge computing device, with limited computational resources for training, is evaluated.}
}


@article{DBLP:journals/iot/TabuencaUGHBGG24,
	author = {Bernardo Tabuenca and
                  Manuel Uche{-}Soria and
                  Wolfgang Greller and
                  Davinia Hern{\'{a}}ndez{-}Leo and
                  Paula Balcells{-}Falgueras and
                  Peter A. Gloor and
                  Juan Garbajosa},
	title = {Greening smart learning environments with Artificial Intelligence
                  of Things},
	journal = {Internet Things},
	volume = {25},
	pages = {101051},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2023.101051},
	doi = {10.1016/J.IOT.2023.101051},
	timestamp = {Sat, 08 Jun 2024 13:15:49 +0200},
	biburl = {https://dblp.org/rec/journals/iot/TabuencaUGHBGG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This article investigates the functionality and applications of an Artificial Intelligence of Things (AIoT) system specifically designed for learning purposes. It presents three compelling case studies that pilot the AIoT system in various educational contexts. The first case study focuses on primary education and the use of a smart dashboard to monitor the state of plants in environmental awareness activities. In the second case study, conducted in higher education, variables such as\nCO\n2\nlevels, light intensity, and temperature are monitored to generate personalised recommendations for creating an optimal learning environment through tailored adjustments. The third case study explores the potential of plants to identify human presence and activity patterns in learning environments. By utilising the AIoT system’s capabilities, plant data is analysed to infer human presence and interactions. This innovative approach offers insights into understanding student behaviour and optimising learning environments based on real-time feedback from the plant ecosystem. Analysing these studies, the article deliberates on implications and future research opportunities in the realm of AI and IoT. It underscores the potential of AIoT systems in enhancing learning experiences, engaging students, and refining educational settings. The findings not only pave the way for future investigations, including model enhancements and privacy considerations but also emphasise AIoT’s potential in reshaping the educational landscape. This article serves as a valuable resource for researchers and practitioners keen on leveraging the synergy of AI and IoT in educational contexts.}
}


@article{DBLP:journals/iot/NogueiraBSGS24,
	author = {Jo{\~{a}}o V{\'{\i}}tor de Castro Martins Ferreira Nogueira and
                  Heder Soares Bernardino and
                  Jairo Francisco de Souza and
                  Luciana Brugiolo Gon{\c{c}}alves and
                  St{\^{e}}nio S{\~{a}} Ros{\'{a}}rio Furtado Soares},
	title = {Exploring the solution space for adaptive curriculum sequencing: Study
                  of a multi-objective approach},
	journal = {Internet Things},
	volume = {25},
	pages = {101052},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2023.101052},
	doi = {10.1016/J.IOT.2023.101052},
	timestamp = {Mon, 01 Apr 2024 11:15:32 +0200},
	biburl = {https://dblp.org/rec/journals/iot/NogueiraBSGS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Adaptive Curriculum Sequencing (ACS) is an important issue in personalized learning. In ACS problems, one desires the best sequence of learning materials that meet the profile of a given student. To do so, multiple features of the students and the materials used are necessary to generate good solutions. In fact, understanding the students’ goals, motivation, and preferences is not an easy task and, consequently, different Internet of Things (IoT) approaches to gather this information during the learning process have been proposed. Actually, some works from the literature consider five objectives and, in this case, one has a many-objective optimization problem. Instead of solving the optimization problem considering the multiple objectives individually, the usual approach is to obtain solutions for a weighted sum of the objective values using search approaches for mono-objective optimization problems. However, this kind of approach may bias the search and limits the capacity of finding good results. Here, we solve the multi-objective ACS problem considering five objective functions. NSGA-II, a well-known Genetic Algorithm for multi-objective optimization problems, was used. In addition, the aggregation trees were employed to reduce the number of objectives to two and three due to the large number of objectives in the original problem. ACS problems from the literature were used to comparatively evaluate the proposed methods and the results obtained were compared to those found by the traditional approach of summing the objective values. According to these results, the best curriculum sequences were reached when using the proposal.}
}


@article{DBLP:journals/iot/AlipioB24,
	author = {Melchizedek Alipio and
                  Miroslav Bures},
	title = {Current testing and performance evaluation methodologies of LoRa and
                  LoRaWAN in IoT applications: Classification, issues, and future directives},
	journal = {Internet Things},
	volume = {25},
	pages = {101053},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2023.101053},
	doi = {10.1016/J.IOT.2023.101053},
	timestamp = {Fri, 22 Mar 2024 08:58:41 +0100},
	biburl = {https://dblp.org/rec/journals/iot/AlipioB24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Long Range (LoRa) and Long Range Wide Area Network (LoRaWAN) are emerging technologies essential in connecting and managing a wide range of devices in various Internet of Things (IoT) systems. Testing and evaluation methods play a crucial role in assessing and optimizing the performance of these technologies before their deployment in real-world IoT applications. Previous review studies focused mainly on the comparison of current Low-Power Wide Area Networks (LPWAN) technologies, evaluating the performance of LoRa and LoRaWAN platforms for a general or specific application, or in a single testing methodology. However, the literature does not include any articles dedicated to comprehensively reviewing the current testing scenarios and performance evaluation methodologies used in LoRa-based or LoRaWAN-based networks deployed for IoT systems. Hence, this paper aims to review the state-of-the-art studies on LoRa and LoRaWAN test and evaluation methods in various IoT applications. In this paper, these studies are critically reviewed and classified according to their test parameters, test architectures, and performance evaluation methodologies. Additionally, a summary and unified view of test and evaluation methodologies to assess the performance characteristics of LoRa and LoRaWAN in IoT-driven applications is presented. Lastly, the issues and challenges behind these test cases and evaluation methods are identified, and the possible future directions of this research domain are discussed.}
}


@article{DBLP:journals/iot/TaoWZZYI24,
	author = {Jing Tao and
                  Junliang Wang and
                  Peng Zhang and
                  Jie Zhang and
                  Kai{-}Leung Yung and
                  W. H. Ip},
	title = {{LEGAN:} {A} low-light image enhancement generative adversarial network
                  for industrial internet of smart-cameras},
	journal = {Internet Things},
	volume = {25},
	pages = {101054},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2023.101054},
	doi = {10.1016/J.IOT.2023.101054},
	timestamp = {Mon, 03 Mar 2025 22:14:49 +0100},
	biburl = {https://dblp.org/rec/journals/iot/TaoWZZYI24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The utilization of smart-cameras in the context of the Internet of Things (IoT) has become increasingly prevalent within smart workshops for performing in-situ quality inspection tasks. However, it is worth noting that these smart-cameras may encounter operational challenges when functioning under low-light conditions. The images acquired in such situation are severely degraded, resulting in the performance decline of the subsequent detection algorithms. Focusing on non-stationary noise compression and detail recovery, this paper constructs a novel enhancement model called LEGAN for the industrial internet of smart-cameras system. Firstly, the input undergoes a decomposition process into two branches using the Harr-wavelet technique. These branches are subsequently encoded independently by a series of compact residual blocks, facilitating effective noise suppression. Secondly, in order to enhance detail recovery, a feature selection module is meticulously designed to extract correlations between image foreground–background and low–high frequency signals, ultimately reconstructing a comprehensive feature map. This enables a multi-scale stepwise up-sampling approach that facilitates image recovery based on the reconstructed feature maps. Lastly, the training phase is supervised by an adversarial loss, comprising MSE loss, VGG loss, and discriminating loss, which ensures a harmonious balance between noise suppression and detail recovery. Comparative experiments clearly show the superiority of the LEGAN in terms of noise compression and detail recovery. Moreover, from an industrial practice perspective, the application of the proposed approach to yarn evenness inspection has proven to be highly effective, significantly enhancing detection accuracy in low-light environments.}
}


@article{DBLP:journals/iot/SergioSDBM24,
	author = {Wagno Le{\~{a}}o Sergio and
                  Victor Str{\"{o}}ele and
                  M{\'{a}}rio Ant{\^{o}}nio Ribeiro Dantas and
                  Regina Braga and
                  Douglas Dyllon Jeronimo de Macedo},
	title = {Enhancing well-being in modern education: {A} comprehensive eHealth
                  proposal for managing stress and anxiety based on machine learning},
	journal = {Internet Things},
	volume = {25},
	pages = {101055},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2023.101055},
	doi = {10.1016/J.IOT.2023.101055},
	timestamp = {Mon, 01 Apr 2024 11:15:32 +0200},
	biburl = {https://dblp.org/rec/journals/iot/SergioSDBM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the evolving education landscape, institutions are transitioning to a hybrid model encompassing physical and virtual classes. In this scenario, as working hours and exhausting routines increase, individuals accumulate psychological and physical challenges over time. This change requires students and educators to adjust to changes in teaching and learning routines, leading to moments of stress and anxiety. Cultivating self-awareness about unhealthy habits emerges as a pragmatic strategy to address this issue. In this work, a comprehensive eHealth proposal is developed to provide individuals with pertinent health information, assisting educational agents (students and teachers) in identifying and managing these stressful instances during their daily activities. This proposal acquires, processes, and disseminates vital sign data using IoT devices, supported by a Fog Computing architecture for scalability and adaptability. IoT plays a pivotal role in this eHealth proposal, facilitating the seamless collection and transmission of real-time data from various devices. Connected wearables and sensors enable the continuous monitoring of vital signs, enhancing the accuracy and responsiveness of the system. Heart rate data from educational agents were collected for implementation, allowing the evaluation of system performance. Machine learning models were leveraged to discern behavioral profiles and predict possible irregularities in vital signs. The results confirm the system’s ability to perform its intended functions, giving users quick and accurate insights into their evolving behavioral patterns. Integrating these research perspectives underscores the importance of adaptive systems in navigating the challenges of modern education environments. The incorporation of IoT technology not only enhances data collection but also opens avenues for real-time interventions and personalized feedback, ultimately contributing to a more proactive approach in addressing health-related concerns within the educational context.}
}


@article{DBLP:journals/iot/SenguptaKDD24,
	author = {Diganta Sengupta and
                  Soumya Suvra Khan and
                  Surajit Das and
                  Debashis De},
	title = {FedEL: Federated Education Learning for generating correlations between
                  course outcomes and program outcomes for Internet of Education Things},
	journal = {Internet Things},
	volume = {25},
	pages = {101056},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2023.101056},
	doi = {10.1016/J.IOT.2023.101056},
	timestamp = {Mon, 01 Apr 2024 11:15:32 +0200},
	biburl = {https://dblp.org/rec/journals/iot/SenguptaKDD24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this study, Federated Learning (FL) has been used for decision making on decentralized Internet of Things (IoT) devices which store private educational data. The decentralized IoT devices form the edge devices at the institution/client level, i.e. each edge device is a single institution; and the decision making is done at the server (university) level. We propose a social Internet of Education Things framework which generates the correlations between the Course Outcomes (CO) and the Program Outcomes (PO) at the client for a certain course. The correlations are then aggregated at the server using fed-averaging. The CO-PO correlations at the edge are generated using distance metric between the semantics of the CO, the PO, and the syllabus. The CO-PO correlations are generated at the client in two ways — manually as well as using an AI model based on semantic analysis. The deviations between the manual and the AI model output is noted and sent to the server which aggregates the deviations, and feeds them back to the AI models at the clients. The clients adjust their CO-PO correlations based on the aggregated deviation values, and generate final CO-PO correlations based on the threshold values of [0, 1, 2, 3] corresponding to [No Correlation, Low, Medium, High] correlations. We observe a performance accuracy of 83.33% and a loss of 0.51 for our framework. To the entirety of our understanding, this study is the first attempt to use FL for generating CO-PO correlations at the edge/institution level.}
}


@article{DBLP:journals/iot/ThaiT24,
	author = {Binh Le Thanh Thai and
                  Hidema Tanaka},
	title = {A statistical Markov-based password strength meter},
	journal = {Internet Things},
	volume = {25},
	pages = {101057},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2023.101057},
	doi = {10.1016/J.IOT.2023.101057},
	timestamp = {Sun, 19 Jan 2025 14:28:18 +0100},
	biburl = {https://dblp.org/rec/journals/iot/ThaiT24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Although multi-factor authentication is gaining popularity, password-based authentication remains the most commonly employed method for both online login and data encryption. To help users choose secure passwords, password strength meters (PSMs) are a well-known and important tool. However, many PSMs still use simple rule sets or rely on heuristic results. With the continuous development of password-cracking methods, it is difficult for such PSMs to provide accurate assessment results. In this paper, we present a new PSM based on statistical results from a huge number of leaked passwords. The proposed method has a very simple structure, requires only a small amount of storage space, and succeeds in providing reliable feedback in real time. We also confirm the influence of linguistic features on user-created passwords and, therefore, recommend evaluating passwords based on the users’ language.}
}


@article{DBLP:journals/iot/AribilolaLA24,
	author = {Ifeoluwapo Aribilola and
                  Brian Lee and
                  Mamoona Naveed Asghar},
	title = {Pixel tampering detection in encrypted surveillance videos on resource-constrained
                  devices},
	journal = {Internet Things},
	volume = {25},
	pages = {101058},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2023.101058},
	doi = {10.1016/J.IOT.2023.101058},
	timestamp = {Sat, 08 Jun 2024 13:15:49 +0200},
	biburl = {https://dblp.org/rec/journals/iot/AribilolaLA24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Encryption (naïve/selective) is recommended to secure the recorded visual content; however, intruders can still manipulate encrypted data. Visually, tampering attacks on encrypted video pixels in selectively encrypted videos are difficult to identify. Thus, this paper presents a tampering detection system that performs vulnerability analysis for Regions-of-Interest (ROI) in encrypted videos. To detect the tampering attacks, we explored the pixels’ intensities and proposed a new TampDetect algorithm. The TampDetect applies the Hue, Saturation, and Value (HSV) colour model to detect the encrypted areas in the video. These encrypted pixels are then segmented and selected from the non-encrypted pixels using a minimum and maximum HSV value and a global threshold. The mean intensity of the encrypted pixels is thus calculated and stored. The integrity of the video frame is then validated by comparing the stored mean intensity with the newly calculated mean intensity to validate tampering/attack. The experiments were conducted on an Intel NUC, and its low computational cost demonstrates the lightweight nature of the proposed TampDetect algorithm for detecting tampering in ROI encrypted videos. The developed dataset for experiments, i.e., original, ROI encrypted, and tampered videos (encrypted/decrypted) is made available on kaggle-repository for future researchers.}
}


@article{DBLP:journals/iot/SekiguchiT24,
	author = {Naoya Sekiguchi and
                  Hidema Tanaka},
	title = {{BGP} hijack attack policy against {AS} topology map},
	journal = {Internet Things},
	volume = {25},
	pages = {101059},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101059},
	doi = {10.1016/J.IOT.2024.101059},
	timestamp = {Sat, 08 Jun 2024 13:15:49 +0200},
	biburl = {https://dblp.org/rec/journals/iot/SekiguchiT24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We focus on the activities of the adversary group targeting Autonomous Systems (AS). Many cases of large-scale disruptions and eavesdropping have been caused by Border Gateway Protocol (BGP) hijack, we evaluate the possibility of attack tactics and propose an attack strategy against AS connections using BGP hijack. Our computer simulations derive a local topology map of AS based on public log data. Using such a topology map, we evaluate the impact of the adversary group’s activity. From the results of computer simulations, we suggest two policies that allow adversary groups to execute attacks more efficiently; how to select the target area from the viewpoint of the attack Scenario and how to select the best attack Scenario from the given target area. Additionally, we analyze trends in the location of the ASes to be attacked. This allows AS managers to estimate the effective protection for more reliable operations.}
}


@article{DBLP:journals/iot/PuluckulSW24,
	author = {Priyesh Pappinisseri Puluckul and
                  Ritesh Kumar Singh and
                  Maarten Weyn},
	title = {TEGBed: {A} thermal energy harvesting testbed for batteryless internet
                  of things},
	journal = {Internet Things},
	volume = {25},
	pages = {101060},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101060},
	doi = {10.1016/J.IOT.2024.101060},
	timestamp = {Sun, 04 Aug 2024 19:51:17 +0200},
	biburl = {https://dblp.org/rec/journals/iot/PuluckulSW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper presents TEGBed, a testbed designed for the evaluation and testing of batteryless devices powered using thermal energy. TEGBed offers the capability to mimic real-life temperature gradients, providing researchers with a controlled environment for testing and evaluating batteryless devices. Researchers can leverage TEGBed to accelerate their investigations, gain insights into the behaviour of batteryless devices, and drive advancements in the field of sustainable and efficient IoT technologies. The TEGBed consists of a temperature emulator for emulating temperature differences, Joule Counter, a novel hardware tool for energy and power measurement, and a framework for non-supervised operation. By using the temperature emulator, TEGBed can emulate real-life energy harvesting situations in the lab. The Joule Counter allows gauging the power output from energy harvesting units for a wide range of output power. This enables researchers to gain insights into the energy harvesting capacity and efficiency of harvesting and power management units under different scenarios. With the help of different real-world use cases, we demonstrate the capabilities and effectiveness of TEGBed in assessing thermal energy harvesters and batteryless designs. In addition, we demonstrate how TEGBed can be used for the feasibility study of harvesting energy from two different underutilized heat sources; the temperature difference between soil and air and the temperature difference between the interior and exterior of a greenhouse. Emulations with the TEGBed show that, we could harvest an average of 0.89 mW power from soil-air temperature differences and 0.60 mW power from greenhouse temperature differences.}
}


@article{DBLP:journals/iot/QuyNAQ24,
	author = {Vu Khanh Quy and
                  Dinh C. Nguyen and
                  Dang Van Anh and
                  Nguyen Minh Quy},
	title = {Federated learning for green and sustainable 6G IIoT applications},
	journal = {Internet Things},
	volume = {25},
	pages = {101061},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101061},
	doi = {10.1016/J.IOT.2024.101061},
	timestamp = {Mon, 03 Mar 2025 22:14:48 +0100},
	biburl = {https://dblp.org/rec/journals/iot/QuyNAQ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The 6th generation mobile network (6G) is expected to be launched in the early 2030s. The architecture of 6G will be the convergence of space, air, ground, and undersea networks. The power and intelligence of 6G based on advanced AI techniques will realize the concept of the Industrial Internet of Things (IIoT). In this study, we conduct a comprehensive survey of 6G IIoT applications based on Federated Learning (FL), starting from introducing recent advances in FL and IIoT systems to discussing how to integrate them. In particular, we highlight the potential of FL for supporting a range of IIoT systems such as smart medical, intelligent transportation, smart cities, unmanned aerial vehicles, and smart industry. The important discussions to drive FL into IIoT applications are emphasized. Finally, we present challenges and open issues for future research to realize green and suitable FL-based IIoT applications.}
}


@article{DBLP:journals/iot/EduardUSOZ24,
	author = {Aida Eduard and
                  Dnislam Urazayev and
                  Aruzhan Sabyrbek and
                  Daniil Orel and
                  Dimitrios Zorbas},
	title = {Ad-hoc train-arrival notification system for railway safety in remote
                  areas},
	journal = {Internet Things},
	volume = {25},
	pages = {101062},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101062},
	doi = {10.1016/J.IOT.2024.101062},
	timestamp = {Sun, 06 Oct 2024 21:31:06 +0200},
	biburl = {https://dblp.org/rec/journals/iot/EduardUSOZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the last few years, a particular interest in using wireless technologies in the industrial domain in order to automate processes and increase the level of safety has been noticed. This paper introduces an affordable mobile system to notify railway workers in rural areas about the approach of trains, and thus, to enhance their safety allowing for the early evacuation of repair sites located near the rails. The system comprises three key elements: a train device, a portable station device, and wearable devices for the workers. The communication methods and the underlying protocols between these components are discussed in detail. The system has been developed for freight trains of the national railway company of Kazakhstan and has undergone extensive testing for each of its components before its final trial. The preliminary results demonstrate that the system meets the requirements in terms of evacuation time, range, and portability, while exhibiting a very low cost of manufacturing. More specifically, the system can achieve a reliable communication range of several kilometers and a maximum response time of 2.3 s. The cost does not exceed $500 for a set of train, station, and 5 worker devices.}
}


@article{DBLP:journals/iot/TrillesHI24,
	author = {Sergio Trilles and
                  Sahibzada Saadoon Hammad and
                  Ditsuhi Iskandaryan},
	title = {Anomaly detection based on Artificial Intelligence of Things: {A}
                  Systematic Literature Mapping},
	journal = {Internet Things},
	volume = {25},
	pages = {101063},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101063},
	doi = {10.1016/J.IOT.2024.101063},
	timestamp = {Sat, 08 Jun 2024 13:15:49 +0200},
	biburl = {https://dblp.org/rec/journals/iot/TrillesHI24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Advanced Machine Learning (ML) algorithms can be applied using Edge Computing (EC) to detect anomalies, which is the basis of Artificial Intelligence of Things (AIoT). EC has emerged as a solution for processing and analysing information on IoT devices. This field aims to allow the implementation of Machine/Deep Learning (DL) models on MicroController Units (MCUs). Integrating anomaly detection analysis on Internet of Things (IoT) devices produces clear benefits as it ensures the use of accurate data from the initial stage. However, this process poses a challenge due to the unique characteristics of IoT. This article presents a Systematic Literature Mapping of scientific research on the application of anomaly detection techniques in EC using MCUs. A total of 18 papers published over the period 2021–2023 were selected from a total of 162 in four databases of scientific papers. The results of this paper provide a comprehensive overview of anomaly detection using TinyML and MCUs. The main contributions of this survey are the fact that it aims to: (a) study techniques for anomaly detection in ML/DL and validation metrics used in the AIoT; (b) analyse data used in the estimation of models; (c) show how ML is applied in EC using hardware or software; (d) investigate the main microcontrollers, types of power supply, and communication technology; and (e) develop a taxonomy of ML/DL algorithms used to detect anomalies in TinyML. Finally, the benefits and challenges of this kind of TinyML analysis are described.}
}


@article{DBLP:journals/iot/IkegamiTKDK24,
	author = {Yukino Ikegami and
                  Setsuo Tsuruta and
                  Andrea Kutics and
                  Ernesto Damiani and
                  Rainer Knauf},
	title = {Fast ML-based next-word prediction for hybrid languages},
	journal = {Internet Things},
	volume = {25},
	pages = {101064},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101064},
	doi = {10.1016/J.IOT.2024.101064},
	timestamp = {Sat, 08 Jun 2024 13:15:49 +0200},
	biburl = {https://dblp.org/rec/journals/iot/IkegamiTKDK24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Smartphone users are beyond two billion worldwide. Heavy users of the texting application rely on input prediction to reduce typing effort. In languages based on the Roman alphabet, many techniques are available. However, Japanese text is based on multiple character sets such as Kanji (Chinese-like word symbols), Hiragana and Katakana syllable sets. For its time/labor intensive input, next word prediction is crucial. It is still an open challenge. To tackle this, a hybrid language model is proposed. It integrates a Recurrent Neural Network (RNN) with an n-gram model. RNNs are powerful models for learning long sequences for next word prediction. N-gram models are best at current word completion. Our RNN language model (RNN-LM) predicts the next words. According the “price” of the performance gain paid by a higher time complexity, our model best deploys on a client-server architecture. Heavily-loaded RNN-LM deploys on the server while the n-gram model on the client. Our RNN-LM consists of an input layer equipped with word embedding, an output layer, and hidden layers connected with LSTMs (Long Short-Term Memories). Training is done via BPTT (Back Propagation Through Time). For robust training, BPTT is elaborated by learning rate refinement and gradient norm scaling. To avoid overfitting, the dropout technique is applied except for LSTM. Our novel model is compact (2 LSTMs, 650 units per layer), indeed. Due to synergetic elaboration, it shows 10 % lower perplexity than Zaremba's excellent conventional models in our Japanese text prediction experiment. Our model has been incorporated into IME (Input Method Editor) we call Flick. On the Japanese text input experiment, Flick outperforms Mozc (Google Japanese Input) by 16 % in time and 34 % in the number of keystrokes.}
}


@article{DBLP:journals/iot/UsmanRMKQ24,
	author = {Muhammad Usman and
                  Azka Rehman and
                  Sharjeel Masood and
                  Tariq Mahmood Khan and
                  Junaid Qadir},
	title = {Intelligent healthcare system for IoMT-integrated sonography: Leveraging
                  multi-scale self-guided attention networks and dynamic self-distillation},
	journal = {Internet Things},
	volume = {25},
	pages = {101065},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101065},
	doi = {10.1016/J.IOT.2024.101065},
	timestamp = {Sun, 19 Jan 2025 14:28:18 +0100},
	biburl = {https://dblp.org/rec/journals/iot/UsmanRMKQ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Through the Internet of Medical Things (IoMT), early diagnosis of various critical diseases has been revolutionized, particularly via sonography in thyroid nodule identification. Despite its benefits, accurate thyroid nodule segmentation remains challenging due to the heterogeneity of nodules in terms of shape, size, and visual characteristics. This complexity underscores the necessity for improved Computer-Aided Diagnosis (CAD) methods that can provide robust assistance to radiologists. Subsequently, this study introduces a multiscale self-guided network leveraging a novel Dynamic Self-Distillation (DSD) training framework to significantly enhance thyroid nodule segmentation. The developed architecture captures rich contextual dependencies by capitalizing on self-guided attention mechanisms, thus fusing the local features with corresponding global dependencies while adaptively highlighting interdependent channel maps. Irrelevant information from coarse multiscale features is filtered out using self-guided attention mechanisms, leading to the generation of refined feature maps. These maps, in turn, facilitate the creation of accurate thyroid nodule segmentation masks. The novel DSD mechanism, implemented to train the architecture, dynamically selects the teacher branch based on performance relative to the ground truth label, and computes distillation losses for each student branch. Evaluation on two publicly available datasets reveals the superior performance of our framework over its downgraded versions and existing state-of-the-art techniques, demonstrating the promising potential of our proposed approach to be employed for thyroid nodule segmentation in IoMT. Our source code is made publicly available at: https://github.com/Azkarehman/MAXedNet.}
}


@article{DBLP:journals/iot/GilaniAKSMS24,
	author = {Syeda Mahnoor Gilani and
                  Adeel Anjum and
                  Abid Khan and
                  Madiha Haider Syed and
                  Syed Atif Moqurrab and
                  Gautam Srivastava},
	title = {A robust Internet of Drones security surveillance communication network
                  based on {IOTA}},
	journal = {Internet Things},
	volume = {25},
	pages = {101066},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101066},
	doi = {10.1016/J.IOT.2024.101066},
	timestamp = {Sat, 08 Jun 2024 13:15:49 +0200},
	biburl = {https://dblp.org/rec/journals/iot/GilaniAKSMS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Drones are increasingly utilized for a variety of purposes, spanning military to civilian applications. The rise in drone usage underscores privacy and security challenges concerning flight boundaries, data collection in public and private domains, as well as data storage and dissemination. Such issues highlight drones’ capability to communicate and securely store data over potentially insecure channels. Recognizing these challenges and gaps in the literature, this paper introduces an efficient and secure security surveillance model for the Internet of Drones (IoD). Our model ensures secure communication between Ground Stations (GS) and Drones, effectively addressing various attack types. Particularly, surveillance drones are vulnerable to physical capture attacks. We delve into a scenario where a network drone is physically apprehended. Leveraging the information stored within a drone, the attacker could potentially access the session. This paper proposes a solution to counter such threats. Through experiments using MATLAB and VScode, we evaluate our network’s efficiency and scalability in relation to the surge in transactions. The findings reveal our model’s prowess in handling large-scale networks. Specifically, when transactions surpass 1000 per minute, our model achieves approximately a 20% reduction in processing time compared to existing works. Moreover, our approach facilitates about 80% enhanced communication efficiency relative to the contemporary state-of-the-art frameworks. A security analysis through Automated Validation of Internet Security Protocols and Applications (AVISPA) further corroborates the robustness and security of our proposed communication strategy against diverse attack types.}
}


@article{DBLP:journals/iot/KumarSCDT24,
	author = {Gulshan Kumar and
                  Rahul Saha and
                  Mauro Conti and
                  Tannishtha Devgun and
                  Reji Thomas},
	title = {{GREPHRO:} Nature-inspired optimization duo for Internet-of-Things},
	journal = {Internet Things},
	volume = {25},
	pages = {101067},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101067},
	doi = {10.1016/J.IOT.2024.101067},
	timestamp = {Tue, 07 May 2024 20:25:59 +0200},
	biburl = {https://dblp.org/rec/journals/iot/KumarSCDT24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The optimization techniques usually work with the maximization or minimization of the problem to obtain the local loci or cumulative global loci. Two-dimensional bio-inspired optimization techniques face convexing problems towards a global solution and use an increased number of iterations. Besides, the duality principle considers the dual optimization aspects of the problems leading to a large duality gap of uncertain deviations and optimization errors between any prime solution and its dual solution. Moreover, several problems exist where one objective function requires maximization and another objective function requires minimization using the same set of parameters and some chaining of the feedback process. In such cases, we generally use two different optimization problems as per the best suit to the problem environment and obtain the different sub-solutions of the individual problems. This increases the complexity of the system and often deviates from the original optimal solution. We address these problems of dual optimization in our present work.}
}


@article{DBLP:journals/iot/AhadZTSSR24,
	author = {Abdul Ahad and
                  Jiangbina Zheng and
                  Mohammad Tahir and
                  Ibraheem Shayea and
                  Muhammad Aman Sheikh and
                  Faizan Rasheed},
	title = {6G and intelligent healthcare: Taxonomy, technologies, open issues
                  and future research directions},
	journal = {Internet Things},
	volume = {25},
	pages = {101068},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101068},
	doi = {10.1016/J.IOT.2024.101068},
	timestamp = {Sun, 19 Jan 2025 14:28:17 +0100},
	biburl = {https://dblp.org/rec/journals/iot/AhadZTSSR24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A decentralised patient-centric paradigm is gradually replacing the traditional hospital and specialist- focused healthcare model. Communication technologies have made it possible to provide customised and remote healthcare services. As the healthcare industry grows, the number of applications connected to the network will create data in various sizes and forms. The future network will face complex data rate, bandwidth, and latency demands. The existing communication technologies cannot meet the complex and diverse demands placed on communication networks by a wide range of healthcare applications. Therefore, the next generation of communication technology touted as the sixth generation (6G), is expected to provide crucial infrastructure for healthcare by 2030. Healthcare will be AI-driven and reliant on 6G connectivity technology, improving quality of life and healthcare services. Furthermore, future intelligent healthcare networks are expected to contain a combination of sixth-generation (6G) and Internet of Things (IoT) components that will increase network performance and cellular coverage and address a number of security concerns. This paper explores challenges in future of smart healthcare concerned with communication technologies and potential solutions for the early detection and mitigation of emergencies from the sixth-generation wireless technology perspective.}
}


@article{DBLP:journals/iot/ZhaoZC24,
	author = {Gang Zhao and
                  Yinan Zhang and
                  Jie Chu},
	title = {A multimodal teacher speech emotion recognition method in the smart
                  classroom},
	journal = {Internet Things},
	volume = {25},
	pages = {101069},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101069},
	doi = {10.1016/J.IOT.2024.101069},
	timestamp = {Mon, 01 Apr 2024 11:15:32 +0200},
	biburl = {https://dblp.org/rec/journals/iot/ZhaoZC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As a collection of various IoT devices, smart classroom can record various forms of teaching data and provide rich data for recognizing teachers' emotions. Recognizing and analyzing teachers' emotions can promote teachers' professional development. Nowadays, most of the automatic emotion recognition methods for teachers in smart classroom are based on facial expressions. However, since teachers usually keep smiling to mobilize the classroom atmosphere, the recognition results may not reflect the real mental state of teachers. By observing teaching videos, it is found that the prosody and text in the teachers' speech can reflect the implicit emotion of the teacher. Therefore, a multimodal teacher emotion dataset (MTED) was built based on teaching videos recorded by IoT cameras and microphones in smart classroom. A neural network combining multiple prosodic features and text content for teacher speech emotion recognition is proposed. The proposed method fills the gap in teacher speech emotion recognition, our proposed method has higher accuracy. Experimental results show that ProsodyBERT achieves 78.6 %\nU\nA\n4\nand 66.2 %\nU\nA\n6\non IEMOCAP and MELD, respectively, surpassing the existing methods. The proposed method reached 82.1%\nU\nA\n6\non MTED self-built dataset, which is 9.6 %-21.4 % higher than that of unimodal method in teacher emotion recognition. An ablation experiment is designed and implemented on MTED dataset to explore the influence of each module in ProsodyBERT on teacher speech emotion recognition task. The experimental results in the smart classroom record show that ProsodyBERT has higher accuracy and stronger robustness than unimodal methods.}
}


@article{DBLP:journals/iot/MaimourAR24,
	author = {Moufida Maimour and
                  Arsalan Ahmed and
                  Eric Rondeau},
	title = {Survey on digital twins for natural environments: {A} communication
                  network perspective},
	journal = {Internet Things},
	volume = {25},
	pages = {101070},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101070},
	doi = {10.1016/J.IOT.2024.101070},
	timestamp = {Sun, 19 Jan 2025 14:28:19 +0100},
	biburl = {https://dblp.org/rec/journals/iot/MaimourAR24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the last decade or so, digital twins have emerged as a disruptive technology opening doors for digital innovation and modernization. A digital twin is defined as an accurate virtual model reflecting the state of a physical asset. With their futuristic applications, digital twins have already revolutionized several industrial sectors including product life cycle management, smart cities, healthcare and aerospace. More recently, researchers have started creating digital twins for natural environments. Virtual models are developed to understand, manage and protect these ecosystems which have huge potential in resisting their global decline in the face of the environmental crisis. Therefore, this article surveys the state-of-the-art research that is available in the area of digital twins for natural environments from a networking perspective. A comprehensive background on the topic is presented along with a systematic literature survey. Based on the survey, a set of open issues are identified and discussed for enhancing the future work in the field.}
}


@article{DBLP:journals/iot/RamisBibiloniC24,
	author = {Jaume Ramis{-}Bibiloni and
                  Loren Carrasco{-}Martorell},
	title = {Lengthening battery life expectancy of sensors in WBANs: {A} multifactorial
                  approach},
	journal = {Internet Things},
	volume = {25},
	pages = {101071},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101071},
	doi = {10.1016/J.IOT.2024.101071},
	timestamp = {Sat, 08 Jun 2024 13:15:49 +0200},
	biburl = {https://dblp.org/rec/journals/iot/RamisBibiloniC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Wireless Body Area Networks (WBANs) are emerging as a key component in healthcare within the Internet of Things (IoT) ecosystem, with sensor battery life being crucial for widespread adoption. To that end, the present work analyzes the different components of sensor’s energy consumption with the objective of deriving analytical expressions for the battery lifespan for an ETSI SmartBAN compliant network. Results have revealed that the sensing energy consumption, commonly considered negligible, cannot always be ignored. Moreover, stringent Quality of Service (QoS) requirements of the physiological sensed data, such as error rate and end-to-end delay, must be fulfilled. Therefore, our approach synergizes an energy-efficient and QoS-aware PHY/MAC configuration framework with sensor energy harvesting. To further increase the WBANs autonomy, the present proposal integrates adaptive sampling mechanisms at sensors. Additionally, this research incorporates the patient’s status information and the sensor’s battery level to regulate the behavior of the system. This novel multifactorial approach has allowed an in-depth and comprehensive investigation of the synergies and mutual influences among the different components that integrate this multipronged proposal, demonstrating a significant potential for lengthening the sensor’s battery life expectancy and to substantially extend the WBANs autonomy. Notably, adaptive sampling markedly improves battery lifespan, especially with higher harvestable power levels and shorter MAC frames. In scenarios with lower battery charge or improved patient conditions, the adaptive sampling framework notably enhances system performance and battery lifetime. An ‘average’ case study, considering a medium patient critical level and a 50% battery charge, shows that adaptive sampling can increase battery duration up to 840.94%, significantly boosting WBANs autonomy.}
}


@article{DBLP:journals/iot/AlshuaibiHH24,
	author = {Enaam Abdulmonem Alshuaibi and
                  Aisha Muhammad Hamdi and
                  Farookh Khadeer Hussain},
	title = {Volunteer Computing for fog scalability: {A} systematic literature
                  review},
	journal = {Internet Things},
	volume = {25},
	pages = {101072},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101072},
	doi = {10.1016/J.IOT.2024.101072},
	timestamp = {Mon, 01 Apr 2024 11:15:32 +0200},
	biburl = {https://dblp.org/rec/journals/iot/AlshuaibiHH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Fog computing (FC) is a scalable and responsive computing paradigm that uses distributed computing resources to provide efficient and localized data processing solutions to industries and businesses. Due to the exponential growth of the Internet of Things (IoT), data processing has evolved from traditional centralized cloud computing to decentralized architectures such as FC. However, due to the distributed nature of the fog network, its implementation presents significant challenges, especially in resource management, due to a number of factors, including the dynamic and unpredictable nature of workloads, energy efficiency considerations, and interoperability concerns. In this paper, we explore the benefits that can be gained and the requirements that are needed to maximize the scalability of FC by using volunteer computing (VC). This paper aims to provide valuable information on the use of volunteer computing as a viable solution to the challenges associated with fog scalability. For this purpose, we identify three requirements that are fundamental to address to ensure the efficient integration of VC in the FC environment to take full advantage of the potential of these idle computing resources before reviewing the existing literature. Five well-known and highly ranked online databases were used to collect and identify state-of-the-art approaches, published between 2015 and 2023, that are relevant to this survey. Based on the analysis of the twelve relevant articles, we identify open issues and potential gaps that need further investigation by synthesizing existing research. Furthermore, we anticipate that this review will inspire researchers and practitioners to explore innovative methods and strategies to overcome the challenges and unlock the full potential of VC in FC environments.}
}


@article{DBLP:journals/iot/QuZL24,
	author = {Songsong Qu and
                  Yubin Zhao and
                  Xiaofan Li},
	title = {Joint energy beamforming and bandwidth allocation for cooperative
                  localization in passive sensor networks},
	journal = {Internet Things},
	volume = {25},
	pages = {101073},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101073},
	doi = {10.1016/J.IOT.2024.101073},
	timestamp = {Sun, 19 Jan 2025 14:28:18 +0100},
	biburl = {https://dblp.org/rec/journals/iot/QuZL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Passive sensor networks (PSNs) harvest continuous radio-frequency (RF) energy to work. However, the location information is difficult to maintain with unstable power supply for each passive sensor node. Cooperative localization is a promising solution utilizes the cooperation between the nodes with unknown positions to maintain the location information. And the localization performance relies on the attained energy from the energy access point (E-AP) and also the allocated bandwidth for each node. In this paper, we analyze the impacts of energy beamforming and bandwidth allocation on the cooperative localization performance of PSNs. We formulate the Fisher information matrix (FIM) and deduce the squared position error bound (SPEB) for the proposed network. Then, we propose an alternative optimization method for jointly energy beamforming and bandwidth allocation. Firstly, we employ the first-order Taylor expansions based on the trust region method to allocate the bandwidth of each node. Secondly, the Lagrangian multiplier based energy beamforming strategy is proposed. Then, the bandwidth allocation and energy beamforming calculations are executed alternatively and iteratively until the global optimal solution is achieved. The simulation results indicate that our proposed two-step method can achieve high precision positioning in different scenarios, and the SPEBs of proposed method reach\n1\n0\n−\n3\nm\n2\n.}
}


@article{DBLP:journals/iot/LiuWSWL24,
	author = {Peiqian Liu and
                  Duoduo Wu and
                  Zihao Shen and
                  Hui Wang and
                  Kun Liu},
	title = {Personalized trajectory privacy data publishing scheme based on differential
                  privacy},
	journal = {Internet Things},
	volume = {25},
	pages = {101074},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101074},
	doi = {10.1016/J.IOT.2024.101074},
	timestamp = {Sun, 19 Jan 2025 14:28:20 +0100},
	biburl = {https://dblp.org/rec/journals/iot/LiuWSWL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The proliferation of smart devices with location-based services has significantly facilitated people's lives and generated a large amount of trajectory data. Analyzing this data can contribute to societal development, such as the construction of public facilities and intelligent transportation systems. But illegal leakage of data poses a serious threat to individual privacy within the released data. Currently, differential privacy technology has emerged as a rigorous and standardized privacy protection framework widely applied in trajectory data publishing. However, existing methods often suffer from either excessive privacy protection or insufficient protection of individual privacy. Therefore, this paper proposes a personalized trajectory privacy data protection scheme based on differential privacy (DP_SR). The scheme combines TF-IDF statistics and designs personalized exponential noise to protect the sensitive personal data in each trajectory, achieving personalized privacy protection. Then an RTF-tree is constructed, and differential privacy techniques are employed to safeguard the security of the entire trajectory dataset. Experimental results on two real trajectory dataset demonstrate that the proposed scheme achieves a better balance between privacy protection and data utility compared with state-of-the-art algorithms.}
}


@article{DBLP:journals/iot/JSBMS24,
	author = {Jyothish Kumar J and
                  Shreya Shivangi and
                  Amish Bibhu and
                  Subhankar Mishra and
                  Sulagna Saha},
	title = {{MIMA} 2.0 - Compact and portable Multifunctional IoT integrated Menstrual
                  Aid},
	journal = {Internet Things},
	volume = {25},
	pages = {101075},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101075},
	doi = {10.1016/J.IOT.2024.101075},
	timestamp = {Sun, 19 Jan 2025 14:28:17 +0100},
	biburl = {https://dblp.org/rec/journals/iot/JSBMS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The shredding intrauterine lining or the endometrium is known as Menstruation. It occurs every month and causes several issues like Menstrual Cramps and aches in the abdominal region, stains, menstrual malodor, rashes in intimate areas, and many more. In our research, almost all of the products available in the market do not cater to these problems single-handedly. There are few remedies available to cater to the cramps, among which heat therapy is the most commonly used. Our methodology, involved surveys regarding problems and the solutions to these problems that are deemed optimal. This inclusive approach helped us infer about the gaps in available menstrual aids which has become our guide towards developing MIMA (Multifunctional IoT Integrated Menstrual Aid). In this paper, we have featured an IOT incorporated multifunctional smart intimate wear that aims to provide for the multiple necessities of women during menstruation like leakproof, antibacterial, anti-odor, rash-free experience along with an integrated Bluetooth-controlled intimate heat-pad for relieving abdominal cramps. The entire process of product development has been done in phases according to feedback from target users in each stage. This paper is an extension to our paper (Bibhu et al., 2022) [1] which serves as the proof of concept for our approach. The development has led us towards MIMA 2.0 featuring a completely concealed and integrated design that includes a safe Bluetooth-controlled heating system for the intimate area. The product has received incredibly positive feedback from survey participants.}
}


@article{DBLP:journals/iot/BilgiliDA24,
	author = {Sedat Bilgili and
                  Alper Kamil Demir and
                  Shahid Alam},
	title = {IfNot: An approach towards mitigating interest flooding attacks in
                  Named Data Networking of Things},
	journal = {Internet Things},
	volume = {25},
	pages = {101076},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101076},
	doi = {10.1016/J.IOT.2024.101076},
	timestamp = {Sat, 08 Jun 2024 13:15:49 +0200},
	biburl = {https://dblp.org/rec/journals/iot/BilgiliDA24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Named Data Networking (NDN) has emerged as a model to accommodate content distribution, security, and mobility. Recently, NDN has been applied to the Internet of Things (IoT), referred to as Named Data Networking of Things (NDNoT). In the rapidly evolving landscape of the NDNoT securing data transmission is paramount. The main purpose and contribution of the research presented in this paper is to safeguard the security vulnerabilities of data transmission in NDNoT. This paper specifically addresses the critical issue of interest flooding attacks in NDNoT. These attacks can disrupt network operations posing far-reaching threats to data integrity and availability. To mitigate these attacks and threats the paper introduces the IfNoT mechanism and evaluates its performance through comprehensive simulations in a realistic and recognized simulator, called Cooja. IfNot identifies the potential interest flooding attacker nodes in the NDNoT environment. It reduces the impact of the attack and the undesirable interest traffic caused by such an attack, which optimizes the network resource utilization at a maximum level. The study also explores the influence of key parameters provided by the IfNoT mechanism. Moreover, the study also identifies optimum settings for these parameters to enhance network utilization. When evaluated using various metrics, including success rate, average latency, and total interest traffic, under different conditions and parameter settings, IfNoT was able to counter the interest flooding attacks effectively. IfNoT mechanism is able to increase success ratio up to 28%, decrease average latency up to 31%, and decrease total interest traffic up to 58%.}
}


@article{DBLP:journals/iot/BandaraLFSMRRZN24,
	author = {Eranga Bandara and
                  Xueping Liang and
                  Peter Foytik and
                  Sachin Shetty and
                  Ravi Mukkamala and
                  Abdul Rahman and
                  Nalin Ranasinghe and
                  Kasun De Zoysa and
                  Wee Keong Ng},
	title = {Lightweight, geo-scalable deterministic blockchain design for 5G networks
                  sliced applications with hierarchical {CFT/BFT} consensus groups,
                  {IPFS} and novel hardware design},
	journal = {Internet Things},
	volume = {25},
	pages = {101077},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101077},
	doi = {10.1016/J.IOT.2024.101077},
	timestamp = {Sun, 06 Oct 2024 21:31:06 +0200},
	biburl = {https://dblp.org/rec/journals/iot/BandaraLFSMRRZN24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {5G network sliced applications enable IoT networks to connect billions of heterogeneous objects, providing high-quality service, network capacity, and enhanced throughput. The blockchain systems which attempt to facilitate 5G network-sliced application requirements present several challenges, such as lack of decentralized governance, reduced transaction throughput/scalability, inability to run on resource-constrained devices, lack of support for real-time/concurrent transaction handling, and non-deterministic Byzantine Fault Tolerance (BFT) consensus models. In this paper, we propose a highly scalable, lightweight blockchain system, “Librum,” for 5G-based network sliced applications. Librum’s lightweight design enables it to run in edge networks, and we have designed low-cost hardware nodes to run the Librum blockchain edge network. The embedded hardware devices contain wifi and cellular modules that allow the Librum blockchain nodes to be run on 5G edge networks. The Librum blockchain, stored on IPFS peer-to-peer decentralized storage, enables any Byzantine node to participate in the network. Librum’s Fungible (ERC20) and Non-Fungible Token (ERC721) smart contracts support concurrent transaction execution with a novel “Validate–Execute” blockchain architecture. We incorporated hierarchical consensus groups to run independent blockchain shards (local consensus groups) on different 5G network slices. The shards can run BFT or CFT (Crash Fault Tolerance) consensus models and reach global consensus via core-blockchain nodes in the network based on connectivity requirements. Core blockchain nodes can also run with BFT (e.g., Tendermint) or CFT (e.g., Proof-of-Authority/Kafka) consensus models, eliminating message-passing overhead and achieving BFT with a deterministic consensus model in Geo-distributed blockchain networks. Dynamic 5G network slice orchestration and data provenance of network slices are implemented with smart contracts. The proposed Librum blockchain is integrated with FreedomeFi and Magma 5G core-based 5G testbed environments.}
}


@article{DBLP:journals/iot/JuniorK24,
	author = {Franklin Magalh{\~{a}}es Ribeiro Junior and
                  Carlos Alberto Kamienski},
	title = {Federated learning for performance behavior detection in a fog-IoT
                  system},
	journal = {Internet Things},
	volume = {25},
	pages = {101078},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101078},
	doi = {10.1016/J.IOT.2024.101078},
	timestamp = {Sun, 19 Jan 2025 14:28:20 +0100},
	biburl = {https://dblp.org/rec/journals/iot/JuniorK24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In fog-based IoT systems, every fog can behave differently due to context and vulnerabilities. In smart irrigation systems, some fog nodes use more or fewer computing resources to analyze the data according to sensor location, soil moisture, plant species, or seasons. Therefore, fog behavior should consider distinct contexts. Federated learning support fog-based IoT systems to detect faster the behavior of fog nodes as it enables them to perceive previous behaviors from their peer nodes. We develop and assess an unsupervised federated learning system to identify fog anomalies. We consider experiments with seven rounds of four minutes, executing K-Means in every node to obtain local centroids, and the system merges them in the cloud to calculate global centroids, sending them back to the fog nodes. This paper evaluates the accuracy and time a fog node needs to predict a behavior already identified by another fog node. We assess the CPU usage and the time the cloud takes to compute global centroids using thousands of local cluster centers and measure the prediction time for different fog hardware. We observe that the cloud CPU usage and time to obtain the global centroids vary according to the number of fog nodes and the number of fog behaviors. Our results also show that, in the worst case, our system predicts a behavior by around 50 ms. In contrast, a non-federated approach must wait for the current round to end, as 51.3 s in our results. Therefore, our approach shows promising results for time-sensitive IoT systems.}
}


@article{DBLP:journals/iot/BalciS24,
	author = {Abdullah Balci and
                  Radosveta Sokullu},
	title = {Fairness aware deep reinforcement learning for grant-free NOMA-IoT
                  networks},
	journal = {Internet Things},
	volume = {25},
	pages = {101079},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101079},
	doi = {10.1016/J.IOT.2024.101079},
	timestamp = {Sun, 19 Jan 2025 14:28:18 +0100},
	biburl = {https://dblp.org/rec/journals/iot/BalciS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Next generation networks have special areas related with the Internet of Things (IoT) to improve the performance of cellular networks in terms of throughput. Grant-free non-orthogonal multiple access (GF-NOMA) seems a feasible solution, letting machine type communication (MTC) devices transmits their packets when they ready to transmit. GF-NOMA increases the spectral efficiency by using the superimposing signals with different power levels over the same time and frequency resources. However, the main drawbacks of GF-NOMA are randomness and the management of power level selection of MTC devices. In 6G-IoT networks, the intelligence should be met to random access. It is time to design new access methods to solve the GF-NOMA issues that should be between the randomness and fully coordinated medium access. Deep-\nQ\n-Network (DQN) has become a very hot research topic in recent years that let the MTC devices to make a smart decision in an intelligent way to improve the throughput. Selfishness is an undesirable behavior of DQN for GF-NOMA system where the resources have different cost. In this study, we develop a novel learning framework for power domain GF-NOMA. The goal of our learning framework is to maximize the throughput considering fairness in power consumption which provides long-life to the IoT network. The learning algorithm push the MTC devices to exchange the resources between each other over time. The results show that the proposed method outperform the NOMA scheme with random selection in terms of throughput and increase the fairness index when the DQN with selfish behavior is employed.}
}


@article{DBLP:journals/iot/BakhtiaryMSE24,
	author = {Vahid Bakhtiary and
                  Meghdad Mirabi and
                  Afshin Salajegheh and
                  Seyed Hossein Erfani},
	title = {Combo-Chain: Towards a hierarchical attribute-based access control
                  system for IoT with smart contract and sharding technique},
	journal = {Internet Things},
	volume = {25},
	pages = {101080},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101080},
	doi = {10.1016/J.IOT.2024.101080},
	timestamp = {Sun, 19 Jan 2025 14:28:18 +0100},
	biburl = {https://dblp.org/rec/journals/iot/BakhtiaryMSE24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Internet of Things (IoT) provides a collaborative environment among different entities (i.e., users, IoT devices, sensors, applications, etc.) to access resources. Despite the benefits that IoT technology brings to individuals, society, and industry, this technology faces a critical challenge in controlling access to various resources in IoT environments. To address this challenge, we propose Combo-Chain, an blockchain-based access control system deeply rooted in the concepts of the attribute-based access control (ABAC) model, smart contracts, and sharding. Combo-Chain introduces the concept of hierarchy for both subject attributes and object attributes to enhance flexibility and dynamicity when specifying ABAC policies, simplifying policy and attribute management. It not only manages access policies but also attributes by deploying a set of smart contracts. Furthermore, Combo-Chain utilizes sharding technique to distribute the overhead associated with storing and managing both access policies and attributes. Sharding also helps Combo-Chain to distribute the computational overhead when evaluating access requests among two groups of nodes, addressing the issues of low scalability and poor performance often associated with blockchain technology. Combo-Chain is implemented on a private Ethereum platform, and the experimental results demonstrate the superiority of Combo-Chain compared to existing blockchain-based access control systems.}
}


@article{DBLP:journals/iot/BounairaAS24,
	author = {Soumaya Bounaira and
                  Ahmed Alioua and
                  Ismahane Souici},
	title = {Blockchain-enabled trust management for secure content caching in
                  mobile edge computing using deep reinforcement learning},
	journal = {Internet Things},
	volume = {25},
	pages = {101081},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101081},
	doi = {10.1016/J.IOT.2024.101081},
	timestamp = {Mon, 01 Apr 2024 11:15:32 +0200},
	biburl = {https://dblp.org/rec/journals/iot/BounairaAS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Mobile edge computing (MEC) has introduced content edge caching to offload network backhaul and improve user quality of experience by transferring frequently requested content to edge nodes near end-users. However, the implementation of edge caching is fraught with significant security and confidentiality issues due to the lack of trust between the different entities involved in the caching process. Most existing solutions for managing trust in edge caching only consider the trust between caching edge servers and ignore the trust between edge servers and content providers. This paper aims to fill this gap by proposing a trust management-based edge caching system that exploits the potential of blockchain technology to secure the caching process by enabling trust between content providers and edge servers. The proposed trust management system establishes trust in both directions of the interaction, providing higher confidence between the caching actors. Our trust system is based on a direct trust score calculated using the subjective three value logic scheme (3VSL). This is complemented by a reputation-based indirect trust score managed by the blockchain. A deep reinforcement learning (DRL) algorithm is proposed to efficiently make secure and intelligent caching decisions. The simulation results show that the proposed blockchain-based trust management system is effective and guarantees a good level of security and confidentiality for edge caching. They also demonstrate that our DRL caching algorithm provides secure and intelligent caching decisions in MEC, outperforming the baseline edge caching schemes.}
}


@article{DBLP:journals/iot/PinoRMO24,
	author = {Andr{\'{e}}s Felipe Solis Pino and
                  Pablo H. Ruiz and
                  Alicia Mon and
                  C{\'{e}}sar Alberto Collazos Ord{\'{o}}{\~{n}}ez},
	title = {Systematic literature review on mechanisms to measure the technological
                  maturity of the Internet of Things in enterprises},
	journal = {Internet Things},
	volume = {25},
	pages = {101082},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101082},
	doi = {10.1016/J.IOT.2024.101082},
	timestamp = {Sun, 19 Jan 2025 14:28:19 +0100},
	biburl = {https://dblp.org/rec/journals/iot/PinoRMO24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Internet of Things has emerged as a disruptive technological paradigm with exponential growth and potential benefits for enterprises. However, assessing its technological maturity in organizations is complex because of the need for standardized mechanisms, adequate tools, and rapid growth. This study aims to consolidate and analyze the existing knowledge in the field to support measuring technological maturity in the domain. A systematic literature review was conducted following the methodology proposed by Petersen to synthesize and analyze the state of the art in the area. The study retrieved 1,375 documents from seven bibliographic databases and applying inclusion and exclusion criteria, 58 primary studies were selected. The main results show a diversity of approaches, mechanisms, and dimensions to estimate the technological maturity of the Internet of Things in enterprises, but also a need for more empirical evidence, practical implementations, and a lack of standardization in the proposals, which limits their possibilities. The most important conclusion is that the domain matures but requires further multidisciplinary research to address the identified challenges and gaps.}
}


@article{DBLP:journals/iot/IslamP24,
	author = {Malik Obaid Ul Islam and
                  Shabir A. Parah},
	title = {Fast and Lightweight Image Cryptosystem for IoMT Applications},
	journal = {Internet Things},
	volume = {25},
	pages = {101083},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101083},
	doi = {10.1016/J.IOT.2024.101083},
	timestamp = {Mon, 03 Mar 2025 22:14:48 +0100},
	biburl = {https://dblp.org/rec/journals/iot/IslamP24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This paper presents a fast and lightweight image encryption technique founded on a new concept of progressive and selective diffusion. We make use of modified chaotic systems like the sine-logistic system, sine-tangent system, and tent-logistic system to generate key blocks for diffusion. The encryption procedure comprises three stages: column diffusion, permutation, and row diffusion, which collectively contribute to the overall encryption mechanism. In the first stage, progressive and selective column substitution of the input image is conducted employing key-blocks\nD\n1\nand\nD\n2\n, in a manner that each substituted column data is a function of previously diffused data. In the second stage, the column-substituted image goes through an adaptive permutation operation realized using an improved sin-logistic system. The last stage incorporates two distinct mappings based on key arrays and key blocks to ensure selective and progressive inter-row substitution/diffusion. The experimental results suggest that the proposed image system exhibits rapid performance as it reports an average encryption time of 0.03 seconds for an image of the size 256×256. Besides, the use of 1-D chaotic maps together with simple yet effective confusion and diffusion processes make it lightweight. Furthermore, it provides better security performance shown by various parameters like Information Entropy Analysis (IE), Correlation Coefficient analysis (CC), Histogram analysis, Differential Attacks Analysis (NPCR and UACI), key sensitivity assessment, and fidelity analysis. The suggested system has the capability to meet the cryptographic objectives as it reports average values of IE = 7.9974, CC =0.0035, NPCR =99.61%, UACI = 33.48%, and an enormously large key space compared to the state-of-art. The proposed technique offers enhanced data security, preserving patient privacy and preventing unauthorized access, while ensuring efficient encryption performance to assure the security and immediate transmission and storage of medical images. The better security performance together with computational efficiency and lightweight nature makes it an ideal candidate to be used in IoMT systems.}
}


@article{DBLP:journals/iot/LiuDYZS24,
	author = {Dengzhi Liu and
                  Yongdong Ding and
                  Geng Yu and
                  Zhaoman Zhong and
                  Yuanzhao Song},
	title = {Privacy-preserving dynamic auditing for regenerating code-based storage
                  in cloud-fog-assisted IIoT},
	journal = {Internet Things},
	volume = {25},
	pages = {101084},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101084},
	doi = {10.1016/J.IOT.2024.101084},
	timestamp = {Sun, 19 Jan 2025 14:28:18 +0100},
	biburl = {https://dblp.org/rec/journals/iot/LiuDYZS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A human-centered, sustainable development technological concept from industry 5.0 is rapidly sparking extensive discussions in the academic and professional communities. Massive data need to be outsourced to nearby fog nodes and remote cloud servers due to the constrained resource of terminals in industrial Internet of things (IIoT) in future industry 5.0. However, terminals are skeptical about the credibility of the outsourced data due to the loss of physical data possession. Existing data storage auditing schemes in cloud computing will be performed with high latency, which is not suitable for cloud-fog-assisted IIoT. To improve the computational efficiency and reduce the communication overhead, in this paper, a privacy-preserving dynamic auditing for regenerating code-based storage in cloud-fog-assisted IIoT is proposed. First, a generalized framework of exact reparation regenerating code is employed to encode the data file, which can improve the data storage security in cloud-fog-assisted IIoT. Then, the ZSS signature is used to generate the authentication tag for each encoded data segment. Moreover, a proper data structure is designed to store the encoded data and authenticators in storage servers based on the properties of exact reparation regenerating code, which can efficiently make full use of the fragmented storage space and significantly reduce the latency of data update. Security analysis shows that the proposed scheme provides the resistance of forgery attacks, replacing attacks, replaying attacks and ensures the data privacy. Performance analysis demonstrates that the proposed scheme can be performed with low computational cost and communication overhead that can be well used in cloud-fog-assisted IIoT.}
}


@article{DBLP:journals/iot/NaqviJFIKK24,
	author = {Syed Shehryar Ali Naqvi and
                  Harun Jamil and
                  Muhammad Faseeh and
                  Naeem Iqbal and
                  Salabat Khan and
                  Do{-}Hyeun Kim},
	title = {A comprehensive review on development strategies of integrated electronic
                  control units in IoEVs for energy management},
	journal = {Internet Things},
	volume = {25},
	pages = {101085},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101085},
	doi = {10.1016/J.IOT.2024.101085},
	timestamp = {Sun, 04 Aug 2024 19:51:17 +0200},
	biburl = {https://dblp.org/rec/journals/iot/NaqviJFIKK24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Among many parts of mobility systems in EVs that the Electrical Control Unit (ECU) supervises and manages are the VCU, ESC, EPS, and BCU. By integrating and synchronizing various subsystems, the integrated ECU facilitates effective power allocation, efficient regenerative energy capture, and maximum usage of available energy resources. The many facets of integrated ECU in EVs and its sub-branches are thoroughly examined in this review research. With an emphasis on energy management, the suggested research study provides a thorough analysis of the integrated ECU’s development plans. Additionally, our research study outlines the components that each control unit uses, emphasizing their functions and importance in facilitating safe and effective vehicle control in next-generation intelligent transportation systems. Furthermore, our research looks at the overview of integrated control unit advancements, carefully assessing the advancements in methods and effectiveness in conjunction with the analysis outcomes of EV performance metrics. Readers are provided with an understanding of the field’s history and accomplishments through a summary of these methodologies and the analytical outcomes. This makes it easier to comprehend in detail the methods applied to improve the handling, stability, and performance of EVs.}
}


@article{DBLP:journals/iot/AhakonyeNLK24,
	author = {Love Allen Chijioke Ahakonye and
                  Cosmas Ifeanyi Nwakanma and
                  Jae{-}Min Lee and
                  Dong{-}Seong Kim},
	title = {Low computational cost convolutional neural network for smart grid
                  frequency stability prediction},
	journal = {Internet Things},
	volume = {25},
	pages = {101086},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101086},
	doi = {10.1016/J.IOT.2024.101086},
	timestamp = {Sun, 19 Jan 2025 14:28:17 +0100},
	biburl = {https://dblp.org/rec/journals/iot/AhakonyeNLK24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the smart grid, it is critical to collect dynamic and time-dependent information on energy demand and consumption and compare it to current supply conditions. The decentral smart grid control (DSGC) system manages frequency, a Smart grid element. It connects energy costs to grid frequency, allowing access to both consumers and producers. This work proposes a pruning of the convolution layers and neurons of 1-dimensional time-aware convolutional neural network (1D CNN) analysis of grid frequency stability to determine efficient energy costs. The proposed solution evaluated augmented grid stability datasets in addition to two other publicly available datasets to ascertain the approach’s feasibility in various scenarios; the simulation demonstrated a minimal train and prediction time of 124.37 s and 17.67 s efficiency over compared models, with prediction accuracy of 99.79% and 0.01 MFLOPs. Matthew’s correlation coefficient was applied to evaluate further the performance of the proposed 1D CNN to ascertain its applicability in various scenarios.}
}


@article{DBLP:journals/iot/SinghBP24,
	author = {Parwinder Singh and
                  Michail J. Beliatis and
                  Mirko Presser},
	title = {Enabling edge-driven Dataspace integration through convergence of
                  distributed technologies},
	journal = {Internet Things},
	volume = {25},
	pages = {101087},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101087},
	doi = {10.1016/J.IOT.2024.101087},
	timestamp = {Sun, 19 Jan 2025 14:28:18 +0100},
	biburl = {https://dblp.org/rec/journals/iot/SinghBP24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Dataspace and emerging technologies play a key role in developing value chain systems using cross-domain data, services and systems integration. Therefore, this study has conducted a comprehensive literature review for six years (2017–2022) on the convergence of Internet of Things (IoT), Artificial Intelligence (AI) and Distributed Ledger (Blockchain) technologies for supporting Dataspace integration efforts at the Edge. As an outcome, this study has identified relevant challenges that include heterogeneity, integration and interoperability, distributed security, trust, scalability, and resource management. It has also been found that very limited research covers the architectural aspects of distributed edge in the context of the convergence of technologies for Dataspace integration purposes. Therefore, this study has proposed an architectural framework – Distributed Edge Network Operations-oriented Semantic (DENOS) model that extends the traditional Cloud–Edge-Device architecture with three new layers – Semantic, Convergence, and Dataspace integration. In addition, the model leverages the power of semantic modelling (i.e., Processing, Service, and Data) context, which enables the model to have a dynamic implementation context to suit the diverse needs of target use cases. To showcase the validation of the model, a use case related to the digital traceable operation of the wind energy domain has been presented. The objective of the DENOS model is to enable Dataspace integration to build edge-enabled value chain networks. Thus, it contributes to secure and semantic integration using the convergence of resources and technologies, cross-domain collaboration, reusability and data-driven decision-making of resources.}
}


@article{DBLP:journals/iot/AhmadS24,
	author = {Mir Shahnawaz Ahmad and
                  Shahid Mehraj Shah},
	title = {A lightweight mini-batch federated learning approach for attack detection
                  in IoT},
	journal = {Internet Things},
	volume = {25},
	pages = {101088},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101088},
	doi = {10.1016/J.IOT.2024.101088},
	timestamp = {Sun, 19 Jan 2025 14:28:17 +0100},
	biburl = {https://dblp.org/rec/journals/iot/AhmadS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Internet of Things (IoT) has recently gained importance in many fields. The use of IoT in different fields leads to an increase in a wide variety of network attacks. Many researchers have used artificial intelligence (AI) based approaches like machine learning and deep learning techniques to detect such attacks. Traditionally these AI techniques train an intelligent model at a cloud data center using the IoT network data gathered by different IoT devices. The sharing of IoT data with the cloud data center may affect the privacy of the user’s sensitive data. The federated learning techniques can be used to generate an effective attack detection AI model that preserve the privacy of IoT users, but these mechanisms have higher computational complexities and require large number of federation rounds. So, to detect such attacks without compromising the privacy of IoT users, we propose a lightweight mini-batch federated learning mechanism, which is computationally efficient and requires minimum number of federation rounds to detect malicious attacks in an IoT network. The performance of the proposed mechanism was tested on benchmark IoT network datasets and the results show that the proposed mechanism achieves an overall attack detection accuracy of 98.85% with a false alarm rate of 0.09% and requires minimal computational resources.}
}


@article{DBLP:journals/iot/SuranthaS24,
	author = {Nico Surantha and
                  Boy Sugijakko},
	title = {Lightweight face recognition-based portable attendance system with
                  liveness detection},
	journal = {Internet Things},
	volume = {25},
	pages = {101089},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101089},
	doi = {10.1016/J.IOT.2024.101089},
	timestamp = {Sun, 19 Jan 2025 14:28:17 +0100},
	biburl = {https://dblp.org/rec/journals/iot/SuranthaS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Face recognition systems that do not implement liveness detection are susceptible to face spoofing attacks. This vulnerability implies that an attacker could disguise themselves as another individual and the system would falsely take the attendance of that other individual. To prevent these attacks, a liveness detection step can be implemented before recognizing subjects. Face recognition-based attendance system devices are typically installed at the entrance to an event or space, so having a portable device that can be easily relocated is practical and efficient. Hence, face recognition systems should be lightweight enough to be able to run on portable devices with limited computational power. Implementing liveness detection will increase the system's processing time. Therefore, this study aims to develop a lightweight liveness detection method that can be run on a Raspberry Pi. To achieve this, several pre-trained models were evaluated and MobileNetV2 was chosen based on the results. The MobileNetV2 model was then trained using transfer learning method. The proposed attendance system achieved an average processing time below 0.6 s and 96 % accuracy for live subjects, 79 % accuracy for level A spoof attacks, 83.7 % accuracy for level B spoof attacks, and 70 % accuracy for level C spoof attacks.}
}


@article{DBLP:journals/iot/HanRMFY24,
	author = {Yuanyuan Han and
                  Nor Haizan Mohamed Radzi and
                  Noorfa Haszlinna Mustaffa and
                  Jianbo Fan and
                  Junzi Yang},
	title = {A predictive maintenance model for internet of things devices using
                  long short-term memory and one-dimensional dilated group convolution
                  with residual connection},
	journal = {Internet Things},
	volume = {25},
	pages = {101090},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101090},
	doi = {10.1016/J.IOT.2024.101090},
	timestamp = {Sat, 08 Jun 2024 13:15:49 +0200},
	biburl = {https://dblp.org/rec/journals/iot/HanRMFY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Predictive Maintenance (PdM) of Internet of Things (IoT) devices to enhance their reliability is becoming increasingly crucial as the IoT develops. Loss caused by malfunction can be avoided or minimized if appropriate preparations are made in advance. By summarizing the relevant literature, the use of deep learning to establish the PdM model has become a current research hotspot, but few studies use the classification method. In the multivariate time-series data produced by IoT devices, each data has a temporal and spatial correlation, so how to obtain the two correlations should be given more attention. We propose to extract temporal correlation using the Short-Term Memory network (LSTM) because it can identify long-term dependencies. To obtain spatial correlation, we propose a one-dimensional dilated group convolution with residual connection (1DDGCR) block. The residual connection in it can avoid gradients vanishing as the network deepens. Then we propose a novel PdM model for IoT equipment combining LSTM and 1DDGCR. It is named LSTM_1DDGCR. We utilize the FD001 public dataset, which is a subset of the C-MAPSS dataset, to evaluate the performance of LSTM_1DDGCR. We compare it with two models proposed by previous researchers and find that the proposed LSTM_1DDGCR model shows better performance. In addition, LSTM_1DDGCR is applied to a real-world dataset, and it also shows good performance in practical applications.}
}


@article{DBLP:journals/iot/Chen24,
	author = {Da{-}Ren Chen},
	title = {Integrating IoT in WBANs: An energy-efficient and QoS-aware approach
                  for rapid model-driven transmission power control and link adaptation},
	journal = {Internet Things},
	volume = {25},
	pages = {101091},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101091},
	doi = {10.1016/J.IOT.2024.101091},
	timestamp = {Sun, 19 Jan 2025 14:28:18 +0100},
	biburl = {https://dblp.org/rec/journals/iot/Chen24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Wireless Body Area Networks (WBAN) are integral to the application framework of the Internet of Things (IoT) domain, especially in applications demanding efficient connectivity and availability. Our study introduces a rapid, model-based, and sensor-centric approach in WBANs, significantly enhancing energy and time efficiency, crucial for IoT devices constrained by limited power supply and the need for extended operational duration. Our scheme maintains a transmit power threshold table, ensuring objective Quality of Service (QoS) while reducing power consumption in sensor nodes. We achieve this through a novel approach that contrasts the target bit error rate (BER) with the received instantaneous BER, refining path loss and channel models to accurately determine receiver sensitivity. The proposed scheme sets a in receiver sensitivity model, establishing the minimum transmit power needed for desired QoS. This is particularly relevant for IoT applications where maintaining consistent communication quality is paramount. Our performance evaluations show that this approach outperforms existing link adaptation and transmit power control methods in sensor overhead, time efficiency, and energy efficiency, marking a significant advancement in IoT connectivity solutions. By addressing the challenges of radio frequency signal vulnerability to body shadowing and path loss in dynamic conditions, our study not only enhances WBAN performance but also contributes to the stability and adaptability of IoT networks. This aligns with the evolving needs of the IoT domain, where efficient, reliable, and adaptive network solutions are increasingly in demand for a wide range of applications.}
}


@article{DBLP:journals/iot/BahadoripourKJI24,
	author = {Sepideh Bahadoripour and
                  Hadis Karimipour and
                  Amir Namavar Jahromi and
                  Anik Islam},
	title = {An explainable multi-modal model for advanced cyber-attack detection
                  in industrial control systems},
	journal = {Internet Things},
	volume = {25},
	pages = {101092},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101092},
	doi = {10.1016/J.IOT.2024.101092},
	timestamp = {Sun, 19 Jan 2025 14:28:18 +0100},
	biburl = {https://dblp.org/rec/journals/iot/BahadoripourKJI24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The convergence of Industrial Control Systems (ICS) and intelligent Internet of Things (IoT) technologies has rendered ICS more vulnerable to a growing range of cyber-attacks, that put the critical infrastructures in danger. Some examples are the recent attacks on gas/oil and water treatment industries Existing attack detection methodologies primarily leverage machine learning techniques, often centralized in nature, raising concerns regarding data privacy and transfer challenges. In response, Federated Learning (FL) emerged as a distributed alternative, gaining traction in ICS attack detection. This paper introduces a deep federated multi-modal model for cyber-attack detection in ICS environments. The model encompasses three key components: representation learning for latent space transformation of original client data, domain adaptation to map client data to a public representation space, and a federated approach for training the cyber-attack detection model. To enhance interpretability, the Shapley Additive Explanations (SHAP) method is employed to provide insights into model output results, aiding decision-making by cybersecurity experts. Experimental assessments reveal an average 8.2% improvement in f1-score across three clients. Moreover, SHAP is applied for feature reduction, yielding a 4.9% f1-score improvement with a halved feature set.}
}


@article{DBLP:journals/iot/AbdeldjalilDSOE24,
	author = {Tabouche Abdeldjalil and
                  Badis Djamaa and
                  Mustapha R{\'{e}}da Senouci and
                  Oussama Elmadani Ouakaf and
                  Abdelmalek Ghefrane Elaziz},
	title = {{TLR:} Traffic-aware load-balanced routing for industrial IoT},
	journal = {Internet Things},
	volume = {25},
	pages = {101093},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101093},
	doi = {10.1016/J.IOT.2024.101093},
	timestamp = {Mon, 01 Apr 2024 11:15:32 +0200},
	biburl = {https://dblp.org/rec/journals/iot/AbdeldjalilDSOE24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Industrial Internet of Things (IIoT) is an evolving technology that addresses various industry challenges, including low latency, high reliability, and low energy consumption. To fulfill these objectives, the IEEE 802.15.4 Time Slotted Channel Hopping (TSCH) mode, along with the IPv6 over TSCH (6TiSCH) standard, stands as a promising technology. A 6TiSCH network supports multi-channel, multi-hop communications using the RPL routing protocol. Nevertheless, running RPL naively over TSCH may fail to fully exploit the potential of TSCH in managing heavy industrial traffic and can result in a potential load-balancing problem that may lead to significant performance degradation. In this paper, we propose an innovative traffic-aware load-balancing routing approach, dubbed TLR, to capture the dynamics of industrial 6TiSCH networks by leveraging metrics such as queue occupancy, cell usage, hop count, and expected transmission count. By harnessing these traffic-aware metrics in TLR’s proactive path selection strategy, efficient load-balancing is achieved and thereby network throughput is enhanced. This is demonstrated through comprehensive simulations and evaluations in a real-world publicly-available testbed, affirming the efficacy of our proposed solution in effectively managing variations in network traffic. Notably, TLR demonstrated remarkable improvements in reliability, latency, and energy efficiency compared to conventional methods. Such achievements position TLR as a promising solution for improving the performance and efficiency of wireless IIoT applications.}
}


@article{DBLP:journals/iot/GarciaBM24,
	author = {{\'{A}}lvaro Garc{\'{\i}}a and
                  An{\'{\i}}bal Breg{\'{o}}n and
                  Miguel A. Mart{\'{\i}}nez{-}Prieto},
	title = {Digital Twin Learning Ecosystem: {A} cyber-physical framework to integrate
                  human-machine knowledge in traditional manufacturing},
	journal = {Internet Things},
	volume = {25},
	pages = {101094},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101094},
	doi = {10.1016/J.IOT.2024.101094},
	timestamp = {Sun, 19 Jan 2025 14:28:18 +0100},
	biburl = {https://dblp.org/rec/journals/iot/GarciaBM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As Industry 4.0 enablers, digital twins of manufacturing systems have led to multiple interaction levels among processes, systems, and workers across the factory. However, open issues still exist when addressing cyber–physical convergence in traditional manufacturing small and medium-sized enterprises. The problem for both traditional operators and the existing infrastructure is how to adapt knowledge to the increasing business needs of manufacturing plants that demand high efficiency, while reducing production costs. In this paper, a framework that implements the novel concept of Digital Twin Learning Ecosystem in traditional manufacturing is presented. The objective is to facilitate the integration of human-machine knowledge in different industrial cyber–physical contexts and eliminate existing technological and workforce barriers. This adaptive approach is particularly important in meeting the requirements to help small and medium-sized enterprises build their own interconnected Digital Twin Learning Ecosystem. The contribution of this work lies in a single digital twin learning framework for different traditional manufacturing scenarios that can work from scratch using a light infrastructure, reusing the knowledge and common condition-based methods well-known by skilled workers to rapidly and flexibly integrate existing legacy resources in a non-intrusive manner. The solution was tested using real data from a milling machine and a currently operating induction furnace with a maximum power of 12 MW in a foundry plant. In both cases, the proposed solution proved its benefits: first, by providing augmented methods for maintenance operations on the milling machine and second, by improving the power efficiency of the induction furnace by approximately 9 percent.}
}


@article{DBLP:journals/iot/MunozBPL24,
	author = {Lucia Arnau Mu{\~{n}}oz and
                  Jos{\'{e}} Vicente Bern{\'{a}}{-}Mart{\'{\i}}nez and
                  Francisco Maci{\'{a}} P{\'{e}}rez and
                  Iren Lorenzo{-}Fonseca},
	title = {Anomaly detection system for data quality assurance in IoT infrastructures
                  based on machine learning},
	journal = {Internet Things},
	volume = {25},
	pages = {101095},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101095},
	doi = {10.1016/J.IOT.2024.101095},
	timestamp = {Sun, 19 Jan 2025 14:28:17 +0100},
	biburl = {https://dblp.org/rec/journals/iot/MunozBPL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The inclusion of IoT in digital platforms is very common nowadays due to the ease of deployment, low power consumption and low cost. It is also common to use heterogeneous IoT devices of ad-hoc or commercial development, using private or third-party network infrastructures. This scenario makes it difficult to detect invalid packets from malfunctioning devices, from sensors to application servers. These invalid packets generate low quality or erroneous data, which negatively influence the services that use them. For this reason, we need to create procedures and mechanisms to ensure the quality of the data obtained from IoT infrastructures, regardless of the type of infrastructure and the control we have over them, so that the systems that use this data can be reliable. In this work we propose the development of an Anomaly Detection System for IoT infrastructures based on Machine Learning using unsupervised learning. We validate the proposal by implementing it on the IoT infrastructure of the University of Alicante, which has a multiple sensing system and uses third-party services, over a campus of one million square meters. The contribution of this work has been the generation of an anomaly detection system capable of revealing incidents in IoT infrastructures, without knowing details about the infrastructures or devices, through the analysis of data in real time. This proposal allows to discard from the IoT data flow all those packets that are suspected to be anomalous to ensure a high quality of information to the tools that consume IoT data.}
}


@article{DBLP:journals/iot/AlmazroiAAAAG24,
	author = {Abdulwahab Ali Almazroi and
                  Mohammed A. Alqarni and
                  Mahmood A. Al{-}Shareeda and
                  Monagi H. Alkinani and
                  Alaa Atallah Almazroey and
                  Tarek Gaber},
	title = {{FCA-VBN:} Fog computing-based authentication scheme for 5G-assisted
                  vehicular blockchain network},
	journal = {Internet Things},
	volume = {25},
	pages = {101096},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101096},
	doi = {10.1016/J.IOT.2024.101096},
	timestamp = {Sun, 19 Jan 2025 14:28:18 +0100},
	biburl = {https://dblp.org/rec/journals/iot/AlmazroiAAAAG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Emerging technology known as intelligent transportation systems allows for seamless two-way communication between moving vehicles and stationary infrastructure. Therefore, core security services in a vehicular network consist of encrypting and trusting information packets for intra- and inter-vehicle systems. However, conventional reconciliation methods incur high communication costs and security risks, and channel imperfection causes important extraction disparities. For a 5G-enabled vehicular blockchain network, we suggested a novel fog computing-based authentication approach for the 5G-assisted vehicular blockchain network (FCA-VBN) scheme, which incorporated fog computing and secure authentication to address these issues. The FCA-VBN scheme employs a channel stage response instituted private key extraction technique for terminal key agreement. Using the blockchain’s immutability and memorability, the novelty of this paper is that it shows how the intelligent contract could be utilized to build and issue the link among the fog server and the node’s data through a transaction. When it comes to message authenticity and integrity, conditional privacy protection, and unlinkability, we demonstrated that the proposed FCA-VBN system is safe and secure. We also spoke about how resistant the method is to various assaults. Ultimately, we theoretically analyzed the suggested FCA-VBN scheme’s achievement on a wide range of metrics, such as computation and communication costs and power usage, to arrive at a comprehensive evaluation.}
}


@article{DBLP:journals/iot/MedinaR24,
	author = {Jorge Medina and
                  Roberto Rojas{-}Cessa},
	title = {AMI-Chain: {A} scalable power-metering blockchain with {IPFS} storage
                  for smart cities},
	journal = {Internet Things},
	volume = {25},
	pages = {101097},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101097},
	doi = {10.1016/J.IOT.2024.101097},
	timestamp = {Sun, 19 Jan 2025 14:28:20 +0100},
	biburl = {https://dblp.org/rec/journals/iot/MedinaR24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {There is a growing interest in utilizing blockchain technology to safeguard grid assets, promote environmental sustainability, and enhance services in smart-city power grids. However, scaling a blockchain to accommodate the multitude of energy sources, prosumers, and consumers is an ongoing challenge. To address this issue, we propose AMI-Chain, a cost-effective blockchain solution that leverages the Inter-Planetary File System (IPFS) for off-chain storage, data aggregation, and compression at the smart meter level. This approach significantly boosts blockchain transaction rates and scalability. However, employing IPFS introduces its unique challenges, particularly in having nodes that stop participating at any given time. Therefore, we also present effective strategies for managing a large number of consumers and introduce a model for optimizing IPFS storage while ensuring data durability. Estimations with our model reveal that AMI-Chain can support over 7.7 million smart meters with a 24-h data compression rate while providing eleven nines for one-year data durability.}
}


@article{DBLP:journals/iot/SahuGAK24,
	author = {Mehar Sahu and
                  Rohan Gupta and
                  Rashmi K. Ambasta and
                  Pravir Kumar},
	title = {IoT-driven augmented reality and virtual reality systems in neurological
                  sciences},
	journal = {Internet Things},
	volume = {25},
	pages = {101098},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101098},
	doi = {10.1016/J.IOT.2024.101098},
	timestamp = {Sun, 06 Oct 2024 21:31:06 +0200},
	biburl = {https://dblp.org/rec/journals/iot/SahuGAK24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Research in augmented and virtual reality in congregation with the Internet of Things has opened many avenues in diagnosing and treating neurological disorders. Augmented reality permits inserting virtual content in the real world, while virtual reality is a simulated experience that provides an artificial three-dimensional environment to the user. These are the game-changer technologies as they give a transformational change to existing technologies and methods. Augmented and virtual reality has come out as a significant technology in treating various mental disorders, thereby providing great applications in the field of neuroscience. In this review, we shed light on different components required for developing an augmented and virtual reality-based technology followed by different devices used in the augmented and virtual-reality-based systems. We highlighted the use of this technology in the diagnosis of neurological defects and proposed strategies to use these advancements to provide an immersive experience for both research and educational purposes. Moreover, we show an extensive implementation of augmented and virtual reality in neurological surgery, neuromodulation, and neuroprosthetics. Therefore, the role of the Internet of Things with augmented and virtual reality for diagnosing and treating neurological disorders is the future.}
}


@article{DBLP:journals/iot/DominguezBolanoBEG24,
	author = {Tom{\'{a}}s Dom{\'{\i}}nguez{-}Bola{\~{n}}o and
                  Valent{\'{\i}}n Barral and
                  Carlos J. Escudero and
                  Jos{\'{e}} Antonio Garc{\'{\i}}a{-}Naya},
	title = {An IoT system for a smart campus: Challenges and solutions illustrated
                  over several real-world use cases},
	journal = {Internet Things},
	volume = {25},
	pages = {101099},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101099},
	doi = {10.1016/J.IOT.2024.101099},
	timestamp = {Sun, 19 Jan 2025 14:28:17 +0100},
	biburl = {https://dblp.org/rec/journals/iot/DominguezBolanoBEG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This article discusses the development of an IoT system for monitoring and controlling various devices and systems from different vendors. The authors considered key challenges in IoT projects, such as interoperability and integration, scalability, and data storage, processing, and visualization, during the design and deployment phases. In addition to these general challenges, the authors also delve into the specific integration challenges they encountered. Various devices and systems were integrated into the system and five real-world scenarios in a university campus environment are used to illustrate the challenges encountered. The scenarios involve monitoring various aspects of a university campus environment, including air quality, environmental parameters, energy efficiency, solar photovoltaic energy, and energy consumption. The authors analyzed data and CPU usage to ensure that the system could handle the large amount of data generated by the devices. The platform developed uses open source projects such as Home Assistant, InfluxDB, Grafana, and Node-RED. All developments have been published as open source in public repositories. In conclusion, this work highlights the potential and feasibility of IoT systems in various real-world applications, the importance of considering key challenges in IoT projects during the design and deployment phases, and the specific integration challenges that may be encountered.}
}


@article{DBLP:journals/iot/PinoRMO24a,
	author = {Andr{\'{e}}s Felipe Solis Pino and
                  Pablo H. Ruiz and
                  Alicia Mon and
                  C{\'{e}}sar Alberto Collazos Ord{\'{o}}{\~{n}}ez},
	title = {Mechanisms for measuring technology maturity on the Internet of Things
                  in enterprises: {A} systematic literature mapping},
	journal = {Internet Things},
	volume = {25},
	pages = {101100},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101100},
	doi = {10.1016/J.IOT.2024.101100},
	timestamp = {Sun, 19 Jan 2025 14:28:18 +0100},
	biburl = {https://dblp.org/rec/journals/iot/PinoRMO24a.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Measuring the technological maturity of the Internet of Things in enterprises is essential for understanding their current capabilities and pinpointing areas that require improvement in terms of adoption and implementation. This study conducted a systematic literature mapping of the mechanisms for measuring Internet of Things technology maturity in enterprises and organizations. A systematic search was executed in six databases, which yielded 1181 studies. Applying inclusion and exclusion criteria, 78 primary studies were selected for analysis to address the research questions and perform a bibliometric analysis. The primary outcome of this research revolves around the existence of multiple mechanisms used to measure the technological maturity of the Internet of Things, including maturity models and frameworks. However, there currently needs to be standardized methods to accomplish this task. The P2668/D5 standard can serve as a reference for criteria, scales, and dimensions. Another significant result refers to the evolving nature of this field, with Germany, India, and China emerging as the main contributors to its progress. Finally, the main challenges and associated problems revolve around the absence of standardization, limited accessibility, and lack of specificity of measurement tools.}
}


@article{DBLP:journals/iot/OrtegaOchoaPADP24,
	author = {Elvis Ortega{-}Ochoa and
                  Jos{\'{e}} Quiroga P{\'{e}}rez and
                  Marta Arguedas and
                  Thanasis Daradoumis and
                  Joan Manuel Marqu{\`{e}}s Puig},
	title = {The effectiveness of empathic chatbot feedback for developing computer
                  competencies, motivation, self-regulation, and metacognitive reasoning
                  in online higher education},
	journal = {Internet Things},
	volume = {25},
	pages = {101101},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101101},
	doi = {10.1016/J.IOT.2024.101101},
	timestamp = {Mon, 03 Mar 2025 22:14:48 +0100},
	biburl = {https://dblp.org/rec/journals/iot/OrtegaOchoaPADP24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {At the forefront of Artificial Intelligence of Things, this paper delves into empathic agents to revolutionize computer competencies acquisition and catalyze motivational, regulatory, and metacognitive dynamics in online higher education. Previous research on student processing of empathic feedback has been limited, often neglecting learning performance and its impact on students’ motivation, self-regulation, and metacognitive reasoning. The objective was to analyze the effectiveness of empathic feedback, cognitive and affective, on these four issues in online learning. A quasi-experimental design was used, in which a conversational agent, DSLab-Bot, was integrated into the syllabus and Information Technology infrastructure. Students from an online university's Distributed Systems course participated (N= 196), selected through one-stage cluster probability sampling. They were divided into experimental and control groups receiving feedback from DSLab-Bot and the teacher, respectively. Results showed no significant differences between the groups in learning performance, motivation, or self-regulation, except in one item of motivation (self-efficacy) and self-regulation. There were strong correlations between thirteen cognitive (1–4, 6, 7, 9–15) and seven affective (1, 4–9) chatbot feedback types with conceptual change (MRCC) and personal growth and understanding (MRPGU). There were high weights of similar chatbot feedback types indicating a pronounced influence of these on metacognitive reasoning components, even self-reflection (MRSR). In conclusion, empathic chatbot feedback is as effective as human teacher feedback in facilitating learning, motivation, and self-regulation. Moreover, specific empathic feedback types are crucial in fostering MRCC, MRPGU, and MRSR strongly. Practitioners should consider these specific types of empathic feedback for future empathic agent configurations.}
}


@article{DBLP:journals/iot/NieLLG24,
	author = {Fengyuan Nie and
                  Weiwei Liu and
                  Guangjie Liu and
                  Bo Gao},
	title = {{M2VT-IDS:} {A} multi-task multi-view learning architecture for designing
                  IoT intrusion detection system},
	journal = {Internet Things},
	volume = {25},
	pages = {101102},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101102},
	doi = {10.1016/J.IOT.2024.101102},
	timestamp = {Sun, 19 Jan 2025 14:28:18 +0100},
	biburl = {https://dblp.org/rec/journals/iot/NieLLG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the rapidly growing frequency of security incidents in the Internet of Things (IoT), intrusion detection systems (IDS) have gained increasing attention in recent years. They have been applied in a variety of tasks, such as anomaly detection, attack identification, and device identification. The intrusion detection approaches based on deep learning have achieved promising performance owing to their capability of automatically discovering generalizable patterns. Nevertheless, the network traffic representations fed into neural networks are often designed for specific tasks, and their efficiency significantly depends on the knowledge of experts. In this paper, using a multi-view representation of network traffic with a multi-task learning architecture, we design a multi-task multi-view IoT intrusion detection system (M2VT-IDS) that can provide multiple intrusion detection capabilities with high detection accuracy. We first construct a packet-wise representation of IoT traffic from a multi-view perspective, including a spatio-temporal series view, a header field pattern view, and a payload semantic view. Then, we design a two-stage multi-task learning architecture that consists of a multi-view shared network and a task-specific attention network, which can simultaneously realize anomaly detection, attack identification, and device identification tasks. Experimental results based on three popular IoT traffic datasets show that the proposed M2VT-IDS can achieve higher accuracy in multiple intrusion detection tasks when compared with other state-of-the-art specialized IDS schemes.}
}


@article{DBLP:journals/iot/PeruginiV24,
	author = {Leonardo Perugini and
                  Andrea Vesco},
	title = {On the integration of Self-Sovereign Identity with {TLS} 1.3 handshake
                  to build trust in IoT systems},
	journal = {Internet Things},
	volume = {25},
	pages = {101103},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101103},
	doi = {10.1016/J.IOT.2024.101103},
	timestamp = {Sun, 19 Jan 2025 14:28:17 +0100},
	biburl = {https://dblp.org/rec/journals/iot/PeruginiV24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The centralized PKI is not a suitable solution to provide identities in large-scale IoT systems. The main problem is the high cost of managing X.509 certificates throughout their lifecycle, from installation to regular updates and revocation. The Self-Sovereign Identity (SSI) is a decentralized option that reduces the need for human intervention, and therefore has the potential to significantly reduce the complexity and cost associated to identity management in large-scale IoT systems. However, to leverage the full potential of SSI, the authentication of IoT nodes needs to be moved from the application to the Transport Layer Security (TLS) level. This paper contributes to the adoption of SSI in large-scale IoT systems by addressing, for the first time, the extension of the original TLS 1.3 handshake to support two new SSI authentication modes while maintaining the interoperability with nodes implementing the original handshake protocol. The open source implementation of the new TLS 1.3 handshake protocol in OpenSSL is used to experimentally prove the feasibility of the approach.}
}


@article{DBLP:journals/iot/SunHSYW24,
	author = {Chen Sun and
                  Guoling Huang and
                  Jian Shu and
                  Youfeng Yang and
                  Bo Wu},
	title = {Joint mode selection and resource allocation based on many-to-many
                  reuse in D2D-aided IoT cellular networks},
	journal = {Internet Things},
	volume = {25},
	pages = {101104},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101104},
	doi = {10.1016/J.IOT.2024.101104},
	timestamp = {Mon, 01 Apr 2024 11:15:32 +0200},
	biburl = {https://dblp.org/rec/journals/iot/SunHSYW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Device-to-Device (D2D) communication is a widely adopted technology to meet the growing demands for connecting Internet of Things (IoT) devices. In order to meet the increasing demands of the growing number of IoT devices on system capacity and spectral efficiency, recent research developments in D2D are increasingly focused on scenarios involving the reuse of multiple channels by multiple D2D pairs (M2M). To ensure the minimum data rate for users under the M2M multiplexing mechanism while enhancing the access proportions of D2D pairs and proportionate fairness among all users within the macrocell environment. We propose a two-stage Joint Mode Selection and Resource Allocation (JMSRA) scheme. This innovative approach transforms the complex interference coordination problem of multi-objective optimization into a more manageable two-stage graph coloring problem, utilizing the D2D Inter-user Interference Graph (DIUIG) and matching theory for its resolution. During the initial stage, graph coloring based on the DIUIG and the Kuhn–Munkres (KM) algorithm accomplish the preliminary mode selection and resource allocation, thereby augmenting the proportion of D2D access. Subsequently, in the second stage, graph coloring based on DIUIG and many-to-many matching theory reallocate channels for D2D, thereby improving the proportional fairness of D2D pairs. The simulation results reveal that the proposed solution surpasses the state-of-the-art benchmarks by enhancing the D2D access proportions by 15% and boosting the average logarithmic capacity of all User Equipments (UEs) by at least 0.77.}
}


@article{DBLP:journals/iot/WangC24,
	author = {Deliang Wang and
                  Gaowei Chen},
	title = {Are perfect transcripts necessary when we analyze classroom dialogue
                  using AIoT?},
	journal = {Internet Things},
	volume = {25},
	pages = {101105},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101105},
	doi = {10.1016/J.IOT.2024.101105},
	timestamp = {Fri, 18 Oct 2024 08:15:19 +0200},
	biburl = {https://dblp.org/rec/journals/iot/WangC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Classroom dialogue plays a crucial role in enhancing the quality of teaching and learning. Many researchers have utilized artificial intelligence (AI) and Internet of things (IoT) to develop models and systems for automatic analysis and feedback. However, the question of whether we should employ these AIoT tools on automatic transcripts of classroom dialogue generated by automatic speech recognition software or on transcripts that have undergone human revision remains unresolved, which involves the trade-off between accuracy and efficiency. Thus, this paper examines whether perfect transcripts are needed to analyze talk moves in classroom dialogue. We initially constructed two deep learning models to analyze teacher talk moves in K-12 mathematics lessons. Subsequently, we collected an additional set of six K-12 mathematics lesson videos and used a classroom dialogue analysis system equipped with speech recognition software to automatically transcribe them, resulting in ASR_pure transcripts. These transcripts were then manually revised and verified to create ASR_human transcripts. A comparison between the two types of transcripts revealed evident errors in the ASR_pure transcripts. Next, we employed the developed AI models to predict talk moves in both ASR_pure and ASR_human transcripts and assessed their consistency. The findings demonstrate a high level of consistency in talk move prediction between the two types of transcripts across the six lessons. Furthermore, the ASR_pure transcripts also exhibit high consistency in specific talk moves (e.g., pressing for accuracy) when compared to ASR_human transcripts. We propose a hypothesis that this consistency between inaccurate ASR_pure transcripts and perfect ASR_human transcripts can be attributed to the ASR software accurately recognizing key indicators that serve as talk moves, rather than accurately identifying every word. Notably, upon removing the key indicator words from teacher utterances, both the talk move level and lesson level consistency experience a substantial decline. Therefore, we suggest that perfect transcripts of classroom dialogue may not be necessary for AIoT to analyze teacher talk moves and provide teachers with prompt and accurate feedback, especially when the ASR software can accurately recognize keywords.}
}


@article{DBLP:journals/iot/VarelaVacaGIG24,
	author = {{\'{A}}ngel Jes{\'{u}}s Varela{-}Vaca and
                  Rafael M. Gasca and
                  David Iglesias and
                  J. M. G{\'{o}}nzalez{-}Guti{\'{e}}rrez},
	title = {Automated trusted collaborative processes through blockchain {\&}
                  IoT integration: The fraud detection case},
	journal = {Internet Things},
	volume = {25},
	pages = {101106},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101106},
	doi = {10.1016/J.IOT.2024.101106},
	timestamp = {Sat, 08 Jun 2024 13:15:49 +0200},
	biburl = {https://dblp.org/rec/journals/iot/VarelaVacaGIG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Collaboration of business processes is essential for business-to-business (B2B) processes. Collaboration is interesting and important in connecting the digital context with the physical world (IoT) to feed processes with data or send data. However, it also presents multiple challenges, such as the lack of trust between participants with each other and additional privacy and security problems in the communicated data. Fraud detection is crucial for many type of organisations that deal with B2B transactions (banking, fintech, health, etc.) and are therefore exposed to a high risk of fraud. Fraud detection requires expensive professional investigations and intensive collaboration between processes of different organisations. This issue could be mitigated by effectively managing digital evidence, fostering trust and ensuring security for various stakeholders involved in the business processes. This paper proposes an approach to modelling and deploying any collaborative business process scenario, ensuring trust, security, and data privacy. Collaboration-level agreements are defined as a means to ensure trust, security, and data privacy. To accomplish this, our approach enables the automatic generation Smart Contract templates for the collaboration-level agreement specification involving different stakeholders in the collaboration. The Smart contracts are deployed in a Blockchain to ensure that the collaboration-level agreement conditions are signed by the parties. To validate the feasibility of our approach, a proof-of-concept for a fraud detection scenario is implemented, where different metrics are tested in relation to a set of threats and vulnerabilities.}
}


@article{DBLP:journals/iot/PutraARSKL24,
	author = {Made Adi Paramartha Putra and
                  Revin Naufal Alief and
                  Syifa Maliah Rachmawati and
                  Gabriel Avelino R. Sampedro and
                  Dong{-}Seong Kim and
                  Jae{-}Min Lee},
	title = {Proof-of-authority-based secure and efficient aggregation with differential
                  privacy for federated learning in industrial IoT},
	journal = {Internet Things},
	volume = {25},
	pages = {101107},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101107},
	doi = {10.1016/J.IOT.2024.101107},
	timestamp = {Wed, 20 Mar 2024 10:34:28 +0100},
	biburl = {https://dblp.org/rec/journals/iot/PutraARSKL24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The industrial internet of things (IIoT) uses connected devices and sensors to improve efficiency in industry, but increased reliance on these systems makes them prone to faults. To ensure the reliability of IIoT systems, robust fault detection is necessary, which can be provided by artificial intelligence (AI). The current state-of-the-art approach for AI in IIoT is mainly focused on centralized learning, which is inefficient due to its high communication cost. Federated learning (FL) addresses this limitation by enabling distributed training without exposing individual information. In order to provide secure and efficient FL for the IIoT environment, several research studies have investigated the use of blockchain networks. However, most of these studies ignore the processing time metric, which is crucial for IIoT networks. In this paper, we propose a secure and efficient parameter aggregation technique that enhances trust, security, and privacy for IIoT. We use a lightweight smart contract deployed with a proof-of-authority (PoA)-based blockchain in combination with a Gaussian differential privacy mechanism. We evaluate our proposed system using a real bearing fault dataset and demonstrate that it is able to provide a secure aggregation process with an accuracy of 94.00% and a processing time of 1.54 s, which is suitable for the IIoT environment with a private blockchain network.}
}


@article{DBLP:journals/iot/MaciasT24,
	author = {Juan Emilio Zurita Macias and
                  Sergio Trilles},
	title = {Machine learning-based prediction model for battery levels in IoT
                  devices using meteorological variables},
	journal = {Internet Things},
	volume = {25},
	pages = {101109},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101109},
	doi = {10.1016/J.IOT.2024.101109},
	timestamp = {Sun, 06 Oct 2024 21:31:06 +0200},
	biburl = {https://dblp.org/rec/journals/iot/MaciasT24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Efficient energy management is vital for the sustainability of IoT devices employing solar harvesting systems, particularly to circumvent battery depletion during periods of diminished solar incidence. Embracing the structured methodology of CRISP-DM, this study introduces machine learning (ML) models that utilise meteorological data to predict battery charge levels in solar-powered IoT devices. These models enable proactive adjustments to the devices’ data sampling frequencies, ensuring effective energy utilisation. The proposed ML models were evaluated using authentic battery charge data and weather forecast records. The empirical results of this study corroborate the predictive prowess of the models, with an average accuracy reaching as high as 94.09% in specific test cases. This substantiates the potential of the developed methodology to significantly enhance the energy autonomy of IoT devices through predictive analytics.}
}


@article{DBLP:journals/iot/SarkerJFA24,
	author = {Iqbal H. Sarker and
                  Helge Janicke and
                  Mohamed Amine Ferrag and
                  Alsharif Abuadbba},
	title = {Multi-aspect rule-based {AI:} Methods, taxonomy, challenges and directions
                  towards automation, intelligence and transparent cybersecurity modeling
                  for critical infrastructures},
	journal = {Internet Things},
	volume = {25},
	pages = {101110},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101110},
	doi = {10.1016/J.IOT.2024.101110},
	timestamp = {Sat, 08 Jun 2024 13:15:49 +0200},
	biburl = {https://dblp.org/rec/journals/iot/SarkerJFA24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Critical infrastructure (CI) typically refers to the essential physical and virtual systems, assets, and services that are vital for the functioning and well-being of a society, economy, or nation. However, the rapid proliferation and dynamism of today’s cyber threats in digital environments may disrupt CI functionalities, which would have a debilitating impact on public safety, economic stability, and national security. This has led to much interest in effective cybersecurity solutions regarding automation and intelligent decision-making, where AI-based modeling is potentially significant. In this paper, we take into account “Rule-based AI” rather than other black-box solutions since model transparency, i.e., human interpretation, explainability, and trustworthiness in decision-making, is an essential factor, particularly in cybersecurity application areas. This article provides an in-depth study on multi-aspect rule based AI modeling considering human interpretable decisions as well as security automation and intelligence for CI. We also provide a taxonomy of rule generation methods by taking into account not only knowledge-driven approaches based on human expertise but also data-driven approaches, i.e., extracting insights or useful knowledge from data, and their hybridization. This understanding can help security analysts and professionals comprehend how systems work, identify potential threats and anomalies, and make better decisions in various real-world application areas. We also cover how these techniques can address diverse cybersecurity concerns such as threat detection, mitigation, prediction, diagnosis for root cause findings, and so on in different CI sectors, such as energy, defence, transport, health, water, agriculture, etc. We conclude this paper with a list of identified issues and opportunities for future research, as well as their potential solution directions for how researchers and professionals might tackle future generation cybersecurity modeling in this emerging area of study.}
}


@article{DBLP:journals/iot/JenaBP24,
	author = {Sanjay Kumar Jena and
                  Ram Chandra Barik and
                  Rojalina Priyadarshini},
	title = {A systematic state-of-art review on digital identity challenges with
                  solutions using conjugation of {IOT} and blockchain in healthcare},
	journal = {Internet Things},
	volume = {25},
	pages = {101111},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101111},
	doi = {10.1016/J.IOT.2024.101111},
	timestamp = {Sun, 19 Jan 2025 14:28:20 +0100},
	biburl = {https://dblp.org/rec/journals/iot/JenaBP24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Digital Identity is a prominent practice across every digital platform for maintaining confidentiality and privacy. The demand for Internet of Things (IoT) and its allied technologies such as Internet of Medical Things (IoMT), the Industrial Internet of Things (IIoT), and the Internet of Video Things (IoVT) is constantly on the rise in both wired and wireless domains. IoT communications emerge as a major challenge for digital identity-based security solutions in the areas of healthcare, transportation, and their allied applications. This paper addresses the different aspects of digital identity for security preservation and maintenance in IoT and blockchain based solutions. It focuses on Confidentiality, Integrity, and Availability (CIA) issues and corresponding digital identity solutions using the duo. The writers perused over 112 publications and shared their findings on cutting-edge technologies related to Digital Identity (DId) in the healthcare industry.}
}


@article{DBLP:journals/iot/SharmaT24,
	author = {Ankur Sharma and
                  Veni Thangaraj},
	title = {Intelligent service placement algorithm based on {DDQN} and prioritized
                  experience replay in IoT-Fog computing environment},
	journal = {Internet Things},
	volume = {25},
	pages = {101112},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101112},
	doi = {10.1016/J.IOT.2024.101112},
	timestamp = {Mon, 01 Apr 2024 11:15:32 +0200},
	biburl = {https://dblp.org/rec/journals/iot/SharmaT24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The widespread use of Internet of Things-based applications has led to the development of the fog computing paradigm, enabling seamless utilization of edge and cloud resources. The placement of IoT service requests at the appropriate fog nodes is one of the key problems in a fog-cloud environment, which affects the overall system performance and user experience. The challenges associated with service placement are the stochastic nature of service demand, heterogeneous and distributed characteristics of fog nodes. The objective of this work is to develop an effective service placement method to meet the varying resource requirements of services while optimizing two important performance parameters: service execution time and fog nodes’ energy consumption. Existing solutions are slow to adapt and neglecting the temporal patterns of service resource demand. This paper proposes a novel service placement algorithm based on double deep Q-Network and prioritized experience replay (DDQN-PER), which explores the optimal service placement strategy using the adaptive learning ability of deep reinforcement learning (DRL). The DRL agent learns the dynamic nature of the resource requirements of services to find an appropriate fog node for service placement. To evaluate the performance of the proposed algorithm, experiments are carried out using Measurement and Analysis on the WIDE Internet (MAWI) traffic traces. The proposed DDQN-PER algorithm, compared with other state-of-the-art methods and experimental results, show that the proposed method can minimize the service latency time and fog node’s energy consumption from 2.5% to 8% and 6% to 17%, respectively.}
}


@article{DBLP:journals/iot/DanganaHAIZ24,
	author = {Muhammad Dangana and
                  Sajjad Hussain and
                  Shuja Ansari and
                  Muhammad Imran and
                  Ahmed Zoha},
	title = {A Digital Twin {(DT)} approach to Narrow-Band Internet of Things (NB-IoT)
                  wireless communication optimization in an industrial scenario},
	journal = {Internet Things},
	volume = {25},
	pages = {101113},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101113},
	doi = {10.1016/J.IOT.2024.101113},
	timestamp = {Mon, 03 Mar 2025 22:14:48 +0100},
	biburl = {https://dblp.org/rec/journals/iot/DanganaHAIZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The pervasive realization of virtual replication of physical entities termed Digital Twin (DT) has been utilized in this paper to optimize the wireless communication of the Narrowband Internet of Things (NB-IoT) in an industrial scenario. This optimization is exclusively achieved through DT approach. NB-IoT is a Low-Powered Wide Area Network (LPWAN) standardized by 3GPP and leverages Long Term Evolution (LTE) technology. The Amplify-and-Forward (AF) optimization technique is used to improve the performance of some notably poor-performing terminals in the scenario. Bit-Error-Rate (BER) tests show the terminals’ overall performance before and after optimization. An improvement of 17% is achieved in BER. The signal quality of the channels is analyzed as well as the Cumulative Distribution Function (CDF) is used to showcase the effective throughput performance of the NB-IoT terminals.}
}


@article{DBLP:journals/iot/ZhangW24,
	author = {Jing Zhang and
                  Jing Wei},
	title = {Multi-residual tensor completion for spatiotemporal data imputation},
	journal = {Internet Things},
	volume = {25},
	pages = {101114},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101114},
	doi = {10.1016/J.IOT.2024.101114},
	timestamp = {Sun, 19 Jan 2025 14:28:19 +0100},
	biburl = {https://dblp.org/rec/journals/iot/ZhangW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In Cyber–Physical Systems, the spatiotemporal data collected often contains many missing values, which result from uncontrollable factors like sensor failure, communication disruption, and environmental interference. The missing values can significantly degrade system performance and even jeopardize system stability. In previous studies, tensor models were considered effective in spatiotemporal data imputation, attributed to their capability to capture spatiotemporal correlations within the data. Although tensor models can effectively capture the global features of data, they cannot learn the local fluctuation characteristics well. To further enhance the tensor model’s ability to capture local features, a residual iteration strategy was designed, enabling the model to learn local features from the previous round of residuals. Additionally, a multi tensor completion strategy was developed to achieve more accurate learning in each round of residuals. Combining these two strategies with tensor completion results in the Multiple Residual Tensor Completion (MRTC). We demonstrate through the visualization of imputation results that MRTC can further learn local features of the data compared to the original tensor completion model. In addition, comparative experiments were conducted on three publicly available spatiotemporal datasets, and the results showed that MRTC performed well in various missing data scenarios, outperforming the other four state-of-the-art tensor based imputation models in most cases.}
}


@article{DBLP:journals/iot/RazaqueKYAAA24,
	author = {Abdul Razaque and
                  Meenhoon Khan and
                  Joon Yoo and
                  Aziz Alotaibi and
                  Majid Alshammari and
                  Muder Almiani},
	title = {Blockchain-enabled heterogeneous 6G supported secure vehicular management
                  system over cloud edge computing},
	journal = {Internet Things},
	volume = {25},
	pages = {101115},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101115},
	doi = {10.1016/J.IOT.2024.101115},
	timestamp = {Tue, 15 Oct 2024 16:43:29 +0200},
	biburl = {https://dblp.org/rec/journals/iot/RazaqueKYAAA24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The emergence of 6G networks increases both the suitability and the speed of Internet-of-Things (IoT) devices within vehicular communication systems (VCSs). Wireless capabilities can be improved using a 6G network to successfully manage IoT devices in VCSs. 6G networks can be employed to reduce cyberattacks due to their unclaimed and unused operating frequencies. However, 6G networks could be vulnerable to cyberattacks due to their flexibility. The issues of 6G networks can adequately be addressed using blockchain technology. If a smart vehicular system uses IoT, then faster response times, substantial power reductions, and security for possible accident avoidance and safety provision can be achieved. Therefore, an energy-efficient consortium-based blockchain-enabled heterogeneous (EBH) 6G network for IoT devices can provide the best platform for secure management vehicular systems. In this article, we introduce a perspective architecture for the IoT-enabled secure vehicular system using a blockchain-enabled heterogeneous 6G network over cloud edge computing. The heterogeneous support of a 6G network is discussed, which is highly effective for smart vehicular management systems. The primary goal of the article is to motivate the community and researchers to use multidisciplinary and cross-cutting technologies integratively.}
}


@article{DBLP:journals/iot/ClementeLopezMR24,
	author = {Daniel Clemente{-}L{\'{o}}pez and
                  Jes{\'{u}}s M. Mu{\~{n}}oz{-}Pacheco and
                  Jos{\'{e}} de Jesus Rangel{-}Magdaleno},
	title = {Experimental validation of IoT image encryption scheme based on a
                  5-D fractional hyperchaotic system and Numba {JIT} compiler},
	journal = {Internet Things},
	volume = {25},
	pages = {101116},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101116},
	doi = {10.1016/J.IOT.2024.101116},
	timestamp = {Mon, 15 Apr 2024 08:26:25 +0200},
	biburl = {https://dblp.org/rec/journals/iot/ClementeLopezMR24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the realm of Internet of Things (IoT) systems, the interconnectivity of physical hardware devices is a fundamental aspect, and as a result, data exchange assumes a critical role in the network. Given the sensitivity of such information, it is imperative to adopt appropriate measures to encrypt the data to safeguard it from unauthorized access. It is, therefore, paramount to prove novel encryption algorithms at an experimental level. To overcome that, a potential solution is fractional-order multi-scroll chaotic systems, which provide an extra degree of freedom to enhance ergodicity and random-like behaviors, which can help to improve encryption keyspace to get robust ciphers. However, the numerical algorithms to obtain a fractional chaotic series increase the computational cost because they demand extensive simulation time to model the memory of the standard fractional derivatives, limiting high-speed encryption. In this framework, a fast encryption scheme using a 5D fractional-order (FO) hyper-chaotic multi-scroll (HCMS) system is proposed and verified experimentally. Based on multiprocessing strategies and the Numba just-in-time (JIT) compiler, the Python code that describes the FO-HCMS system is optimized, which enables image encryption in real-time. The physical implementation of the encryption scheme is performed on an Advance RISC Machine (ARM) processor, and it is applied for image encryption on a machine-to-machine (M2M) communication using the message queuing telemetry transport (MQTT) protocol. The obtained results indicate that the proposed encryption scheme can reach encryption throughputs of up to 19.891 Mbps on an ARM with a 1.4 GHz CPU and 77.864 Mbps on a PC with a 3.1 GHz CPU.}
}


@article{DBLP:journals/iot/GhosalDUSBW24,
	author = {Sagnik Ghosal and
                  Debanjan Das and
                  Venkanna Udutalapally and
                  Srivatsan Sridhar and
                  Syed Maaiz Syed Shabbeer Basha and
                  Preetam Narayan Wasnik},
	title = {DeepVitals: Deep neural and IoT based vitals monitoring in smart teleconsultation
                  system},
	journal = {Internet Things},
	volume = {25},
	pages = {101117},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101117},
	doi = {10.1016/J.IOT.2024.101117},
	timestamp = {Sun, 04 Aug 2024 19:51:17 +0200},
	biburl = {https://dblp.org/rec/journals/iot/GhosalDUSBW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the ubiquitous presence of smart devices, teleconsultation has been an emerging aspect of smart healthcare to stem the increasing dangers of deadly contagious diseases and identify any illness, disease, or medical condition. Heart rate, blood pressure, and oxygen saturation are the most observed vitals for any medical prognosis. However, existing methods to measure them are invasive or contact-based, requiring specialists to operate. The paper introduces a deep neural, non-invasive model to estimate the vitals. The proposed method processes photoplethysmography signals and feeds them to deep neural networks to evaluate the user’s vitals. The model monitors the vitals and can discern anomalous readings. The proposed model’s results further establish itself as a reliable vitals measurement and monitoring device that bolsters the at-home diagnosis feature.}
}


@article{DBLP:journals/iot/BakerAKAG24,
	author = {Thar Baker and
                  Zaher Al Aghbari and
                  Ahmed M. Khedr and
                  Naveed Ahmed and
                  Shini Girija},
	title = {{EDITORS:} Energy-aware Dynamic Task Offloading using Deep Reinforcement
                  Transfer Learning in SDN-enabled Edge Nodes},
	journal = {Internet Things},
	volume = {25},
	pages = {101118},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101118},
	doi = {10.1016/J.IOT.2024.101118},
	timestamp = {Sat, 08 Jun 2024 13:15:49 +0200},
	biburl = {https://dblp.org/rec/journals/iot/BakerAKAG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In mobile edge computing systems, a task offloading approach should balance efficiency, adaptability, trust management, and reliability. This approach aims to maximise resource utilisation, improve user experience, and satisfy application-specific requirements while taking into account the dynamic and limited resource nature of edge environments. Additionally, while offloading tasks, these systems are vulnerable to several attacks and privacy breaches, necessitating edge node trust evaluation. However, not all of these necessary features are present in the offloading methods currently used. This research proposes ‘EDITORS’ (energy-aware dynamic task offloading method utilising Deep Reinforcement Transfer Learning (DRTL) in Software-Defined Network (SDN) enabled edge computing environments), a novel approach aimed at addressing the multifaceted issues associated with offloading in mobile edge computing systems. The primary goal of EDITORS is to design a task offloading system that incorporates trusted edge nodes while prioritising energy efficiency, timeliness, reliability, adaptability, and outperforming existing task offloading methods in terms of the quality of the task offloading plan. This method uses of DRTL agents at edge nodes, which communicate with the SDN controller to learn the most appropriate offloading choices based on network conditions and resource availability. Extensive simulations (six) are conducted which show that the EDITORS significantly increases energy efficiency while preserving low-latency task completion compared to five existing offloading methods (DDLO, DROO, DMRO, DRL without TL and SDN and DRL with SDN). EDITORS includes trust evaluation, trusted edge device prediction using LSTM, and adaptation of newly added devices through transfer learning, unlike other task offloading methods that just concentrate on task offloading.}
}


@article{DBLP:journals/iot/IbrahimCEYIAI24,
	author = {Ali M. A. Ibrahim and
                  Zhigang Chen and
                  Hala A. Eljailany and
                  Genghua Yu and
                  Aridegbe A. Ipaye and
                  Khalid A. Abouda and
                  Wail M. Idress},
	title = {Advancing 6G-IoT networks: Willow catkin packet transmission scheduling
                  with {AI} and bayesian game-theoretic approach-based resource allocation},
	journal = {Internet Things},
	volume = {25},
	pages = {101119},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101119},
	doi = {10.1016/J.IOT.2024.101119},
	timestamp = {Sun, 21 Jul 2024 18:16:55 +0200},
	biburl = {https://dblp.org/rec/journals/iot/IbrahimCEYIAI24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The rapid expansion of mobile broadband networks and the proliferation of Internet of Things (IoT) applications have substantially increased data transmission and processing demands. However, the application domains of IoT-enabled models often face resource limitations, requiring rapid responses, low latency, and large bandwidth, surpassing their inherent capabilities. To address these challenges, we propose a fishnet approach-based packet scheduling and resource allocation system, termed Fishnet-6G, to optimize network resource allocation in the proposed 6G networks. Initially, we constructed a Sierpinski Triangle-based network in a 6G-IoT environment, enhancing device connectivity. We utilize the Quantum Density Peak Clustering (QDPC) algorithm to perform clustering for IoT devices, establishing Cluster Head (CH) and Substitute CH (SUB CH) based on actual metrics. Furthermore, traffic prediction is achieved through two processes, grouping, and fair queue status, using the Improved Deep Deterministic Policy Gradient (IMPDDPG) algorithm with a variable sampling rate, resulting in well-organized packet scheduling. Subsequently, we perform optimal packet scheduling by employing the Willow Catkin Optimization (WCO) algorithm, and the scheduled packets are managed within a Fishing Net Topology to reduce energy consumption and system complexity. Finally, we allocate the scheduled packets to the desired resource blocks using the Bayesian Game-Theoretic Approach (BGTA). The proposed approach is implemented using Network Simulator-3.26, and the performance of the Fishnet-6G model is evaluated based on time, transmission rate, energy efficiency, average throughput, latency, and Packet loss rate. Numerical analysis demonstrates that Fishnet-6G outperforms existing approaches across these metrics, showcasing its effectiveness in addressing the challenges of 6G-IoT networks.}
}


@article{DBLP:journals/iot/SandhuSBZK24,
	author = {Moid Sandhu and
                  David Silvera{-}Tawil and
                  Paulo Borges and
                  Qing Zhang and
                  Brano Kusy},
	title = {Internet of robotic things for independent living: Critical analysis
                  and future directions},
	journal = {Internet Things},
	volume = {25},
	pages = {101120},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101120},
	doi = {10.1016/J.IOT.2024.101120},
	timestamp = {Thu, 08 Aug 2024 08:08:45 +0200},
	biburl = {https://dblp.org/rec/journals/iot/SandhuSBZK24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The elderly population is growing rapidly around the world. At the same time, the number of people living with a disability is increasing. Due to lower immunity, decreased mobility, and a shortage in healthcare facilities and clinical staff, these populations face severe health challenges, including a limited ability to live independently. Advanced technological solutions can be used to support healthy and independent living, improving the quality of life of individuals. In this paper, we explore the emerging but underexplored field of internet of robotic things (IoRT) for independent living support. IoRT employs various on-body, off-body and ambient sensors to get real-time information from individuals, with robotic systems used to provide assistance with daily activities, critical and emergency events. We find that most of the previous IoRT works monitor the people offline and store their sensory data for later analysis instead of online processing and offering real-time assistance. We undertake a critical examination of the limitations and future opportunities in the field, with particular attention given to the health domain to provide autonomous, secure and independent living to elderly and people living with a disability (PLWD).}
}


@article{DBLP:journals/iot/KhanGNAD24,
	author = {Latif U. Khan and
                  Mohsen Guizani and
                  Dusit Niyato and
                  Ala I. Al{-}Fuqaha and
                  M{\'{e}}rouane Debbah},
	title = {Metaverse for wireless systems: Architecture, advances, standardization,
                  and open challenges},
	journal = {Internet Things},
	volume = {25},
	pages = {101121},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101121},
	doi = {10.1016/J.IOT.2024.101121},
	timestamp = {Mon, 01 Apr 2024 11:15:32 +0200},
	biburl = {https://dblp.org/rec/journals/iot/KhanGNAD24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The growing landscape of emerging wireless applications is a key driver towards the development of novel wireless system designs. Such a design can be based on a metaverse that uses a virtual model of the physical world system along with other schemes/technologies (e.g., optimization theory, machine learning, and blockchain). A metaverse using a virtual model performs proactive intelligent analytics prior to a user request for analysis and efficient management of the wireless system resources. A metaverse also enables self-sustainability in wireless systems that leads to the least possible intervention from network operators for its operation. Although the metaverse can offer many benefits, it faces some challenges as well. Therefore, in this tutorial, we discuss the role of a metaverse in enabling wireless applications. We present an overview, key enablers, design aspects (i.e., metaverse for wireless and wireless for metaverse), and high-level architecture of metaverse-based wireless systems. Then, we discuss network management, reliability, and security of the metaverse-based system. Finally, we outline open challenges and present possible solutions.}
}


@article{DBLP:journals/iot/AsieduLY24,
	author = {Derek Kwaku Pobi Asiedu and
                  Kyoung{-}Jae Lee and
                  Ji{-}Hoon Yun},
	title = {Energy-efficient routing, power control and energy clustering for
                  energy harvesting-enabled spectrum sharing IoT sensor networks},
	journal = {Internet Things},
	volume = {25},
	pages = {101122},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101122},
	doi = {10.1016/J.IOT.2024.101122},
	timestamp = {Mon, 01 Apr 2024 11:15:33 +0200},
	biburl = {https://dblp.org/rec/journals/iot/AsieduLY24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We investigate a spectrum sharing system that enables energy harvesting from distributed multi-antenna energy transmitter devices for primary dual-band device-to-device networks and secondary dual-band wireless sensor networks (WSNs), incorporating a multi-stage rectenna energy harvesting circuit model. We formulate a new multi-hop routing problem for network energy efficiency maximization of this system, which involves the interconnected tasks of WSN routing, controlling the transmit power of sensor nodes, and energy transmitter clustering, taking into account interference, power budget and rate constraints. To tackle these interconnected tasks effectively, we propose an integrated solution that includes both centralized and distributed routing schemes. Furthermore, the solution incorporates energy transmitter clustering schemes based on harvested power and channel gain. We provide an analysis of the computation complexity and signaling overhead for the proposed solution. Our simulation results demonstrate that the proposed routing and clustering schemes outperform their respective benchmark schemes, achieving significant performance gains.}
}


@article{DBLP:journals/iot/AbdulmalekNJ24,
	author = {Suliman Abdulmalek and
                  Abdul Nasir and
                  Waheb A. Jabbar},
	title = {LoRaWAN-based hybrid internet of wearable things system implementation
                  for smart healthcare},
	journal = {Internet Things},
	volume = {25},
	pages = {101124},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101124},
	doi = {10.1016/J.IOT.2024.101124},
	timestamp = {Sat, 08 Jun 2024 13:15:49 +0200},
	biburl = {https://dblp.org/rec/journals/iot/AbdulmalekNJ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This study introduces the design and development of an Internet of Wearable Things-based Hybrid Healthcare Monitoring System (IoWT-HHMS) for smart medical applications. The system incorporates smart wearable sensing units for real-time, remote monitoring of vital health parameters such as Blood Pressure (BP), Heart Rate (HR), and Body Temperature (BT). A key innovation is the development of a hybrid wireless network communication mechanism within the IoWT-HHMS, utilising the FiPy microcontroller. This mechanism supports both short- and long-range connectivity and integrates an algorithm for efficient data acquisition and updating to the IoT platform. The IoWT-HHMS has undergone extensive testing and validation across various scenarios, including sensor functionality, performance of Wi-Fi and LoRaWAN networks, hybrid network connectivity, and accuracy assessment using the Datacake dashboard. The tests evaluated crucial aspects such as communication reliability, power consumption, and latency. The results demonstrate the system's high stability and accuracy in reading health parameters. Comparisons with reference devices reveal impressive accuracy levels for Systolic BP (SBP), Diastolic BP (DBP), HR, and BT, recording 96.37 %, 95.17 %, 97 %, and 98.57 % accuracy, respectively. Both Wi-Fi and LoRaWAN networks proved reliable in indoor and outdoor settings, maintaining data transmission over distances up to 1.5 km without data loss. In conclusion, the developed IoWT-HHMS shows great promise for efficient and effective real-time remote monitoring of patients' health conditions using an innovative hybrid wireless network communication mechanism.}
}


@article{DBLP:journals/iot/Pereira24,
	author = {Rui Humberto R. Pereira},
	title = {Lightweight data bridge for connecting self-service end-user analytic
                  tools to NGSI-based IoT systems},
	journal = {Internet Things},
	volume = {25},
	pages = {101125},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101125},
	doi = {10.1016/J.IOT.2024.101125},
	timestamp = {Sat, 08 Jun 2024 13:15:49 +0200},
	biburl = {https://dblp.org/rec/journals/iot/Pereira24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The FIWARE and related projects aim to provide an open, sustainable ecosystem based on public standards and royalty-free that accelerates the development of Smart Solutions. The broker (Orion, Scorpio and Stellio) and additional components, named Generic Enablers (GE), provide means for collecting IoT data and feeding a data layer. The NGSI standard has a structural role in terms of interoperability, thus promoting the development of new GEs. However, this standard is not being adopted in analytic tools. In general, these tools connect to the IoT backend databases, which poses problems regarding data access control management and requires specialised IT support. Thus, it is not well suited for enterprise scenarios like, for instance, smart agriculture or smart industry, in which self-service tools, such as Power BI, Tableau and Qlik, are frequently used.}
}


@article{DBLP:journals/iot/QaziKKAK24,
	author = {Faiza Qazi and
                  Daehan Kwak and
                  Fiaz Gul Khan and
                  Farman Ali and
                  Sami Ullah Khan},
	title = {Service Level Agreement in cloud computing: Taxonomy, prospects, and
                  challenges},
	journal = {Internet Things},
	volume = {25},
	pages = {101126},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101126},
	doi = {10.1016/J.IOT.2024.101126},
	timestamp = {Sat, 08 Jun 2024 13:15:49 +0200},
	biburl = {https://dblp.org/rec/journals/iot/QaziKKAK24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cloud computing represents a distributed computing paradigm, offering hosted services via the internet on a pay-as-you-go basis. The Service Level Agreement (SLA) serves as a pivotal element of communication between Cloud Service Providers (CSPs) and Cloud Service Users (CSUs), detailing Service Level Objectives (SLOs) pertinent to service functionalities and Quality of Service (QoS). Within an SLA, service terms are formally documented in a contract between the CSP and CSU, ensuring that outsourcing customers establish an SLA with their vendors, thereby holding vendors accountable for financial consequences or payments should the set objectives not be achieved. In recent years, SLA methodologies in cloud computing have attracted considerable attention from the research community, with numerous strategies being developed to tackle challenges that may impede the efficient provisioning and management of QoS. This survey paper offers a comprehensive review of SLA techniques, presenting a detailed taxonomy based on their distinctive attributes. It discusses the evaluation parameters and platforms utilized in analyzing SLA approaches. Furthermore, the paper outlines design objectives and highlights open research issues that should be addressed when proposing new SLA techniques.}
}


@article{DBLP:journals/iot/CamposRGBS24,
	author = {Enrique M{\'{a}}rmol Campos and
                  Jos{\'{e}} Luis Hern{\'{a}}ndez Ramos and
                  Aurora Gonz{\'{a}}lez{-}Vidal and
                  Gianmarco Baldini and
                  Antonio F. Skarmeta},
	title = {Misbehavior detection in intelligent transportation systems based
                  on federated learning},
	journal = {Internet Things},
	volume = {25},
	pages = {101127},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101127},
	doi = {10.1016/J.IOT.2024.101127},
	timestamp = {Sat, 08 Jun 2024 13:15:49 +0200},
	biburl = {https://dblp.org/rec/journals/iot/CamposRGBS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Misbehavior detection represents a key security approach in vehicular scenarios to identify attacks that cannot be detected by traditional cryptographic mechanisms. In this context, the application of Machine Learning (ML) techniques has been widely considered to identify increasingly sophisticated misbehavior attacks. However, most of the proposed approaches are based on centralized settings, which could pose privacy issues, as well as an increased latency leading to severe consequences in the vehicular environment where real-time and scalability requirements are challenging. To address this issue, we propose a collaborative learning approach based on Federated Learning (FL) for vehicles’ misbehavior detection. We use the reference misbehavior dataset VeReMi, which is re-balanced by applying the SMOTE-Tomek technique. We carry out a thorough evaluation considering different balancing settings and number of nodes. The evaluation results overcome recent state-of-the-art approaches, with an overall accuracy of 93% using an optimized multilayer perceptron (MLP) for multiclass classification.}
}


@article{DBLP:journals/iot/FernandezVF24,
	author = {Eduardo Illueca Fern{\'{a}}ndez and
                  Antonio Jes{\'{u}}s Jara Valera and
                  Jesualdo Tom{\'{a}}s Fern{\'{a}}ndez{-}Breis},
	title = {Embedded machine learning of IoT streams to promote early detection
                  of unsafe environments},
	journal = {Internet Things},
	volume = {25},
	pages = {101128},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101128},
	doi = {10.1016/J.IOT.2024.101128},
	timestamp = {Sat, 08 Jun 2024 13:15:49 +0200},
	biburl = {https://dblp.org/rec/journals/iot/FernandezVF24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Indoor particulate matter (PM) are small solid and liquid particles present in the air, and its monitoring is one of the key challenges regarding workplace safety because of its impact on human health. To address this issue, the Internet of Things (IoT) paradigm allows the implementation of hyperlocal monitoring systems, typically using traditional cloud architectures, which can be enhanced using edge computing architectures. For this reason, we propose an IoT-Edge-Cloud architecture for a platform which promotes the early detection of unsafe environments through machine learning, composed of a sensing layer that collects all the data, an edge layer that performs the artificial intelligence tasks and a cloud layer orchestrating. This architecture is based on the FogFlow framework and the FIWARE components. Our solution proposes an embedded model that can predict the occurrence of PM values higher than the recommended ones—according to the Occupational Safety and Health Administration (OSHA) indicators—with an 87 % of accuracy and a reduction of latency of 26 %. Our platform is innovative because it is based on the FogFlow framework for edge computing and supported by the Smart Spot device validated in a field test. This step is missing from similar state-of-the-art platforms. Thus, we believe that this work contributes to demonstrating the usefulness of AIoT to monitor workplace safety and make trustable predictions, avoiding risky environments.}
}


@article{DBLP:journals/iot/GhoshKASVS24,
	author = {Joydev Ghosh and
                  Neeraj Kumar and
                  Khaled Abdul{-}Aziz Al{-}Utaibi and
                  Sadiq M. Sait and
                  Van Nhan Vo and
                  Chakchai So{-}In},
	title = {Reliable data transmission for a VANET-IoIT architecture: {A} {DNN}
                  approach},
	journal = {Internet Things},
	volume = {25},
	pages = {101129},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101129},
	doi = {10.1016/J.IOT.2024.101129},
	timestamp = {Mon, 01 Apr 2024 11:15:33 +0200},
	biburl = {https://dblp.org/rec/journals/iot/GhoshKASVS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The challenges and resilience of vehicular ad hoc network (VANET) and deep neural network (DNN) hybrid architectures in terms of reliability in smart cities have attracted much global interest stemming from the rollout of the next generation of intelligent networks. In this paper, we propose a novel distributed DNN (D-DNN) scheme with blockchain to support the Internet of Intelligent Things (IoIT) infrastructure in the VANET environment of the future. In particular, because the communication links between edge nodes are very unstable in VANETs, a new neuro-fuzzy server that serves the dual roles of finding reliable links between edge nodes and performing optimal routing path selection is proposed. Next, a blockchain layer is employed at the edge nodes, which are initially scrutinized before establishing communication links to ensure reliability during data transfer. Then, the proposed D-DNN (PD-DNN) scheme is applied to enhance the performance of the VANET-IoIT architecture by improving the data flow and convergence rate and mitigating erratic variations in output. To address reliability concerns, the coverage probability (CP) metric is investigated as a measure of network connectivity. Furthermore, we present an analysis of the PD-DNN scheme in comparison with the traditional DNN (T-DNN) scheme. Finally, simulation results for VANET-IoIT scenarios show that, subject to data protection and privacy constraints, the CP values corresponding to different communication links are improved to a greater extent under our scheme than under the traditional scheme, demonstrating the feasibility of the proposed scheme.}
}


@article{DBLP:journals/iot/CardellOliverCH24,
	author = {Rachel Cardell{-}Oliver and
                  Andrea Cominola and
                  Jin B. Hong},
	title = {Activity and resolution aware privacy protection for smart water meter
                  databases},
	journal = {Internet Things},
	volume = {25},
	pages = {101130},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101130},
	doi = {10.1016/J.IOT.2024.101130},
	timestamp = {Sat, 08 Jun 2024 13:15:49 +0200},
	biburl = {https://dblp.org/rec/journals/iot/CardellOliverCH24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Identifying water end-uses from household meter readings yields valuable commercial and environmental insights for both customers and water providers. However, smart water meter databases may expose sensitive information about the activities of metered households, thus raising privacy concerns that limit the possibility of making smart meter data available for research and planning. This paper considers the case where a water provider wishes to publish a database of household water meter traces to be used by water analysts, who are often external entities. This scenario presents privacy risks should an adversary gain access to this database, with the threat of uniquely identifying a household of interest and exposing its water use activities. To mitigate such risks, this paper proposes a process for activity-aware privacy protection and evaluates its effectiveness using real-world and synthetic databases. Our experimental analysis shows that water meter privacy protection is strongly dependent on the type of activity, temporal resolution, and population size. For example, in the case of a high-resolution database, we found that a large base population, small published sample, and 30-second resolution provided optimal trade-offs between privacy and information value. For a low-resolution database with a population of over 3500 households, 1-hour resolution provided strong information value and customisable privacy guarantees depending on the published sample size.}
}


@article{DBLP:journals/iot/AlomariK24,
	author = {Ahmad Alomari and
                  Sathish A. P. Kumar},
	title = {Securing IoT systems in a post-quantum environment: Vulnerabilities,
                  attacks, and possible solutions},
	journal = {Internet Things},
	volume = {25},
	pages = {101132},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101132},
	doi = {10.1016/J.IOT.2024.101132},
	timestamp = {Mon, 01 Apr 2024 11:15:33 +0200},
	biburl = {https://dblp.org/rec/journals/iot/AlomariK24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The Internet of Things (IoT) refers to the distributed systems environment connecting billions of devices to the Internet, and quantum computing is an emerging technology that has a positive impact on IoT security by speeding up data processing while also having a negative impact due to post-quantum security attacks. In this survey, we provide detailed information on the possible post-quantum security attacks that threaten the security of the layers of IoT systems in terms of their vulnerabilities. Also, we provide detailed information on the existing solutions against post-quantum security attacks and show how limitations in these solutions decrease the security performance. Furthermore, we develop classification models to allow the readers to choose the best security approach against post-quantum security attacks in terms of IoT layers. Finally, we show the open challenges of the surveyed quantum security solutions and propose a framework based on quantum machine learning that takes advantage of optical pulses of secure communication as a future solution for detecting post-quantum security attacks.}
}


@article{DBLP:journals/iot/HasanSJYO24,
	author = {Haya R. Hasan and
                  Khaled Salah and
                  Raja Jayaraman and
                  Ibrar Yaqoob and
                  Mohammed A. Omar},
	title = {NFTs for combating deepfakes and fake metaverse digital contents},
	journal = {Internet Things},
	volume = {25},
	pages = {101133},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101133},
	doi = {10.1016/J.IOT.2024.101133},
	timestamp = {Sat, 08 Jun 2024 13:15:49 +0200},
	biburl = {https://dblp.org/rec/journals/iot/HasanSJYO24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The metaverse has gained immense popularity in recent years. However, the widespread adoption of this immersive virtual environment faces a substantial challenge from deepfake technology. The proliferation of deepfakes poses a significant risk as it enables the dissemination of misinformation and manipulated digital media. In this paper, we propose a blockchain and Non-Fungible Tokens (NFTs) based solution to combat the threats associated with deepfakes. Our proposed solution is applicable to various types of digital media found on the internet, social media platforms, and within the metaverse. We incorporate decentralized off-chain storage to ensure the security and integrity of digital media. This leads to preserving both the digital media and associated NFT metadata in a secure manner. We leverage the intrinsic features of blockchain, such as tamper-proof logs and data provenance, to enable users to verify the authenticity of digital media. We introduce a decentralized reputation system that employs equations, trust factors, and trust badges. Through this system, digital creators are incentivized with trust badges based on their trust factor values, which enhances the overall credibility of the content. We present the cost and security analyses as well as provide a comparative evaluation against existing solutions. We make our smart contract code publicly available on GitHub.}
}


@article{DBLP:journals/iot/TangCSXZ24,
	author = {Junyi Tang and
                  Jin Chen and
                  Yong Su and
                  Meng Xing and
                  Shuang Zhu},
	title = {{MTAN:} Multi-degree Tail-aware Attention Network for human motion
                  prediction},
	journal = {Internet Things},
	volume = {25},
	pages = {101134},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101134},
	doi = {10.1016/J.IOT.2024.101134},
	timestamp = {Mon, 01 Apr 2024 11:15:33 +0200},
	biburl = {https://dblp.org/rec/journals/iot/TangCSXZ24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Human motion prediction (HMP) aims to predict future human motions from historical pose sequences. Extensive efforts have adopted the Transformers or Graph Neural Networks (GNNs) to capture the spatio-temporal relationships between poses and thus incorporate the contextual information and complex behavior relationships for motion inference. However, most existing approaches treat the HMP task as a deterministic problem, thus resulting in poor diversity and long tail problems. This study attributes such issues to positional bias within the Transformers and the lack of degrees of freedom within the predictive model. Hence, we propose a novel Multi-degree Tail-aware Attention Network (MTAN) involving a tail-aware attention mechanism and a multi-degree feature representation strategy. Specifically, we introduce a tail-aware attention mechanism to adeptly capture spatio-temporal dependencies that accommodate both head and tail actions. Based on CVAE, the multi-degree feature representation strategy learns to capture temporal diversity by learning the joint distribution of observed and future sequences. Ultimately, we leverage GCN to model spatial dependencies effectively, culminating in a comprehensive spatiotemporal prediction model. We evaluate the effectiveness of our approach using three benchmark datasets, including Human3.6M, AMASS, and 3DPW. The results demonstrate that our approach surpasses state-of-the-art transformer methods, establishing its superiority in HMP.}
}


@article{DBLP:journals/iot/AsoreyCachedaGGG24,
	author = {Rafael Asorey{-}Cacheda and
                  Laura Garc{\'{\i}}a and
                  Antonio{-}Javier Garc{\'{\i}}a{-}S{\'{a}}nchez and
                  Joan Garc{\'{\i}}a{-}Haro},
	title = {Transmission power allocation in flow-guided nanocommunication networks},
	journal = {Internet Things},
	volume = {25},
	pages = {101137},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101137},
	doi = {10.1016/J.IOT.2024.101137},
	timestamp = {Sat, 08 Jun 2024 13:15:49 +0200},
	biburl = {https://dblp.org/rec/journals/iot/AsoreyCachedaGGG24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Flow-guided electromagnetic nanonetworks hold tremendous potential for transformative medical applications, enabling monitoring, information gathering, and data transmission within the human body. Operating in challenging environments with stringent computational and power constraints within human vascular systems, these nanonetworks face significant hurdles. Successful transmissions between in-body nanonodes and on-body nanorouters are infrequent, requiring novel approaches to enhance network throughput under such circumstances. Traditional flow-guided nanonetworks rely on nanonodes to transmit packets if they possess sufficient energy, irrespective of their proximity to the nanorouter. In this paper, we present an extended model for legacy flow-guided nanonetworks that offers substantial throughput improvements while reducing the required number of nanonodes compared to the baseline blind transmission approach. By allocating transmission energy to allow more than one transmission during a charging cycle, our proposed model significantly enhances network throughput, facilitating the deployment of nanocommunication-supported medical applications. For example, with only two transmissions, it is possible to increase throughput by around 46% with the same number of nanonodes or, equivalently, reduce the number of nanonodes by the same amount to achieve the same throughput.}
}


@article{DBLP:journals/iot/HanZW24,
	author = {Yue Han and
                  Yue Zhang and
                  Jun Wang},
	title = {Semantic-driven dimension reduction for wireless internet of things},
	journal = {Internet Things},
	volume = {25},
	pages = {101138},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101138},
	doi = {10.1016/J.IOT.2024.101138},
	timestamp = {Wed, 20 Mar 2024 10:34:29 +0100},
	biburl = {https://dblp.org/rec/journals/iot/HanZW24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent years, mobile communication and artificial intelligence technologies have been widely used in the construction of wireless networks, bringing about a dramatic increase in data size. Existing wireless networks usually consist of a large number of nodes, with the potential risk of the curse of dimensionality. High dimensionality plays a negative role in learning effectiveness and efficiency, which should have been studied in depth but is neglected in existing wireless network research. In order to generate effective semantic-driven efficiency, this paper focuses on semantic-driven dimensionality reduction for wireless Internet of Things. Specifically, this paper introduces a series of feature selection techniques centered on Mahalanobis distance for dimensionality reduction, which helps to select discriminative features by measuring the effectiveness of semantic preferences and semantic-driven efficiency through Mahalanobis distance. Experiments on a set of wireless sensor data and various high-dimensional microarray data validate the superior performance of the proposed method.}
}


@article{DBLP:journals/iot/StangaciuSCM24,
	author = {Valentin Stangaciu and
                  Cristina Stangaciu and
                  Daniel{-}Ioan Curiac and
                  Mihai V. Micea},
	title = {PARSECS{\_}RT: {A} real-time PARSECS-based communication protocol
                  stack for critical sensing applications},
	journal = {Internet Things},
	volume = {25},
	pages = {101139},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101139},
	doi = {10.1016/J.IOT.2024.101139},
	timestamp = {Sat, 08 Jun 2024 13:15:49 +0200},
	biburl = {https://dblp.org/rec/journals/iot/StangaciuSCM24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The real-time characteristics of modular systems have been a long sought-after goal in many industries including automotive, aeronautics or mobile robotics. Yet scientists and practitioners are still struggling to find widespread implementation solutions that may accommodate diverse inter-modular real-time communication requirements. In an attempt to cover this research gap, the current paper proposes a real-time version of the PARSECS protocol for low-end devices. Our new protocol, coined as PARSECS_RT, was designed according to Open Systems Interconnection Reference Model. It offers a full communication stack from the physical layer to the application layer on top of the SPI interface in order to provide a stable, hard real-time communication platform. PARSECS_RT was evaluated in real and simulated environments providing promising results.}
}


@article{DBLP:journals/iot/NieJLLQE24,
	author = {Jing Nie and
                  Jiachen Jiang and
                  Yang Li and
                  Jingbin Li and
                  Yujie Qiao and
                  Sezai Ercisli},
	title = {UAVEC-FLchain: Distributed multi-regional jujube orchard joint yield
                  estimation for secure agricultural-IoT applications},
	journal = {Internet Things},
	volume = {25},
	pages = {101143},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101143},
	doi = {10.1016/J.IOT.2024.101143},
	timestamp = {Thu, 19 Dec 2024 09:14:48 +0100},
	biburl = {https://dblp.org/rec/journals/iot/NieJLLQE24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent years, Internet of Things (IoT) is closely integrated with smart agriculture, providing better technical guarantee for the growth management and yield estimation of agricultural products. In this paper, targeted at the distributed jujube orchards, we develop a federated learning-based framework for secure multi-regional yield estimation on IoT edge devices. In specific, we propose the UAVEC-FLchain framework for secure and efficient jujube yield estimation, consisting of the UAVEC module, data joint processing module, and data tracking module. Different UAV devices are used at edge terminals to collect distributed images of different jujube orchards, and the model is trained securely with federation learning and blockchain. Furthermore, we propose a method to avoid malicious node attacks by calculating the contribution of computing nodes. Experimental results indicate that as the number of participating nodes increases, the average detection accuracy improves. The results of training with 60 nodes show an 8.06 % improvement over training with 6 nodes. When facing malicious node attacks, the relative error of the proposed framework is 10.24 % lower than that with traditional federated learning.}
}


@article{DBLP:journals/iot/Li24,
	author = {Boyuan Li},
	title = {Federated learning with a Balanced Heterogeneous-Yoke and Loose restriction},
	journal = {Internet Things},
	volume = {25},
	pages = {101144},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101144},
	doi = {10.1016/J.IOT.2024.101144},
	timestamp = {Mon, 01 Apr 2024 11:15:33 +0200},
	biburl = {https://dblp.org/rec/journals/iot/Li24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The most critical challenges of federated learning for joint modeling via model sharing are the problem of model drift due to the heterogeneous distribution of local data, and the cooperation of a subset of random devices due to communication constraints. To address these dilemmas, we propose a novel Federated Learning algorithm with a Balanced Heterogeneous-Yoke and Loose restriction(FedByL), which chooses to exploit more historical gradients from the client to accelerate model convergence; in addition, a more relaxed local restriction is chosen in local updates, and an incentive clause is proposed to encourage cooperative clients to find the global optimum. Experiments and analyses on 95 sets of five real-world datasets and one synthetic dataset show that FedByL achieves better in terms of convergence speed and accuracy compared to superior algorithms (e.g. FedDyn, SCAFFOLD). In particular, FedByL communication overhead is the same as FedAvg, being lightweight and requiring only one additional storage variable locally, which greatly reduces the communication burden and the risk of information being hijacked.}
}


@article{DBLP:journals/iot/TranTDDC24,
	author = {Nam{-}Phuong Tran and
                  Thanh Phung Truong and
                  Quang Tuan Do and
                  Nhu{-}Ngoc Dao and
                  Sungrae Cho},
	title = {Joint wireless resource allocation and bitrate adaptation for QoE
                  improvement in IRS-aided RSMA-enabled IoMT streaming systems},
	journal = {Internet Things},
	volume = {25},
	pages = {101145},
	year = {2024},
	url = {https://doi.org/10.1016/j.iot.2024.101145},
	doi = {10.1016/J.IOT.2024.101145},
	timestamp = {Sun, 06 Oct 2024 21:31:07 +0200},
	biburl = {https://dblp.org/rec/journals/iot/TranTDDC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the context of the increasing demand for Internet of Multimedia Things (IoMT) services, rate splitting multiple access (RSMA) and intelligent reflecting surface (IRS) technologies have been considered potential networking enablers to provide ultra-throughput wireless access. However, challenges arise due to the heterogeneity of IoMT devices and arbitrary network quality changes, resulting in unwanted service quality fluctuations and downgradation. This study addresses this problem by jointly optimizing wireless resource allocation and bitrate adaptation with Deep Reinforcement Learning (DRL)-based QoE management for IRS-aided RSMA-enabled IoMT streaming systems. We formulated the problem as a Markov decision process (MDP) and apply Proximal Policy Optimization (PPO) method to flexibly adjust IoMT bitrate, transmission beamforming, IRS phase shift, and RSMA parameters. As a result, our algorithm mitigates overestimation of client-side bandwidth, leading to smoother playback and reduced quality fluctuations. Simulations show that our approach outperforms baseline methods in terms of video resolution (up to 2.5 times) and achievable sum-rate (up to 50%), contributing to a superior streaming experience in IoMT systems.}
}
