@article{DBLP:journals/tkdd/LiuWGRFSZ22,
	author = {Fenglin Liu and
                  Xian Wu and
                  Shen Ge and
                  Xuancheng Ren and
                  Wei Fan and
                  Xu Sun and
                  Yuexian Zou},
	title = {DiMBERT: Learning Vision-Language Grounded Representations with Disentangled
                  Multimodal-Attention},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {1},
	pages = {1:1--1:19},
	year = {2022},
	url = {https://doi.org/10.1145/3447685},
	doi = {10.1145/3447685},
	timestamp = {Tue, 09 Jul 2024 15:32:27 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/LiuWGRFSZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Vision-and-language (V-L) tasks require the system to understand both vision content and natural language, thus learning fine-grained joint representations of vision and language (a.k.a. V-L representations) is of paramount importance. Recently, various pre-trained V-L models are proposed to learn V-L representations and achieve improved results in many tasks. However, the mainstream models process both vision and language inputs with the same set of attention matrices. As a result, the generated V-L representations are entangled in one common latent space. To tackle this problem, we propose DiMBERT (short for Disentangled Multimodal-Attention BERT), which is a novel framework that applies separated attention spaces for vision and language, and the representations of multi-modalities can thus be disentangled explicitly. To enhance the correlation between vision and language in disentangled spaces, we introduce the visual concepts to DiMBERT which represent visual information in textual format. In this manner, visual concepts help to bridge the gap between the two modalities. We pre-train DiMBERT on a large amount of image–sentence pairs on two tasks: bidirectional language modeling and sequence-to-sequence language modeling. After pre-train, DiMBERT is further fine-tuned for the downstream tasks. Experiments show that DiMBERT sets new state-of-the-art performance on three tasks (over four datasets), including both generation tasks (image captioning and visual storytelling) and classification tasks (referring expressions). The proposed DiM (short for Disentangled Multimodal-Attention) module can be easily incorporated into existing pre-trained V-L models to boost their performance, up to a 5% increase on the representative task. Finally, we conduct a systematic analysis and demonstrate the effectiveness of our DiM and the introduced visual concepts.}
}


@article{DBLP:journals/tkdd/GaoLFCZHJ22,
	author = {Chen Gao and
                  Yong Li and
                  Fuli Feng and
                  Xiangning Chen and
                  Kai Zhao and
                  Xiangnan He and
                  Depeng Jin},
	title = {Cross-domain Recommendation with Bridge-Item Embeddings},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {1},
	pages = {2:1--2:23},
	year = {2022},
	url = {https://doi.org/10.1145/3447683},
	doi = {10.1145/3447683},
	timestamp = {Sat, 03 Aug 2024 16:25:29 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/GaoLFCZHJ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Web systems that provide the same functionality usually share a certain amount of items. This makes it possible to combine data from different websites to improve recommendation quality, known as the cross-domain recommendation task. Despite many research efforts on this task, the main drawback is that they largely assume the data of different systems can be fully shared. Such an assumption is unrealistic different systems are typically operated by different companies, and it may violate business privacy policy to directly share user behavior data since it is highly sensitive. In this work, we consider a more practical scenario to perform cross-domain recommendation. To avoid the leak of user privacy during the data sharing process, we consider sharing only the information of the item side, rather than user behavior data. Specifically, we transfer the item embeddings across domains, making it easier for two companies to reach a consensus (e.g., legal policy) on data sharing since the data to be shared is user-irrelevant and has no explicit semantics. To distill useful signals from transferred item embeddings, we rely on the strong representation power of neural networks and develop a new method named as NATR (short for Neural Attentive Transfer Recommendation). We perform extensive experiments on two real-world datasets, demonstrating that NATR achieves similar or even better performance than traditional cross-domain recommendation methods that directly share user-relevant data. Further insights are provided on the efficacy of NATR in using the transferred item embeddings to alleviate the data sparsity issue.}
}


@article{DBLP:journals/tkdd/LinZLCX22,
	author = {Luyue Lin and
                  Xin Zheng and
                  Bo Liu and
                  Wei Chen and
                  Yanshan Xiao},
	title = {A Latent Variable Augmentation Method for Image Categorization with
                  Insufficient Training Samples},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {1},
	pages = {3:1--3:35},
	year = {2022},
	url = {https://doi.org/10.1145/3451165},
	doi = {10.1145/3451165},
	timestamp = {Fri, 17 Nov 2023 08:06:17 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/LinZLCX22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Over the past few years, we have made great progress in image categorization based on convolutional neural networks (CNNs). These CNNs are always trained based on a large-scale image data set; however, people may only have limited training samples for training CNN in the real-world applications. To solve this problem, one intuition is augmenting training samples. In this article, we propose an algorithm called Lavagan (Latent Variables Augmentation Method based on Generative Adversarial Nets) to improve the performance of CNN with insufficient training samples. The proposed Lavagan method is mainly composed of two tasks. The first task is that we augment a number latent variables (LVs) from a set of adaptive and constrained LVs distributions. In the second task, we take the augmented LVs into the training procedure of the image classifier. By taking these two tasks into account, we propose a uniform objective function to incorporate the two tasks into the learning. We then put forward an alternative two-play minimization game to minimize this uniform loss function such that we can obtain the predictive classifier. Moreover, based on Hoeffding’s Inequality and Chernoff Bounding method, we analyze the feasibility and efficiency of the proposed Lavagan method, which manifests that the LV augmentation method is able to improve the performance of Lavagan with insufficient training samples. Finally, the experiment has shown that the proposed Lavagan method is able to deliver more accurate performance than the existing state-of-the-art methods.}
}


@article{DBLP:journals/tkdd/GaoYXWZL22,
	author = {Jianliang Gao and
                  Xiaoting Ying and
                  Cong Xu and
                  Jianxin Wang and
                  Shichao Zhang and
                  Zhao Li},
	title = {Graph-Based Stock Recommendation by Time-Aware Relational Attention
                  Network},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {1},
	pages = {4:1--4:21},
	year = {2022},
	url = {https://doi.org/10.1145/3451397},
	doi = {10.1145/3451397},
	timestamp = {Fri, 05 Apr 2024 12:23:10 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/GaoYXWZL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The stock market investors aim at maximizing their investment returns. Stock recommendation task is to recommend stocks with higher return ratios for the investors. Most stock prediction methods study the historical sequence patterns to predict stock trend or price in the near future. In fact, the future price of a stock is correlated not only with its historical price, but also with other stocks. In this article, we take into account the relationships between stocks (corporations) by stock relation graph. Furthermore, we propose a Time-aware Relational Attention Network (TRAN) for graph-based stock recommendation according to return ratio ranking. In TRAN, the time-aware relational attention mechanism is designed to capture time-varying correlation strengths between stocks by the interaction of historical sequences and stock description documents. With the dynamic strengths, the nodes of the stock relation graph aggregate the features of neighbor stock nodes by graph convolution operation. For a given group of stocks, the proposed TRAN model can output the ranking results of stocks according to their return ratios. The experimental results on several real-world datasets demonstrate the effectiveness of our TRAN for stock recommendation.}
}


@article{DBLP:journals/tkdd/LinHLZW22,
	author = {Yaojin Lin and
                  Qinghua Hu and
                  Jinghua Liu and
                  Xingquan Zhu and
                  Xindong Wu},
	title = {{MULFE:} Multi-Label Learning via Label-Specific Feature Space Ensemble},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {1},
	pages = {5:1--5:24},
	year = {2022},
	url = {https://doi.org/10.1145/3451392},
	doi = {10.1145/3451392},
	timestamp = {Mon, 05 Feb 2024 20:24:42 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/LinHLZW22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In multi-label learning, label correlations commonly exist in the data. Such correlation not only provides useful information, but also imposes significant challenges for multi-label learning. Recently, label-specific feature embedding has been proposed to explore label-specific features from the training data, and uses feature highly customized to the multi-label set for learning. While such feature embedding methods have demonstrated good performance, the creation of the feature embedding space is only based on a single label, without considering label correlations in the data. In this article, we propose to combine multiple label-specific feature spaces, using label correlation, for multi-label learning. The proposed algorithm, multi-label-specific feature space ensemble (MULFE), takes consideration label-specific features, label correlation, and weighted ensemble principle to form a learning framework. By conducting clustering analysis on each label’s negative and positive instances, MULFE first creates features customized to each label. After that, MULFE utilizes the label correlation to optimize the margin distribution of the base classifiers which are induced by the related label-specific feature spaces. By combining multiple label-specific features, label correlation based weighting, and ensemble learning, MULFE achieves maximum margin multi-label classification goal through the underlying optimization framework. Empirical studies on 10 public data sets manifest the effectiveness of MULFE.}
}


@article{DBLP:journals/tkdd/LinH22,
	author = {Fandel Lin and
                  Hsun{-}Ping Hsieh},
	title = {A Joint Passenger Flow Inference and Path Recommender System for Deploying
                  New Routes and Stations of Mass Transit Transportation},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {1},
	pages = {6:1--6:36},
	year = {2022},
	url = {https://doi.org/10.1145/3451393},
	doi = {10.1145/3451393},
	timestamp = {Thu, 23 Jun 2022 20:05:38 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/LinH22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this work, a novel decision assistant system for urban transportation, called Route Scheme Assistant (RSA), is proposed to address two crucial issues that few former researches have focused on: route-based passenger flow (PF) inference and multivariant high-PF route recommendation. First, RSA can estimate the PF of arbitrary user-designated routes effectively by utilizing Deep Neural Network (DNN) for regression based on geographical information and spatial-temporal urban informatics. Second, our proposed Bidirectional Prioritized Spanning Tree (BDPST) intelligently combines the parallel computing concept and Gaussian mixture model (GMM) for route recommendation under users’ constraints running in a timely manner. We did experiments on bus-ticket data of Tainan and Chicago and the experimental results show that the PF inference model outperforms baseline and comparative methods from 41% to 57%. Moreover, the proposed BDPST algorithm's performance is not far away from the optimal PF and outperforms other comparative methods from 39% to 71% in large-scale route recommendations.}
}


@article{DBLP:journals/tkdd/LiuJWXYN22,
	author = {Huafeng Liu and
                  Liping Jing and
                  Jingxuan Wen and
                  Pengyu Xu and
                  Jian Yu and
                  Michael K. Ng},
	title = {Bayesian Additive Matrix Approximation for Social Recommendation},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {1},
	pages = {7:1--7:34},
	year = {2022},
	url = {https://doi.org/10.1145/3451391},
	doi = {10.1145/3451391},
	timestamp = {Thu, 07 Nov 2024 15:00:13 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/LiuJWXYN22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Social relations between users have been proven to be a good type of auxiliary information to improve the recommendation performance. However, it is a challenging issue to sufficiently exploit the social relations and correctly determine the user preference from both social and rating information. In this article, we propose a unified Bayesian Additive Matrix Approximation model (BAMA), which takes advantage of rating preference and social network to provide high-quality recommendation. The basic idea of BAMA is to extract social influence from social networks, integrate them to Bayesian additive co-clustering for effectively determining the user clusters and item clusters, and provide an accurate rating prediction. In addition, an efficient algorithm with collapsed Gibbs Sampling is designed to inference the proposed model. A series of experiments were conducted on six real-world social datasets. The results demonstrate the superiority of the proposed BAMA by comparing with the state-of-the-art methods from three views, all users, cold-start users, and users with few social relations. With the aid of social information, furthermore, BAMA has ability to provide the explainable recommendation.}
}


@article{DBLP:journals/tkdd/GuoCG22,
	author = {Jinjin Guo and
                  Longbing Cao and
                  Zhiguo Gong},
	title = {Recurrent Coupled Topic Modeling over Sequential Documents},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {1},
	pages = {8:1--8:32},
	year = {2022},
	url = {https://doi.org/10.1145/3451530},
	doi = {10.1145/3451530},
	timestamp = {Mon, 03 Jan 2022 22:12:26 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/GuoCG22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The abundant sequential documents such as online archival, social media, and news feeds are streamingly updated, where each chunk of documents is incorporated with smoothly evolving yet dependent topics. Such digital texts have attracted extensive research on dynamic topic modeling to infer hidden evolving topics and their temporal dependencies. However, most of the existing approaches focus on single-topic-thread evolution and ignore the fact that a current topic may be coupled with multiple relevant prior topics. In addition, these approaches also incur the intractable inference problem when inferring latent parameters, resulting in a high computational cost and performance degradation. In this work, we assume that a current topic evolves from all prior topics with corresponding coupling weights, forming the multi-topic-thread evolution. Our method models the dependencies between evolving topics and thoroughly encodes their complex multi-couplings across time steps. To conquer the intractable inference challenge, a new solution with a set of novel data augmentation techniques is proposed, which successfully discomposes the multi-couplings between evolving topics. A fully conjugate model is thus obtained to guarantee the effectiveness and efficiency of the inference technique. A novel Gibbs sampler with a backward–forward filter algorithm efficiently learns latent time-evolving parameters in a closed-form. In addition, the latent Indian Buffet Process compound distribution is exploited to automatically infer the overall topic number and customize the sparse topic proportions for each sequential document without bias. The proposed method is evaluated on both synthetic and real-world datasets against the competitive baselines, demonstrating its superiority over the baselines in terms of the low per-word perplexity, high coherent topics, and better document time prediction.}
}


@article{DBLP:journals/tkdd/GuoL22,
	author = {Yunyan Guo and
                  Jianzhong Li},
	title = {Distributed Latent Dirichlet Allocation on Streams},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {1},
	pages = {9:1--9:20},
	year = {2022},
	url = {https://doi.org/10.1145/3451528},
	doi = {10.1145/3451528},
	timestamp = {Thu, 04 Aug 2022 19:55:16 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/GuoL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Latent Dirichlet Allocation (LDA) has been widely used for topic modeling, with applications spanning various areas such as natural language processing and information retrieval. While LDA on small and static datasets has been extensively studied, several real-world challenges are posed in practical scenarios where datasets are often huge and are gathered in a streaming fashion. As the state-of-the-art LDA algorithm on streams, Streaming Variational Bayes (SVB) introduced Bayesian updating to provide a streaming procedure. However, the utility of SVB is limited in applications since it ignored three challenges of processing real-world streams: topic evolution, data turbulence, and real-time inference. In this article, we propose a novel distributed LDA algorithm—referred to as StreamFed-LDA—to deal with challenges on streams. For topic modeling of streaming data, the ability to capture evolving topics is essential for practical online inference. To achieve this goal, StreamFed-LDA is based on a specialized framework that supports lifelong (continual) learning of evolving topics. On the other hand, data turbulence is commonly present in streams due to real-life events. In that case, the design of StreamFed-LDA allows the model to learn new characteristics from the most recent data while maintaining the historical information. On massive streaming data, it is difficult and crucial to provide real-time inference results. To increase the throughput and reduce the latency, StreamFed-LDA introduces additional techniques that substantially reduce both computation and communication costs in distributed systems. Experiments on four real-world datasets show that the proposed framework achieves significantly better performance of online inference compared with the baselines. At the same time, StreamFed-LDA also reduces the latency by orders of magnitudes in real-world datasets.}
}


@article{DBLP:journals/tkdd/HanL22,
	author = {Juhee Han and
                  Younghoon Lee},
	title = {Explainable Artificial Intelligence-Based Competitive Factor Identification},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {1},
	pages = {10:1--10:11},
	year = {2022},
	url = {https://doi.org/10.1145/3451529},
	doi = {10.1145/3451529},
	timestamp = {Mon, 20 Sep 2021 09:50:43 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/HanL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Competitor analysis is an essential component of corporate strategy, providing both offensive and defensive strategic contexts to identify opportunities and threats. The rapid development of social media has recently led to several methodologies and frameworks facilitating competitor analysis through online reviews. Existing studies only focused on detecting comparative sentences in review comments or utilized low-performance models. However, this study proposes a novel approach to identifying the competitive factors using a recent explainable artificial intelligence approach at the comprehensive product feature level. We establish a model to classify the review comments for each corresponding product and evaluate the relevance of each keyword in such comments during the classification process. We then extract and prioritize the keywords and determine their competitiveness based on relevance. Our experiment results show that the proposed method can effectively extract the competitive factors both qualitatively and quantitatively.}
}


@article{DBLP:journals/tkdd/LaishramWS22,
	author = {Ricky Laishram and
                  Jeremy D. Wendt and
                  Sucheta Soundarajan},
	title = {{MCS+:} An Efficient Algorithm for Crawling the Community Structure
                  in Multiplex Networks},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {1},
	pages = {11:1--11:32},
	year = {2022},
	url = {https://doi.org/10.1145/3451527},
	doi = {10.1145/3451527},
	timestamp = {Fri, 17 Sep 2021 14:46:37 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/LaishramWS22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this article, we consider the problem of crawling a multiplex network to identify the community structure of a layer-of-interest. A multiplex network is one where there are multiple types of relationships between the nodes. In many multiplex networks, some layers might be easier to explore (in terms of time, money etc.). We propose MCS+, an algorithm that can use the information from the easier to explore layers to help in the exploration of a layer-of-interest that is expensive to explore. We consider the goal of exploration to be generating a sample that is representative of the communities in the complete layer-of-interest. This work has practical applications in areas such as exploration of dark (e.g., criminal) networks, online social networks, biological networks, and so on. For example, in a terrorist network, relationships such as phone records, e-mail records, and so on are easier to collect; in contrast, data on the face-to-face communications are much harder to collect, but also potentially more valuable. We perform extensive experimental evaluations on real-world networks, and we observe that MCS+ consistently outperforms the best baseline—the similarity of the sample that MCS+ generates to the real network is up to three times that of the best baseline in some networks. We also perform theoretical and experimental evaluations on the scalability of MCS+ to network properties, and find that it scales well with the budget, number of layers in the multiplex network, and the average degree in the original network.}
}


@article{DBLP:journals/tkdd/WangDF22,
	author = {Lichen Wang and
                  Zhengming Ding and
                  Yun Fu},
	title = {Generic Multi-label Annotation via Adaptive Graph and Marginalized
                  Augmentation},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {1},
	pages = {12:1--12:20},
	year = {2022},
	url = {https://doi.org/10.1145/3451884},
	doi = {10.1145/3451884},
	timestamp = {Fri, 17 Sep 2021 14:46:31 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/WangDF22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Multi-label learning recovers multiple labels from a single instance. It is a more challenging task compared with single-label manner. Most multi-label learning approaches need large-scale well-labeled samples to achieve high accurate performance. However, it is expensive to build such a dataset. In this work, we propose a generic multi-label learning framework based on Adaptive Graph and Marginalized Augmentation (AGMA) in a semi-supervised scenario. Generally speaking, AGMA makes use of a small amount of labeled data associated with a lot of unlabeled data to boost the learning performance. First, an adaptive similarity graph is learned to effectively capture the intrinsic structure within the data. Second, marginalized augmentation strategy is explored to enhance the model generalization and robustness. Third, a feature-label autoencoder is further deployed to improve inferring efficiency. All the modules are jointly trained to benefit each other. State-of-the-art benchmarks in both traditional and zero-shot multi-label learning scenarios are evaluated. Experiments and ablation studies illustrate the accuracy and efficiency of our AGMA method.}
}


@article{DBLP:journals/tkdd/MoreoES22,
	author = {Alejandro Moreo and
                  Andrea Esuli and
                  Fabrizio Sebastiani},
	title = {Lost in Transduction: Transductive Transfer Learning in Text Classification},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {1},
	pages = {13:1--13:21},
	year = {2022},
	url = {https://doi.org/10.1145/3453146},
	doi = {10.1145/3453146},
	timestamp = {Sun, 04 Aug 2024 19:52:23 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/MoreoES22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Obtaining high-quality labelled data for training a classifier in a new application domain is often costly. Transfer Learning (a.k.a. “Inductive Transfer”) tries to alleviate these costs by transferring, to the “target” domain of interest, knowledge available from a different “source” domain. In transfer learning the lack of labelled information from the target domain is compensated by the availability at training time of a set of unlabelled examples from the target distribution. Transductive Transfer Learning denotes the transfer learning setting in which the only set of target documents that we are interested in classifying is known and available at training time. Although this definition is indeed in line with Vapnik’s original definition of “transduction”, current terminology in the field is confused. In this article, we discuss how the term “transduction” has been misused in the transfer learning literature, and propose a clarification consistent with the original characterization of this term given by Vapnik. We go on to observe that the above terminology misuse has brought about misleading experimental comparisons, with inductive transfer learning methods that have been incorrectly compared with transductive transfer learning methods. We then, give empirical evidence that the difference in performance between the inductive version and the transductive version of a transfer learning method can indeed be statistically significant (i.e., that knowing at training time the only data one needs to classify indeed gives an advantage). Our clarification allows a reassessment of the field, and of the relative merits of the major, state-of-the-art algorithms for transfer learning in text classification.}
}


@article{DBLP:journals/tkdd/LiLCZZL22,
	author = {Yangfan Li and
                  Kenli Li and
                  Cen Chen and
                  Xu Zhou and
                  Zeng Zeng and
                  Keqin Li},
	title = {Modeling Temporal Patterns with Dilated Convolutions for Time-Series
                  Forecasting},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {1},
	pages = {14:1--14:22},
	year = {2022},
	url = {https://doi.org/10.1145/3453724},
	doi = {10.1145/3453724},
	timestamp = {Fri, 17 Sep 2021 14:46:31 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/LiLCZZL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Time-series forecasting is an important problem across a wide range of domains. Designing accurate and prompt forecasting algorithms is a non-trivial task, as temporal data that arise in real applications often involve both non-linear dynamics and linear dependencies, and always have some mixtures of sequential and periodic patterns, such as daily, weekly repetitions, and so on. At this point, however, most recent deep models often use Recurrent Neural Networks (RNNs) to capture these temporal patterns, which is hard to parallelize and not fast enough for real-world applications especially when a huge amount of user requests are coming. Recently, CNNs have demonstrated significant advantages for sequence modeling tasks over the de-facto RNNs, while providing high computational efficiency due to the inherent parallelism. In this work, we propose HyDCNN, a novel hybrid framework based on fully Dilated CNN for time-series forecasting tasks. The core component in HyDCNN is a proposed hybrid module, in which our proposed position-aware dilated CNNs are utilized to capture the sequential non-linear dynamics and an autoregressive model is leveraged to capture the sequential linear dependencies. To further capture the periodic temporal patterns, a novel hop scheme is introduced in the hybrid module. HyDCNN is then composed of multiple hybrid modules to capture the sequential and periodic patterns. Each of these hybrid modules targets on either the sequential pattern or one kind of periodic patterns. Extensive experiments on five real-world datasets have shown that the proposed HyDCNN is better compared with state-of-the-art baselines and is at least 200% better than RNN baselines. The datasets and source code will be published in Github to facilitate more future work.}
}


@article{DBLP:journals/tkdd/YangGLBCZ22,
	author = {Keyu Yang and
                  Yunjun Gao and
                  Lei Liang and
                  Song Bian and
                  Lu Chen and
                  Baihua Zheng},
	title = {CrowdTC: Crowd-powered Learning for Text Classification},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {1},
	pages = {15:1--15:23},
	year = {2022},
	url = {https://doi.org/10.1145/3457216},
	doi = {10.1145/3457216},
	timestamp = {Sat, 30 Sep 2023 10:29:07 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/YangGLBCZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Text classification is a fundamental task in content analysis. Nowadays, deep learning has demonstrated promising performance in text classification compared with shallow models. However, almost all the existing models do not take advantage of the wisdom of human beings to help text classification. Human beings are more intelligent and capable than machine learning models in terms of understanding and capturing the implicit semantic information from text. In this article, we try to take guidance from human beings to classify text. We propose Crowd-powered learning for Text Classification (CrowdTC for short). We design and post the questions on a crowdsourcing platform to extract keywords in text. Sampling and clustering techniques are utilized to reduce the cost of crowdsourcing. Also, we present an attention-based neural network and a hybrid neural network to incorporate the extracted keywords as human guidance into deep neural networks. Extensive experiments on public datasets confirm that CrowdTC improves the text classification accuracy of neural networks by using the crowd-powered keyword guidance.}
}


@article{DBLP:journals/tkdd/LiuZZXYT22,
	author = {Haobing Liu and
                  Yanmin Zhu and
                  Tianzi Zang and
                  Yanan Xu and
                  Jiadi Yu and
                  Feilong Tang},
	title = {Jointly Modeling Heterogeneous Student Behaviors and Interactions
                  among Multiple Prediction Tasks},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {1},
	pages = {16:1--16:24},
	year = {2022},
	url = {https://doi.org/10.1145/3458023},
	doi = {10.1145/3458023},
	timestamp = {Wed, 07 Aug 2024 09:20:37 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/LiuZZXYT22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Prediction tasks about students have practical significance for both student and college. Making multiple predictions about students is an important part of a smart campus. For instance, predicting whether a student will fail to graduate can alert the student affairs office to take predictive measures to help the student improve his/her academic performance. With the development of information technology in colleges, we can collect digital footprints that encode heterogeneous behaviors continuously. In this article, we focus on modeling heterogeneous behaviors and making multiple predictions together, since some prediction tasks are related and learning the model for a specific task may have the data sparsity problem. To this end, we propose a variant of Long-Short Term Memory (LSTM) and a soft-attention mechanism. The proposed LSTM is able to learn the student profile-aware representation from heterogeneous behavior sequences. The proposed soft-attention mechanism can dynamically learn different importance degrees of different days for every student. In this way, heterogeneous behaviors can be well modeled. In order to model interactions among multiple prediction tasks, we propose a co-attention mechanism based unit. With the help of the stacked units, we can explicitly control the knowledge transfer among multiple tasks. We design three motivating behavior prediction tasks based on a real-world dataset collected from a college. Qualitative and quantitative experiments on the three prediction tasks have demonstrated the effectiveness of our model.}
}


@article{DBLP:journals/tkdd/LeeSSCZWC22,
	author = {Wu Lee and
                  Yuliang Shi and
                  Hongfeng Sun and
                  Lin Cheng and
                  Kun Zhang and
                  Xinjun Wang and
                  Zhiyong Chen},
	title = {{MSIPA:} Multi-Scale Interval Pattern-Aware Network for {ICU} Transfer
                  Prediction},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {1},
	pages = {17:1--17:17},
	year = {2022},
	url = {https://doi.org/10.1145/3458284},
	doi = {10.1145/3458284},
	timestamp = {Fri, 01 Apr 2022 11:24:51 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/LeeSSCZWC22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Accurate prediction of patients’ ICU transfer events is of great significance for improving ICU treatment efficiency. ICU transition prediction task based on Electronic Health Records (EHR) is a temporal mining task like many other health informatics mining tasks. In the EHR-based temporal mining task, existing approaches are usually unable to mine and exploit patterns used to improve model performance. This article proposes a network based on Interval Pattern-Aware, Multi-Scale Interval Pattern-Aware (MSIPA) network. MSIPA mines different interval patterns in temporal EHR data according to the short, medium, and long intervals. MSIPA utilizes the Scaled Dot-Product Attention mechanism to query the contexts corresponding to the three scale patterns. Furthermore, Transformer will use all three types of contextual information simultaneously for ICU transfer prediction. Extensive experiments on real-world data demonstrate that an MSIPA network outperforms state-of-the-art methods.}
}


@article{DBLP:journals/tkdd/ZhangFW22,
	author = {Min{-}Ling Zhang and
                  Jun{-}Peng Fang and
                  Yi{-}Bo Wang},
	title = {BiLabel-Specific Features for Multi-Label Classification},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {1},
	pages = {18:1--18:23},
	year = {2022},
	url = {https://doi.org/10.1145/3458283},
	doi = {10.1145/3458283},
	timestamp = {Mon, 20 Sep 2021 09:50:43 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/ZhangFW22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In multi-label classification, the task is to induce predictive models which can assign a set of relevant labels for the unseen instance. The strategy of label-specific features has been widely employed in learning from multi-label examples, where the classification model for predicting the relevancy of each class label is induced based on its tailored features rather than the original features. Existing approaches work by generating a group of tailored features for each class label independently, where label correlations are not fully considered in the label-specific features generation process. In this article, we extend existing strategy by proposing a simple yet effective approach based on BiLabel-specific features. Specifically, a group of tailored features is generated for a pair of class labels with heuristic prototype selection and embedding. Thereafter, predictions of classifiers induced by BiLabel-specific features are ensembled to determine the relevancy of each class label for unseen instance. To thoroughly evaluate the BiLabel-specific features strategy, extensive experiments are conducted over a total of 35 benchmark datasets. Comparative studies against state-of-the-art label-specific features techniques clearly validate the superiority of utilizing BiLabel-specific features to yield stronger generalization performance for multi-label classification.}
}


@article{DBLP:journals/tkdd/LiuZX22,
	author = {Bo Liu and
                  Haowen Zhong and
                  Yanshan Xiao},
	title = {New Multi-View Classification Method with Uncertain Data},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {1},
	pages = {19:1--19:23},
	year = {2022},
	url = {https://doi.org/10.1145/3458282},
	doi = {10.1145/3458282},
	timestamp = {Mon, 27 Sep 2021 08:24:46 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/LiuZX22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Multi-view classification aims at designing a multi-view learning strategy to train a classifier from multi-view data, which are easily collected in practice. Most of the existing works focus on multi-view classification by assuming the multi-view data are collected with precise information. However, we always collect the uncertain multi-view data due to the collection process is corrupted with noise in real-life application. In this case, this article proposes a novel approach, called uncertain multi-view learning with support vector machine (UMV-SVM) to cope with the problem of multi-view learning with uncertain data. The method first enforces the agreement among all the views to seek complementary information of multi-view data and takes the uncertainty of the multi-view data into consideration by modeling reachability area of the noise. Then it proposes an iterative framework to solve the proposed UMV-SVM model such that we can obtain the multi-view classifier for prediction. Extensive experiments on real-life datasets have shown that the proposed UMV-SVM can achieve a better performance for uncertain multi-view classification in comparison to the state-of-the-art multi-view classification methods.}
}


@article{DBLP:journals/tkdd/NaC22,
	author = {Gyoung S. Na and
                  Hyunju Chang},
	title = {Unsupervised Subspace Extraction via Deep Kernelized Clustering},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {1},
	pages = {20:1--20:15},
	year = {2022},
	url = {https://doi.org/10.1145/3459082},
	doi = {10.1145/3459082},
	timestamp = {Mon, 20 Sep 2021 09:50:43 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/NaC22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Feature extraction has been widely studied to find informative latent features and reduce the dimensionality of data. In particular, due to the difficulty in obtaining labeled data, unsupervised feature extraction has received much attention in data mining. However, widely used unsupervised feature extraction methods require side information about data or rigid assumptions on the latent feature space. Furthermore, most feature extraction methods require predefined dimensionality of the latent feature space,which should be manually tuned as a hyperparameter. In this article, we propose a new unsupervised feature extraction method called Unsupervised Subspace Extractor (USE), which does not require any side information and rigid assumptions on data. Furthermore, USE can find a subspace generated by a nonlinear combination of the input feature and automatically determine the optimal dimensionality of the subspace for the given nonlinear combination. The feature extraction process of USE is well justified mathematically, and we also empirically demonstrate the effectiveness of USE for several benchmark datasets.}
}


@article{DBLP:journals/tkdd/Aggarwal22,
	author = {Charu C. Aggarwal},
	title = {Communication from the Editor-in-Chief: State of the {ACM} Transactions
                  on Knowledge Discovery from Data},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {2},
	pages = {21e:1--21e:2},
	year = {2022},
	url = {https://doi.org/10.1145/3463950},
	doi = {10.1145/3463950},
	timestamp = {Fri, 17 Sep 2021 14:46:31 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/Aggarwal22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {No abstract available.}
}


@article{DBLP:journals/tkdd/ZhangDYGY22,
	author = {Chunkai Zhang and
                  Zilin Du and
                  Yuting Yang and
                  Wensheng Gan and
                  Philip S. Yu},
	title = {On-Shelf Utility Mining of Sequence Data},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {2},
	pages = {21:1--21:31},
	year = {2022},
	url = {https://doi.org/10.1145/3457570},
	doi = {10.1145/3457570},
	timestamp = {Mon, 18 Jul 2022 13:55:22 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/ZhangDYGY22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Utility mining has emerged as an important and interesting topic owing to its wide application and considerable popularity. However, conventional utility mining methods have a bias toward items that have longer on-shelf time as they have a greater chance to generate a high utility. To eliminate the bias, the problem of on-shelf utility mining (OSUM) is introduced. In this article, we focus on the task of OSUM of sequence data, where the sequential database is divided into several partitions according to time periods and items are associated with utilities and several on-shelf time periods. To address the problem, we propose two methods, OSUM of sequence data (OSUMS) and OSUMS+, to extract on-shelf high-utility sequential patterns. For further efficiency, we also design several strategies to reduce the search space and avoid redundant calculation with two upper bounds time prefix extension utility (TPEU) and time reduced sequence utility (TRSU). In addition, two novel data structures are developed for facilitating the calculation of upper bounds and utilities. Substantial experimental results on certain real and synthetic datasets show that the two methods outperform the state-of-the-art algorithm. In conclusion, OSUMS may consume a large amount of memory and is unsuitable for cases with limited memory, while OSUMS+ has wider real-life applications owing to its high efficiency.}
}


@article{DBLP:journals/tkdd/TranSS22,
	author = {Cong Tran and
                  Won{-}Yong Shin and
                  Andreas Spitz},
	title = {Community Detection in Partially Observable Social Networks},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {2},
	pages = {22:1--22:24},
	year = {2022},
	url = {https://doi.org/10.1145/3461339},
	doi = {10.1145/3461339},
	timestamp = {Mon, 20 Sep 2021 09:50:43 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/TranSS22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The discovery of community structures in social networks has gained significant attention since it is a fundamental problem in understanding the networks’ topology and functions. However, most social network data are collected from partially observable networks with both missing nodes and edges. In this article, we address a new problem of detecting overlapping community structures in the context of such an incomplete network, where communities in the network are allowed to overlap since nodes belong to multiple communities at once. To solve this problem, we introduce KroMFac, a new framework that conducts community detection via regularized nonnegative matrix factorization (NMF) based on the Kronecker graph model. Specifically, from an inferred Kronecker generative parameter matrix, we first estimate the missing part of the network. As our major contribution to the proposed framework, to improve community detection accuracy, we then characterize and select influential nodes (which tend to have high degrees) by ranking, and add them to the existing graph. Finally, we uncover the community structures by solving the regularized NMF-aided optimization problem in terms of maximizing the likelihood of the underlying graph. Furthermore, adopting normalized mutual information (NMI), we empirically show superiority of our KroMFac approach over two baseline schemes by using both synthetic and real-world networks.}
}


@article{DBLP:journals/tkdd/LiSHWG22,
	author = {Zhao Li and
                  Junshuai Song and
                  Zehong Hu and
                  Zhen Wang and
                  Jun Gao},
	title = {Constrained Dual-Level Bandit for Personalized Impression Regulation
                  in Online Ranking Systems},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {2},
	pages = {23:1--23:23},
	year = {2022},
	url = {https://doi.org/10.1145/3461340},
	doi = {10.1145/3461340},
	timestamp = {Fri, 02 Sep 2022 08:42:25 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/LiSHWG22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Impression regulation plays an important role in various online ranking systems, e.g., e-commerce ranking systems always need to achieve local commercial demands on some pre-labeled target items like fresh item cultivation and fraudulent item counteracting while maximizing its global revenue. However, local impression regulation may cause “butterfly effects” on the global scale, e.g., in e-commerce, the price preference fluctuation in initial conditions (overpriced or underpriced items) may create a significantly different outcome, thus affecting shopping experience and bringing economic losses to platforms. To prevent “butterfly effects”, some researchers define their regulation objectives with global constraints, by using contextual bandit at the page-level that requires all items on one page sharing the same regulation action, which fails to conduct impression regulation on individual items. To address this problem, in this article, we propose a personalized impression regulation method that can directly makes regulation decisions for each user-item pair. Specifically, we model the regulation problem as a Constrained Dual-level Bandit (CDB) problem, where the local regulation action and reward signals are at the item-level while the global effect constraint on the platform impression can be calculated at the page-level only. To handle the asynchronous signals, we first expand the page-level constraint to the item-level and then derive the policy updating as a second-order cone optimization problem. Our CDB approaches the optimal policy by iteratively solving the optimization problem. Experiments are performed on both offline and online datasets, and the results, theoretically and empirically, demonstrate CDB outperforms state-of-the-art algorithms.}
}


@article{DBLP:journals/tkdd/OHareJC22,
	author = {Kevin O'Hare and
                  Anna Jurek{-}Loughrey and
                  Cassio P. de Campos},
	title = {High-Value Token-Blocking: Efficient Blocking Method for Record Linkage},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {2},
	pages = {24:1--24:17},
	year = {2022},
	url = {https://doi.org/10.1145/3450527},
	doi = {10.1145/3450527},
	timestamp = {Fri, 17 Sep 2021 14:46:31 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/OHareJC22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Data integration is an important component of Big Data analytics. One of the key challenges in data integration is record linkage, that is, matching records that represent the same real-world entity. Because of computational costs, methods referred to as blocking are employed as a part of the record linkage pipeline in order to reduce the number of comparisons among records. In the past decade, a range of blocking techniques have been proposed. Real-world applications require approaches that can handle heterogeneous data sources and do not rely on labelled data. We propose high-value token-blocking (HVTB), a simple and efficient approach for blocking that is unsupervised and schema-agnostic, based on a crafted use of Term Frequency-Inverse Document Frequency. We compare HVTB with multiple methods and over a range of datasets, including a novel unstructured dataset composed of titles and abstracts of scientific papers. We thoroughly discuss results in terms of accuracy, use of computational resources, and different characteristics of datasets and records. The simplicity of HVTB yields fast computations and does not harm its accuracy when compared with existing approaches. It is shown to be significantly superior to other methods, suggesting that simpler methods for blocking should be considered before resorting to more sophisticated methods.}
}


@article{DBLP:journals/tkdd/DingWW22,
	author = {Ming Ding and
                  Tianyu Wang and
                  Xudong Wang},
	title = {Establishing Smartphone User Behavior Model Based on Energy Consumption
                  Data},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {2},
	pages = {25:1--25:40},
	year = {2022},
	url = {https://doi.org/10.1145/3461459},
	doi = {10.1145/3461459},
	timestamp = {Tue, 21 Sep 2021 14:19:17 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/DingWW22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In smartphone data analysis, both energy consumption modeling and user behavior mining have been explored extensively, but the relationship between energy consumption and user behavior has been rarely studied. Such a relationship is explored over large-scale users in this article. Based on energy consumption data, where each users’ feature vector is represented by energy breakdown on hardware components of different apps, User Behavior Models (UBM) are established to capture user behavior patterns (i.e., app preference, usage time). The challenge lies in the high diversity of user behaviors (i.e., massive apps and usage ways), which leads to high dimension and dispersion of data. To overcome the challenge, three mechanisms are designed. First, to reduce the dimension, apps are ranked with the top ones identified as typical apps to represent all. Second, the dispersion is reduced by scaling each users’ feature vector with typical apps to unit ℓ1 norm. The scaled vector becomes Usage Pattern, while the ℓ1 norm of vector before scaling is treated as Usage Intensity. Third, the usage pattern is analyzed with a two-layer clustering approach to further reduce data dispersion. In the upper layer, each typical app is studied across its users with respect to hardware components to identify Typical Hardware Usage Patterns (THUP). In the lower layer, users are studied with respect to these THUPs to identify Typical App Usage Patterns (TAUP). The analytical results of these two layers are consolidated into Usage Pattern Models (UPM), and UBMs are finally established by a union of UPMs and Usage Intensity Distributions (UID). By carrying out experiments on energy consumption data from 18,308 distinct users over 10 days, 33 UBMs are extracted from training data. With the test data, it is proven that these UBMs cover 94% user behaviors and achieve up to 20% improvement in accuracy of energy representation, as compared with the baseline method, PCA. Besides, potential applications and implications of these UBMs are illustrated for smartphone manufacturers, app developers, network providers, and so on.}
}


@article{DBLP:journals/tkdd/SaudeRBC22,
	author = {Jo{\~{a}}o Sa{\'{u}}de and
                  Guilherme Ramos and
                  Ludovico Boratto and
                  Carlos Caleiro},
	title = {A Robust Reputation-Based Group Ranking System and Its Resistance
                  to Bribery},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {2},
	pages = {26:1--26:35},
	year = {2022},
	url = {https://doi.org/10.1145/3462210},
	doi = {10.1145/3462210},
	timestamp = {Tue, 07 May 2024 20:19:56 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/SaudeRBC22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The spread of online reviews and opinions and its growing influence on people’s behavior and decisions boosted the interest to extract meaningful information from this data deluge. Hence, crowdsourced ratings of products and services gained a critical role in business and governments. Current state-of-the-art solutions rank the items with an average of the ratings expressed for an item, with a consequent lack of personalization for the users, and the exposure to attacks and spamming/spurious users. Using these ratings to group users with similar preferences might be useful to present users with items that reflect their preferences and overcome those vulnerabilities. In this article, we propose a new reputation-based ranking system, utilizing multipartite rating subnetworks, which clusters users by their similarities using three measures, two of them based on Kolmogorov complexity. We also study its resistance to bribery and how to design optimal bribing strategies. Our system is novel in that it reflects the diversity of preferences by (possibly) assigning distinct rankings to the same item, for different groups of users. We prove the convergence and efficiency of the system. By testing it on synthetic and real data, we see that it copes better with spamming/spurious users, being more robust to attacks than state-of-the-art approaches. Also, by clustering users, the effect of bribery in the proposed multipartite ranking system is dimmed, comparing to the bipartite case.}
}


@article{DBLP:journals/tkdd/WuMWXJ22,
	author = {Hanlu Wu and
                  Tengfei Ma and
                  Lingfei Wu and
                  Fangli Xu and
                  Shouling Ji},
	title = {Exploiting Heterogeneous Graph Neural Networks with Latent Worker/Task
                  Correlation Information for Label Aggregation in Crowdsourcing},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {2},
	pages = {27:1--27:18},
	year = {2022},
	url = {https://doi.org/10.1145/3460865},
	doi = {10.1145/3460865},
	timestamp = {Fri, 07 Jun 2024 23:10:40 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/WuMWXJ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Crowdsourcing has attracted much attention for its convenience to collect labels from non-expert workers instead of experts. However, due to the high level of noise from the non-experts, a label aggregation model that infers the true label from noisy crowdsourced labels is required. In this article, we propose a novel framework based on graph neural networks for aggregating crowd labels. We construct a heterogeneous graph between workers and tasks and derive a new graph neural network to learn the representations of nodes and the true labels. Besides, we exploit the unknown latent interaction between the same type of nodes (workers or tasks) by adding a homogeneous attention layer in the graph neural networks. Experimental results on 13 real-world datasets show superior performance over state-of-the-art models.}
}


@article{DBLP:journals/tkdd/LiWBCS22,
	author = {Hui{-}Jia Li and
                  Lin Wang and
                  Zhan Bu and
                  Jie Cao and
                  Yong Shi},
	title = {Measuring the Network Vulnerability Based on Markov Criticality},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {2},
	pages = {28:1--28:24},
	year = {2022},
	url = {https://doi.org/10.1145/3464390},
	doi = {10.1145/3464390},
	timestamp = {Sun, 02 Oct 2022 15:51:30 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/LiWBCS22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Vulnerability assessment—a critical issue for networks—attempts to foresee unexpected destructive events or hostile attacks in the whole system. In this article, we consider a new Markov global connectivity metric—Kemeny constant, and take its derivative called Markov criticality to identify critical links. Markov criticality allows us to find links that are most influential on the derivative of Kemeny constant. Thus, we can utilize it to identity a critical link (i, j) from node i to node j, such that removing it leads to a minimization of networks’ global connectivity, i.e., the Kemeny constant. Furthermore, we also define a novel vulnerability index to measure the average speed by which we can disconnect a specified ratio of links with network decomposition. Our method is of high efficiency, which can be easily employed to calculate the Markov criticality in real-life networks. Comprehensive experiments on several synthetic and real-life networks have demonstrated our method’s better performance by comparing it with state-of-the-art baseline approaches.}
}


@article{DBLP:journals/tkdd/WangCZHY22,
	author = {Guangtao Wang and
                  Gao Cong and
                  Ying Zhang and
                  Zhen Hai and
                  Jieping Ye},
	title = {A Synopsis Based Approach for Itemset Frequency Estimation over Massive
                  Multi-Transaction Stream},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {2},
	pages = {29:1--29:30},
	year = {2022},
	url = {https://doi.org/10.1145/3465238},
	doi = {10.1145/3465238},
	timestamp = {Wed, 05 Jan 2022 16:54:22 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/WangCZHY22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The streams where multiple transactions are associated with the same key are prevalent in practice, e.g., a customer has multiple shopping records arriving at different time. Itemset frequency estimation on such streams is very challenging since sampling based methods, such as the popularly used reservoir sampling, cannot be used. In this article, we propose a novel k-Minimum Value (KMV) synopsis based method to estimate the frequency of itemsets over multi-transaction streams. First, we extract the KMV synopses for each item from the stream. Then, we propose a novel estimator to estimate the frequency of an itemset over the KMV synopses. Comparing to the existing estimator, our method is not only more accurate and efficient to calculate but also follows the downward-closure property. These properties enable the incorporation of our new estimator with existing frequent itemset mining (FIM) algorithm (e.g., FP-Growth) to mine frequent itemsets over multi-transaction streams. To demonstrate this, we implement a KMV synopsis based FIM algorithm by integrating our estimator into existing FIM algorithms, and we prove it is capable of guaranteeing the accuracy of FIM with a bounded size of KMV synopsis. Experimental results on massive streams show our estimator can significantly improve on the accuracy for both estimating itemset frequency and FIM compared to the existing estimators.}
}


@article{DBLP:journals/tkdd/YinWGBJLH22,
	author = {Jianfei Yin and
                  Ruili Wang and
                  Yeqing Guo and
                  Yizhe Bai and
                  Shunda Ju and
                  Weili Liu and
                  Joshua Zhexue Huang},
	title = {Wealth Flow Model: Online Portfolio Selection Based on Learning Wealth
                  Flow Matrices},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {2},
	pages = {30:1--30:27},
	year = {2022},
	url = {https://doi.org/10.1145/3464308},
	doi = {10.1145/3464308},
	timestamp = {Wed, 16 Mar 2022 23:54:46 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/YinWGBJLH22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This article proposes a deep learning solution to the online portfolio selection problem based on learning a latent structure directly from a price time series. It introduces a novel wealth flow matrix for representing a latent structure that has special regular conditions to encode the knowledge about the relative strengths of assets in portfolios. Therefore, a wealth flow model (WFM) is proposed to learn wealth flow matrices and maximize portfolio wealth simultaneously. Compared with existing approaches, our work has several distinctive benefits: (1) the learning of wealth flow matrices makes our model more generalizable than models that only predict wealth proportion vectors, and (2) the exploitation of wealth flow matrices and the exploration of wealth growth are integrated into our deep reinforcement algorithm for the WFM. These benefits, in combination, lead to a highly-effective approach for generating reasonable investment behavior, including short-term trend following, the following of a few losers, no self-investment, and sparse portfolios. Extensive experiments on five benchmark datasets from real-world stock markets confirm the theoretical advantage of the WFM, which achieves the Pareto improvements in terms of multiple performance indicators and the steady growth of wealth over the state-of-the-art algorithms.}
}


@article{DBLP:journals/tkdd/HidalgoSB22,
	author = {Juan Isidro Gonz{\'{a}}lez Hidalgo and
                  Silas G. T. C. Santos and
                  Roberto S. M. Barros},
	title = {Dynamically Adjusting Diversity in Ensembles for the Classification
                  of Data Streams with Concept Drift},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {2},
	pages = {31:1--31:20},
	year = {2022},
	url = {https://doi.org/10.1145/3466616},
	doi = {10.1145/3466616},
	timestamp = {Fri, 17 Sep 2021 14:46:31 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/HidalgoSB22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A data stream can be defined as a system that continually generates a lot of data over time. Today, processing data streams requires new demands and challenging tasks in the data mining and machine learning areas. Concept Drift is a problem commonly characterized as changes in the distribution of the data within a data stream. The implementation of new methods for dealing with data streams where concept drifts occur requires algorithms that can adapt to several scenarios to improve its performance in the different experimental situations where they are tested. This research proposes a strategy for dynamic parameter adjustment in the presence of concept drifts. Parameter Estimation Procedure (PEP) is a general method proposed for dynamically adjusting parameters which is applied to the diversity parameter (λ) of several classification ensembles commonly used in the area. To this end, the proposed estimation method (PEP) was used to create Boosting-like Online Learning Ensemble with Parameter Estimation (BOLE-PE), Online AdaBoost-based M1 with Parameter Estimation (OABM1-PE), and Oza and Russell’s Online Bagging with Parameter Estimation (OzaBag-PE), based on the existing ensembles BOLE, OABM1, and OzaBag, respectively. To validate them, experiments were performed with artificial and real-world datasets using Hoeffding Tree (HT) as base classifier. The accuracy results were statistically evaluated using a variation of the Friedman test and the Nemenyi post-hoc test. The experimental results showed that the application of the dynamic estimation in the diversity parameter (λ) produced good results in most scenarios, i.e.,\xa0the modified methods have improved accuracy in the experiments with both artificial and real-world datasets.}
}


@article{DBLP:journals/tkdd/CantiniMBT22,
	author = {Riccardo Cantini and
                  Fabrizio Marozzo and
                  Giovanni Bruno and
                  Paolo Trunfio},
	title = {Learning Sentence-to-Hashtags Semantic Mapping for Hashtag Recommendation
                  on Microblogs},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {2},
	pages = {32:1--32:26},
	year = {2022},
	url = {https://doi.org/10.1145/3466876},
	doi = {10.1145/3466876},
	timestamp = {Mon, 26 Jun 2023 20:57:02 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/CantiniMBT22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The growing use of microblogging platforms is generating a huge amount of posts that need effective methods to be classified and searched. In Twitter and other social media platforms, hashtags are exploited by users to facilitate the search, categorization, and spread of posts. Choosing the appropriate hashtags for a post is not always easy for users, and therefore posts are often published without hashtags or with hashtags not well defined. To deal with this issue, we propose a new model, called HASHET (HAshtag recommendation using Sentence-to-Hashtag Embedding Translation), aimed at suggesting a relevant set of hashtags for a given post. HASHET is based on two independent latent spaces for embedding the text of a post and the hashtags it contains. A mapping process based on a multi-layer perceptron is then used for learning a translation from the semantic features of the text to the latent representation of its hashtags. We evaluated the effectiveness of two language representation models for sentence embedding and tested different search strategies for semantic expansion, finding out that the combined use of BERT (Bidirectional Encoder Representation from Transformer) and a global expansion strategy leads to the best recommendation results. HASHET has been evaluated on two real-world case studies related to the 2016 United States presidential election and COVID-19 pandemic. The results reveal the effectiveness of HASHET in predicting one or more correct hashtags, with an average F-score up to 0.82 and a recommendation hit-rate up to 0.92. Our approach has been compared to the most relevant techniques used in the literature (generative models, unsupervised models, and attention-based supervised models) by achieving up to 15% improvement in F-score for the hashtag recommendation task and 9% for the topic discovery task.}
}


@article{DBLP:journals/tkdd/AbebeCKLPST22,
	author = {Rediet Abebe and
                  T.{-}H. Hubert Chan and
                  Jon M. Kleinberg and
                  Zhibin Liang and
                  David C. Parkes and
                  Mauro Sozio and
                  Charalampos E. Tsourakakis},
	title = {Opinion Dynamics Optimization by Varying Susceptibility to Persuasion
                  via Non-Convex Local Search},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {2},
	pages = {33:1--33:34},
	year = {2022},
	url = {https://doi.org/10.1145/3466617},
	doi = {10.1145/3466617},
	timestamp = {Mon, 01 May 2023 13:01:58 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/AbebeCKLPST22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {A long line of work in social psychology has studied variations in people’s susceptibility to persuasion—the extent to which they are willing to modify their opinions on a topic. This body of literature suggests an interesting perspective on theoretical models of opinion formation by interacting parties in a network: in addition to considering interventions that directly modify people’s intrinsic opinions, it is also natural to consider interventions that modify people’s susceptibility to persuasion. In this work, motivated by this fact, we propose an influence optimization problem. Specifically, we adopt a popular model for social opinion dynamics, where each agent has some fixed innate opinion, and a resistance that measures the importance it places on its innate opinion; agents influence one another’s opinions through an iterative process. Under certain conditions, this iterative process converges to some equilibrium opinion vector. For the unbudgeted variant of the problem, the goal is to modify the resistance of any number of agents (within some given range) such that the sum of the equilibrium opinions is minimized; for the budgeted variant, in addition the algorithm is given upfront a restriction on the number of agents whose resistance may be modified. We prove that the objective function is in general non-convex. Hence, formulating the problem as a convex program as in an early version of this work (Abebe et\xa0al., KDD’18) might have potential correctness issues. We instead analyze the structure of the objective function, and show that any local optimum is also a global optimum, which is somehow surprising as the objective function might not be convex. Furthermore, we combine the iterative process and the local search paradigm to design very efficient algorithms that can solve the unbudgeted variant of the problem optimally on large-scale graphs containing millions of nodes. Finally, we propose and evaluate experimentally a family of heuristics for the budgeted variant of the problem.}
}


@article{DBLP:journals/tkdd/YangWSLZXY22,
	author = {Yang Yang and
                  Hongchen Wei and
                  Zhen{-}Qiang Sun and
                  Guangyu Li and
                  Yuanchun Zhou and
                  Hui Xiong and
                  Jian Yang},
	title = {{S2OSC:} {A} Holistic Semi-Supervised Approach for Open Set Classification},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {2},
	pages = {34:1--34:27},
	year = {2022},
	url = {https://doi.org/10.1145/3468675},
	doi = {10.1145/3468675},
	timestamp = {Fri, 17 Jun 2022 20:50:50 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/YangWSLZXY22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Open set classification (OSC) tackles the problem of determining whether the data are in-class or out-of-class during inference, when only provided with a set of in-class examples at training time. Traditional OSC methods usually train discriminative or generative models with the owned in-class data, and then utilize the pre-trained models to classify test data directly. However, these methods always suffer from the embedding confusion problem, i.e., partial out-of-class instances are mixed with in-class ones of similar semantics, making it difficult to classify. To solve this problem, we unify semi-supervised learning to develop a novel OSC algorithm, S2OSC, which incorporates out-of-class instances filtering and model re-training in a transductive manner. In detail, given a pool of newly coming test data, S2OSC firstly filters the mostly distinct out-of-class instances using the pre-trained model, and annotates super-class for them. Then, S2OSC trains a holistic classification model by combing in-class and out-of-class labeled data with the remaining unlabeled test data in a semi-supervised paradigm. Furthermore, considering that data are usually in the streaming form in real applications, we extend S2OSC into an incremental update framework (I-S2OSC), and adopt a knowledge memory regularization to mitigate the catastrophic forgetting problem in incremental update. Despite the simplicity of proposed models, the experimental results show that S2OSC achieves state-of-the-art performance across a variety of OSC tasks, including 85.4% of F1 on CIFAR-10 with only 300 pseudo-labels. We also demonstrate how S2OSC can be expanded to incremental OSC setting effectively with streaming data.}
}


@article{DBLP:journals/tkdd/ZhangWLS22,
	author = {Yiding Zhang and
                  Xiao Wang and
                  Nian Liu and
                  Chuan Shi},
	title = {Embedding Heterogeneous Information Network in Hyperbolic Spaces},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {2},
	pages = {35:1--35:23},
	year = {2022},
	url = {https://doi.org/10.1145/3468674},
	doi = {10.1145/3468674},
	timestamp = {Wed, 16 Mar 2022 23:54:45 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/ZhangWLS22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Heterogeneous information network (HIN) embedding, aiming to project HIN into a low-dimensional space, has attracted considerable research attention. Most of the existing HIN embedding methods focus on preserving the inherent network structure and semantic correlations in Euclidean spaces. However, one fundamental problem is whether the Euclidean spaces are the intrinsic spaces of HIN? Recent researches find the complex network with hyperbolic geometry can naturally reflect some properties, e.g., hierarchical and power-law structure. In this article, we make an effort toward embedding HIN in hyperbolic spaces. We analyze the structures of three HINs and discover some properties, e.g., the power-law distribution, also exist in HINs. Therefore, we propose a novel HIN embedding model HHNE. Specifically, to capture the structure and semantic relations between nodes, HHNE employs the meta-path guided random walk to sample the sequences for each node. Then HHNE exploits the hyperbolic distance as the proximity measurement. We also derive an effective optimization strategy to update the hyperbolic embeddings iteratively. Since HHNE optimizes different relations in a single space, we further propose the extended model HHNE++. HHNE++ models different relations in different spaces, which enables it to learn complex interactions in HINs. The optimization strategy of HHNE++ is also derived to update the parameters of HHNE++ in a principle manner. The experimental results demonstrate the effectiveness of our proposed models.}
}


@article{DBLP:journals/tkdd/WangZWQMD22,
	author = {Xueyuan Wang and
                  Hongpo Zhang and
                  Zongmin Wang and
                  Yaqiong Qiao and
                  Jiangtao Ma and
                  Honghua Dai},
	title = {Con{\&}Net: {A} Cross-Network Anchor Link Discovery Method Based
                  on Embedding Representation},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {2},
	pages = {36:1--36:18},
	year = {2022},
	url = {https://doi.org/10.1145/3469083},
	doi = {10.1145/3469083},
	timestamp = {Thu, 02 Feb 2023 15:37:35 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/WangZWQMD22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cross-network anchor link discovery is an important research problem and has many applications in heterogeneous social network. Existing schemes of cross-network anchor link discovery can provide reasonable link discovery results, but the quality of these results depends on the features of the platform. Therefore, there is no theoretical guarantee to the stability. This article employs user embedding feature to model the relationship between cross-platform accounts, that is, the more similar the user embedding features are, the more similar the two accounts are. The similarity of user embedding features is determined by the distance of the user features in the latent space. Based on the user embedding features, this article proposes an embedding representation-based method Con&Net(Content and Network) to solve cross-network anchor link discovery problem. Con&Net combines the user’s profile features, user-generated content (UGC) features, and user’s social structure features to measure the similarity of two user accounts. Con&Net first trains the user’s profile features to get profile embedding. Then it trains the network structure of the nodes to get structure embedding. It connects the two features through vector concatenating, and calculates the cosine similarity of the vector based on the embedding vector. This cosine similarity is used to measure the similarity of the user accounts. Finally, Con&Net predicts the link based on similarity for account pairs across the two networks. A large number of experiments in Sina Weibo and Twitter networks show that the proposed method Con&Net is better than state-of-the-art method. The area under the curve (AUC) value of the receiver operating characteristic (ROC) curve predicted by the anchor link is 11% higher than the baseline method, and Precision@30 is 25% higher than the baseline method.}
}


@article{DBLP:journals/tkdd/ZhangWC22,
	author = {Hangbin Zhang and
                  Raymond K. Wong and
                  Victor W. Chu},
	title = {Hybrid Variational Autoencoder for Recommender Systems},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {2},
	pages = {37:1--37:37},
	year = {2022},
	url = {https://doi.org/10.1145/3470659},
	doi = {10.1145/3470659},
	timestamp = {Wed, 16 Mar 2022 23:54:45 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/ZhangWC22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {E-commerce platforms heavily rely on automatic personalized recommender systems, e.g., collaborative filtering models, to improve customer experience. Some hybrid models have been proposed recently to address the deficiency of existing models. However, their performances drop significantly when the dataset is sparse. Most of the recent works failed to fully address this shortcoming. At most, some of them only tried to alleviate the problem by considering either user side or item side content information. In this article, we propose a novel recommender model called Hybrid Variational Autoencoder (HVAE) to improve the performance on sparse datasets. Different from the existing approaches, we encode both user and item information into a latent space for semantic relevance measurement. In parallel, we utilize collaborative filtering to find the implicit factors of users and items, and combine their outputs to deliver a hybrid solution. In addition, we compare the performance of Gaussian distribution and multinomial distribution in learning the representations of the textual data. Our experiment results show that HVAE is able to significantly outperform state-of-the-art models with robust performance.}
}


@article{DBLP:journals/tkdd/OliveiraMV22,
	author = {Lucas Santos de Oliveira and
                  Pedro Olmo Stancioli Vaz de Melo and
                  Aline Carneiro Viana},
	title = {Assessing Large-Scale Power Relations among Locations from Mobility
                  Data},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {2},
	pages = {38:1--38:31},
	year = {2022},
	url = {https://doi.org/10.1145/3470770},
	doi = {10.1145/3470770},
	timestamp = {Wed, 16 Mar 2022 23:54:45 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/OliveiraMV22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The pervasiveness of smartphones has shaped our lives, social norms, and the structure that dictates human behavior. They now directly influence how individuals demand resources or interact with network services. From this scenario, identifying key locations in cities is fundamental for the investigation of human mobility and also for the understanding of social problems. In this context, we propose the first graph-based methodology in the literature to quantify the power of Point-of-Interests (POIs) over its vicinity by means of user mobility trajectories. Different from literature, we consider the flow of people in our analysis, instead of the number of neighbor POIs or their structural locations in the city. Thus, we modeled POI’s visits using the multiflow graph model where each POI is a node and the transitions of users among POIs are a weighted direct edge. Using this multiflow graph model, we compute the attract, support, and independence powers. The attract power and support power measure how many visits a POI gathers from and disseminate over its neighborhood, respectively. Moreover, the independence power captures the capacity of a POI to receive visitors independently from other POIs. We tested our methodology on well-known university campus mobility datasets and validated on Location-Based Social Networks (LBSNs) datasets from various cities around the world. Our findings show that in university campus: (i) buildings have low support power and attract power; (ii) people tend to move over a few buildings and spend most of their time in the same building; and (iii) there is a slight dependence among buildings, even those with high independence power receive user visits from other buildings on campus. Globally, we reveal that (i) our metrics capture places that impact the number of visits in their neighborhood; (ii) cities in the same continent have similar independence patterns; and (iii) places with a high number of visitation and city central areas are the regions with the highest degree of independence.}
}


@article{DBLP:journals/tkdd/ZhangZYY22,
	author = {Zhenyu Zhang and
                  Lei Zhang and
                  Dingqi Yang and
                  Liu Yang},
	title = {{KRAN:} Knowledge Refining Attention Network for Recommendation},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {2},
	pages = {39:1--39:20},
	year = {2022},
	url = {https://doi.org/10.1145/3470783},
	doi = {10.1145/3470783},
	timestamp = {Wed, 16 Mar 2022 23:54:46 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/ZhangZYY22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recommender algorithms combining knowledge graph and graph convolutional network are becoming more and more popular recently. Specifically, attributes describing the items to be recommended are often used as additional information. These attributes along with items are highly interconnected, intrinsically forming a Knowledge Graph (KG). These algorithms use KGs as an auxiliary data source to alleviate the negative impact of data sparsity. However, these graph convolutional network based algorithms do not distinguish the importance of different neighbors of entities in the KG, and according to Pareto’s principle, the important neighbors only account for a small proportion. These traditional algorithms can not fully mine the useful information in the KG. To fully release the power of KGs for building recommender systems, we propose in this article KRAN, a Knowledge Refining Attention Network, which can subtly capture the characteristics of the KG and thus boost recommendation performance. We first introduce a traditional attention mechanism into the KG processing, making the knowledge extraction more targeted, and then propose a refining mechanism to improve the traditional attention mechanism to extract the knowledge in the KG more effectively. More precisely, KRAN is designed to use our proposed knowledge-refining attention mechanism to aggregate and obtain the representations of the entities (both attributes and items) in the KG. Our knowledge-refining attention mechanism first measures the relevance between an entity and it’s neighbors in the KG by attention coefficients, and then further refines the attention coefficients using a “richer-get-richer” principle, in order to focus on highly relevant neighbors while eliminating less relevant neighbors for noise reduction. In addition, for the item cold start problem, we propose KRAN-CD, a variant of KRAN, which further incorporates pre-trained KG embeddings to handle cold start items. Experiments show that KRAN and KRAN-CD consistently outperform state-of-the-art baselines across different settings.}
}


@article{DBLP:journals/tkdd/ZhaoGYCYLR22,
	author = {Liang Zhao and
                  Yuyang Gao and
                  Jieping Ye and
                  Feng Chen and
                  Yanfang Ye and
                  Chang{-}Tien Lu and
                  Naren Ramakrishnan},
	title = {Spatio-Temporal Event Forecasting Using Incremental Multi-Source Feature
                  Learning},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {2},
	pages = {40:1--40:28},
	year = {2022},
	url = {https://doi.org/10.1145/3464976},
	doi = {10.1145/3464976},
	timestamp = {Mon, 01 May 2023 13:01:58 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/ZhaoGYCYLR22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The forecasting of significant societal events such as civil unrest and economic crisis is an interesting and challenging problem which requires both timeliness, precision, and comprehensiveness. Significant societal events are influenced and indicated jointly by multiple aspects of a society, including its economics, politics, and culture. Traditional forecasting methods based on a single data source find it hard to cover all these aspects comprehensively, thus limiting model performance. Multi-source event forecasting has proven promising but still suffers from several challenges, including (1) geographical hierarchies in multi-source data features, (2) hierarchical missing values, (3) characterization of structured feature sparsity, and (4) difficulty in model’s online update with incomplete multiple sources. This article proposes a novel feature learning model that concurrently addresses all the above challenges. Specifically, given multi-source data from different geographical levels, we design a new forecasting model by characterizing the lower-level features’ dependence on higher-level features. To handle the correlations amidst structured feature sets and deal with missing values among the coupled features, we propose a novel feature learning model based on an \\(N\\)th-order strong hierarchy and fused-overlapping group Lasso. An efficient algorithm is developed to optimize model parameters and ensure global optima. More importantly, to enable the model update in real time, the online learning algorithm is formulated and active set techniques are leveraged to resolve the crucial challenge when new patterns of missing features appear in real time. Extensive experiments on 10 datasets in different domains demonstrate the effectiveness and efficiency of the proposed models.}
}


@article{DBLP:journals/tkdd/LeiZZBL22,
	author = {Shuo Lei and
                  Xuchao Zhang and
                  Liang Zhao and
                  Arnold P. Boedihardjo and
                  Chang{-}Tien Lu},
	title = {Online and Distributed Robust Regressions with Extremely Noisy Labels},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {3},
	pages = {41:1--41:24},
	year = {2022},
	url = {https://doi.org/10.1145/3473038},
	doi = {10.1145/3473038},
	timestamp = {Sun, 02 Oct 2022 15:51:30 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/LeiZZBL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In today’s era of big data, robust least-squares regression becomes a more challenging problem when considering the extremely corrupted labels along with explosive growth of datasets. Traditional robust methods can handle the noise but suffer from several challenges when applied in huge dataset including (1) computational infeasibility of handling an entire dataset at once, (2) existence of heterogeneously distributed corruption, and (3) difficulty in corruption estimation when data cannot be entirely loaded. This article proposes online and distributed robust regression approaches, both of which can concurrently address all the above challenges. Specifically, the distributed algorithm optimizes the regression coefficients of each data block via heuristic hard thresholding and combines all the estimates in a distributed robust consolidation. In addition, an online version of the distributed algorithm is proposed to incrementally update the existing estimates with new incoming data. Furthermore, a novel online robust regression method is proposed to estimate under a biased-batch corruption. We also prove that our algorithms benefit from strong robustness guarantees in terms of regression coefficient recovery with a constant upper bound on the error of state-of-the-art batch methods. Extensive experiments on synthetic and real datasets demonstrate that our approaches are superior to those of existing methods in effectiveness, with competitive efficiency.}
}


@article{DBLP:journals/tkdd/LiXCHLXD22,
	author = {Xingjian Li and
                  Haoyi Xiong and
                  Zeyu Chen and
                  Jun Huan and
                  Ji Liu and
                  Cheng{-}Zhong Xu and
                  Dejing Dou},
	title = {Knowledge Distillation with Attention for Deep Transfer Learning of
                  Convolutional Networks},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {3},
	pages = {42:1--42:20},
	year = {2022},
	url = {https://doi.org/10.1145/3473912},
	doi = {10.1145/3473912},
	timestamp = {Sun, 06 Oct 2024 21:41:27 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/LiXCHLXD22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Transfer learning through fine-tuning a pre-trained neural network with an extremely large dataset, such as ImageNet, can significantly improve and accelerate training while the accuracy is frequently bottlenecked by the limited dataset size of the new target task. To solve the problem, some regularization methods, constraining the outer layer weights of the target network using the starting point as references (SPAR), have been studied. In this article, we propose a novel regularized transfer learning framework \\(\\operatorname{DELTA}\\), namely DEep Learning Transfer using Feature Map with Attention. Instead of constraining the weights of neural network, \\(\\operatorname{DELTA}\\) aims at preserving the outer layer outputs of the source network. Specifically, in addition to minimizing the empirical loss, \\(\\operatorname{DELTA}\\) aligns the outer layer outputs of two networks, through constraining a subset of feature maps that are precisely selected by attention that has been learned in a supervised learning manner. We evaluate \\(\\operatorname{DELTA}\\) with the state-of-the-art algorithms, including \\(L^2\\) and \\(\\emph {L}^2\\text{-}SP\\). The experiment results show that our method outperforms these baselines with higher accuracy for new tasks. Code has been made publicly available.}
}


@article{DBLP:journals/tkdd/NashaatGMQ22,
	author = {Mona Nashaat and
                  Aindrila Ghosh and
                  James Miller and
                  Shaikh Quader},
	title = {Semi-Supervised Ensemble Learning for Dealing with Inaccurate and
                  Incomplete Supervision},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {3},
	pages = {43:1--43:33},
	year = {2022},
	url = {https://doi.org/10.1145/3473910},
	doi = {10.1145/3473910},
	timestamp = {Sun, 04 Aug 2024 19:52:23 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/NashaatGMQ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In real-world tasks, obtaining a large set of noise-free data can be prohibitively expensive. Therefore, recent research tries to enable machine learning to work with weakly supervised datasets, such as inaccurate or incomplete data. However, the previous literature treats each type of weak supervision individually, although, in most cases, different types of weak supervision tend to occur simultaneously. Therefore, in this article, we present Smart MEnDR, a Classification Model that applies Ensemble Learning and Data-driven Rectification to deal with inaccurate and incomplete supervised datasets. The model first applies a preliminary phase of ensemble learning in which the noisy data points are detected while exploiting the unlabelled data. The phase employs a semi-supervised technique with maximum likelihood estimation to decide on the disagreement rate. Second, the proposed approach applies an iterative meta-learning step to tackle the problem of knowing which points should be made correct to improve the performance of the final classifier. To evaluate the proposed framework, we report the classification performance, noise detection, and the labelling accuracy of the proposed method against state-of-the-art techniques. The experimental results demonstrate the effectiveness of the proposed framework in detecting noise, providing correct labels, and attaining high classification performance.}
}


@article{DBLP:journals/tkdd/ShaoYXW22,
	author = {Ping Shao and
                  Yang Yang and
                  Shengyao Xu and
                  Chunping Wang},
	title = {Network Embedding via Motifs},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {3},
	pages = {44:1--44:20},
	year = {2022},
	url = {https://doi.org/10.1145/3473911},
	doi = {10.1145/3473911},
	timestamp = {Tue, 20 Feb 2024 10:21:42 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/ShaoYXW22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Network embedding has emerged as an effective way to deal with downstream tasks, such as node classification \xa0[16, 31, 42]. Most existing methods leverage multi-similarities between nodes such as connectivity, which considers vertices that are closely connected to be similar and structural similarity, which is measured by assessing their relations to neighbors; while these methods only focus on static graphs. In this work, we bridge connectivity and structural similarity in a uniform representation via motifs, and consequently present an algorithm for Learning Embeddings by leveraging Motifs Of Networks (LEMON), which aims to learn embeddings for vertices and various motifs. Moreover, LEMON is inherently capable of dealing with inductive learning tasks for dynamic graphs. To validate the effectiveness and efficiency, we conduct various experiments on two real-world datasets and five public datasets from diverse domains. Through comparison with state-of-the-art baseline models, we find that LEMON achieves significant improvements in downstream tasks. We release our code on Github at https://github.com/larry2020626/LEMON.}
}


@article{DBLP:journals/tkdd/KuangZWWZZ22,
	author = {Kun Kuang and
                  Hengtao Zhang and
                  Runze Wu and
                  Fei Wu and
                  Yueting Zhuang and
                  Aijun Zhang},
	title = {Balance-Subsampled Stable Prediction Across Unknown Test Data},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {3},
	pages = {45:1--45:21},
	year = {2022},
	url = {https://doi.org/10.1145/3477052},
	doi = {10.1145/3477052},
	timestamp = {Mon, 05 Feb 2024 20:24:41 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/KuangZWWZZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In data mining and machine learning, it is commonly assumed that training and test data share the same population distribution. However, this assumption is often violated in practice because of the sample selection bias, which might induce the distribution shift from training data to test data. Such a model-agnostic distribution shift usually leads to prediction instability across unknown test data. This article proposes a novel balance-subsampled stable prediction (BSSP) algorithm based on the theory of fractional factorial design. It isolates the clear effect of each predictor from the confounding variables. A design-theoretic analysis shows that the proposed method can reduce the confounding effects among predictors induced by the distribution shift, improving both the accuracy of parameter estimation and the stability of prediction across unknown test data. Numerical experiments on synthetic and real-world datasets demonstrate that our BSSP algorithm can significantly outperform the baseline methods for stable prediction across unknown test data.}
}


@article{DBLP:journals/tkdd/ChenTCQLZ22,
	author = {Ling Chen and
                  Xing Tang and
                  Weiqi Chen and
                  Yuntao Qian and
                  Yansheng Li and
                  Yongjun Zhang},
	title = {{DACHA:} {A} Dual Graph Convolution Based Temporal Knowledge Graph
                  Representation Learning Method Using Historical Relation},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {3},
	pages = {46:1--46:18},
	year = {2022},
	url = {https://doi.org/10.1145/3477051},
	doi = {10.1145/3477051},
	timestamp = {Sat, 30 Sep 2023 10:29:07 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/ChenTCQLZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Temporal knowledge graph (TKG) representation learning embeds relations and entities into a continuous low-dimensional vector space by incorporating temporal information. Latest studies mainly aim at learning entity representations by modeling entity interactions from the neighbor structure of the graph. However, the interactions of relations from the neighbor structure of the graph are neglected, which are also of significance for learning informative representations. In addition, there still lacks an effective historical relation encoder to model the multi-range temporal dependencies. In this article, we propose a dual graph convolution network based TKG representation learning method using historical relations (DACHA). Specifically, we first construct the primal graph according to historical relations, as well as the edge graph by regarding historical relations as nodes. Then, we employ the dual graph convolution network to capture the interactions of both entities and historical relations from the neighbor structure of the graph. In addition, the temporal self-attentive historical relation encoder is proposed to explicitly model both local and global temporal dependencies. Extensive experiments on two event based TKG datasets demonstrate that DACHA achieves the state-of-the-art results.}
}


@article{DBLP:journals/tkdd/WangLLCJ22,
	author = {Huandong Wang and
                  Yong Li and
                  Junjie Lin and
                  Hancheng Cao and
                  Depeng Jin},
	title = {Context-Aware Semantic Annotation of Mobility Records},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {3},
	pages = {47:1--47:20},
	year = {2022},
	url = {https://doi.org/10.1145/3477048},
	doi = {10.1145/3477048},
	timestamp = {Mon, 03 Jan 2022 22:12:26 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/WangLLCJ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The wide adoption of mobile devices has provided us with a massive volume of human mobility records. However, a large portion of these records is unlabeled, i.e., only have GPS coordinates without semantic information (e.g., Point of Interest (POI)). To make those unlabeled records associate with more information for further applications, it is of great importance to annotate the original data with POIs information based on the external context. Nevertheless, semantic annotation of mobility records is challenging due to three aspects: the complex relationship among multiple domains of context, the sparsity of mobility records, and difficulties in balancing personal preference and crowd preference. To address these challenges, we propose CAP, a context-aware personalized semantic annotation model, where we use a Bayesian mixture model to model the complex relationship among five domains of context—location, time, POI category, personal preference, and crowd preference. We evaluate our model on two real-world datasets, and demonstrate that our proposed method significantly outperforms the state-of-the-art algorithms by over 11.8%.}
}


@article{DBLP:journals/tkdd/ShiZWR22,
	author = {Tian Shi and
                  Xuchao Zhang and
                  Ping Wang and
                  Chandan K. Reddy},
	title = {Corpus-level and Concept-based Explanations for Interpretable Document
                  Classification},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {3},
	pages = {48:1--48:17},
	year = {2022},
	url = {https://doi.org/10.1145/3477539},
	doi = {10.1145/3477539},
	timestamp = {Wed, 18 Oct 2023 14:03:48 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/ShiZWR22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Using attention weights to identify information that is important for models’ decision making is a popular approach to interpret attention-based neural networks. This is commonly realized in practice through the generation of a heat-map for every single document based on attention weights. However, this interpretation method is fragile and it is easy to find contradictory examples. In this article, we propose a corpus-level explanation approach, which aims at capturing causal relationships between keywords and model predictions via learning the importance of keywords for predicted labels across a training corpus based on attention weights. Based on this idea, we further propose a concept-based explanation method that can automatically learn higher level concepts and their importance to model prediction tasks. Our concept-based explanation method is built upon a novel Abstraction-Aggregation Network (AAN), which can automatically cluster important keywords during an end-to-end training process. We apply these methods to the document classification task and show that they are powerful in extracting semantically meaningful keywords and concepts. Our consistency analysis results based on an attention-based Naïve Bayes classifier (NBC) also demonstrate that these keywords and concepts are important for model predictions.}
}


@article{DBLP:journals/tkdd/FengLLRSGJ22,
	author = {Jie Feng and
                  Yong Li and
                  Ziqian Lin and
                  Can Rong and
                  Funing Sun and
                  Diansheng Guo and
                  Depeng Jin},
	title = {Context-aware Spatial-Temporal Neural Network for Citywide Crowd Flow
                  Prediction via Modeling Long-range Spatial Dependency},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {3},
	pages = {49:1--49:21},
	year = {2022},
	url = {https://doi.org/10.1145/3477577},
	doi = {10.1145/3477577},
	timestamp = {Mon, 28 Aug 2023 21:37:08 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/FengLLRSGJ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Crowd flow prediction is of great importance in a wide range of applications from urban planning, traffic control to public safety. It aims at predicting the inflow (the traffic of crowds entering a region in a given time interval) and outflow (the traffic of crowds leaving a region for other places) of each region in the city with knowing the historical flow data. In this article, we propose DeepSTN+, a deep learning-based convolutional model, to predict crowd flows in the metropolis. First, DeepSTN+ employs the ConvPlus structure to model the long-range spatial dependence among crowd flows in different regions. Further, PoI distributions and time factor are combined to express the effect of location attributes to introduce prior knowledge of the crowd movements. Finally, we propose a temporal attention-based fusion mechanism to stabilize the training process, which further improves the performance. Extensive experimental results based on four real-life datasets demonstrate the superiority of our model, i.e., DeepSTN+ reduces the error of the crowd flow prediction by approximately 10%–21% compared with the state-of-the-art baselines.}
}


@article{DBLP:journals/tkdd/ZhouRJZZJYD22,
	author = {Yang Zhou and
                  Jiaxiang Ren and
                  Ruoming Jin and
                  Zijie Zhang and
                  Jingyi Zheng and
                  Zhe Jiang and
                  Da Yan and
                  Dejing Dou},
	title = {Unsupervised Adversarial Network Alignment with Reinforcement Learning},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {3},
	pages = {50:1--50:29},
	year = {2022},
	url = {https://doi.org/10.1145/3477050},
	doi = {10.1145/3477050},
	timestamp = {Tue, 07 May 2024 20:19:55 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/ZhouRJZZJYD22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Network alignment, which aims at learning a matching between the same entities across multiple information networks, often suffers challenges from feature inconsistency, high-dimensional features, to unstable alignment results. This article presents a novel network alignment framework, Unsupervised Adversarial learning based Network Alignment(UANA), that combines generative adversarial network (GAN) and reinforcement learning (RL) techniques to tackle the above critical challenges. First, we propose a bidirectional adversarial network distribution matching model to perform the bidirectional cross-network alignment translations between two networks, such that the distributions of real and translated networks completely overlap together. In addition, two cross-network alignment translation cycles are constructed for training the unsupervised alignment without the need of prior alignment knowledge. Second, in order to address the feature inconsistency issue, we integrate a dual adversarial autoencoder module with an adversarial binary classification model together to project two copies of the same vertices with high-dimensional inconsistent features into the same low-dimensional embedding space. This facilitates the translations of the distributions of two networks in the adversarial network distribution matching model. Finally, we develop an RL based optimization approach to solve the vertex matching problem in the discrete space of the GAN model, i.e., directly select the vertices in target networks most relevant to the vertices in source networks, without unstable similarity computation that is sensitive to discriminative features and similarity metrics. Extensive evaluation on real-world graph datasets demonstrates the outstanding capability of UANA to address the unsupervised network alignment problem, in terms of both effectiveness and scalability.}
}


@article{DBLP:journals/tkdd/WuLLGFZW22,
	author = {Youxi Wu and
                  Lanfang Luo and
                  Yan Li and
                  Lei Guo and
                  Philippe Fournier{-}Viger and
                  Xingquan Zhu and
                  Xindong Wu},
	title = {NTP-Miner: Nonoverlapping Three-Way Sequential Pattern Mining},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {3},
	pages = {51:1--51:21},
	year = {2022},
	url = {https://doi.org/10.1145/3480245},
	doi = {10.1145/3480245},
	timestamp = {Mon, 28 Aug 2023 21:37:08 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/WuLLGFZW22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Nonoverlapping sequential pattern mining is an important type of sequential pattern mining (SPM) with gap constraints, which not only can reveal interesting patterns to users but also can effectively reduce the search space using the Apriori (anti-monotonicity) property. However, the existing algorithms do not focus on attributes of interest to users, meaning that existing methods may discover many frequent patterns that are redundant. To solve this problem, this article proposes a task called nonoverlapping three-way sequential pattern (NTP) mining, where attributes are categorized according to three levels of interest: strong, medium, and weak interest. NTP mining can effectively avoid mining redundant patterns since the NTPs are composed of strong and medium interest items. Moreover, NTPs can avoid serious deviations (the occurrence is significantly different from its pattern) since gap constraints cannot match with strong interest patterns. To mine NTPs, an effective algorithm is put forward, called NTP-Miner, which applies two main steps: support (frequency occurrence) calculation and candidate pattern generation. To calculate the support of an NTP, depth-first and backtracking strategies are adopted, which do not require creating a whole Nettree structure, meaning that many redundant nodes and parent–child relationships do not need to be created. Hence, time and space efficiency is improved. To generate candidate patterns while reducing their number, NTP-Miner employs a pattern join strategy and only mines patterns of strong and medium interest. Experimental results on stock market and protein datasets show that NTP-Miner not only is more efficient than other competitive approaches but can also help users find more valuable patterns. More importantly, NTP mining has achieved better performance than other competitive methods in clustering tasks. Algorithms and data are available at: https://github.com/wuc567/Pattern-Mining/tree/master/NTP-Miner.}
}


@article{DBLP:journals/tkdd/JiangLZSLQ22,
	author = {Yuanchun Jiang and
                  Ruicheng Liang and
                  Ji Zhang and
                  Jianshan Sun and
                  Ye{-}Zheng Liu and
                  Yang Qian},
	title = {Network Public Opinion Detection During the Coronavirus Pandemic:
                  {A} Short-Text Relational Topic Model},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {3},
	pages = {52:1--52:27},
	year = {2022},
	url = {https://doi.org/10.1145/3480246},
	doi = {10.1145/3480246},
	timestamp = {Tue, 16 Jul 2024 20:30:58 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/JiangLZSLQ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Online social media provides rich and varied information reflecting the significant concerns of the public during the coronavirus pandemic. Analyzing what the public is concerned with from social media information can support policy-makers to maintain the stability of the social economy and life of the society. In this article, we focus on the detection of the network public opinions during the coronavirus pandemic. We propose a novel Relational Topic Model for Short texts (RTMS) to draw opinion topics from social media data. RTMS exploits the feature of texts in online social media and the opinion propagation patterns among individuals. Moreover, a dynamic version of RTMS (DRTMS) is proposed to capture the evolution of public opinions. Our experiment is conducted on a real-world dataset which includes 67,592 comments from 14,992 users. The results demonstrate that, compared with the benchmark methods, the proposed RTMS and DRTMS models can detect meaningful public opinions by leveraging the feature of social media data. It can also effectively capture the evolution of public concerns during different phases of the coronavirus pandemic.}
}


@article{DBLP:journals/tkdd/SunLLYHQH22,
	author = {Heli Sun and
                  Yang Li and
                  Bing Lv and
                  Wujie Yan and
                  Liang He and
                  Shaojie Qiao and
                  Jianbin Huang},
	title = {Graph Community Infomax},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {3},
	pages = {53:1--53:21},
	year = {2022},
	url = {https://doi.org/10.1145/3480244},
	doi = {10.1145/3480244},
	timestamp = {Mon, 04 Sep 2023 20:40:38 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/SunLLYHQH22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graph representation learning aims at learning low-dimension representations for nodes in graphs, and has been proven very useful in several downstream tasks. In this article, we propose a new model, Graph Community Infomax (GCI), that can adversarial learn representations for nodes in attributed networks. Different from other adversarial network embedding models, which would assume that the data follow some prior distributions and generate fake examples, GCI utilizes the community information of networks, using nodes as positive(or real) examples and negative(or fake) examples at the same time. An autoencoder is applied to learn the embedding vectors for nodes and reconstruct the adjacency matrix, and a discriminator is used to maximize the mutual information between nodes and communities. Experiments on several real-world and synthetic networks have shown that GCI outperforms various network embedding methods on community detection tasks.}
}


@article{DBLP:journals/tkdd/LiuLLW22,
	author = {Guliu Liu and
                  Lei Li and
                  Guanfeng Liu and
                  Xindong Wu},
	title = {Social Group Query Based on Multi-Fuzzy-Constrained Strong Simulation},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {3},
	pages = {54:1--54:27},
	year = {2022},
	url = {https://doi.org/10.1145/3481640},
	doi = {10.1145/3481640},
	timestamp = {Sat, 30 Sep 2023 10:29:07 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/LiuLLW22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Traditional social group analysis mostly uses interaction models, event models, or other social network analysis methods to identify and distinguish groups. This type of method can divide social participants into different groups based on their geographic location, social relationships, and/or related events. However, in some applications, it is necessary to make more specific restrictions on the members and the interactions between members of the group. Generally, Graph Pattern Matching (GPM) technique is used to solve this problem. However, the existing GPM methods rarely consider the rich contextual information of nodes and edges to measure the credibility between members. In this article, first, a social group query problem that needs to consider the trust between members of the group is proposed. Then, to solve this problem, a multi-fuzzy-constrained strong simulation matching model is proposed based on multi-constrained simulation, and a Strong Simulation GPM algorithm (NTSS) based on the exploration of pattern Node Topological ordered sequence is proposed. Aiming at the inefficiency of the NTSS algorithm when pattern graph with multiple nodes with zero in-degree and the problem of repeated calculation of matching edges shared by multiple matching subgraphs, two optimization strategies are proposed. Finally, we conduct verification experiments on the effectiveness and efficiency of the NTSS algorithm and the algorithms with the optimization strategies on four social network datasets in real applications. Experimental results show that the NTSS algorithm is significantly better than the existing multi-constrained GPM algorithm, and the NTSS_Inv_EdgC algorithm, which combines two optimization strategies, greatly improves the efficiency of the NTSS algorithm.}
}


@article{DBLP:journals/tkdd/LiangOM22,
	author = {Shangsong Liang and
                  Zhuo Ouyang and
                  Zaiqiao Meng},
	title = {A Normalizing Flow-Based Co-Embedding Model for Attributed Networks},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {3},
	pages = {55:1--55:31},
	year = {2022},
	url = {https://doi.org/10.1145/3477049},
	doi = {10.1145/3477049},
	timestamp = {Sat, 08 Jan 2022 02:24:19 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/LiangOM22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Network embedding is a technique that aims at inferring the low-dimensional representations of nodes in a semantic space. In this article, we study the problem of inferring the low-dimensional representations of both nodes and attributes for attributed networks in the same semantic space such that the affinity between a node and an attribute can be effectively measured. Intuitively, this problem can be addressed by simply utilizing existing variational auto-encoder (VAE) based network embedding algorithms. However, the variational posterior distribution in previous VAE based network embedding algorithms is often assumed and restricted to be a mean-field Gaussian distribution or other simple distribution families, which results in poor inference of the embeddings. To alleviate the above defect, we propose a novel VAE-based co-embedding method for attributed network, F-CAN, where posterior distributions are flexible, complex, and scalable distributions constructed through the normalizing flow. We evaluate our proposed models on a number of network tasks with several benchmark datasets. Experimental results demonstrate that there are clear improvements in the qualities of embeddings generated by our model to the state-of-the-art attributed network embedding methods.}
}


@article{DBLP:journals/tkdd/XuSZYMYMHWMSM22,
	author = {Yonghui Xu and
                  Shengjie Sun and
                  Huiguo Zhang and
                  Chang'an Yi and
                  Yuan Miao and
                  Dong Yang and
                  Xiaonan Meng and
                  Yi Hu and
                  Ke Wang and
                  Huaqing Min and
                  Hengjie Song and
                  Chuanyan Miao},
	title = {Time-Aware Graph Embedding: {A} Temporal Smoothness and Task-Oriented
                  Approach},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {3},
	pages = {56:1--56:23},
	year = {2022},
	url = {https://doi.org/10.1145/3480243},
	doi = {10.1145/3480243},
	timestamp = {Tue, 07 May 2024 20:19:56 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/XuSZYMYMHWMSM22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Knowledge graph embedding, which aims at learning the low-dimensional representations of entities and relationships, has attracted considerable research efforts recently. However, most knowledge graph embedding methods focus on the structural relationships in fixed triples while ignoring the temporal information. Currently, existing time-aware graph embedding methods only focus on the factual plausibility, while ignoring the temporal smoothness, which models the interactions between a fact and its contexts, and thus can capture fine-granularity temporal relationships. This leads to the limited performance of embedding related applications. To solve this problem, this article presents a Robustly Time-aware Graph Embedding (RTGE) method by incorporating temporal smoothness. Two major innovations of our article are presented here. At first, RTGE integrates a measure of temporal smoothness in the learning process of the time-aware graph embedding. Via the proposed additional smoothing factor, RTGE can preserve both structural information and evolutionary patterns of a given graph. Secondly, RTGE provides a general task-oriented negative sampling strategy associated with temporally aware information, which further improves the adaptive ability of the proposed algorithm and plays an essential role in obtaining superior performance in various tasks. Extensive experiments conducted on multiple benchmark tasks show that RTGE can increase performance in entity/relationship/temporal scoping prediction tasks.}
}


@article{DBLP:journals/tkdd/SowahKMATBA22,
	author = {Robert A. Sowah and
                  Bernard Kuditchar and
                  Godfrey A. Mills and
                  Amevi Acakpovi and
                  Raphael A. Twum and
                  Gifty Buah and
                  Robert Agboyi},
	title = {{HCBST:} An Efficient Hybrid Sampling Technique for Class Imbalance
                  Problems},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {3},
	pages = {57:1--57:37},
	year = {2022},
	url = {https://doi.org/10.1145/3488280},
	doi = {10.1145/3488280},
	timestamp = {Sun, 06 Oct 2024 21:41:28 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/SowahKMATBA22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Class imbalance problem is prevalent in many real-world domains. It has become an active area of research. In binary classification problems, imbalance learning refers to learning from a dataset with a high degree of skewness to the negative class. This phenomenon causes classification algorithms to perform woefully when predicting positive classes with new examples. Data resampling, which involves manipulating the training data before applying standard classification techniques, is among the most commonly used techniques to deal with the class imbalance problem. This article presents a new hybrid sampling technique that improves the overall performance of classification algorithms for solving the class imbalance problem significantly. The proposed method called the Hybrid Cluster-Based Undersampling Technique (HCBST) uses a combination of the cluster undersampling technique to under-sample the majority instances and an oversampling technique derived from Sigma Nearest Oversampling based on Convex Combination, to oversample the minority instances to solve the class imbalance problem with a high degree of accuracy and reliability. The performance of the proposed algorithm was tested using 11 datasets from the National Aeronautics and Space Administration Metric Data Program data repository and University of California Irvine Machine Learning data repository with varying degrees of imbalance. Results were compared with classification algorithms such as the K-nearest neighbours, support vector machines, decision tree, random forest, neural network, AdaBoost, naïve Bayes, and quadratic discriminant analysis. Tests results revealed that for the same datasets, the HCBST performed better with average performances of 0.73, 0.67, and 0.35 in terms of performance measures of area under curve, geometric mean, and Matthews Correlation Coefficient, respectively, across all the classifiers used for this study. The HCBST has the potential of improving the performance of the class imbalance problem, which by extension, will improve on the various applications that rely on the concept for a solution.}
}


@article{DBLP:journals/tkdd/JinHJK22,
	author = {Junchen Jin and
                  Mark Heimann and
                  Di Jin and
                  Danai Koutra},
	title = {Toward Understanding and Evaluating Structural Node Embeddings},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {3},
	pages = {58:1--58:32},
	year = {2022},
	url = {https://doi.org/10.1145/3481639},
	doi = {10.1145/3481639},
	timestamp = {Thu, 05 May 2022 15:59:21 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/JinHJK22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {While most network embedding techniques model the proximity between nodes in a network, recently there has been significant interest in structural embeddings that are based on node equivalences, a notion rooted in sociology: equivalences or positions are collections of nodes that have similar roles—i.e., similar functions, ties or interactions with nodes in other positions—irrespective of their distance or reachability in the network. Unlike the proximity-based methods that are rigorously evaluated in the literature, the evaluation of structural embeddings is less mature. It relies on small synthetic or real networks with labels that are not perfectly defined, and its connection to sociological equivalences has hitherto been vague and tenuous. With new node embedding methods being developed at a breakneck pace, proper evaluation, and systematic characterization of existing approaches will be essential to progress. To fill in this gap, we set out to understand what types of equivalences structural embeddings capture. We are the first to contribute rigorous intrinsic and extrinsic evaluation methodology for structural embeddings, along with carefully-designed, diverse datasets of varying sizes. We observe a number of different evaluation variables that can lead to different results (e.g., choice of similarity measure, classifier, and label definitions). We find that degree distributions within nodes’ local neighborhoods can lead to simple yet effective baselines in their own right and guide the future development of structural embedding. We hope that our findings can influence the design of further node embedding methods and also pave the way for more comprehensive and fair evaluation of structural embedding methods.}
}


@article{DBLP:journals/tkdd/GuoXZLL22,
	author = {Mengzhuo Guo and
                  Zhongzhi Xu and
                  Qingpeng Zhang and
                  Xiuwu Liao and
                  Jiapeng Liu},
	title = {Deciphering Feature Effects on Decision-Making in Ordinal Regression
                  Problems: An Explainable Ordinal Factorization Model},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {3},
	pages = {59:1--59:26},
	year = {2022},
	url = {https://doi.org/10.1145/3487048},
	doi = {10.1145/3487048},
	timestamp = {Mon, 05 Feb 2024 20:24:41 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/GuoXZLL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Ordinal regression predicts the objects’ labels that exhibit a natural ordering, which is vital to decision-making problems such as credit scoring and clinical diagnosis. In these problems, the ability to explain how the individual features and their interactions affect the decisions is as critical as model performance. Unfortunately, the existing ordinal regression models in the machine learning community aim at improving prediction accuracy rather than explore explainability. To achieve high accuracy while explaining the relationships between the features and the predictions, we propose a new method for ordinal regression problems, namely the Explainable Ordinal Factorization Model (XOFM). XOFM uses piecewise linear functions to approximate the shape functions of individual features, and renders the pairwise features interaction effects as heat-maps. The proposed XOFM captures the nonlinearity in the main effects and ensures the interaction effects’ same flexibility. Therefore, the underlying model yields comparable performance while remaining explainable by explicitly describing the main and interaction effects. To address the potential sparsity problem caused by discretizing the whole feature scale into several sub-intervals, XOFM integrates the Factorization Machines (FMs) to factorize the model parameters. Comprehensive experiments with benchmark real-world and synthetic datasets demonstrate that the proposed XOFM leads to state-of-the-art prediction performance while preserving an easy-to-understand explainability.}
}


@article{DBLP:journals/tkdd/LinDSLY22,
	author = {Jerry Chun{-}Wei Lin and
                  Youcef Djenouri and
                  Gautam Srivastava and
                  Yuanfa Li and
                  Philip S. Yu},
	title = {Scalable Mining of High-Utility Sequential Patterns With Three-Tier
                  MapReduce Model},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {3},
	pages = {60:1--60:26},
	year = {2022},
	url = {https://doi.org/10.1145/3487046},
	doi = {10.1145/3487046},
	timestamp = {Sun, 06 Oct 2024 21:41:27 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/LinDSLY22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {High-utility sequential pattern mining (HUSPM) is a hot research topic in recent decades since it combines both sequential and utility properties to reveal more information and knowledge rather than the traditional frequent itemset mining or sequential pattern mining. Several works of HUSPM have been presented but most of them are based on main memory to speed up mining performance. However, this assumption is not realistic and not suitable in large-scale environments since in real industry, the size of the collected data is very huge and it is impossible to fit the data into the main memory of a single machine. In this article, we first develop a parallel and distributed three-stage MapReduce model for mining high-utility sequential patterns based on large-scale databases. Two properties are then developed to hold the correctness and completeness of the discovered patterns in the developed framework. In addition, two data structures called sidset and utility-linked list are utilized in the developed framework to accelerate the computation for mining the required patterns. From the results, we can observe that the designed model has good performance in large-scale datasets in terms of runtime, memory, efficiency of the number of distributed nodes, and scalability compared to the serial HUSP-Span approach.}
}


@article{DBLP:journals/tkdd/GuptaA22,
	author = {Manish Gupta and
                  Puneet Agrawal},
	title = {Compression of Deep Learning Models for Text: {A} Survey},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {4},
	pages = {61:1--61:55},
	year = {2022},
	url = {https://doi.org/10.1145/3487045},
	doi = {10.1145/3487045},
	timestamp = {Wed, 16 Mar 2022 23:54:46 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/GuptaA22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recent years, the fields of natural language processing (NLP) and information retrieval (IR) have made tremendous progress thanks to deep learning models like Recurrent Neural Networks (RNNs), Gated Recurrent Units (GRUs) and Long Short-Term Memory (LSTMs) networks, and Transformer\xa0[121] based models like Bidirectional Encoder Representations from Transformers (BERT)\xa0[24], Generative Pre-training Transformer (GPT-2)\xa0[95], Multi-task Deep Neural Network (MT-DNN)\xa0[74], Extra-Long Network (XLNet)\xa0[135], Text-to-text transfer transformer (T5)\xa0[96], T-NLG\xa0[99], and GShard\xa0[64]. But these models are humongous in size. On the other hand, real-world applications demand small model size, low response times, and low computational power wattage. In this survey, we discuss six different types of methods (Pruning, Quantization, Knowledge Distillation (KD), Parameter Sharing, Tensor Decomposition, and Sub-quadratic Transformer-based methods) for compression of such models to enable their deployment in real industry NLP projects. Given the critical need of building applications with efficient and small models, and the large amount of recently published work in this area, we believe that this survey organizes the plethora of work done by the “deep learning for NLP” community in the past few years and presents it as a coherent story.}
}


@article{DBLP:journals/tkdd/LiuYGG22,
	author = {Chang Liu and
                  Jie Yan and
                  Feiyue Guo and
                  Min Guo},
	title = {Forecasting the Market with Machine Learning Algorithms: An Application
                  of {NMC-BERT-LSTM-DQN-X} Algorithm in Quantitative Trading},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {4},
	pages = {62:1--62:22},
	year = {2022},
	url = {https://doi.org/10.1145/3488378},
	doi = {10.1145/3488378},
	timestamp = {Tue, 15 Feb 2022 17:11:23 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/LiuYGG22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Although machine learning (ML) algorithms have been widely used in forecasting the trend of stock market indices, they failed to consider the following crucial aspects for market forecasting: (1) that investors’ emotions and attitudes toward future market trends have material impacts on market trend forecasting (2) the length of past market data should be dynamically adjusted according to the market status and (3) the transition of market statutes should be considered when forecasting market trends. In this study, we proposed an innovative ML method to forecast China's stock market trends by addressing the three issues above. Specifically, sentimental factors (see Appendix [1] for full trans) were first collected to measure investors’ emotions and attitudes. Then, a non-stationary Markov chain (NMC) model was used to capture dynamic transitions of market statutes. We choose the state-of-the-art (SOTA) method, namely, Bidirectional Encoder Representations from Transformers (BERT), to predict the state of the market at time t, and a long short-term memory (LSTM) model was used to estimate the varying length of past market data in market trend prediction, where the input of LSTM (the state of the market at time t) was the output of BERT and probabilities for opening and closing of the gates in the LSTM model were based on outputs of the NMC model. Finally, the optimum parameters of the proposed algorithm were calculated using a reinforced learning-based deep Q-Network. Compared to existing forecasting methods, the proposed algorithm achieves better results with a forecasting accuracy of 61.77%, annualized return of 29.25%, and maximum losses of −8.29%. Furthermore, the proposed model achieved the lowest forecasting error: mean square error (0.095), root mean square error (0.0739), mean absolute error (0.104), and mean absolute percent error (15.1%). As a result, the proposed market forecasting model can help investors obtain more accurate market forecast information.}
}


@article{DBLP:journals/tkdd/LiuLBLS22,
	author = {Danlu Liu and
                  Yu Li and
                  William Baskett and
                  Dan Lin and
                  Chi{-}Ren Shyu},
	title = {RHPTree - Risk Hierarchical Pattern Tree for Scalable Long Pattern
                  Mining},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {4},
	pages = {63:1--63:33},
	year = {2022},
	url = {https://doi.org/10.1145/3488380},
	doi = {10.1145/3488380},
	timestamp = {Mon, 28 Aug 2023 21:37:08 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/LiuLBLS22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Risk patterns are crucial in biomedical research and have served as an important factor in precision health and disease prevention. Despite recent development in parallel and high-performance computing, existing risk pattern mining methods still struggle with problems caused by large-scale datasets, such as redundant candidate generation, inability to discover long significant patterns, and prolonged post pattern filtering. In this article, we propose a novel dynamic tree structure, Risk Hierarchical Pattern Tree (RHPTree), and a top-down search method, RHPSearch, which are capable of efficiently analyzing a large volume of data and overcoming the limitations of previous works. The dynamic nature of the RHPTree avoids costly tree reconstruction for the iterative search process and dataset updates. We also introduce two specialized search methods, the extended target search (RHPSearch-TS) and the parallel search approach (RHPSearch-SD), to further speed up the retrieval of certain items of interest. Experiments on both UCI machine learning datasets and sampled datasets of the Simons Foundation Autism Research Initiative (SFARI)—Simon’s Simplex Collection (SSC) datasets demonstrate that our method is not only faster but also more effective in identifying comprehensive long risk patterns than existing works. Moreover, the proposed new tree structure is generic and applicable to other pattern mining problems.}
}


@article{DBLP:journals/tkdd/MaRCRZLMR22,
	author = {Muyang Ma and
                  Pengjie Ren and
                  Zhumin Chen and
                  Zhaochun Ren and
                  Lifan Zhao and
                  Peiyu Liu and
                  Jun Ma and
                  Maarten de Rijke},
	title = {Mixed Information Flow for Cross-Domain Sequential Recommendations},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {4},
	pages = {64:1--64:32},
	year = {2022},
	url = {https://doi.org/10.1145/3487331},
	doi = {10.1145/3487331},
	timestamp = {Mon, 21 Aug 2023 13:19:54 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/MaRCRZLMR22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cross-domain sequential recommendation is the task of predict the next item that the user is most likely to interact with based on past sequential behavior from multiple domains. One of the key challenges in cross-domain sequential recommendation is to grasp and transfer the flow of information from multiple domains so as to promote recommendations in all domains. Previous studies have investigated the flow of behavioral information by exploring the connection between items from different domains. The flow of knowledge (i.e., the connection between knowledge from different domains) has so far been neglected. In this article, we propose a mixed information flow network for cross-domain sequential recommendation to consider both the flow of behavioral information and the flow of knowledge by incorporating a behavior transfer unit and a knowledge transfer unit. The proposed mixed information flow network is able to decide when cross-domain information should be used and, if so, which cross-domain information should be used to enrich the sequence representation according to users’ current preferences. Extensive experiments conducted on four e-commerce datasets demonstrate that the proposed mixed information flow network is able to improve recommendation performance in different domains by modeling mixed information flow. In this article, we focus on the application of mixed information flow networks to a scenario with two domains, but the method can easily be extended to multiple domains.}
}


@article{DBLP:journals/tkdd/FuYN22,
	author = {Zhe Fu and
                  Li Yu and
                  Xi Niu},
	title = {{TRACE:} Travel Reinforcement Recommendation Based on Location-Aware
                  Context Extraction},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {4},
	pages = {65:1--65:22},
	year = {2022},
	url = {https://doi.org/10.1145/3487047},
	doi = {10.1145/3487047},
	timestamp = {Fri, 25 Aug 2023 19:04:15 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/FuYN22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As the popularity of online travel platforms increases, users tend to make ad-hoc decisions on places to visit rather than preparing the detailed tour plans in advance. Under the situation of timeliness and uncertainty of users’ demand, how to integrate real-time context into dynamic and personalized recommendations have become a key issue in travel recommender system. In this article, by integrating the users’ historical preferences and real-time context, a location-aware recommender system called TRACE (Travel Reinforcement Recommendations Based on Location-Aware Context Extraction) is proposed. It captures users’ features based on location-aware context learning model, and makes dynamic recommendations based on reinforcement learning. Specifically, this research: (1) designs a travel reinforcing recommender system based on an Actor-Critic framework, which can dynamically track the user preference shifts and optimize the recommender system performance; (2) proposes a location-aware context learning model, which aims at extracting user context from real-time location and then calculating the impacts of nearby attractions on users’ preferences; and (3) conducts both offline and online experiments. Our proposed model achieves the best performance in both of the two experiments, which demonstrates that tracking the users’ preference shifts based on real-time location is valuable for improving the recommendation results.}
}


@article{DBLP:journals/tkdd/YuYD22,
	author = {Kui Yu and
                  Yajing Yang and
                  Wei Ding},
	title = {Causal Feature Selection with Missing Data},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {4},
	pages = {66:1--66:24},
	year = {2022},
	url = {https://doi.org/10.1145/3488055},
	doi = {10.1145/3488055},
	timestamp = {Tue, 08 Feb 2022 10:43:29 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/YuYD22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Causal feature selection aims at learning the Markov blanket (MB) of a class variable for feature selection. The MB of a class variable implies the local causal structure among the class variable and its MB and all other features are probabilistically independent of the class variable conditioning on its MB, this enables causal feature selection to identify potential causal features for feature selection for building robust and physically meaningful prediction models. Missing data, ubiquitous in many real-world applications, remain an open research problem in causal feature selection due to its technical complexity. In this article, we discuss a novel multiple imputation MB (MimMB) framework for causal feature selection with missing data. MimMB integrates Data Imputation with MB Learning in a unified framework to enable the two key components to engage with each other. MB Learning enables Data Imputation in a potentially causal feature space for achieving accurate data imputation, while accurate Data Imputation helps MB Learning identify a reliable MB of the class variable in turn. Then, we further design an enhanced kNN estimator for imputing missing values and instantiate the MimMB. In our comprehensively experimental evaluation, our new approach can effectively learn the MB of a given variable in a Bayesian network and outperforms other rival algorithms using synthetic and real-world datasets.}
}


@article{DBLP:journals/tkdd/GaoLGSLW22,
	author = {Fei Gao and
                  Jiada Li and
                  Yisu Ge and
                  Jianwen Shao and
                  Shufang Lu and
                  Libo Weng},
	title = {A Trajectory Evaluator by Sub-tracks for Detecting VOT-based Anomalous
                  Trajectory},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {4},
	pages = {67:1--67:19},
	year = {2022},
	url = {https://doi.org/10.1145/3490032},
	doi = {10.1145/3490032},
	timestamp = {Tue, 08 Feb 2022 10:43:29 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/GaoLGSLW22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the popularization of visual object tracking (VOT), more and more trajectory data are obtained and have begun to gain widespread attention in the fields of mobile robots, intelligent video surveillance, and the like. How to clean the anomalous trajectories hidden in the massive data has become one of the research hotspots. Anomalous trajectories should be detected and cleaned before the trajectory data can be effectively used. In this article, a Trajectory Evaluator by Sub-tracks (TES) for detecting VOT-based anomalous trajectory is proposed. Feature of Anomalousness is defined and described as the Eigenvector of classifier to filter Track Lets anomalous trajectory and IDentity Switch anomalous trajectory, which includes Feature of Anomalous Pose and Feature of Anomalous Sub-tracks (FAS). In the comparative experiments, TES achieves better results on different scenes than state-of-the-art methods. Moreover, FAS makes better performance than point flow, least square method fitting and Chebyshev Polynomial Fitting. It is verified that TES is more accurate and effective and is conducive to the sub-tracks trajectory data analysis.}
}


@article{DBLP:journals/tkdd/JafariakinabadH22,
	author = {Fereshteh Jafariakinabad and
                  Kien A. Hua},
	title = {A Self-Supervised Representation Learning of Sentence Structure for
                  Authorship Attribution},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {4},
	pages = {68:1--68:16},
	year = {2022},
	url = {https://doi.org/10.1145/3491203},
	doi = {10.1145/3491203},
	timestamp = {Tue, 08 Feb 2022 10:43:29 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/JafariakinabadH22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The syntactic structure of sentences in a document substantially informs about its authorial writing style. Sentence representation learning has been widely explored in recent years and it has been shown that it improves the generalization of different downstream tasks across many domains. Even though utilizing probing methods in several studies suggests that these learned contextual representations implicitly encode some amount of syntax, explicit syntactic information further improves the performance of deep neural models in the domain of authorship attribution. These observations have motivated us to investigate the explicit representation learning of syntactic structure of sentences. In this article, we propose a self-supervised framework for learning structural representations of sentences. The self-supervised network contains two components; a lexical sub-network and a syntactic sub-network which take the sequence of words and their corresponding structural labels as the input, respectively. Due to the n-to-1 mapping of words to their structural labels, each word will be embedded into a vector representation which mainly carries structural information. We evaluate the learned structural representations of sentences using different probing tasks, and subsequently utilize them in the authorship attribution task. Our experimental results indicate that the structural embeddings significantly improve the classification tasks when concatenated with the existing pre-trained word embeddings.}
}


@article{DBLP:journals/tkdd/XuCL22,
	author = {Honghui Xu and
                  Zhipeng Cai and
                  Wei Li},
	title = {Privacy-Preserving Mechanisms for Multi-Label Image Recognition},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {4},
	pages = {69:1--69:21},
	year = {2022},
	url = {https://doi.org/10.1145/3491231},
	doi = {10.1145/3491231},
	timestamp = {Mon, 28 Aug 2023 21:37:07 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/XuCL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Multi-label image recognition has been an indispensable fundamental component for many real computer vision applications. However, a severe threat of privacy leakage in multi-label image recognition has been overlooked by existing studies. To fill this gap, two privacy-preserving models, Privacy-Preserving Multi-label Graph Convolutional Networks (P2-ML-GCN) and Robust P2-ML-GCN (RP2-ML-GCN), are developed in this article, where differential privacy mechanism is implemented on the model’s outputs so as to defend black-box attack and avoid large aggregated noise simultaneously. In particular, a regularization term is exploited in the loss function of RP2-ML-GCN to increase the model prediction accuracy and robustness. After that, a proper differential privacy mechanism is designed with the intention of decreasing the bias of loss function in P2-ML-GCN and increasing prediction accuracy. Besides, we analyze that a bounded global sensitivity can mitigate excessive noise’s side effect and obtain a performance improvement for multi-label image recognition in our models. Theoretical proof shows that our two models can guarantee differential privacy for model’s outputs, weights and input features while preserving model robustness. Finally, comprehensive experiments are conducted to validate the advantages of our proposed models, including the implementation of differential privacy on model’s outputs, the incorporation of regularization term into loss function, and the adoption of bounded global sensitivity for multi-label image recognition.}
}


@article{DBLP:journals/tkdd/AbulaishFZ22,
	author = {Muhammad Abulaish and
                  Mohd Fazil and
                  Mohammed J. Zaki},
	title = {Domain-Specific Keyword Extraction Using Joint Modeling of Local and
                  Global Contextual Semantics},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {4},
	pages = {70:1--70:30},
	year = {2022},
	url = {https://doi.org/10.1145/3494560},
	doi = {10.1145/3494560},
	timestamp = {Sun, 06 Oct 2024 21:41:27 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/AbulaishFZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Domain-specific keyword extraction is a vital task in the field of text mining. There are various research tasks, such as spam e-mail classification, abusive language detection, sentiment analysis, and emotion mining, where a set of domain-specific keywords (aka lexicon) is highly effective. Existing works for keyword extraction list all keywords rather than domain-specific keywords from a document corpus. Moreover, most of the existing approaches perform well on formal document corpuses but fail on noisy and informal user-generated content in online social media. In this article, we present a hybrid approach by jointly modeling the local and global contextual semantics of words, utilizing the strength of distributional word representation and contrasting-domain corpus for domain-specific keyword extraction. Starting with a seed set of a few domain-specific keywords, we model the text corpus as a weighted word-graph. In this graph, the initial weight of a node (word) represents its semantic association with the target domain calculated as a linear combination of three semantic association metrics, and the weight of an edge connecting a pair of nodes represents the co-occurrence count of the respective words. Thereafter, a modified PageRank method is applied to the word-graph to identify the most relevant words for expanding the initial set of domain-specific keywords. We evaluate our method over both formal and informal text corpuses (comprising six datasets), and show that it performs significantly better in comparison to state-of-the-art methods. Furthermore, we generalize our approach to handle the language-agnostic case, and show that it outperforms existing language-agnostic approaches.}
}


@article{DBLP:journals/tkdd/YuanZLLX22,
	author = {Mu Yuan and
                  Lan Zhang and
                  Xiang{-}Yang Li and
                  Lin{-}Zhuo Yang and
                  Hui Xiong},
	title = {Adaptive Model Scheduling for Resource-efficient Data Labeling},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {4},
	pages = {71:1--71:22},
	year = {2022},
	url = {https://doi.org/10.1145/3494559},
	doi = {10.1145/3494559},
	timestamp = {Tue, 12 Jul 2022 10:00:18 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/YuanZLLX22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Labeling data (e.g., labeling the people, objects, actions, and scene in images) comprehensively and efficiently is a widely needed but challenging task. Numerous models were proposed to label various data and many approaches were designed to enhance the ability of deep learning models or accelerate them. Unfortunately, a single machine-learning model is not powerful enough to extract various semantic information from data. Given certain applications, such as image retrieval platforms and photo album management apps, it is often required to execute a collection of models to obtain sufficient labels. With limited computing resources and stringent delay, given a data stream and a collection of applicable resource-hungry deep-learning models, we design a novel approach to adaptively schedule a subset of these models to execute on each data item, aiming to maximize the value of the model output (e.g., the number of high-confidence labels). Achieving this lofty goal is nontrivial since a model’s output on any data item is content-dependent and unknown until we execute it. To tackle this, we propose an Adaptive Model Scheduling framework, consisting of (1) a deep reinforcement learning-based approach to predict the value of unexecuted models by mining semantic relationship among diverse models, and (2) two heuristic algorithms to adaptively schedule the model execution order under a deadline or deadline-memory constraints, respectively. The proposed framework does not require any prior knowledge of the data, which works as a powerful complement to existing model optimization technologies. We conduct extensive evaluations on five diverse image datasets and 30 popular image labeling models to demonstrate the effectiveness of our design: our design could save around 53% execution time without loss of any valuable labels.}
}


@article{DBLP:journals/tkdd/ZhangWB22,
	author = {Min{-}Ling Zhang and
                  Jing{-}Han Wu and
                  Wei{-}Xuan Bao},
	title = {Disambiguation Enabled Linear Discriminant Analysis for Partial Label
                  Dimensionality Reduction},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {4},
	pages = {72:1--72:18},
	year = {2022},
	url = {https://doi.org/10.1145/3494565},
	doi = {10.1145/3494565},
	timestamp = {Tue, 08 Feb 2022 10:43:29 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/ZhangWB22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As an emerging weakly supervised learning framework, partial label learning considers inaccurate supervision where each training example is associated with multiple candidate labels among which only one is valid. In this article, a first attempt toward employing dimensionality reduction to help improve the generalization performance of partial label learning system is investigated. Specifically, the popular linear discriminant analysis (LDA) techniques are endowed with the ability of dealing with partial label training examples. To tackle the challenge of unknown ground-truth labeling information, a novel learning approach named Delin is proposed which alternates between LDA dimensionality reduction and candidate label disambiguation based on estimated labeling confidences over candidate labels. On one hand, the (kernelized) projection matrix of LDA is optimized by utilizing disambiguation-guided labeling confidences. On the other hand, the labeling confidences are disambiguated by resorting to kNN aggregation in the LDA-induced feature space. Extensive experiments over a broad range of partial label datasets clearly validate the effectiveness of Delin in improving the generalization performance of well-established partial label learning algorithms.}
}


@article{DBLP:journals/tkdd/HuangFLCZ22,
	author = {Chenji Huang and
                  Yixiang Fang and
                  Xuemin Lin and
                  Xin Cao and
                  Wenjie Zhang},
	title = {{ABLE:} Meta-Path Prediction in Heterogeneous Information Networks},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {4},
	pages = {73:1--73:21},
	year = {2022},
	url = {https://doi.org/10.1145/3494558},
	doi = {10.1145/3494558},
	timestamp = {Tue, 08 Feb 2022 10:43:29 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/HuangFLCZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Given a heterogeneous information network (HIN) H, a head node h, a meta-path P, and a tail node t, the meta-path prediction aims at predicting whether h can be linked to t by an instance of P. Most existing solutions either require predefined meta-paths, which limits their scalability to schema-rich HINs and long meta-paths, or do not aim at predicting the existence of an instance of P. To address these issues, in this article, we propose a novel prediction model, called ABLE, by exploiting the Attention mechanism and BiLSTM for Embedding. Particularly, we present a concatenation node embedding method by considering the node types and a dynamic meta-path embedding method that carefully considers the importance and positions of edge types in the meta-paths by the Attention mechanism and BiLSTM model, respectively. A triplet embedding is then derived to complete the prediction. We conduct extensive experiments on four real datasets. The empirical results show that ABLE outperforms the state-of-the-art methods by up to 20% and 22% of improvement of AUC and AP scores, respectively.}
}


@article{DBLP:journals/tkdd/YuanWKLWWL22,
	author = {Junkun Yuan and
                  Anpeng Wu and
                  Kun Kuang and
                  Bo Li and
                  Runze Wu and
                  Fei Wu and
                  Lanfen Lin},
	title = {Auto {IV:} Counterfactual Prediction via Automatic Instrumental Variable
                  Decomposition},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {4},
	pages = {74:1--74:20},
	year = {2022},
	url = {https://doi.org/10.1145/3494568},
	doi = {10.1145/3494568},
	timestamp = {Tue, 08 Feb 2022 10:43:29 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/YuanWKLWWL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Instrumental variables (IVs), sources of treatment randomization that are conditionally independent of the outcome, play an important role in causal inference with unobserved confounders. However, the existing IV-based counterfactual prediction methods need well-predefined IVs, while it’s an art rather than science to find valid IVs in many real-world scenes. Moreover, the predefined hand-made IVs could be weak or erroneous by violating the conditions of valid IVs. These thorny facts hinder the application of the IV-based counterfactual prediction methods. In this article, we propose a novel Automatic Instrumental Variable decomposition (AutoIV) algorithm to automatically generate representations serving the role of IVs from observed variables (IV candidates). Specifically, we let the learned IV representations satisfy the relevance condition with the treatment and exclusion condition with the outcome via mutual information maximization and minimization constraints, respectively. We also learn confounder representations by encouraging them to be relevant to both the treatment and the outcome. The IV and confounder representations compete for the information with their constraints in an adversarial game, which allows us to get valid IV representations for IV-based counterfactual prediction. Extensive experiments demonstrate that our method generates valid IV representations for accurate IV-based counterfactual prediction.}
}


@article{DBLP:journals/tkdd/BhatiaLHYSF22,
	author = {Siddharth Bhatia and
                  Rui Liu and
                  Bryan Hooi and
                  Minji Yoon and
                  Kijung Shin and
                  Christos Faloutsos},
	title = {Real-Time Anomaly Detection in Edge Streams},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {4},
	pages = {75:1--75:22},
	year = {2022},
	url = {https://doi.org/10.1145/3494564},
	doi = {10.1145/3494564},
	timestamp = {Tue, 08 Feb 2022 10:43:29 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/BhatiaLHYSF22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Given a stream of graph edges from a dynamic graph, how can we assign anomaly scores to edges in an online manner, for the purpose of detecting unusual behavior, using constant time and memory? Existing approaches aim to detect individually surprising edges. In this work, we propose Midas, which focuses on detecting microcluster anomalies, or suddenly arriving groups of suspiciously similar edges, such as lockstep behavior, including denial of service attacks in network traffic data. We further propose Midas-F, to solve the problem by which anomalies are incorporated into the algorithm’s internal states, creating a “poisoning” effect that can allow future anomalies to slip through undetected. Midas-F introduces two modifications: (1) we modify the anomaly scoring function, aiming to reduce the “poisoning” effect of newly arriving edges; (2) we introduce a conditional merge step, which updates the algorithm’s data structures after each time tick, but only if the anomaly score is below a threshold value, also to reduce the “poisoning” effect. Experiments show that Midas-F has significantly higher accuracy than Midas. In general, the algorithms proposed in this work have the following properties: (a) they detects microcluster anomalies while providing theoretical guarantees about the false positive probability; (b) they are online, thus processing each edge in constant time and constant memory, and also processes the data orders-of-magnitude faster than state-of-the-art approaches; and (c) they provides up to 62% higher area under the receiver operating characteristic curve than state-of-the-art approaches.}
}


@article{DBLP:journals/tkdd/SheshboloukiO22,
	author = {Aida Sheshbolouki and
                  M. Tamer {\"{O}}zsu},
	title = {sGrapp: Butterfly Approximation in Streaming Graphs},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {4},
	pages = {76:1--76:43},
	year = {2022},
	url = {https://doi.org/10.1145/3495011},
	doi = {10.1145/3495011},
	timestamp = {Mon, 28 Aug 2023 21:37:07 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/SheshboloukiO22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We study the fundamental problem of butterfly (i.e., (2,2)-bicliques) counting in bipartite streaming graphs. Similar to triangles in unipartite graphs, enumerating butterflies is crucial in understanding the structure of bipartite graphs. This benefits many applications where studying the cohesion in a graph shaped data is of particular interest. Examples include investigating the structure of computational graphs or input graphs to the algorithms, as well as dynamic phenomena and analytic tasks over complex real graphs. Butterfly counting is computationally expensive, and known techniques do not scale to large graphs; the problem is even harder in streaming graphs. In this article, following a data-driven methodology, we first conduct an empirical analysis to uncover temporal organizing principles of butterflies in real streaming graphs and then we introduce an approximate adaptive window-based algorithm, sGrapp, for counting butterflies as well as its optimized version sGrapp-x. sGrapp is designed to operate efficiently and effectively over any graph stream with any temporal behavior. Experimental studies of sGrapp and sGrapp-x show superior performance in terms of both accuracy and efficiency.}
}


@article{DBLP:journals/tkdd/WuN22,
	author = {Hanrui Wu and
                  Michael K. Ng},
	title = {Multiple Graphs and Low-Rank Embedding for Multi-Source Heterogeneous
                  Domain Adaptation},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {4},
	pages = {77:1--77:25},
	year = {2022},
	url = {https://doi.org/10.1145/3492804},
	doi = {10.1145/3492804},
	timestamp = {Wed, 03 Aug 2022 15:48:38 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/WuN22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Multi-source domain adaptation is a challenging topic in transfer learning, especially when the data of each domain are represented by different kinds of features, i.e., Multi-source Heterogeneous Domain Adaptation (MHDA). It is important to take advantage of the knowledge extracted from multiple sources as well as bridge the heterogeneous spaces for handling the MHDA paradigm. This article proposes a novel method named Multiple Graphs and Low-rank Embedding (MGLE), which models the local structure information of multiple domains using multiple graphs and learns the low-rank embedding of the target domain. Then, MGLE augments the learned embedding with the original target data. Specifically, we introduce the modules of both domain discrepancy and domain relevance into the multiple graphs and low-rank embedding learning procedure. Subsequently, we develop an iterative optimization algorithm to solve the resulting problem. We evaluate the effectiveness of the proposed method on several real-world datasets. Promising results show that the performance of MGLE is better than that of the baseline methods in terms of several metrics, such as AUC, MAE, accuracy, precision, F1 score, and MCC, demonstrating the effectiveness of the proposed method.}
}


@article{DBLP:journals/tkdd/ProkhorenkovaTL22,
	author = {Liudmila Prokhorenkova and
                  Alexey Tikhonov and
                  Nelly Litvak},
	title = {When Less Is More: Systematic Analysis of Cascade-Based Community
                  Detection},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {4},
	pages = {78:1--78:22},
	year = {2022},
	url = {https://doi.org/10.1145/3494563},
	doi = {10.1145/3494563},
	timestamp = {Tue, 08 Feb 2022 10:43:29 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/ProkhorenkovaTL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Information diffusion, spreading of infectious diseases, and spreading of rumors are fundamental processes occurring in real-life networks. In many practical cases, one can observe when nodes become infected, but the underlying network, over which a contagion or information propagates, is hidden. Inferring properties of the underlying network is important since these properties can be used for constraining infections, forecasting, viral marketing, and so on. Moreover, for many applications, it is sufficient to recover only coarse high-level properties of this network rather than all its edges. This article conducts a systematic and extensive analysis of the following problem: Given only the infection times, find communities of highly interconnected nodes. This task significantly differs from the well-studied community detection problem since we do not observe a graph to be clustered. We carry out a thorough comparison between existing and new approaches on several large datasets and cover methodological challenges specific to this problem. One of the main conclusions is that the most stable performance and the most significant improvement on the current state-of-the-art are achieved by our proposed simple heuristic approaches agnostic to a particular graph structure and epidemic model. We also show that some well-known community detection algorithms can be enhanced by including edge weights based on the cascade data.}
}


@article{DBLP:journals/tkdd/YangSYGL22,
	author = {Xu Yang and
                  Chao Song and
                  Mengdi Yu and
                  Jiqing Gu and
                  Ming Liu},
	title = {Distributed Triangle Approximately Counting Algorithms in Simple Graph
                  Stream},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {4},
	pages = {79:1--79:43},
	year = {2022},
	url = {https://doi.org/10.1145/3494562},
	doi = {10.1145/3494562},
	timestamp = {Mon, 25 Nov 2024 22:15:58 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/YangSYGL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recently, the counting algorithm of local topology structures, such as triangles, has been widely used in social network analysis, recommendation systems, user portraits and other fields. At present, the problem of counting global and local triangles in a graph stream has been widely studied, and numerous triangle counting steaming algorithms have emerged. To improve the throughput and scalability of streaming algorithms, many researches of distributed streaming algorithms on multiple machines are studied. In this article, we first propose a framework of distributed streaming algorithm based on the Master-Worker-Aggregator architecture. The two core parts of this framework are an edge distribution strategy, which plays a key role to affect the performance, including the communication overhead and workload balance, and aggregation method, which is critical to obtain the unbiased estimations of the global and local triangle counts in a graph stream. Then, we extend the state-of-the-art centralized algorithm TRIÈST into four distributed algorithms under our framework. Compared to their competitors, experimental results show that DVHT-i is excellent in accuracy and speed, performing better than the best existing distributed streaming algorithm. DEHT-b is the fastest algorithm and has the least communication overhead. What’s more, it almost achieves absolute workload balance.}
}


@article{DBLP:journals/tkdd/WuN22a,
	author = {Hanrui Wu and
                  Michael K. Ng},
	title = {Hypergraph Convolution on Nodes-Hyperedges Network for Semi-Supervised
                  Node Classification},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {4},
	pages = {80:1--80:19},
	year = {2022},
	url = {https://doi.org/10.1145/3494567},
	doi = {10.1145/3494567},
	timestamp = {Wed, 03 Aug 2022 15:48:38 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/WuN22a.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Hypergraphs have shown great power in representing high-order relations among entities, and lots of hypergraph-based deep learning methods have been proposed to learn informative data representations for the node classification problem. However, most of these deep learning approaches do not take full consideration of either the hyperedge information or the original relationships among nodes and hyperedges. In this article, we present a simple yet effective semi-supervised node classification method named Hypergraph Convolution on Nodes-Hyperedges network, which performs filtering on both nodes and hyperedges as well as recovers the original hypergraph with the least information loss. Instead of only reducing the cross-entropy loss over the labeled samples as most previous approaches do, we additionally consider the hypergraph reconstruction loss as prior information to improve prediction accuracy. As a result, by taking both the cross-entropy loss on the labeled samples and the hypergraph reconstruction loss into consideration, we are able to achieve discriminative latent data representations for training a classifier. We perform extensive experiments on the semi-supervised node classification problem and compare the proposed method with state-of-the-art algorithms. The promising results demonstrate the effectiveness of the proposed method.}
}


@article{DBLP:journals/tkdd/ShenOL22,
	author = {Yanyan Shen and
                  Baoyuan Ou and
                  Ranzhen Li},
	title = {{MBN:} Towards Multi-Behavior Sequence Modeling for Next Basket Recommendation},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {5},
	pages = {81:1--81:23},
	year = {2022},
	url = {https://doi.org/10.1145/3497748},
	doi = {10.1145/3497748},
	timestamp = {Thu, 09 Jun 2022 19:57:20 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/ShenOL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Next basket recommendation aims at predicting the next set of items that a user would likely purchase together, which plays an important role in e-commerce platforms. Unlike conventional item recommendation, the next basket recommendation focuses on capturing item correlations among baskets and learning the user’s temporal interest from the past purchasing basket sequence. In practice, most users interact with items in various kinds of behaviors. The multi-behavior data sheds light on user’s potential purchasing intention and resolves noisy signals from accidentally purchased items. In this article, we conduct an empirical study on real datasets to exploit the characteristics of multi-behavior data and confirm its positive effects on next basket recommendation. We develop a novel Multi-Behavior Network (MBN) model that captures item correlations and acquires meta-knowledge from multi-behavior basket sequences effectively. MBN employs the meta multi-behavior sequence encoder to model temporal dependencies of each individual behavior and extract meta-knowledge across different behaviors. Furthermore, we design the recurring-item-aware predictor in MBN to realize the high degree of the repeated occurrences of items, leading to better recommendation performance. We conduct extensive experiments to evaluate the performance of our proposed MBN model using real-world multi-behavior data. The results demonstrate the superior recommendation performance of MBN compared with various state-of-the-art methods.}
}


@article{DBLP:journals/tkdd/KeKB22,
	author = {Xiangyu Ke and
                  Arijit Khan and
                  Francesco Bonchi},
	title = {Multi-relation Graph Summarization},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {5},
	pages = {82:1--82:30},
	year = {2022},
	url = {https://doi.org/10.1145/3494561},
	doi = {10.1145/3494561},
	timestamp = {Tue, 21 Mar 2023 21:07:47 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/KeKB22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graph summarization is beneficial in a wide range of applications, such as visualization, interactive and exploratory analysis, approximate query processing, reducing the on-disk storage footprint, and graph processing in modern hardware. However, the bulk of the literature on graph summarization surprisingly overlooks the possibility of having edges of different types. In this article, we study the novel problem of producing summaries of multi-relation networks, i.e., graphs where multiple edges of different types may exist between any pair of nodes. Multi-relation graphs are an expressive model of real-world activities, in which a relation can be a topic in social networks, an interaction type in genetic networks, or a snapshot in temporal graphs. The first approach that we consider for multi-relation graph summarization is a two-step method based on summarizing each relation in isolation, and then aggregating the resulting summaries in some clever way to produce a final unique summary. In doing this, as a side contribution, we provide the first polynomial-time approximation algorithm based on the k-Median clustering for the classic problem of lossless single-relation graph summarization. Then, we demonstrate the shortcomings of these two-step methods, and propose holistic approaches, both approximate and heuristic algorithms, to compute a summary directly for multi-relation graphs. In particular, we prove that the approximation bound of k-Median clustering for the single relation solution can be maintained in a multi-relation graph with proper aggregation operation over adjacency matrices corresponding to its multiple relations. Experimental results and case studies (on co-authorship networks and brain networks) validate the effectiveness and efficiency of the proposed algorithms.}
}


@article{DBLP:journals/tkdd/ChenZYCCL22,
	author = {Weirong Chen and
                  Jiaqi Zheng and
                  Haoyu Yu and
                  Guihai Chen and
                  Yixin Chen and
                  Dongsheng Li},
	title = {Online Learning Bipartite Matching with Non-stationary Distributions},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {5},
	pages = {83:1--83:22},
	year = {2022},
	url = {https://doi.org/10.1145/3502734},
	doi = {10.1145/3502734},
	timestamp = {Wed, 22 Nov 2023 12:10:46 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/ChenZYCCL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Online bipartite matching has attracted wide interest since it can successfully model the popular online car-hailing problem and sharing economy. Existing works consider this problem under either adversary setting or i.i.d. setting. The former is too pessimistic to improve the performance in the general case; the latter is too optimistic to deal with the varying distribution of vertices. In this article, we initiate the study of the non-stationary online bipartite matching problem, which allows the distribution of vertices to vary with time and is more practical. We divide the non-stationary online bipartite matching problem into two subproblems, the matching problem and the selecting problem, and solve them individually. Combining Batch algorithms and deep Q-learning networks, we first construct a candidate algorithm set to solve the matching problem. For the selecting problem, we use a classical online learning algorithm, Exp3, as a selector algorithm and derive a theoretical bound. We further propose CDUCB as a selector algorithm by integrating distribution change detection into UCB. Rigorous theoretical analysis demonstrates that the performance of our proposed algorithms is no worse than that of any candidate algorithms in terms of competitive ratio. Finally, extensive experiments show that our proposed algorithms have much higher performance for the non-stationary online bipartite matching problem comparing to the state-of-the-art.}
}


@article{DBLP:journals/tkdd/IhouAB22,
	author = {Koffi Eddy Ihou and
                  Manar Amayri and
                  Nizar Bouguila},
	title = {Stochastic Variational Optimization of a Hierarchical Dirichlet Process
                  Latent Beta-Liouville Topic Model},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {5},
	pages = {84:1--84:48},
	year = {2022},
	url = {https://doi.org/10.1145/3502727},
	doi = {10.1145/3502727},
	timestamp = {Mon, 26 Jun 2023 20:57:03 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/IhouAB22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In topic models, collections are organized as documents where they arise as mixtures over latent clusters called topics. A topic is a distribution over the vocabulary. In large-scale applications, parametric or finite topic mixture models such as LDA (latent Dirichlet allocation) and its variants are very restrictive in performance due to their reduced hypothesis space. In this article, we address the problem related to model selection and sharing ability of topics across multiple documents in standard parametric topic models. We propose as an alternative a BNP (Bayesian nonparametric) topic model where the HDP (hierarchical Dirichlet process) prior models documents topic mixtures through their multinomials on infinite simplex. We, therefore, propose asymmetric BL (Beta-Liouville) as a diffuse base measure at the corpus level DP (Dirichlet process) over a measurable space. This step illustrates the highly heterogeneous structure in the set of all topics that describes the corpus probability measure. For consistency in posterior inference and predictive distributions, we efficiently characterize random probability measures whose limits are the global and local DPs to approximate the HDP from the stick-breaking formulation with the GEM (Griffiths-Engen-McCloskey) random variables. Due to the diffuse measure with the BL prior as conjugate to the count data distribution, we obtain an improved version of the standard HDP that is usually based on symmetric Dirichlet (Dir). In addition, to improve coordinate ascent framework while taking advantage of its deterministic nature, our model implements an online optimization method based on stochastic, at document level, variational inference to accommodate fast topic learning when processing large collections of text documents with natural gradient. The high value in the predictive likelihood per document obtained when compared to the performance of its competitors is also consistent with the robustness of our fully asymmetric BL-based HDP. While insuring the predictive accuracy of the model using the probability of the held-out documents, we also added a combination of metrics such as the topic coherence and topic diversity to improve the quality and interpretability of the topics discovered. We also compared the performance of our model using these metrics against the standard symmetric LDA. We show that online HDP-LBLA (Latent BL Allocation)’s performance is the asymptote for parametric topic models. The accuracy in the results (improved predictive distributions of the held out) is a product of the model’s ability to efficiently characterize dependency between documents (topic correlation) as now they can easily share topics, resulting in a much robust and realistic compression algorithm for information modeling.}
}


@article{DBLP:journals/tkdd/DavvetasKSK22,
	author = {Athanasios Davvetas and
                  Iraklis A. Klampanos and
                  Spiros Skiadopoulos and
                  Vangelis Karkaletsis},
	title = {Evidence Transfer: Learning Improved Representations According to
                  External Heterogeneous Task Outcomes},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {5},
	pages = {85:1--85:22},
	year = {2022},
	url = {https://doi.org/10.1145/3502732},
	doi = {10.1145/3502732},
	timestamp = {Wed, 07 Dec 2022 23:04:50 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/DavvetasKSK22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Unsupervised representation learning tends to produce generic and reusable latent representations. However, these representations can often miss high-level features or semantic information, since they only observe the implicit properties of the dataset. On the other hand, supervised learning frameworks learn task-oriented latent representations that may not generalise in other tasks or domains. In this article, we introduce evidence transfer, a deep learning method that incorporates the outcomes of external tasks in the unsupervised learning process of an autoencoder. External task outcomes also referred to as categorical evidence, are represented by categorical variables, and are either directly or indirectly related to the primary dataset—in the most straightforward case they are the outcome of another task on the same dataset. Evidence transfer allows the manipulation of generic latent representations in order to include domain or task-specific knowledge that will aid their effectiveness in downstream tasks. Evidence transfer is robust against evidence of low quality and effective when introduced with related, corresponding, or meaningful evidence.}
}


@article{DBLP:journals/tkdd/Varde22,
	author = {Aparna S. Varde},
	title = {Computational Estimation by Scientific Data Mining with Classical
                  Methods to Automate Learning Strategies of Scientists},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {5},
	pages = {86:1--86:52},
	year = {2022},
	url = {https://doi.org/10.1145/3502736},
	doi = {10.1145/3502736},
	timestamp = {Mon, 28 Aug 2023 21:37:08 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/Varde22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Experimental results are often plotted as 2-dimensional graphical plots (aka graphs) in scientific domains depicting dependent versus independent variables to aid visual analysis of processes. Repeatedly performing laboratory experiments consumes significant time and resources, motivating the need for computational estimation. The goals are to estimate the graph obtained in an experiment given its input conditions, and to estimate the conditions that would lead to a desired graph. Existing estimation approaches often do not meet accuracy and efficiency needs of targeted applications. We develop a computational estimation approach called AutoDomainMine that integrates clustering and classification over complex scientific data in a framework so as to automate classical learning methods of scientists. Knowledge discovered thereby from a database of existing experiments serves as the basis for estimation. Challenges include preserving domain semantics in clustering, finding matching strategies in classification, striking a good balance between elaboration and conciseness while displaying estimation results based on needs of targeted users, and deriving objective measures to capture subjective user interests. These and other challenges are addressed in this work. The AutoDomainMine approach is used to build a computational estimation system, rigorously evaluated with real data in Materials Science. Our evaluation confirms that AutoDomainMine provides desired accuracy and efficiency in computational estimation. It is extendable to other science and engineering domains as proved by adaptation of its sub-processes within fields such as Bioinformatics and Nanotechnology.}
}


@article{DBLP:journals/tkdd/ZhouZYW22,
	author = {Peng Zhou and
                  Shu Zhao and
                  Yuan{-}Ting Yan and
                  Xindong Wu},
	title = {Online Scalable Streaming Feature Selection via Dynamic Decision},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {5},
	pages = {87:1--87:20},
	year = {2022},
	url = {https://doi.org/10.1145/3502737},
	doi = {10.1145/3502737},
	timestamp = {Mon, 28 Aug 2023 21:37:08 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/ZhouZYW22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Feature selection is one of the core concepts in machine learning, which hugely impacts the model’s performance. For some real-world applications, features may exist in a stream mode that arrives one by one over time, while we cannot know the exact number of features before learning. Online streaming feature selection aims at selecting optimal stream features at each timestamp on the fly. Without the global information of the entire feature space, most of the existing methods select stream features in terms of individual feature information or the comparison of features in pairs. This article proposes a new online scalable streaming feature selection framework from the dynamic decision perspective that is scalable on running time and selected features by dynamic threshold adjustment. Regarding the philosophy of “Thinking-in-Threes”, we classify each new arrival feature as selecting, discarding, or delaying, aiming at minimizing the overall decision risks. With the dynamic updating of global statistical information, we add the selecting features into the candidate feature subset, ignore the discarding features, cache the delaying features into the undetermined feature subset, and wait for more information. Meanwhile, we perform the redundancy analysis for the candidate features and uncertainty analysis for the undetermined features. Extensive experiments on eleven real-world datasets demonstrate the efficiency and scalability of our new framework compared with state-of-the-art algorithms.}
}


@article{DBLP:journals/tkdd/PoojaMC22,
	author = {K. M. Pooja and
                  Samrat Mondal and
                  Joydeep Chandra},
	title = {Exploiting Higher Order Multi-dimensional Relationships with Self-attention
                  for Author Name Disambiguation},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {5},
	pages = {88:1--88:23},
	year = {2022},
	url = {https://doi.org/10.1145/3502730},
	doi = {10.1145/3502730},
	timestamp = {Thu, 09 Jun 2022 19:57:20 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/PoojaMC22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Name ambiguity is a prevalent problem in scholarly publications due to the unprecedented growth of digital libraries and number of researchers. An author is identified by their name in the absence of a unique identifier. The documents of an author are mistakenly assigned due to underlying ambiguity, which may lead to an improper assessment of the author. Various efforts have been made in the literature to solve the name disambiguation problem with supervised and unsupervised approaches. The unsupervised approaches for author name disambiguation are preferred due to the availability of a large amount of unlabeled data. Bibliographic data contain heterogeneous features, thus recently, representation learning-based techniques have been used in literature to embed heterogeneous features in common space. Documents of a scholar are connected by multiple relations. Recently, research has shifted from a single homogeneous relation to multi-dimensional (heterogeneous) relations for the latent representation of document. Connections in graphs are sparse, and higher order links between documents give an additional clue. Therefore, we have used multiple neighborhoods in different relation types in heterogeneous graph for representation of documents. However, different order neighborhood in each relation type has different importance which we have empirically validated also. Therefore, to properly utilize the different neighborhoods in relation type and importance of each relation type in the heterogeneous graph, we propose attention-based multi-dimensional multi-hop neighborhood-based graph convolution network for embedding that uses the two levels of an attention, namely, (i) relation level and (ii) neighborhood level, in each relation. A significant improvement over existing state-of-the-art methods in terms of various evaluation matrices has been obtained by the proposed approach.}
}


@article{DBLP:journals/tkdd/PeiXWXLLLW22,
	author = {Shuyu Pei and
                  Kun Xie and
                  Xin Wang and
                  Gaogang Xie and
                  Kenli Li and
                  Wei Li and
                  Yanbiao Li and
                  Jigang Wen},
	title = {B\({}_{\mbox{\emph{h}}}\)BF: {A} Bloom Filter Using B\({}_{\mbox{\emph{h}}}\)
                  Sequences for Multi-set Membership Query},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {5},
	pages = {89:1--89:26},
	year = {2022},
	url = {https://doi.org/10.1145/3502735},
	doi = {10.1145/3502735},
	timestamp = {Thu, 09 Jun 2022 19:57:20 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/PeiXWXLLLW22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Multi-set membership query is a fundamental issue for network functions such as packet processing and state machines monitoring. Given the rigid query speed and memory requirements, it would be promising if a multi-set query algorithm can be designed based on Bloom filter (BF), a space-efficient probabilistic data structure. However, existing efforts on multi-set query based on BF suffer from at least one of the following drawbacks: low query speed, low query accuracy, limitation in only supporting insertion and query operations, or limitation in the set size. To address the issues, we design a novel Bh sequence-based Bloom filter (BhBF) for multi-set query, which supports four operations: insertion, query, deletion, and update. In BhBF, the set ID is encoded as a code in a Bh sequence. Exploiting good properties of Bh sequences, we can correctly decode the BF cells to obtain the set IDs even when the number of hash collisions is high, which brings high query accuracy. In BhBF, we propose two strategies to further speed up the query speed and increase the query accuracy. On the theoretical side, we analyze the false positive and classification failure rate of our BhBF. Our results from extensive experiments over two real datasets demonstrate that BhBF significantly advances state-of-the-art multi-set query algorithms.}
}


@article{DBLP:journals/tkdd/ChenS22,
	author = {Ling Chen and
                  Hongyu Shi},
	title = {DexDeepFM: Ensemble Diversity Enhanced Extreme Deep Factorization
                  Machine Model},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {5},
	pages = {90:1--90:17},
	year = {2022},
	url = {https://doi.org/10.1145/3505272},
	doi = {10.1145/3505272},
	timestamp = {Mon, 28 Aug 2023 21:37:07 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/ChenS22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Predicting user positive response (e.g., purchases and clicks) probability is a critical task in Web applications. To identify predictive features from raw data, the state-of-the-art extreme deep factorization machine model (xDeepFM) introduces a new interaction network to leverage feature interactions at the vector-wise level explicitly. However, since each hidden layer in the interaction network is a collection of feature maps, it can be viewed essentially as an ensemble of different feature maps. In this case, only using a single objective to minimize the prediction loss may lead to overfitting and generate correlated errors. In this article, an ensemble diversity enhanced extreme deep factorization machine model (DexDeepFM) is proposed, which designs the ensemble diversity measure in each hidden layer and considers both ensemble diversity and prediction accuracy in the objective function. In addition, the attention mechanism is introduced to discriminate the importance of ensemble diversity measures with different feature interaction orders. Extensive experiments on three public real-world datasets are conducted to show the effectiveness of the proposed model.}
}


@article{DBLP:journals/tkdd/SinghCCM22,
	author = {Shikha Singh and
                  Emilie Chouzenoux and
                  Giovanni Chierchia and
                  Angshul Majumdar},
	title = {Multi-label Deep Convolutional Transform Learning for Non-intrusive
                  Load Monitoring},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {5},
	pages = {91:1--91:6},
	year = {2022},
	url = {https://doi.org/10.1145/3502729},
	doi = {10.1145/3502729},
	timestamp = {Mon, 27 May 2024 22:16:32 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/SinghCCM22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The objective of this letter is to propose a novel computational method to learn the state of an appliance (ON / OFF) given the aggregate power consumption recorded by the smart-meter. We formulate a multi-label classification problem where the classes correspond to the appliances. The proposed approach is based on our recently introduced framework of convolutional transform learning. We propose a deep supervised version of it relying on an original multi-label cost. Comparisons with state-of-the-art techniques show that our proposed method improves over the benchmarks on popular non-intrusive load monitoring datasets.}
}


@article{DBLP:journals/tkdd/SatoYK22,
	author = {Ryoma Sato and
                  Makoto Yamada and
                  Hisashi Kashima},
	title = {Constant Time Graph Neural Networks},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {5},
	pages = {92:1--92:31},
	year = {2022},
	url = {https://doi.org/10.1145/3502733},
	doi = {10.1145/3502733},
	timestamp = {Mon, 26 Jun 2023 20:57:03 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/SatoYK22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The recent advancements in graph neural networks (GNNs) have led to state-of-the-art performances in various applications, including chemo-informatics, question-answering systems, and recommender systems. However, scaling up these methods to huge graphs, such as social networks and Web graphs, remains a challenge. In particular, the existing methods for accelerating GNNs either are not theoretically guaranteed in terms of the approximation error or incurred at least a linear time computation cost. In this study, we reveal the query complexity of the uniform node sampling scheme for Message Passing Neural Networks, including GraphSAGE, graph attention networks (GATs), and graph convolutional networks (GCNs). Surprisingly, our analysis reveals that the complexity of the node sampling method is completely independent of the number of the nodes, edges, and neighbors of the input and depends only on the error tolerance and confidence probability while providing a theoretical guarantee for the approximation error. To the best of our knowledge, this is the first article to provide a theoretical guarantee of approximation for GNNs within constant time. Through experiments with synthetic and real-world datasets, we investigated the speed and precision of the node sampling scheme and validated our theoretical results.}
}


@article{DBLP:journals/tkdd/LingYLLZW22,
	author = {Zhaolong Ling and
                  Kui Yu and
                  Lin Liu and
                  Jiuyong Li and
                  Yiwen Zhang and
                  Xindong Wu},
	title = {{PSL:} An Algorithm for Partial Bayesian Network Structure Learning},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {5},
	pages = {93:1--93:25},
	year = {2022},
	url = {https://doi.org/10.1145/3508071},
	doi = {10.1145/3508071},
	timestamp = {Mon, 28 Aug 2023 21:37:08 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/LingYLLZW22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Learning partial Bayesian network (BN) structure is an interesting and challenging problem. In this challenge, it is computationally expensive to use global BN structure learning algorithms, while only one part of a BN structure is interesting, local BN structure learning algorithms are not a favourable solution either due to the issue of false edge orientation. To address the problem, this article first presents a detailed analysis of the false edge orientation issue with local BN structure learning algorithms and then proposes PSL, an efficient and accurate Partial BN Structure Learning (PSL) algorithm. Specifically, PSL divides V-structures in a Markov blanket (MB) into two types: Type-C V-structures and Type-NC V-structures, then it starts from the given node of interest and recursively finds both types of V-structures in the MB of the current node until all edges in the partial BN structure are oriented. To further improve the efficiency of PSL, the PSL-FS algorithm is designed by incorporating Feature Selection (FS) into PSL. Extensive experiments with six benchmark BNs validate the efficiency and accuracy of the proposed algorithms.}
}


@article{DBLP:journals/tkdd/SharmaMS22,
	author = {Promila Sharma and
                  Uma Meena and
                  Girish Kumar Sharma},
	title = {Intelligent Data Analysis using Optimized Support Vector Machine Based
                  Data Mining Approach for Tourism Industry},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {5},
	pages = {94:1--94:20},
	year = {2022},
	url = {https://doi.org/10.1145/3494566},
	doi = {10.1145/3494566},
	timestamp = {Mon, 28 Aug 2023 21:37:08 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/SharmaMS22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Data analysis involves the deployment of sophisticated approaches from data mining methods, information theory, and artificial intelligence in various fields like tourism, hospitality, and so on for the extraction of knowledge from the gathered and preprocessed data. In tourism, pattern analysis or data analysis using classification is significant for finding the patterns that represent new and potentially useful information or knowledge about the destination and other data. Several data mining techniques are introduced for the classification of data or patterns. However, overfitting, less accuracy, local minima, sensitive to noise are the drawbacks in some existing data mining classification methods. To overcome these challenges, Support vector machine with Red deer optimization (SVM-RDO) based data mining strategy is proposed in this article. Extended Kalman filter (EKF) is utilized in the first phase, i.e., data cleaning to remove the noise and missing values from the input data. Mantaray foraging algorithm (MaFA) is used in the data selection phase, in which the significant data are selected for the further process to reduce the computational complexity. The final phase is the classification, in which SVM-RDO is proposed to access the useful pattern from the selected data. PYTHON is the implementation tool used for the experiment of the proposed model. The experimental analysis is done to show the efficacy of the proposed work. From the experimental results, the proposed SVM-RDO achieved better accuracy, precision, recall, and F1 score than the existing methods for the tourism dataset. Thus, it is showed the effectiveness of the proposed SVM-RDO for pattern analysis.}
}


@article{DBLP:journals/tkdd/HuaiZMYZ22,
	author = {Mengdi Huai and
                  Tianhang Zheng and
                  Chenglin Miao and
                  Liuyi Yao and
                  Aidong Zhang},
	title = {On the Robustness of Metric Learning: An Adversarial Perspective},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {5},
	pages = {95:1--95:25},
	year = {2022},
	url = {https://doi.org/10.1145/3502726},
	doi = {10.1145/3502726},
	timestamp = {Sat, 30 Sep 2023 10:29:07 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/HuaiZMYZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Metric learning aims at automatically learning a distance metric from data so that the precise similarity between data instances can be faithfully reflected, and its importance has long been recognized in many fields. An implicit assumption in existing metric learning works is that the learned models are performed in a reliable and secure environment. However, the increasingly critical role of metric learning makes it susceptible to a risk of being malicious attacked. To well understand the performance of metric learning models in adversarial environments, in this article, we study the robustness of metric learning to adversarial perturbations, which are also known as the imperceptible changes to the input data that are crafted by an attacker to fool a well-learned model. However, different from traditional classification models, metric learning models take instance pairs rather than individual instances as input, and the perturbation on one instance may not necessarily affect the prediction result for an instance pair, which makes it more difficult to study the robustness of metric learning. To address this challenge, in this article, we first provide a definition of pairwise robustness for metric learning, and then propose a novel projected gradient descent-based attack method (called AckMetric) to evaluate the robustness of metric learning models. To further explore the capability of the attacker to change the prediction results, we also propose a theoretical framework to derive the upper bound of the pairwise adversarial loss. Finally, we incorporate the derived bound into the training process of metric learning and design a novel defense method to make the learned models more robust. Extensive experiments on real-world datasets demonstrate the effectiveness of the proposed methods.}
}


@article{DBLP:journals/tkdd/QiuHW22,
	author = {Zhaopeng Qiu and
                  Yunfan Hu and
                  Xian Wu},
	title = {Graph Neural News Recommendation with User Existing and Potential
                  Interest Modeling},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {5},
	pages = {96:1--96:17},
	year = {2022},
	url = {https://doi.org/10.1145/3511708},
	doi = {10.1145/3511708},
	timestamp = {Tue, 09 Jul 2024 15:32:27 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/QiuHW22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Personalized news recommendations can alleviate the information overload problem. To enable personalized recommendation, one critical step is to learn a comprehensive user representation to model her/his interests. Many existing works learn user representations from the historical clicked news articles, which reflect their existing interests. However, these approaches ignore users’ potential interests and pay less attention to news that may interest the users in the future. To address this problem, we propose a novel Graph neural news Recommendation model with user Existing and Potential interest modeling, named GREP. Different from existing works, GREP introduces three modules to jointly model users’ existing and potential interests: (1) Existing Interest Encoding module mines user historical clicked news and applies the multi-head self-attention mechanism to capture the relatedness among the news; (2) Potential Interest Encoding module leverages the graph neural network to explore the user potential interests on the knowledge graph; and (3) Bi-directional Interaction module dynamically builds a news-entity bipartite graph to further enrich two interest representations. Finally, GREP combines the existing and potential interest representations to represent the user and leverages a prediction layer to estimate the clicking probability of the candidate news. Experiments on two real-world large-scale datasets demonstrate the state-of-the-art performance of GREP.}
}


@article{DBLP:journals/tkdd/GoelLMW22,
	author = {Kanika Goel and
                  Sander J. J. Leemans and
                  Niels Martin and
                  Moe Thandar Wynn},
	title = {Quality-Informed Process Mining: {A} Case for Standardised Data Quality
                  Annotations},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {5},
	pages = {97:1--97:47},
	year = {2022},
	url = {https://doi.org/10.1145/3511707},
	doi = {10.1145/3511707},
	timestamp = {Mon, 28 Aug 2023 21:37:08 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/GoelLMW22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Real-life event logs, reflecting the actual executions of complex business processes, are faced with numerous data quality issues. Extensive data sanity checks and pre-processing are usually needed before historical data can be used as input to obtain reliable data-driven insights. However, most of the existing algorithms in process mining, a field focusing on data-driven process analysis, do not take any data quality issues or the potential effects of data pre-processing into account explicitly. This can result in erroneous process mining results, leading to inaccurate, or misleading conclusions about the process under investigation. To address this gap, we propose data quality annotations for event logs, which can be used by process mining algorithms to generate quality-informed insights. Using a design science approach, requirements are formulated, which are leveraged to propose data quality annotations. Moreover, we present the “Quality-Informed visual Miner” plug-in to demonstrate the potential utility and impact of data quality annotations. Our experimental results, utilising both synthetic and real-life event logs, show how the use of data quality annotations by process mining techniques can assist in increasing the reliability of performance analysis results.}
}


@article{DBLP:journals/tkdd/LiuGZZYDX22,
	author = {Hao Liu and
                  Qingyu Guo and
                  Hengshu Zhu and
                  Fuzhen Zhuang and
                  Shenwen Yang and
                  Dejing Dou and
                  Hui Xiong},
	title = {Who will Win the Data Science Competition? Insights from {KDD} Cup
                  2019 and Beyond},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {5},
	pages = {98:1--98:24},
	year = {2022},
	url = {https://doi.org/10.1145/3511896},
	doi = {10.1145/3511896},
	timestamp = {Mon, 28 Aug 2023 21:37:07 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/LiuGZZYDX22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Data science competitions are becoming increasingly popular for enterprises collecting advanced innovative solutions and allowing contestants to sharpen their data science skills. Most existing studies about data science competitions have a focus on improving task-specific data science techniques, such as algorithm design and parameter tuning. However, little effort has been made to understand the data science competition itself. To this end, in this article, we shed light on the team’s competition performance, and investigate the team’s evolving performance in the crowd-sourcing competitive innovation context. Specifically, we first acquire and construct multi-sourced datasets of various data science competitions, including the KDD Cup 2019 machine learning competition and beyond. Then, we conduct an empirical analysis to identify and quantify a rich set of features that are significantly correlated with teams’ future performances. By leveraging team’s rank as a proxy, we observe “the stronger, the stronger” rule; that is, top-ranked teams tend to keep their advantages and dominate weaker teams for the rest of the competition. Our results also confirm that teams with diversified backgrounds tend to achieve better performances. After that, we formulate the team’s future rank prediction problem and propose the Multi-Task Representation Learning\xa0(MTRL) framework to model both static features and dynamic features. Extensive experimental results on four real-world data science competitions demonstrate the team’s future performance can be well predicted by using MTRL. Finally, we envision our study will not only help competition organizers to understand the competition in a better way, but also provide strategic implications to contestants, such as guiding the team formation and designing the submission strategy.}
}


@article{DBLP:journals/tkdd/OliveiraGZ22,
	author = {Saullo H. G. Oliveira and
                  Andr{\'{e}} R. Gon{\c{c}}alves and
                  Fernando J. Von Zuben},
	title = {Asymmetric Multi-Task Learning with Local Transference},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {5},
	pages = {99:1--99:30},
	year = {2022},
	url = {https://doi.org/10.1145/3514252},
	doi = {10.1145/3514252},
	timestamp = {Mon, 13 Jun 2022 20:56:44 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/OliveiraGZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this article, we present the Group Asymmetric Multi-Task Learning (GAMTL) algorithm that automatically learns from data how tasks transfer information among themselves at the level of a subset of features. In practice, for each group of features GAMTL extracts an asymmetric relationship supported by the tasks, instead of assuming a single structure for all features. The additional flexibility promoted by local transference in GAMTL allows any two tasks to have multiple asymmetric relationships. The proposed method leverages the information present in these multiple structures to bias the training of individual tasks towards more generalizable models. The solution to the GAMTL’s associated optimization problem is an alternating minimization procedure involving tasks parameters and multiple asymmetric relationships, thus guiding to convex smaller sub-problems. GAMTL was evaluated on both synthetic and real datasets. To evidence GAMTL versatility, we generated a synthetic scenario characterized by diverse profiles of structural relationships among tasks. GAMTL was also applied to the problem of Alzheimer’s Disease (AD) progression prediction. Our experiments indicated that the proposed approach not only increased prediction performance, but also estimated scientifically grounded relationships among multiple cognitive scores, taken here as multiple regression tasks, and regions of interest in the brain, directly associated here with groups of features. We also employed stability selection analysis to investigate GAMTL’s robustness to data sampling rate and hyper-parameter configuration. GAMTL source code is available on GitHub: https://github.com/shgo/gamtl.}
}


@article{DBLP:journals/tkdd/ZhongSM22,
	author = {Sheng Zhong and
                  Vin{\'{\i}}cius M. A. de Souza and
                  Abdullah Mueen},
	title = {Combining Filtering and Cross-Correlation Efficiently for Streaming
                  Time Series},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {5},
	pages = {100:1--100:24},
	year = {2022},
	url = {https://doi.org/10.1145/3502738},
	doi = {10.1145/3502738},
	timestamp = {Sat, 07 Sep 2024 13:34:29 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/ZhongSM22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Monitoring systems have hundreds or thousands of distributed sensors gathering and transmitting real-time streaming data. The early detection of events in these systems, such as an earthquake in a seismic monitoring system, is the base for essential tasks as warning generations. To detect such events is usual to compute pairwise correlation across the disparate signals generated by the sensors. Since the data sources (e.g., sensors) are spatially separated, it is essential to consider the lagged correlation between the signals. Besides, many applications require to process a specific band of frequencies depending on the event’s type, demanding a pre-processing step of filtering before computing correlations. Due to the high speed of data generation and a large number of sensors in these systems, the operations of filtering and lagged cross-correlation need to be efficient to provide real-time responses without data losses. This article proposes a technique named FilCorr that efficiently computes both operations in one single step. We achieve an order of magnitude speedup by maintaining frequency transforms over sliding windows. Our method is exact, devoid of sensitive parameters, and easily parallelizable. Besides our algorithm, we also provide a publicly available real-time system named Seisviz that employs FilCorr in its core mechanism for monitoring a seismometer network. We demonstrate that our technique is suitable for several monitoring applications as seismic signal monitoring, motion monitoring, and neural activity monitoring.}
}


@article{DBLP:journals/tkdd/JirinaK22,
	author = {Marcel Jirina and
                  Said Krayem},
	title = {The Distance Function Optimization for the Near Neighbors-Based Classifiers},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {6},
	pages = {101:1--101:21},
	year = {2022},
	url = {https://doi.org/10.1145/3434769},
	doi = {10.1145/3434769},
	timestamp = {Mon, 28 Aug 2023 21:37:07 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/JirinaK22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Based on the analysis of conditions for a good distance function we found four rules that should be fulfilled. Then, we introduce two new distance functions, a metric and a pseudometric one. We have tested how they fit for distance-based classifiers, especially for the IINC classifier. We rank distance functions according to several criteria and tests. Rankings depend not only on criteria or nature of the statistical test, but also whether it takes into account different difficulties of tasks or whether it considers all tasks as equally difficult. We have found that the new distance functions introduced belong among the four or five best out of 23 distance functions. We have tested them on 24 different tasks, using the mean, the median, the Friedman aligned test, and the Quade test. Our results show that a suitable distance function can improve behavior of distance-based classification rules.}
}


@article{DBLP:journals/tkdd/TeyWC22,
	author = {Fu Jie Tey and
                  Tin{-}Yu Wu and
                  Jiann{-}Liang Chen},
	title = {Machine Learning-based Short-term Rainfall Prediction from Sky Data},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {6},
	pages = {102:1--102:18},
	year = {2022},
	url = {https://doi.org/10.1145/3502731},
	doi = {10.1145/3502731},
	timestamp = {Mon, 28 Aug 2023 21:37:08 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/TeyWC22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {To predict rainfall, our proposed model architecture combines the Convolutional Neural Network (CNN), which uses the ResNet-152 pre-training model, with the Recurrent Neural Network (RNN), which uses the Long Short-term Memory Network (LSTM) layer, for model training. By encoding the cloud images through CNN, we extract the image feature vectors in the training process and train the vectors and meteorological data as the input of RNN. After training, the accuracy of the prediction model can reach up to 82%. The result has proven not only the outperformance of our proposed rainfall prediction method in terms of cost and prediction time, but also its accuracy and feasibility compared with general prediction methods.}
}


@article{DBLP:journals/tkdd/MahmoudH22,
	author = {Reem A. Mahmoud and
                  Hazem M. Hajj},
	title = {Multi-objective Learning to Overcome Catastrophic Forgetting in Time-series
                  Applications},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {6},
	pages = {103:1--103:20},
	year = {2022},
	url = {https://doi.org/10.1145/3502728},
	doi = {10.1145/3502728},
	timestamp = {Mon, 05 Dec 2022 13:35:30 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/MahmoudH22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {One key objective of artificial intelligence involves the continuous adaptation of machine learning models to new tasks. This branch of continual learning is also referred to as lifelong learning (LL), where a major challenge is to minimize catastrophic forgetting, or forgetting previously learned tasks. While previous work on catastrophic forgetting has been focused on vision problems; this work targets time-series data. In addition to choosing an architecture appropriate for time-series sequences, our work addresses limitations in previous work, including the handling of distribution shifts in class labels. We present multi-objective learning with three loss functions to minimize catastrophic forgetting, prediction error, and errors in generalizing across label shifts, simultaneously. We build a multi-task autoencoder network with a hierarchical convolutional recurrent architecture. The proposed method is capable of learning multiple time-series tasks simultaneously. For cases where the model needs to learn multiple new tasks, we propose sequential learning, starting with tasks that have the best individual performances. This solution was evaluated on four benchmark human activity recognition datasets collected from mobile sensing devices. A wide set of baseline comparisons is performed, and an ablation analysis is run to evaluate the impact of the different losses in the proposed multi-objective method. The results demonstrate an up to 4% performance improvement in catastrophic forgetting compared to the use of loss functions in state-of-the-art solutions while demonstrating minimal losses compared to upper bound methods of traditional fine-tuning (FT) and multi-task learning (MTL).}
}


@article{DBLP:journals/tkdd/WangZZLWL22,
	author = {Zhaobo Wang and
                  Yanmin Zhu and
                  Qiaomei Zhang and
                  Haobing Liu and
                  Chunyang Wang and
                  Tong Liu},
	title = {Graph-Enhanced Spatial-Temporal Network for Next {POI} Recommendation},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {6},
	pages = {104:1--104:21},
	year = {2022},
	url = {https://doi.org/10.1145/3513092},
	doi = {10.1145/3513092},
	timestamp = {Tue, 17 Dec 2024 16:16:32 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/WangZZLWL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The task of next Point-of-Interest (POI) recommendation aims at recommending a list of POIs for a user to visit at the next timestamp based on his/her previous interactions, which is valuable for both location-based service providers and users. Recent state-of-the-art studies mainly employ recurrent neural network (RNN) based methods to model user check-in behaviors according to user’s historical check-in sequences. However, most of the existing RNN-based methods merely capture geographical influences depending on physical distance or successive relation among POIs. They are insufficient to capture the high-order complex geographical influences among POI networks, which are essential for estimating user preferences. To address this limitation, we propose a novel Graph-based Spatial Dependency modeling (GSD) module, which focuses on explicitly modeling complex geographical influences by leveraging graph embedding. GSD captures two types of geographical influences, i.e., distance-based and transition-based influences from designed POI semantic graphs. Additionally, we propose a novel Graph-enhanced Spatial-Temporal network (GSTN), which incorporates user spatial and temporal dependencies for next POI recommendation. Specifically, GSTN consists of a Long Short-Term Memory (LSTM) network for user-specific temporal dependencies modeling and GSD for user spatial dependencies learning. Finally, we evaluate the proposed model using three real-world datasets. Extensive experiments demonstrate the effectiveness of GSD in capturing various geographical influences and the improvement of GSTN over state-of-the-art methods.}
}


@article{DBLP:journals/tkdd/TipirneniR22,
	author = {Sindhu Tipirneni and
                  Chandan K. Reddy},
	title = {Self-Supervised Transformer for Sparse and Irregularly Sampled Multivariate
                  Clinical Time-Series},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {6},
	pages = {105:1--105:17},
	year = {2022},
	url = {https://doi.org/10.1145/3516367},
	doi = {10.1145/3516367},
	timestamp = {Mon, 05 Dec 2022 13:35:29 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/TipirneniR22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Multivariate time-series data are frequently observed in critical care settings and are typically characterized by sparsity (missing information) and irregular time intervals. Existing approaches for learning representations in this domain handle these challenges by either aggregation or imputation of values, which in-turn suppresses the fine-grained information and adds undesirable noise/overhead into the machine learning model. To tackle this problem, we propose a Self-supervised Transformer for Time-Series (STraTS) model, which overcomes these pitfalls by treating time-series as a set of observation triplets instead of using the standard dense matrix representation. It employs a novel Continuous Value Embedding technique to encode continuous time and variable values without the need for discretization. It is composed of a Transformer component with multi-head attention layers, which enable it to learn contextual triplet embeddings while avoiding the problems of recurrence and vanishing gradients that occur in recurrent architectures. In addition, to tackle the problem of limited availability of labeled data (which is typically observed in many healthcare applications), STraTS utilizes self-supervision by leveraging unlabeled data to learn better representations by using time-series forecasting as an auxiliary proxy task. Experiments on real-world multivariate clinical time-series benchmark datasets demonstrate that STraTS has better prediction performance than state-of-the-art methods for mortality prediction, especially when labeled data is limited. Finally, we also present an interpretable version of STraTS, which can identify important measurements in the time-series data. Our data preprocessing and model implementation codes are available at https://github.com/sindhura97/STraTS.}
}


@article{DBLP:journals/tkdd/GuQH22,
	author = {Shilin Gu and
                  Yuhua Qian and
                  Chenping Hou},
	title = {Incremental Feature Spaces Learning with Label Scarcity},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {6},
	pages = {106:1--106:26},
	year = {2022},
	url = {https://doi.org/10.1145/3516368},
	doi = {10.1145/3516368},
	timestamp = {Mon, 05 Dec 2022 13:35:30 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/GuQH22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recently, learning and mining from data streams with incremental feature spaces have attracted extensive attention, where data may dynamically expand over time in both volume and feature dimensions. Existing approaches usually assume that the incoming instances can always receive true labels. However, in many real-world applications, e.g., environment monitoring, acquiring the true labels is costly due to the need of human effort in annotating the data. To tackle this problem, we propose a novel incremental Feature spaces Learning with Label Scarcity (FLLS) algorithm, together with its two variants. When data streams arrive with augmented features, we first leverage the margin-based online active learning to select valuable instances to be labeled and thus build superior predictive models with minimal supervision. After receiving the labels, we combine the online passive-aggressive update rule and margin-maximum principle to jointly update the dynamic classifier in the shared and augmented feature space. Finally, we use the projected truncation technique to build a sparse but efficient model. We theoretically analyze the error bounds of FLLS and its two variants. Also, we conduct experiments on synthetic data and real-world applications to further validate the effectiveness of our proposed algorithms.}
}


@article{DBLP:journals/tkdd/LiSLCWL22,
	author = {Zhe Li and
                  Chunhua Sun and
                  Chunli Liu and
                  Xiayu Chen and
                  Meng Wang and
                  Yezheng Liu},
	title = {Dual-MGAN: An Efficient Approach for Semi-supervised Outlier Detection
                  with Few Identified Anomalies},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {6},
	pages = {107:1--107:30},
	year = {2022},
	url = {https://doi.org/10.1145/3522690},
	doi = {10.1145/3522690},
	timestamp = {Mon, 05 Dec 2022 13:35:30 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/LiSLCWL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Outlier detection is an important task in data mining, and many technologies for it have been explored in various applications. However, owing to the default assumption that outliers are not concentrated, unsupervised outlier detection may not correctly identify group anomalies with higher levels of density. Although high detection rates and optimal parameters can usually be achieved by using supervised outlier detection, obtaining a sufficient number of correct labels is a time-consuming task. To solve these problems, we focus on semi-supervised outlier detection with few identified anomalies and a large amount of unlabeled data. The task of semi-supervised outlier detection is first decomposed into the detection of discrete anomalies and that of partially identified group anomalies, and a distribution construction sub-module and a data augmentation sub-module are then proposed to identify them, respectively. In this way, the dual multiple generative adversarial networks (Dual-MGAN) that combine the two sub-modules can identify discrete as well as partially identified group anomalies. In addition, in view of the difficulty of determining the stop node of training, two evaluation indicators are introduced to evaluate the training status of the sub-GANs. Extensive experiments on synthetic and real-world data show that the proposed Dual-MGAN can significantly improve the accuracy of outlier detection, and the proposed evaluation indicators can reflect the training status of the sub-GANs.}
}


@article{DBLP:journals/tkdd/WangTZL22,
	author = {Yu Wang and
                  Hanghang Tong and
                  Ziye Zhu and
                  Yun Li},
	title = {Nested Named Entity Recognition: {A} Survey},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {6},
	pages = {108:1--108:29},
	year = {2022},
	url = {https://doi.org/10.1145/3522593},
	doi = {10.1145/3522593},
	timestamp = {Mon, 05 Dec 2022 13:35:30 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/WangTZL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the rapid development of text mining, many studies observe that text generally contains a variety of implicit information, and it is important to develop techniques for extracting such information. Named Entity Recognition (NER), the first step of information extraction, mainly identifies names of persons, locations, and organizations in text. Although existing neural-based NER approaches achieve great success in many language domains, most of them normally ignore the nested nature of named entities. Recently, diverse studies focus on the nested NER problem and yield state-of-the-art performance. This survey attempts to provide a comprehensive review on existing approaches for nested NER from the perspectives of the model architecture and the model property, which may help readers have a better understanding of the current research status and ideas. In this survey, we first introduce the background of nested NER, especially the differences between nested NER and traditional (i.e., flat) NER. We then review the existing nested NER approaches from 2002 to 2020 and mainly classify them into five categories according to the model architecture, including early rule-based, layered-based, region-based, hypergraph-based, and transition-based approaches. We also explore in greater depth the impact of key properties unique to nested NER approaches from the model property perspective, namely entity dependency, stage framework, error propagation, and tag scheme. Finally, we summarize the open challenges and point out a few possible future directions in this area. This survey would be useful for three kinds of readers: (i) Newcomers in the field who want to learn about NER, especially for nested NER. (ii) Researchers who want to clarify the relationship and advantages between flat NER and nested NER. (iii) Practitioners who just need to determine which NER technique (i.e., nested or not) works best in their applications.}
}


@article{DBLP:journals/tkdd/XiaoW22,
	author = {Houping Xiao and
                  Shiyu Wang},
	title = {Toward Quality of Information Aware Distributed Machine Learning},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {6},
	pages = {109:1--109:28},
	year = {2022},
	url = {https://doi.org/10.1145/3522591},
	doi = {10.1145/3522591},
	timestamp = {Sat, 30 Sep 2023 10:29:07 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/XiaoW22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the era of big data, data are usually distributed across numerous connected computing and storage units (i.e., nodes or workers). Under such an environment, many machine learning problems can be reformulated as a consensus optimization problem, which consists of one objective and constraint terms splitting into N parts (each corresponds to a node). Such a problem can be solved efficiently in a distributed manner via Alternating Direction Method of Multipliers (ADMM). However, existing consensus optimization frameworks assume that every node has the same quality of information (QoI), i.e., the data from all the nodes are equally informative for the estimation of global model parameters. As a consequence, they may lead to inaccurate estimates in the presence of nodes with low QoI. To overcome this challenge, in this article, we propose a novel consensus optimization framework for distributed machine-learning that incorporates the crucial metric, QoI. Theoretically, we prove that the convergence rate of the proposed framework is linear to the number of iterations, but has a tighter upper bound compared with ADMM. Experimentally, we show that the proposed framework is more efficient and effective than existing ADMM-based solutions on both synthetic and real-world datasets due to its faster convergence rate and higher accuracy.}
}


@article{DBLP:journals/tkdd/CaiYYZH22,
	author = {Jianghui Cai and
                  Yuqing Yang and
                  Haifeng Yang and
                  Xujun Zhao and
                  Jing Hao},
	title = {{ARIS:} {A} Noise Insensitive Data Pre-Processing Scheme for Data
                  Reduction Using Influence Space},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {6},
	pages = {110:1--110:39},
	year = {2022},
	url = {https://doi.org/10.1145/3522592},
	doi = {10.1145/3522592},
	timestamp = {Mon, 05 Dec 2022 13:35:30 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/CaiYYZH22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The extensive growth of data quantity has posed many challenges to data analysis and retrieval. Noise and redundancy are typical representatives of the above-mentioned challenges, which may reduce the reliability of analysis and retrieval results and increase storage and computing overhead. To solve the above problems, a two-stage data pre-processing framework for noise identification and data reduction, called ARIS, is proposed in this article. The first stage identifies and removes noises by the following steps: First, the influence space (IS) is introduced to elaborate data distribution. Second, a ranking factor (RF) is defined to describe the possibility that the points are regarded as noises, then, the definition of noise is given based on RF. Third, a clean dataset (CD) is obtained by removing noise from the original dataset. The second stage learns representative data and realizes data reduction. In this process, CD is divided into multiple small regions by IS. Then the reduced dataset is formed by collecting the representations of each region. The performance of ARIS is verified by experiments on artificial and real datasets. Experimental results show that ARIS effectively weakens the impact of noise and reduces the amount of data and significantly improves the accuracy of data analysis within a reasonable time cost range.}
}


@article{DBLP:journals/tkdd/ZhangXL22,
	author = {Xiaoying Zhang and
                  Hong Xie and
                  John C. S. Lui},
	title = {Improving Bandit Learning Via Heterogeneous Information Networks:
                  Algorithms and Applications},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {6},
	pages = {111:1--111:25},
	year = {2022},
	url = {https://doi.org/10.1145/3522590},
	doi = {10.1145/3522590},
	timestamp = {Fri, 09 Dec 2022 10:11:45 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/ZhangXL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Contextual bandit serves as an invaluable tool to balance the exploration vs. exploitation tradeoff in various applications such as online recommendation. In many applications, heterogeneous information networks (HINs) provide rich side information for contextual bandits, such as different types of attributes and relationships among users and items. In this article, we propose the first HIN-assisted contextual bandit framework, which utilizes a given HIN to assist contextual bandit learning. The proposed framework uses meta-paths in HIN to extract rich relations among users and items for the contextual bandit. The main challenge is how to leverage these relations, since users’ preference over items, the target of our online learning, are closely related to users’ preference over meta-paths. However, it is unknown which meta-path a user prefers more. Thus, both preferences are needed to be learned in an online fashion with exploration vs. exploitation tradeoff balanced. We propose the HIN-assisted upper confidence bound (HUCB) algorithm to address such a challenge. For each meta-path, the HUCB algorithm employs an independent base bandit algorithm to handle online item recommendations by leveraging the relationship captured in this meta-path. A bandit master is then employed to learn users’ preference over meta-paths to dynamically combine base bandit algorithms with a balance of exploration vs. exploitation tradeoff. We theoretically prove that the HUCB algorithm can achieve similar performance compared with the optimal algorithm where each user is served according to his true preference over meta-paths (assuming the optimal algorithm knows the preference). Moreover, we prove that the HUCB algorithm benefits from leveraging HIN in achieving a smaller regret upper bound than the baseline algorithm without leveraging HIN. Experimental results on a synthetic dataset, as well as real datasets from LastFM and Yelp demonstrate the fast learning speed of the HUCB algorithm.}
}


@article{DBLP:journals/tkdd/DeSantisSTA22,
	author = {Derek DeSantis and
                  Erik Skau and
                  Duc Phan Minh Truong and
                  Boian S. Alexandrov},
	title = {Factorization of Binary Matrices: Rank Relations, Uniqueness and Model
                  Selection of Boolean Decomposition},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {6},
	pages = {112:1--112:24},
	year = {2022},
	url = {https://doi.org/10.1145/3522594},
	doi = {10.1145/3522594},
	timestamp = {Mon, 28 Aug 2023 21:37:08 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/DeSantisSTA22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The application of binary matrices are numerous. Representing a matrix as a mixture of a small collection of latent vectors via low-rank decomposition is often seen as an advantageous method to interpret and analyze data. In this work, we examine the factorizations of binary matrices using standard arithmetic (real and nonnegative) and logical operations (Boolean and ℤ2). We examine the relationships between the different ranks, and discuss when factorization is unique. In particular, we characterize when a Boolean factorization X = W ∧ H has a unique W, a unique H (for a fixed W), and when both W and H are unique, given a rank constraint. We introduce a method for robust Boolean model selection, called BMFk, and show on numerical examples that BMFk not only accurately determines the correct number of Boolean latent features but reconstruct the pre-determined factors accurately.}
}


@article{DBLP:journals/tkdd/YangZZ22,
	author = {Xing Yang and
                  Chen Zhang and
                  Baihua Zheng},
	title = {Segment-Wise Time-Varying Dynamic Bayesian Network with Graph Regularization},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {6},
	pages = {113:1--113:23},
	year = {2022},
	url = {https://doi.org/10.1145/3522589},
	doi = {10.1145/3522589},
	timestamp = {Mon, 05 Dec 2022 13:35:30 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/YangZZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Time-varying dynamic Bayesian network (TVDBN) is essential for describing time-evolving directed conditional dependence structures in complex multivariate systems. In this article, we construct a TVDBN model, together with a score-based method for its structure learning. The model adopts a vector autoregressive (VAR) model to describe inter-slice and intra-slice relations between variables. By allowing VAR parameters to change segment-wisely over time, the time-varying dynamics of the network structure can be described. Furthermore, considering some external information can provide additional similarity information of variables. Graph Laplacian is further imposed to regularize similar nodes to have similar network structures. The regularized maximum a posterior estimation in the Bayesian inference framework is used as a score function for TVDBN structure evaluation, and the alternating direction method of multipliers (ADMM) with L-BFGS-B algorithm is used for optimal structure learning. Thorough simulation studies and a real case study are carried out to verify our proposed method’s efficacy and efficiency.}
}


@article{DBLP:journals/tkdd/WangZLYHQL22,
	author = {Shaowei Wang and
                  Lingling Zhang and
                  Xuan Luo and
                  Yi Yang and
                  Xin Hu and
                  Tao Qin and
                  Jun Liu},
	title = {Computer Science Diagram Understanding with Topology Parsing},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {6},
	pages = {114:1--114:20},
	year = {2022},
	url = {https://doi.org/10.1145/3522689},
	doi = {10.1145/3522689},
	timestamp = {Tue, 08 Oct 2024 17:17:08 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/WangZLYHQL22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Diagram is a special form of visual expression for representing complex concepts, logic, and knowledge, which widely appears in educational scenes such as textbooks, blogs, and encyclopedias. Current research on diagrams preliminarily focuses on natural disciplines such as Biology and Geography, whose expressions are still similar to natural images. In this article, we construct the first novel geometric type of diagrams dataset in Computer Science field, which has more abstract expressions and complex logical relations. The dataset has exhaustive annotations of objects and relations for about 1,300 diagrams and 3,500 question-answer pairs. We introduce the tasks of diagram classification (DC) and diagram question answering (DQA) based on the new dataset, and propose the Diagram Paring Net (DPN) that focuses on analyzing the topological structure and text information of diagrams. We use DPN-based models to solve DC and DQA tasks, and compare the performances to well-known natural images classification models and visual question answering models. Our experiments show the effectiveness of the proposed DPN-based models on diagram understanding tasks, also indicate that our dataset is more complex compared to previous natural image understanding datasets. The presented dataset opens new challenges for research in diagram understanding, and the DPN method provides a novel perspective for studying such data. Our dataset can be available from https://github.com/WayneWong97/CSDia.}
}


@article{DBLP:journals/tkdd/JangPJKK22,
	author = {Jun{-}Gi Jang and
                  Chaeheum Park and
                  Changwon Jang and
                  Geonsoo Kim and
                  U Kang},
	title = {Finding Key Structures in {MMORPG} Graph with Hierarchical Graph Summarization},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {6},
	pages = {115:1--115:21},
	year = {2022},
	url = {https://doi.org/10.1145/3522691},
	doi = {10.1145/3522691},
	timestamp = {Mon, 05 Dec 2022 13:35:30 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/JangPJKK22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {What are the key structures existing in a large real-world MMORPG (Massively Multiplayer Online Role-Playing Game) graph? How can we compactly summarize an MMORPG graph with hierarchical node labels, considering substructures at different levels of hierarchy? Recent MMORPGs generate complex interactions between entities inducing a heterogeneous graph where each entity has hierarchical labels. Succinctly summarizing a heterogeneous MMORPG graph is crucial to better understand its structure; however it is a challenging task since it needs to handle complex interactions and hierarchical labels efficiently. Although there exist few methods to summarize a large-scale graph, they do not deal with heterogeneous graphs with hierarchical node labels.We propose GSHL, a novel method that summarizes a heterogeneous graph with hierarchical labels. We formulate the encoding cost of hierarchical labels using MDL (Minimum Description Length). GSHL exploits the formulation to identify and segment subgraphs, and discovers compact and consistent structures in the graph. Experiments on a large real-world MMORPG graph with multi-million edges show that GSHL is a useful and scalable tool for summarizing the graph, finding important structures in the graph, and finding similar users.}
}


@article{DBLP:journals/tkdd/ZhuCLLLLLX22,
	author = {Nengjun Zhu and
                  Jian Cao and
                  Xinjiang Lu and
                  Chuanren Liu and
                  Hao Liu and
                  Yanyan Li and
                  Xiangfeng Luo and
                  Hui Xiong},
	title = {Predicting a Person's Next Activity Region with a Dynamic Region-Relation-Aware
                  Graph Neural Network},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {6},
	pages = {116:1--116:23},
	year = {2022},
	url = {https://doi.org/10.1145/3529091},
	doi = {10.1145/3529091},
	timestamp = {Sun, 12 Nov 2023 02:17:44 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/ZhuCLLLLLX22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The understanding of people’s inter-regional mobility behaviors, such as predicting the next activity region (AR) or uncovering the intentions for regional mobility, is of great value to public administration or business interests. While there are numerous studies on human mobility, these studies are mainly from a statistical view or study movement behaviors within a region. The work on individual-level inter-regional mobility behavior is limited. To this end, in this article, we propose a dynamic region-relation-aware graph neural network (DRRGNN) for exploring individual mobility behaviors over ARs. Specifically, we aim at developing models that can answer three questions: (1) Which regions are the ARs? (2) Which region will be the next AR, and (3) Why do people make this regional mobility? To achieve these tasks, we first propose a method to find out people’s ARs. Then, the designed model integrates a dynamic graph convolution network (DGCN) and a recurrent neural network (RNN) to depict the evolution of relations between ARs and mine the regional mobility patterns. In the learning process, the model further considers peoples’ profiles and visited point-of-interest (POIs). Finally, extensive experiments on two real-world datasets show that the proposed model can significantly improve accuracy for both the next AR prediction and mobility intention prediction.}
}


@article{DBLP:journals/tkdd/XiongWZCLZH22,
	author = {Haoyi Xiong and
                  Ruosi Wan and
                  Jian Zhao and
                  Zeyu Chen and
                  Xingjian Li and
                  Zhanxing Zhu and
                  Jun Huan},
	title = {GrOD: Deep Learning with Gradients Orthogonal Decomposition for Knowledge
                  Transfer, Distillation, and Adversarial Training},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {6},
	pages = {117:1--117:25},
	year = {2022},
	url = {https://doi.org/10.1145/3530836},
	doi = {10.1145/3530836},
	timestamp = {Tue, 20 Dec 2022 14:49:47 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/XiongWZCLZH22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Regularization that incorporates the linear combination of empirical loss and explicit regularization terms as the loss function has been frequently used for many machine learning tasks. The explicit regularization term is designed in different types, depending on its applications. While regularized learning often boost the performance with higher accuracy and faster convergence, the regularization would sometimes hurt the empirical loss minimization and lead to poor performance. To deal with such issues in this work, we propose a novel strategy, namely Gradients Orthogonal Decomposition (GrOD), that improves the training procedure of regularized deep learning. Instead of linearly combining gradients of the two terms, GrOD re-estimates a new direction for iteration that does not hurt the empirical loss minimization while preserving the regularization affects, through orthogonal decomposition. We have performed extensive experiments to use GrOD improving the commonly used algorithms of transfer learning\xa0[2], knowledge distillation\xa0[3], and adversarial learning\xa0[4]. The experiment results based on large datasets, including Caltech 256\xa0[5], MIT indoor 67\xa0[6], CIFAR-10\xa0[7], and ImageNet\xa0[8], show significant improvement made by GrOD for all three algorithms in all cases.}
}


@article{DBLP:journals/tkdd/BenarousTB22,
	author = {Maya Benarous and
                  Eran Toch and
                  Irad Ben{-}Gal},
	title = {Synthesis of Longitudinal Human Location Sequences: Balancing Utility
                  and Privacy},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {6},
	pages = {118:1--118:27},
	year = {2022},
	url = {https://doi.org/10.1145/3529260},
	doi = {10.1145/3529260},
	timestamp = {Mon, 28 Aug 2023 21:37:07 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/BenarousTB22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {People’s location data are continuously tracked from various devices and sensors, enabling an ongoing analysis of sensitive information that can violate people’s privacy and reveal confidential information. Synthetic data have been used to generate representative location sequences yet to maintain the users’ privacy. Nonetheless, the privacy-accuracy tradeoff between these two measures has not been addressed systematically. In this article, we analyze the use of different synthetic data generation models for long location sequences, including extended short-term memory networks (LSTMs), Markov Chains (MC), and variable-order Markov models (VMMs). We employ different performance measures, such as data similarity and privacy, and discuss the inherent tradeoff. Furthermore, we introduce other measurements to quantify each of these measures. Based on the anonymous data of 300 thousand cellular-phone users, our work offers a road map for developing policies for synthetic data generation processes. We propose a framework for building data generation models and evaluating their effectiveness regarding those accuracy and privacy measures.}
}


@article{DBLP:journals/tkdd/Coscia22,
	author = {Michele Coscia},
	title = {Generalized Euclidean Measure to Estimate Distances on Multilayer
                  Networks},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {6},
	pages = {119:1--119:22},
	year = {2022},
	url = {https://doi.org/10.1145/3529396},
	doi = {10.1145/3529396},
	timestamp = {Mon, 28 Aug 2023 21:37:07 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/Coscia22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Estimating the distance covered by a spreading event on a network can lead to a better understanding of epidemics, economic growth, and human behavior. There are many methods solving this problem—which has been called Node Vector Distance (NVD)—for single layer networks. However, many phenomena are better represented by multilayer networks: networks in which nodes can connect in qualitatively different ways. In this article, we extend the literature by proposing an algorithm solving NVD for multilayer networks. We do so by adapting the Mahalanobis distance, incorporating the graph’s topology via the pseudoinverse of its Laplacian. Since this is a proper generalization of the Euclidean distance in a complex space defined by the topology of the graph, and that it works on multilayer networks, we call our measure the Multi Layer Generalized Euclidean (MLGE). In our experiments, we show that MLGE is intuitive, theoretically simpler than the alternatives, performs well in recovering infection parameters, and it is useful in specific case studies. MLGE requires solving a special case of the effective resistance on the graph, which has a high time complexity. However, this needs to be done only once per network. In the experiments, we show that MLGE can cache its most computationally heavy parts, allowing it to solve hundreds of NVD problems on the same network with little to no additional runtime. MLGE is provided as a free open source tool, along with the data and the code necessary to replicate our results.}
}


@article{DBLP:journals/tkdd/YildizDEOCCI22,
	author = {Ilkay Yildiz and
                  Jennifer G. Dy and
                  Deniz Erdogmus and
                  Susan Ostmo and
                  J. Peter Campbell and
                  Michael F. Chiang and
                  Stratis Ioannidis},
	title = {Spectral Ranking Regression},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {6},
	pages = {120:1--120:38},
	year = {2022},
	url = {https://doi.org/10.1145/3530693},
	doi = {10.1145/3530693},
	timestamp = {Mon, 05 Dec 2022 13:35:29 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/YildizDEOCCI22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We study the problem of ranking regression, in which a dataset of rankings is used to learn Plackett–Luce scores as functions of sample features. We propose a novel spectral algorithm to accelerate learning in ranking regression. Our main technical contribution is to show that the Plackett–Luce negative log-likelihood augmented with a proximal penalty has stationary points that satisfy the balance equations of a Markov Chain. This allows us to tackle the ranking regression problem via an efficient spectral algorithm by using the Alternating Directions Method of Multipliers (ADMM). ADMM separates the learning of scores and model parameters, and in turn, enables us to devise fast spectral algorithms for ranking regression via both shallow and deep neural network (DNN) models. For shallow models, our algorithms are up to 579 times faster than the Newton’s method. For DNN models, we extend the standard ADMM via a Kullback–Leibler proximal penalty and show that this is still amenable to fast inference via a spectral approach. Compared to a state-of-the-art siamese network, our resulting algorithms are up to 175 times faster and attain better predictions by up to 26% Top-1 Accuracy and 6% Kendall-Tau correlation over five real-life ranking datasets.}
}


@article{DBLP:journals/tkdd/LiYTZ22,
	author = {Ziyue Li and
                  Hao Yan and
                  Fugee Tsung and
                  Ke Zhang},
	title = {Profile Decomposition Based Hybrid Transfer Learning for Cold-Start
                  Data Anomaly Detection},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {6},
	pages = {121:1--121:28},
	year = {2022},
	url = {https://doi.org/10.1145/3530990},
	doi = {10.1145/3530990},
	timestamp = {Mon, 05 Dec 2022 13:35:29 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/LiYTZ22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Anomaly detection is an essential task for quality management in smart manufacturing. An accurate data-driven detection method usually needs enough data and labels. However, in practice, there commonly exist newly set-up processes in manufacturing, and they only have quite limited data available for analysis. Borrowing the name from the recommender system, we call this process a cold-start process. The sparsity of anomaly, the deviation of the profile, and noise aggravate the detection difficulty. Transfer learning could help to detect anomalies for cold-start processes by transferring the knowledge from more experienced processes to the new processes. However, the existing transfer learning and multi-task learning frameworks are established on task- or domain-level relatedness. We observe instead, within a domain, some components (background and anomaly) share more commonality, others (profile deviation and noise) not. To this end, we propose a more delicate component-level transfer learning scheme, i.e., decomposition-based hybrid transfer learning (DHTL): It first decomposes a domain (e.g., a data source containing profiles) into different components (smooth background, profile deviation, anomaly, and noise); then, each component’s transferability is analyzed by expert knowledge; Lastly, different transfer learning techniques could be tailored accordingly. We adopted the Bayesian probabilistic hierarchical model to formulate parameter transfer for the background, and “L2,1+L1”-norm to formulate low dimension feature-representation transfer for the anomaly. An efficient algorithm based on Block Coordinate Descend is proposed to learn the parameters. A case study based on glass coating pressure profiles demonstrates the improved accuracy and completeness of detected anomaly, and a simulation demonstrates the fidelity of the decomposition results.}
}


@article{DBLP:journals/tkdd/HuQWW22,
	author = {Yue Hu and
                  Ao Qu and
                  Yanbing Wang and
                  Daniel B. Work},
	title = {Streaming Data Preprocessing via Online Tensor Recovery for Large
                  Environmental Sensor Networks},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {6},
	pages = {122:1--122:24},
	year = {2022},
	url = {https://doi.org/10.1145/3532189},
	doi = {10.1145/3532189},
	timestamp = {Mon, 28 Aug 2023 21:37:07 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/HuQWW22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Measuring the built and natural environment at a fine-grained scale is now possible with low-cost urban environmental sensor networks. However, fine-grained city-scale data analysis is complicated by tedious data cleaning including removing outliers and imputing missing data. While many methods exist to automatically correct anomalies and impute missing entries, challenges still exist on data with large spatial-temporal scales and shifting patterns. To address these challenges, we propose an online robust tensor recovery (OLRTR) method to preprocess streaming high-dimensional urban environmental datasets. A small-sized dictionary that captures the underlying patterns of the data is computed and constantly updated with new data. OLRTR enables online recovery for large-scale sensor networks that provide continuous data streams, with a lower computational memory usage compared to offline batch counterparts. In addition, we formulate the objective function so that OLRTR can detect structured outliers, such as faulty readings over a long period of time. We validate OLRTR on a synthetically degraded National Oceanic and Atmospheric Administration temperature dataset, and apply it to the Array of Things city-scale sensor network in Chicago, IL, showing superior results compared with several established online and batch-based low-rank decomposition methods.}
}


@article{DBLP:journals/tkdd/MaWLGJZW22,
	author = {Pengfei Ma and
                  Youxi Wu and
                  Yan Li and
                  Lei Guo and
                  He Jiang and
                  Xingquan Zhu and
                  Xindong Wu},
	title = {HW-Forest: Deep Forest with Hashing Screening and Window Screening},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {6},
	pages = {123:1--123:24},
	year = {2022},
	url = {https://doi.org/10.1145/3532193},
	doi = {10.1145/3532193},
	timestamp = {Mon, 05 Dec 2022 13:35:29 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/MaWLGJZW22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As a novel deep learning model, gcForest has been widely used in various applications. However, current multi-grained scanning of gcForest produces many redundant feature vectors, and this increases the time cost of the model. To screen out redundant feature vectors, we introduce a hashing screening mechanism for multi-grained scanning and propose a model called HW-Forest which adopts two strategies: hashing screening and window screening. HW-Forest employs perceptual hashing algorithm to calculate the similarity between feature vectors in hashing screening strategy, which is used to remove the redundant feature vectors produced by multi-grained scanning and can significantly decrease the time cost and memory consumption. Furthermore, we adopt a self-adaptive instance screening strategy called window screening to improve the performance of our approach, which can achieve higher accuracy without hyperparameter tuning on different datasets. Our experimental results show that HW-Forest has higher accuracy than other models, and the time cost is also reduced.}
}


@article{DBLP:journals/tkdd/PellegrinaCVR22,
	author = {Leonardo Pellegrina and
                  Cyrus Cousins and
                  Fabio Vandin and
                  Matteo Riondato},
	title = {MCRapper: Monte-Carlo Rademacher Averages for Poset Families and Approximate
                  Pattern Mining},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {6},
	pages = {124:1--124:29},
	year = {2022},
	url = {https://doi.org/10.1145/3532187},
	doi = {10.1145/3532187},
	timestamp = {Mon, 28 Aug 2023 21:37:07 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/PellegrinaCVR22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {“I’m an MC still as honest” – Eminem, Rap God We present MCRapper, an algorithm for efficient computation of Monte-Carlo Empirical Rademacher Averages (MCERA) for families of functions exhibiting poset (e.g., lattice) structure, such as those that arise in many pattern mining tasks. The MCERA allows us to compute upper bounds to the maximum deviation of sample means from their expectations, thus it can be used to find both (1) statistically-significant functions (i.e., patterns) when the available data is seen as a sample from an unknown distribution, and (2) approximations of collections of high-expectation functions (e.g., frequent patterns) when the available data is a small sample from a large dataset. This flexibility offered by MCRapper is a big advantage over previously proposed solutions, which could only achieve one of the two. MCRapper uses upper bounds to the discrepancy of the functions to efficiently explore and prune the search space, a technique borrowed from pattern mining itself. To show the practical use of MCRapper, we employ it to develop an algorithm TFP-R for the task of True Frequent Pattern (TFP) mining, by appropriately computing approximations of the negative and positive borders of the collection of patterns of interest, which allow an effective pruning of the pattern space and the computation of strong bounds to the supremum deviation. TFP-R gives guarantees on the probability of including any false positives (precision) and exhibits higher statistical power (recall) than existing methods offering the same guarantees. We evaluate MCRapper and TFP-R and show that they outperform the state-of-the-art for their respective tasks.}
}


@article{DBLP:journals/tkdd/BechiniBBDMR22,
	author = {Alessio Bechini and
                  Alessandro Bondielli and
                  Jos{\'{e}} Luis Corcuera B{\'{a}}rcena and
                  Pietro Ducange and
                  Francesco Marcelloni and
                  Alessandro Renda},
	title = {A News-Based Framework for Uncovering and Tracking City Area Profiles:
                  Assessment in Covid-19 Setting},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {16},
	number = {6},
	pages = {125:1--125:29},
	year = {2022},
	url = {https://doi.org/10.1145/3532186},
	doi = {10.1145/3532186},
	timestamp = {Sun, 16 Oct 2022 14:19:59 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/BechiniBBDMR22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the last years, there has been an ever-increasing interest in profiling various aspects of city life, especially in the context of smart cities. This interest has become even more relevant recently when we have realized how dramatic events, such as the Covid-19 pandemic, can deeply affect the city life, producing drastic changes. Identifying and analyzing such changes, both at the city level and within single neighborhoods, may be a fundamental tool to better manage the current situation and provide sound strategies for future planning. Furthermore, such fine-grained and up-to-date characterization can represent a valuable asset for other tools and services, e.g., web mapping applications or real estate agency platforms. In this article, we propose a framework featuring a novel methodology to model and track changes in areas of the city by extracting information from online newspaper articles. The problem of uncovering clusters of news at specific times is tackled by means of the joint use of state-of-the-art language models to represent the articles, and of a density-based streaming clustering algorithm, properly shaped to deal with high-dimensional text embeddings. Furthermore, we propose a method to automatically label the obtained clusters in a semantically meaningful way, and we introduce a set of metrics aimed at tracking the temporal evolution of clusters. A case study focusing on the city of Rome during the Covid-19 pandemic is illustrated and discussed to evaluate the effectiveness of the proposed approach.}
}
