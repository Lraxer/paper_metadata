@article{DBLP:journals/tkdd/YangZLXM25,
	author = {Guangqian Yang and
                  Lei Zhang and
                  Yi Liu and
                  Hongtao Xie and
                  Zhendong Mao},
	title = {Exploiting Pre-Trained Language Models for Black-Box Attack against
                  Knowledge Graph Embeddings},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {1},
	pages = {1:1--1:14},
	year = {2025},
	url = {https://doi.org/10.1145/3688850},
	doi = {10.1145/3688850},
	timestamp = {Sun, 02 Nov 2025 21:29:25 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/YangZLXM25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Despite the emerging research on adversarial attacks against knowledge graph embedding (KGE) models, most of them focus on white-box attack settings. However, white-box attacks are difficult to apply in practice compared to black-box attacks since they require access to model parameters that are unlikely to be provided. In this article, we propose a novel black-box attack method that only requires access to knowledge graph data, making it more realistic in real-world attack scenarios. Specifically, we utilize pre-trained language models (PLMs) to encode text features of the knowledge graphs, an aspect neglected by previous research. We then employ these encoded text features to identify the most influential triples for constructing corrupted triples for the attack. To improve the transferability of the attack, we further propose to fine-tune the PLM model by enriching triple embeddings with structure information. Extensive experiments conducted on two knowledge graph datasets illustrate the effectiveness of our proposed method.}
}


@article{DBLP:journals/tkdd/YuLZLZ25,
	author = {Xiao Yu and
                  Hui Liu and
                  Yan Zhang and
                  Yuxiu Lin and
                  Caiming Zhang},
	title = {Hubness-Enabled Clustering and Recovery for Large-Scale Incomplete
                  Multi-View Data},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {1},
	pages = {2:1--2:23},
	year = {2025},
	url = {https://doi.org/10.1145/3694689},
	doi = {10.1145/3694689},
	timestamp = {Fri, 07 Mar 2025 18:31:23 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/YuLZLZ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Incomplete multi-view clustering has gained considerable attention in recent years due to the prevalence of incomplete multi-view data in real-world applications. However, existing methods often struggle to effectively deal with large-scale datasets, particularly those with a significant number of missing instances. To address these issues, we propose a novel method called Hubness-Enabled Clustering and Recovery for Large-Scale Incomplete Multi-View Data (HENRI). HENRI utilizes the consensus hubs of all views to identify informative anchors to handle large-scale incomplete datasets. Furthermore, it incorporates a novel sample-level fusion strategy that effectively integrates information from all views, leading to remarkable outcomes in both cluster formation and missing data reconstruction. HENRI demonstrates exceptional capability in capturing the underlying structures of the data and recovering missing information, even when faced with a significant number of instances with incomplete data in partial views. To validate its effectiveness, we conducted experiments on 6 complete datasets and 31 incomplete datasets, comparing against 11 baseline methods. The results are impressive, demonstrating the superior performance of HENRI over the state-of-the-art methods.}
}


@article{DBLP:journals/tkdd/HarelM25,
	author = {Omer David Harel and
                  Robert Moskovitch},
	title = {{STORM:} {A} MapReduce Framework for Symbolic Time Intervals Series
                  Classification},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {1},
	pages = {3:1--3:54},
	year = {2025},
	url = {https://doi.org/10.1145/3694788},
	doi = {10.1145/3694788},
	timestamp = {Sun, 02 Nov 2025 21:29:25 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/HarelM25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Symbolic Time Intervals (STIs)  represent events having a non-zero time duration, which are common in various application domains. In this article, we focus on the challenge of STIs series classification (STIC). While in the related problem of time series classification (TSC) Rocket is well-known for its exceptionally fast runtime while achieving accuracy comparable to state-of-the-art, it has only recently been studied in the field of STIC. However, since Rocket as well as its enhanced variants for TSC (e.g., MiniRocket and MultiRocket) solely rely on global features, they might not always fit best for the classification of thousands of time-units long STI series out-of-the-box, which are rather common in STIC. We introduce STORM—a novel, generic MapReduce framework for STIC, which (1) converts raw input STIs series into multivariate time series (MTS) representation; (2) partitions the converted MTS into fixed-sized blocks, each transformed independently into a uniform latent space via a common, desired Rocket variant used as a base transformation in STORM; and (3) performs sequence classification of the blocks’ transformed feature vectors via a deep, lightweight, bidirectional LSTM network. The evaluation demonstrates that STORM significantly improves accuracy over eight state-of-the-art methods for STIC either when applied with MiniRocket and MultiRocket as base transformations, as well as over the baselines of applying the respective Rocket variants directly to the converted MTS representation, that is, while also reporting overall comparable training times, on a benchmark of eight real-world STIC datasets including both extremely long and short STIs series.}
}


@article{DBLP:journals/tkdd/LeiZLGC25,
	author = {Fatang Lei and
                  Chao Zhang and
                  Huaxiong Li and
                  Yang Gao and
                  Chunlin Chen},
	title = {Label Distribution Guided Hashing for Cross-Modal Retrieval},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {1},
	pages = {4:1--4:23},
	year = {2025},
	url = {https://doi.org/10.1145/3697353},
	doi = {10.1145/3697353},
	timestamp = {Thu, 06 Nov 2025 14:13:41 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/LeiZLGC25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Hashing methods have recently attracted extensive attention in cross-modal retrieval. Most supervised hashing methods attempt to preserve the semantic information into hash codes by leveraging the original logical label matrix. However, they generally treat all labels equally, and ignore the relative significance of different labels due to the variety of data features. In this article, we argue that exploring the relative importance of labels benefits the enhancement of semantic information, and we propose a novel LAbel Distribution Guided Hashing (LADH) method for cross-modal retrieval. In particular, LADH first learns a feature-induced label distribution for each sample to weigh different labels, which leverages the multi-modal feature information to enrich the semantic label information. By jointly using the learned label distributions and multi-modal features, the latent representation and hash codes are obtained with multi-modal feature selection and enhanced semantic similarities embedded. An efficient algorithm is designed to solve the proposed method whose time complexity is linear to the number of the training instances. Experimental results on several public benchmark datasets verify the effectiveness and efficiency of our method compared with the state-of-the-art methods.}
}


@article{DBLP:journals/tkdd/ZhangWFSS25,
	author = {Zhiwen Zhang and
                  Hongjun Wang and
                  Zipei Fan and
                  Xuan Song and
                  Ryosuke Shibasaki},
	title = {Assessing the Spatial-Temporal Causal Impact of COVID-19-Related Policies
                  on Epidemic Spread},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {1},
	pages = {5:1--5:19},
	year = {2025},
	url = {https://doi.org/10.1145/3697841},
	doi = {10.1145/3697841},
	timestamp = {Sun, 02 Nov 2025 21:29:25 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/ZhangWFSS25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Analyzing the causal impact of various government-related policies on the epidemic spread is of critical importance. This article aims to investigate the problem of assessing the causal effects of different COVID-19-related policies on the USA epidemic spread in different counties at any given time period, while eliminating biased interference from unobserved confounders (e.g., the vigilance of residents). However, the infection outcome of each region is influenced not only by its own confounding factors but also by policy interventions implemented in neighboring regions. Furthermore, the government policy index may exhibit a time-delay influence on outbreak dynamics. To this end, we implement observational data about different COVID-19-related policies (treatment) and outbreak dynamics (outcome) across different U.S. counties over time and develop a causal framework that learns the representations of time-varying confounders to tackle the aforementioned issues. More specifically, we employ one recurrent structure to capture the accumulative effects stemming from the policy history and then utilize hypergraph neural network to model the interactions among spatial regions. Our experimental results demonstrate the effectiveness of the proposed framework in quantifying the causal impact of different policy types on epidemics. Compared with baseline methods, our assessment provides valuable insights for future policy-making endeavors.}
}


@article{DBLP:journals/tkdd/HuQYCX25,
	author = {Hanwen Hu and
                  Shiyou Qian and
                  Dingyu Yang and
                  Jian Cao and
                  Guangtao Xue},
	title = {Iterative Time Series Imputation by Maintaining Dependency Consistency},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {1},
	pages = {6:1--6:24},
	year = {2025},
	url = {https://doi.org/10.1145/3698107},
	doi = {10.1145/3698107},
	timestamp = {Fri, 07 Mar 2025 18:31:23 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/HuQYCX25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Data imputation is crucial in the analysis of incomplete time series, such as forecasting and classification, which involves learning dependencies among the observed values to infer missing ones. As there are no ground truths for missing values, the challenge of time series imputation lies in preventing the model from overfitting to spurious correlations. In this article, we believe that  ensuring dependency consistency  between observed and imputed values in a sequence is paramount for data imputation. Based on this idea, we propose a model called  IR 2 -Net , 1  which combines an  incomplete representation mechanism (IRM)  with an  iterative reconstruction framework (IRF)  to establish a closed-loop learning-validation imputation paradigm. Firstly, IRM facilitates the representation of dependencies in  incomplete sequences  while preserving their distributions and semantics, effectively preventing the model from capturing spurious correlations. Secondly, IRF enables the model to reconstruct identical complete sequences separately based on imputed and observed values, ensuring that the dependencies of imputed values remain consistent with those of the observed ones. We conduct experiments on four datasets and compare IR 2 -Net with seven state-of-the-art imputation models. The experiment results show that IR 2 -Net outperforms all the baselines by 4.1%–23.4% in terms of accuracy. Moreover, IRF and IRM are two general modules that can be easily integrated into two existing models, significantly enhancing their performance by 18.3%–42.0%.}
}


@article{DBLP:journals/tkdd/MaoLLWZC25,
	author = {Qingyang Mao and
                  Zhi Li and
                  Qi Liu and
                  Likang Wu and
                  Hefu Zhang and
                  Enhong Chen},
	title = {Promoting Machine Abilities of Discovering and Utilizing Knowledge
                  in a Unified Zero-Shot Learning Paradigm},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {1},
	pages = {7:1--7:26},
	year = {2025},
	url = {https://doi.org/10.1145/3700444},
	doi = {10.1145/3700444},
	timestamp = {Sun, 02 Nov 2025 21:29:25 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/MaoLLWZC25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Knowledge discovery and utilization are two essential cognitive processes that enable humans to understand the world and extract new insights from their surroundings. These processes have motivated machine learning studies, particularly zero-shot (ZS) learning, which seeks to identify unseen concepts through the use of side information. Previous ZS studies primarily focused on utilizing existing knowledge to infer unseen events, yet they overlook the crucial process of knowledge discovery and the integrated modeling of these knowledge-aware processes. In this study, we present a comprehensive ZS learning approach that explores and evaluates the machine’s abilities of discovering and utilizing knowledge. More specifically, to emulate human-like knowledge discovery and utilization processes, we propose a novel visual-aware ZS knowledge graph completion task for evaluation, incorporating a traditional ZS image classification task. Technically, we develop a unified ZS learning paradigm named Cognitive Learner (CoLa) to foster the two knowledge-aware abilities. Including a knowledge representation learning (KRL) module and a knowledge adaptation (KA) module, CoLa adapts well to the two specified tasks with the corresponding data. Extensive experiments on large-scale datasets demonstrate CoLa models’ outstanding performance over compared methods in the two ZS tasks, illustrating their superior ability of discovering and utilizing knowledge.}
}


@article{DBLP:journals/tkdd/MaiLCZ25,
	author = {Chengyuan Mai and
                  Tianchi Liao and
                  Chuan Chen and
                  Zibin Zheng},
	title = {{FGTL:} Federated Graph Transfer Learning for Node Classification},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {1},
	pages = {8:1--8:20},
	year = {2025},
	url = {https://doi.org/10.1145/3699962},
	doi = {10.1145/3699962},
	timestamp = {Fri, 07 Mar 2025 18:31:23 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/MaiLCZ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Unsupervised multi-source domain transfer in federated scenario has become an emerging research direction, which can help unlabeled target domain to obtain the adapted model through source domains under privacy-preserving. However, when local data are graph, the difference of domains (or data heterogeneity) mainly originates from the difference in node attributes and sub-graph structures, leading to serious model drift, which is not considered by the existing related algorithms. Currently, there are two challenges in this scenario: (1) The node representations extracted directly through conventional GNNs lack inter-domain generalized and consistent information, making it difficult to apply existing federated learning algorithms. (2) The knowledge of source domains has quality differences, which may lead to negative transfer. To address these issues, we propose a novel two-phase Federated Graph Transfer Learning (FGTL) framework. In the generalization phase, FGTL utilizes local contrastive learning and global context embedding to force node representations to capture the inter-domain generalized and consistent information, lightly alleviating model drift. In the transfer phase, FGTL utilizes consensus knowledge to force the decision bound of classifier to adapt to the target client. In addition, FGTL+ exploits model grouping to make consensus knowledge generation more efficient, further enhancing the scalability of FGTL. Extensive experiments show that FGTL significantly outperforms state-of-the-art related methods, while FGTL+ further enhances privacy protection and reduces both communication and computation overhead.}
}


@article{DBLP:journals/tkdd/LingLZZWHYW25,
	author = {Zhaolong Ling and
                  Bo Li and
                  Yiwen Zhang and
                  Peng Zhou and
                  Xingyu Wu and
                  Yuee Huang and
                  Kui Yu and
                  Xindong Wu},
	title = {Causal Discovery Using Weight-Based Conditional Independence Test},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {1},
	pages = {9:1--9:24},
	year = {2025},
	url = {https://doi.org/10.1145/3687467},
	doi = {10.1145/3687467},
	timestamp = {Wed, 17 Sep 2025 09:32:37 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/LingLZZWHYW25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Conditional Independence (CI)  tests play an essential role in causal discovery from observational data, enabling the measurement of independence between two nodes. However, traditional CI tests ignore the imbalanced occurrence probabilities of node values, which may affect the accuracy of determining independence between nodes. To address this problem, we first introduce a new concept of the Node-imbalance phenomenon to describe the imbalance of node values in the Bayesian network data and analyze the influence of the Node-imbalance phenomenon on the traditional CI tests, then we propose a  Weight-Based Conditional Independence (WCI)  test to improve the accuracy of CI tests in the presence of Node-imbalance. In the experiments, we verify that WCI effectively measures the dependency between nodes in the Node-imbalance phenomenon compared with the traditional independence tests, and the state-of-the-art causal discovery algorithms reduce the number of false causal orientations through WCI.}
}


@article{DBLP:journals/tkdd/HeHLOVK25,
	author = {Bing He and
                  Yibo Hu and
                  Yeon{-}Chang Lee and
                  Soyoung Oh and
                  Gaurav Verma and
                  Srijan Kumar},
	title = {A Survey on the Role of Crowds in Combating Online Misinformation:
                  Annotators, Evaluators, and Creators},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {1},
	pages = {10:1--10:30},
	year = {2025},
	url = {https://doi.org/10.1145/3694980},
	doi = {10.1145/3694980},
	timestamp = {Mon, 29 Sep 2025 10:00:55 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/HeHLOVK25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Online misinformation poses a global risk with significant real-world consequences. To combat misinformation, current research relies on professionals like journalists and fact-checkers for annotating and debunking false information while also developing automated machine learning methods for detecting misinformation. Complementary to these approaches, recent research has increasingly concentrated on utilizing the power of ordinary social media users, a.k.a. “the crowd,” who act as eyes-on-the-ground proactively questioning and countering misinformation. Notably, recent studies show that 96% of counter-misinformation responses originate from them. Acknowledging their prominent role, we present the first systematic and comprehensive survey of research papers that actively leverage the crowds to combat misinformation. In this survey, we first identify 88 papers related to crowd-based efforts, 1  following a meticulous annotation process adhering to the PRISMA framework (preferred reporting items for systematic reviews and meta-analyses). We then present key statistics related to misinformation, counter-misinformation, and crowd input in different formats and topics. Upon holistic analysis of the papers, we introduce a novel taxonomy of the roles played by the crowds in combating misinformation: (i)  crowds as annotators  who actively identify misinformation; (ii)  crowds as evaluators  who assess counter-misinformation effectiveness; (iii)  crowds as creators  who create counter-misinformation. This taxonomy explores the crowd’s capabilities in misinformation detection, identifies the prerequisites for effective counter-misinformation, and analyzes crowd-generated counter-misinformation. In each assigned role, we conduct a detailed analysis to categorize the specific utilization of the crowd. Particularly, we delve into (i) distinguishing individual, collaborative, and machine-assisted labeling for annotators; (ii) analyzing the effectiveness of counter-misinformation through surveys, interviews, and in-lab experiments for evaluators; and (iii) characterizing creation patterns and creator profiles for creators. Finally, we conclude this survey by outlining potential avenues for future research in this field.}
}


@article{DBLP:journals/tkdd/ChenCSZWY25,
	author = {Donghui Chen and
                  Ling Chen and
                  Zongjiang Shang and
                  Youdong Zhang and
                  Bo Wen and
                  Chenghu Yang},
	title = {Scale-Aware Neural Architecture Search for Multivariate Time Series
                  Forecasting},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {1},
	pages = {11:1--11:23},
	year = {2025},
	url = {https://doi.org/10.1145/3701038},
	doi = {10.1145/3701038},
	timestamp = {Fri, 07 Mar 2025 18:31:23 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/ChenCSZWY25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Multivariate time series (MTS) forecasting has attracted much attention in many intelligent applications. It is not a trivial task, as we need to consider both intra-variable dependencies and inter-variable dependencies. However, existing works are designed for specific scenarios and require much domain knowledge and expert efforts, which is difficult to transfer between different scenarios. In this article, we propose a scale-aware neural architecture search framework for MTS forecasting (SNAS4MTF). A multi-scale decomposition module transforms raw time series into multi-scale sub-series, which can preserve multi-scale temporal patterns. An adaptive graph learning module infers the different inter-variable dependencies under different time scales without any prior knowledge. For MTS forecasting, a search space is designed to capture both intra-variable dependencies and inter-variable dependencies at each time scale. The multi-scale decomposition, adaptive graph learning, and neural architecture search modules are jointly learned in an end-to-end framework. Extensive experiments on two real-world datasets demonstrate that SNAS4MTF achieves a promising performance compared with the state-of-the-art methods.}
}


@article{DBLP:journals/tkdd/ZhangHZZXJN25,
	author = {Hao Zhang and
                  Ting{-}Zhu Huang and
                  Xi{-}Le Zhao and
                  Shuqin Zhang and
                  Jinyu Xie and
                  Tai{-}Xiang Jiang and
                  Michael K. Ng},
	title = {Learnable Transform-Assisted Tensor Decomposition for Spatio-Irregular
                  Multidimensional Data Recovery},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {1},
	pages = {12:1--12:23},
	year = {2025},
	url = {https://doi.org/10.1145/3701235},
	doi = {10.1145/3701235},
	timestamp = {Fri, 12 Dec 2025 18:35:07 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/ZhangHZZXJN25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Tensor decompositions have been successfully applied to multidimensional data recovery. However, classical tensor decompositions are not suitable for emerging spatio-irregular multidimensional data (i.e., spatio-irregular tensor), whose spatial domain is non-rectangular, e.g., spatial transcriptomics data from bioinformatics and semantic units from computer vision. By using preprocessing (e.g., zero-padding or element-wise 0-1 weighting), the spatio-irregular tensor can be converted to a spatio-regular tensor and then classical tensor decompositions can be applied, but this strategy inevitably introduces bias information, leading to artifacts. How to design a tensor-based method suitable for emerging spatio-irregular tensors is an imperative challenge. To address this challenge, we propose a learnable transform-assisted tensor singular value decomposition (LTA-TSVD) for spatio-irregular tensor recovery, which allows us to leverage the intrinsic structure behind the spatio-irregular tensor. Specifically, we design a learnable transform to project the original spatio-irregular tensor into its latent spatio-regular tensor, and then the latent low-rank structure is captured by classical TSVD on the resulting regular tensor. Empowered by LTA-TSVD, we develop spatio-irregular low-rank tensor completion (SIR-LRTC) and spatio-irregular tensor robust principal component analysis (SIR-TRPCA) models for the spatio-irregular tensor imputation and denoising respectively, and we design corresponding solving algorithms with theoretical convergence. Extensive experiments including the spatial transcriptomics data imputation and hyperspectral image denoising show SIR-LRTC and SIR-TRPCA are superior performance to competing approaches and benefit downstream applications.}
}


@article{DBLP:journals/tkdd/LiangGCW25,
	author = {Weichao Liang and
                  Guangliang Gao and
                  Lei Chen and
                  Youquan Wang},
	title = {Partial Multi-Label Learning via Exploiting Instance and Label Correlations},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {1},
	pages = {13:1--13:22},
	year = {2025},
	url = {https://doi.org/10.1145/3700879},
	doi = {10.1145/3700879},
	timestamp = {Thu, 18 Sep 2025 10:18:19 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/LiangGCW25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The goal of partial multi-label learning is to induce a multi-label classifier from partial multi-label data where each instance is annotated with a number of candidate labels but only a subset of them are valid. Many of the existing studies either fail to fully utilize instance and label correlations to eliminate noisy labels or build an over-simplified multi-label classifier, both of which are unfavorable for the improvement of generalization performance. In this article, we put forward a novel model named P ml-ilc  to learn a multi-label classifier from partial multi-label data. Specifically, P ml-ilc  first encodes instances and labels into a compact semantic space and takes full advantage of instance and label correlations to eliminate noisy labels. Then, it induces a linear mapping from the feature space to the label space while exploiting label-specific features and instance correlations to facilitate the multi-label classifier learning process. Finally, the above two steps are combined into a joint optimization problem and an efficient alternating optimization procedure is developed to find a satisfactory solution. Extensive experiments show that P ml-ilc  achieves superior performance on both real-world and synthetic partial multi-label datasets in terms of different evaluation metrics.}
}


@article{DBLP:journals/tkdd/WangZSRY25,
	author = {Zhixiao Wang and
                  Jiayu Zhao and
                  Chengcheng Sun and
                  Xiaobin Rui and
                  Philip S. Yu},
	title = {A General Concave Fairness Framework for Influence Maximization Based
                  on Poverty Reward},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {1},
	pages = {14:1--14:23},
	year = {2025},
	url = {https://doi.org/10.1145/3701737},
	doi = {10.1145/3701737},
	timestamp = {Fri, 07 Mar 2025 18:31:23 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/WangZSRY25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Influence maximization (IM) aims to find a group of influential nodes as initial spreaders to maximize the influence spread over a network. Yet, traditional IM algorithms have not been designed with fairness in mind, resulting in discrimination against some groups, like LGBTQ communities and racial minorities. This issue has spurred research on Fair Influence Maximization (FIM). However, existing FIM studies come with some drawbacks. First, most proposed notions of fairness for FIM cannot adjust the tradeoff between fairness level and influence spread. Second, though a few specific notions of fairness allow such balancing, they are limited to a few specific concave functions, which may not be suitable for various real-world scenarios. Furthermore, none of them have studied the deep relations between the features of concave functions and the level of fairness. Third, existing fairness metrics are limited to their corresponding concepts of fairness. Comparing the level of fairness across different algorithms using existing metrics can be challenging. To tackle the above problems, this article first proposes a novel fairness notion named Poverty Reward (PR), which achieves fairness by rewarding the enrichment of groups with low utility. Based on PR, we further propose an algorithmic framework called Concave Fairness Framework (CFF) that allows any concave function that satisfies specific requirements. We also systematically clarify how fairness is improved by applying concave functions and provide an in-depth quantitative analysis of how to select appropriate concave functions for different utility distributions. Moreover, we propose the Reward of Fairness (RoF) metric that evaluates the disparity between groups. Based on RoF, an evaluation system is built to uniformly compare FIM algorithms from different fairness notions. Experiments in real-world datasets have demonstrated the validity of the CFF, as well as the proposed fairness notion.}
}


@article{DBLP:journals/tkdd/LiuSLHL25,
	author = {Haoqiang Liu and
                  Weikang Su and
                  Tong Li and
                  Wenzhen Huang and
                  Yong Li},
	title = {Digital Twin Enhanced Multi-Agent Reinforcement Learning for Large-Scale
                  Mobile Network Coverage Optimization},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {1},
	pages = {15:1--15:23},
	year = {2025},
	url = {https://doi.org/10.1145/3702644},
	doi = {10.1145/3702644},
	timestamp = {Fri, 07 Mar 2025 18:31:23 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/LiuSLHL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the rapid advancement of communication technology and the exponential growth of mobile users, improving network coverage quality and throughput has become increasingly important. In particular, large-scale Base Station (BS) cooperative optimization has become a highly significant topic. BSs can adjust various parameters for high-quality communication, but automating this optimization remains challenging due to environmental sensitivity and interdependencies. Traditional methods for network optimization are constrained by the intricate nature of real-world environments. Further, Reinforcement Learning (RL) techniques, which are effective for configuration policies, encounter difficulties in intricate, high-dimensional wireless communication networks, especially in multi-agent cooperative optimization. To overcome these challenges, this article proposes the Enhanced Multi-Agent Proximal Policy Optimization (EMAPPO), which utilizes the capabilities of the UNet network to extract multi-spatial relationships among a massive number of network elements and employs the DiffPool network to efficiently depict the impact of large-scale action coordination among massive agents on coverage performance. To facilitate evaluation in communication optimization, we further introduce a high-fidelity digital twin-driven mobile network. Extensive experiments validate the effectiveness and superior performance of EMAPPO by utilizing the network digital twin. The results demonstrate significant improvements in signal coverage rate and network throughput compared to the competing methods.}
}


@article{DBLP:journals/tkdd/JaysawalH25,
	author = {Bijay Prasad Jaysawal and
                  Jen{-}Wei Huang},
	title = {{SOHUPDS+:} An Efficient One-phase Algorithm for Mining High Utility
                  Patterns over a Data Stream},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {1},
	pages = {16:1--16:32},
	year = {2025},
	url = {https://doi.org/10.1145/3702645},
	doi = {10.1145/3702645},
	timestamp = {Sun, 02 Nov 2025 21:29:25 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/JaysawalH25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Existing algorithms for mining high utility patterns over a data stream are two-phase algorithms that are not scalable due to the large number of candidates generation in the first phase, particularly when the minimum utility threshold is low. Moreover, in the second phase, the algorithm needs to scan the database again to find out actual utility for candidates. In this article, we propose one-phase algorithm SOHUPDS +  to mine high utility itemsets in the current sliding window of the data stream with respect to absolute or relative minimum utility threshold. To facilitate SOHUPDS + , we propose a data structure  IUDataListSW + , which stores and maintains utility and upper-bound values of the items in the current sliding window when sliding window advances. In addition, we propose a transaction merging strategy, called  BitmapTransactionMerging , which saves execution time for utility and upper-bound values computations in denser datasets. Moreover, we propose update strategies to utilize mined high utility patterns from the previous sliding window to update high utility patterns in the current sliding window. The results of experiments illustrate that SOHUPDS +  is more efficient than the state-of-the-art algorithms in terms of execution time as well as memory usage in most of the experiments on various datasets.}
}


@article{DBLP:journals/tkdd/SunDZYSL25,
	author = {Jianwen Sun and
                  Shangheng Du and
                  Jianpeng Zhou and
                  Xin Yuan and
                  Xiaoxuan Shen and
                  Ruxia Liang},
	title = {Question Embedding on Weighted Heterogeneous Information Network for
                  Knowledge Tracing},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {1},
	pages = {17:1--17:28},
	year = {2025},
	url = {https://doi.org/10.1145/3703158},
	doi = {10.1145/3703158},
	timestamp = {Fri, 07 Mar 2025 18:31:23 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/SunDZYSL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Knowledge Tracing (KT) aims to predict students’ future performance on answering questions based on their historical exercise sequences. To alleviate the problem of data sparsity in KT, recent works have introduced auxiliary information to mine question similarity, resulting in the enhancement of question embeddings. Nonetheless, there remains a gap in developing an approach that effectively incorporates various forms of auxiliary information, including relational information (e.g.,  question–student ,  question–skill  relation), relationship attributes (e.g.,  correctness  indicating a student's performance on a question), and node attributes (e.g.,  student ability ). To tackle this challenge, the Similarity-enhanced Question Embedding (SimQE) method for KT is proposed, with its central feature being the utilization of weighted and attributed meta-paths for extracting question similarity. To capture multi-dimensional question similarity semantics by integrating multiple relations, various meta-paths are constructed for learning question embeddings separately. These embeddings, each encoding different similarity semantics, are then fused to serve the task of KT. To capture finer-grained similarity by leveraging the relationship attributes and node attributes on the meta-paths, the  biased random walk algorithm  is designed. In addition, the  auxiliary node generation method  is proposed to capture high-order question similarity. Finally, extensive experiments conducted on six datasets demonstrate that SimQE performs the best among 10 representative question embedding methods. Furthermore, SimQE proves to be more effective in alleviating the problem of data sparsity.}
}


@article{DBLP:journals/tkdd/GuanYYZLX25,
	author = {Zhihao Guan and
                  Jia{-}Qi Yang and
                  Yang Yang and
                  Hengshu Zhu and
                  Wenjie Li and
                  Hui Xiong},
	title = {JobFormer: Skill-Aware Job Recommendation with Semantic-Enhanced Transformer},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {1},
	pages = {18:1--18:20},
	year = {2025},
	url = {https://doi.org/10.1145/3701735},
	doi = {10.1145/3701735},
	timestamp = {Fri, 07 Mar 2025 18:31:23 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/GuanYYZLX25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Job recommendation aims to provide potential talents with suitable job descriptions (JDs) consistent with their career trajectory, which plays an essential role in proactive talent recruitment. In real-world management scenarios, the available JD-user records always consist of JDs, user profiles, and click data, in which the user profiles are typically summarized as the user's skill distribution for privacy reasons. Although existing sophisticated recommendation methods can be directly employed, effective recommendation still has challenges considering the information deficit of JD itself and the natural heterogeneous gap between JD and user profile. To address these challenges, we proposed a novel skill-aware recommendation model based on the designed semantic-enhanced Transformer to parse JDs and complete personalized job recommendation. Specifically, we first model the relative items of each JD and then adopt an encoder with the local-global attention mechanism to better mine the intra-job and inter-job dependencies from JD tuples. Moreover, we adopt a two-stage learning strategy for skill-aware recommendation, in which we utilize the skill distribution to guide JD representation learning in the recall stage and then combine the user profiles for final prediction in the ranking stage. Consequently, we can embed rich contextual semantic representations for learning JDs, while skill-aware recommendation provides effective JD-user joint representation for click-through rate (CTR) prediction. To validate the superior performance of our method for job recommendation, we present a thorough empirical analysis of large-scale real-world and public datasets to demonstrate its effectiveness and interpretability.}
}


@article{DBLP:journals/tkdd/HongHXRWML25,
	author = {Xiaobin Hong and
                  Jiangyi Hu and
                  Taishan Xu and
                  Xiancheng Ren and
                  Feng Wu and
                  Xiangkai Ma and
                  Wenzhong Li},
	title = {MagNet: Multilevel Dynamic Wavelet Graph Neural Network for Multivariate
                  Time Series Classification},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {1},
	pages = {19:1--19:22},
	year = {2025},
	url = {https://doi.org/10.1145/3703915},
	doi = {10.1145/3703915},
	timestamp = {Fri, 07 Mar 2025 18:31:23 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/HongHXRWML25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Multivariate Time Series Classification (MTSC)  is a fundamental data mining task, which is widely applied in the fields like health care and energy management. However, the existing MTSC methods are mostly adapted from univariate versions and model the static patterns among series in the time domain. We argue they fail to capture the inter-dependencies across variables and rarely consider the unique dynamic features in multilevel frequencies, which are susceptible to signal noise and lack sufficient feature extraction capability to achieve satisfactory classification accuracy. To address these issues, we propose a novel framework called  Multilevel Dynamic Wavelet Graph Neural Network (MagNet) , which effectively captures inherent temporal-frequency dependencies in multivariate time series data in a global view, facilitating the information flow among inter-related variables and leveraging learnable  Graph Neural Networks (GNNs)  to uncover dynamic frequency dependencies. We propose an orthogonal temporal convolution layer that utilizes soft orthogonal losses to constrain features learned at different frequency components to reduce feature redundancy. Additionally, we introduce a hierarchical graph coarsening operator to address the flat learning challenges in traditional GNNs. Our dynamic wavelet GNN and hierarchical coarsening enable deep model stacking and end-to-end learning. Extensive experiments on 30 UEA benchmarks demonstrate that our method outperforms the state-of-the-art baselines in the MTSC tasks.}
}


@article{DBLP:journals/tkdd/WuWGJL25,
	author = {Yuchen Wu and
                  Huandong Wang and
                  Changzheng Gao and
                  Depeng Jin and
                  Yong Li},
	title = {GeoGail: {A} Model-Based Imitation Learning Framework for Human Trajectory
                  Synthesizing},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {1},
	pages = {20:1--20:23},
	year = {2025},
	url = {https://doi.org/10.1145/3699961},
	doi = {10.1145/3699961},
	timestamp = {Sun, 02 Nov 2025 21:29:25 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/WuWGJL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Synthesized human trajectories are crucial for a large number of applications. Existing solutions are mainly based on the generative adversarial network (GAN), which is limited due to the lack of modeling the human decision-making process. In this article, we propose a novel imitation learning-based method to synthesize human trajectories. This model utilizes a novel semantics-based interaction mechanism between the decision-making strategy and visitations to diverse geographical locations to model them in the semantic domain in a uniform manner. To augment the modeling ability to the real-world human decision-making policy, we propose a feature extraction model to extract the internal latent factors of variation of different individuals and then propose a novel self-attention-based policy net to capture the long-term correlation of mobility and decision-making patterns. Then, to better reward users’ mobility behavior, we propose a novel multi-scale reward net combined with mutual information to model the instant reward, long-term reward, and individual characteristics in a cohesive manner. Extensive experimental results on two real-world trajectory datasets show that our proposed model can synthesize the most high-quality trajectory data compared with six state-of-the-art baselines in terms of a number of key usability metrics and can well support practical applications based on trajectory data, demonstrating its effectiveness. Furthermore, our proposed method can learn explainable knowledge automatically from data, including explainable statistical features of trajectories and statistical relation between decision-making policy and features.}
}


@article{DBLP:journals/tkdd/HangZ25,
	author = {Jun{-}Yi Hang and
                  Min{-}Ling Zhang},
	title = {Dual Perspective of Label-Specific Feature Learning for Multi-Label
                  Classification},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {1},
	pages = {21:1--21:30},
	year = {2025},
	url = {https://doi.org/10.1145/3705006},
	doi = {10.1145/3705006},
	timestamp = {Fri, 07 Mar 2025 18:31:23 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/HangZ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Label-specific features work as an effective supervised feature manipulation strategy to account for distinct discriminative properties of each class label in multi-label classification. Existing approaches implement this strategy in its primal form, i.e., finding the most pertinent features specific to each class label and directly inducing classifiers on these features. Instead of such a straightforward implementation, a dual perspective for label-specific feature learning is investigated in this article. As a dual problem of existing primal one, we consider label-specific discriminative properties by identifying non-informative features for each class label and making the discrimination process immutable to variations of identified features. Accordingly, a perturbation-based approach  Dela  is presented, which endows classifiers with immutability on simultaneously identified non-informative features by solving a probabilistically relaxed expected risk minimization problem. Furthermore, we touch the realistic issue of label-specific feature learning in a weakly supervised scenario via extending  Dela  to accommodate to multi-label data with missing labels. Comprehensive experiments show that our approach outperforms the state-of-the-art counterparts.}
}


@article{DBLP:journals/tkdd/SongDYLL25,
	author = {Yiwen Song and
                  Jingtao Ding and
                  Jian Yuan and
                  Qingmin Liao and
                  Yong Li},
	title = {Controllable Human Trajectory Generation Using Profile-Guided Latent
                  Diffusion},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {1},
	pages = {22:1--22:25},
	year = {2025},
	url = {https://doi.org/10.1145/3701736},
	doi = {10.1145/3701736},
	timestamp = {Sun, 02 Nov 2025 21:29:25 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/SongDYLL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Trajectory generation is a vital element in AI applications. Firstly, it enables simulation such as traffic simulation and epidemic spreading modeling. Secondly, it can provide synthetic privacy-preserving data for training AI models. Notably, trajectory generation featuring controllable user profiles holds substantial value in generating customized mobility trajectories tailored to diverse requirements. However, relevant work is still lacking. On the one hand, traditional deep generative models fall short in guiding controllable trajectory generation due to the statistical nature of human mobility patterns and the corresponding insufficient control mechanisms. On the other hand, though the diffusion model has demonstrated strong generative capabilities in many fields, to achieve controllable generation on discrete trajectory data, we still need to redesign the structure of the continuous diffusion model. In this article, we introduce a controllable trajectory generation framework that leverages a continuous diffusion model and classifier guidance for more robust condition control. Our proposed framework comprises two modules: a latent trajectory diffusion model and a trajectory classifier for profile guidance. Experiments on two real-world mobility datasets consistently demonstrate its capability of generating trajectories matching given user profiles and conforming to human mobility patterns. Our source code and trained models are released at  https://github.com/tsinghua-fib-lab/User-Profile-Guided-Latent-Diffusion .}
}


@article{DBLP:journals/tkdd/ZhuRHDRSK25,
	author = {Jiong Zhu and
                  Aishwarya Reganti and
                  Edward W. Huang and
                  Charles Dickens and
                  Nikhil Rao and
                  Karthik Subbian and
                  Danai Koutra},
	title = {Simplifying Distributed Neural Network Training on Massive Graphs:
                  Randomized Partitions Improve Model Aggregation},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {1},
	pages = {23:1--23:26},
	year = {2025},
	url = {https://doi.org/10.1145/3701563},
	doi = {10.1145/3701563},
	timestamp = {Fri, 07 Mar 2025 18:31:23 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/ZhuRHDRSK25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Distributed graph neural network (GNN) training facilitates learning on massive graphs that surpass the storage and computational capabilities of a single machine. Traditional distributed frameworks strive for performance parity with centralized training by maximally recovering cross-instance node dependencies, relying either on inter-instance communication or periodic fallback to centralized training. However, these processes create overhead and constrain the scalability of the framework. In this work, we propose a streamlined framework for distributed GNN training that eliminates these costly operations, yielding improved scalability, convergence speed, and performance over state-of-the-art approaches. Our framework (1) comprises independent trainers that  asynchronously  learn local models from locally available parts of the training graph and (2) synchronizes these local models only through periodic (time-based) model aggregation. Contrary to prevailing belief, our theoretical analysis shows that it is not essential to maximize the recovery of cross-instance node dependencies to achieve performance parity with centralized training. Instead, our framework leverages randomized assignment of nodes or super-nodes (i.e., collections of original nodes) to partition the training graph in order to enhance data uniformity and minimize discrepancies in gradient and loss function across instances. Experiments on social and e-commerce networks with up to 1.3 billion edges show that our proposed framework achieves state-of-the-art performance and 2.31 ×  speedup compared to the fastest baseline despite using less training data.}
}


@article{DBLP:journals/tkdd/LiuRLY25,
	author = {Kaijun Liu and
                  Sijie Ruan and
                  Cheng Long and
                  Liang Yu},
	title = {Modeling On-road Trajectories with Multi-task Learning},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {1},
	pages = {24:1--24:26},
	year = {2025},
	url = {https://doi.org/10.1145/3705005},
	doi = {10.1145/3705005},
	timestamp = {Fri, 07 Mar 2025 18:31:23 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/LiuRLY25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the increasing popularity of GPS modules, there are various urban applications such as car navigation relying on trajectory data modeling. In this work, we study the problem of modeling on-road trajectories, which is to predict the next road segment given a partial GPS trajectory. Existing methods that model trajectories with Markov chain or recurrent neural network suffer from various issues, including limited capability of sequential modeling, insufficiency of incorporating the road network context, and lack of capturing the underlying semantics of trajectories. In this article, we propose a new trajectory modeling framework called Multi-task Modeling for Trajectories (MMTraj+), which avoids these issues. Specifically, MMTraj+ uses multi-head self-attention networks for sequential modeling, captures the overall road network as the context information for road segment embedding, and performs an auxiliary task of predicting the trajectory destination information (namely the ID and bearing angle) to better guide the main trajectory modeling task (controlled by a carefully designed gating mechanism). In addition, we tailor MMTraj+ for the cases where the destination information is known by dropping its auxiliary task of predicting the trajectory destination information. Extensive experiments conducted on real-world datasets demonstrate the superiority of the proposed method over the baseline methods.}
}


@article{DBLP:journals/tkdd/HeXBWSH25,
	author = {Kun He and
                  Xiaodong Xin and
                  Jialu Bao and
                  Meng Wang and
                  Bart Selman and
                  John E. Hopcroft},
	title = {Structure Amplification on Multi-layer Stochastic Block Models},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {1},
	pages = {25:1--25:26},
	year = {2025},
	url = {https://doi.org/10.1145/3706111},
	doi = {10.1145/3706111},
	timestamp = {Thu, 07 Aug 2025 10:37:31 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/HeXBWSH25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Much of the complexity of social, biological, and engineering systems arises from the complicated interactions among the entities in the corresponding networks. A number of network analysis tools have been successfully used to discover latent structures termed communities in such networks. However, some communities with relatively weak structures can be difficult to uncover because they are obscured by other stronger connections. To cope with this situation, our previous work proposes an algorithm called HICODE to detect and amplify the dominant and hidden community structures. In this work, we conduct a comprehensive and systematic theoretical analysis on the impact of hidden community structure and the efficacy of the HICODE algorithm, as well as provide illustrations of the detection process and results. Specifically, we define a multi-layer stochastic block model and use this model to explain why the existence of hidden structure makes the detection of dominant structure harder than equivalent random noises, which can also explain why many community detection algorithms only focusing on the dominant structure do not work well as expected. We then provide theoretical analysis that the iterative reducing methods could help to enhance the discovery of hidden structure as well as the dominant structure in the multi-layer stochastic block model for the two cases of accurate and inaccurate detection. Finally, visual simulations and experimental results are presented to show the process of HICODE algorithm and the impact of different number of layers on the detection quality.}
}


@article{DBLP:journals/tkdd/QinPWS25,
	author = {Yalan Qin and
                  Nan Pu and
                  Hanzhou Wu and
                  Nicu Sebe},
	title = {Margin-aware Noise-robust Contrastive Learning for Partially View-aligned
                  Problem},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {1},
	pages = {26:1--26:20},
	year = {2025},
	url = {https://doi.org/10.1145/3707646},
	doi = {10.1145/3707646},
	timestamp = {Mon, 03 Mar 2025 22:25:33 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/QinPWS25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this article, we study a challenging problem in contrastive learning when just a portion of data is aligned in multi-view dataset due to temporal, spatial, or spatio-temporal asynchronism across views. It is important to study partially view-aligned data since this type of data is common in real-world application and easily leads to data inconsistency among different views. Such a Partially View-aligned Problem (PVP) in contrastive learning has been relatively less touched so far, especially in downstream tasks, i.e., classification and clustering. In order to solve this problem, we introduce a flexible margin and propose margin-aware noise-robust contrastive learning to simultaneously identify the within-category counterparts from the other view of one data point based on the established cross-view correspondence and learn a shared representation. To be specific, the proposed learning framework is built on a novel margin-aware noise-robust contrastive loss. Since data pairs are used as input for the proposed margin-aware noise-robust contrastive learning, we build positive pairs according to the known correspondences and negative pairs in the manner of random sampling. Our margin-aware noise-robust contrastive learning framework is able to effectively reduce or remove the impacts caused by the possible existing noise for the constructed pairs in a margin-aware manner, i.e., false negative pairs led by random sampling in PVP. We relax the proposed margin-aware noise-robust contrastive loss and then give a detailed mathematical analysis for the effectiveness of our loss. As an instantiation, we construct an example under the proposed margin-aware noise-robust contrastive learning framework for validation in this work. To the best of our knowledge, this is the first attempt of extending contrastive learning to a margin-aware noise-robust version for dealing with PVP. We also enrich the learning paradigm when there is noise in the data. Extensive experiments on different datasets demonstrate the promising performance of the proposed method in the classification and clustering tasks.}
}


@article{DBLP:journals/tkdd/LiangJZCL25,
	author = {Ruicheng Liang and
                  Yuanchun Jiang and
                  Feida Zhu and
                  Ling Cheng and
                  Huiwen Liu},
	title = {Defending Federated Recommender Systems against Untargeted Attacks:
                  {A} Contribution-Aware Robust Aggregation Scheme},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {1},
	pages = {27:1--27:28},
	year = {2025},
	url = {https://doi.org/10.1145/3706112},
	doi = {10.1145/3706112},
	timestamp = {Fri, 07 Mar 2025 18:31:23 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/LiangJZCL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated recommender systems (FedRSs) effectively tackle the tradeoff between recommendation accuracy and privacy preservation. However, recent studies have revealed severe vulnerabilities in FedRSs, particularly against untargeted attacks seeking to undermine their overall performance. Defense methods employed in traditional recommender systems are not applicable to FedRSs, and existing robust aggregation schemes for other federated learning-based applications have proven ineffective in FedRSs. Building on the observation that malicious clients contribute negatively to the training process, we design a novel contribution-aware robust aggregation scheme to defend FedRSs against untargeted attacks, named contribution-aware Bayesian knowledge distillation aggregation (ConDA), comprising two key components for the defense. In the first contribution estimation component, we decentralize the estimation from the server side to the client side and propose an ensemble-based Shapley value to enable the efficient calculation of contributions, addressing the limitations of lacking auxiliary validation data and high computational complexity. In the second contribution-aware aggregation component, we merge the decentralized contributions via a majority voting mechanism and integrate the merged contributions into a Bayesian knowledge distillation aggregation scheme for robust aggregation, mitigating the impact of unreliable contributions induced by attacks. We evaluate the effectiveness and efficiency of ConDA on two real-world datasets from movie and music service providers. Through extensive experiments, we demonstrate the superiority of ConDA over the baseline robust aggregation schemes.}
}


@article{DBLP:journals/tkdd/AydinY25,
	author = {Soner Aydin and
                  Sinan Yildirim},
	title = {Bayesian Frequency Estimation under Local Differential Privacy with
                  an Adaptive Randomized Response Mechanism},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {2},
	pages = {28:1--28:40},
	year = {2025},
	url = {https://doi.org/10.1145/3706584},
	doi = {10.1145/3706584},
	timestamp = {Wed, 11 Jun 2025 21:01:27 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/AydinY25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Frequency estimation plays a critical role in many applications involving personal and private categorical data. Such data are often collected sequentially over time, making it valuable to estimate their distribution online while preserving privacy. We propose AdOBEst-LDP, a new algorithm for adaptive, online Bayesian estimation of categorical distributions under local differential privacy (LDP). The key idea behind AdOBEst-LDP is to enhance the utility of future privatized categorical data by leveraging inference from previously collected privatized data. To achieve this, AdOBEst-LDP uses a new adaptive LDP mechanism to collect privatized data. This LDP mechanism constrains its output to a  subset  of categories that “predicts” the next user’s data. By adapting the subset selection process to the past privatized data via Bayesian estimation, the algorithm improves the utility of future privatized data. To quantify utility, we explore various well-known information metrics, including (but not limited to) the Fisher information matrix, total variation distance, and information entropy. For Bayesian estimation, we utilize  posterior sampling  through stochastic gradient Langevin dynamics, a computationally efficient approximate Markov chain Monte Carlo (MCMC) method. We provide a theoretical analysis showing that (i) the posterior distribution of the category probabilities targeted with Bayesian estimation converges to the true probabilities even for approximate posterior sampling, and (ii) AdOBEst-LDP eventually selects the optimal subset for its LDP mechanism with high probability if posterior sampling is performed exactly. We also present numerical results to validate the estimation accuracy of AdOBEst-LDP. Our comparisons show its superior performance against non-adaptive and semi-adaptive competitors across different privacy levels and distributional parameters.}
}


@article{DBLP:journals/tkdd/WangZLWTHC25,
	author = {Zimu Wang and
                  Hao Zou and
                  Jiashuo Liu and
                  Jiayun Wu and
                  Pengfei Tian and
                  Yue He and
                  Peng Cui},
	title = {AdaptSel: Adaptive Selection of Biased and Debiased Recommendation
                  Models for Varying Test Environments},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {2},
	pages = {29:1--29:39},
	year = {2025},
	url = {https://doi.org/10.1145/3706637},
	doi = {10.1145/3706637},
	timestamp = {Wed, 11 Jun 2025 21:01:27 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/WangZLWTHC25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recommendation systems are frequently challenged by pervasive biases in the training set that can compromise model effectiveness. To address this issue, various debiasing techniques have been developed to eliminate biases and produce debiased models. However, when encountering varying test environments, some data patterns manifested by the training data could be beneficial to the model’s performance. Completely removing biases may overlook the beneficial data patterns and consequently diminish recommendation accuracy. Thus, it is crucial to carefully integrate certain biases to optimize performance, while the ideal level of bias integration is highly dependent on the test environment. Moreover, these systems operate in dynamic scenarios where the test environments could vary, necessitating an adaptive integration strategy customized to the environment. Our research establishes that discrepancies in predictions of models can guide the selection of the most fitting model for specific situations. Building on this understanding, we present AdaptSel, a pioneering method for the adaptive selection of the superior model during the testing phase. Empirical evaluations substantiate the foundational assumptions of AdaptSel, accentuating its effectiveness in adaptively selecting the most suitable model for varying test environments.}
}


@article{DBLP:journals/tkdd/CaiCCQYW25,
	author = {Qiqi Cai and
                  Jian Cao and
                  Yirong Chen and
                  Shiyou Qian and
                  Liangxiao Yuan and
                  Jie Wang},
	title = {{PREFER:} {A} Pre-trained Model Recommendation Framework for Edge
                  Computing Enabled Traffic Flow Prediction},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {2},
	pages = {30:1--30:26},
	year = {2025},
	url = {https://doi.org/10.1145/3707464},
	doi = {10.1145/3707464},
	timestamp = {Wed, 11 Jun 2025 21:01:27 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/CaiCCQYW25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The recent years have witnessed a surge in the development of traffic flow prediction methods, often deployed on cloud platforms to offer predictive services for entire transportation networks. However, the processes of training and executing a model for the entire traffic network are both time-consuming and computationally expensive. As a result, the utilization of edge servers for local sub-network prediction services has gained prominence. Nevertheless, training prediction models for numerous sub-networks within the extensive traffic network remains a time-intensive and computing resource-consuming task. To tackle this challenge, this article introduces the Pre-trained model REcommendation Framework for Edge computing enabled tRaffic flow prediction (PREFER). PREFER trains a set of traffic flow prediction models on selected sub-networks, then recommends optimal pre-trained models for edge servers. The recommendation is specifically based on performance prediction, integrating neural collaborative filtering and traffic flow characteristics. Experiments conducted on real datasets reveal that the pre-trained models recommended by PREFER perform close to the actual optimal ones and significantly outperform existing recommendation algorithms.}
}


@article{DBLP:journals/tkdd/HeZBFYY25,
	author = {Qiang He and
                  Zelin Zhang and
                  Tingting Bi and
                  Hui Fang and
                  Xiushuang Yi and
                  Keping Yu},
	title = {Adaptive Rumor Suppression on Social Networks: {A} Multi-Round Hybrid
                  Approach},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {2},
	pages = {31:1--31:24},
	year = {2025},
	url = {https://doi.org/10.1145/3701738},
	doi = {10.1145/3701738},
	timestamp = {Wed, 11 Jun 2025 21:01:27 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/HeZBFYY25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Rumor suppression is targeted at diminishing the impact of false and negative information within social networks by decreasing the prevalence of belief in such rumors among individuals, utilizing diverse strategies. Previous studies have broadly delineated rumor suppression strategies into two primary categories: targeting key nodes or edges for obstruction, and enlisting high-influence nodes to disseminate truth-related accurate information. Traditionally, employing a singular strategy involves utilizing a static algorithm throughout the rumor suppression endeavor. This method, however, encounters difficulties in adapting to fluctuating external conditions, rendering it less efficacious in the management of rumor proliferation. In response to these challenges, we introduce the concept of Adaptive Rumor Suppression (ARS), which aims to dynamically counter rumors by taking into account the nuances of propagation dynamics and the surrounding environmental context. We propose a multi-label state transition linear threshold model to more closely mirror the complex process of information diffusion across social networks. Furthermore, we advocate for a multi-round hybrid strategy that amalgamates blocking and clarification tactics to address the ARS problem within the confines of limited resource allocations. To navigate the complexities of ARS, we introduce the Hybrid Strategy of Each Round (HS-R) algorithm, which synergizes multiple strategies to effectively counter the spread of rumors. In extension, we present the Multi-Round Multi-Label (MRML) algorithm, designed to augment the efficiency of the HS-R algorithm. Experimental evaluations conducted on authentic social network datasets illustrate that our methodologies significantly outshine baseline algorithms, offering a more effective and adaptable solution to curb rumor propagation across varied environments.}
}


@article{DBLP:journals/tkdd/MaoJYWXLYLZ25,
	author = {Zhengyang Mao and
                  Wei Ju and
                  Siyu Yi and
                  Yifan Wang and
                  Zhiping Xiao and
                  Qingqing Long and
                  Nan Yin and
                  Xinwang Liu and
                  Ming Zhang},
	title = {Learning Knowledge-diverse Experts for Long-tailed Graph Classification},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {2},
	pages = {32:1--32:24},
	year = {2025},
	url = {https://doi.org/10.1145/3705323},
	doi = {10.1145/3705323},
	timestamp = {Mon, 04 Aug 2025 19:02:54 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/MaoJYWXLYLZ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graph neural networks (GNNs)  have shown remarkable success in graph-level classification tasks. However, most of the existing GNN-based studies are based on balanced datasets, while many real-world datasets exhibit long-tailed distributions. In such datasets, the tail classes receive limited attention during training, leading to prediction bias and degraded performance. To address this issue, a range of long-tailed learning strategies have been proposed, such as data re-balancing and transfer learning. However, these approaches encounter several challenges, including insufficient representation capacity for tail classes and their evaluation solely on uniform test data, limiting their capacity to handle unknown class distributions. To tackle these challenges, we introduce a novel framework, namely  Knowledge-diverse Experts (KDEX)  for long-tailed graph classification. Our KDEX leverages a dynamic memory module to enable the transfer of knowledge from head to tail, which improves the representation ability of the tail. To deal with unknown test distributions, KDEX introduces a knowledge-diverse expert training approach to train experts with different capacities in managing various test distributions. Moreover, we train the hierarchical router in a self-supervised manner to dynamically aggregate each knowledge-diverse expert during testing. Experimental results on multiple benchmarks reveal that our KDEX outperforms current baselines in both standard and test-agnostic long-tailed graph classification.}
}


@article{DBLP:journals/tkdd/XiaXZZ25,
	author = {Haisong Xia and
                  Wanyue Xu and
                  Zuobai Zhang and
                  Zhongzhi Zhang},
	title = {Means of Hitting Times for Random Walks on Graphs: Connections, Computation,
                  and Optimization},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {2},
	pages = {33:1--33:35},
	year = {2025},
	url = {https://doi.org/10.1145/3708561},
	doi = {10.1145/3708561},
	timestamp = {Wed, 11 Jun 2025 21:01:27 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/XiaXZZ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {For random walks on graph   with   vertices and   edges, the mean hitting time   from a vertex chosen from the stationary distribution to vertex   measures the importance for  , while the Kemeny constant   is the mean hitting time from one vertex to another selected randomly according to the stationary distribution. In this article, we first establish a connection between the two quantities, representing   in terms of   for all vertices. We then develop an efficient algorithm estimating   for all vertices and   in nearly linear time of  . Moreover, we extend the centrality   of a single vertex to   of a vertex set  , and establish a link between   and some other quantities. We further study the NP-hard problem of selecting a group   of   vertices with minimum  , whose objective function is monotonic and supermodular. We finally propose two greedy algorithms approximately solving the problem. The former has an approximation factor   and   running time, while the latter returns a  -approximation solution in nearly-linear time of  , for any parameter  . Extensive experiment results validate the performance of our algorithms.}
}


@article{DBLP:journals/tkdd/DiZYZC25,
	author = {Shimin Di and
                  Yongqi Zhang and
                  Quanming Yao and
                  Xiaofang Zhou and
                  Lei Chen},
	title = {Efficient Latent-based Scoring Function Search for N-ary Relational
                  Knowledge Bases},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {2},
	pages = {34:1--34:26},
	year = {2025},
	url = {https://doi.org/10.1145/3707644},
	doi = {10.1145/3707644},
	timestamp = {Wed, 11 Jun 2025 21:01:27 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/DiZYZC25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Designing a proper scoring function is the key to ensuring the excellent performance of knowledge base (KB) embedding. Recently, the scoring function search method introduces the automated machine learning technique to design the data-aware scoring function for the given binary relational data (a.k.a. knowledge graph, KG), which can consistently achieve good performance on different data sets. However, the current data-aware search method is still not as good as desired. First, the existing model can only search scoring functions on the given binary relational data, which is a special form of N-ary relational KBs. Second, observing that existing scoring functions can exhibit distinct performance on different semantic patterns, we are motivated to explore such semantics by searching pattern-aware scoring functions. Unfortunately, it is hard to extend existing search approaches to the scenarios of N-ary and pattern-aware due to the search efficiency and effectiveness issues. In this paper, we propose latent-based factors to model relational patterns and an efficient search algorithm on the N-ary scenario, i.e., efficient  LA tent-based  SCO ring function search for N-ary relational KBs (LASCO). The empirical results of LASCO on binary and N-ary relational data sets demonstrate that the proposed method can efficiently search pattern-aware scoring functions and achieve better embedding performance than advanced baselines.}
}


@article{DBLP:journals/tkdd/MoghaddamKLLY25,
	author = {Arya Hadizadeh Moghaddam and
                  Mohsen Nayebi Kerdabadi and
                  Bin Liu and
                  Mei Liu and
                  Zijun Yao},
	title = {Discovering Time-aware Hidden Dependencies with Personalized Graphical
                  Structure in Electronic Health Records},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {2},
	pages = {35:1--35:21},
	year = {2025},
	url = {https://doi.org/10.1145/3709143},
	doi = {10.1145/3709143},
	timestamp = {Wed, 11 Jun 2025 21:01:27 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/MoghaddamKLLY25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Over the past decade, significant advancements in mining electronic health records (EHRs) have enabled a broad range of decision-support applications and offered an unprecedented capacity for predicting critical events such as disease prognosis and mortality in healthcare. Despite the availability of comprehensive coding systems in EHRs (e.g., ICD-9), which are designed to record diverse information on diseases, procedures, and medications over time, the complex and dynamic dependencies among the recorded data are usually not captured. This limitation often hinders the contextual understanding of medical observations for effective EHR representation learning. Therefore, there is a compelling need to discover a hidden “EHR graph” that represents the medical relationship between the observed features according to a patient’s history. These hidden graphs consisting of the medical codes from the same visits can offer a comprehensive insight derived from disease-to-disease, disease-to-drug, and drug-to-drug dependencies. However, it is still unclear how to address the challenge that the dependencies may vary from patient to patient, and they can dynamically evolve from one visit to another. To this end, we propose  Time-aware Personalized Graph Transformer  (TPGT), a novel attention-based time-aware hidden graph model, that captures the personalized graphical structures among observed medical codes and summarizes the temporal code dependencies over time to improve patient representation for outcome prediction. Built upon an intra-visit and an inter-visit dual-attention mechanism to model patients’ EHR graphs, our model offers an interpretability of what diagnosis or medication in a patient’s history can interact, and how those interactions may change over time. We conduct extensive experiments on two real-world EHR datasets for different healthcare predictive tasks: acute kidney injury (AKI) prediction and ICU mortality prediction. The experimental results demonstrate a significant performance improvement of the proposed model over baselines through multi-aspect quantitative evaluation. Furthermore, we perform various qualitative studies to validate the interpretability of the model which highlights the application of the proposed method in the context of personalized medicine.}
}


@article{DBLP:journals/tkdd/WangTQGH25,
	author = {Huan Wang and
                  Yu Teng and
                  Lingsong Qin and
                  Xuan Guo and
                  Po Hu},
	title = {A Multiple Attention Layer-shareable Method for Link Prediction in
                  Multilayer Networks},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {2},
	pages = {36:1--36:22},
	year = {2025},
	url = {https://doi.org/10.1145/3709142},
	doi = {10.1145/3709142},
	timestamp = {Thu, 20 Nov 2025 14:41:01 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/WangTQGH25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Link prediction in multilayer networks aims to predict missing links at the target layer by incorporating structural information from both auxiliary layers and the target layer. Existing methods tend to learn layer-specific knowledge to maximize the link prediction performance on a specific network layer. However, they have difficulty incorporating multilayer structural information to improve the link prediction performance. Therefore, we propose a Multiple Attention Layer-shareable Method (MALM) for link prediction in multilayer networks, which consists of a feature encoder, a knowledge learner, and a fusion predictor. The feature encoder introduces multiple attention mechanisms to encode the feature representations of links by differentiating the importance of structural information for each link. In cooperation with the feature encoder, the knowledge learner splits the link prediction tasks into different layers and employs meta-learning to learn layer-shareable knowledge from these link prediction tasks. Finally, the fusion predictor combines the learned layer-shareable knowledge with the layer-specific knowledge at the target layer for link prediction. Experiments on real-world datasets demonstrate that the proposed MALM outperforms existing state-of-the-art baselines in link prediction in multilayer networks.}
}


@article{DBLP:journals/tkdd/ZhangLZLL25,
	author = {Yingxue Zhang and
                  Yanhua Li and
                  Xun Zhou and
                  Zhenming Liu and
                  Jun Luo},
	title = {\emph{C}\({}^{\mbox{3}}\)-GAN+: Complex-Condition-Controlled Generative
                  Adversarial Networks with Enhanced Embedding},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {2},
	pages = {37:1--37:21},
	year = {2025},
	url = {https://doi.org/10.1145/3712264},
	doi = {10.1145/3712264},
	timestamp = {Thu, 03 Jul 2025 20:32:21 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/ZhangLZLL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Given historical traffic distributions and associated urban conditions observed in a city, the conditional urban traffic estimation problem aims at estimating realistic future projections of the traffic under a set of new urban conditions, e.g., new bus routes, rainfall intensity, and travel demands. The problem is important in reducing traffic congestion, improving public transportation efficiency, and facilitating urban planning. However, solving this problem is challenging due to the strong spatial dependencies of traffic patterns and the complex relations between the traffic and urban conditions. Recently, we proposed a  Complex-Condition-Controlled Generative Adversarial Network ( C 3 -GAN) , which tackles both of the challenges and solves the urban traffic estimation problem under various complex conditions by adding a fixed embedding network and an inference network on top of the standard conditional GAN model. The randomly chosen embedding network transforms the complex conditions to latent vectors, and the inference network enhances the connections between the embedded vectors and the traffic data. However, a randomly chosen embedding network cannot always successfully extract features of complex urban conditions, which indicates  C 3 -GAN is unable to uniquely map different urban conditions to proper latent distributions. Thus,  C 3 -GAN would fail in certain traffic estimation tasks. Besides,  C 3 -GAN is hard to train due to vanishing gradients and mode collapse problems. To address these issues, in this article, we extend our prior work by introducing a new deep generative model, namely,  C 3 -GAN + , which significantly improves the estimation performance and model stability.  C 3 -GAN +  has new objective, architecture, and training algorithm. The new objective applies Wasserstein loss to the conditional generation case to encourage stable training. Shared convolutional layers between the discriminator and the inference network help to capture spatial dependencies of traffic more efficiently, part of the shared convolutional layers are used to update the embedding network periodically aiming to encourage good representation and avoid model divergence. Extensive experiments on real-world datasets demonstrate that our  C 3 -GAN +  produces high-quality traffic estimations and outperforms state-of-the-art baseline methods.}
}


@article{DBLP:journals/tkdd/HuHQYCX25,
	author = {Hanwen Hu and
                  Zhangchi Han and
                  Shiyou Qian and
                  Dingyu Yang and
                  Jian Cao and
                  Guangtao Xue},
	title = {Pattern-oriented Attention Mechanism for Multivariate Time Series
                  Forecasting},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {2},
	pages = {38:1--38:26},
	year = {2025},
	url = {https://doi.org/10.1145/3712606},
	doi = {10.1145/3712606},
	timestamp = {Wed, 11 Jun 2025 21:01:27 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/HuHQYCX25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Multivariate time series forecasting is applied in many domains, such as finance, transportation, and industry. The main challenge of precise forecasting lies in accurately capturing latent dependencies. Recent studies develop various frameworks to reduce computational complexity or to enhance the learning of intricate relationships, while lacking interpretability and generality. In this article, we aim to elucidate the capture of dependencies as the recognition of patterns. We believe that patterns can be formally described from two aspects: the shapes of segments that frequently repeat and the corresponding forms of repetitions. Drawing upon this idea, we design a multivariate time series forecasting model named  PRformer , 1  which incorporates a pattern-oriented attention mechanism and a pattern-based projector. The attention mechanism can perceive different forms of repetitions by embedded with various similarity evaluation metrics between segments, and filter out noise from segments to extract potential patterns with a statistical-driven weighting scheme. The pattern-based projector is employed to form the forecasting results by deriving the representative patterns from the set of potential ones. By incorporating explicit definitions of patterns, PRformer is interpretable and general to various time series scenarios. Experimental results on seven datasets demonstrate that PRformer outperforms six state-of-the-art models by about 10.7% in forecasting accuracy.}
}


@article{DBLP:journals/tkdd/HuXDGTH25,
	author = {Zhihao Hu and
                  Yiran Xu and
                  Mengnan Du and
                  Jindong Gu and
                  Xinmei Tian and
                  Fengxiang He},
	title = {Boosting Fair Classifier Generalization through Adaptive Priority
                  Reweighing},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {2},
	pages = {40:1--40:26},
	year = {2025},
	url = {https://doi.org/10.1145/3665895},
	doi = {10.1145/3665895},
	timestamp = {Wed, 11 Jun 2025 21:01:27 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/HuXDGTH25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the increasing penetration of machine learning applications in critical decision-making areas, calls for algorithmic fairness are more prominent. Although there have been various modalities to improve algorithmic fairness through learning with fairness constraints, their performance does not generalize well in the test set. A performance-promising fair algorithm with better generalizability is needed. This article proposes a novel adaptive reweighing method to eliminate the impact of the distribution shifts between training and test data on model generalizability. Most previous reweighing methods propose to assign a unified weight for each (sub)group. Rather, our method granularly models the distance from the sample predictions to the decision boundary. Our adaptive reweighing method prioritizes samples closer to the decision boundary and assigns a higher weight to improve the generalizability of fair classifiers. Extensive experiments are performed to validate the generalizability of our adaptive priority reweighing method for accuracy and fairness measures (i.e., equal opportunity, equalized odds, and demographic parity) in tabular benchmarks. We also highlight the performance of our method in improving the fairness of language and vision models. The code is available at  https://github.com/che2198/APW .}
}


@article{DBLP:journals/tkdd/ZhangLSLJ25,
	author = {Hengyuan Zhang and
                  Zitao Liu and
                  Chenming Shang and
                  Dawei Li and
                  Yong Jiang},
	title = {A Question-centric Multi-experts Contrastive Learning Framework for
                  Improving the Accuracy and Interpretability of Deep Sequential Knowledge
                  Tracing Models},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {2},
	pages = {41:1--41:25},
	year = {2025},
	url = {https://doi.org/10.1145/3674840},
	doi = {10.1145/3674840},
	timestamp = {Wed, 11 Jun 2025 21:01:27 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/ZhangLSLJ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Knowledge tracing (KT) plays a crucial role in predicting students’ future performance by analyzing their historical learning processes. Deep neural networks (DNNs) have shown great potential in solving the KT problem. However, there still exist some important challenges when applying deep learning techniques to model the KT process. The first challenge lies in modeling the individual question information. This is crucial because students’ knowledge acquisition on questions that share the same set of knowledge components (KCs) may vary significantly. However, due to the large question bank, the average number of interactions per question may not be sufficient. This limitation can potentially result in overfitting of the question embedding and inaccurate question knowledge acquisition state that relies on its corresponding question representation. Furthermore, there is a considerable portion of questions receiving relatively less interaction from students in comparison to the majority of questions. This can further increase the risk of overfitting and lower the accuracy of the obtained question knowledge acquisition state. The second challenge lies in interpreting the prediction results from existing deep learning-based KT models. In real-world applications, while it may not be necessary to have complete transparency and interpretability of the model parameters, it is crucial to present the model’s prediction results in a manner that teachers find interpretable. This makes teachers accept the rationale behind the prediction results and utilize them to design teaching activities and tailored learning strategies for students. However, the inherent black-box nature of deep learning techniques often poses a hurdle for teachers to fully embrace the model’s prediction results. To address these challenges, we propose a Question-centric Multi-experts Contrastive Learning framework for KT called Q-MCKT. This framework explicitly models students’ knowledge acquisition state at both the question and concept levels. It leverages the mixture of experts technique to capture a more robust and accurate knowledge acquisition state in both question and concept levels for prediction. Additionally, a fine-grained question-centric contrastive learning task is introduced to enhance the representations of less interactive questions and improve the accuracy of their corresponding question knowledge acquisition states. Moreover, Q-MCKT utilizes an item response theory-based prediction layer to generate interpretable prediction results based on the knowledge acquisition states obtained from the question and concept knowledge acquisition modules. We evaluate the proposed Q-MCKT framework on four public real-world educational datasets. The experimental results demonstrate that our approach outperforms a wide range of deep learning-based KT models in terms of prediction accuracy while maintaining better model interpretability. To ensure reproducibility, we have provided all the datasets and code on our website at  https://github.com/rattlesnakey/Q-MCKT .}
}


@article{DBLP:journals/tkdd/RongWFLLKH25,
	author = {Yao Rong and
                  Guanchu Wang and
                  Qizhang Feng and
                  Ninghao Liu and
                  Zirui Liu and
                  Enkelejda Kasneci and
                  Xia Hu},
	title = {Efficient {GNN} Explanation via Learning Removal-based Attribution},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {2},
	pages = {42:1--42:23},
	year = {2025},
	url = {https://doi.org/10.1145/3685678},
	doi = {10.1145/3685678},
	timestamp = {Mon, 12 Jan 2026 20:31:19 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/RongWFLLKH25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {As Graph Neural Networks (GNNs) have been widely used in real-world applications, model explanations are required not only by users but also by legal regulations. However, simultaneously achieving high fidelity and low computational costs in generating explanations has been a challenge for current methods. In this work, we propose a framework of GNN explanation named  L e A rn  R emoval-based  A ttribution (LARA) to address this problem. Specifically, we introduce removal-based attribution and demonstrate its substantiated link to interpretability fidelity theoretically and experimentally. The explainer in LARA learns to generate removal-based attribution which enables providing explanations with high fidelity. A strategy of subgraph sampling is designed in LARA to improve the scalability of the training process. In the deployment, LARA can efficiently generate the explanation through a feed-forward pass. We benchmark our approach with other state-of-the-art GNN explanation methods on six datasets. Results highlight the effectiveness of our framework regarding both efficiency and fidelity. In particular, LARA is 3.1 ×  faster and achieves higher fidelity than the state-of-the-art method on the large dataset ogbn-arxiv (more than 160K nodes and 1M edges), showing its great potential in real-world applications. Our source code is available at  https://github.com/yaorong0921/LARA .}
}


@article{DBLP:journals/tkdd/LiLZWLZC25,
	author = {Sihang Li and
                  Yanchen Luo and
                  An Zhang and
                  Xiang Wang and
                  Longfei Li and
                  Jun Zhou and
                  Tat{-}Seng Chua},
	title = {Self-attentive Rationalization for Interpretable Graph Contrastive
                  Learning},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {2},
	pages = {43:1--43:21},
	year = {2025},
	url = {https://doi.org/10.1145/3665894},
	doi = {10.1145/3665894},
	timestamp = {Wed, 11 Jun 2025 21:01:27 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/LiLZWLZC25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graph augmentation is the key component to reveal instance-discriminative features of a graph as its rationale—an interpretation for it—in graph contrastive learning (GCL). Existing rationale-aware augmentation mechanisms in GCL frameworks roughly fall into two categories and suffer from inherent limitations: (1) non-heuristic methods with the guidance of domain knowledge to preserve salient features, which require expensive expertise and lack generality, or (2) heuristic augmentations with a co-trained auxiliary model to identify crucial substructures, which face not only the dilemma between system complexity and transformation diversitybut also the instability stemming from the co-training of two separated sub-models. Inspired by recent studies on transformers, we propose self-attentive rationale-guided GCL (SR-GCL), which integrates rationale generator and encoder together, leverages the self-attention values in transformer module as a natural guidance to delineate semantically informative substructures from both node- and edge-wise perspectives, and contrasts on rationale-aware augmented pairs. On real-world biochemistry datasets, visualization results verify the effectiveness and interpretability of self-attentive rationalization, and the performance on downstream tasks demonstrates the state-of-the-art performance of SR-GCL for graph model pre-training. Codes are available at  https://github.com/lsh0520/SR-GCL .}
}


@article{DBLP:journals/tkdd/LinZ25,
	author = {Guo Lin and
                  Yongfeng Zhang},
	title = {Fuzzy Neural Logic Reasoning for Robust Classification},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {2},
	pages = {44:1--44:29},
	year = {2025},
	url = {https://doi.org/10.1145/3704728},
	doi = {10.1145/3704728},
	timestamp = {Fri, 21 Nov 2025 10:50:41 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/LinZ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The efficacy of neural networks is widely recognized across a multitude of machine learning tasks, yet their black-box nature impedes the understanding of their decision-making processes. Such lack of explainability limits their use in high-stake fields such as medicine and finance, where transparent decision-making is essential. In contrast, traditional rule-based models offer clear input-output mappings, but often lag in performance when compared to their neural network counterparts. To address this challenge, this study introduces Fuzzy Neural Logic Reasoning (FNLR), a novel architecture that combines the best of both rule-based and deep learning models to achieve performance, interpretability, and noise robustness simultaneously. At its core, FNLR employs a “Symbolic Pre-Training  +  Neural Fine-Tuning” paradigm. Initially, the model adapts a pre-fitted binary decision tree. It then performs a “neuralization” process, replacing each node of the tree with a corresponding neural network equivalent. This transformation is facilitated through three shallow MLP modules, which are trained to emulate the relational operators intrinsic to decision trees. The model architecture is also extensible, allowing it to further boost expressiveness. Furthermore, FNLR incorporates fuzzy logic by proposing novel fuzzy relational operators, accounting for satisfaction degrees of propositions and thus eliminating rigid decision boundaries. This approach enhances model flexibility, enabling all paths of the decision tree to contribute to the target prediction in a weighted manner. Empirical evaluations on tabular datasets from various domains demonstrate that FNLR performs comparably to, or better than, state-of-the-art deep learning models designed for tabular data, while also exhibiting strong robustness to noise.}
}


@article{DBLP:journals/tkdd/DaiW25,
	author = {Enyan Dai and
                  Suhang Wang},
	title = {Towards Prototype-Based Self-Explainable Graph Neural Network},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {2},
	pages = {45:1--45:20},
	year = {2025},
	url = {https://doi.org/10.1145/3689647},
	doi = {10.1145/3689647},
	timestamp = {Sun, 02 Nov 2025 21:29:25 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/DaiW25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graph Neural Networks (GNNs) have shown great ability in modeling graph-structured data for various domains. However, GNNs are known as black-box models that lack interpretability. Without understanding their inner working, we cannot fully trust them, which largely limits their adoption in high-stake scenarios. Though some initial efforts have been taken to interpret the predictions of GNNs, they mainly focus on providing  post hoc  explanations using an additional explainer, which could misrepresent the true inner working mechanism of the target GNN. The works on self-explainable GNNs are rather limited. Therefore, we study a novel problem of learning prototype-based self-explainable GNNs that can simultaneously give accurate predictions and prototype-based explanations on predictions. We design a framework which can learn prototype graphs that capture representative patterns of each class as class-level explanations. The learned prototypes are also used to simultaneously make prediction for a test instance and provide instance-level explanation. Extensive experiments on real-world and synthetic datasets show the effectiveness of the proposed framework for both prediction accuracy and explanation quality.}
}


@article{DBLP:journals/tkdd/ChuangLTDCZH25,
	author = {Yu{-}Neng Chuang and
                  Kwei{-}Herng Lai and
                  Ruixiang Tang and
                  Mengnan Du and
                  Chia{-}Yuan Chang and
                  Na Zou and
                  Xia Hu},
	title = {Fair-RGNN: Mitigating Relational Bias on Knowledge Graphs},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {2},
	pages = {46:1--46:18},
	year = {2025},
	url = {https://doi.org/10.1145/3681792},
	doi = {10.1145/3681792},
	timestamp = {Tue, 13 May 2025 07:31:32 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/ChuangLTDCZH25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Knowledge graph data are prevalent in real-world applications, and knowledge graph neural networks (KGNNs) are essential techniques for knowledge graph representation learning. Although KGNN effectively models the structural information from knowledge graphs, these frameworks amplify the underlying data bias that leads to discrimination towards certain groups or individuals in resulting applications. Additionally, as existing debiasing approaches mainly focus on entity-wise bias, eliminating the multi-hop relational bias that pervasively exists in knowledge graphs remains an open question. However, it is very challenging to eliminate relational bias due to the sparsity of the paths that generate the bias and the non-linear proximity structure of knowledge graphs. To tackle the challenges, we propose Fair-KGNN, a KGNN framework that simultaneously alleviates multi-hop bias and preserves the proximity information of entity-to-relation in knowledge graphs. The proposed framework is generalizable to mitigate relational bias for all types of KGNN. Fair-KGNN is applicable to incorporate two state-of-the-art KGNN models, RGCN and CompGCN, to mitigate gender-occupation and nationality-salary bias. The experiments carried out on three benchmark knowledge graph datasets demonstrate that Fair-KGNN can effectively mitigate unfair situations during representation learning while preserving the predictive performance of KGNN models. The source code of the proposed method is available at:  https://github.com/ynchuang/Mitigating-Relational-Bias-on-Knowledge-Graphs .}
}


@article{DBLP:journals/tkdd/HuangWLLJ25,
	author = {Yuxi Huang and
                  Huandong Wang and
                  Guanghua Liu and
                  Yong Li and
                  Tao Jiang},
	title = {NeuralCODE: Neural Compartmental Ordinary Differential Equations Model
                  with AutoML for Interpretable Epidemic Forecasting},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {2},
	pages = {47:1--47:18},
	year = {2025},
	url = {https://doi.org/10.1145/3694688},
	doi = {10.1145/3694688},
	timestamp = {Wed, 11 Jun 2025 21:01:27 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/HuangWLLJ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In order to prevent the re-emergence of an epidemic, predicting its trend while gaining insight into the intrinsic factors affecting it is a key issue in urban governance. Traditional SIR-like compartment models provide insight into the explanatory parameters of an outbreak, and the vast majority of existing deep learning models can predict the course of an outbreak well, but neither performs well in the other’s domain. Simultaneously, studying the commonalities and diversities in the causes of outbreaks among different countrywide regions is also a way to interrupt outbreaks. To address the issues of outbreak intrinsic relationships and prediction, we propose the Neural Compartmental Ordinary Differential Equations (NeuralCODE) model to study the relationship between population movements and outbreak development in different regions. Furthermore, to incorporate the commonalities and diversities in causes among different regions into the prediction and intrinsic inquiry problem, we propose an AutoML framework. Our results found that simply using the NeuralCODE algorithm could obtain better prediction and insight capabilities within different regions. With the introduction of AutoML, it became possible to explore the factors inherent in the epidemic’s development across regions and further improve the original algorithm’s predictive performance.}
}


@article{DBLP:journals/tkdd/QianZXZZXC25,
	author = {Fulan Qian and
                  Yuanjun Zou and
                  Mengyao Xu and
                  Xuejun Zhang and
                  Chonghao Zhang and
                  Chenchu Xu and
                  Hai Chen},
	title = {A Comprehensive Understanding of the Impact of Data Augmentation on
                  the Transferability of 3D Adversarial Examples},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {2},
	pages = {48:1--48:41},
	year = {2025},
	url = {https://doi.org/10.1145/3673232},
	doi = {10.1145/3673232},
	timestamp = {Wed, 11 Jun 2025 21:01:27 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/QianZXZZXC25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {3D point cloud classifiers exhibit vulnerability to imperceptible perturbations, which poses a serious threat to the security and reliability of deep learning models in practical applications, making the robustness evaluation of deep 3D point cloud models increasingly important. Due to the difficulty in obtaining model parameters, black-box attacks have become a mainstream means of assessing the adversarial robustness of 3D classification models. The core of improving the transferability of adversarial examples generated by black-box attacks is to generate better generalized adversarial examples, where data augmentation has become one of the popular approaches. In this article, we employ five mainstream attack methods and combine six data augmentation strategies, namely point dropping, flipping, rotating, scaling, shearing, and translating, in order to comprehensively explore the impact of these strategies on the transferability of adversarial examples. Our research reveals that data augmentation methods generally improve the transferability of the adversarial examples, and the effect is better when the methods are stacked. The interaction between data augmentation methods, model characteristics, attack, and defense strategies collectively determines the transferability of adversarial examples. In order to comprehensively understand and improve the effectiveness of adversarial examples, it is necessary to comprehensively consider these complex interrelationships.}
}


@article{DBLP:journals/tkdd/XiaoWQFNDZ25,
	author = {Meng Xiao and
                  Min Wu and
                  Ziyue Qiao and
                  Yanjie Fu and
                  Zhiyuan Ning and
                  Yi Du and
                  Yuanchun Zhou},
	title = {Interdisciplinary Fairness in Imbalanced Research Proposal Topic Inference:
                  {A} Hierarchical Transformer-based Method with Selective Interpolation},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {2},
	pages = {49:1--49:21},
	year = {2025},
	url = {https://doi.org/10.1145/3671149},
	doi = {10.1145/3671149},
	timestamp = {Thu, 27 Nov 2025 10:59:59 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/XiaoWQFNDZ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The objective of topic inference in research proposals aims to obtain the most suitable disciplinary division from the discipline system defined by a funding agency. The agency will subsequently find appropriate peer-review experts from their database based on this division. Automated topic inference can reduce human errors caused by manual topic filling, bridge the knowledge gap between funding agencies and project applicants, and improve system efficiency. Existing methods focus on modeling this as a hierarchical multi-label classification problem, using generative models to iteratively infer the most appropriate topic information. However, these methods overlook the gap in scale between interdisciplinary research proposals and non-interdisciplinary ones, leading to an unjust phenomenon where the automated inference system categorizes interdisciplinary proposals as non-interdisciplinary, causing unfairness during the expert assignment. How can we address this data imbalance issue under a complex discipline system and hence resolve this unfairness? In this article, we implement a topic label inference system based on a Transformer encoder–decoder architecture. Furthermore, we utilize interpolation techniques to create a series of pseudo-interdisciplinary proposals from non-interdisciplinary ones during training based on non-parametric indicators, such as cross-topic probabilities and topic occurrence probabilities. This approach aims to reduce the bias of the system during model training. Finally, we conduct extensive experiments on a real-world dataset to verify the effectiveness of the proposed method. The experimental results demonstrate that our training strategy can significantly mitigate the unfairness generated in the topic inference task. To improve the reproducibility of our research, we have released accompanying code by Dropbox. 1}
}


@article{DBLP:journals/tkdd/MaLGZH25,
	author = {Li Ma and
                  Yongchao Liu and
                  Xiaofeng Gao and
                  Peng Zhang and
                  Chuntao Hong},
	title = {Building Robust and Trustworthy {HGNN} Models: {A} Learnable Threshold
                  Approach for Node Classification},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {2},
	pages = {50:1--50:17},
	year = {2025},
	url = {https://doi.org/10.1145/3707645},
	doi = {10.1145/3707645},
	timestamp = {Tue, 14 Oct 2025 11:39:33 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/MaLGZH25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Message passing scheme is a general idea for Graph Neural Networks (GNNs) to learn node representations. During message passing, given a target node, we transform and aggregate the feature vectors of its neighbors and generate a representation vector for the target node. However, real-world graph data is usually constructed from complicated scenarios based on manually pre-defined rules; it is often the case that noisy information gets involved in message passing, thereby resulting in sub-optimal performance for GNNs and also impacting their trustworthiness and reliability. In this study, we present an effective learnable threshold technique that explicitly optimizes heterogeneous graph structure with the goal to maximize performance improvement of GNNs for downstream tasks. We give an explanation about the design of the learnable threshold and show the ability that our model can be applied to large-scale graphs. Experiments on seven datasets show that our model has a powerful ability to deal with homogeneous graphs with low homophily ratio and dense graphs. With the verification of robustness analysis, our model can resist the noisy information, which proves the robustness of our model.}
}


@article{DBLP:journals/tkdd/SuiWSLCLZWH25,
	author = {Yongduo Sui and
                  Shuyao Wang and
                  Jie Sun and
                  Zhiyuan Liu and
                  Qing Cui and
                  Longfei Li and
                  Jun Zhou and
                  Xiang Wang and
                  Xiangnan He},
	title = {A Simple Data Augmentation for Graph Classification: {A} Perspective
                  of Equivariance and Invariance},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {2},
	pages = {51:1--51:24},
	year = {2025},
	url = {https://doi.org/10.1145/3706062},
	doi = {10.1145/3706062},
	timestamp = {Mon, 15 Sep 2025 08:16:37 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/SuiWSLCLZWH25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In graph classification, the out-of-distribution (OOD) issue is attracting great attention. To address this issue, a prevailing idea is to learn stable features, on the assumption that they are substructures causally determining the label and that their relationship with the label is stable to the distributional uncertainty. In contrast, the complementary parts termed environmental features, fail to determine the label solely and hold varying relationships with the label, thus ascribed to the possible reason for the distribution shift. Existing generalization efforts mainly encourage the model’s insensitivity to environmental features. While the sensitivity to stable features is promising to distinguish the crucial clues from the distributional uncertainty but largely unexplored. A paradigm of simultaneously exploring the sensitivity to stable features and insensitivity to environmental features is until-now lacking to achieve the generalizable graph classification, to the best of our knowledge. In this work, we conjecture that generalizable models should be sensitive to stable features and insensitive to environmental features. To this end, we propose a simple yet effective augmentation strategy for graph classification: Equivariant and Invariant Cross-Data Augmentation (EI-CDA). By employing equivariance, given a pair of input graphs, we first estimate their stable and environmental features via masks. Then, we linearly mix the estimated stable features of two graphs and encourage the model predictions faithfully reflect their mixed semantics. Meanwhile, by using invariance, we swap the estimated environmental features of two graphs and keep the predictions invariant. This simple yet effective strategy endows the models with both sensitivity to stable features and insensitivity to environmental features. Extensive experiments show that EI-CDA significantly improves performance and outperforms leading baselines. Our codes are available at:  https://github.com/yongduosui/EI-GNN .}
}


@article{DBLP:journals/tkdd/FanCWH25,
	author = {Mingyuan Fan and
                  Cen Chen and
                  Chengyu Wang and
                  Jun Huang},
	title = {Exploiting Pre-Trained Models and Low-Frequency Preference for Cost-Effective
                  Transfer-based Attack},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {2},
	pages = {52:1--52:18},
	year = {2025},
	url = {https://doi.org/10.1145/3680553},
	doi = {10.1145/3680553},
	timestamp = {Sun, 02 Nov 2025 21:29:25 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/FanCWH25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The transferability of adversarial examples enables practical transfer-based attacks. However, existing theoretical analysis cannot effectively reveal what factors contribute to cross-model transferability. Furthermore, the assumption that the target model dataset is available together with expensive prices of training proxy models also leads to insufficient practicality. We first propose a novel frequency perspective to study the transferability and then identify two factors that impair the transferability: an unchangeable intrinsic difference term along with a controllable perturbation-related term. To enhance the transferability, an optimization task with the constraint that decreases the impact of the perturbation-related term is formulated and an approximate solution for the task is designed to address the intractability of Fourier expansion. To address the second issue, we suggest employing pre-trained models as proxy models, which are freely available. Leveraging these advancements, we introduce cost-effective transfer-based attack ( CTA ), which addresses the optimization task in pre-trained models.  CTA  can be unleashed  against broad applications, at any time, with minimal effort and nearly zero cost to attackers.  This remarkable feature indeed makes  CTA  an effective, versatile, and fundamental tool for attacking and understanding a wide range of target models, regardless of their architecture or training dataset used. Extensive experiments show impressive attack performance of  CTA  across various models trained in seven black-box domains, highlighting the broad applicability and effectiveness of  CTA .}
}


@article{DBLP:journals/tkdd/WangZQLLXDQL25,
	author = {Haochun Wang and
                  Sendong Zhao and
                  Zewen Qiang and
                  Zijian Li and
                  Chi Liu and
                  Nuwa Xi and
                  Yanrui Du and
                  Bing Qin and
                  Ting Liu},
	title = {Knowledge-tuning Large Language Models with Structured Medical Knowledge
                  Bases for Trustworthy Response Generation in Chinese},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {2},
	pages = {53:1--53:17},
	year = {2025},
	url = {https://doi.org/10.1145/3686807},
	doi = {10.1145/3686807},
	timestamp = {Sun, 02 Nov 2025 21:29:25 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/WangZQLLXDQL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Large Language Models (LLMs) have demonstrated remarkable success in diverse natural language processing (NLP) tasks in general domains. However, LLMs sometimes generate responses with the  hallucination  about medical facts due to limited domain knowledge. Such shortcomings pose potential risks in the utilization of LLMs within medical contexts. To address this challenge, we propose knowledge-tuning, which leverages structured medical knowledge bases for the LLMs to grasp domain knowledge efficiently and facilitate trustworthy response generation. We also release cMedKnowQA, a Chinese medical knowledge question-answering dataset constructed from medical knowledge bases to assess the medical knowledge proficiency of LLMs. Experimental results show that the LLMs which are knowledge-tuned with cMedKnowQA can exhibit higher levels of accuracy in response generation compared with vanilla instruction-tuning and offer a new trustworthy way for the domain adaptation of LLMs. We release our code and data at  https://github.com/SCIR-HI/Huatuo-Llama-Med-Chinese .}
}


@article{DBLP:journals/tkdd/CuiDHZ25,
	author = {Peng Cui and
                  Zhijie Deng and
                  Wenbo Hu and
                  Jun Zhu},
	title = {{SDE-HNN:} Accurate and Well-Calibrated Forecasting Using Stochastic
                  Differential Equations},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {2},
	pages = {54:1--54:23},
	year = {2025},
	url = {https://doi.org/10.1145/3691346},
	doi = {10.1145/3691346},
	timestamp = {Wed, 11 Jun 2025 21:01:28 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/CuiDHZ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {It is crucial yet challenging for deep learning models to properly characterize uncertainty that is pervasive in real-world environments. Heteroscedastic neural networks (HNNs) are promising methods that capture data uncertainty for forecasting problems while existing HNNs have difficulties in conjoining calibrated uncertainty estimation and satisfactory predictive performance due to the failure to construct an explicit interaction between the prediction and its associated uncertainty. This article develops SDE-HNN, an improved HNN equipped with stochastic differential equations (SDE), to characterize the interaction between the predictive mean and variance inside HNNs for accurate and reliable forecasting. The existence and uniqueness of the solution to the devised neural SDE are guaranteed. Moreover, based on the bias-variance tradeoff for the optimization in SDE-HNN, we design an enhanced numerical SDE solver to improve learning stability. Finally, we present two new diagnostic uncertainty metrics to systematically evaluate the predictive uncertainty. Experiments on various challenging datasets show that our method significantly outperforms state-of-the-art baselines on both predictive performance and uncertainty quantification, delivering well-calibrated and sharp prediction intervals in time-series forecasting.}
}


@article{DBLP:journals/tkdd/LiuSMLZY25,
	author = {Xueyan Liu and
                  Wenzhuo Song and
                  Katarzyna Musial and
                  Yang Li and
                  Xuehua Zhao and
                  Bo Yang},
	title = {Stochastic Block Models for Complex Network Analysis: {A} Survey},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {3},
	pages = {55:1--55:35},
	year = {2025},
	url = {https://doi.org/10.1145/3713076},
	doi = {10.1145/3713076},
	timestamp = {Wed, 11 Jun 2025 21:01:28 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/LiuSMLZY25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Complex networks enable to represent and characterize the interactions between entities in various complex systems which widely exist in the real world and usually generate vast amounts of data about all the elements, their behaviors and interactions over time. The studies concentrating on new network analysis approaches and methodologies are vital because of the diversity and ubiquity of complex networks. The stochastic block model (SBM), based on Bayesian theory, is a statistical network model. SBMs are essential tools for analyzing complex networks since SBMs have the advantages of interpretability, expressiveness, flexibility and generalization. Thus, designing diverse SBMs and their learning algorithms for various networks has become an intensively researched topic in network analysis and data mining. In this article, we review, in a comprehensive and in-depth manner, SBMs for different types of networks (i.e., model extensions), existing methods (including parameter estimation and model selection) for learning optimal SBMs for given networks and SBMs combined with deep learning. Finally, we provide an outlook on the future research directions of SBMs.}
}


@article{DBLP:journals/tkdd/GuoZZ25,
	author = {Mengzhuo Guo and
                  Qingpeng Zhang and
                  Daniel Dajun Zeng},
	title = {An Interpretable Deep Learning-based Model for Decision-making through
                  Piecewise Linear Approximation},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {3},
	pages = {56:1--56:35},
	year = {2025},
	url = {https://doi.org/10.1145/3715150},
	doi = {10.1145/3715150},
	timestamp = {Sat, 31 May 2025 23:18:31 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/GuoZZ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Full-complexity machine learning models, such as the deep neural network, are non-traceable black-box, whereas the classic interpretable models, such as linear regression models, are often over-simplified, leading to lower accuracy. Model interpretability limits the application of machine learning models in management problems, which requires high prediction performance, as well as the understanding of individual features’ contributions to the model outcome. To enhance model interpretability while preserving good prediction performance, we propose a hybrid interpretable model that combines a piecewise linear component and a nonlinear component. The first component describes the explicit feature contributions by piecewise linear approximation to increase the expressiveness of the model. The other component uses a multi-layer perceptron to increase the prediction performance by capturing the high-order interactions between features and their complex nonlinear transformations. The interpretability is obtained once the model is learned in the form of shape functions for the main effects. We also provide a variant to explore the higher-order interactions among features. Experiments are conducted on synthetic and real-world datasets to demonstrate that the proposed models can achieve good interpretability by explicitly describing the main effects and the interaction effects of the features while maintaining state-of-the-art accuracy.}
}


@article{DBLP:journals/tkdd/LiFS25,
	author = {Yongkang Li and
                  Zipei Fan and
                  Xuan Song},
	title = {Heterogeneous Hyperbolic Hypergraph Neural Network for Friend Recommendation
                  in Location-based Social Networks},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {3},
	pages = {57:1--57:29},
	year = {2025},
	url = {https://doi.org/10.1145/3708999},
	doi = {10.1145/3708999},
	timestamp = {Sat, 31 May 2025 23:18:31 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/LiFS25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Friend recommendation is an important real-world application in Location-based Social Networks (LBSN), helping users discover potential friends and enhance their overall happiness. LBSN mainly comprises two distinct data structures: spatio-temporal data for human mobility and graph data for social networks. These two data structures make it challenging to model the complex relationships between them, which are essential for comprehensively understanding users’ lives. Previous studies have either modeled user trajectories and social networks separately or used classical simple graph-based methods, where a simple edge links only two nodes, failing to capture the multiple relationships inherent in LBSN. Furthermore, most studies have relied on Euclidean space to train their graph models, which could result in significant distortion because of tree-like social network data structure. To address these limitations, we propose a novel heterogeneous LBSN hypergraph that represents user check-in records and continuous trajectories—comprising multiple Points of Interest (POI)—as hyperedges, enabling the representation of complex spatio-temporal relationships. This approach enables us to link multiple nodes of different types by hyperedges and use hyperbolic spaces to create more efficient graph representations. Additionally, we devise a new type-specific attention mechanism for our Heterogeneous Hyperbolic Hypergraph Neural Network (H 3 GNN), which is end-to-end trainable and employs supervised contrastive learning to learn hypergraph node embeddings for the subsequent friend recommendation task with the help of hyperbolic space. Finally, our model H 3 GNN achieves better results than existing methods on six real-world city datasets, and our ablation studies demonstrate the effectiveness of each component. Additionally, our experiments indicate that H 3 GNN requires less data storage and training time compared to previous methods.}
}


@article{DBLP:journals/tkdd/YaoLWZWYJ25,
	author = {Dezhong Yao and
                  Sanmu Li and
                  Zhiwei Wang and
                  Peilin Zhao and
                  Gang Wu and
                  Chen Yu and
                  Hai Jin},
	title = {Efficient Distributed Sparse Relative Similarity Learning},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {3},
	pages = {58:1--58:27},
	year = {2025},
	url = {https://doi.org/10.1145/3712603},
	doi = {10.1145/3712603},
	timestamp = {Wed, 11 Jun 2025 21:01:28 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/YaoLWZWYJ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Learning a good similarity measure for large-scale high-dimensional data is a crucial task in machine learning applications, yet it poses a significant challenge. Distributed minibatch Stochastic Gradient Descent (SGD) serves as an efficient optimization method in large-scale distributed training, allowing linear speedup in proportion to the number of workers. However, communication efficiency in distributed SGD requires a sufficiently large minibatch size, presenting two distinct challenges. Firstly, a large minibatch size leads to high memory usage and computational complexity during parallel training of high-dimensional models. Second, a larger batch size of data reduces the convergence rate. To overcome these challenges, we propose an Efficient Distributed Sparse Relative Similarity Learning ( EDSRSL ) framework. This framework integrates two strategies: local minibatch SGD and sparse relative similarity learning. By effectively reducing the number of updates through synchronous delay while maintaining a large batch size, we address the issue of high computational cost. Additionally, we incorporate sparse model learning into the training process, significantly reducing computational cost. This article also provides theoretical proof that the convergence rate does not decrease significantly with increasing batch size. Various experiments on six high-dimensional real-world datasets demonstrate the efficacy and efficiency of the proposed algorithms, with a communication cost reduction of up to  90.89 %  and a maximum wall time speedup of  5.66 ×  compared to the baseline methods.}
}


@article{DBLP:journals/tkdd/GaoLYLY25,
	author = {Yibo Gao and
                  Zhen Liu and
                  Xinxin Yang and
                  Sibo Lu and
                  Yafan Yuan},
	title = {Disentangled Multi-Graph Convolution for Cross-Domain Recommendation},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {3},
	pages = {59:1--59:28},
	year = {2025},
	url = {https://doi.org/10.1145/3715151},
	doi = {10.1145/3715151},
	timestamp = {Thu, 22 Jan 2026 15:00:17 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/GaoLYLY25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Data sparsity poses a significant challenge for recommendation systems, prompting the research of Cross-Domain Recommendation ( CDR ). CDR aims to leverage more user-item interaction information from source domains to improve the recommendation performance in the target domain. However, a major challenge in CDR is the identification of transferable features. Traditional CDR methods struggle to distinguish between the various features of users, including domain-invariant features that are effective for feature transfer and domain-specific features that are detrimental to cross-domain information transfer. In this article, we aim to disentangle domain-invariant features and domain-specific features and effectively utilize these different features. This enables effective domain-to-domain information transfer by only transferring domain-invariant features while still considering the role of domain-specific features within their respective domains. Based on the superiority of graph structural feature learning and disentangled represent learning, we propose  DMGCDR —a model that learns  D isentangled user feature representations and constructs a  M ulti- G raph network for bidirectional knowledge transfer of shared features for  CDR . Specifically, we designed two regularization terms to disentangle domain-invariant features and domain-specific features. Subsequently, we established a multi-graph convolutional network to enhance domain-specific features within single-domain graphs and transfer domain-invariant features across cross-domain graphs. Our approach also includes designing feature constraints to enhance the combination of features derived from different graphs and to uncover potential correlations among them. Extensive experiments on real-world datasets have demonstrated that our model significantly outperforms state-of-the-art CDR approaches.}
}


@article{DBLP:journals/tkdd/ShaoL25,
	author = {Yuanhang Shao and
                  Xiuwen Liu},
	title = {Nonlinear Correct and Smooth for Graph-Based Semi-Supervised Learning},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {3},
	pages = {60:1--60:32},
	year = {2025},
	url = {https://doi.org/10.1145/3712604},
	doi = {10.1145/3712604},
	timestamp = {Wed, 11 Jun 2025 21:01:28 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/ShaoL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graph-based semi-supervised learning (GSSL) has achieved significant success across various applications by leveraging the graph structure and labeled samples for classification tasks. In the field of GSSL, Label Propagation (LP) and Graph Neural Networks (GNNs) are two complementary methods, in which LP iteratively propagates and updates node labels through connected nodes, whereas GNNs aggregate node features by incorporating information from their neighbors. Recently, the complementary nature of LP and GNNs has been utilized to improve performance through the combination of two approaches. However, the utilization of higher-order graph structures within these combined approaches, such as triangles, is still under-explored. Therefore, to advance understanding in this ongoing research, we first model GSSL as a two-step feature-label process. Then, we introduce Nonlinear Correct and Smooth (NLCS) in the post-processing step, a combined method that incorporates nonlinearity and higher-order structures into the residual propagation to handle intricate node relationships effectively. We propose a new synthetic graph generator to deepen the analysis and broaden the experimentation, providing insights into the mechanisms that enable NLCS to handle intricate node relationships effectively. Our systematic evaluations across six synthetic graphs show that NLCS outperforms base predictions by an average of 12.44% and the existing state-of-the-art post-processing method by 8.04%. Furthermore, on six commonly used real-world datasets, NLCS demonstrates a 10.9% improvement over six base prediction models and a 1.6% over the state-of-the-art post-processing method. Our comparisons and analyses reveal that NLCS substantially enhances the prediction accuracy of nodes within complex graph structures by effectively utilizing higher-order structures of graphs.}
}


@article{DBLP:journals/tkdd/ZhangJZW25,
	author = {Huan Zhang and
                  Liangxiao Jiang and
                  Wenjun Zhang and
                  Geoffrey I. Webb},
	title = {Dual-View Learning from Crowds},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {3},
	pages = {61:1--61:21},
	year = {2025},
	url = {https://doi.org/10.1145/3712605},
	doi = {10.1145/3712605},
	timestamp = {Wed, 11 Jun 2025 21:01:28 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/ZhangJZW25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Crowdsourcing services provide a fast and cheap way to obtain substantial labeled data by employing crowd workers on the Internet. In crowdsourcing learning, two-stage methods have been widely used, which first infer the integrated label for each instance and then build a learning model using instances with their integrated labels. However, existing two-stage methods mainly focus on how to infer more accurate integrated labels, after that, most of them directly regard the integrated labels as class labels to build a learning model, which loses the detailed worker labeling information in multiple noisy labels and thus results in sub-optimal model accuracy. To solve this problem, in this study, we take the multiple noisy labels of each instance as its attribute value vector to construct another view in addition to the original attribute view, and propose a novel two-stage method called dual-view learning from crowds (DVLFC). In DVLFC, we first pick out workers with sufficient number of labels and augment the multiple noisy label set for each instance, then we build a supervised learning model in each view and at last we fuse their class-membership probabilities to get the final classification result. Extensive experiments on both real-world and artificial crowdsourced datasets prove the effectiveness of DVLFC.}
}


@article{DBLP:journals/tkdd/LinNF25,
	author = {Peng Lin and
                  Martin Neil and
                  Norman E. Fenton},
	title = {Stacking Factorizing Partitioned Expressions in Hybrid Bayesian Network
                  Models},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {3},
	pages = {62:1--62:28},
	year = {2025},
	url = {https://doi.org/10.1145/3714473},
	doi = {10.1145/3714473},
	timestamp = {Wed, 11 Jun 2025 21:01:28 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/LinNF25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Hybrid Bayesian networks (HBN) contain complex conditional probability distributions (CPD) specified as partitioned expressions over discrete and continuous variables. The size of these CPDs grows exponentially with the number of parent nodes, and when using discrete inference methods, it results in significant execution time and space inefficiency. To reduce the CPD size, a binary factorization (BF) algorithm can be used to decompose the statistical or arithmetic functions in the CPD by factorizing the number of connected parent nodes into sets of size two. However, the BF algorithm was not designed to handle partitioned expressions. Therefore, we propose a new stacking factorization (SF) algorithm to decompose partitioned expressions. The SF algorithm creates intermediate nodes to incrementally reconstruct the conditional densities in the original partitioned expression, ensuring that no more than two continuous parent nodes are connected to each child node in the resulting HBN. It generally applies to both discrete and continuous child nodes with complex partitioned expressions. When we combine SF with a dynamic discretization (DD) inference algorithm, we achieve a significant improvement in inference efficiency. Experimental results demonstrate that the combination of SF and DD can effectively manage HBNs with complex CPDs that may challenge other algorithms, which also outperform competing inference algorithms in accuracy.}
}


@article{DBLP:journals/tkdd/WangNWWL25,
	author = {Sisi Wang and
                  Feiping Nie and
                  Zheng Wang and
                  Rong Wang and
                  Xuelong Li},
	title = {Fuzzy Weighted Principal Component Analysis for Anomaly Detection},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {3},
	pages = {63:1--63:22},
	year = {2025},
	url = {https://doi.org/10.1145/3715148},
	doi = {10.1145/3715148},
	timestamp = {Wed, 11 Jun 2025 21:01:28 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/WangNWWL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Principal Component Analysis (PCA) is one of the most famous unsupervised dimensionality reduction algorithms and has been widely used in many fields. However, it is very sensitive to outliers, which reduces the robustness of the algorithm. In recent years, many studies have tried to employ  ℓ 1 -norm to improve the robustness of PCA, but they all lack rotation invariance or the solution is expensive. In this article, we propose a novel robust PCA, namely, Fuzzy Weighted Principal Component Analysis (FWPCA), which still uses squared  ℓ 2 -norm to minimize reconstruction error and maintains rotation invariance of PCA. The biggest bright spot is that the contribution of data is restricted by fuzzy weights, so that the contribution of normal samples is much greater than noise or abnormal data, and realizes anomaly detection. Besides, a more reasonable data center can be obtained by solving the optimal mean to make projection matrix more accurate. Subsequently, an effective iterative optimization algorithm is developed to solve this problem, and its convergence is strictly proved. Extensive experimental results on face datasets and RGB anomaly detection datasets show the superiority of our proposed method.}
}


@article{DBLP:journals/tkdd/AbdallahRMKZB25,
	author = {Mustafa Abdallah and
                  Ryan A. Rossi and
                  Kanak Mahadik and
                  Sungchul Kim and
                  Handong Zhao and
                  Saurabh Bagchi},
	title = {Evaluation-free Time-series Forecasting Model Selection via Meta-learning},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {3},
	pages = {64:1--64:41},
	year = {2025},
	url = {https://doi.org/10.1145/3715149},
	doi = {10.1145/3715149},
	timestamp = {Wed, 11 Jun 2025 21:01:28 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/AbdallahRMKZB25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Time-series forecasting models are invariably used in a variety of domains for crucial decision-making. Traditionally these models are constructed by experts with considerable manual effort. Unfortunately, this approach has poor scalability while generating accurate forecasts for new datasets belonging to diverse applications. Without access to skilled domain-knowledge, one approach is to train all the models on the new time-series data and then select the best one. However, this approach is nonviable in practice. In this work, we develop techniques for fast automatic selection of the best forecasting model for a new unseen time-series dataset, without having to first train (or evaluate) all the models on the new time-series data to select the best one. In particular, we develop a forecasting meta-learning approach called  AutoForecast  that allows for the quick inference of the best time-series forecasting model for an unseen dataset. Our approach learns both forecasting models’ performances over time horizon of the same dataset and task similarity across different datasets. The experiments demonstrate the effectiveness of the approach over state-of-the-art (SOTA) single and ensemble methods and several SOTA meta-learners (adapted to our problem) in terms of selecting better forecasting models (i.e., 2 \\(\\times\\)  gain) for unseen tasks for univariate and multivariate testbeds.  AutoForecast  has also significant reduction in inference time compared to the naïve approach (doing inference using all possible models and then selecting the best one), with median of 42 \\(\\times\\)  across the two testbeds. We release our meta-learning database corpus (348 datasets), performances of the 322 forecasting models on the database corpus, meta-features, and source codes for the community to access them for forecasting model selection and to build on them with new datasets and models which can help advance automating time-series forecasting problem. In our released database corpus, we unveil new traces of Adobe computing cluster usage for production workloads.}
}


@article{DBLP:journals/tkdd/ZhouWZLZW25,
	author = {Peng Zhou and
                  Qi Wang and
                  Yunyun Zhang and
                  Zhaolong Ling and
                  Shu Zhao and
                  Xindong Wu},
	title = {Online Stable Streaming Feature Selection via Feature Aggregation},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {3},
	pages = {65:1--65:23},
	year = {2025},
	url = {https://doi.org/10.1145/3715918},
	doi = {10.1145/3715918},
	timestamp = {Thu, 22 Jan 2026 08:57:44 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/ZhouWZLZW25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Feature selection is an essential pre-process component in data mining that aims to select the most relevant features from the target dataset. Datasets are always dynamic in real-world applications, and features may exist in stream mode. Then, online streaming feature selection methods are proposed, which deal with streaming features arriving continuously in real-time. However, most existing algorithms prioritize high accuracy and low time-consumption but overlook the stability of the selected features. Stable feature selection results are crucial for users in practice. For instance, in the medical field, unstable feature selection results can make it challenging for experts to identify the main causative factors of a disease. Motivated by this, this article proposes a new online stable streaming feature selection method via feature aggregation named OSSFS. Specifically, inspired by the cohesive MeanShift approach, OSSFS applies an incremental aggregation strategy to partition the streaming features into multiple hyperellipsoids. Then, we incrementally update and merge these hyperellipsoids with new streaming features. Finally, we select representative features from each hyperellipsoid as the final selected feature subset. Extensive experiments are conducted on several real-world datasets to compare our new method with state-of-the-art competing algorithms in cases of stability and predictive accuracy. Experimental results indicate that OSSFS achieves optimal stability without losing prediction accuracy.}
}


@article{DBLP:journals/tkdd/PaulMMRS25,
	author = {Jayanta Paul and
                  Siddhartha Mallick and
                  Abhijit Mitra and
                  Anuska Roy and
                  Jaya Sil},
	title = {Multi-modal Twitter Data Analysis for Identifying Offensive Posts
                  Using a Deep Cross-Attention-based Transformer Framework},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {3},
	pages = {66:1--66:30},
	year = {2025},
	url = {https://doi.org/10.1145/3713077},
	doi = {10.1145/3713077},
	timestamp = {Wed, 11 Jun 2025 21:01:28 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/PaulMMRS25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In today’s society dissemination of information among the individuals occur very rapidly due to the widespread usage of social media platforms like Twitter (now-a-days acclaimed as X). However, information may pose challenges to maintaining a healthy online environment because often it contains harmful content. This article presents a novel approach to identify different categories of offensive posts such as hate speech, profanity, targeted insult, and derogatory commentary by analyzing multi-modal image and text data, collected from Twitter. We propose a comprehensive deep learning framework, “Value Mixed Cross-Attention Transformer” (VMCA-Trans) that leverage a combination of computer vision and natural language processing methodologies to effectively classify the posts into four classes with binary labels. We have created an in-house dataset (OffenTweet) comprising of Twitter posts having textual content, accompanying with images to build the proposed model. The dataset is carefully annotated by several experts with offensive labels such as hate speech, profanity, targeted insult, and derogatory commentary. VMCA-Trans utilizes fine-tuned state-of-the-art transformer-based backbones such as ViT, BERT, RoBERTA. The combined representation of image and text embeddings obtained by these fine-tuned transformer encoders is fed into a classifier to categorize the posts into offensive and non-offensive classes. To assess its effectiveness, we extensively evaluate the VMCA-Trans model using various performance metrics. The results indicate that the proposed multi-modal approach achieves superior performance compared to traditional unimodal methods.}
}


@article{DBLP:journals/tkdd/XuZAAH25,
	author = {Paiheng Xu and
                  Yuhang Zhou and
                  Bang An and
                  Wei Ai and
                  Furong Huang},
	title = {GFairHint: Improving Individual Fairness for Graph Neural Networks
                  via Fairness Hint},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {3},
	pages = {67:1--67:22},
	year = {2025},
	url = {https://doi.org/10.1145/3714472},
	doi = {10.1145/3714472},
	timestamp = {Wed, 11 Jun 2025 21:01:28 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/XuZAAH25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Given the growing concerns about fairness in machine learning and the impressive performance of Graph Neural Networks (GNNs) on graph data learning, algorithmic fairness in GNNs has attracted significant attention. While many existing studies improve fairness at the group level, only a few works promote individual fairness, which renders similar outcomes for similar individuals. A desirable framework that promotes individual fairness should (1) balance fairness and performance, (2) accommodate two commonly-used individual similarity measures (externally annotated and computed from input features), and, (3) generalize across various GNNs. Unfortunately, none of the prior work achieves all the desirables. In this work, we propose a novel method,  GFairHint , which promotes individual fairness in GNNs and achieves all aforementioned desirables. GFairHint learns fairness representations through an auxiliary link prediction task, which is inspired by a theoretical analysis of the definition of individual fairness. We then concatenate the representations with the learned node embeddings in original GNNs as a  “fairness hint” . Through extensive experimental investigations on five real-world graph datasets under three prevalent GNNs covering both individual similarity measures above, GFairHint achieves the best fairness results in almost all combinations of datasets with various backbone models, while generating comparable utility results, with much less computational cost compared to the previous state-of-the-art method.}
}


@article{DBLP:journals/tkdd/SusnjakHRBMR25,
	author = {Teo Susnjak and
                  Peter Hwang and
                  Napoleon H. Reyes and
                  Andre L. C. Barczak and
                  Timothy R. McIntosh and
                  Surangika Ranathunga},
	title = {Automating Research Synthesis with Domain-Specific Large Language
                  Model Fine-Tuning},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {3},
	pages = {68:1--68:39},
	year = {2025},
	url = {https://doi.org/10.1145/3715964},
	doi = {10.1145/3715964},
	timestamp = {Sun, 02 Nov 2025 21:29:25 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/SusnjakHRBMR25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This research pioneers the use of fine-tuned Large Language Models (LLMs) to automate Systematic Literature Reviews (SLRs), presenting a significant and novel contribution in integrating AI to enhance academic research methodologies. Our study employed advanced fine-tuning methodologies on open sourced LLMs, applying textual data mining techniques to automate the knowledge discovery and synthesis phases of an SLR process, thus demonstrating a practical and efficient approach for extracting and analyzing high-quality information from large academic datasets. The results maintained high fidelity in factual accuracy in LLM responses, and were validated through the replication of an existing PRISMA-conforming SLR. Our research proposed solutions for mitigating LLM hallucination and proposed mechanisms for tracking LLM responses to their sources of information, thus demonstrating how this approach can meet the rigorous demands of scholarly research. The findings ultimately confirmed the potential of fine-tuned LLMs in streamlining various labor-intensive processes of conducting literature reviews. As a scalable proof-of-concept, this study highlights the broad applicability of our approach across multiple research domains. The potential demonstrated here advocates for updates to PRISMA reporting guidelines, incorporating AI-driven processes to ensure methodological transparency and reliability in future SLRs. This study broadens the appeal of AI-enhanced tools across various academic and research fields, demonstrating how to conduct comprehensive and accurate literature reviews with more efficiency in the face of ever-increasing volumes of academic studies while maintaining high standards.}
}


@article{DBLP:journals/tkdd/WangLA25,
	author = {Chenyang Wang and
                  Ling Luo and
                  Uwe Aickelin},
	title = {Time Series Classification with Elasticity Using Augmented Path Signatures},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {3},
	pages = {69:1--69:32},
	year = {2025},
	url = {https://doi.org/10.1145/3715702},
	doi = {10.1145/3715702},
	timestamp = {Wed, 11 Jun 2025 21:01:28 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/WangLA25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We often compare time-dependent data elastically such that some compression or dilation along the time dimension can be ignored, for example, spatial trajectories of vehicles moving at different speeds or accelerometer data for exercises completed at variable rhythms. Traditionally this is possible via an alignment-based elastic distance measure, such as dynamic time warping (DTW). We may also control the degree of allowable warping with warping constraints. However, these elastic distance measures are not easy to use in large-scale time series classification, as they need to be evaluated pairwise and often cannot be directly converted into feature sets that we may use with arbitrary classifiers or combine with other features. In this research, we focus on the study of path signatures, a transformation with time warping invariance property, and how we may augment a time series to make its signature space representation reflect common warping constraints. We demonstrate that the comparing signatures is analogous to comparing time series with elastic distances, and that augmented signature features can serve as warping invariant or insensitive features in time series classification. Finally, we construct multiple path signatures with constraining augmentations classifier (MultiPSCA), a general-purpose minimal tuning time series classifier using augmented signatures and show that it is able to beat existing best-performing elastic time series classification algorithms without per-dataset hyperparameter tuning.}
}


@article{DBLP:journals/tkdd/GuJRBC25,
	author = {Xiao Gu and
                  Ling Jian and
                  Chongzhi Rao and
                  Zhaohui Bu and
                  Xianggang Cheng},
	title = {Together Is Better: Knowledge-aware Model with Resume Fusion for Online
                  Job Recommendation},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {3},
	pages = {70:1--70:15},
	year = {2025},
	url = {https://doi.org/10.1145/3716503},
	doi = {10.1145/3716503},
	timestamp = {Wed, 11 Jun 2025 21:01:28 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/GuJRBC25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Widespread adoption of online recruitment platforms has led to explosive growth in employment information, resulting in an ever-increasing demand from job seekers for accurate and effective job recommendations. Existing studies on the Person-Job Fit models focus on the correlation between resumes and job descriptions, with rare consideration given to user historical behavior such as click and application. On the contrary, job recommendation methods always ignore the crucial information lurking in the resume text. In addition, the continuous influx of a vast amount of job data poses challenges to the updating of online recommendation results. To this end, we propose a novel  O nline  J ob  R ecommendation model  via R esume  F usion (OJRRF) in this article, aimed at making accurate and efficient online job recommendations with the merits of addressing job cold start and long tail problems. The key contribution lies in two facets: (1) incorporating resume text information into the knowledge graph attention framework to enhance job seekers’ vector representations jointly; (2) designing a hybrid recommender strategy by combining the knowledge-aware offline model with the content-based online model. Finally, we conducted extensive comparison experiments and online A/B test on the recruitment platform of JiuYeJie big data company to validate the effectiveness and real-time capability of OJRRF. The release code can be found in  https://github.com/urnotada/OJRRF .}
}


@article{DBLP:journals/tkdd/GallegoFontenlaGVL25,
	author = {V{\'{\i}}ctor Gallego{-}Fontenla and
                  Pedro Gamallo{-}Fernandez and
                  Juan Carlos Vidal and
                  Manuel Lama},
	title = {Gradual Drift Detection in Process Models Using Conformance Metrics},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {3},
	pages = {71:1--71:40},
	year = {2025},
	url = {https://doi.org/10.1145/3716169},
	doi = {10.1145/3716169},
	timestamp = {Sat, 31 May 2025 23:18:31 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/GallegoFontenlaGVL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Changes, planned or unexpected, are common during the execution of real-life processes. Detecting these changes is a must for optimizing the performance of organizations running such processes. Most of the algorithms present in the  state-of-the-art  focus on the detection of sudden changes, leaving aside other types of changes. In this article, we will focus on the automatic detection of gradual drifts, a special type of change, in which the cases of two models overlap during a period of time. The proposed algorithm relies on conformance checking metrics to carry out the automatic detection of the changes, performing also a fully automatic classification of these changes into sudden or gradual. The approach has been validated with a synthetic dataset consisting of 120 logs with different distributions of changes, getting better results in terms of detection and classification accuracy, delay, and change region overlapping than the main  state-of-the-art  algorithms.}
}


@article{DBLP:journals/tkdd/LinYXLXL25,
	author = {Mingwei Lin and
                  Hengshuo Yang and
                  Xiuqin Xu and
                  Ling Lin and
                  Zeshui Xu and
                  Xin Luo},
	title = {Momentum-Accelerated and Biased Unconstrained Non-Negative Latent
                  Factor Model for Handling High-Dimensional and Incomplete Data},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {3},
	pages = {72:1--72:25},
	year = {2025},
	url = {https://doi.org/10.1145/3717069},
	doi = {10.1145/3717069},
	timestamp = {Wed, 11 Jun 2025 21:01:28 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/LinYXLXL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {High-dimensional and incomplete (HDI) data are involved frequently in big data-related industrial applications. Latent factor (LF) analysis aims at extracting the knowledge of great value from such extremely sparse HDI data efficiently. Non-negative LF models based on the single LF-dependent, non-negative, and multiplicative update rules exactly are the representative of LF analysis. However, these models face low generalization dilemma due to incompatible with general unconstrained optimization techniques. To address this issue, this article proposes a novel momentum-accelerated and biased unconstrained non-negative latent factor (MBUNLF) model, which matches with unconstrained optimization techniques. The proposed MBUNLF model is built on three main ideas: (a) Improving the generalization through a non-negative mapping function; (b) Capturing information among different entities through linear biases; (c) Accelerating convergence during the training process through generalized momentum method. Empirical studies on six datasets from industrial applications indicate that the proposed MBUNLF model outperforms nine state-of-the-art models when processing HDI data, reducing the root mean square error by 19.47% on average. It demonstrates the validity of the MBUNLF model in extracting non-negative LFs from HDI data.}
}


@article{DBLP:journals/tkdd/JingCYL25,
	author = {Xuechun Jing and
                  Fuyuan Cao and
                  Kui Yu and
                  Jiye Liang},
	title = {CM-CaFE: {A} Clustering Method with Causality-based Feature Embedding},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {3},
	pages = {73:1--73:23},
	year = {2025},
	url = {https://doi.org/10.1145/3717068},
	doi = {10.1145/3717068},
	timestamp = {Wed, 11 Jun 2025 21:01:28 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/JingCYL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Clustering is a fundamental technique widely used for exploring the inherent data structure. Many studies indicate that an appropriate feature representation can effectively improve clustering performance. However, the existing feature representation methods are based on correlation to select or extract features, which makes it hard to deal with spurious correlations. The spurious correlations mislead the correlation-based methods to consider features that have no causal relationship as being correlative, which limits the clustering performance and feature interpretability. To tackle this issue, inspired by causal learning, we propose a new joint optimization  Clustering Method with Causal Feature Embedding (CM-CaFE) , which utilizes the causality of features to learn more discriminative representation for clustering. Specifically, to eliminate spurious correlations among features, we first employ any state-of-the-art Markov blanket learning method to learn an undirected causal graph. Next, we extract the maximal fully connected causal subgraphs from the learned undirected causal graph and propose an approach to merge them to generate the causal matrix. Based on the causal matrix, we present an objective function that consists of a clustering loss term and a causal matrix fitting term to learn a causal transformation matrix. The causal transformation matrix is utilized to map the original data into a new space for clustering. Finally, we comprehensively compare the proposed method with some state-of-the-art clustering approaches on several datasets to demonstrate the effectiveness and interpretability of the proposed method.}
}


@article{DBLP:journals/tkdd/ZhuWS25,
	author = {Yu Zhu and
                  Ou Wu and
                  Fengguang Su},
	title = {Subclass-wise Logit Perturbation for Multi-label Learning},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {3},
	pages = {74:1--74:40},
	year = {2025},
	url = {https://doi.org/10.1145/3715919},
	doi = {10.1145/3715919},
	timestamp = {Wed, 29 Oct 2025 17:44:12 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/ZhuWS25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Logit perturbation refers to adding perturbation on logit, which has been shown to be capable of enhancing the robustness and generalization capabilities of deep neural networks in machine learning. However, studies on logit perturbation for multi-label learning are limited and they only consider the issue of class imbalance in the training data. Furthermore, the logit perturbation vectors in these methods are identical for negative classes containing different subclasses when multi-label learning is viewed as a multiple binary classification problem. This study investigates logit perturbation by exploring the characteristics of subclass-wise multi-label training data. First, the influence of the characteristics of multi-label training data on classification performance is analyzed in terms of the three data characteristics, namely, proportion, variance, and co-occurrence for each category (or subclass). Quantitative analyses reveal that variance differences among the subclasses in the negative class of a decomposed binary task also negatively impact the training performance, and if multiple characteristics affect simultaneously, the performance deterioration will be more severe. Second, theoretical analysis is performed for subclass-wise logit perturbation and a new subclass-wise logit perturbation method is proposed for multi-label learning. In our method, each class/subclass has a carefully designed perturbation implementation according to its proportion, variance, and co-occurrence. Finally, our proposed method is further explained through a regularization view. Extensive experiments demonstrate that our method consistently enhances the generalization performance of popular depth networks on multi-label benchmark datasets.}
}


@article{DBLP:journals/tkdd/LiuZZQZ25,
	author = {Jian Ying Liu and
                  Chaowei Zhang and
                  Min Zhang and
                  Xiao Qin and
                  Jifu Zhang},
	title = {Similarity Metrics: Chebyshev Coulomb Force and Resultant Force for
                  High-Dimensional Data},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {3},
	pages = {75:1--75:25},
	year = {2025},
	url = {https://doi.org/10.1145/3715963},
	doi = {10.1145/3715963},
	timestamp = {Wed, 27 Aug 2025 11:29:37 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/LiuZZQZ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The similarity metric has garnered widespread attention thanks to its potential applications in the fields of data mining, machine learning, and so on. Due to the interference of “distance concentration” caused by “Curse of dimensionality,” however, existing similarity metrics are inadequate in high-dimensional data analysis. In this study, we propose two innovative similarity metrics—Chebyshev Coulomb force and Chebyshev Coulomb resultant force—anchored on Chebyshev p-norms. In the initial phase, we eliminate dependency relationships among attributes by applying a metric matrix—and the theoretical analysis reveals that the Chebyshev p-norms is capable of mitigating the effect of “distance concentration” among high-dimensional data objects. Next, we devise two similarity metrics—Chebyshev Coulomb force and Chebyshev Coulomb resultant force—by adopting the metric matrix and Chebyshev p-norms. Chebyshev Coulomb force and Chebyshev Coulomb resultant force, being effective in characterizing the similarity among data objects, quantify the deviation of data objects from their respective dataset centers. Additionally, the two metrics alleviate the interference of “distance concentration.” Importantly, the discrepancy of data objects in attribute dimensions is captured by Chebyshev Coulomb force vector, rendering the similarity metric interpretable. By utilizing the UCI dataset, the experimental validation demonstrates the superiority of our similarity metrics, confirming their efficacy in mitigating the interference of “distance concentration.” Compared with the existing similarity metric approaches, the AUC index of outlier detection shows an average improvement of 8.18%—and the ARI, NMI, and F_score indices of clustering are revamped by averages 6.56%, 6.87%, and 6.01%, respectively.}
}


@article{DBLP:journals/tkdd/KouLG25,
	author = {Yannian Kou and
                  Qiuqiang Lin and
                  Chuanhou Gao},
	title = {{ORIC:} Feature Interaction Detection through Online Random Interaction
                  Chains for Click-Through Rate Prediction},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {3},
	pages = {76:1--76:31},
	year = {2025},
	url = {https://doi.org/10.1145/3717070},
	doi = {10.1145/3717070},
	timestamp = {Wed, 11 Jun 2025 21:01:28 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/KouLG25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Click-through rate prediction aims to predict the ratio of clicks to impressions of a specific link, which is challenging due to (1) extremely high-dimensional categorical features; (2) both important original features and their interactions; and (3) reliance on different features and interactions in different time periods. To overcome these difficulties, we propose a new feature interaction detection method based on the idea of frequent itemset mining, named Online Random Intersection Chains (ORIC), which detects informative feature interactions with high interpretability. ORIC can be updated by controlling the importance of the historical and latest data with a tuning parameter, which saves computational burden and makes full use of historical information. Further, Streaming Integrated Model (SIM) is developed to feed the time-varying feature interactions into CTR prediction models. Empirical results on three benchmark datasets show that SIM achieves better performance than many CTR prediction models, as well as the efficiency, consistency, and interpretability of ORIC.}
}


@article{DBLP:journals/tkdd/HanZMSCGL25,
	author = {Xiaolin Han and
                  Yikun Zhang and
                  Chenhao Ma and
                  Xuequn Shang and
                  Reynold Cheng and
                  Tobias Grubenmann and
                  Xiaodong Li},
	title = {Hypergraph-Enhanced Multi-Granularity Stochastic Weight Completion
                  in Sparse Road Networks},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {3},
	pages = {77:1--77:23},
	year = {2025},
	url = {https://doi.org/10.1145/3719013},
	doi = {10.1145/3719013},
	timestamp = {Wed, 11 Jun 2025 21:01:28 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/HanZMSCGL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Road network applications, such as navigation, incident detection, and Point-of-Interest (POI) recommendation, make extensive use of network edge weights (e.g., traveling times). Some of these weights can be missing, especially in a road network where traffic data may not be available for every road. In this article, we study the  stochastic weight completion  (SWC) problem, which computes the weight distributions of missing road edges. This is difficult, due to the intricate temporal and spatial correlations among neighboring edges. Besides, the road network can be  sparse , i.e., there is a lack of traveling information in a large portion of the network. To tackle these challenges, we propose a multi-granularity framework for  Region-Wise Graph Completion (RegGC) . To learn coarse spatial correlations among distantly located roads, we construct a region-wise hypergraph neural architecture based on semantic region dependencies. For finer spatial correlations, we incorporate contextual road network properties (e.g., speed limits, lane counts, and road types). Moreover, it incorporates recent and periodic dimensions of road traffic. We evaluate RegGC against 10 existing methods on 3 real road network datasets. They show that RegGC is more effective and efficient than state-of-the-art solutions.}
}


@article{DBLP:journals/tkdd/LuoZ25,
	author = {Xinjian Luo and
                  Xianglong Zhang},
	title = {Exploiting Defenses against GAN-Based Feature Inference Attacks in
                  Federated Learning},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {3},
	pages = {78:1--78:20},
	year = {2025},
	url = {https://doi.org/10.1145/3719350},
	doi = {10.1145/3719350},
	timestamp = {Wed, 11 Jun 2025 21:01:28 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/LuoZ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated Learning (FL) is a decentralized model training framework that aims to merge isolated data islands while maintaining data privacy. However, recent studies have revealed that Generative Adversarial Network (GAN)-based attacks can be employed in FL to learn the distribution of private datasets and reconstruct recognizable images. In this article, we exploit defenses against GAN-based attacks in FL and propose a framework, Anti-GAN, to prevent attackers from learning the real distribution of the victim’s data. The core idea of Anti-GAN is to manipulate the visual features of private training images to make them indistinguishable to human eyes even restored by attackers. Specifically, Anti-GAN projects the private dataset onto a GAN’s generator and combines the generated fake images with the actual images to create the training dataset, which is then used for federated model training. The experimental results demonstrate that Anti-GAN is effective in preventing attackers from learning the distribution of private images while causing minimal harm to the accuracy of the federated model.}
}


@article{DBLP:journals/tkdd/FangHZLMWZ25,
	author = {Xiangfei Fang and
                  Chengying Huan and
                  Heng Zhang and
                  Yongchao Liu and
                  Shaonan Ma and
                  Yanjun Wu and
                  Chen Zhao},
	title = {\emph{OTM}: Efficient \emph{k}-Order-Based Core Maintenance in Large-Scale
                  Dynamic Hypergraphs},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {3},
	pages = {79:1--79:33},
	year = {2025},
	url = {https://doi.org/10.1145/3719205},
	doi = {10.1145/3719205},
	timestamp = {Tue, 14 Oct 2025 11:39:33 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/FangHZLMWZ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The  k -core model has garnered widespread adoption for preserving essential cohesive subgraphs owing to its linear-time computability, making it particularly suitable for hypergraph analysis. However, considering the continuously evolving characteristics of real-world hypergraphs, recent research efforts have focused on developing efficient algorithms that can maintain the core value of each vertex amid structural alterations. Despite these efforts, frequent insertions and deletions in dynamic hypergraphs continue to pose significant inefficiencies, primarily due to the increased traversal overhead incurred by hyperedge insertion algorithms. This exacerbates performance disparities between handling hyperedge insertions and deletions, underscoring the persistent challenge of effective  k -core analysis in hypergraphs. To effectively address these challenges, we have gained key insights that enable us to define a specific order, termed the hypergraph  k -order, which significantly reduces redundant vertex traversal and narrows down the search space during hyperedge insertions. Based on the proposed hypergraph  k -order, we define two indices, the order index and the pivotal index, aimed at minimizing traversal costs and expediting the hyperedge insertion algorithm. Moreover, it is essential to recognize that the recomputation of the support degree ( sd ) for all vertices following each hyperedge deletion can significantly diminish the performance efficiency of deletion algorithms. To address this, we introduce an optimized approach that leverages the incremental maintenance of the support degree ( sd ) value to expedite the hyperedge deletion process. By leveraging these optimizations, we introduce a novel Order-based Traversal core Maintenance methodology, designated as  OTM , which markedly enhances the efficiency of core maintenance in dynamic hypergraphs. Our comprehensive evaluation, which covers 12 real-world hypergraph datasets and a synthetic dataset, reveals that  OTM  achieves staggering speedup, outperforming the state-of-the-art approach with a  41,420 ×  speedup in the insertion algorithm and  8,284 ×  speedup in the deletion algorithm, underscoring its remarkable efficiency and effectiveness.}
}


@article{DBLP:journals/tkdd/LiWM25,
	author = {Yang Li and
                  Di Wang and
                  Jos{\'{e}} M. F. Moura},
	title = {Forecasting Graph-Based Time-Dependent Data with Graph Sequence Attention},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {4},
	pages = {1--26},
	year = {2025},
	url = {https://doi.org/10.1145/3721435},
	doi = {10.1145/3721435},
	timestamp = {Sat, 06 Sep 2025 20:29:30 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/LiWM25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Forecasting graph-based, time-dependent data has broad practical applications but presents challenges. Effective models must capture both spatial and temporal dependencies in the data, while also incorporating auxiliary information to enhance prediction accuracy. In this article, we identify limitations in current state-of-the-art models regarding temporal dependency handling. To overcome this, we introduce GSA-Forecaster, a new deep learning model designed for forecasting in graph-based, time-dependent contexts. GSA-Forecaster utilizes graph sequence attention, a new attention mechanism proposed in this article, to effectively manage temporal dependencies. GSA-Forecaster integrates the data’s graph structure directly into its architecture, addressing spatial dependencies. Additionally, it incorporates auxiliary information to refine its predictions further. We validate its performance using real-world graph-based, time-dependent datasets, where it demonstrates superior effectiveness compared to existing state-of-the-art models.}
}


@article{DBLP:journals/tkdd/ChenHLSYS25,
	author = {Fa{-}You Chen and
                  Yun{-}Jui Hsu and
                  Chia{-}Hsun Lu and
                  Hong{-}Han Shuai and
                  Lo{-}Yao Yeh and
                  Chih{-}Ya Shen},
	title = {Compressing Deep Neural Networks with Goal-Specific Pruning and Self-Distillation},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {4},
	pages = {1--27},
	year = {2025},
	url = {https://doi.org/10.1145/3721293},
	doi = {10.1145/3721293},
	timestamp = {Sat, 06 Sep 2025 20:29:30 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/ChenHLSYS25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Neural network (NN) compression aims at reducing the model size and receives much research attention. Nevertheless, we observe that when compressing convolutional neural networks (CNNs), previous approaches may not well measure the impact of filters to loss, resulting in a significant performance degradation after compression. On the other hand, for compressing the fully connected neural networks (FCNNs), we observe that converting the weight matrix to the  block diagonal structure  would result in better compression. Therefore, for compressing CNNs, we propose a new pipeline in this article, named  Retraining-Aware Pruning (RAP) , with a new self-distillation approach, named  High-Level Activation-Guided Attention-Preserving Self-Distillation (HAP)  and a novel filter pruning strategy, named  Normalized Gradients and Geometric Median (NGGM)  to effectively improve the accuracy and reduce the model size. Further, for reducing the model size of FCNNs, we formulate a new research problem, i.e.,  Compression with Difference-Minimized Block Diagonal Structure (COMIS) , and propose a new algorithm,  Memory-Efficient and Structure-Aware Compression (MESA)  to effectively prune the weights into a block diagonal structure to significantly boost the compression rate. Extensive experiments on different models show that our approaches significantly outperform the state-of-the-art baselines in terms of compression rate, accuracy, and inference speed-up.}
}


@article{DBLP:journals/tkdd/WangLCCZ25,
	author = {Tianchun Wang and
                  Dongsheng Luo and
                  Wei Cheng and
                  Haifeng Chen and
                  Xiang Zhang},
	title = {DyExplainer: Self-explainable Dynamic Graph Neural Network with Sparse
                  Attentions},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {4},
	pages = {1--21},
	year = {2025},
	url = {https://doi.org/10.1145/3729173},
	doi = {10.1145/3729173},
	timestamp = {Thu, 11 Sep 2025 20:24:53 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/WangLCCZ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graph Neural Networks (GNNs) resurge as a trending research subject owing to their impressive ability to capture representations from graph-structured data. However, the black-box nature of GNNs presents a significant challenge in terms of comprehending and trusting these models, thereby limiting their practical applications in mission-critical scenarios. Although there has been substantial progress in the field of explaining GNNs in recent years, the majority of these studies are centered on static graphs, leaving the explanation of dynamic GNNs less explored. Dynamic GNNs, with their ever-evolving graph structures, pose a unique challenge and require additional efforts to effectively capture temporal dependencies and structural relationships. To address this challenge, we present DyExplainer, a novel approach to explaining dynamic GNNs on the fly. DyExplainer trains a dynamic GNN backbone to extract representations of the graph at each snapshot, while simultaneously exploring structural relationships and temporal dependencies through a sparse attention technique. To preserve the desired properties of the explanation, such as structural consistency and temporal continuity, we augment our approach with contrastive learning techniques to provide  a priori -guided regularization. To model longer-term temporal dependencies, we develop a buffer-based live-updating scheme for training. The results of our extensive experiments on various datasets demonstrate the superiority of DyExplainer, not only providing faithful explainability of the model predictions but also significantly improving the model prediction accuracy, as evidenced in the link prediction task.}
}


@article{DBLP:journals/tkdd/ChenWXS25,
	author = {Congcong Chen and
                  Lifei Wei and
                  Jintao Xie and
                  Yang Shi},
	title = {Privacy-Preserving Machine Learning Based on Cryptography: {A} Survey},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {4},
	pages = {1--33},
	year = {2025},
	url = {https://doi.org/10.1145/3729234},
	doi = {10.1145/3729234},
	timestamp = {Thu, 11 Sep 2025 20:24:53 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/ChenWXS25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Machine learning has profoundly influenced various aspects of our lives. However, privacy breaches have caused significant unease and concern among the general public. Preserving the privacy of sensitive data during the training and inference phases of machine learning is a key challenge. Cryptography-based privacy-preserving machine learning (crypto-based PPML) offers a viable solution to this challenge. In this article, we studied over 100 publications on crypto-based PPML frameworks published between 2016 and 2024, including 55  client-server architecture  frameworks and 64  multi-party architecture  frameworks. We provide a comprehensive overview of these frameworks, highlighting their features across various dimensions. Furthermore, we conduct an in-depth analysis, delving into scenarios, privacy goals, threat models, and optimization techniques that underpin these innovative solutions. We also discuss the challenges in the field of crypto-based PPML, including aspects of  security and privacy ,  efficiency , and  availability and usability . Finally, we offer an outlook on future research directions, aiming to provide valuable insights for both scholars and practitioners.}
}


@article{DBLP:journals/tkdd/LiLL25,
	author = {Dongjie Li and
                  Dong Li and
                  Guang Lian},
	title = {Representation Learning Based on Ordinary Differential Equations for
                  Dynamic Networks},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {4},
	pages = {1--23},
	year = {2025},
	url = {https://doi.org/10.1145/3723359},
	doi = {10.1145/3723359},
	timestamp = {Fri, 26 Dec 2025 20:52:36 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/LiLL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Representation learning on networks, mapping the network into a low-dimensional vector space, has received signification attention recently due to its widespread application in graph data mining tasks. With the success of representation learning in static networks, we push further for practical scenarios of dynamic networks. Existing methods model the dynamic network by dividing the dynamic network into sequences of network snapshots, see each network snapshot as a static network, and utilize the dynamic evolution between snapshots, they capture the discrete dynamic evolution of dynamic networks. However, a dynamic network continuously evolves over time. Capturing the continuously dynamic evolution of dynamic networks is important for dynamic network representation. In this article, we regard a dynamic network as a dynamic system, use the ordinary differential equation (ODE) to model the dynamic evolution of dynamic networks, and integrate the ODE over continuous-time to capture continuously dynamic evolution of dynamic networks; and design a new encoder-decoder model for dynamic networks representation. We improve the gated recurrent unit (GRU) module (only capturing the discrete dynamic evolution of the dynamic network and structure information) by combining an ODE and a GRU. The improved GRU as the encoder can learn the continuously dynamic evolution, and structure information of the dynamic network, where the ODE parameterized by a graph neural network models the continuously dynamic evolution of each network snapshot. Use the ODE and Inner-Productor as the decoder, where the ODE is integrated over continuous-time to learn the continuous dynamic evolution of the latent representation of the whole dynamic network, and the Inner-Productor reconstructs the topological structure of each snapshot by doing the inner-product between nodes representation, the reconstructing errors as the objective function of our method. To assess our model, we expand the experiment on several real-world dynamic networks, and results show that our method consistently outperforms existing baselines in three dynamic link prediction tasks; the best is up to 6.54  improvement. To our knowledge, our method is the first work using the ODE to capture the continuously dynamic evolution of dynamic networks.}
}


@article{DBLP:journals/tkdd/LiuZY25,
	author = {Zhanyu Liu and
                  Guanjie Zheng and
                  Yanwei Yu},
	title = {Multi-scale Traffic Pattern Bank for Cross-city Few-shot Traffic Forecasting},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {4},
	pages = {1--24},
	year = {2025},
	url = {https://doi.org/10.1145/3727622},
	doi = {10.1145/3727622},
	timestamp = {Thu, 11 Sep 2025 20:24:53 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/LiuZY25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Traffic forecasting is crucial for  intelligent transportation systems (ITS) , aiding in efficient resource allocation and effective traffic control. However, its effectiveness often relies heavily on abundant traffic data, while many cities lack sufficient data due to limited device support, posing a significant challenge for traffic forecasting. Recognizing this challenge, we have made a noteworthy observation: traffic patterns exhibit similarities across diverse cities. Building on this key insight, we propose a solution for the cross-city few-shot traffic forecasting problem called  Multi-scale Traffic Pattern Bank (MTPB) . Primarily, MTPB initiates its learning process by leveraging data-rich source cities, effectively acquiring comprehensive traffic knowledge through a spatial-temporal-aware pre-training process. Subsequently, the framework employs advanced clustering techniques to systematically generate a multi-scale traffic pattern bank derived from the learned knowledge. Next, the traffic data of the data-scarce target city could query the traffic pattern bank, facilitating the aggregation of meta-knowledge. This meta-knowledge, in turn, assumes a pivotal role as a robust guide in subsequent processes involving graph reconstruction and forecasting. Empirical assessments conducted on real-world traffic datasets affirm the superior performance of MTPB, surpassing existing methods across various categories and exhibiting numerous attributes conducive to the advancement of cross-city few-shot forecasting methodologies. The code is available in  https://github.com/zhyliu00/MTPB .}
}


@article{DBLP:journals/tkdd/NguyenT25,
	author = {Minh Duc Nguyen and
                  Viet Cuong Ta},
	title = {Temporal Structural Preserving with Subtree Attention in Dynamic Graph
                  Transformers},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {4},
	pages = {1--24},
	year = {2025},
	url = {https://doi.org/10.1145/3720549},
	doi = {10.1145/3720549},
	timestamp = {Thu, 11 Sep 2025 20:24:53 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/NguyenT25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Dynamic graph learning is a rapidly developing area of research due to its widespread application in various real-world networks. Most existing works combine graph neural networks and sequential models to exploit the graph topology and the temporal information of dynamic graphs. However, these methods exhibit certain limitations in extracting local and global information and capturing fine-grained temporal structure in dynamic graphs. In this article, we present our novel framework, Dynamic Graph Subtree Attention, which is centralized by a learnable temporal edge sampling module and a lightweight attention operator to address the aforementioned issues. Our approach first constructs a temporal union graph for each time step using an adaptive edge sampling module, which preserves relevant interactions for our graph encoder to directly exploit fine-gained interactions across different times. Based on the temporal union graph, we further propose a subtree attention module that leverages the multi-hop representation and the self-attention mechanism to properly extract the local and global information from first- to high-order neighborhoods. To further reduce the computation complexity, the subtree module is equipped with a kernelized attention operation, which scales linearly with respect to the number of edges. By performing extensive experiments, we demonstrate the superiority of our proposed model in dynamic graph representation learning, as it consistently outperforms existing methods in future link prediction tasks. The code is publicly available at:  https://github.com/minhduc1122002/DySubTree .}
}


@article{DBLP:journals/tkdd/PellizzoniPP25,
	author = {Paolo Pellizzoni and
                  Andrea Pietracaprina and
                  Geppino Pucci},
	title = {Fully Dynamic Clustering and Diversity Maximization in Doubling Metrics},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {4},
	pages = {1--45},
	year = {2025},
	url = {https://doi.org/10.1145/3727881},
	doi = {10.1145/3727881},
	timestamp = {Sat, 06 Sep 2025 20:29:30 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/PellizzoniPP25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We present approximation algorithms for some variants of  k -center clustering and diversity maximization in a fully dynamic setting, where the active pointset evolves through arbitrary insertions and deletions. All algorithms employ a coreset-based strategy and rely on the use of the cover tree data structure, which we crucially augment to maintain, at any time, some additional information enabling the efficient extraction of the solution for the specific problem. For all the problems under consideration, our algorithms compute  \\((\\alpha+\\varepsilon)\\) -approximate solutions, where  \\(\\alpha\\)  is the best-known approximation attainable in polynomial time in the standard static setting, and  \\(\\varepsilon > 0\\)  is a user-provided accuracy parameter. Remarkably, and unlike previous works, the (cover tree) data structure used by our algorithms and the running times of the update procedures are both independent of the accuracy parameter  \\(\\varepsilon\\)  and, for the  k -center variants, also of parameter  k . The analysis is performed in terms of the doubling dimension of the metric space which the points belong to, and it shows that, for spaces of bounded doubling dimension, the times required to extract solutions to the above problems are dramatically smaller than those that would be required to recompute solutions on the entire active pointset from scratch. To the best of our knowledge, ours are the first solutions for the matroid center and diversity maximization problems in the fully dynamic setting. The theoretical results are complemented by an extensive set of experiments, which demonstrate the efficiency and effectiveness of our algorithms for  k -center without and with outliers against previously known ones.}
}


@article{DBLP:journals/tkdd/ZhaoTLHM25,
	author = {Yaling Zhao and
                  Lei Tang and
                  Yunji Liang and
                  Zeyu He and
                  Junchi Ma},
	title = {Optimizing Matching for On-Demand Ride-Pooling with Stochastic Day-to-Day
                  Dynamics},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {4},
	pages = {1--29},
	year = {2025},
	url = {https://doi.org/10.1145/3721434},
	doi = {10.1145/3721434},
	timestamp = {Thu, 11 Sep 2025 20:24:53 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/ZhaoTLHM25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Ride-pooling significantly reduces traffic congestion by enhancing fleet utilization through effective ride-matching. Real-world ride-pooling systems are dynamic, with fluctuations in driver availability and demand throughout the day. This necessitates adaptive ride-matching strategies that can quickly adjust to changing proximities and identify new carpooling opportunities by recalculating driver-rider correlations. However, most current methods primarily focus on static demand-supply scenarios and short-term accessibility, falling short in dynamic environment. In this study, we introduce a dynamic heterogeneous network model that captures the evolving nature of ride-pooling systems, where new requests and carpooling arrangements continuously emerge. We propose an embedding model-based matching decision process that operates online, adjusting to changes in the network’s structure. This process involves constructing a dynamic heterogeneous ride-pooling network that encompasses diverse node attributes and driver-rider connections, updating these representations to reflect the network’s evolution, and quickly identifying and ranking candidate riders for efficient online matching. Our approach demonstrates improved performance in offline evaluations using datasets from Austin, TX (RideAustin) and Chengdu, China (DiDi Chuxing). We observe a reduction in the necessary fleet size as new orders are placed, and an improvement in drivers’ matching probability compared to existing methods (e.g., an increase of 5.4–31.1% in the assignment rate on DiDi dataset), showcasing the advantage of employing dynamic network embedding to cut down on matching time (e.g., a decrease of 3.7–228.8 seconds in running time on DiDi dataset). Furthermore, we develop a simulated ride-pooling system (SRPool) that mimics dynamic demand-supply fluctuations and supports vehicle routing, providing a robust platform for evaluating ride-matching strategies. Our strategy not only excels in the SRPool environment but also effectively minimizes the total trip distance and rider waiting times.}
}


@article{DBLP:journals/tkdd/XuLXL25,
	author = {Xiuqin Xu and
                  Mingwei Lin and
                  Zeshui Xu and
                  Xin Luo},
	title = {Attention-Mechanism-Based Neural Latent-Factorization-of-Tensors Model},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {4},
	pages = {1--27},
	year = {2025},
	url = {https://doi.org/10.1145/3719295},
	doi = {10.1145/3719295},
	timestamp = {Sat, 06 Sep 2025 20:29:30 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/XuLXL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {High-Dimensional and Incomplete (HDI) tensors contain a wealth of knowledge and patterns, which are typically utilized to characterize complex relationships between entities in a variety of industrial applications. Currently, the neural network-based tensor factorization model has shown superiority when handling the missing data in HDI tensors. However, it only uses the outer product of latent factors (LFs) of entities and neglects the interactions between the LF. In addition, the simple linear operation does not consider the nonlinear structure of the HDI tensor. To overcome the aforementioned issues, an Attention-mechanism-based Neural Latent-Factorization-of-Tensors (ANLFT) model is provided in this article. It encompasses three primary ideas: (a) incorporating the theory of neural networks with the latent factorization of tensor to construct the nonlinear structure in the HDI tensor effectively; (b) adopting the attention mechanism to depict the interactions between LF; (c) using the position-transitional particle swarm optimization backward propagation learning ( P 2 BP) scheme to train the ANLFT model efficiently. The experimental results on eight HDI datasets show that the ANLFT model can obtain higher estimation performance gain than state-of-the-art models. The convergence performance of the proposed model is also competitive with that of state-of-the-art models.}
}


@article{DBLP:journals/tkdd/ZongFWXL25,
	author = {Zefang Zong and
                  Tao Feng and
                  Jingwei Wang and
                  Tong Xia and
                  Yong Li},
	title = {Deep Reinforcement Learning for Demand-Driven Services in Logistics
                  and Transportation Systems: {A} Survey},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {4},
	pages = {1--42},
	year = {2025},
	url = {https://doi.org/10.1145/3708325},
	doi = {10.1145/3708325},
	timestamp = {Thu, 11 Sep 2025 20:24:53 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/ZongFWXL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recent technology development brings the boom of numerous new Demand-Driven Services (DDS) into urban lives, including ridesharing, on-demand delivery, express systems, and warehousing. In DDS, a service loop is an elemental structure, including its service worker, the service providers, and corresponding service targets. The service workers should transport either people or parcels from the providers to the target locations. Various planning tasks within DDS can thus be classified into two individual stages: (1) Dispatching, which is to form service loops from demand/supply distributions, and (2) Routing, which is to decide specific serving orders within the constructed loops. Generating high-quality strategies in both stages is important to develop DDS but faces several challenges. Meanwhile, deep reinforcement learning (DRL) has been developed rapidly in recent years. It is a powerful tool to solve these problems since DRL can learn a parametric model without relying on too many problem-based assumptions and optimize long-term effects by learning sequential decisions. In this survey, we first define DDS, then highlight common applications and important decision/control problems within. For each problem, we comprehensively introduce the existing DRL solutions. We also introduce open simulation environments for development and evaluation of DDS applications. Finally, we analyze remaining challenges and discuss further research opportunities in DRL solutions for DDS.}
}


@article{DBLP:journals/tkdd/LiWLGFWW25,
	author = {Yan Li and
                  Zhulin Wang and
                  Jing Liu and
                  Lei Guo and
                  Philippe Fournier{-}Viger and
                  Youxi Wu and
                  Xindong Wu},
	title = {Mining Repetitive Negative Sequential Patterns with Gap Constraints},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {4},
	pages = {1--29},
	year = {2025},
	url = {https://doi.org/10.1145/3716390},
	doi = {10.1145/3716390},
	timestamp = {Fri, 12 Sep 2025 07:39:22 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/LiWLGFWW25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Sequential pattern mining (SPM) with gap constraints (or repetitive SPM or tandem repeat discovery in bioinformatics) can find frequent repetitive subsequences satisfying gap constraints, which are called positive sequential patterns with gap constraints (PSPGs). However, classical SPM with gap constraints cannot find the frequent missing items in the PSPGs. To tackle this issue, this article explores negative sequential patterns with gap constraints (NSPGs). We propose an efficient NSPG-Miner algorithm that can mine both frequent PSPGs and NSPGs simultaneously. To effectively reduce candidate patterns, we propose a pattern join strategy with negative patterns which can generate both positive and negative candidate patterns at the same time. To calculate the support (frequency of occurrence) of a pattern in each sequence, we explore a NegPair algorithm that employs a key-value pair array structure to deal with the gap constraints and the negative items simultaneously and can avoid redundant rescanning of the original sequence, thus improving the efficiency of the algorithm. To report the performance of NSPG-Miner, 11 competitive algorithms and 11 datasets are employed. The experimental results not only validate the effectiveness of the strategies adopted by NSPG-Miner but also verify that NSPG-Miner can discover more valuable information than the state-of-the-art algorithms. Algorithms and datasets can be downloaded from  https://github.com/wuc567/Pattern-Mining/tree/master/NSPG-Miner .}
}


@article{DBLP:journals/tkdd/YanWLYYW25,
	author = {Hao Yan and
                  Senzhang Wang and
                  Chaozhuo Li and
                  Jun Yin and
                  Philip S. Yu and
                  Jianxin Wang},
	title = {Have Our Cake and Eat It: Augmentation Diversity and Semantic Consistency
                  Balanced Graph Contrastive Learning},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {4},
	pages = {1--25},
	year = {2025},
	url = {https://doi.org/10.1145/3728646},
	doi = {10.1145/3728646},
	timestamp = {Thu, 11 Sep 2025 20:24:53 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/YanWLYYW25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Self-supervised learning on graph neural networks is receiving increasing attention due to the difficulty of obtaining graph labels in many real applications. Graph contrastive learning (GCL), a recently popular method for self-supervised learning on graphs, has achieved great success in many tasks. The key to the effectiveness of GCL is the construction of suitable contrasting pairs to capture important attributes of the data through the data augmentation modules. However, most of the existing approaches fail to fully consider both data diversity and the semantic consistency when conducting data augmentation. To fill this gap, we propose an augmentation diversity and semantic consistency balanced graph contrastive learning model (ADSCB for short), which enhances the representation ability of the CL model through richer contrasting objectives. In particular, we first introduce a semantic consistency module to extract the subgraph from the original graph through optimizing a carefully designed semantic consistency loss. Then, we introduce an augmentation diversity module and perform data augmentation and cross-scale mix-up operations on the original graph and the extracted semantic preserved subgraph to generate more diverse contrasting pairs. With the above two modules, our model ultimately achieves two contrasting objectives: diversity contrasting and semantic contrasting. The tradeoff between these two contrasting objectives allows our model to benefit from both the augmentation diversity and the semantic consistency. We evaluate ADSCB for graph classification in unsupervised, semi-supervised, and transfer learning settings using standard graph contrastive learning benchmarks. The results demonstrate the superiority of our method against several state-of-the-art baselines.}
}


@article{DBLP:journals/tkdd/XiaML25,
	author = {Hongbin Xia and
                  Xiangzhong Meng and
                  Yuan Liu},
	title = {Non-Parallel Story Author-Style Transfer with Disentangled Representation
                  Learning},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {4},
	pages = {1--26},
	year = {2025},
	url = {https://doi.org/10.1145/3726870},
	doi = {10.1145/3726870},
	timestamp = {Thu, 11 Sep 2025 20:24:53 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/XiaML25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Non-parallel story author-style transfer is an important but challenging task in natural language process, which requires transferring an input story into another author-style while maintaining source semantics. Despite recent progress, current text style transfer systems still face the challenges of low robustness of the model and low quality of the generated stories. To address these challenges, we propose an end-to-end framework incorporating dual encoder components and a fusion mechanism, which can achieve explicit style-content disentanglement and effectively fusing source-domain content with target-domain stylistic features. First, we extract text from source stories containing content information using empirical extraction rules and prompt engineering. And then, we propose a novel generation model which achieves story-style transfer through capturing source content features and target style features and then fusing them. We use two additional training objectives to learn high-level discourse representations. Moreover, we have constructed a new dataset for this task. Extensive experiments based on automatic and human evaluation show that our model significantly outperforms state-of-the-art baselines, achieving approximately 8.5% average improvement in comprehensive performance metrics, demonstrating the effectiveness of our model in story-style transfer.}
}


@article{DBLP:journals/tkdd/JirachanchaisiriMT25,
	author = {Pongsakorn Jirachanchaisiri and
                  Saranya Maneeroj and
                  Atsuhiro Takasu},
	title = {COLANet: Cross-Domain Recommender Systems with Latent Overlapping
                  Items on Graph Neural Networks},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {5},
	pages = {1--33},
	year = {2025},
	url = {https://doi.org/10.1145/3730404},
	doi = {10.1145/3730404},
	timestamp = {Thu, 11 Sep 2025 20:24:53 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/JirachanchaisiriMT25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cross-domain recommender systems (CDRSs) enhance recommendations by transferring knowledge of overlapping users across two domains. Deep canonical correlation analysis (DCCA) shows promising results in CDRSs by maximizing correlations between representations of overlapping users, enabling cross-domain knowledge transfer that depends on the degree of relationship between domains. As a result, DCCA selectively shares only relevant knowledge, alleviating the problem of noisy representation found in traditional CDRSs, where they transfer knowledge regardless of the correlation strength between domains. Although DCCA is used for user transfer, item transfer, referring to the transfer of explicit knowledge of the same items between domains, is impossible due to the absence of overlapping items to facilitate direct knowledge transfer. Meanwhile, graph neural networks (GNNs) embed users and items from separate user and item graphs in each domain. Therefore, better representations are obtained from captured complex relationships and collaborative signals. To construct graphs of overlapping items, latent linkages among items between domains could be discovered by the neural topic model (NTM), forming new graphs representing the latent relationships. Therefore, COLANet, a GNN-based CDRS, is proposed to solve the DCCA limitation on item transfer by proposing the extraction of item representations that do not exist in another domain using latent characteristics. First, user-user graphs are constructed using user similarity, and the item-topic graph is constructed using latent topics learned from item descriptions with NTM. Hence, user and item graphs of each domain are constructed separately, preventing domain relationship misalignment. Second, these graphs are fed to GNN to obtain user and item representations. Third, these representations are fed to DCCA to transfer knowledge between user-user and item-item. Finally, correlated user and item representations of each domain are used to predict ratings. The experiments demonstrate that COLANet outperforms the baselines across four pairs of domains, including both similar and different domains.}
}


@article{DBLP:journals/tkdd/XuZMZZB25,
	author = {Hongjia Xu and
                  Liangliang Zhang and
                  Yao Ma and
                  Sheng Zhou and
                  Zhuonan Zheng and
                  Jiajun Bu},
	title = {Learning to Reduce the Scale of Large Graphs: {A} Comprehensive Survey},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {5},
	pages = {1--25},
	year = {2025},
	url = {https://doi.org/10.1145/3729427},
	doi = {10.1145/3729427},
	timestamp = {Thu, 11 Sep 2025 20:24:53 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/XuZMZZB25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graph data, prevalent across domains like social networks, biological systems, and recommendation systems, presents significant challenges due to its large scale and complex structure. The advent of Graph Neural Networks (GNNs) has revolutionized graph data mining by effectively capturing node dependencies and neighborhood information. However, the computational complexity of processing large-scale graphs remains a major hurdle, as real-world graphs often consist of millions or even billions of nodes and edges. Efficient techniques like message passing and sampling have helped mitigate this issue, but memory and processing constraints persist. A promising approach to addressing these challenges is learning to reduce the size of large-scale graphs while retaining essential information, thus facilitating faster and more efficient graph data mining tasks, such as graph condensation, reduction, coarsening, summarization, and so on. Despite the differences in terminology, approaches under these topics share the same motivation: to generate smaller yet informative graphs that can replace the original large-scale datasets. In this article, we unify these approaches under the concept of Graph Scaling (GS), highlighting the shared motivation across multiple topics. Alongside this definition, to clarify the question of what principles should be followed when scaling a graph and how a scaled graph was formulated, we propose a taxonomy to methodically categorize and understand existing methods. Moreover, by organizing the dataset and evaluation metrics, we aim to provide a more comprehensive understanding of the GS methods from a practical perspective. Moving forward, we delve into the limitations and challenges of GS methods, identifying the shortcomings and potential in the literature. Finally, we conclude this article by outlining future directions and offering concise guidelines to inspire future research in this field. A full paper list and online resources about GS are available at  https://github.com/Frostland12138/Awesome-Graph-Scaling .}
}


@article{DBLP:journals/tkdd/AiLJ25,
	author = {Yuyan Ai and
                  Chaoqun Li and
                  Liangxiao Jiang},
	title = {Intent-aware Recommendation Based on Principal Component Analysis},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {5},
	pages = {1--21},
	year = {2025},
	url = {https://doi.org/10.1145/3731761},
	doi = {10.1145/3731761},
	timestamp = {Thu, 11 Sep 2025 20:24:53 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/AiLJ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In recommender systems, exploring user intents allows for a better understanding and exploration of user preferences, thereby improving recommendation performance. However, existing methods for modeling user intents often do so by statically setting the intent count, which can result in redundancy or insufficiency in capturing the full range of user intents. In order to solve this problem, this article proposes a model named  Intent-aware Recommendation Based on Principal Component Analysis (Intent PCA) . Intent PCA is a novel application of PCA in the field of recommender systems. This model defines intents as users’ preferences for some specific relations shown on a knowledge graph and constructs a user-relation matrix to calculate users’ preferences for relations. Then PCA is applied on the user-relation matrix to extract user intents. Benefit from good characteristics of PCA, our PCA-based user intent extraction model can comprehensively model user intents while simultaneously avoid intent redundancy. Moreover, by combining the user intents, this article designs an intent-based information propagation method to differentially aggregate information from surrounding neighbor nodes. Experiments conducted on three datasets validate the effectiveness of the proposed Intent PCA model.}
}


@article{DBLP:journals/tkdd/GuptaK25,
	author = {Shubham Gupta and
                  Suman Kundu},
	title = {Communities in Streaming Graphs: Small Space Data Structure, Benchmark
                  Data Generation, and Linear Algorithm},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {5},
	pages = {1--24},
	year = {2025},
	url = {https://doi.org/10.1145/3735976},
	doi = {10.1145/3735976},
	timestamp = {Sat, 06 Sep 2025 20:29:30 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/GuptaK25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Identifying and preserving community structures in a streaming graph is a very challenging task. However, many applications require the identification of these communities in very limited space and time. In this article, we design Community Sketch, a small space data structure that efficiently preserves communities. On query, it provides communities in constant time. With the use of community sketch data structure, a linear streaming community detection algorithm is proposed. Experimental results on the large real-world networks show that our algorithm outperforms other state-of-the-art algorithms in terms of quality metrics (NMI, F1-score, and WCC). Further, we propose an algorithm to produce benchmark network, namely, Temporal Community Benchmark Dataset (TCBD) which contains both true community labels and temporal information of edges. These synthetic networks are used to validate the proposed algorithm.}
}


@article{DBLP:journals/tkdd/XuZLWCZW25,
	author = {Lanling Xu and
                  Junjie Zhang and
                  Bingqian Li and
                  Jinpeng Wang and
                  Sheng Chen and
                  Wayne Xin Zhao and
                  Ji{-}Rong Wen},
	title = {Tapping the Potential of Large Language Models as Recommender Systems:
                  {A} Comprehensive Framework and Empirical Analysis},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {5},
	pages = {1--51},
	year = {2025},
	url = {https://doi.org/10.1145/3726871},
	doi = {10.1145/3726871},
	timestamp = {Thu, 11 Sep 2025 20:24:53 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/XuZLWCZW25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recently, Large Language Models (LLMs) such as ChatGPT have showcased remarkable abilities in solving general tasks, demonstrating the potential for applications in recommender systems. To assess how effectively LLMs can be used in recommendation tasks, our study primarily focuses on employing LLMs as recommender systems through prompt engineering. We propose a general framework for leveraging LLMs in recommendation tasks, focusing on the capabilities of LLMs as recommenders. To conduct our analysis, we formalize the input of LLMs for recommendation into natural language prompts with two key aspects and explain how our framework can be generalized to various recommendation scenarios. As for the use of LLMs as recommenders, we analyze the impact of public availability, tuning strategies, model architecture, parameter scale, and context length on recommendation results based on the classification of LLMs. As for prompt engineering, we further analyze the impact of four important components of prompts, i.e., task descriptions, user interest modeling, candidate items construction, and prompting strategies. In each section, we first define and categorize concepts in line with the existing literature. Then, we propose inspiring research questions followed by detailed experiments on two public datasets, in order to systematically analyze the impact of different factors on recommendation performance. Based on our empirical analysis, we finally summarize promising directions to shed lights on future research.}
}


@article{DBLP:journals/tkdd/ZhengLZWW25,
	author = {Xiulin Zheng and
                  Pei{-}Pei Li and
                  Zan Zhang and
                  Jia Wu and
                  Xindong Wu},
	title = {A Relation-Constraint Link Prediction Model for Dynamic Knowledge
                  Graphs with Entity Drift},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {5},
	pages = {1--38},
	year = {2025},
	url = {https://doi.org/10.1145/3725815},
	doi = {10.1145/3725815},
	timestamp = {Thu, 11 Sep 2025 20:24:53 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/ZhengLZWW25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Knowledge Graphs (KGs) often suffer from incompleteness and this issue motivates the task of Knowledge Graph Completion (KGC). Traditional KGC models mainly concentrate on static KGs with a fixed set of entities and relations, or dynamic KGs with temporal characteristics, faltering in their generalization to constantly evolving KGs with possible irregular entity drift. Thus, in this article, we propose a novel link prediction model based on the embedding representation to handle the incompleteness of KGs with entity drift, termed as DCEL. Unlike traditional link prediction, DCEL could generate precise embeddings for drifted entity without imposing any regular temporal characteristic. The drifted entity is added into the KG with its links to the existing entity predicted in an incremental fashion with no requirement to retrain the whole KG for computational efficiency. In terms of DCEL model, it fully takes advantages of unstructured textual description, and is composed of four modules, namely Machine Reading Comprehension (MRC), Relation Constraint Attentive Aggregator (RCAA), Relation-Specific Alignment (RSA), and Relation Constraint Embedding Optimization (RCEO). Specifically, the MRC module is first employed to extract short texts from long and redundant descriptions. Then, RCAA is used to aggregate the embeddings of textual description of drifted entity and the pre-trained word embeddings learned from corpus to a single text-based entity embedding while shielding the impact of noise and irrelevant information. After that, RSA is applied to align the text-based entity embedding to graph-based space to obtain the corresponding graph-based entity embedding, and then the learned embeddings are fed into the gate structure to be optimized based on the RCEO to improve the accuracy of representation learning. Finally, the graph-based model TransE is used to perform link prediction for drifted entity. Extensive experiments conducted on benchmark datasets in terms of evaluation protocols of MRR and Hits@ k  reveal the superiority of DCEL model compared to its SOTAs.}
}


@article{DBLP:journals/tkdd/HuJLZH25,
	author = {Lianyu Hu and
                  Mudi Jiang and
                  Yan Liu and
                  Quan Zou and
                  Zengyou He},
	title = {Clustering Categorical Data via Multiple Hypothesis Testing},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {5},
	pages = {1--31},
	year = {2025},
	url = {https://doi.org/10.1145/3735977},
	doi = {10.1145/3735977},
	timestamp = {Thu, 11 Sep 2025 20:24:53 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/HuJLZH25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Categorical data clustering is a fundamental data mining problem, which has been extensively studied during the past decades. To date, many effective clustering algorithms for categorical data are available in the literature. However, almost all existing categorical data clustering algorithms did not address the issue of the statistical significance of detected clusters. In particular, how to assess the statistical significance of a set of non-overlapping categorical clusters still remains unaddressed. In this article, we formulate the categorical data clustering problem as a multiple hypothesis testing problem, where the null hypothesis is that each attribute is independent of the given partition of clusters. Then, all individual  p -values from different attributes are integrated to obtain a consensus  p -value through statistical meta-analysis. Thereafter, a significance-based clustering algorithm is proposed in which the combined  p -value is efficiently optimized in an indirectly and incremental manner. Experimental results on 25 real-world datasets demonstrate that our method is capable of achieving comparable performance to state-of-the-art categorical data clustering algorithms. Furthermore, our method has a good capability of determining whether there really exists a clustering structure and assessing whether a given set of clusters is statistically significant.}
}


@article{DBLP:journals/tkdd/MozhdehiWSW25,
	author = {Arash Mozhdehi and
                  Yunli Wang and
                  Sun Sun and
                  Xin Wang},
	title = {{SED2AM:} Solving Multi-Trip Time-Dependent Vehicle Routing Problem
                  Using Deep Reinforcement Learning},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {5},
	pages = {1--33},
	year = {2025},
	url = {https://doi.org/10.1145/3721983},
	doi = {10.1145/3721983},
	timestamp = {Thu, 11 Sep 2025 20:24:53 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/MozhdehiWSW25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Deep Reinforcement Learning (DRL)-based frameworks, featuring Transformer-style policy networks, have demonstrated their efficacy across various Vehicle Routing Problem (VRP) variants. However, the application of these methods to the Multi-Trip Time-Dependent Vehicle Routing Problem (MTTDVRP) with maximum working hours constraints—a pivotal element of urban logistics—remains largely unexplored. This article introduces a DRL-based method called the Simultaneous Encoder and Dual Decoder Attention Model (SED2AM), tailored for the MTTDVRP with maximum working hours constraints. The proposed method introduces a temporal locality inductive bias to the encoding module of the policy networks, enabling it to effectively account for the time dependency in travel distance/time. The decoding module of SED2AM includes a vehicle selection decoder that selects a vehicle from the fleet, effectively associating trips with vehicles for functional multi-trip routing. Additionally, this decoding module is equipped with a trip construction decoder leveraged for constructing trips for the vehicles. This policy model is equipped with two classes of state representations, fleet state, and routing state, providing the information needed for effective route construction in the presence of maximum working hours constraints. Experimental results using real-world datasets from two major Canadian cities not only show that SED2AM outperforms the current state-of-the-art DRL-based and metaheuristic-based baselines but also demonstrate its generalizability to solve larger scale problems.}
}


@article{DBLP:journals/tkdd/LiZXQG25,
	author = {Dong Li and
                  Aijia Zhang and
                  Huan Xiong and
                  Biqing Qi and
                  Junqi Gao},
	title = {FDphormer: Beyond Homophily with Feature-Difference Position Encoding},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {5},
	pages = {1--19},
	year = {2025},
	url = {https://doi.org/10.1145/3727882},
	doi = {10.1145/3727882},
	timestamp = {Thu, 16 Oct 2025 20:58:18 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/LiZXQG25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graph Transformers have garnered significant attention due to their ability to address the challenges of long-distance interactions in previous GNNs. However, most current graph Transformers face difficulties when dealing with heterophilic graphs. To investigate this issue, we first analyzed the distribution of attention weights for homophilic and heterophilic graphs. We discovered that heterophily interferes with the allocation of attention weights, leading to errors in node classification. Further investigation revealed that the root cause may be the difficulty of current graph Transformers in capturing the difference between the features of each node and its neighbors. To alleviate this issue, we propose a position encoding strategy called DiSP to better capture the feature difference and introduce FDphormer, a new efficient and simple graph Transformer model based on DiSP. Additionally, we analyze the generalization error of existing graph Transformer models and provide an upper bound on the generalization error of current graph Transformers with the introduction of DiSP. Extensive experiments demonstrate that FDphormer not only outperforms state-of-the-art methods on diverse heterogeneous datasets but also exhibits competitive performance under homophily.}
}


@article{DBLP:journals/tkdd/XuWHTZL25,
	author = {Liming Xu and
                  Yongheng Wang and
                  Chunlin He and
                  Quan Tang and
                  Xianhua Zeng and
                  Jiancheng Lv},
	title = {Deep Disease Label-guided Graph Convolutional Network for Medical
                  Report Generation},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {5},
	pages = {1--23},
	year = {2025},
	url = {https://doi.org/10.1145/3722226},
	doi = {10.1145/3722226},
	timestamp = {Thu, 11 Sep 2025 20:24:53 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/XuWHTZL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Medical report generation which extracts pathological information within medical images and subsequently produces diagnostic text autonomously aims to alleviate the workload of medical experts and offers auxiliary support in diagnoses. Despite some preliminary progress have been made, several limitations still persist, including lack of specificity in extracted visual features, insufficient consideration of cross-modal alignment and extensive preparatory work required for prior knowledge. To address these issues, we, in this article, propose a novel deep label-guided graph convolutional network for medical report generation which utilizes disease label to guide to extract pathological information from medical images. To be specific, we first construct graph convolutional network to guide the model to extract the specific visual features based on disease labels, which allowing us to selectively extract disease specificity information resided in medical images. Then, we develop cross-modal alignment module to guide the alignment across medical image, diagnose report and disease label, which enables more accurate generation with more precise description. Besides, we build pre-constructed relational matrix to guide report generation model to learn the relationship between visual features and disease types with minimal additional workload to further reduce intensive workload. Extensive experiments on three benchmark datasets, i.e., IU X-ray, MIMIC-CXR, and COV-CTR, demonstrate that the proposed method outperforms the recent state-of-the-art medical report generation methods. Ours shows a 9.2% improvement in BLEU-4 score on the IU X-ray dataset, and both BLEU-4 and CIDEr scores improve by 6.31% on the MIMIC-CXR dataset. Additionally, the results show that it can be easily to applied and extended to medical image report generation with different modalities.}
}


@article{DBLP:journals/tkdd/SangGLZ25,
	author = {Chun{-}Yan Sang and
                  Ming Gong and
                  Shigen Liao and
                  Wei Zhou},
	title = {{MA-GCL4SR:} Improving Graph Contrastive Learning-Based Sequential
                  Recommendation with Model Augmentation},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {5},
	pages = {1--21},
	year = {2025},
	url = {https://doi.org/10.1145/3722561},
	doi = {10.1145/3722561},
	timestamp = {Thu, 11 Sep 2025 20:24:53 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/SangGLZ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Sequential recommendation (SR) has leveraged the advantages of graph contrastive learning (GCL) to enhance the representation of SR, which mitigates to some extent the constraint of scarce labeled data for supervision in SR. Existing work applies general graph data augmentation strategies to generate positive sample pairs, then further representation learning is conducted through a shared graph neural network. In this study, we identify limitations in applying traditional GCL to sequential recommendation: after the data augmentation, the shared graph neural network architecture used for feature learning fails to supply sufficiently diverse contrastive views, which are necessary to effectively identify and focus on the key information that is truly relevant for sequential recommendation. To ease this limitation, we propose a novel framework named Model Augmented Graph Contrastive Learning for Sequential Recommendation (MA-GCL4SR), which emphasizes modifying the internal architectures of the graph neural network through the use of model augmentation strategies, rather than focusing on making improvements during the data augmentation phase before encoding. Thereby, we construct a non-shared view encoder for SR, enriching the samples of user’s interaction sequences and strengthen the stability of the augmented sequence. Extensive experiments on four real-world datasets confirm the effectiveness of the proposed MA-GCL4SR paradigm, showcasing its consistent ability to elevate model performance across various real-world scenarios.}
}


@article{DBLP:journals/tkdd/LuLZ25,
	author = {Moli Lu and
                  Linhao Luo and
                  Xiaofeng Zhang},
	title = {Beyond Static Boundaries: Unraveling Temporal Overlapping Communities
                  with Information Bottleneck Guidance},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {5},
	pages = {1--25},
	year = {2025},
	url = {https://doi.org/10.1145/3716391},
	doi = {10.1145/3716391},
	timestamp = {Thu, 11 Sep 2025 20:24:53 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/LuLZ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Community detection has gained significant research interest within the data mining field. It involves identifying subsets of nodes with dense internal connections and sparse external connections. Most studies on community detection focus solely on identifying non-overlapping communities in a static graph. However, in practice, communities often overlap, and the structure of the graphs is dynamically evolving. This dynamic nature leads to community changes and poses a significant challenge in detecting overlapping communities on temporal graphs (T-OCD). While graph neural networks have shown great performance in generating node representations for community detection, learning representations that capture temporal graph structures and support overlapping community detection remain an open question. To address these challenges, we present  T-OCDIB , a novel approach for  T emporal  O verlapping  C ommunity  D etection guided by  I nformation  B ottleneck. Specifically, we first propose an overlapping community detection approach for static graphs, under the guidance of a community-oriented information bottleneck. This approach allows us to learn discriminative node representations specific to each community, facilitating the detection of overlapping communities. Following this, we extend this method to temporal graphs by presenting a temporal convolution module. This module uses adaptive weight matrices based on evolving graph structures to capture temporal dependencies for community detection. Additionally, to promote smooth transitions between consecutive communities, we introduce a temporal smoothing module to further constrain changes in community structure. We evaluate the proposed approach on both real-world and synthetic temporal networks. Experimental results illustrate the superiority of  T-OCDIB  over other community detection methods.}
}


@article{DBLP:journals/tkdd/LiuRZYMWFS25,
	author = {Fenglin Liu and
                  Xuancheng Ren and
                  Guangxiang Zhao and
                  Chenyu You and
                  Sherry Ma and
                  Xian Wu and
                  Wei Fan and
                  Xu Sun},
	title = {Rethinking Natural Language Generation with Layer-Wise Multi-View
                  Decoding},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {5},
	pages = {1--25},
	year = {2025},
	url = {https://doi.org/10.1145/3729536},
	doi = {10.1145/3729536},
	timestamp = {Thu, 11 Sep 2025 20:24:53 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/LiuRZYMWFS25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In natural language generation, language models, particularly those based on decoder-only architectures as in popular Large Language Models (LLMs), have demonstrated impressive performance across a wide range of tasks. However, encoder-decoder architectures remain highly effective for tasks involving non-text data, such as images and time-series data. The decoder relies on the attention mechanism to efficiently extract information from the encoder. While it is common practice to draw information from only the last encoder layer, this might lead to insufficient training of the encoder layer stack due to the  hierarchy bypassing  problem. In this work, we propose  layer-wise multi-view decoding  for improved encoder-decoder language models, where for each decoder layer, together with the representations from the last encoder layer, which serve as a global view, those from other encoder layers are supplemented for a stereoscopic view of the source inputs. Systematic experiments and analyses show that we successfully address the hierarchy bypassing problem, require almost negligible parameter increase, and improve the performance of sequence learning with deep representations on diverse tasks, i.e., machine translation, abstractive summarization, image captioning, video captioning, medical report generation, and paraphrase generation. In particular, our approach achieves new state-of-the-art results on benchmark datasets, including a low-resource machine translation dataset and low-resource medical report generation datasets.}
}


@article{DBLP:journals/tkdd/MicaleMGBFSGP25,
	author = {Giovanni Micale and
                  Antonio Di Maria and
                  Roberto Grasso and
                  Vincenzo Bonnici and
                  Alfredo Ferro and
                  Dennis Shasha and
                  Rosalba Giugno and
                  Alfredo Pulvirenti},
	title = {MultiGraphMatch: {A} Subgraph Matching Algorithm for Multigraphs},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {5},
	pages = {1--36},
	year = {2025},
	url = {https://doi.org/10.1145/3728361},
	doi = {10.1145/3728361},
	timestamp = {Sat, 06 Sep 2025 20:29:30 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/MicaleMGBFSGP25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Subgraph matching is the problem of finding all the occurrences of a small graph, called the query, in a larger graph, called the target. Although the problem has been widely studied in simple graphs, few solutions have been proposed for multigraphs, in which two nodes can be connected by multiple edges, each denoting a possibly different type of relationship. In our new algorithm MultiGraphMatch (MGM), nodes and edges can be associated with labels and multiple properties. MGM introduces a novel data structure called bit matrix to efficiently index both the query and the target and filter the set of target edges that are matchable with each query edge. In addition, the algorithm proposes a new technique for ordering the processing of query edges based on the cardinalities of the sets of matchable edges. Using the CYPHER query definition language, MGM can perform queries with logical conditions on node and edge labels. We compare MGM with SuMGra and graph database systems Memgraph and Neo4J, showing comparable or better performance in all queries on a wide variety of synthetic and real-world graphs.}
}


@article{DBLP:journals/tkdd/HossainFBKT25,
	author = {Shamima Hossain and
                  Christos Faloutsos and
                  Boris Baer and
                  Hyoseung Kim and
                  Vassilis J. Tsotras},
	title = {Principled Mining, Forecasting, and Monitoring of Honeybee Time Series
                  with {EBV+}},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {5},
	pages = {1--30},
	year = {2025},
	url = {https://doi.org/10.1145/3719014},
	doi = {10.1145/3719014},
	timestamp = {Thu, 11 Sep 2025 20:24:53 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/HossainFBKT25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Honeybees, as natural crop pollinators, play a significant role in biodiversity and food production for human civilization. Bees actively regulate hive temperature (homeostasis) to maintain a colony’s proper functionality. Deviations from usual thermoregulation behavior due to external stressors (e.g., extreme environmental temperature, parasites, pesticide exposure) indicate an impending colony collapse. Anticipating such threats by forecasting hive temperature and finding changes in temperature patterns would allow beekeepers to take early preventive measures and avoid critical issues. In that case, how can we model bees’ thermoregulation behavior for an interpretable and effective hive monitoring system? In this article, we propose the  principled  Electronic Bee-Veterinarian Plus (EBV+) method based on the thermal diffusion equation and a novel “ sigmoid ” feedback-loop (P) controller for analyzing hive health with the following properties: (i) it is  effective  on multiple, real-world beehive time sequences (recorded and streaming), (ii) it is  explainable  with only a few parameters (e.g., hive health factor) that beekeepers can easily quantify and trust, (iii) it issues  proactive  alerts to beekeepers before any potential issue affecting homeostasis becomes detrimental, and (iv) it is  scalable  with a time complexity of  O ( t )  for reconstructing and  O ( t × m )  for finding  m  cuts of a sequence with  t  time-ticks. Experimental results on multiple real-world time sequences showcase the potential and practical feasibility of EBV+. Our method yields accurate forecasting (up to  72%  improvement in RMSE) with up to  600  times fewer parameters compared to baselines (ARX, seasonal ARX, Holt-winters, and DeepAR), as well as detects discontinuities and raises alerts that coincide with domain experts’ opinions. Moreover, EBV+ is scalable and fast, taking less than  1 minute  on a stock laptop to reconstruct 2 months of sensor data.}
}


@article{DBLP:journals/tkdd/QiuZYWH25,
	author = {Jin{-}Jie Qiu and
                  Shengda Zhuo and
                  Philip S. Yu and
                  Chang{-}Dong Wang and
                  Shuqiang Huang},
	title = {Online Learning for Noisy Labeled Streams},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {6},
	pages = {1--29},
	year = {2025},
	url = {https://doi.org/10.1145/3734875},
	doi = {10.1145/3734875},
	timestamp = {Thu, 11 Sep 2025 20:24:53 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/QiuZYWH25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Online learning, characterized by its feature space’s adaptability over time, has emerged as a flexible learning paradigm that has attracted widespread attention. However, existing online learning methods often overlook the distributional differences between instances and the presence of label noise in streaming data, thus significantly hindering the effectiveness and robustness of these algorithms. To overcome these challenges, we propose an online confidence learning algorithm for noisy labeled features, which aims to achieve robustness against arbitrary data streams and noisy labels. It employs two new strategies: online confidence inference, which applies the principle of empirical risk minimization to identify inconsistencies in spatial distributions, and geometric structure learning, which utilizes dynamic instance confidence to compute disparities between instances and their labels. Empirical findings demonstrate that our label correction mechanism enhances classification accuracy more effectively across various types of noisy labels (i.e., symmetric, asymmetric, and flipped). Additionally, a case study on image datasets was conducted to illustrate in detail the effectiveness of our OLNLS algorithm. Code is released in  https://github.com/Zhuosd/OLNLS .}
}


@article{DBLP:journals/tkdd/WangWLCS25,
	author = {Rui Wang and
                  Yanan Wang and
                  Ziang Li and
                  Haitao Cheng and
                  Guozi Sun},
	title = {Distributed Keyword-guided Topic Model with Lexical Knowledge Supervision},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {6},
	pages = {1--19},
	year = {2025},
	url = {https://doi.org/10.1145/3737881},
	doi = {10.1145/3737881},
	timestamp = {Thu, 11 Sep 2025 20:24:53 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/WangWLCS25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Topic models are often used to discover latent semantic patterns from document collections. However, existing unsupervised approaches have the following drawbacks: (1) The mined topics may not match user interests; (2) They are prone to extract semantically similar topics and sacrifice diversity; (3) The mined topics often have low interpretability, which does not meet common sense knowledge. To address these limitations, we propose the Distributed Keyword-guided Topic Model (DiskTM) that incorporates Gaussian-distributed keyword prior knowledge into the modeling process to mine user-interested topics. Furthermore, to inject common-sense knowledge and improve the topic’s interpretability, we extend DiskTM and propose the Distributed Keyword-guided Topic Model with Lexical Knowledge (DiskTM-LK). Experimental results on three publicly available text corpora show that our proposed approaches could extract topics that match user interests (keywords). Moreover, DiskTM and DiskTM-LK could also obtain more coherent and diverse topics, outperforming the state-of-the-art baseline approaches.}
}


@article{DBLP:journals/tkdd/ZhangCM25,
	author = {Zhaodu Zhang and
                  Yue Chao and
                  Xuejun Ma},
	title = {Robust Distributed Estimation for Modal Regression under Least Squares
                  Approximation},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {6},
	pages = {1--21},
	year = {2025},
	url = {https://doi.org/10.1145/3742477},
	doi = {10.1145/3742477},
	timestamp = {Thu, 11 Sep 2025 20:24:53 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/ZhangCM25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Massive datasets pose a serious challenge to traditional statistical methods. Modal regression has greater robustness and high inference efficiency compared to mean regression and likelihood-based methods. In this article, we present a robust distributed least squares approximation (RDLSA) method for heterogeneously distributed massive datasets under the modal regression framework. Specifically, we first approximate the local objective function for each worker/server/machine by using the Taylor expansion, where it is necessary to remain the main quadratic term. Then, each of local machines calculates their corresponding estimates and uploads them to a master machine for obtaining the approximated aggregated estimator. This process yields a one-step global estimator such that one round of communication is required. Correspondingly, the consistency and asymptotic normality of the estimator are rigorously established under some mild conditions. To further reduce the estimation bias, we perform one Newton-Raphson iteration to obtain a two-step global aggregated estimator. In addition, we develop a variable selection procedure for the distributed modal regression under the robust least squares approximation procedure. Finally, we provide simulation experiments and a real data application to verify the superiority of our method.}
}


@article{DBLP:journals/tkdd/FengLWWXWL25,
	author = {Jiadong Feng and
                  Wei Li and
                  Suhuang Wu and
                  Zhao Wei and
                  Yong Xu and
                  Juhong Wang and
                  Hui Li},
	title = {Deep Code Search with Naming-Agnostic Contrastive Multi-View Learning},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {6},
	pages = {1--26},
	year = {2025},
	url = {https://doi.org/10.1145/3737878},
	doi = {10.1145/3737878},
	timestamp = {Wed, 03 Dec 2025 13:26:26 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/FengLWWXWL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Software development is a repetitive task, as developers usually reuse or get inspiration from existing implementations. Code search, which refers to the retrieval of relevant code snippets from a codebase according to the developer’s intent that has been expressed as a query, has become increasingly important in the software development process. Due to the success of deep learning in various applications, a great number of deep learning-based code search approaches have sprung up and achieved promising results. However, developers may not follow the same naming conventions and the same variable may have different variable names in different implementations, bringing a challenge to deep learning-based code search methods that rely on explicit variable correspondences to understand source code. To overcome this challenge, we propose a Naming-Agnostic Code Search (NACS) method based on contrastive multi-view code representation learning. NACS strips information bound to variable names from Abstract Syntax Tree (AST), the representation of the abstract syntactic structure of source code, and focuses on capturing intrinsic properties solely from AST structures. We use semantic-level and syntax-level augmentation techniques to prepare realistically rational data and adopt contrastive learning to design a graph-view modeling component in NACS to enhance the understanding of code snippets. We further model ASTs in a path view to strengthen the graph-view modeling component through multi-view learning. Extensive experiments show that NACS provides superior code search performance compared to baselines and NACS can be adapted to help existing code search methods overcome the impact of different naming conventions. Our implementation is available at  https://github.com/KDEGroup/NACS .}
}


@article{DBLP:journals/tkdd/TingZPLLZ25,
	author = {Kai Ming Ting and
                  Zhong Zhuang and
                  Guansong Pang and
                  Zongyou Liu and
                  Tianrun Liang and
                  Qiuran Zhao},
	title = {What Are Anomalies in a Network?},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {6},
	pages = {1--34},
	year = {2025},
	url = {https://doi.org/10.1145/3723007},
	doi = {10.1145/3723007},
	timestamp = {Thu, 11 Sep 2025 20:24:53 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/TingZPLLZ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This article examines a collection of assumptions used in the current literature on node anomaly detection in a network. The examination raises the question: What are anomalies in a network? Our attempt to answer this question has provided some interesting findings and led to some open questions. This is the first article which formally defines anomalies in a network and introduces the concept of self-verifiability of a detector without ground-truths in a network. They enable existing detectors to be categorized into two types along the line whether they are self-verifiable or not. We suggest a method to evaluate self-verifiable detectors without ground-truths as an alternative to the existing evaluation method that relies on ground-truths.}
}


@article{DBLP:journals/tkdd/PotinFLL25,
	author = {Lucas Potin and
                  Rosa Figueiredo and
                  Vincent Labatut and
                  Christine Largeron},
	title = {Pattern-Based Graph Classification: Comparison of Quality Measures
                  and Importance of Preprocessing},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {6},
	pages = {1--49},
	year = {2025},
	url = {https://doi.org/10.1145/3743143},
	doi = {10.1145/3743143},
	timestamp = {Sat, 06 Sep 2025 20:29:30 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/PotinFLL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graph classification aims to categorize graphs based on their structural and attribute features, with applications in diverse fields such as social network analysis and bioinformatics. Among the methods proposed to solve this task, those relying on patterns (i.e., subgraphs) provide good explainability, as the patterns used for classification can be directly interpreted. To identify meaningful patterns, a standard approach is to use a quality measure, i.e., a function that evaluates the discriminative power of each pattern. However, the literature provides tens of such measures, making it difficult to select the most appropriate for a given application. Only a handful of surveys try to provide some insight by comparing these measures, and none of them specifically focuses on graphs. This typically results in the systematic use of the most widespread measures, without thorough evaluation. To address this issue, we present a comparative analysis of 38 quality measures from the literature. We characterize them theoretically, based on four mathematical properties. We leverage publicly available datasets to constitute a benchmark, and propose a method to elaborate a gold standard ranking of the patterns. We exploit these resources to perform an empirical comparison of the measures, both in terms of pattern ranking and classification performance. Moreover, we propose a clustering-based preprocessing step, which groups patterns appearing in the same graphs to enhance classification performance. Our experimental results demonstrate the effectiveness of this step, reducing the number of patterns to be processed while achieving comparable performance. Additionally, we show that some popular measures widely used in the literature are not associated with the best results.}
}


@article{DBLP:journals/tkdd/GuanHHGC25,
	author = {Yue Guan and
                  Yumei He and
                  Ni Huang and
                  Xunhua Guo and
                  Guoqing Chen},
	title = {Mining Linguistic Styles in Bilateral Matching: {A} Contrastive Learning
                  Approach to Reciprocal Recommendation},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {6},
	pages = {1--25},
	year = {2025},
	url = {https://doi.org/10.1145/3736418},
	doi = {10.1145/3736418},
	timestamp = {Thu, 11 Sep 2025 20:24:53 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/GuanHHGC25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Reciprocal recommendation systems are crucial for online dating platforms to provide quality matches and reduce choice overload. However, the design of reciprocal recommendation systems grapples with the challenges of estimating interpersonal compatibility and predicting the likelihood that two prospective partners will accept each other. Furthermore, despite the crucial role of users’ linguistic styles in determining user match decision-making, the contemporary design of such recommendation systems has not yet effectively incorporated this information. To bridge these gaps, we develop an end-to-end personalized Linguistic Style Matching-based Reciprocal Recommendation System (LS-RRS). We propose cross-user and within-user contrastive learning strategies combined with random masking to extract users’ linguistic styles and further integrate visual and textual information using an efficient convolution block. LS-RRS further models the matching probability using a conditional probability function and introduces a preference inflation factor on the receiver side to account for the asymmetric roles of the bilateral sides. The proposed model addresses the challenge of incorporating users’ linguistic styles into reciprocal recommendation and details the modeling of the two-stage matching process. Extensive experiments show that LS-RRS outperforms state-of-the-art models in recommendation performance, with a 29.35% increase in NDCG@10 when incorporating linguistic styles. Our follow-up analyses further validate the importance and effectiveness of the linguistic style extraction design through word-level and sentence-level visualizations, as well as qualitative case studies. This research contributes to the literature on reciprocal recommendation and offers a viable solution for alleviating user choice overload on online dating platforms.}
}


@article{DBLP:journals/tkdd/WangLZZHLC25,
	author = {Zimu Wang and
                  Jiashuo Liu and
                  Hao Zou and
                  Xingxuan Zhang and
                  Yue He and
                  Dongxu Liang and
                  Peng Cui},
	title = {Exploring and Exploiting Data Heterogeneity in Recommendation},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {6},
	pages = {1--34},
	year = {2025},
	url = {https://doi.org/10.1145/3737290},
	doi = {10.1145/3737290},
	timestamp = {Thu, 11 Sep 2025 20:24:53 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/WangLZZHLC25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Massive amounts of data are the foundation of data-driven recommendation models. As an inherent nature of big data, data heterogeneity widely exists in real-world recommendation systems. It reflects the differences in the properties among sub-populations. Ignoring the heterogeneity in recommendation data could mislead the models, hurt the sub-populational robustness, and finally limit the performance of recommendation models. However, data heterogeneity has not received substantial attention within the recommendation community, prompting us to adequately explore and exploit data heterogeneity to solve these challenges and enhance data analysis. In this study, we specifically focus on two representative categories of heterogeneity in recommendation data: heterogeneity of prediction mechanism and covariate distribution. To explore the data heterogeneity, we propose an algorithm based on bilevel clustering. Additionally, we demonstrate how the explored data heterogeneity can be exploited for prediction and debias in recommendation scenarios, specifically by building models using multiple sub-models and augmenting the propensity score estimation. Extensive experiments conducted on real-world data substantiate the existence of heterogeneity in recommendation data and validate the effectiveness of exploring and exploiting data heterogeneity in improving recommendation performance.}
}


@article{DBLP:journals/tkdd/GuanCZGQ25,
	author = {Wei Guan and
                  Jian Cao and
                  Haiyan Zhao and
                  Yang Gu and
                  Shiyou Qian},
	title = {FeadSeq: {A} Personalized Federated Anomaly Detection Framework for
                  Discrete Event Sequences},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {6},
	pages = {1--26},
	year = {2025},
	url = {https://doi.org/10.1145/3742896},
	doi = {10.1145/3742896},
	timestamp = {Thu, 11 Sep 2025 20:24:53 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/GuanCZGQ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Event sequence anomaly detection has garnered considerable attention in research, encompassing applications such as identifying anomalies in system logs, anomalous transaction users, and so on. Yet, prevailing anomaly detection methods often rely solely on local data for training, potentially leading to imperfect detection performance. In this article, we introduce a personalized Federated anomaly detection framework for discrete event Sequences, named FeadSeq. Specifically, we propose a separate architecture for sequence reconstruction networks (SEPRE) which partitions the network into two parts: a shared part and a standalone part, better suited for federated learning schemes. In tandem, we propose a novel partial shared federated learning scheme that employs a mask strategy to alleviate communication overhead and produce personalized local models to address the statistical heterogeneity of data among clients. This scheme dictates that a subset of weights is communicated between clients and servers for collaborative training, while the remaining weights are trained exclusively locally. To evaluate the effectiveness of FeadSeq, we conduct extensive experiments on both system logs and business process event logs. The results affirm the superiority of FeadSeq over existing personalized federated learning algorithms, showcasing not only improved performance but also reduced communication overhead.}
}


@article{DBLP:journals/tkdd/VillaizanValleladoSSA25,
	author = {Mario Villaiz{\'{a}}n{-}Vallelado and
                  Matteo Salvatori and
                  Carlos Segura and
                  Ioannis Arapakis},
	title = {Diffusion Models for Tabular Data Imputation and Synthetic Data Generation},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {6},
	pages = {1--32},
	year = {2025},
	url = {https://doi.org/10.1145/3742435},
	doi = {10.1145/3742435},
	timestamp = {Thu, 11 Sep 2025 20:24:53 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/VillaizanValleladoSSA25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Data imputation and data generation have important applications across many domains where incomplete or missing data can hinder accurate analysis and decision-making. Diffusion models have emerged as powerful generative models capable of capturing complex data distributions across various data modalities such as image, audio, and time series. Recently, they have been also adapted to generate tabular data. In this article, we propose a diffusion model for tabular data that introduces three key enhancements: (1) a conditioning attention mechanism, (2) an encoder–decoder transformer as the denoising network, and (3) dynamic masking. The conditioning attention mechanism is designed to improve the model’s ability to capture the relationship between the condition and synthetic data. The transformer layers help model interactions within the condition (encoder) or synthetic data (decoder), while dynamic masking enables our model to efficiently handle both missing data imputation and synthetic data generation tasks within a unified framework. We conduct a comprehensive evaluation by comparing the performance of diffusion models with transformer conditioning against state-of-the-art techniques such as Variational Autoencoders, Generative Adversarial Networks, and Diffusion Models, on benchmark datasets. Our evaluation focuses on the assessment of the generated samples with respect to three important criteria, namely: (1) machine learning efficiency, (2) statistical similarity, and (3) privacy risk mitigation. For the task of data imputation, we consider the efficiency of the generated samples across different levels of missing features. The results demonstrate average superior machine learning efficiency and statistical accuracy compared to the baselines, while maintaining privacy risks at a comparable level, particularly showing increased performance in datasets with a large number of features. By conditioning the data generation on a desired target variable, the model can mitigate systemic biases, generate augmented datasets to address data imbalance issues, and improve data quality for subsequent analysis. This has significant implications for domains such as healthcare and finance, where accurate, unbiased, and privacy-preserving data are critical for informed decision-making and fair model outcomes.}
}


@article{DBLP:journals/tkdd/AlfasKSK25,
	author = {Muhammad S. T. Alfas and
                  Manoj Kumar and
                  Shaurya Shriyam and
                  Sandeep Kumar},
	title = {An Efficient Framework for Epidemiological Parameter Estimation via
                  Graph Reduction and Graph Neural Networks},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {6},
	pages = {1--29},
	year = {2025},
	url = {https://doi.org/10.1145/3736727},
	doi = {10.1145/3736727},
	timestamp = {Mon, 22 Sep 2025 08:40:26 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/AlfasKSK25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {We propose an epidemiological parameter estimation framework based on contact networks and graph neural networks (GNNs). Contact network-based epidemiological models allow us to capture heterogeneity and individual-level details more effectively. Parameter estimation involves fitting real-world disease data to mathematical models. Traditionally, several likelihood-based methods that focus on compartment-based simulation models have been widely used to perform parameter estimation. However, these methods suffer from making assumptions such as homogeneous traits among the individuals of the population under consideration, which may cause them to fail in handling the complexity and diversity of real-world data. Our proposed framework estimates epidemiological parameters based on the availability of contact network data and individual-level disease time series data. We use supervised as well as self-supervised GNN architectures to incorporate the contact network information into the model. We also employed graph reduction methods such as sampling and coarsening to study scaling behavior and computational efficiency. We formulated the parameter estimation in two ways to study the predictive behavior better: classification and inference problems. We experimentally confirm improvements over the baselines chosen in this article. We also conducted ablation studies, explainability quantification, and scalability experiments to generate further insights into the GNN models.}
}


@article{DBLP:journals/tkdd/JinZ25,
	author = {Yufei Jin and
                  Xingquan Zhu},
	title = {A Systematic Study and Analysis of Graph Neural Networks under Noise},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {6},
	pages = {1--20},
	year = {2025},
	url = {https://doi.org/10.1145/3733605},
	doi = {10.1145/3733605},
	timestamp = {Thu, 11 Sep 2025 20:24:53 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/JinZ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graph Neural Networks (GNNs) have shown superb performance in handling networked data, mainly attributed to their message passing and convolution process across neighbors. For most literature, the performance of GNNs is mainly reported based on noise-free data environments. No study has systematically evaluated GNNs’ performance under noise. In this article, we carry out an empirical study and theoretical analysis of four types of GNNs, including Graph Convolutional Networks (GCNs), Graph Attention Networks (GATs), Graph Contrastive Networks (GCL), and graph UniFilter under three types of noise, including attribute noise, structure noise, and label noise. Our study shows that GNNs behave tremendously differently in response to different types of noise. Overall, GAT is the most noise vulnerable and sensitive, whereas GCL is the most noise resilient. We further carry out theoretical analysis to explain the reason causing GAT to be sensitive to noise, and propose a solution to enhance its noise resilience. Our study brings in-depth firsthand knowledge of GNNs under noise for researchers and practitioners to better utilize GNNs in real-world applications.}
}


@article{DBLP:journals/tkdd/LiG25,
	author = {Shangyang Li and
                  Jiayan Guo},
	title = {Subgraph Federated Learning with Information Bottleneck Constrained
                  Generative Learning},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {6},
	pages = {1--23},
	year = {2025},
	url = {https://doi.org/10.1145/3737879},
	doi = {10.1145/3737879},
	timestamp = {Sat, 06 Sep 2025 20:29:30 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/LiG25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated Learning (FL) is a groundbreaking approach that enables multiple clients to jointly train deep learning models by pooling their data, while addressing privacy and bandwidth issues that prevent direct data sharing. This approach is particularly suitable for building strong and widely applicable graph models, given the increasing amounts of graph data stored across different locations. However, FL for subgraph models faces significant challenges, such as the diversity of data and the risk of attacks, which can affect the strength and reliability of these models. In response to these challenges, our research delves into the complexities of FL for subgraphs from an information theory perspective. We identify a major issue that affects the performance of graph models: the bias in the optimization goal of the commonly used FedAVG training method. To address this, we propose InfoFedGNN, an innovative FL framework for subgraphs that is based on the Information Bottleneck principle. InfoFedGNN is designed to overcome the problem of Non-Independent and Identically Distributed (non-i.i.d.) data in FL and to significantly improve its defense against security threats. Our thorough evaluation of InfoFedGNN on five public datasets, with both uniform and diverse data distributions, highlights its improved defense capabilities and better training outcomes. These results confirm the effectiveness of InfoFedGNN in enhancing the security and efficiency of FL, demonstrating its potential to push forward the development of federated graph models.}
}


@article{DBLP:journals/tkdd/SubagdjaST25,
	author = {Budhitama Subagdja and
                  D. Shanthoshigaa and
                  Ah{-}Hwee Tan},
	title = {DisambiguART: {A} Neural-based Inference Model for Knowledge Graph
                  Disambiguation},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {6},
	pages = {1--29},
	year = {2025},
	url = {https://doi.org/10.1145/3737880},
	doi = {10.1145/3737880},
	timestamp = {Thu, 11 Sep 2025 20:24:53 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/SubagdjaST25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {One main challenge in constructing a Knowledge Graph (KG) is to deal with ambiguity. Specifically, an entity in the graph can be assigned with multiple meanings while two or more entities considered to have different meanings may actually be the same. Assigning an entity with the correct meaning may involve re-evaluation of its relevant contexts. This costly operation typically involves searching for other similar entities within the KG such that the context can be determined. In this article, a new model called DisambiguART is proposed leveraging multi-channel matching and inference in a self-organizing neural network for sense disambiguation in KGs. Unlike other disambiguation methods that rely on representation learning to identify the relevant contexts whereby similarities among entities are learned, DisambiguART extends the working principle of multi-channel Adaptive Resonance Theory (ART) to conduct inferences directly over the graph representation through bi-directional interactions of bottom-up activations and top-down matching to find similar entities and select the correct meaning according to the right context. The proposed method is evaluated on the tasks of entity sense disambiguation in three domain KGs (jet engine, biomedical, and kinship) and author name disambiguation in bibliographic KGs, demonstrating the effectiveness and efficiency of DisambiguART against the state-of-the-art methods.}
}


@article{DBLP:journals/tkdd/HuangGY25,
	author = {Gengsen Huang and
                  Wensheng Gan and
                  Philip S. Yu},
	title = {Towards Sequence Utility Maximization under Utility Occupancy Measure},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {7},
	pages = {126:1--126:27},
	year = {2025},
	url = {https://doi.org/10.1145/3744344},
	doi = {10.1145/3744344},
	timestamp = {Thu, 11 Sep 2025 20:24:53 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/HuangGY25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The discovery of utility-driven patterns is a valuable and difficult research topic. It can extract significant and interesting information from specific and varied databases, increasing the value of the services provided. In practice, the utility measure is often used to reflect the importance, profit, or risk of an object or pattern. In the database, while utility is a flexible criterion for patterns, it is also a somewhat limited criterion due to the overlook of utility sharing. This leads to the derived patterns only exploring partial and local knowledge in the database. Utility occupancy considers the problem of mining with high utility but low occupancy. However, existing studies are focused on itemsets that cannot reveal the temporal relationship of object occurrences. Therefore, this article first defines the concept of utility occupancy of sequence data and raises the problem of High-Utility Occupancy Sequential Pattern Mining (HUOSPM). Three dimensions, including frequency, utility, and occupancy, are comprehensively evaluated in HUOSPM. An algorithm called Sequence Utility Maximization with Utility occupancy measure (SUMU) is proposed. Furthermore, two data structures for storing pattern-related information, including Utility-Occupancy-List-Chain (UOL-Chain) and Utility-Occupancy-Table (UO-Table), are designed, and six upper bounds are proposed to improve efficiency. Extensive experiments are conducted to evaluate the efficiency and effectiveness of the novel algorithm. A specific case study is provided, and the effects of different upper bounds and pruning strategies are analyzed. The comprehensive results suggest that the HUOSPM task is useful and efficient.}
}


@article{DBLP:journals/tkdd/ZhangXJZC25,
	author = {Shichao Zhang and
                  Penghui Xi and
                  Mengqi Jiang and
                  Guixian Zhang and
                  Debo Cheng},
	title = {Latent Representation Learning for Attributed Graph Anomaly Detection},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {7},
	pages = {127:1--127:22},
	year = {2025},
	url = {https://doi.org/10.1145/3733604},
	doi = {10.1145/3733604},
	timestamp = {Thu, 11 Sep 2025 20:24:53 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/ZhangXJZC25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Anomaly detection in attributed graph data has been widely applied in real applications. However, the intricate topology of graph data, high-dimensional attributes, and class imbalance inherent in anomaly detection tasks render attributed graph anomaly detection a challenging task. To detect anomalies using the intricate topology information of graph data, a dual-masked autoencoders is proposed for attributed graph anomaly detection, denoted as MAGAD. Specifically, in the MAGAD, the class imbalance in attributed graph data is dealt with by randomly masking the original graph data to obtain masked graph data for the anomaly detection task. And then, a latent representation of the graph data is obtained by training dual autoencoders, where one autoencoder is developed for reconstructing the original graph data, and another for reconstructing randomly masked graph data. This assists in identifying abnormal nodes in the attributed graph data. Subsequently, to capture anomalous information from relevant features, MAGAD uses a random re-masking strategy for latent representations learned from the masked graph. Finally, the anomaly scores of the nodes are calculated using the learned latent representations from the decoders of the dual autoencoders. Experimental results on five real-world datasets demonstrate that the MAGAD algorithm outperforms state-of-the-art anomaly detection algorithms.}
}


@article{DBLP:journals/tkdd/AlptekinBG25,
	author = {Ece Alptekin and
                  Berkay Kemal Balioglu and
                  Mehmet Emre Gursoy},
	title = {Hierarchical Spatial Decompositions under Local Differential Privacy},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {7},
	pages = {128:1--128:37},
	year = {2025},
	url = {https://doi.org/10.1145/3744569},
	doi = {10.1145/3744569},
	timestamp = {Thu, 11 Sep 2025 20:24:53 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/AlptekinBG25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The popularity of smartphones, GPS-enabled devices, social networks, and connected vehicles all contribute to the increasing volume of spatial data. Spatial decompositions assist in handling big spatial data, and they have been commonly used in the Differential Privacy (DP) literature for range query answering, spatial indexing, count-of-counts histograms, data summarization, and visualization. However, their applications under the emerging Local DP (LDP) notion are scarce. In this article, we study the problem of building hierarchical spatial decompositions under LDP, focusing on two methods: quadtrees and kd-trees. We develop two solutions for quadtrees: a baseline solution that is inspired by the centralized DP literature, and a proposed solution that utilizes a single data collection step from users, propagates density estimates to remaining nodes, and performs structural corrections to the quadtree. Since kd-trees rely on node medians which are data-dependent, we observe that it is not feasible to build kd-trees using a single data collection step. We therefore propose an iterative solution that constructs kd-trees in top-down fashion by utilizing a novel algorithm for estimating node medians at each tree depth. We experimentally evaluate our quadtree and kd-tree algorithms using four real-world spatial datasets, multiple utility metrics, varying privacy budgets, and tree parameters. Results demonstrate that our algorithms enable the building of accurate spatial decompositions that provide high utility in practice. Notably, our quadtrees and kd-trees achieve substantially lower errors in answering spatial density queries (up to 10-fold improvement) when compared with a state-of-the-art method.}
}


@article{DBLP:journals/tkdd/QianCCCZZ25,
	author = {Fulan Qian and
                  Wenbin Chen and
                  Hai Chen and
                  Yan Cui and
                  Shu Zhao and
                  Yanping Zhang},
	title = {Understanding the Robustness of Deep Recommendation under Adversarial
                  Attacks},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {7},
	pages = {129:1--129:46},
	year = {2025},
	url = {https://doi.org/10.1145/3744570},
	doi = {10.1145/3744570},
	timestamp = {Wed, 05 Nov 2025 15:01:28 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/QianCCCZZ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {It has been shown that deep recommendation models are susceptible to adversarial attacks, with this vulnerability potentially leading to significant economic losses in the e-commerce field. However, the robustness of deep recommendation models in response to adversarial attacks has not been systematically investigated. In this article, therefore, we comprehensively evaluate the adversarial robustness of various representative deep models in different settings, aiming to analyze their performance impact under adversarial attacks and compare it with traditional collaborative filtering models. Notably, we examine poisoning attacks under different proportions of fake users and various popularity conditions to understand why certain deep recommendation models perform exceptionally or sub-optimally. On this basis, we further proposed practical robustness improvement strategy for the problems found in the evaluation and fully verified it through rigorous experiments. Key findings include: (1) the sparser the training dataset, the weaker the robustness of a recommendation model’s performance under adversarial attacks; (2) deep recommendation models exhibit greater robustness in recommending popular items under adversarial attacks, while they are more vulnerable when attacked with non-popular items; (3) the robustness of deep recommendation models is not consistently weaker than that of traditional collaborative filtering models across all attack settings. These findings highlight the security concerns in deep recommendation systems and contribute to developing more reliable models.}
}


@article{DBLP:journals/tkdd/ZhouLLPFWZWZ25,
	author = {Jianping Zhou and
                  Bin Lu and
                  Zhanyu Liu and
                  Siyu Pan and
                  Xuejun Feng and
                  Hua Wei and
                  Guanjie Zheng and
                  Xinbing Wang and
                  Chenghu Zhou},
	title = {MagiNet: Mask-Aware Graph Imputation Network for Incomplete Traffic
                  Data},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {7},
	pages = {130:1--130:20},
	year = {2025},
	url = {https://doi.org/10.1145/3743141},
	doi = {10.1145/3743141},
	timestamp = {Thu, 11 Sep 2025 20:24:53 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/ZhouLLPFWZWZ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Due to detector malfunctions and communication failures, missing data is ubiquitous during the collection of traffic data. Therefore, it is of vital importance to impute the missing values to facilitate data analysis and decision-making for  Intelligent Transportation System (ITS) . However, existing imputation methods generally perform  zero  pre-filling techniques to initialize missing values, introducing inevitable noise. Moreover, we observe prevalent over-smoothed interpolations, falling short in revealing the intrinsic spatio-temporal correlations of incomplete traffic data. To this end, we propose  Mask-Aware Graph Imputation Network (MagiNet) . Our method designs an adaptive mask spatio-temporal encoder to learn the latent representations of incomplete data, eliminating the reliance on pre-filling missing values. Furthermore, we devise a spatio-temporal decoder that stacks multiple blocks to capture the inherent spatial and temporal dependencies within incomplete traffic data, alleviating over-smoothed imputation. Extensive experiments demonstrate that our method outperforms state-of-the-art imputation methods on five real-world traffic datasets, yielding an average improvement of 4.31% in RMSE and 3.72% in MAPE under  Missing Completely at Random (MCAR)  pattern. Code is available at  https://github.com/JeremyChou28/MagiNet .}
}


@article{DBLP:journals/tkdd/TaoXLTX25,
	author = {Zhen Tao and
                  Dinghao Xi and
                  Zhiyu Li and
                  Liumin Tang and
                  Wei Xu},
	title = {{CAT-LLM:} Style-enhanced Large Language Models with Text Style Definition
                  for Chinese Article-style Transfer},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {7},
	pages = {131:1--131:33},
	year = {2025},
	url = {https://doi.org/10.1145/3744250},
	doi = {10.1145/3744250},
	timestamp = {Thu, 11 Sep 2025 20:24:53 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/TaoXLTX25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Text style transfer plays a vital role in online entertainment and social media. However, existing models struggle to handle the complexity of Chinese long texts, such as rhetoric, structure, and culture, which restricts their broader application. To bridge this gap, we propose a Chinese Article-style Transfer (CAT-LLM) framework, which addresses the challenges of style transfer in complex Chinese long texts. At its core, CAT-LLM features a bespoke pluggable Text Style Definition (TSD) module that integrates machine learning algorithms to analyze and model article styles at both word and sentence levels. This module acts as a bridge, enabling large language models (LLMs) to better understand and adapt to the complexities of Chinese article styles. Furthermore, it supports the dynamic expansion of internal style trees, enabling the framework to seamlessly incorporate new and diverse style definitions, enhancing adaptability and scalability for future research and applications. Additionally, to facilitate robust evaluation, we created 10 parallel datasets using a combination of ChatGPT and various Chinese texts, each corresponding to distinct writing styles, significantly improving the accuracy of the model evaluation and establishing a novel paradigm for text style transfer research. Extensive experimental results demonstrate that CAT-LLM, combined with GPT-3.5-Turbo, achieves state-of-the-art performance, with a transfer accuracy F1 score of 79.36% and a content preservation F1 score of 96.47% on the “Fortress Besieged” dataset. These results highlight CAT-LLM’s innovative contributions to style transfer research, including its ability to preserve content integrity while achieving precise and flexible style transfer across diverse Chinese text domains. Building on these contributions, CAT-LLM presents significant potential for advancing Chinese digital media and facilitating automated content creation. Source code is available at GitHub ( https://github.com/TaoZhen1110/CAT-LLM ).}
}


@article{DBLP:journals/tkdd/ZongZLDZL25,
	author = {Haoran Zong and
                  Xiao Zhang and
                  Ruichen Li and
                  Jianhui Duan and
                  Derun Zou and
                  Wenzhong Li},
	title = {Convergence-Guaranteed Federated Learning through Gradient Trajectory
                  Smoothing with Triple-Objective Decomposition},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {7},
	pages = {132:1--132:31},
	year = {2025},
	url = {https://doi.org/10.1145/3743142},
	doi = {10.1145/3743142},
	timestamp = {Thu, 11 Sep 2025 20:24:53 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/ZongZLDZL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated Learning (FL) has been widely adopted as a distributed machine learning paradigm aiming to derive a global model without transferring local data to the server. In the context of heterogeneous environments typical of many FL deployments, our research has identified the performance oscillation problem in existing FL methods, resulting in slow convergence and severe performance drop. In this article, we first investigate the global optimizing objective in FL and demonstrate that, due to data heterogeneity and partial client participation, the global updates in a single training epoch may diverge from the intended objectives of conventional FL methods. To address this problem, we introduce a triple-objective decomposition mechanism to decompose the overarching global objective into three distinct local objectives aimed at aligning client gradients. Subsequently, we propose a gradient trajectory smoothing technique known as FedGTS, which refines local updates by estimating a pseudo-gradient leveraging historical global update trajectories. This approach is designed to mitigate performance oscillations and enhance the stability of the learning process. We theoretically demonstrate that our approach reduces variance of local updates and achieves a guaranteed convergence rate. We experimentally show that the proposed method outperforms the baselines with faster convergence and higher accuracy. Extensive experiments validate the effectiveness of the proposed approach across various heterogeneity settings. Our codes are publicly available at GitHub ( https://github.com/ZongHR/FedGTS ).}
}


@article{DBLP:journals/tkdd/ChenCWCH25,
	author = {Jian Chen and
                  Yile Chen and
                  Zeyi Wen and
                  Yawen Chen and
                  Jin Huang},
	title = {Towards Recommendation on Good Quality Data Science Solutions},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {7},
	pages = {133:1--133:19},
	year = {2025},
	url = {https://doi.org/10.1145/3746235},
	doi = {10.1145/3746235},
	timestamp = {Thu, 11 Sep 2025 20:24:53 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/ChenCWCH25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Data science aims to solve real-world problems with the knowledge derived from data. Successfully tackling a data science problem requires practitioners to choose an appropriate solution, which potentially comprises various components such as pre-processing techniques, learning algorithms, hyper-parameters, and so on. Therefore, a problem-driven recommendation for the promising solution is invaluable, as it facilitates efficient and convenient problem-solving. However, existing solution recommendation approaches confront notable challenges when dealing with limited and sparse prior experience in practical applications. Learning from such prior easily leads to overfitting and poor generalization in solution recommendations. To address this issue, we propose a novel solution recommendation method that can predict a good-quality data science solution, including the pre-processing, the learning algorithm, and hyper-parameters, for a given problem. The foundation of our method is a carefully designed ranking model that exploits a weight-sharing structure and a newly proposed loss. The ranking model focuses on incorporating relative ranking information into the predicted performance score of each solution. With these techniques, our method can recommend the solution with the highest score and effectively mitigate the limitations of using sparse prior experience. Our experiments demonstrate the superiority of our method in predicting solutions with higher accuracy and rank, even trained on highly sparse historical performance records. It also reduces recommendation time significantly compared to the baselines, offering remarkable efficiency and convenience for practitioners.}
}


@article{DBLP:journals/tkdd/SunWLTZQW25,
	author = {Haifeng Sun and
                  Yuanyi Wang and
                  Han Li and
                  Wei Tang and
                  Zirui Zhuang and
                  Qi Qi and
                  Jingyu Wang},
	title = {Understanding and Guiding Weakly Supervised Entity Alignment with
                  Potential Isomorphism Propagation},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {7},
	pages = {134:1--134:28},
	year = {2025},
	url = {https://doi.org/10.1145/3742436},
	doi = {10.1145/3742436},
	timestamp = {Thu, 11 Sep 2025 20:24:54 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/SunWLTZQW25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Weakly Supervised Entity Alignment (EA) is the task of identifying equivalent entities across diverse knowledge graphs (KGs) using only a limited number of seed alignments. Despite substantial advances in aggregation-based weakly supervised EA, the underlying mechanisms in this setting remain unexplored. In this article, we present a propagation perspective to analyze weakly supervised EA and explain the existing aggregation-based EA models. Our theoretical analysis reveals that these models essentially seek propagation operators for pairwise entity similarities. We further prove that, despite the structural heterogeneity across different KGs, the potentially aligned entities within aggregation-based EA models exhibit isomorphic subgraphs, a fundamental yet underexplored premise of EA. Leveraging this insight, we introduce a potential isomorphism propagation operator to enhance the propagation of neighborhood information across KGs. We develop a general EA framework, PipEA, incorporating this operator to improve the accuracy of every type of aggregation-based model without altering the learning process. Extensive experiments substantiate our theoretical findings and demonstrate PipEA’s significant performance gains over state-of-the-art weakly supervised EA methods. Our work advances the field and enhances our comprehension of aggregation-based weakly supervised EA.}
}


@article{DBLP:journals/tkdd/BuL25,
	author = {Xiya Bu and
                  Yu Liu},
	title = {Knowledge Graph Fine-grained Modeling Network with Contrastive Learning
                  for Recommendation},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {7},
	pages = {135:1--135:18},
	year = {2025},
	url = {https://doi.org/10.1145/3744926},
	doi = {10.1145/3744926},
	timestamp = {Thu, 11 Sep 2025 20:24:54 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/BuL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Knowledge graph (KG) is often introduced into recommendation systems because of its large amount of edge information. The method based on graph neural networks (GNNs) has gradually become the mainstream of KG-aware recommendation. However, traditional KG-aware recommendation models based on GNNs fail to utilize the dependencies of items and item attributes to model user preferences at a fine-grained level, which will result in a lack of interpretability in the model’s recommendations to users. In addition, traditional KG-aware recommendation models based on GNNs fail to mine supervision signals from the perspective of user preferences and item attributes, which will result in a lack of effective supervision signals in the model. In this study, we utilize a combination of items and attributes behind the items to model user preferences at a fine-grained level, so as to achieve independence between different user preferences. Furthermore, we utilize the KG and the user–item interaction graph (UIIG) to construct the user-specific preference similarity view and the item-specific attribute correlation views, respectively, and then apply the contrastive learning framework to effectively mine the association signals between users and between items. Based on this, we propose a novel model named Knowledge Graph Fine-grained Modeling Network with Contrastive Learning (KGFM-CL). Extensive experiments conducted on two real-world datasets demonstrate that KGFM-CL significantly outperforms state-of-the-art baseline models.}
}


@article{DBLP:journals/tkdd/ChinpattanakarnA25,
	author = {Naaek Chinpattanakarn and
                  Chainarong Amornbunchornvej},
	title = {Framework for Variable-Lag Motif Following Relation Inference in Time
                  Series Using Matrix Profile Analysis},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {7},
	pages = {136:1--136:24},
	year = {2025},
	url = {https://doi.org/10.1145/3744652},
	doi = {10.1145/3744652},
	timestamp = {Thu, 11 Sep 2025 20:24:54 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/ChinpattanakarnA25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Knowing who follows whom and what patterns they are following are crucial steps to understand collective behaviors (e.g., a group of human, a school of fish, or a stock market). Time series is one of the resources that can be used to get insight regarding following relations. However, the concept of following patterns or motifs and the solution to find them in time series are not obvious. In this work, we formalize a concept of following motifs between two time series and present a framework to infer following patterns between two time series. The framework utilizes one of the efficient and scalable methods to retrieve motifs from time series called the Matrix Profile Inference Method. We compare our proposed framework with several baselines. The framework performs better than baselines in the simulation datasets. In the dataset of sound recording, the framework is able to retrieve the following motifs within a pair of time series in which two singers sing following each other. In the cryptocurrency dataset, the framework is capable of capturing the following motifs within a pair of time series from two digital currencies, which implies that the values of one currency follow the values of another currency patterns. Our framework can be utilized in any field of time series to get insight regarding following patterns between time series. The code and datasets can be found at  https://github.com/hughnaaek/Following-Motif-Relation .}
}


@article{DBLP:journals/tkdd/LiDY25,
	author = {Bohao Li and
                  Bowen Du and
                  Junchen Ye},
	title = {{PRIME:} Pretraining for Patient Condition Representation with Irregular
                  Multimodal Electronic Health Records},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {7},
	pages = {137:1--137:39},
	year = {2025},
	url = {https://doi.org/10.1145/3744251},
	doi = {10.1145/3744251},
	timestamp = {Thu, 11 Sep 2025 20:24:54 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/LiDY25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the increasing collection of electronic health records (EHRs), deep learning has become a crucial tool for real-time treatment analysis. However, due to patient privacy concerns, the scarcity of labeled data limits the end-to-end models that rely on large training data. Self-supervised pretraining offers a promising solution. Nevertheless, applying pretraining to EHRs faces two key issues: (1) EHRs exhibit multimodality, including monitoring data and recorded clinical note. For multimodal pretraining, designing a self-supervised task that can establish cross-modal associations while preserving all modal-unique information remains challenging. (2) Both modalities are sequential and irregular, with varying intervals between monitoring or records. Aligning monitoring times with recorded times poses a significant issue for fine-grained cross-modal pretraining. Existing pretraining models either focus on a single modality or only models regular data, failing to address them together. To fill this gap and fully utilize unlabel EHR data, we propose a  p retraining model to learn patient  r epresentation using unlabel  i rregular  m ultimodal  E HRs, named PRIME. We first utilize a multi-element encoding module to extract patient condition snapshots from both modalities. Then, to construct multiple aligned cross-modal positive sample pairs that span the entire treatment process from irregular data, we employ patient condition alignment modules that integrate time-aware and feature-aware components to transfer snapshots to the aligned timestamps. Next, to preserve both shared and unique information of each modality, our decoupled representation learning strategy first uses a constraint matrix to separate shared information. We then employ contrastive-based cross-modal learning and reconstruction-based intra-modal learning to model shared and complete information, respectively. Extensive experiments on two real-world tasks demonstrate the superiority of PRIME over the state-of-the-art models, especially with limited labels.}
}


@article{DBLP:journals/tkdd/LiuZLZW25,
	author = {Huiting Liu and
                  Wei Zhang and
                  Pei{-}Pei Li and
                  Peng Zhao and
                  Xindong Wu},
	title = {Causal Meta-learning with Multi-view Graphs for Cold-start Recommendation},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {7},
	pages = {138:1--138:29},
	year = {2025},
	url = {https://doi.org/10.1145/3732943},
	doi = {10.1145/3732943},
	timestamp = {Thu, 11 Sep 2025 20:24:54 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/LiuZLZW25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Cold-start recommendation is a well-known problem in practical application scenarios. Generating reliable recommendations can be challenging when interactions are typically sparse. To mitigate the cold-start problem, some methods incorporate auxiliary information about users and items, and others adopt meta-learning to improve recommendation accuracy. However, these approaches overlook the fact that items are interdependent and likely to be related or similar. Moreover, user preference distributions in the meta-training and meta-testing phases are different in the cold-start scenario. To address these problems, we present a novel strategy called Causal Meta-learning with Multi-view Graphs (CausalMMG). Specifically, we first construct multi-view item-item graphs to explore the correlations and similarities between items from multiple perspectives. A\xa0multi-view item representer is then used to learn item representations, exploiting graph convolution neural networks to capture the structure of these different item–item graphs. We then resort to the structural causal models of causal inference and further develop a causality-enhanced bi-level adaptive meta-learner to eliminate bias caused by the different distributions of user preferences. Moreover, the meta-learner learns the user preferences for items in different orders through hierarchical and task-level adaptations. Finally, we evaluate CausalMMG on several real-world datasets, demonstrating its effectiveness in various scenarios. The results show that the proposed CausalMMG is significantly superior to competitive baseline methods for cold-start recommendation on all datasets, highlighting the importance of incorporating the multiple relationships between items and modeling different user preference distributions in recommender systems.}
}


@article{DBLP:journals/tkdd/ChakrabortyKL25,
	author = {Mohna Chakraborty and
                  Adithya Kulkarni and
                  Qi Li},
	title = {Weakly Supervised Open-Domain Aspect-Based Sentiment Analysis},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {7},
	pages = {139:1--139:29},
	year = {2025},
	url = {https://doi.org/10.1145/3747849},
	doi = {10.1145/3747849},
	timestamp = {Thu, 11 Sep 2025 20:24:54 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/ChakrabortyKL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Aspect-Based Sentiment Analysis (ABSA) comprises several subtasks: aspect term extraction (ATE), opinion term extraction (OTE), aspect term sentiment extraction (ATSE), aspect-opinion pair extraction (AOPE), and aspect sentiment triplet extraction (ASTE). Existing unified frameworks for ABSA rely heavily on large-scale annotated data, limiting scalability across domains. We propose UAOS, a double-layer unified span extraction framework that performs all five ABSA subtasks under weak supervision. Our approach first extracts aspect-opinion pairs using universal dependency-based rules from unannotated corpora. Sentiment labels for these pairs are generated via a novel zero-shot, domain-agnostic prompt-based method. The resulting weak labels train a unified span extraction architecture equipped with canonical correlation analysis for early stopping and a self-training mechanism to mitigate noise and bias in supervision. Extensive experiments on four ABSA benchmarks demonstrate that UAOS achieves competitive or superior performance compared to fully supervised baselines. It improves upon the state-of-the-art ODAO by +1.54 F1 for ATE, +0.56 for OTE, and +0.82 for AOPE. In ATSE and ASTE, where no weakly supervised baselines exist, UAOS outperforms several supervised models, setting new benchmarks. To assess domain generalizability, we evaluate UAOS on a psychology/education-domain dataset of student reflections spanning four instructional conditions. Without in-domain fine-tuning, it achieves macro F1 scores of 71.05 (ATE), 74.39 (OTE), 68.24 (AOPE), and 60.56 (ASTE). These results highlight the model’s ability to generalize to out-of-distribution, non-commercial text, underscoring its scalability for low-resource ABSA applications.}
}


@article{DBLP:journals/tkdd/YangCLWLGZ25,
	author = {Hanchen Yang and
                  Jiannong Cao and
                  Wengen Li and
                  Shuyu Wang and
                  Hui Li and
                  Jihong Guan and
                  Shuigeng Zhou},
	title = {Spatial-Temporal Data Mining for Ocean Science: Data, Methodologies
                  and Opportunities},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {7},
	pages = {140:1--140:47},
	year = {2025},
	url = {https://doi.org/10.1145/3748259},
	doi = {10.1145/3748259},
	timestamp = {Wed, 26 Nov 2025 13:34:43 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/YangCLWLGZ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {With the rapid amassing of  spatial-temporal  (ST) ocean data, many  spatial-temporal data mining  (STDM) studies have been conducted to address various oceanic issues, including climate forecasting and disaster warning. Compared with typical ST data (e.g., traffic data), ST ocean data presents some unique characteristics, e.g., diverse regionality and high sparsity. These characteristics make it difficult to design and train STDM models on ST ocean data. To the best of our knowledge, a comprehensive survey of existing studies remains missing in the literature, which hinders not only computer scientists from identifying the research issues in ocean data mining but also ocean scientists to apply advanced STDM techniques. In this article, we provide a comprehensive survey of existing STDM studies for ocean science. Concretely, we first review the widely used ST ocean datasets and highlight their unique characteristics. Then, typical ST ocean data quality enhancement techniques are discussed. Next, we classify existing STDM studies for ocean science into four types of tasks, i.e., prediction, event detection, pattern mining, and anomaly detection, and elaborate the techniques for these tasks. Finally, promising research opportunities are discussed. This survey can help scientists from both computer science and ocean science better understand the fundamental concepts, key techniques, and open challenges of STDM for ocean science.}
}


@article{DBLP:journals/tkdd/LiuLZLL25,
	author = {Hao Liu and
                  Dong Li and
                  Bing Zeng and
                  Wei Liang and
                  Dongjie Li},
	title = {Graph Self-attention Mechanism for Interpretable Multi-hop Knowledge
                  Graph Link Prediction},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {7},
	pages = {141:1--141:22},
	year = {2025},
	url = {https://doi.org/10.1145/3737702},
	doi = {10.1145/3737702},
	timestamp = {Sun, 26 Oct 2025 20:31:51 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/LiuLZLL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Knowledge Graphs (KGs) are extensively used in recommendation systems and information retrieval but often suffer from incompleteness. A popular solution to this problem is multi-hop inference through a reinforcement learning framework, which provides an interpretable path for predicting missing links in KGs. Most previous work focuses on improving the performance of multi-hop link prediction. However, it has been observed that many multi-hop paths generated by these methods are irrational; they often fail to reasonably explain the predicted answer entities. To address this challenge, we introduce the  Joint Multi-hop Link Prediction (JMLP)  framework. The framework consists of a relation attention network and an entity attention network, which collaboratively generate the reasoning paths. The relation attention module utilizes an induction network to encode historical paths and employs the graph self-attention mechanism to refine the interaction of relation contextual information. The entity attention module uses the graph attention mechanism to obtain the aggregated contextual features and leverages self-attention to strengthen the correlation between local and global contextual entity features. Extensive experiments on five datasets validate the effectiveness of our approach, demonstrating significant improvements both in predictive performance and interpretability compared to state-of-the-art methods.}
}


@article{DBLP:journals/tkdd/ZhaoAXQG25,
	author = {Xingyu Zhao and
                  Yuexuan An and
                  Ning Xu and
                  Lei Qi and
                  Xin Geng},
	title = {Interactive Fusion Label Enhancement for Multi-Label Learning},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {7},
	pages = {142:1--142:23},
	year = {2025},
	url = {https://doi.org/10.1145/3744571},
	doi = {10.1145/3744571},
	timestamp = {Thu, 11 Sep 2025 20:24:54 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/ZhaoAXQG25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Multi-Label Learning (MLL) involves the task of assigning a set of relevant labels to a given instance. Recently,  Label Enhancement  (LE) has gained significant attention in various MLL tasks, as it allows for effective mining the implicit relative importance information of different labels. However, in existing LE-based MLL methods, the LE process is decoupled from the MLL process. Consequently, the label distribution recovered by the LE process may not be suitable for training the predictive model, thus affecting the overall learning system. In this study, we propose a novel approach named  interactive Fusion Label Enhancement for Multi-Label Learning  ( Flem ) that seamlessly integrates the LE process with the MLL process. Specifically, we introduce a matching and interaction mechanism comprising a novel interaction label enhancement loss and a contrastive alignment approach to prevent object mismatch. Furthermore, we present a unified label distribution loss that establishes the relationship between the recovered label distribution and the training of the predictive model. By leveraging these losses, the label distributions obtained from the LE process can be efficiently utilized for training the predictive model. Experimental results on multiple benchmark datasets demonstrate the effectiveness of the proposed method.}
}


@article{DBLP:journals/tkdd/WangLSGZZ25,
	author = {Jiaqi Wang and
                  Wengen Li and
                  Yulou Shu and
                  Jihong Guan and
                  Yichao Zhang and
                  Shuigeng Zhou},
	title = {Raker: {A} Relation-Aware Knowledge Reasoning Model for Inductive
                  Relation Prediction},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {7},
	pages = {143:1--143:20},
	year = {2025},
	url = {https://doi.org/10.1145/3745029},
	doi = {10.1145/3745029},
	timestamp = {Thu, 11 Sep 2025 20:24:54 +0200},
	biburl = {https://dblp.org/rec/journals/tkdd/WangLSGZZ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Inductive relation prediction, an important task for knowledge graph completion, is to predict the relations between entities that are unseen at the training stage. The latest methods use Pre-Trained Language Models (PLMs) to encode the paths between the head entity and tail entity and achieve state-of-the-art prediction performance. However, these methods cannot handle no-path scenarios well and lack the capability to learn comprehensive relation representations for distinguishing different relations. To tackle this issue, we propose a novel  R elation- a ware  k nowledg e r easoning model entitled Raker, which introduces an adaptive reasoning information extraction method to identify relation-aware reasoning neighbors of entities in the target triple to handle no-path scenarios and enables the PLM to better distinguish different relations via the relation-specific soft prompting. Raker is evaluated on three public datasets and achieves SOTA performance in inductive relation prediction when compared with the baseline methods. Notably, the absolute improvement of Raker is even more than 5% on the FB15k-237 dataset in the inductive setting. Moreover, Raker also demonstrates the superiority in transductive, few-shot, and unseen relation settings. The code of Raker is available at  https://github.com/ADMIS-TONGJI/Raker .}
}


@article{DBLP:journals/tkdd/YerburyCJGO25,
	author = {Luke W. Yerbury and
                  Ricardo J. G. B. Campello and
                  G. C. Livingston Jr and
                  Mark Goldsworthy and
                  Lachlan O'Neil},
	title = {On the Use of Relative Validity Indices for Comparing Clustering Approaches},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {8},
	pages = {144:1--144:53},
	year = {2025},
	url = {https://doi.org/10.1145/3748726},
	doi = {10.1145/3748726},
	timestamp = {Sun, 09 Nov 2025 16:30:33 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/YerburyCJGO25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Relative Validity Indices (RVIs) such as the Silhouette Width Criterion, Calinski–Harabasz and Davies-Bouldin indices are the most widely used tools for evaluating and optimising clustering outcomes. Traditionally, their ability to rank collections of candidate dataset partitions has been used to guide the selection of the number of clusters and to compare partitions from different clustering algorithms. However, there is a growing trend in the literature to use RVIs when selecting a Similarity Paradigm (SP) for clustering—the combination of normalisation procedure, representation method and distance measure which affects the computation of object dissimilarities used in clustering. Despite the growing prevalence of this practice, there has been no empirical or theoretical investigation into the suitability of RVIs for this purpose. Moreover, since RVIs are computed using object dissimilarities, it remains unclear how they would need to be implemented for fair comparisons of different SPs. This study presents the first comprehensive investigation into the reliability of RVIs for SP selection. We conducted extensive experiments with seven popular RVIs on over 2.7 million clustering partitions of synthetic and real-world datasets, encompassing feature-vector and time-series data. We identified fundamental conceptual limitations undermining the use of RVIs for SP selection, and our empirical findings confirmed this predicted unsuitability. Among our recommendations, we suggest instead that practitioners select SPs by using external validation on high quality labelled datasets or carefully designed outcome-oriented objective criteria, both of which should be informed by careful consideration of dataset characteristics and domain requirements. Our findings have important implications for clustering methodology and evaluation, suggesting the need for more rigorous approaches to SP selection in clustering applications.}
}


@article{DBLP:journals/tkdd/JiangZXLWY25,
	author = {Lu Jiang and
                  Ruilou Zhang and
                  Yanan Xiao and
                  Kunpeng Liu and
                  Kaidi Wang and
                  Minghao Yin},
	title = {Understanding User Perspectives for {MOOC} Quality Evaluation with
                  Hypergraph Learning},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {8},
	pages = {145:1--145:19},
	year = {2025},
	url = {https://doi.org/10.1145/3749845},
	doi = {10.1145/3749845},
	timestamp = {Sun, 09 Nov 2025 16:30:33 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/JiangZXLWY25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Evaluation of Massive Open Online Course (MOOC) quality is crucial to enhance the educational resources, benefiting user services, and enhancing students’ learning efficiency. Despite achieving encouraging results, current efforts are hindered by complex relationships between entities and individual varies. To address the above problem, in this article, we frame the issue as a task of learning course representations and proceed to develop an  U ser-Centric  H ypergraph  R epresentation  L earning ( UHRL ) for online course quality evaluation. In particular, we initially construct a MOOC hypergraph to depict the interactions and connections between the entities and use cross-hyperedge alignment to reveal the semantics of courses. And then we incorporate an attention mechanism in the information transmission process to ensure semantic integrity. Furthermore, to tackle the bias of users’ preference, our framework exploits mutual information for preserving the fairness of representation learning. Finally, our comprehensive experiments on three real-world datasets confirm the effectiveness of our approach compared to cutting-edge methods in evaluating online course quality across various performance metrics.}
}


@article{DBLP:journals/tkdd/LiuMYJZZDWDV25,
	author = {Ji Liu and
                  Beichen Ma and
                  Qiaolin Yu and
                  Ruoming Jin and
                  Jingbo Zhou and
                  Yang Zhou and
                  Huaiyu Dai and
                  Haixun Wang and
                  Dejing Dou and
                  Patrick Valduriez},
	title = {Efficient Federated Learning with Heterogeneous Data and Adaptive
                  Dropout},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {8},
	pages = {146:1--146:31},
	year = {2025},
	url = {https://doi.org/10.1145/3749376},
	doi = {10.1145/3749376},
	timestamp = {Sun, 23 Nov 2025 13:29:58 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/LiuMYJZZDWDV25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Federated Learning (FL) is a promising distributed machine learning approach that enables collaborative training of a global model using multiple edge devices. The data distributed among the edge devices are highly heterogeneous. Thus, FL faces the challenge of data distribution and heterogeneity, where non-Independent and Identically Distributed (non-IID) data across edge devices may yield in significant accuracy drop. Furthermore, the limited computation and communication capabilities of edge devices increase the likelihood of stragglers, thus leading to slow model convergence. In this article, we propose the FedDHAD FL framework, which comes with two novel methods: dynamic heterogeneous model aggregation (FedDH) and adaptive dropout (FedAD). FedDH dynamically adjusts the weights of each local model within the model aggregation process based on the non-IID degree of heterogeneous data to deal with the statistical data heterogeneity. FedAD performs neuron-adaptive operations in response to heterogeneous devices to improve accuracy while achieving superb efficiency. The combination of these two methods makes FedDHAD significantly outperform state-of-the-art solutions in terms of accuracy (up to 6.7% higher), efficiency (up to 2.02 times faster), and computation cost (up to 15.0% smaller).}
}


@article{DBLP:journals/tkdd/ZhaoCZDPL25,
	author = {Jie Zhao and
                  Chao Chen and
                  Wanyi Zhang and
                  Mingyu Deng and
                  Huayan Pu and
                  Jun Luo},
	title = {{SE-GCL:} {A} Semantic-Enhanced Graph Contrastive Learning Framework
                  for Road Network Embedding},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {8},
	pages = {147:1--147:27},
	year = {2025},
	url = {https://doi.org/10.1145/3757921},
	doi = {10.1145/3757921},
	timestamp = {Sun, 09 Nov 2025 16:30:33 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/ZhaoCZDPL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Representation learning of road networks is essential for various downstream traffic-related tasks, as road network contain multi-modal data with rich information, and the learned embeddings can be directly used in machine learning models. However, due to the dynamic changes in road networks with respect to topology and associated data, as well as the local and long-range dependency caused by complex mobility semantics, learning robust and effective representations remains challenging. To this end, we exploit the properties of the road network and the mobility semantics embedded in trajectories, and propose a novel  S emantic- E nhanced  G raph  C ontrastive  L earning (SE-GCL) framework, for learning general-purpose embeddings of road networks. Specifically, in this framework, we propose (1) a multi-modal feature embedding module to capture both the attribute and visual information of road segments, (2) a semantic-enhanced graph augmentation strategy to simulate topological changes and data missing in the road network, and (3) a semantic-enhanced contrastive optimization module that leverages geo-locality and mobility semantics to guide representation learning. Extensive experiments are conducted on two real-world road networks with three representative downstream tasks. The result demonstrate that SE-GCL yields more robust and effective representations, outperforming the state-of-the-art baselines. The source code is available at  https://github.com/csjiezhao/SE-GCL .}
}


@article{DBLP:journals/tkdd/LiZHLWWX25,
	author = {Qian Li and
                  Wenhao Zhang and
                  Bojian Hu and
                  Tun Li and
                  Rong Wang and
                  Shihong Wei and
                  Yunpeng Xiao},
	title = {A Propagation Model of Derived Topic Based on Cognitive Accumulation
                  and Transfer Learning},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {8},
	pages = {148:1--148:24},
	year = {2025},
	url = {https://doi.org/10.1145/3747187},
	doi = {10.1145/3747187},
	timestamp = {Sun, 09 Nov 2025 16:30:33 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/LiZHLWWX25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The propagation of hot topics often gives rise to a series of derivative topics. In view of the sparsity of user behavior data and the cognitive accumulation of the original topic, a prediction model of derived topic propagation based on cognitive accumulation and transfer learning is proposed. First, for the complexity of the derived topic feature space, considering the relation and difference between derivative topics and original topics, this study designs I(Iterative)T(Topic)2vec, a topic iterative representation method based on original topics to get the low-dimensional representation of the derived topic feature space more richly from the perspectives of both original topics and derivative topics. Second, it aims at the problem of users’ cognitive accumulation of the original topic before the outbreak of derivative topic. The subjective game theory is introduced to construct the cognitive influence of users. At the same time, considering the timeliness of the propagation cycle of derivative topics, we discretized the derivative topic data, and further proposed a derivative topic propagation model based on Subjective Adapt-CNN (SA-CNN). Finally, the sparsity of effective behavior data of users at the beginning of the outbreak of derivative topics is discussed. Considering the rich user behavior data in the communication history of the original topic, data migration is carried out by using the original topic. At the same time, the domain adaptive method based on Transfer Component Analysis (TCA) is introduced to achieve feature adaptation from the original topic data to the derived topic data, further improving the accuracy of the derived topic propagation model. Experiments show that this model can not only effectively alleviate the problem of data sparsity but also perceive the propagation situation of derived topics well.}
}


@article{DBLP:journals/tkdd/ZhangSSWGY25,
	author = {Qi Zhang and
                  Mengmeng Si and
                  Yanfeng Sun and
                  Shaofan Wang and
                  Junbin Gao and
                  Baocai Yin},
	title = {GFformer: {A} Graph Transformer for Extracting All Frequency Information
                  from Large-scale Graphs},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {8},
	pages = {149:1--149:20},
	year = {2025},
	url = {https://doi.org/10.1145/3750051},
	doi = {10.1145/3750051},
	timestamp = {Mon, 10 Nov 2025 08:52:10 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/ZhangSSWGY25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graph Transformers have demonstrated outstanding performance across various graph-based applications. Despite their success, applying them to large-scale graphs presents significant scalability challenges, limiting their practical use in industrial environments. Recent studies have attempted to overcome this challenge by focusing on the spatial domain of graphs, leading to the development of various scalable models. However, these approaches neglect the spectral characteristics of graphs, which are crucial for adaptively extracting information from full-frequency bands based on the graph’s inherent properties. As a result, existing scalable Graph Transformers tend to rely heavily on low-frequency features, overlooking valuable mid- and high-frequency information. This article proposes the Graph Filter Transformer (GFformer), a framework designed to effectively extract full-frequency information from large-scale graphs. Unlike existing Graph Transformers, GFformer integrates graph filters into the Transformer architecture, thereby enhancing its ability to model both structural and frequency-related properties. Utilizing the proposed Spectral Token Converter (ST-converter), GFformer generates a unique spectral token sequence for each node by incorporating features from diverse frequencies that act as tokens. This design enables the independent learning of node representations in parallel and supports mini-batch training with flexible batch sizes, making GFformer highly scalable. ST-converter employs spectral graph filters, including low-, mid-, and high-pass filters, to extract features serving as tokens. Consequently, each sequence encompasses features from various frequencies, enabling GFformer to capture comprehensive frequency information effectively. Extensive experiments on datasets of varying scales, including both homophilic and heterophilic graphs, consistently demonstrate that GFformer outperforms existing representative methods.}
}


@article{DBLP:journals/tkdd/ZhuoWHHW25,
	author = {Shengda Zhuo and
                  Di Wu and
                  Yi He and
                  Shuqiang Huang and
                  Xindong Wu},
	title = {Online Learning from Mix-typed, Drifted, and Incomplete Streaming
                  Features},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {8},
	pages = {150:1--150:28},
	year = {2025},
	url = {https://doi.org/10.1145/3744712},
	doi = {10.1145/3744712},
	timestamp = {Sun, 09 Nov 2025 16:30:33 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/ZhuoWHHW25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Online learning, where feature spaces can change over time, offers a flexible learning paradigm that has attracted considerable attention. However, it still faces three significant challenges. First, the heterogeneity of real-world data streams with mixed feature types presents challenges for traditional parametric modeling. Second, data stream distributions can shift over time, causing an abrupt and substantial decline in model performance. Additionally, the time and cost constraints make it infeasible to label every data instance in a supervised setting. To overcome these challenges, we propose a new algorithm  Online Learning from Mix-typed, Drifted, and Incomplete Streaming Features  (OL-MDISF), which aims to relax restrictions on both feature types, data distribution, and supervision information. Our approach involves utilizing copula models to create a comprehensive latent space, employing an adaptive sliding window for detecting drift points to ensure model stability, and establishing label proximity information based on geometric structural relationships. To demonstrate the model’s efficiency and effectiveness, we provide theoretical analysis and comprehensive experimental results.}
}


@article{DBLP:journals/tkdd/ZhangYHYZ25,
	author = {Jingyuan Zhang and
                  Lei Yu and
                  Zhirong Huang and
                  Li Yang and
                  Fengjun Zhang},
	title = {Topology Augmented Multi-Band and Multi-Scale Filtering for Graph
                  Anomaly Detection},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {8},
	pages = {151:1--151:27},
	year = {2025},
	url = {https://doi.org/10.1145/3748727},
	doi = {10.1145/3748727},
	timestamp = {Sun, 09 Nov 2025 16:30:33 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/ZhangYHYZ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Graph Anomaly Detection (GAD) has gained significant attention in areas such as financial risk control and social network security, becoming a critical research problem. Vanilla Graph Neural Networks (GNNs), a popular method for graph modeling, are known to perform poorly in GAD due to the assumption of homophily preferences. This article argues that the issue lies in the insufficient feature extraction ability caused by their single filtering property (low-pass filtering) and revealing the effectiveness of multi-band filtering to deal with GAD. From this, we note two other overlooked issues: (1) How can multi-band band-pass filtering further fuse multi-scale neighborhood information? (2) Adaptation between raw attributes of nodes and graph filters (graph topology). The former bridges the respective advantages of spectral domain and spatial domain, and the latter is an important bottleneck for the encoding capacity of the filters. To address these, we propose a new GAD method, Graph Perturbed Networks (GraphPN). Each hidden layer of GraphPN is a band-pass filter, enabling multi-band and multi-scale filtering through simple stacking and skip connections. We analyze its spectral locality and spatial locality to provide theoretical support. Additionally, GraphPN is supplemented with a tailored feature activation module to complete the adaptation of the above two. This module readjusts node indices and decouples graph convolution, introducing rich topological information to node attributes. In addition to further enhancing detection performance, another possibly counter-intuitive effect is that the distinguishability of the two classes of nodes is improved even before filtering. The proposed method performs well in real-world datasets compared with the current state-of-the-art baselines, which fully demonstrates its superiority. Codes are available at  https://github.com/Thankstaro/GraphPN .}
}


@article{DBLP:journals/tkdd/LiZMHZ25,
	author = {Xuchao Li and
                  Peng Zhang and
                  Ru Ma and
                  Chenghang Huo and
                  Fuzhi Zhang},
	title = {Integrating Heterogeneous Graph Attention Network with Label Propagation
                  for Detecting Spammer Groups on E-Commerce Platforms},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {8},
	pages = {152:1--152:28},
	year = {2025},
	url = {https://doi.org/10.1145/3749846},
	doi = {10.1145/3749846},
	timestamp = {Sun, 09 Nov 2025 16:30:33 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/LiZMHZ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The collusive fraudulent behaviors on e-commerce platforms lead to proliferation of fraudulent reviews, which disrupt fair competition among merchants and mislead consumers’ shopping decisions. Detection of spammer groups helps purify the e-commerce environment and enhances consumers’ shopping experience. However, existing graph-based methods for detecting spammer groups first learn user node vector representations from the graph, and then use clustering methods to obtain candidate groups. Such separate two-stage detection methods are difficult to obtain high-quality candidate groups, resulting in suboptimal detection performance. Additionally, current graph construction methods used in spammer group detection do not fully consider the characteristics of spammer groups, which limits the detection performance. Aiming these concerns, we integrate heterogeneous graph attention network (HGAN) with label propagation (LP) for detecting spammer groups. First, we build a heterogeneous weighted directed (HWD) graph by analyzing the dataset and assign an initial label to each node. Then, we integrate a HGAN-module with an LP-module to obtain the HWD graph’s node embeddings and simultaneously generate candidate groups. We enhance the quality of embeddings and groups through the collaborative optimization between the predicted labels obtained from the HGAN-module and the pseudo-labels obtained from the LP-module. Finally, we calculate the suspiciousness values of groups using the reconstruction loss of the autoencoder for spammer group identification. Experiments conducted on real-world review datasets, including Amazon, Yelp, and YelpChi, demonstrate that our method achieves significant improvements in average Precision@k and Recall@k metrics compared with state-of-the-art baseline approaches.}
}


@article{DBLP:journals/tkdd/FuLXH25,
	author = {Ningning Fu and
                  Shengheng Liu and
                  Weiliang Xie and
                  Yongming Huang},
	title = {Multi-Grained Spatial-Temporal Feature Complementarity for Accurate
                  Online Cellular Traffic Prediction},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {8},
	pages = {153:1--153:27},
	year = {2025},
	url = {https://doi.org/10.1145/3758099},
	doi = {10.1145/3758099},
	timestamp = {Sun, 09 Nov 2025 16:30:33 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/FuLXH25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Knowledge discovered from telecom data can facilitate proactive understanding of network dynamics and user behaviors, which in turn empowers service providers to optimize cellular traffic scheduling and resource allocation. Nevertheless, the telecom industry still heavily relies on manual expert intervention. Existing studies have been focused on exhaustively exploring the spatial-temporal correlations. However, they often overlook the underlying characteristics of cellular traffic, which are shaped by the sporadic and bursty nature of telecom services. Additionally, concept drift creates substantial obstacles to maintaining satisfactory accuracy in continuous cellular forecasting tasks. To resolve these problems, we put forward an online cellular traffic prediction method grounded in Multi-Grained Spatial-Temporal feature Complementarity (MGSTC). The proposed method is devised to achieve high-precision predictions in practical continuous forecasting scenarios. Concretely, MGSTC segments historical data into chunks and employs the coarse-grained temporal attention to offer a trend reference for the prediction horizon. Subsequently, fine-grained spatial attention is utilized to capture detailed correlations among network elements, which enables localized refinement of the established trend. The complementarity of these multi-grained spatial-temporal features facilitates the efficient transmission of valuable information. To accommodate continuous forecasting needs, we implement an online learning strategy that can detect concept drift in real-time and promptly switch to the appropriate parameter update stage. Experiments carried out on four real-world datasets demonstrate that MGSTC outperforms eleven state-of-the-art baselines consistently.}
}


@article{DBLP:journals/tkdd/MaW25,
	author = {Fei Ma and
                  Ping Wang},
	title = {Growth Scale-Free Networks by Various Generative Ways},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {8},
	pages = {154:1--154:32},
	year = {2025},
	url = {https://doi.org/10.1145/3748512},
	doi = {10.1145/3748512},
	timestamp = {Sun, 09 Nov 2025 16:30:33 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/MaW25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In this article, the popularly discussed topic, i.e., how to construct available theoretical networked models that certainly capture some structural features popularly observed on realistic networks, is still our focus. Specifically, we first propose an evolving deterministic network  N ( t )  using three types of growth ways. Then, we study some topological structural parameters including degree distribution, diameter, and clustering coefficient on network  N ( t ) . The results demonstrate that the proposed network has scale-free feature and small-world property. In the meantime, we obtain an interesting finding, i.e., the first handshake between Fibonacci series and the “pure” preferential attachment mechanism. Next, we enumerate spanning trees on network  N ( t )  and derive the closed-form solution of spanning trees number. Second, we introduce randomness into the growth process of network  N ( t )  to further establish evolving stochastic networks  N ( t )  that follow the same degree distribution as network  N ( t )  and also determine some topological structural parameters so as to investigate effect of randomness on structural properties. We show analytically that such a randomization approach makes the resulting stochastic networks not only to greatly inherit some fundamental structural properties from deterministic network  N ( t )  but also to considerably improve the robustness of network when encountering deliberate removal of edge. Lastly, we list out some open problems.}
}


@article{DBLP:journals/tkdd/ShenYWLS25,
	author = {Xiaoxuan Shen and
                  Fenghua Yu and
                  Qian Wan and
                  Ruxia Liang and
                  Jianwen Sun},
	title = {Multi-level Contrastive Learning for Knowledge Tracing},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {8},
	pages = {155:1--155:29},
	year = {2025},
	url = {https://doi.org/10.1145/3759920},
	doi = {10.1145/3759920},
	timestamp = {Sun, 09 Nov 2025 16:30:33 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/ShenYWLS25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Knowledge Tracing (KT) is the task of predicting students’ future performance based on their past interactions with educational resources. A key aspect of KT is representation learning, which aims to capture meaningful features from students’ learning behaviors to improve prediction performance. Recently, contrastive learning methods have shown great promise in representation learning. As a result, KT models based on contrastive learning have been introduced to enhance representation learning for KT. However, these models have posed several challenges. Firstly, most of these models adopt the contrastive learning approach used in other fields, which involves data augmentation followed by contrastive learning, yet effectively applying data augmentation in KT remains an open challenge. Secondly, these models typically apply contrastive learning to only one of the fundamental components of KT: questions, interactions, or knowledge states, thereby limiting their overall performance. To address these issues, this article proposes a Multi-level Contrastive learning model for Knowledge Tracing (MCKT). MCKT (The code can be found at  https://github.com/lilstrawberry/MCKT .) does not rely on data augmentation strategies; instead, it deeply integrates domain knowledge and performs contrastive learning at three levels: questions, interactions, and knowledge states. Experimental results on four publicly available datasets, compared against a total of 20 state-of-the-art KT models, demonstrate that MCKT consistently outperforms other models. Subsequent experiments further validate the effectiveness of the multi-level contrastive learning approach.}
}


@article{DBLP:journals/tkdd/FitzpatrickJD25,
	author = {Padraig Fitzpatrick and
                  Anna Jurek{-}Loughrey and
                  Pawel Dlotko},
	title = {New Automated Approach to Selection of Mapper Clustering Parameters},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {8},
	pages = {156:1--156:36},
	year = {2025},
	url = {https://doi.org/10.1145/3746065},
	doi = {10.1145/3746065},
	timestamp = {Sun, 09 Nov 2025 16:30:33 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/FitzpatrickJD25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Topological methods have recently gained traction as powerful tools for extracting insights from high-dimensional data, forming the foundation of an approach known as Topological Data Analysis (TDA). Among the key developments in TDA is the Mapper algorithm, which constructs graph-based representations of complex datasets, capturing their topological structure at a user-defined resolution. The Mapper algorithm has shown promise across various applications, particularly in biomedical data analysis. However, its application requires careful selection of several parameters, especially the clustering algorithm and its settings. Without prior knowledge and a deep understanding of the data, these choices are non-trivial and can be a major barrier for researchers aiming to leverage Mapper effectively. In this work, we introduce enhancements to the Mapper algorithm to address this challenge. Specifically, we investigate the integration of ensemble learning (EL) techniques into Mapper’s graph construction to eliminate the need for arbitrary parameter selection. Additionally, we propose a data-driven criterion for selecting the clustering method best suited to the Mapper algorithm. Our experimental results demonstrate that the proposed approach enables the construction of Mapper graphs that accurately capture the underlying structure of the input data, all without manual parameter tuning.}
}


@article{DBLP:journals/tkdd/LazriDPBDHW25,
	author = {Zachary McBride Lazri and
                  Danial Dervovic and
                  Antigoni Polychroniadou and
                  Ivan Brugere and
                  Dana Dachman{-}Soled and
                  Furong Huang and
                  Min Wu},
	title = {Balancing Fairness and Accuracy in Data-Restricted Binary Classification},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {8},
	pages = {157:1--157:40},
	year = {2025},
	url = {https://doi.org/10.1145/3747850},
	doi = {10.1145/3747850},
	timestamp = {Sun, 09 Nov 2025 16:30:33 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/LazriDPBDHW25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Fair decision-making in Machine Learning (ML) remains a critical challenge, particularly when access to sensitive information is restricted due to legal, ethical, or organizational constraints. These limitations affect both accuracy and fairness, creating tradeoffs central to the deployment of ML systems in the real world. While prior work has studied fairness-accuracy tradeoffs, most approaches focus on model outputs rather than directly examining how restricted data access impacts fairness. This leaves an important gap:  understanding how fairness constraints affect model performance under real-world data restrictions . To address this gap, we propose a framework that explicitly models fairness-accuracy tradeoffs in data-restricted environments. Unlike prior work, our approach analyzes the behavior of the optimal Bayesian classifier using a discrete approximation of the data distribution, allowing us to systematically isolate the effects of fairness constraints. We evaluate our framework on three benchmark datasets—Adult, Law, and Dutch Census—revealing key insights: (1) enforcing equal accuracy on imbalanced datasets can substantially degrade performance under additional fairness constraints, (2) individual and group fairness often impose conflicting constraints, and (3) decorrelating sensitive attributes from features does not usually reduce accuracy. These findings demonstrate that our framework provides an effective, structured approach for practitioners to assess fairness constraints in decision-making pipelines.}
}


@article{DBLP:journals/tkdd/JianZQXXZL25,
	author = {Yue Jian and
                  Miao Zhang and
                  Ziyue Qin and
                  Chuyuan Xie and
                  Kui Xiao and
                  Yan Zhang and
                  Zhifei Li},
	title = {Adaptive Modality Interaction Transformer for Multimodal Knowledge
                  Graph Completion},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {8},
	pages = {158:1--158:24},
	year = {2025},
	url = {https://doi.org/10.1145/3760786},
	doi = {10.1145/3760786},
	timestamp = {Sun, 09 Nov 2025 16:30:33 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/JianZQXXZL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Knowledge graphs (KGs) are frequently confronted with the challenge of incompleteness, a problem that extends to multimodal knowledge graphs (MKGs). The primary goal of multimodal knowledge graph completion (MKGC) is to predict missing entities within MKGs. However, current MKGC methods face difficulties in adequately addressing modal preferences and imbalances in modal information. To overcome these issues, we introduce AdaMKGC, an innovative hybrid model incorporating an adaptive modality interaction transformer. This model employs a dynamic attention interaction strategy and a self-enhancing sampling approach. AdaMKGC achieves a more precise utilization of multimodal information by integrating modal preference information into modal interactions. Additionally, it effectively mitigates the issue of modal imbalance through targeted sampling and adjustment for entities with deficient information. Experimental evaluations demonstrate AdaMKGC’s superior performance in overcoming these prevalent challenges. Compared to existing state-of-the-art MKGC models, AdaMKGC shows a notable enhancement of 28% in MR on the WN18-IMG dataset and an improvement of 2.7% in Hits@1 on the FB15k-237-IMG dataset. Our code is available at  https://github.com/HubuKG/AdaMKGC .}
}


@article{DBLP:journals/tkdd/WangQWSZJLW25,
	author = {Chengsen Wang and
                  Qi Qi and
                  Jinming Wu and
                  Haifeng Sun and
                  Zirui Zhuang and
                  Yuhan Jing and
                  Lianyuan Li and
                  Jingyu Wang},
	title = {{MCAKE:} Memory-Augmented Autoencoder with Contrastive Learning for
                  Unsupervised Anomaly Detection},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {8},
	pages = {159:1--159:18},
	year = {2025},
	url = {https://doi.org/10.1145/3759460},
	doi = {10.1145/3759460},
	timestamp = {Sun, 09 Nov 2025 16:30:33 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/WangQWSZJLW25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recently, reconstruction-based deep models have gained widespread usage in unsupervised anomaly detection. However, they may overlook some anomalies owing to the over-generalization of neural networks. Several studies have incorporated memory networks to mitigate this problem. Nonetheless, some of them lack an explicit memory updating process, while others rely on data-driven updating methods that are sensitive to initial values and unsuitable for end-to-end training. Additionally, the traditional criterion for detection computed in the high-dimensional input space may collapse as the spike in the deviation score is averaged across numerous dimensions. To address these challenges, we propose MCAKE, a  M emory-augmented  C ontrastive  A utoencoder with  K NN-Based  E xtraction. It is designed to highlight the deviation score for anomalies by reconstructing input using fixed normal prototypes recorded in the memory. We explicitly encourage the memory to be autonomously learned and effectively allocated through contrastive learning with multiple positive and multiple negative samples. Furthermore, we introduce a bivariate detection criterion that calculates anomaly scores considering both input and latent space to tackle the collapse. Extensive experiments on 50 datasets across various categories demonstrate the superiority of our approach, with a 2% relative improvement over the previous state-of-the-art models.}
}


@article{DBLP:journals/tkdd/KouLWFG25,
	author = {Yannian Kou and
                  Qiuqiang Lin and
                  Yunhao Wen and
                  Di Fan and
                  Chuanhou Gao},
	title = {{ORIC} {V2:} Improved Feature Interaction Detection Model through
                  Online Random Interaction Chains for Click-Through Rate Prediction},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {8},
	pages = {160:1--160:26},
	year = {2025},
	url = {https://doi.org/10.1145/3762667},
	doi = {10.1145/3762667},
	timestamp = {Sun, 09 Nov 2025 16:30:33 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/KouLWFG25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Predicting the probability that a user clicks a specific item is fundamental in online advertising and recommendation. Further, it is crucial to use the latest and historical data appropriately in online scenarios to train CTR models. Online Random Interaction Chains (ORIC) was proposed to detect informative and interpretable feature interactions without retraining on historical data in online scenario, and the Streaming Integrated Model (SIM) framework was designed to integrate these time-varying feature interactions into CTR prediction models. Unfortunately, ORIC exhibits latency when provides the feature interactions used to evaluate SIM, and ORIC is not applicable for numerical features. For these reasons, we propose ORIC-V2 that uses time series models to predict the confidence of candidate evaluating feature interactions and selects reasonable feature interactions, and combines numerical features with ORIC-V2 through a discretization model to obtain DORIC-V2. Feeding the feature interactions found by ORIC-V2 and DORIC-V2 into SIM obtains significant experimental results on three datasets, demonstrating the effectiveness and interpretability of ORIC-V2 and DORIC-V2.}
}


@article{DBLP:journals/tkdd/TangWHZJ25,
	author = {Yingxia Tang and
                  Yanxuan Wei and
                  Yupeng Hu and
                  Xiangwei Zheng and
                  Cun Ji},
	title = {Convolutional Network Integrated with Frequency Adaptive Learning
                  for Multivariate Time Series Classification},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {8},
	pages = {161:1--161:23},
	year = {2025},
	url = {https://doi.org/10.1145/3761818},
	doi = {10.1145/3761818},
	timestamp = {Sun, 09 Nov 2025 16:30:33 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/TangWHZJ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Multivariate time series classification (MTSC) is a significant research topic in the realm of data mining, with broad applications in different industries, including healthcare, finance, meteorology, and traffic. While existing studies have designed many classifiers based on LSTMs, CNNs, and Transformer, the sophisticated architectures raise concerns regarding efficiency in computation. Additionally, most methods concentrate on a single dimension, typically temporal patterns, without fully considering multi-dimensional information such as the independence and interactions across variables that are essential in multivariate settings. To address these challenges, this article introduces FreConvNet, a lightweight convolutional network integrated with frequency adaptive learning. Inheriting the modular design paradigm of Transformer to achieve multi-view modeling of multivariate time series. FreConvNet consists of two key components: the frequency adaptive block (FAB) and the convolutional feed-forward network (ConvFFN). The FAB leverages the Fourier Transform in conjunction with adaptive filters to capture both long-term and short-term dependencies in the temporal dimension. Following that, ConvFFN captures cross-variable and cross-feature interactions by controlling inter-channel information flow through grouped pointwise convolutions, while introducing non-linearity to enhance representational capacity. Extensive experiments conducted on the well-known UEA archive validate that FreConvNet outperforms existing convolution-based, Transformer-based, and hybrid methods in classification performance and offers a computationally efficient solution.}
}


@article{DBLP:journals/tkdd/VillaizanValleladoSSA25a,
	author = {Mario Villaiz{\'{a}}n{-}Vallelado and
                  Matteo Salvatori and
                  Carlos Segura and
                  Ioannis Arapakis},
	title = {Corrigendum: Diffusion Models for Tabular Data Imputation and Synthetic
                  Data Generation},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {8},
	pages = {C1:1},
	year = {2025},
	url = {https://doi.org/10.1145/3761939},
	doi = {10.1145/3761939},
	timestamp = {Sun, 09 Nov 2025 16:30:33 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/VillaizanValleladoSSA25a.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {This is a corrigendum for the article “Diffusion Models for Tabular Data Imputation and Synthetic Data Generation” published in ACM Trans. Knowl. Discov. Data 19(6): 125:1-125:32 (2025).}
}


@article{DBLP:journals/tkdd/BerahmandMSJNK25,
	author = {Kamal Berahmand and
                  Mehrnoush Mohammadi and
                  Razieh Sheikhpour and
                  Mahdi Jalili and
                  Richi Nayak and
                  Hassan Khosravi},
	title = {Relative Entropy-based Regularized Non-negative Matrix Factorization
                  for Attributed Graph Clustering},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {9},
	pages = {162:1--162:28},
	year = {2025},
	url = {https://doi.org/10.1145/3765742},
	doi = {10.1145/3765742},
	timestamp = {Sun, 01 Feb 2026 13:44:09 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/BerahmandMSJNK25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Attributed graph clustering is a fundamental task in network mining, essential for uncovering valuable insights in various applications. However, the heterogeneity of information from structural and attribute spaces poses significant challenges in achieving consistent and meaningful clustering. To address this, we propose Relative Entropy-based Regularized Non-negative Matrix Factorization (RENMF), a novel approach that integrates structural and attribute information through advanced matrix factorization techniques. RENMF employs Symmetric NMF and Projective NMF to extract community membership distributions from the structural and attribute spaces, respectively. By treating these distributions as homogeneous, RENMF preserves distinct, denoised information from both spaces while considering their heterogeneous complementary information. We introduce Relative Entropy (RE) as a novel regularization term to facilitate interaction between these spaces, aiming to maximize consistency between the discovered latent distributions. In this interaction, we leverage the asymmetric property of RE to emphasize attributes as essential complementary information for structural clustering. The RENMF model is solved using a new iterative multiplicative update rule, with convergence theoretically proven. We evaluate RENMF’s effectiveness through extensive experiments on 10 real-world networks, comparing it to 11 state-of-the-art clustering methods. The results demonstrate RENMF’s superiority in ground truth matching and key quality metrics, outperforming existing methods.}
}


@article{DBLP:journals/tkdd/XiongSZ25,
	author = {Guangzhi Xiong and
                  Sanchit Sinha and
                  Aidong Zhang},
	title = {ProtoNAM: Prototypical Neural Additive Models for Interpretable Deep
                  Tabular Learning},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {9},
	pages = {163:1--163:25},
	year = {2025},
	url = {https://doi.org/10.1145/3766072},
	doi = {10.1145/3766072},
	timestamp = {Sun, 01 Feb 2026 13:44:10 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/XiongSZ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Generalized Additive Models (GAMs) have long been a powerful white-box tool for the intelligible analysis of tabular data, revealing the influence of each feature on the model predictions. Despite the success of Neural Networks (NNs) in various domains, their application as NN-based GAMs in tabular data analysis remains suboptimal compared to tree-based ones, and the opacity of encoders in NN-GAMs also prevents users from understanding how networks learn the functions. In this work, we propose a new deep tabular learning method, termed Prototypical Neural Additive Model (ProtoNAM), which introduces prototypes into NNs in the framework of GAMs. With the introduced prototype-based feature activation, ProtoNAM can flexibly model the irregular mapping from tabular features to the outputs while maintaining the explainability of the final prediction. We also propose a gradient-boosting inspired hierarchical shape function modeling method, facilitating the discovery of complex feature patterns and bringing transparency into the learning process of each network layer. Our empirical evaluations demonstrate that ProtoNAM outperforms all existing NN-based GAMs, while providing additional insights into the shape function learned for each feature. The source code of ProtoNAM is available at  https://github.com/Teddy-XiongGZ/ProtoNAM .}
}


@article{DBLP:journals/tkdd/KongSWSX25,
	author = {Xiangjie Kong and
                  Siyue Shuai and
                  Hui Wang and
                  Guojiang Shen and
                  Feng Xia},
	title = {Dual-View Anomaly Detection in Heterogeneous Information Networks
                  with Hierarchical Neighborhood Fusion},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {9},
	pages = {164:1--164:24},
	year = {2025},
	url = {https://doi.org/10.1145/3767156},
	doi = {10.1145/3767156},
	timestamp = {Sun, 01 Feb 2026 13:44:09 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/KongSWSX25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The primary objective of graph node anomaly detection is to pinpoint rare patterns that display marked deviations from the typical one. Existing methods utilize Graph Convolutional Networks (GCNs) to model complex interactions in Heterogeneous Information Networks (HINs), typically homogenizing HINs using meta-paths to effectively focus on particular semantic scenarios. However, meta-paths excessively emphasize specific nodes and their connections on predefined paths, leading to the neglect of one-hop context-rich neighbors. Furthermore, the conversion from heterogeneous to homogeneous structures disrupts inherent relationships, resulting in an irreversible loss of direct links. Thus, we propose a dual-view-based  H eterogeneous  I nformation  N etworks Node  Ano maly Detection framework, HINAno, to mitigate structural loss. HINAno adopts a synergetic approach that balances local structural information with semantic richness, drawing from both the one-hop neighbor view and the meta-path view. Specifically, this dual-view utilizes hierarchical fusion mechanisms at node, type, and semantic levels to capture one-hop and multi-hop neighborhoods in a level-wise manner. In addition, HINAno adopts self-supervised contrastive learning and GCNs to amplify the gap between normal and abnormal nodes, thereby reducing the reliance on anomalous labels and enhancing the capability of anomaly detection. Finally, we successfully verify that the HINAno framework is effective and superior on four real-world datasets.}
}


@article{DBLP:journals/tkdd/TuMLZHSW25,
	author = {Cheng Tu and
                  Yunshan Ma and
                  Yang Li and
                  Min Zhang and
                  Miao Hu and
                  Fan Shi and
                  Xiang Wang},
	title = {Website Owner Identification through Multi-level Contrastive Representation
                  Learning},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {9},
	pages = {165:1--165:39},
	year = {2025},
	url = {https://doi.org/10.1145/3767155},
	doi = {10.1145/3767155},
	timestamp = {Sun, 01 Feb 2026 13:44:10 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/TuMLZHSW25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Website owner identification aims to recognize the organization or individual who owns a given website that is served on the web. It is a crucial step for cyberspace surveying and mapping, playing a significant role in cyberspace administration and governance. Existing widely employed solutions for website owner identification mainly fall into two paradigms: (1) querying the public information databases such as WHOIS, which store the Internet resource’s registered users or assignees; and (2) directly extracting the organization or individual name of the website owner from the webpage using the technique of named entity recognition. However, the former is less reliable due to the incomplete, encrypted, and outdated records in the public information databases. Meanwhile, the latter requires that the webpages explicitly and precisely present their owner names without ambiguity, which is often hard to guarantee in practice. To address these limitations, we propose to formulate website owner identification as a problem of webpage representation learning, thereby introducing a novel representation learning framework empowered by large language model-based text Rewriting and Multi-level contrastive learning, named ReMon. First, we devise a prompt to rewrite the webpages using large language models, which effectively filters out noise from the original webpages. Second, we model website–website, website–owner, and owner–owner interactions through multi-level contrastive learning, fully utilizing the self-supervision signals on long-tail items to learn the multi-level constraints. Third, we design a retrieval-based prediction framework and a clustering-based framework to apply websites’ and owners’ representations for different scenarios of the website owner identification task. To evaluate ReMon under our formulation, we construct two datasets based on real-world data. Compared to existing approaches, our ReMon can address the challenging scenarios when valid information cannot be found in public information databases and the owner’s name does not appear on the webpage. Meanwhile, the experimental results show that ReMon outperforms all representation learning-based baselines and significantly enhances training efficiency. The code is available at  https://github.com/tuchen9/ReMon .}
}


@article{DBLP:journals/tkdd/JianLLYWW25,
	author = {Meng Jian and
                  Ruoxi Li and
                  Meishan Liu and
                  Meijuan Yang and
                  Shaona Wang and
                  Lifang Wu},
	title = {Interest-Disentangled Contrastive Sample Generation for Recommendation},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {9},
	pages = {166:1--166:20},
	year = {2025},
	url = {https://doi.org/10.1145/3768160},
	doi = {10.1145/3768160},
	timestamp = {Sun, 01 Feb 2026 13:44:09 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/JianLLYWW25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In the domain of recommendations, previous works often retrieve items through sampling strategies from the database to gather negative signals for exploring implicit feedback. However, because of extremely sparse records, the existing items used as negative samples may not sufficiently support the interacted items in depicting the diverse interests of users. Consequently, the generation of negative samples needs to be explored in recommendation systems. In this study, we propose an interest-disentangled contrastive sample generation (IDCG) model to enhance interest modeling by contrasting interacted items with the generated samples for recommendation. Specifically, we decouple the interacted items of users into positively relevant and irrelevant factors of interest, providing a valuable clue to learn negatively relevant factors in personalized interests. Then, negative samples are generated by merging the learned negatively relevant factors and irrelevant factors. At this point, a two-level contrast is constructed between positive and negative samples and between the relevant factors of positives and negatives, providing auxiliary collaborative signals to debias and alleviate the interaction sparsity issue. Extensive experiments on three real datasets demonstrate the effectiveness of IDCG in generating targeted and meaningful negative samples from the perspective of disentangling relevant factors to promote interest modeling for recommendation.}
}


@article{DBLP:journals/tkdd/WangWWJX25,
	author = {Rong Wang and
                  Zerui Wu and
                  Liangyu Wang and
                  Chaolong Jia and
                  Yunpeng Xiao},
	title = {A Rumor Propagation Model Based on User Cognition and Evolutionary
                  Game},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {9},
	pages = {167:1--167:33},
	year = {2025},
	url = {https://doi.org/10.1145/3767161},
	doi = {10.1145/3767161},
	timestamp = {Sun, 01 Feb 2026 13:44:10 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/WangWWJX25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In social networks, studying rumor propagation patterns is essential for curbing the spread of rumors. Given the coexistence and conflict of multiple-type rumor information, as well as users’ cognitive differences, this article presents a rumor propagation model grounded in user cognition and evolutionary game theory. First, considering the potential impact of social relationships between users on rumor propagation, the KD-Tree algorithm is employed to uncover hidden connections between users, thereby enriching the topology of the user’s social network. Second, a user behavior driving mechanism for rumor, anti-rumor, and motivation-rumor types is constructed based on evolutionary games to reflect the interactive and strategic nature of users’ responses. Moreover, the Lotka-Volterra equation is utilized to explore the dynamic game of multi-type rumor information and the cognitive process of users. Finally, to address differences in users’ cognition, this article introduces the anti-rumor trust state  A  and the motivation-rumor trust state  M , which arise from users’ exposure to multiple types of rumor information. Based on these trust states, a rumor propagation model, SIAMR, is constructed using user cognition and evolutionary game theory. Experiments demonstrate that the model accurately captures the dynamic interactions between multi-type rumor information and the transmission process of rumor topics in social networks. The proposed model integrates cognitive psychology with a strategic interaction framework, offering a more realistic representation of rumor propagation behavior in the real world. Experimental results reveal that SIAMR improves prediction accuracy by 14.23% over baseline models in simulating the dynamics of multiple types of rumors, effectively capturing users’ cognitive influences and the mechanisms of information competition.}
}


@article{DBLP:journals/tkdd/YangCLYLKZGZ25,
	author = {Hanchen Yang and
                  Jiannong Cao and
                  Wengen Li and
                  Yu Yang and
                  Xiaoyi Li and
                  Lingbai Kong and
                  Yichao Zhang and
                  Jihong Guan and
                  Shuigeng Zhou},
	title = {Towards Robust and Interpretable Spatial-Temporal Graph Modeling for
                  Traffic Prediction},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {9},
	pages = {168:1--168:20},
	year = {2025},
	url = {https://doi.org/10.1145/3769297},
	doi = {10.1145/3769297},
	timestamp = {Sun, 01 Feb 2026 13:44:10 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/YangCLYLKZGZ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Accurate spatial-temporal (ST) traffic prediction plays an essential role in intelligent transportation systems. Existing advanced traffic prediction methods typically utilize spatial-temporal graph neural networks (STGNNs) to capture the ST correlations and achieve excellent prediction performance. However, our experimental investigation reveals that existing static and dynamic graph-based STGNNs still incur excessive noise and redundancy, and fail to discover robust and reliable ST correlations in traffic networks. Moreover, most methods cannot explain the underlying reasons behind the ST correlations. To solve these problems, we propose a novel  S patial- T emporal  G raph  M odeling framework via  A daptive contrastive learning (ST-GMA). Firstly, we design a robust augmentation learning module to generate high-level and robust data augmentations via a self-supervised task for modeling reliable correlations. Then, we develop an adaptive contrastive learning module to update correlation graphs by effectively selecting positive and negative augmentations, reducing redundant calculations, and providing insights into the correlation changes. Finally, ST-GMA integrates the generated correlation graphs with ST convolution blocks to conduct traffic prediction tasks. Experimental results on five real-world datasets demonstrate that ST-GMA not only achieves significant prediction performance compared with state-of-the-art methods but also exhibits a new perspective on the interpretability of correlation changes.}
}


@article{DBLP:journals/tkdd/GongLL25,
	author = {Fang Gong and
                  Tao Lu and
                  Kuayue Liu},
	title = {Hidden Inverted Specific-Class Distance Measure for Nominal Attributes},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {9},
	pages = {169:1--169:17},
	year = {2025},
	url = {https://doi.org/10.1145/3769293},
	doi = {10.1145/3769293},
	timestamp = {Sun, 01 Feb 2026 13:44:09 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/GongLL25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The inverted specific-class distance measure (ISCDM) is a popular distance metric that uses conditional probability term to calculate the distance between two nominal attribute values, but the reliability of the conditional probability term is limited by the attribute independence assumption, which leads to the suboptimal performance in applications involving sophisticated attribute dependencies. To obtain more accurate conditional probability estimation, in this study, we derive an enhanced ISCDM by leveraging structure extension to alleviate the unrealistic attribute assumption. We denominate the resulting model as the hidden inverted specific-class distance measure (HISCDM). In HISCDM, the structure extension scheme of hidden naive bayes is adopted to find the weighted dependence relationships between attributes, and then is incorporated into the conditional probability estimation. The comprehensive experimental results demonstrate that our proposed HISCDM significantly outperforms all other methods used for comparison in terms of classification accuracy.}
}


@article{DBLP:journals/tkdd/YangXYZZ25,
	author = {Jinjing Yang and
                  Shaohua Xu and
                  Zebin Yang and
                  Aijun Zhang and
                  Yong{-}Dao Zhou},
	title = {Stable Subsampling under Model Misspecification and Covariate Shift},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {9},
	pages = {170:1--170:26},
	year = {2025},
	url = {https://doi.org/10.1145/3769077},
	doi = {10.1145/3769077},
	timestamp = {Sun, 01 Feb 2026 13:44:10 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/YangXYZZ25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {The presence of covariate shift between training and test datasets, coupled with model misspecification, can lead to instability in regression predictions across diverse datasets. Meanwhile, training complex models with massive data imposes significant computational burden. In this article, we present a novel model-free subsampling algorithm for stable prediction, which employs uniform design and confounder balancing methods. Our subsampling algorithm aims to find the nearest neighbor subsampling points of uniform design with the goal of minimizing global stability loss, thereby reducing the data volume while achieving stable predictions. Theoretic analyses show that the uniform measure minimizes the maximum integrated mean square error (MIMSE) and the global stability loss evaluates the independence among variables in each candidate MIMSE-optimal subsampled sets. Simulation studies conducted on synthetic datasets, as well as applications on real datasets, demonstrate the superiority of our proposed method under model misspecification and covariate shift.}
}


@article{DBLP:journals/tkdd/XieGG25,
	author = {Tianyang Xie and
                  Yong Ge and
                  Shuojia Guo},
	title = {Accuracy, Fairness, Diversity All at Once: An Influence-Function-Guided
                  Data Enhancement Approach for Recommender System},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {9},
	pages = {171:1--171:27},
	year = {2025},
	url = {https://doi.org/10.1145/3768316},
	doi = {10.1145/3768316},
	timestamp = {Sun, 01 Feb 2026 13:44:10 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/XieGG25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Recommender systems play a pivotal role in curating high-quality content for users, predominantly leveraging data-driven algorithms and machine learning methodologies. However, the intrinsic data-centric nature of these systems raises critical concerns; biased datasets and algorithms can inadvertently propagate biases to end-users. Furthermore, machine learning techniques, while powerful, can overfit a user’s preference, leading to a monotonous stream of content suggestions. Both the CS and IS community have well-recognized the need of fairness and diversity in recommender systems and many studies are proposed to mitigate these challenges. Yet, a tangible solution that holistically addressed all three components—accuracy, fairness, and diversity—in unison remains elusive. This article aims to bridge this gap, introducing a novel Influence-Function-Guided, Fair, and Diverse Data Enhancement (InFoDance) approach that enhances all three perspectives simultaneously. It consists of four interconnected modules: model training, candidate data generation, influence function-based candidate evaluation, and virtual data selection. It iteratively generates virtual data to update the trained recommender system. The empirical evaluation has shown that our approach can improve accuracy, fairness, and diversity by up to 24.27%, 55.29%, and 1.85% simultaneously and significantly outperform the state-of-the-art baselines on multiple evaluation metrics.}
}


@article{DBLP:journals/tkdd/ZuinV25,
	author = {Gianlucca L. Zuin and
                  Adriano Veloso},
	title = {"A 6 or a 9?": Ensemble Learning through the Multiplicity
                  of Performant Models and Explanations},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {9},
	pages = {172:1--172:39},
	year = {2025},
	url = {https://doi.org/10.1145/3767735},
	doi = {10.1145/3767735},
	timestamp = {Sun, 01 Feb 2026 13:44:10 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/ZuinV25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Creating models from past observations and ensuring their effectiveness on new data is the essence of machine learning. However, selecting models that generalize well remains a challenging task. Related to this topic, the Rashomon Effect refers to cases where multiple models perform similarly well for a given learning problem. This often occurs in real-world scenarios, like the manufacturing process or medical diagnosis, where diverse patterns in data lead to multiple high-performing solutions. We propose the Rashomon Ensemble, a method that strategically selects models from these diverse high-performing solutions to improve generalization. By grouping models based on both their performance and explanations, we construct ensembles that maximize diversity while maintaining predictive accuracy. This selection ensures that each model covers a distinct region of the solution space, making the ensemble more robust to distribution shifts and variations in unseen data. We validate our approach on both open and proprietary collaborative real-world datasets, demonstrating up to 0.20+ AUROC improvements in scenarios where the Rashomon ratio is large. Additionally, we demonstrate tangible benefits for businesses in various real-world applications, highlighting the robustness, practicality, and effectiveness of our approach.}
}


@article{DBLP:journals/tkdd/MoorthyPVP25,
	author = {Adithya K. Moorthy and
                  Jaya Teja Reddy Pochimireddy and
                  Vijaya Saradhi Vedula and
                  Bhanu Prasad},
	title = {Towards Fair Decision Boundaries in Clustering: Integrating Disparate
                  Impact Criteria into Maximum Margin Clustering},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {9},
	pages = {173:1--173:24},
	year = {2025},
	url = {https://doi.org/10.1145/3770078},
	doi = {10.1145/3770078},
	timestamp = {Sun, 01 Feb 2026 13:44:09 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/MoorthyPVP25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {Extensive application of machine learning in the areas that impact human lives has significantly spurred considerable interest in developing algorithms that are demonstrably fair. Recent efforts in this field have led to the creation of numerous algorithms addressing the paradigm of clustering with fairness constraints. In this research, we adopt disparate impact criteria from supervised learning scenarios and incorporate it into clustering by specifically focusing on decision boundary fairness. The existing fairness definitions in clustering scenarios mostly deal with Balance of the clusters or the representation of sensitive groups in the clusters. We developed a new algorithm called Fair Maximum Margin Clustering (FMMC), by incorporating the disparate impact criteria into the Maximum Margin Clustering (MMC) algorithm. The FMMC algorithm ensures that the distance of each data point from hyperplane is uncorrelated with that data point’s sensitive attribute value. This constraint is designed to prevent any sensitive group from being negatively impacted by the decision boundary. We show that the performance of the FMMC algorithm is better than that of MMC algorithm in terms of traditional fairness measures such as Balance. We also demonstrate that the FMMC algorithm achieves fair clustering while maintaining the clustering performance of the original MMC algorithm. We validate the effectiveness of our approach through experiments on synthetic and real-world datasets.}
}


@article{DBLP:journals/tkdd/ChenJLWWT25,
	author = {Guobang Chen and
                  Wenjun Jiang and
                  Kenli Li and
                  Jingjing Wang and
                  Jie Wu and
                  Kian{-}Lee Tan},
	title = {Integrating Group Consensus for Competitive Influence Maximization
                  in OSNs},
	journal = {{ACM} Trans. Knowl. Discov. Data},
	volume = {19},
	number = {9},
	pages = {174:1--174:38},
	year = {2025},
	url = {https://doi.org/10.1145/3768583},
	doi = {10.1145/3768583},
	timestamp = {Sun, 01 Feb 2026 13:44:09 +0100},
	biburl = {https://dblp.org/rec/journals/tkdd/ChenJLWWT25.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	abstract = {In online social networks (OSNs), people usually join groups for communication. Information diffusion often occurs with some cost, either between individuals or within/among groups; and different opinions may compete with each other. The groups can make decisions based on the majority of the group members. This type of group consensus is common in group activities. However, existing research on maximization of competitive influence often neglects the effects of group consensus. To this end, we introduce the process of group consensus reaching in influence maximization and propose a novel Group consensus-based Competitive Linear Threshold (GCLT) propagation model; then we study the Budgeted Competitive Influence Maximization (BCIM) problem under the GCLT model. We reveal that the problem is NP-hard, and the objective function is proven to be neither submodular nor supermodular. To this end, we construct an equivalent Group consensus-based Competitive Live-Edge (GCLE) model of GCLT by sampling method. Based on GCLE, develop two submodular functions of the upper and lower bounds. Then, we propose the  SBG  algorithm by applying the Sandwich Approximation framework for the BCIM problem under the GCLT model. In  SBG , we provide an approximate solution to the lower bound and the upper bound by the proposed  OPIM-B  algorithm. Then, we select the seed set of solutions that achieves the best influence spread in Monte Carlo simulations. We also propose two strategies to optimize  SBG . The experiments on six real social network datasets verify the effectiveness and scalability of our method and validate the impact of group consensus on the competitive influence dissemination process, as well as the importance of considering the process of reaching group consensus.}
}
